# 希腊字母

	| 大写 | 小写 | 英文读音 |   国际音标   |                     意义                     |
	|------|------|----------|--------------|----------------------------------------------|
	| Α    | α    | alpha    | /ˈælfə/      | 角度，系数，角加速度                         |
	| Β    | β    | beta     | /'beitə/     | 磁通系数，角度，系数                         |
	| Γ    | γ    | gamma    | /'gæmə/      | 电导系数，角度，比热容比                     |
	| Δ    | δ    | delta    | /'deltə/     | 变化量，屈光度，一元二次方程中的判别式       |
	| Ε    | ε    | epsilon  | /ep'silon/   | 对数的基数，介电常数                         |
	| Ζ    | ζ    | zeta     | /'zi:tə/     | 系数，方位角，阻抗，相对粘度                 |
	| Η    | η    | eta      | /'i:tə/      | 迟滞系数，效率                               |
	| Θ    | θ    | theta    | /'θi:tə/     | 温度，角度                                   |
	| Ι    | ι ℩  | iota     | /ai'oute/    | 微小，一点                                   |
	| Κ    | κ    | kappa    | /'kæpə/      | 介质常数，绝热指数                           |
	| Λ    | λ    | lambda   | /'læmdə/     | 波长，体积，导热系数                         |
	| Μ    | μ    | mu       | /mju:/       | 磁导系数，微，动摩擦系（因）数，流体动力粘度 |
	| Ν    | ν    | nu       | /nju:/       | 磁阻系数，流体运动粘度,光子频率              |
	| Ξ    | ξ    | xi       | /ksi/        | 随机数，（小）区间内的一个未知特定值         |
	| Ο    | ο    | omicron  | /oumaik'rən/ | 高阶无穷小函数                               |
	| ∏    | π    | pi       | /pai/        | 圆周率，π(n)表示不大于n的质数个数            |
	| Ρ    | ρ    | rho      | /rou/        | 电阻系数，柱坐标和极坐标中的极径，密度       |
	| ∑    | σ ς  | sigma    | /'sigmə/     | 总和，表面密度，跨导，正应力                 |
	| Τ    | τ    | tau      | /tau/        | 时间常数，切应力                             |
	| Υ    | υ    | upsilon  | /ju:p'silən/ | 位移                                         |
	| Φ    | φ    | phi      | /fai/        | 磁通，角，透镜焦度，热流量                   |
	| Χ    | χ    | chi      | /kai/        | 统计学中有卡方(χ2)分布                       |
	| Ψ    | ψ    | psi      | /psai/       | 角速，介质电通量                             |
	| Ω    | ω    | omega    | /'oumigə/    | 欧姆，角速度，交流电的电角度                 |


# Essence of Linear Algebra 线性代数
- [矩阵乘法运算的本质](https://www.zhihu.com/question/21351965)
- [图形学中的基本变换 Basic Transforms](https://zhuanlan.zhihu.com/p/96717729)
- [3blue1brown 线性代数的本质](https://www.bilibili.com/video/BV1ys411472E)
- [Grant Sanderson 主页](http://www.3blue1brown.com/about/)
- [数学工作室](http://mathstud.io/)
- https://www.mathsisfun.com/algebra/matrix-multiplying.html
- https://mathworld.wolfram.com/topics/Algebra.html
- Advanced Modern Algebra Joseph J. Rotman https://book4you.org/book/439766/a9d5bc
- Contemporary Abstract Algebra Joseph A. Gallian https://book4you.org/book/3374622/f78616

代数学发展的 4 个阶段：算术、初等代数、高等代数、抽象代数。

- 线性代数：核心是线性空间和线性变换（而不是算行列式和矩阵求逆！但国内很多学校，尤其是工科，把讲课和考试重点放在了各种计算上，不好说他们误人子弟吧，反正是没讲到线性代数里最核心最美的部分。怎么说呢，毕竟我们需要的工程师多于科学家，不甚理解概念但算工扎实也还算对得起社会）。讲的东西比较具体，比如乘一个矩阵相当于对图片进行多少度旋转之类的，容易有直观认识。在计算机图形学中非常重要。

- 高等代数：线性代数的加强版，是线性代数到抽象代数之间的过渡（在我校课程设置里，线代和高代算是一门课的难度不同的版本）。和线性代数相比，更加注重证明和对线性空间等概念的理解。内容开始从具体变得抽象，比如丘维生那本高代会讲一些多项式环的内容，慢慢往抽象代数过渡。

- 抽象代数（近世代数）：主要讲各种代数结构（群/环/域/格），内容高度抽象，学的就是概念和结构，基本上是定理和证明堆起来的，几乎没有计算。在密码学中非常重要，在程序语言设计和编译系统设计中稍有应用。


线性代数是一个解决线性问题的工具，从几何的观点去理解线性代数是一个能直观感受什么是线性的本质。

在学校，教书的人不一定能以你能理解的的方式向你教授什么是线性代数，因此，从另一个角度去理解线性代数而不是一味地学习线性代数的运算规则，更能呈现线性代数的简明本质。普适的代价是抽象 Abstractness is the price of generality！

以下是 Jean Dieudonné 一段话：尽管一批教授和教科书编者用关于矩阵的荒唐至极的计算掩盖了线性代数的简明性，这鲜有与之相较更为初等的理论。

> There is hardly any theory which is more elementary than linear algebra, in spite of the fact that generations of professors and textbook writers hav obscured its simplicity by preposterous calculations with matrices.
>
> -- Jean Dieudonné


线性代数是众多学科需要使用的计算工具：

- 计算机科学 Computer Science
- 物理学 Physics
- 电气工程学 Electrical engineering
- 机械工程学 Mechanical engineering
- 统计学 Statistics

通常，学校教学的知识是肤浅的矩阵加乘，点积，叉积，或行列式计算，但是，对于线性代数背后的本质理解相当薄弱。这取决于以下两种绝然不同的思维：

- 数值计算 Numeric operations
- 几何直观 Geometric intution

相比数值计算的教学方式，几何直观更有助于理解为何线性代数的要如此定义运算规则，以及线性代数的作用和意义。而数值计算的学习，是能让你正确运用这些工具。但是没有几何直观的理解，你只充当的一台计算机的工作，并不知道这运算背后所包含的意义及后续的作用。

本文配合视频使用效果更佳。

原作者 3Blue1Brown 本名 Grant Sanderson 是斯坦福毕业的学生，美男子一枚，这套视频里的动画演示都是他自己用 Python 编写的，github 上有。线代这套视频片头 BGM 也是他自己写的，在他个人主页有介绍。

Grant 毕业于斯坦福大学数学系，他毕业之后加入了 Khan Academy 担任了 2 年的数学讲师，他的早期课程（如 Multivariable Calculus 多元函数微积分）大家依然可以去围观。Grant 在他的自我介绍里坦诚，他爱好数学多年来感受最深一点，并不是为了写出一道证明题的解，而是能够自己摸索并最终自己发现真理的过程。他坚信能迫使加深理解的最好方法，是尝试把知识点解释给别人，这样做才会有那种自己探索的过程。在 Khan Academy 的两年更加坚定了他对数学教学的这个看法，但他同时也更想尝试些创新，尤其是想释放他本人在动画 Animation 方面的激情，于是便有了现在的三蓝一棕频道。之所以取名三蓝一棕是因为 Grant 本人就是异色瞳，3/4 蓝色 1/4 棕色。


## Algebra Introduction
- https://www.mathsisfun.com/algebra/index.html

`代数` Algebra 的基本概念就是用符号代替数字，`公式` Formula 是约定成俗的计算规划，`方程` Equation 的基本概念是 Balance `平衡`等式，平衡式两边再时做相同的运算处理依然保持平衡。`不等式` Inequalities 则是不平衡的式子，和平衡式的差别在于它的平衡状态，类似地，在不等式子两边做相同的运算可以保持不平衡性。而，解不等式 Solve Inequalities 就是找出不平衡的因素。

例如，以下这条方程： 

	x / 3 = 5

两边同时乘 3，方程持平衡不变，但是表现形式却改变了，选择乘 3 是因为可以将左侧的分母 3 消去：

	x = 3 * 5

代数式中通常涉及`常量` Constant，`变量` Variable 和`系数` Coefficient，列如，下面的常量 c、系数 a、b，和变量 x，`指数` 或者叫幂 Exponents 为 2 也可以当作常量看待。

	ax^2 + bx + c

指数，表示含代数项本身相乘的次数，当指数为 0 表示 1，除非代数本身为 0，如果指数为负数，则表示相除次数，也只可以用其`倒数` Reciprocal 的指数形式表达，一个数的倒数就是用它自身作分母，或者用 -1 次方表示：

	8^0 = 1
	8^3 = 8 × 8 × 8 = 512
	8^-2 = 1/8^2 = 1/(8 × 8) = 1/64

1 和 0 的指数运算保持不变，但 0^0 的指数是未定义的 indeterminate，也许它可以定义为 1：

	1^3 = 1
	0^3 = 0

当指数在 (0, 1) 这个取值区间时比较有意思，可以看作一般整数指数运行的逆运算，指数为 2 说是`平方` Square，指数是 1/2 说明`开平方根` Square Root，类似还有`立方` Cube 即 3 次方，`立方根` Cube Root。开方根运算常常产生无限不循环的数，叫做`无理数` Surd，拉丁文的 surdus：

	4^(1/2) = 2 ---> 2^2 = 4

那些大于 0 的`整数` Integer 归类为`自然数` Natural，而能用自然数的分式表达的数都是`有理数` Rational，否则就是`无理数` Irrational。

将直线数轴的概念扩大，还有`负数` Negative 和`正数` Positive，和`小数` 或者叫分数 Fraction。再增加一条竖直坐标，还可以扩展到`复数` Complex 概念，水平数轴上的称为`实数` Real，竖起轴上的称为`虚数` Imaginary Number。

**质数** Prime 以前也叫素数，指那么大于 1 不能被其它数整除的数，除了其自身。

`多项式` Polynomial 是指可以包含常量、变量、系数、指数，但没有除数一个式子，每个项就是一个 Term，有一个项就是单项式 Monomial，两项就是 Binomial，三项就是 Trinomial，如上面的二次多项式。

代数运算中，基本的顺序是 PEMDAS 或 BODMAS!

- P - Parentheses first
- B - Brackets first
- E - Exponents (ie Powers and Square Roots, etc.)
- O - Orders (i.e. Powers and Square Roots, etc.)
- DM -  Division and Multiplication (left-to-right)
- AS -  Addition and Subtraction (left-to-right)


线性代数之所以叫线性代数，因为它就是用来解决线性问题的，而线性问题可以理解为，能用二维坐标中的线条表示的问题。

列表有一系列食品：

|    食品   |  单价 |
|-----------|------|
| Apple     | $3   |
| Cherry    | $4   |
| Blueberry | $2   |

销售量：

|           | Mon | Tue | Wed | thu |
|-----------|-----|-----|-----|-----|
| Apple     | 13  | 9   | 7   | 15  |
| Cherry    | 8   | 7   | 4   | 6   |
| Blueberry | 6   | 4   | 0   | 3   |
| Count     | $83 | $63 | $37 | $75 |

把它们当作两个矩阵，计算周一的销售额，就是点积 dot product：

	($3, $4, $2) • (13, 8, 6) = $3×13 + $4×8 + $2×6 = $83

反过来，假如知道当天的销售额，而不知道某一个销售量，这就一个典型的线性代数问题。

这种，用矩阵的行和矩阵的列中的各个相乘再相加的式子也叫行列式 The determinant，当然这只是一种形象的名称，行列式的含义不仅限于此。


 

## 线性代数在图像处理的应用

在向量系统中，基底 Basis 是特别重要的单位，二维空间中的任何向量都是可以通过缩放 i、j 这两个向量基底再将它们相加的值表示出来。譬如向量 (3, 2) 就是沿着 i 的方向拉伸 3 倍, 再沿着 j 方向拉伸 2 倍的向量。

例如，二维空间中，当两个向量相加，几何图形上就是按基底前的系数进行比例缩放，和轴线方向缩放值再相加。

线性变换是一种保留向量加法和标量乘法的运算，向量中的数值系数称为标量 Scalars，在向量的运算过程中也只是放大缩小的作用，所以可以等价 Scale。旋转变换是另一种线性变换。缩放变换和旋转变换，事实上所有的对于 3D 向量的线性变换，都可以表示成一个 [3 x 3] 的矩阵。

在计算机图形学中，我们时常想要把各种变换结合起来，如先把一个物体缩小一半，再绕某个轴旋转 90 度，再平移到某个位置。但这种结合无法只用一个简单的 3D 矩阵实现。

为了结合线性变换和平移变换可以使用仿射变换 Affine Transform，通常存储在一个 [4 x 4] 的矩阵中。仿射变换是一种变换，即先完成线性变换，然后再完成平移变换。

图像处理中，颜色转换涉及使用矩阵来修改颜色，通过矩阵转换 RGB 颜色。 

若要理解这些颜色转换，一定要熟悉矩阵概念。矩阵就是一种数据格式，由于它具有统一的加减乘除等丰富的运算规则，非常方便处理线性代数问题，而广泛应用于计算机图形学上。

列如最常见的灰度化处理，对于使用标准红色绿色蓝色 sRGB 色域的视频，此公式为：

	gray-shade = 0.2126·R + 0.7152·G + 0.0722·B

直接使用公式也是可以计算得到灰度图形的，但是实际应用中，不仅只有这一条公式，就以仿射变换为例，它有平移、旋转、缩放、切变等等。使用矩阵的好处就是，通过定义矩阵的系数就可以通过矩阵的运行法则来得到不同公式的结果，这真的很方便！更重要的是，图形处理中，常常是以图片中一组像素数据作为输入，输出另一组变换后的像素数据，这也使得直接应用公式的方法受到极大的束缚。

灰度颜色矩阵是最常见的用途之一，这涉及到红色、绿色和蓝色值的加权平均值的公式。 若要将颜色位图转换为灰色缩放位图，R'、G' 和 B' 结果必须等于相同的值。 矩阵为：

	| 0.21 0.72 0.07 0 0 |    | R |   | 0.2126·R + 0.7152·G + 0.0722·B |
	| 0.21 0.72 0.07 0 0 |    | G |   | 0.2126·R + 0.7152·G + 0.0722·B |
	| 0.21 0.72 0.07 0 0 |  × | B | = | 0.2126·R + 0.7152·G + 0.0722·B |
	| 0    0    0    1 0 |    | A |   | A |
							  | 1 |

## Vectors, what event are they?
- [数学运算符 Unicode 字符表](http://www.52unicode.com/supplemental-mathematical-operators-zifu)

向量是线性代数的基本，没有向量这个概念就描述不了线性代数。所以，对于向量要有一个统一的概念。

向量空间 Vector 是什么？一般来讲，有三种观点：

- 计算机学生眼里向量是数字列表
- 物理学生眼里向量是箭头
- 数学家认为向量可以表示任何东西，只要满足两个运算关系——数乘 scalar multiplication 与加法

基本上来讲，向量有两个基本特征，长度 `Length` 和方向 `Direction`，所以用一条带箭头的线段表示向量是恰当的。在一个平面上，只要保持两个特征不变，任意移动这个箭头线段，向量还是保持为原来那个向量。这是二维 Two-Dimentional 向量，当然还有三维空间上的向量 Three-Dimentional。在计算机科学中，向量表示为有序的数值，或用列表，或者用数据保存。

而科学家则会使用更抽象的符号来表示向量，通常是小写字母上面加一个向右的箭头表示，在这里方便打字，可以直接用 v、u、w 这样的字母符号表示向量。⨯ 或 · 点作为叉乘和点积的运算符号。

在学习向量运算前，先来理解向量的几何意义，把线段的一端作为起点，箭头所指的末端作为终点，那在一个空间中，向量始终向起点指向终点。而有序的数值这个概念，也就是从这个角度去理解的。建立两者的关系理解，就是数值计算和几何直观的两种观念的转变，或互换。

为了方便研究向量，需要在平面上画一条水平线和一个垂直线，等距分割线条作标记点，建立一个十字坐标系统，向右为 x Axis 轴正向，向上为 y Axis 轴正方向。那么给定一个向量，比如坐标 (-2, 3) 对应在 x 轴上的负方向走出去两段，再沿 y 轴的正向走 3 格，然后，从原点指向终点的这个线段和箭头所指的方向结合起来就是这个向量所表示的几何意义。在三维空间上，增加了一个坐标维度，但这个概念同样理解。同样，对于一维的情况，也就是一条数轴的情况下，也适合这样的理解。

举例，两个向量相加，(-2, 3) + (-1, 2)，几何上理解就是，从起点沿着 x 轴走 -3 段，-2 加 -1 的结果。然后，再向 y 轴走 5 段，用线性代数的表达式表示：

	| -2 |   | -1 |   | -2 + -1 | 
	|  3 | + |  2 | = |  3 +  2 | 

向量每个坐标值乘上一个数，即`数乘`，可以理解为在某轴上进行缩放 `Scaling`，它和标量 `Scalars` 是同一个目标意思。

对于二维坐标上的点，用两行表达，如果是三维坐标点，就需要三行。





## Linear combinations, span and bases
基底与线性组合、张成空间

实际应用中为了简化运算，需要引入`基底` Basis Vectors 的概念，为每个轴上定义一个单位向量。也就是前面建立坐标系统进等距分割数轴时，沿 x 轴分割的一等分记作沿 x 正方向的单位向量 i，正式书写时，它应该上面加个盖帽。还有 y 轴上的单位向量 j，同样也应该在上面加个盖帽，但是这里为了方便打字省略了。

这样一来，向量相加和数乘就可以理解为，对各轴单位向量的缩放再相加，这个思想既重要又基础。

可以这样理解线性，在一个平面中选取两个向量，保持其中一个不变，另外一个任意伸缩，那么这两个向量相加的结果就是扫过这个平面上的一条直线。

当两个向量都进行伸缩时，那么它们就会扫过整个平面，而这些变化中的向量集合成的平面就叫作`张成空间` Span space。例外的情况是，这两个向量的方向重叠时，它们张成是一条直线。

同样，在三维空间上的三个不同方向的向量，它们张成的空间就是三维空间的体积。只要其中有两个向量其线，那么张成空间就压缩为平面，如果三向量都共线，张成空间就压缩为一条线。有个极端的情况，即向量都为 0 向量时，张成空间就是原点。

当一个维度的的向量的增加或数乘不能增加张成空间的维度时，也即称为`线性相关` Linearly dependent，或者理解为这个向量约束在其它向量张成的空间内。原文是 dependent 原单是依赖、束缚的意思，中文的相关一词略显松垮不严谨。而当，某向量的加入可以增加原有向量的张成空间的维度，那么这就是非线性约束，即`线性不相关` Linearly independent。

当我们要考虑很多向量的时候，使用箭头表达向量的方式会让空间显得过于拥挤，可以使用简化的圆点来表示，只要原点指向圆点的位置符合原先的向量方向即是等价的。


基底的严格定义 Technical definition of basis：

> The basis of a vector space is a set of linearly independent vectors that span the full space。
> 
> 向量空间的一组基底是张成该空间的线性无关的向量集。



## Matrices as linear transfomations
线性变换与矩阵

墨菲斯有绝佳的句子描述直观理解矩阵操作重要性：

> Unfortunately, no one can be told what the matrixs is, You have to see it for yourself. - Morpheus
>
> 很遗憾，没人能告诉你矩阵是什么，你须自己亲眼眼透。 - 墨菲斯


`线性变换` Linear transformation 中的变换本质是函数的花哨说法，这个变换函数接收输出的向量，按矩阵运算规则输出向量。使用`变换`一词的目的是，提醒我们，应该以运动的视角去理解这个函数。即输入的向量，会在矩阵中描述的那变换到新的坐标位置，平移、旋转、切变等，即`仿射变换` Affine Transform。当然还有非线性的变换，只不过，考虑线性变换更容易去理解矩阵操作背后的几何直观。

给定一个向量 (5, 7) 考虑如下的变换，按数值计算应该如下：

	| 1  -3 |   | 5 |   | 1x5 + -3x7 |   | -16 |
	| 3   4 | x | 7 | = | 2x5 +  4x7 | = |  38 |

线性变换要满足两个条件：

- 直线依旧是直线 Lines remain lines
- 原点保持不变 Origin remains fixed

在仿射变换中，可能出现原点移动了，所以不是所有防射变换都是线性变换。原有坐标系统按方格标记，变换后，如果改变原有的网格比例的也不是线性变换。

一个更直观描述变换的方法是，直接观察基底向量的变换前后的差异来得出变换结果。

例如，有一个输出向量 (-1, 2)，即 v = -1i + 2j。通过图形观察，变换前，两个基底的坐标是 (1, 0)、 (0, 1) 变换后的基底坐标是 (1, -2)、 (3, 0) 。要计算变换矩阵，可以将其对两个基底的变换作用提取到矩阵中，再与输入向量做作数乘再相加，可以计算出变换后的向量落到 (5, 2)，这其实是一个旋转加切换的变换：

	   |  1 |     | 3 |   |  -1x1 + 2x3 |   | 5 |
	-1 | -2 | + 2 | 0 | = | -1x-2 + 2x0 | = | 2 |

注意，上面的式子，i 和 j 两个向量坐标分别和输入向量的 x、 y 坐标相乘，结果需要一个新坐标，这里的计算就是数乘再相加，输入向量的坐标系数作为基底向量的缩放比例。

以上式子说的是，一个二维纯属变换仅用四个数字就可以完全确定，即变换后 i 向量的坐标和 j 向量的坐标，通常它们包装为 2x2 的矩阵中。用代数式表达这两个坐标 (a, c)、 (b, d)，可以将上面的式子写成通用的格式。

	| a  b |  | x |     | a |     | b |   | ax + by |
	| c  d |  | y | = x | c | + y | d | = | cx + dy |

应用以上的方法，比如将坐标进行逆时针 90 度的旋转，那变换后的 i 和 j 的坐标就是 (0, 1)、 (-1, 0)，这个旋转 90 度的变换矩阵就是：

	| 0 -1 |
	| 1  0 |

任何坐标，只要和这个矩阵相乘就可以旋转 90 度，按同样的理解，要沿着 x 轴切变，j 向量不变，j 向量左右移动，那么向右切变的矩阵应该如下：

	| 1  1 |
	| 0  1 |

反过来，给定一个变换矩阵，如下，它是什么变换呢：

	| 1  3 |
	| 2  1 |

是不是可以很直观看到，这个变换在 i 向量的 y 轴伸长到 2 倍，在 j 向量的 x 轴上由 0 伸长 3 的位置。并且产生了一个翻转，因为 j 向量跑到 i 向量右侧了。如果不能通过以上矩阵相像到这样的变换，那么重复学习前面的内容。

再来看看另一个矩阵：

	| 2 -2 |
	| 1 -1 |

这个变换在 i 向量的 x 轴伸长到 2 倍，y 轴移动到 1 的位置，在 j 向量的 x 轴上伸长到负轴的 2 位置，y 轴反转到 -1 位置。这时它们共线了，并且方向相反，复习前面线性相关的慨念，这里就是`线性相关列` Linearly dependent columns，也就是说，变换后原本的张成平面空间变成了一条线。



## Maxtrix multiplication as composition
以组合变换的几何形式理解矩阵乘法

前面讲到矩阵用于变换的几何意义，使用矩阵，只需要选择特定的数字，就可以得到平移、旋转、缩放、切变等等的运算，并且它们的复合计算也可以表达在矩阵内。

列如，二维平面上的点进行仿射变换 Affine Transform，只需要一个 2 x 2 矩阵，如下式子，左乘两个矩阵具有连续几何变换作用，这里是 Shear 和 Rotation 两种几何变换：

	| 1 1 |   | 0 -1 |   | x |     | 1 -1 |   | x |
	| 0 1 |   | 1  0 |   | y |  =  | 1  0 |   | y |
	 Shear    Rotation            Composition

上面的写法中两个独立的变换等价于一个复合变换，可以计算 [x, y] 旋转后 [-x, y]，也就是逆时针 90 度旋转，再沿 x 轴切变为 [-x + y, y]。注意，这两个变换的矩阵运算顺序会影响结果。前面的变换矩阵之所以计算和书写都从右往左，是和 f(g(x)) 这样的函数表达是一致的。后而可以计算，和两个单独的矩阵等价的组合变换矩阵，但是现在记住两个矩阵相乘的几何意义更重要。

利用几何变换的意义去替代实际的运算，即通过跟踪向量基底的运动方向来理解矩阵运算产生的几何意义，这样更有助于理解线性变换的意义。

现在来试试以下两个变换是如何得到等价的组合矩阵的，右侧四个问题表示的是 i 和 j 向量最终的坐标，第一列是 i 的坐标，第二列是 j 的坐标：

	| 0 2 |   | 1 -2 |     | ? ? |
	| 1 0 |   | 1  0 |  =  | ? ? |

首先，右侧这个矩阵，取出 i 向量，即 (1, 1)，它就是第一个变换后得到的 i 向量位置。接下来还要经过第二个变换，懂么按前面的计算方法：

	| 0 2 |  | 1 |       | 0 |     | 2 |   | 1x0 + 1x2 |   | 2 |
	| 1 0 |  | 1 |  =  1 | 1 | + 1 | 0 | = | 1x1 + 1x0 | = | 1 |

这里得到的二维坐标 (2, 1) 就是经过二个变换矩阵的 i 向量最终坐标。按同样的计算方法，可以得到 j 的最终坐是 (0, -2)，所以组件矩阵的最终结果如下：

	| 2  0 |
	| 1 -2 |

这个方法具有普适性，This method works generally!

好的解析 Good explanation 胜于符号的证明 Symbolic proof！

在三维空间上的变换也适用，通过追踪三维空间中的基底向量 i、j、k 变换就可以像二维空间中的变换一样处理变换处理。比如以下这个变换矩阵，每一个向量的变换都是叠加的，先是 i 保持不变，j 向量在 y 轴上移动到 0 点，z 轴上移动 -1 个单位，k 向量向 y 轴移动 -1 个单位，z 轴上移动到 0 点。三者叠加后，原来的空间，就会沿 x 轴做 90 度旋转。

	| 1  0  0 |
	| 0  0 -1 |
	| 0 -1  0 |



## The determinant
行列式

英语用 `determinant` 表达这个东西是有问题的，这算是一个历史遗留的“错误”。英语 determinant 来自拉丁语 determinantem，和英语 determine 出自同一词根。determinantem 最早作为数学术语使用的记录来自高斯，如果要直接翻译的话很接近现在`判别式`的意思。高斯是在研究二次型的时候引入这个词的，当时用 determinantem 表示二次型的判别式是比较合理的。只不过后来 determinant 的使用范围被推广，从对称二次型推广到了一般方阵，这个时候再用“判别式”表达这个意思就不太合适了。但这个词最终就这么沿用下来了，现在英语中常用来表达判别式的词 `discriminant` 是后来造的。

determinant 不仅被用于二次型，当时也会有一个多项式函数的 determinant 这样的表达。之后 determinant 的其他含义逐渐消失，在数学上基本上只剩下了行列式这一个意思。梳理了历史就可以看到，中文要表达这个概念，直接翻译 determinant 并不合适。另造一个词表达这个意思才是合理的选择。

简单地说，英文名称从本质出发，而中文称为`行列式`是从式子的形状出发的。

对于二维空间方阵的行列式是一个数字，这个数字包含了矩阵的大量信息。计算结果直观说明了以下几种上情况：

- 二维行列式的值表明矩阵变换后原来向量构成的四边形面积的变化。
- 矩阵的行列式为零的话，矩阵就没有逆矩阵，表明变换后张成空间压缩成一条线或一个点，即线性相关。
- 矩阵的行列式小于零，表明矩阵翻转了，就像一张纸翻到了背面。

行列式的这些特性，可以从前面学到的矩阵变换的几何直观的角度来理解。

	    | a b |
	det | c d | = ad - cb

从几何变换上理解，行列式还可以表达为：

	    | a b |
	det | c d | = (a + b)(c + d) - ac - bd - 2bc

而对于三维空间的行列式，也做同样理解，不同的是从面积变更成体积。

	    | a b c |         |     |         |     |         |     |
	det | d e f | = a det | e f | - b det | d f | + c det | d e |
	    | g h i |         | h i |         | g i |         | g h |


## Inverse matrices, column space and null space
逆矩阵、列空间、零空间

逆矩阵、列空间、秩、零空间（Inverse matrices, Column space, Rank, Null space）


## Dot prooducts and duality
点积与对偶性

## Cross products via transformations
线性变换的眼光看叉积

## Change of basis
基底互换

## Eigenvectors and eigenvalues
特征向量与特征值

## Abstract vector spaces
抽象向量空间


















