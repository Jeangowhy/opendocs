中国科学院大学硕士研究生入学考试
=====================================

   中国科学院大学硕士研究生入学考试
   《人工智能基础》考试大纲

   一、基本要求及适用范围

   《人工智能基础》考试大纲适用于中国科学院大学（085410）人工智能专业硕士
   研究生入学考试。《人工智能基础》考试强调人工智能及其数学基础，要求考生对所
   涉及的基本概念和方法有准确的理解，具备较好数学基础和专业知识。

   二、考试形式及试卷结构

   考试采取闭卷笔试形式，考试时间 180 分钟，总分 150 分。  
   考查内容：人工智能基础（约占 70%）、数学基础（约占 30%）。  
   题型包括：选择、填空、判断、简答、计算及证明、综合等。  

   三、考试内容

   （一）人工智能的数学基础
   1.事件与概率
   2.随机变量与概率分布
   3.期望、方差与协方差的定义与应用
   4.矩阵基础

   （二）机器学习基础
   1.监督学习、无监督学习、半监督学习
   2.数据集、损失函数、优化方法
   3.泛化、过拟合、欠拟合

   （三）线性回归
   1.分类与回归
   2.优化方法
   3.岭回归、套索回归
   4.支持向量机

   （四）决策树模型
   1.决策树定义
   2.训练算法

   （五）神经网络基础
   1.深度线性网络与非线性神经网络
   2.反向传播算法、优化器
   3.权值初始化方法
   4.卷积神经网络、循环神经网络

   （六）计算机视觉基础
   1.视觉基本原理与概念
   2.线性滤波器
   3.边缘检测、物体检测、语义分割

   （七）自然语言处理基础
   1.语言模型基础
   2.向量语义
   3.基于神经网络的语言模型处理与机器翻译
   4.预训练语言模型

   四、考试要求

   （一）人工智能的数学基础
   掌握概率基础知识，例如概率分布、联合概率、边缘概率、条件概率等概念；  
   掌握离散随机变量、连续随机变量的主要性质，了解掌握伯努利分布、泊松分布、均匀分布、正态分布等常用概率分布的公式与参数；  
   掌握样本的概念和性质，统计量的定义与性质，三大抽样分布函数的定义；  
   掌握大数定理和中心极限定理；  
   掌握参数估计的定义，掌握点估计、极大似然估计方法的原理；  
   掌握评价估计量的标准、区间估计的概念和方法；  
   掌握矩阵的基础知识，例如矩阵的基本运算、矩阵的秩、特征值分解、奇异值分解等基本原理等。  

   （二）人工智能基础
   了解掌握人工智能的基本概念与定义；  
   了解人工智能主要领域方向的起源与发展历程；  
   了解掌握机器学习中监督学习、无监督学习和半监督学习的概念，掌握数据集、优化、泛化等过程中的方法和存在的问题；  
   了解掌握分类与回归的基本原理，基本优化方法，岭回归、套索回归、支持向量机等常见算法的原理；  
   了解掌握决策树的原理与训练算法；  
   了解掌握神经元网络的结构、反向传播算法、优化器、权值初始化、权值共享等原理；  
   了解掌握计算机视觉的基本概念，卷积神经网络的结构与原理，物体检测、语义分割等原理与方法；  
   了解掌握语言模型基本概念、向量语义、基于神经网络的语言模型处理、基于神经网络的机器翻译、预训练语言模型的基本原理与方法。  

   五、主要参考书目

   姚期智，《人工智能》，清华大学出版社，2022。
   编制单位：中国科学院大学
   编制日期：2024 年 8 月 30 日

   人工智能专业硕士研究生研究方向

   1.  人工智能（华大专项）
   2.  移动通信与多媒体通信
   3.  物联网技术及应用
   4.  智能终端与移动安全
   5.  图像处理与计算机视觉
   6.  语音信号处理与语音识别
   7.  视频（信号）处理与分析
   8.  无线传感器网络关键技术
   9.  无线泛在业务架构及技术
   10. 多传感器集成与数据融合
   11. 云计算、虚拟化
   12. 大数据技术与应用
   13. 计算机安全技术
   14. 脑认知与智能医生
   15. 智能控制与计算智能
   16. 模式识别
   17. 智能机器人
   18. 图像与视频处理
   19. 显微影像分析

清华大人工智能班教学设计
============================

清华大学本科培养方案
----------------------------

   交叉信息研究院

   计算机科学与技术（人工智能班）专业本科培养方案

   一、培养目标

   1. 全面掌握人工智能基础理论与前沿应用知识，科研实践能力强，并能终身学习。  
   2. 熟悉人工智能前沿领域，具有良好科学素养和创新精神，成为能够从事人工智能领域研究的领跑国际拔尖创新人工智能领域人才 。  
   3. 具有职业道德和社会责任感，具备与世界一流高校本科生同等、甚至更高的竞争力。  

   二、培养成效

   a. 应用数学、科学和工程知识的能力；  
   b. 发现、提出和解决工程问题的能力；  
   c. 理解所学专业的职业责任和职业道德；  
   d. 有效沟通的能力；  
   e. 认识终身学习的重要性并有效实施的能力；  
   f. 具备从本专业角度理解当代社会和科技热点问题的知识；  
   g. 综合运用技术、技能和现代工程共聚来进行工程实践的能力。   

   三、学制与学位授予

   学制：本科四年学制，按学制进行课程设置及学分分配。
   授予学位：工学学士学位。 

   四、基本学分学时

   本科培养总学分为 150 学分，实习实践 17 周。其中，全校统一设置课程（校级通识教育课程）46 学分，
   夏季学期 3 周；院系设置课程 104 学分，夏季学期 14 周。 

   五、课程设置与学分分布

   1．校级通识教育 46学分

   (1) 思想政治理论课 必修 17学分

   10610183 思想道德修养与法律基础 3学分  
   10680011 形势与政策 1学分  
   10610193 中国近现代史纲要 3学分  
   10610204 马克思主义基本原理 4学分  
   10680032 毛泽东思想和中国特色社会主义理论体系概论（1） 2学分  
   10680042 毛泽东思想和中国特色社会主义理论体系概论（2） 2学分  
   10680022 习近平新时代中国特色社会主义思想概论 2学分  

   (2) 体育 4学分

   第 1-4 学期的体育(1)-(4)为必修，每学期 1 学分；第 5-8 学期的体育专项不设学分，其中第5-6学期为限选，
   第 7-8 学期为任选。学生大三结束申请推荐免试攻读研究生需完成第1-4 学期的体育必修课程并取得学分。
   本科毕业必须通过学校体育部组织的游泳测试。

   体育课的选课、退课、游泳测试及境外交换学生的体育课程认定等请详见 2019 级学生手册《清华大学本科体育课程的有关规定及要求》。

   (3) 外语（一外英语学生必修8学分，一外其他语种学生必修6学分）
   
      学生  课组 课程 课程面向学分要求
      一外
      英语
      学生

      英语综合能力课组
      英语综合训练（C1）
      学分英语综合训练（C2）     入学分级考试 1 级4 
      英语阅读写作（B）
      级英语听说交流（B）        入学分级考试 2 
      英语阅读写作（A）
      英语听说交流（A）          入学分级考试 3 级、4 级

      第二外语课组
      外国语言文化课组
      外语专项提高课组           详见选课手册 4 学分
      一外小语种学生             详见选课手册 6 学分

   公外课程免修、替代等详细规定见教学门户-清华大学本科生公共外语课程设置及修读管理办法。

   (4) 写作与沟通课 必修 2学分  
   (5) 通识选修课 限选 11学分  
   通识选修课包括人文、社科、艺术、科学四大课组，要求学生每个课组至少选修2 学分。《学术之道》（10690013）必修。

   (6) 军事课程 4学分  

      12090052 军事理论 2学分  
      12090052 军事训练 2学分

   2．专业教育 104学分  

   （1）基础课程 29学分

   1) 数学必修 21学分

      10421055 微积分A(1) 5学分  
      10421065 微积分A(2) 5学分  
      20470044 线性代数 4学分  
      20470054 抽象代数 4学分  
               概率与统计 3学分  

   2) 物理必修 8学分

      20470024 普通物理(1)英 4学分  
      20470034 普通物理(2)英 4学分  

   （2）专业主修课程 49学分

      20470073 人工智能入门 3学分
      30470293 人工智能应用数学 3学分
      30470124 算法设计 4学分
      30470134 计算理论 4学分
      40470243 人工智能：原理与技术 3学分
      30470104 机器学习 4学分
               深度学习 3学分
               计算机视觉 3学分
      40470333 数据挖掘 3学分
               自然语言处理 3学分               四选三
               人工智能交叉项目(AI+X) 6学分
               人工智能研究实践 9学分

   （3）夏季学期和实践训练 11 学分

      30470232 信息物理 2学分
      20470062 代数与计算 2学分
      30470312 数据库系统概论 2学分
      40470342 生物信息学概论 2学分
      40470085 专题训练实践 5学分

   （4）综合论文训练要求 15学分


清华大学本科指导性教学计划
----------------------------

   交叉信息研究院计算机科学与技术（人工智能班）专业本科指导性教学计划
   
   第一学年

      课程编号 课程名称 学分 周学时 说明及主要先修课
      12090052 军事理论 2 3
      12090062 军事技能 2 3

      秋季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10610183 思想道德修养与法律基础 3 2
      10680011 形势与政策 1 1
      10720011 体育(1) 1 2
      10640532 英语(1) 2 2
      10691342 写作与沟通 2 2
      10421055 微积分A(1) 5 5
      20470044 线性代数 4 4
      20470073 人工智能入门 3 3
      合计：: 21

      春季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10610193 中国近现代史纲要 3 2
      10720021 体育(2) 1 2
      10640682 英语(2) 2 2
      10690013 学术之道 3 3
      10421065 微积分A(2) 5 5
      20470054 抽象代数 4 4
      20470024 普通物理(1)英 4 4
      30470293 人工智能应用数学 3 3
      合计： 25

      夏季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      30470232 信息物理 2 3
      20470062 代数与计算 2 3
      30470312 数据库系统概论 2 3   二选一
      合计： 4

   第二学年

      秋季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10610204 马克思主义基本原理 4 3
      10720031 体育(3) 1 2
      10641132 英语(3) 2 2
      20470034 普通物理(2)英 4 4
      30470124 算法设计 4 4
      30470303 概率与统计 3 3
      30470104 机器学习 4 4
      40470243 人工智能：原理与技术 3 3
      合计： 25

      春季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10680032 毛泽东思想和中国特色社会主义理论体系概论(1) 2
      10680022 习近平新时代中国特色社会主义思想概论 2 2
      10720041 体育(4) 1 2
      10641142 英语(4) 2 2
      30470134 计算理论 4 4
      40470284 量子计算机科学 4 4
      ******** 计算机视觉* 3 3
      ******** 深度学习* 3 3
      合计： 18
      注：*课程为四选三

      夏季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      40470342 生物信息学概论 2 3
      合计： 2 3

   第三学年

      秋季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10720110 体育专项(1) 2
      ******** 通识选修课 4 4
      40470333 数据挖掘* 3 3
      ******** 自然语言处理* 3 3
      ******** 人工智能交叉项目(AI+X) 6 6
      合计： 16
      注：*课程为四选三

      春季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10720120 体育专项(2) 2
      ******** 通识选修课 4 4
      合计： 4

      夏季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      40470085 专题训练实践 5 5
      合计： 5 5

   第四学年

      秋季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10720130 体育专项(3)
      ******** 人工智能研究实践 9 9
      合计： 9

      春季学期
      课程编号 课程名称 学分 周学时 说明及主要先修课
      10720140 体育专项(4)
      通识选修 2 2
      40470075 综合论文训练 15
      合计： 15

AI 论理学
======================

   CS 3111: Computer Ethics  
   https://www.d.umn.edu/~tcolburn/cs3111/  
   https://www.d.umn.edu/~tcolburn/cs3111/slides/ai/overview.pdf  

   Abridged history of AI

   •  1943 McCulloch & Pitts: Boolean circuit model of brain  
   •  1950 Turing's "Computing Machinery and Intelligence"  
   •  1956 Dartmouth meeting: "Artificial Intelligence" adopted  
   •  1952—69 Look, Ma, no hands!  
   •  1950s Early AI programs, including Samuel's checkers program, Newell & Simon's 
      Logic Theorist, Gelernter's Geometry Engine
   •  1965 Robinson's complete algorithm for logical reasoning (逻辑推理算法)  
   •  1966—73 AI discovers computational complexity Neural network research almost disappears  
   •  1969—79 Early development of knowledge-based systems  
   •  1980-- AI becomes an industry  
   •  1986-- Neural networks return to popularity as part of machine learning  
   •  1987-- AI becomes a science—triumph of neats over scruffies  
   •  1995-- The emergence of intelligent agents -- “-bots”  

   AI Ancient History

   •  800 B.C. -- Moving statue of the god Amon in ancient Egypt operated with 
      levers by a concealed priest.  
   •  300-100 B.C. -- Automated figures (like singing ravens) through the force 
      of steam and water in Greek city of Alexandria.

   AI Collaborators

   •  Philosophy Logic, methods of reasoning, mind as physical system foundations 
      of learning, language, rationality
   •  Mathematics Formal representation and proof algorithms, computation, 
      (un)decidability, (in)tractability, probability
   •  Economics utility, decision theory  
   •  Neuroscience physical substrate for mental activity  
   •  Psychology phenomena of perception and motor control, experimental techniques
   •  Computer building fast computers engineering
   •  Control theory design systems that maximize an objective function over time
   •  Linguistics knowledge representation, grammar  

   Sub-human Level

   •  Handwriting recognition  
   •  Object recognition  
   •  Translation  
   •  Speech recognition  
   •  Word-sense disambiguation  
   •  Natural language processing  

   Super- Or Par-human Level

   •  Backgammon, Bridge  
   •  Chess, Crosswords  
   •  Jigsaw puzzles  
   •  Car driving  
   •  Scrabble  
   •  Quiz show question answering  
   •  Go  
   •  OCR for printed text  

   Examples

   •  Deep Blue defeated the reigning world chess champion Garry Kasparov in 1997
   •  Proved a mathematical conjecture (Robbins conjecture) unsolved for decades
   •  No hands across America (driving autonomously 98% of the time from Pittsburgh to San Diego)
   •  During the 1991 Gulf War, US forces deployed an AI logistics planning and 
      scheduling program that involved up to 50,000 vehicles, cargo, and people
   •  NASA's on-board autonomous planning program controlled the scheduling of 
      operations for a spacecraft
   •  Proverb solves crossword puzzles better than most humans
   •  IBM's Watson beats best humans at Jeopardy!

   Aristotle's Logic of Syllogisms (350 B.C.)

   All men are mortal.  
   Socrates is a man.  
   Therefore, Socrates is mortal.  

   All S are P.  
   a is an S.  
   Therefore, a is a P  

   All S are P.  
   a is not a P.  
   Therefore, a is not an S  

   Modern notation:

   ∀x S(x) ⟶ P(x)  
   S(a)  
   ∴ P(a)  



# NLP
- [NLP - Natural Language Processing](https://algorithmia.com/blog/introduction-natural-language-processing-nlp)
- [Natural Language Toolkit(NLTK)](http://www.nltk.org/)
- [Apache OpenNLP](https://opennlp.apache.org/)
- [NLP with Python --- Analyzing Text with NLTK](http://www.nltk.org/book_1ed/)
- [自然语言处理是如何工作的？一步步教你构建 NLP 流水线](https://zhuanlan.zhihu.com/p/41850756)
- [夕小瑶的卖萌屋/ NLP](https://www.zhihu.com/people/tsxiyao/posts)
- [万字长文概述NLP中的深度学习技术](https://zhuanlan.zhihu.com/p/57979184)
- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [卷积神经网络 convolutional neural network，CNN](https://mp.weixin.qq.com/s/vcw_b2jBMiPQLW5gbjyVlg)
- Artificial Intelligence: A Modern Approach, 4th US ed. by Stuart Russell and Peter Norvig
  https://aima.cs.berkeley.edu/  
  https://github.dev/sxcong/books/blob/main/Artificial-Intelligence-A-Modern-Approach-4th.pdf


自然语言处理 NLP - Natural Language Processing 就是用计算机来处理、理解以及运用人类语言(如中文、英文等)，它属于人工智能的一个分支，是计算机科学与语言学的交叉学科，又常被称为计算语言学。由于自然语言是人类区别于其他动物的根本标志。没有语言，人类的思维也就无从谈起，所以自然语言处理体现了人工智能的最高任务与境界，也就是说，只有当计算机具备了处理自然语言的能力时，机器才算实现了真正的智能。

从研究内容来看，自然语言处理包括语法分析、语义分析、篇章理解等。从应用角度来看，自然语言处理具有广泛的应用前景。特别是在信息时代，自然语言处理的应用包罗万象，例如：机器翻译、手写体和印刷体字符识别、语音识别及文语转换、信息检索、信息抽取与过滤、文本分类与聚类、舆情分析和观点挖掘等，它涉及与语言处理相关的数据挖掘、机器学习、知识获取、知识工程、人工智能研究和与语言计算相关的语言学研究等。

中文信息处理是自然语言处理的分支。和大部分西方语言不同，书面汉语的词语之间没有明显的空格标记，句子是以字串的形式出现。因此对中文信息进行处理的第一步就是进行分词，将字串（character string）转变成词串（word string）。依据字在词语中位置，为每个字赋予不同的状态（如句子开始、句子中间、句子结尾、单字成词等），将输入的中文句子转化为状态序列。

NLP 作为人工智能的一个分支，能够处理机器和人类自然语言之间的交互，即 NLP 帮助计算机机器以各种形式使用自然人类语言进行交流，包括进行分析、理解、改变或生成自然语言。主要涉及的如下范畴（维基百科）：

- 中文自动分词
- 词性标注
- 句法分析
- 文本分类
- 信息抽取
- 知识图谱
- 问答系统和自动聊天机器人
- 机器翻译
- 自动摘要

以下都是自然语言处理（NLP）的一些成功应用：

- 搜索引擎，比如谷歌，雅虎等等。谷歌等搜索引擎会通过 NLP 了解到你是一个科技发烧友，所以它会返回科技相关的结果。
- 社交网站信息流，比如 Facebook 的信息流。新闻馈送算法通过自然语言处理了解到你的兴趣，并向你展示相关的广告以及消息，而不是一些无关的信息。
- 语音助手，诸如苹果 Siri。
- 垃圾邮件程序，比如 Google 的垃圾邮件过滤程序，这不仅仅是通常会用到的普通的垃圾邮件过滤，现在，垃圾邮件过滤器会对电子邮件的内容进行分析，看看该邮件是否是垃圾邮件。

事实上，“人工智能”被作为一个研究问题正式提出来的时候，创始人把计算机国际象棋和机器翻译作为两个标志性的任务，认为只要国际象棋系统能够打败人类世界冠军，机器翻译系统达到人类翻译水平，就可以宣告人工智能的胜利。四十年后的1997年，IBM公司的深蓝超级计算机已经能够打败国际象棋世界冠军卡斯帕罗夫。而机器翻译到现在仍无法与人类翻译水平相比，从此可以看出自然语言处理有多么困难！

理解人类语言远比破译密码要复杂得多，1966 年的一份研究报告总结发现，经过十年之久的研究，结果远远未能达到预期，因此支持资金急剧下降，使自然语言处理（特别是机器翻译）的研究陷入长达二十年的低潮。直到二十世纪八十年代，随着电子计算机的计算能力的飞速提高和制造成本的大幅下降，研究者又开始重新关注自然语言处理这个极富挑战的研究领域。三十年沧海桑田，此时研究者已经认识到简单的语言规则的堆砌无法实现对人类语言的真正理解。研究发现，通过对大量的文本数据的自动学习和统计，能够更好地解决自然语言处理问题，如语言的自动翻译。这一思想被称为自然语言处理的**统计学习模型**，至今方兴未艾。

基于机器学习框架的自然语言处理主要困难或挑战很多，不过关键在于**消除歧义**，如词法分析、句法分析、语义分析等过程中存在的歧义问题，简称为消歧。而正确的消歧需要大量的知识，包括语言学知识（如词法、句法、语义、上下文等）和世界知识（与语言无关）。这带来自然语言处理的两个主要困难。

- 场景的困难：语言的多样性、多变性、歧义性
- 学习的困难：艰难的数学模型（hmm, crf, EM, 深度学习等）
- 语料的困难：什么的语料？语料的作用？如何获取语料？

首先，语言中充满了大量的歧义，这主要体现在词法、句法及语义三个层次上。歧义的产生是由于自然语言所描述的对象――人类活动非常复杂，而语言的词汇和句法规则又是有限的，这就造成同一种语言形式可能具有多种含义。

正确的单词切分取决于对文本语义的正确理解，而单词切分又是理解语言的最初的一道工序。这样的一个“鸡生蛋、蛋生鸡”的问题自然成了（中文）自然语言处理的第一条拦路虎。

其他级别的语言单位也存在着各种歧义问题。例如在短语级别上，“进口彩电”可以理解为动宾关系（从国外进口了一批彩电），也可以理解为偏正关系（从国外进口的彩电）。又如在句子级别上，“做手术的是她的父亲”可以理解为她父亲生病了需要做手术，也可以理解为她父亲是医生，帮别人做手术。总之，同样一个单词、短语或者句子有多种可能的理解，表示多种可能的语义。如果不能解决好各级语言单位的歧义问题，我们就无法正确理解语言要表达的意思。

另外一个方面，消除歧义所需要的知识在获取、表达以及运用上存在困难。由于语言处理的复杂性，合适的语言处理方法和模型难以设计。

在试图理解一句话的时候，即使不存在歧义问题，也往往需要考虑上下文的影响。以“小明欺负小亮，因此我批评了他”为例。在其中的第二句话中的“他”是指代“小明”还是“小亮”呢？要正确理解这句话，我们就要理解上句话“小明欺负小亮”意味着“小明”做得不对，因此第二句中的“他”应当指代的是“小明”。由于上下文对于当前句子的暗示形式是多种多样的，因此如何考虑上下文影响问题是自然语言处理中的主要困难之一。 

正确理解人类语言还要有足够的背景知识。举一个简单的例子，在机器翻译研究的初期，人们经常举一个例子来说明机器翻译任务的艰巨性。在英语中“The spirit is willing but the flesh is weak.”，意思是“心有余而力不足”。但是当时的某个机器翻译系统将这句英文翻译到俄语，然后再翻译回英语的时候，却变成了“The Voltka is strong but the meat is rotten.”，意思是“伏特加酒是浓的，但肉却腐烂了”。从字面意义上看，“spirit”（烈性酒）与“Voltka”（伏特加）对译似无问题，而“flesh”和“meat”也都有肉的意思。那么这两句话在意义上为什么会南辕北辙呢？关键的问题就在于在翻译的过程中，机器翻译系统对于英语成语并无了解，仅仅是从字面上进行翻译，结果自然失之毫厘，差之千里。 

从上面的两个方面的主要困难，我们看到自然语言处理这个难题的根源就是人类语言的复杂性和语言描述的外部世界的复杂性。人类语言承担着人类表达情感、交流思想、传播知识等重要功能，因此需要具备强大的灵活性和表达能力，而理解语言所需要的知识又是无止境的。

目前，人们主要通过两种思路来进行自然语言处理：

- 一种是基于规则的理性主义；
- 另外一种是基于统计的经验主义；

理性主义方法认为，人类语言主要是由语言规则来产生和描述的，因此只要能够用适当的形式将人类语言规则表示出来，就能够理解人类语言，并实现语言之间的翻译等各种自然语言处理任务。而经验主义方法则认为，从语言数据中获取语言统计知识，有效建立语言的统计模型。因此只要能够有足够多的用于统计的语言数据，就能够理解人类语言。然而，当面对现实世界充满模糊与不确定性时，这两种方法都面临着各自无法解决的问题。例如，人类语言虽然有一定的规则，但是在真实使用中往往伴随大量的噪音和不规范性。理性主义方法的一大弱点就是鲁棒性差，只要与规则稍有偏离便无法处理。而对于经验主义方法而言，又不能无限地获取语言数据进行统计学习，因此也不能够完美地理解人类语言。二十世纪八十年代以来的趋势就是，基于语言规则的理性主义方法不断受到质疑，大规模语言数据处理成为目前和未来一段时期内自然语言处理的主要研究目标。统计学习方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。


迈进二十一世纪，我们已经进入了以互联网为主要标志的海量信息时代，这些海量信息大部分是以自然语言表示的。一方面，海量信息也为计算机学习人类语言提供了更多的“素材”，另一方面，这也为自然语言处理提供了更加宽广的应用舞台。例如，作为自然语言处理的重要应用，搜索引擎逐渐成为人们获取信息的重要工具，涌现出以百度、谷歌等为代表的搜索引擎巨头；机器翻译也从实验室走入寻常百姓家，谷歌、百度等公司都提供了基于海量网络数据的机器翻译和辅助翻译工具；基于自然语言处理的中文（输入法如搜狗、微软、谷歌等输入法）成为计算机用户的必备工具；带有语音识别的计算机和手机也正大行其道，协助用户更有效地工作学习。总之，随着互联网的普及和海量信息的涌现，自然语言处理正在人们的日常生活中扮演着越来越重要的作用。

然而，我们同时面临着一个严峻事实，那就是如何有效利用海量信息已成为制约信息技术发展的一个全局性瓶颈问题。自然语言处理无可避免地成为信息科学技术中长期发展的一个新的战略制高点。同时，人们逐渐意识到，单纯依靠统计方法已经无法快速有效地从海量数据中学习语言知识，只有同时充分发挥基于规则的理性主义方法和基于统计的经验主义方法的各自优势，两者互相补充，才能够更好、更快地进行自然语言处理。

基本概念：

- 文本集合称为语料库 Corpus 当有几个这样的文本集合的时候，称之为语料库集合 Corpora。
- LSTM 长短期记忆网络 Long Short-Term Memory Networks
- GRU 门控循环单元 
- ResNet 和残差网络 
- RNN 循环神经网络 Recurrent Neural Network

    深度学习有一个 Recursive Neural Network 也称为 RNN，注意区别。

    人类的思考具有持续性，当你读这篇文章的时候，你会根据你对前面单词的理解来理解每个单词，你不会把所有的东西都扔掉然后从头开始思考。 

    传统的神经网络无法做到这一点，假设您想对电影中每一点发生的事件进行分类，目前还不清楚传统的神经网络如何利用它对电影中先前事件的推理来告知后来的事件。 

    递归神经网络解决了这个问题，它们是带有循环的网络，允许信息持续存在。

- CNN 卷积神经网络 convolutional neural network

    是一种专门用来处理网格结构数据（例如图像数据）的前馈神经网络，是由生物学家Hubel和Wiesel在早期关于猫脑视觉皮层的研究发展而来。

    卷积 Convolution 是分析数学中一种重要的运算，有着非常广泛的运用，在图像处理中，常用的是二维卷积。以单通道的灰度图像为例，对图像进行卷积操作，就是使用一个卷积核（也称滤波器，在本书中统一称为卷积核）分别与图像的同大小区域进行点乘，卷积核依次从左往右从上往下滑过该图像的所有区域，点乘后得到的矩阵其各个位置上的值累加，作为卷积后图像上的像素值。这种将图像和卷积核进行按位点乘后求和的操作，就是卷积神经网络中的卷积操作。

    卷积神经网络主要有以下三大特性：

    1. 局部连接

    前馈神经网络相邻的两层之间，前一层的每一个神经元与后一层的每一个神经元都有连接，这种情况称为全连接。全连接网络的一个缺点就是参数太多，假设我们输入到神经网络中的是一张三通道的彩色图像，图像像素量 128 * 128 和输入层单元个数一致。使用全连接网络的话，输入层到第一层隐藏层的每一个神经元都有49150个连接，随着网络层数的增加和每一层中神经元数量的增加，网络中的参数也会急剧增加。大量的参数不仅会拉低神经网络训练的效率，也很容易导致过拟合。

    在卷积神经网络中，层与层之间不再是全连接，而是局部连接，具体的实现方法就是我们在4.2节中会介绍的卷积操作。

    2. 权值共享

    在卷积神经网络中，每一层卷积层中都会有一个或者多个卷积核（也称为滤波器），这些卷积核可以识别图像中某些特定的特征，每个卷积核会去滑动卷积上一层的特征图，在卷积的过程中卷积核的参数是不变且共享的。这样在训练过程中，与之前的全连接神经网络训练大尺度输入样本时需要大量参数相比，卷积神经网络只需要相对少很多的参数就可以完成训练。

    3. 子采样

    子采样层（subsamplinglayer）也称作池化层（pooling layer）, 其作用是对上一卷积层进行聚合，使得上一层卷积层的输入特征图尺寸在经过该子采样层的聚合（也就是我们说的池化）后减小，从而降低特征数量，减少参数的数量。子采样层所做的事其实就是对上一层卷积层进行扫描，每次扫描特定区域，然后计算该区域特征的最大值（最大池化（maximum pooling））或者平均值（平均池化（mean pooling）），作为该区域特征的表示。

- DCNN 动态卷积神经网络 
- TDNN 时延神经网络 
- BP 反向传播算法 Backpropagation Algorithm，简称 BP算法，是深度学习的重要思想基础
- BERT - Bidirectional Encoder Representations from Transformers，是预训练语言表示的方法，可以在大型文本语料库（如维基百科）上训练通用的“语言理解”模型，然后将该模型用于下游NLP任务，比如机器翻译、问答。
- SRN 简单循环网络 Simple recurrent networks 又称为 Elman network，是 1990 年由 Jeff Elman 提出来的。



# NLP 库

现在有许多开源的自然语言处理库：

- Natural language toolkit (NLTK)
- Apache OpenNLP
- Stanford NLP suite
- Gate NLP library

自然语言工具包（NLTK）是最受欢迎的自然语言处理（NLP）库。它是用 Python 语言编写的，背后有强大的社区支持。

NLTK 也很容易入门，实际上，它将是你用到的最简单的自然语言处理（NLP）库。


NLP 库的核心功能比较：

|     名称     | SparkNLP | NLTK | SpaCy | CoreNLP |
|--------------|----------|------|-------|---------|
| 句子检测     | ✅        | ✅    | ✅     | ✅       |
| 细粒度单位化 | ✅        | ✅    | ✅     | ✅       |
| 词干提取     | ✅        | ✅    | ✅     | ✅       |
| 语法         | ✅        | ✅    | ✅     | ✅       |
| 磁性标注     | ✅        | ✅    | ✅     | ✅       |
| 命名实体识别 | ✅        | ✅    | ✅     | ✅       |
| 依赖分析     | ✅        | ✅    | ✅     | ✅       |
| 文本匹配     | ✅        | ❌    | ❌     | ✅       |
| 日期匹配     | ✅        | ❌    | ❌     | ✅       |
| 段落分解     | ✅        | ✅    | ✅     | ✅       |
| 拼写检查     | ✅        | ❌    | ❌     | ❌       |
| 情绪检测     | ✅        | ❌    | ❌     | ✅       |
| 预训练模型   | ✅        | ✅    | ✅     | ✅       |
| 训练模型     | ✅        | ✅    | ✅     | ✅       |

现代计算平台和流行编程语言的支持：

|            特性            | SparkNLP | NLTK | spaCy | CoreNLP | OpenNLP |
|----------------------------|-----------|------|-------|---------|---------|
| 完整支持JavaAPI            | ✅        | ❌   | ❌     | ✅     | ✅    |
| 完整支持ScalaAPI           | ✅        | ❌   | ❌     | ❌     | ❌    |
| 完整支持PythonAPI          | ✅        | ✅   | ✅     | ❌     | ❌    |
| 支持GPU训练                | ✅        | ❌   | ✅     | ❌     | ❌    |
| 支持用户定义的深度神经网络   | ✅        | ❌   | ❌     | ❌     | ❌    |
| 原生支持 Spark             | ✅        | ❌   | ❌     | ❌     | ❌    |
| 支持 Hadoop, YARN, HDFS    | ✅        | ❌   | ❌     | ❌    | ❌     |

许可支持的对比：

|   名字   |        语言       |   许可证   | 商业用途 | 商业支持 |
|----------|-------------------|------------|----------|----------|
| SparkNLP | Python Java Scala | Apache 2.0 | ✅       | ✅       |
| spaCy    | Python            | MIT        | ✅       | ✅       |
| NLTK     | Python            | Apache 2.0 | ✅       | ❌       |
| CoreNLP  | Java              | GNU GPL    | 付费许可 | ❌       |
| OpenNLP  | Java              | Apache 2.0 | ✅       | ❌       |

斯坦福大学出售 CoreNLP 的商业许可证，这是商业用途所必需的。为 spaCy 提供商业许可证和支持的 explosion.ai 同样也为快速标注迭代工具 prodigy、机器学习库 thinc 提供许可证。John Snow Labs 提供企业级 SparkNLP 服务，包括基本版，24×7 级别的支持，以及诸如命名实体解析，断言状态检测、ID 脱敏等高级功能。它还为提供医疗领域专用的 SparkNLP，其中包括一套针对生物医学 NLP 的最先进的模型和数据集。

大多数 NLP 库支持用户训练新模型，但 NLP 库具有现有的预训练的高质量模型这一点非常重要。

不过，大多数 NLP 库仅支持通用的预训练模型（POS，NER等）。由于其许可证的要求，某些库根据模型授权状态，不允许将预训练模型作商业用途。

|   名称   | 通用预训练模型 | 领域特定预训练模型 | 许可证是否允许商用 |
|----------|----------------|--------------------|--------------------|
| SparkNLP | ✅             | ✅（医疗领域）     | ✅（通用）         |
| spaCy    | ✅             | ❌                 | ✅（某些GPL许可）  |
| NLTK     | ✅             | ❌                 | ✅                 |
| CoreNLP  | ✅             | ❌                 | ❌                 |
| OpenNLP  | ✅             | ❌                 | ✅                 |

每个库打包的通用预训练模型：

|   名称   | 语法化 | 词性标注 | 命名实体识别 | 依赖关系解析 | 拼写检查 | 情感分析 |
|----------|--------|---------|------------|-------------|---------|----------|
| SparkNLP | ✅    | ✅      | ✅        | ✅         | ✅      | ✅       |
| spaCy    | ✅    | ✅      | ✅        | ✅         | ❌      | ❌       |
| NLTK     | ✅    | ✅      | ✅        | ✅         | ❌      | ❌       |
| CoreNLP  | ✅    | ✅      | ✅        | ✅         | ❌      | ✅       |
| OpenNLP  | ✅    | ✅      | ✅        | ✅         | ❌      | ❌       |



# NLTK
- [结巴 - 中文分词](https://github.com/fxsjy/jieba)

安装：

    pip install nltk

下载相应的语料库和训练模型，以 Brown Corpus 为例：

    >>> import nltk
    >>> nltk.download('browm')

不给 download 函数传入参数时会打开 NLTK Download 图形界面，参考其源代码 downloader.py 中的 DownloaderGUI 类实现。

使用语料库时，NLTK 会在以下目录搜索已经安装的语料库：

    - 'C:\\Users\\OCEAN/nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - 'C:\\Anaconda3\\nltk_data'
    - 'C:\\Anaconda3\\share\\nltk_data'
    - 'C:\\Anaconda3\\lib\\nltk_data'
    - 'C:\\Users\\OCEAN\\AppData\\Roaming\\nltk_data'

打印语料库的单词：

    >>> from nltk.corpus import brown
    >>> brown.words()
    ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]

以下程序示范：


示例程序要点：

- urllib.request.urlopen 获取 HTML 页面内容；
- bs4.BeautifulSoup 对 HTML 进行标签过滤得到文本；
- tokens = [t for t in text.split()] 对文本进行分割；
- nltk.FreqDist(tokens) 函数实现词频统计；
- 

有一些词，如"the," "of," "a," "an," 等等。这些词是停止词。一般来说，停止词语应该被删除，以防止它们影响我们的结果。

NLTK 具有大多数语言的停止词表。要获得英文停止词，你可以使用以下代码：

    from nltk.corpus import stopwords
    stopwords.words('english')

这样得到的结果更加清晰，因为没有了停止词的干扰。

使用 nltk 处理中文资料，怎么样分词是个大问题。NLTK 工具目前只能比较好的处理英文和其他的一些拉丁语系，这些语种单词之间有个空格隔开，分词较容易实现！中文汉字一个挨一个的，nltk 在分词这一关就过不去了，分词没法分，剩下的就都做不了。唯一能做的，就是对网上现有的中文语料进行处理，这些语料都分好了词，可以使用 nltk 进行类似与英文的处理。

NLTK 有一个 Sinica中央研究院提供的繁体中文语料库，安装了这个语料库 sinica_treebank。

    import nltk
    from nltk.corpus import sinica_treebank
     
    print(sinica_treebank.words())
    ['一', '友情', '嘉珍', '和', '我', '住在', '同一條', '巷子', '我們', ...]

来看一下 NLTK 中文语法树：

    >>>sinica_treebank.parsed_sents()[33].draw()

搜索中文：

    import nltk
    from nltk.corpus import sinica_treebank
     
    sinica_text=nltk.Text(sinica_treebank.words())
    print(sinica_text.concordance('我'))