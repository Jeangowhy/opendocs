# Elasticsearch 全文搜索索引原理分析
- 《Elasticsearch 权威指南》
- [《Elasticsearch 源码解析与优化实战》](https://www.jianshu.com/p/e853a8ba4eaf)
- [Elasticsearch－基础介绍及索引原理分析](https://www.cnblogs.com/dreamroute/p/8484457.html)
- [全文搜索引擎 Elasticsearch 入门教程](http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html)
- [时间序列数据库的秘密 (2)——索引](https://www.infoq.cn/article/database-timestamp-02/)
- [如何构建一个高可用、低延迟的 Elasticsearch 集群？](https://gitbook.cn/gitchat/column/5ce4ff9a308dd66813d92799/topic/5ce50135308dd66813d927a6)
- [Elasticsearch 权威指南](https://github.com/elastic/elasticsearch-definitive-guide/)
- [Elasticsearch 2.x 权威指南](https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html)
- [Elasticsearch 与 Solr 优缺点比较](https://www.jianshu.com/p/132b8f1b66a7)
- []()

# Introduction 介绍

Lucene['lusen] 的原作者是 Doug Cutting，一位资深全文索引/检索专家，曾经是 V-Twin 搜索引擎的主要开发者，后在 Excite 担任高级系统架构设计师，当前从事于一些 Internet 底层架构的研究。早先发布在作者自己的博客上，他贡献出 Lucene 的目标是为各种中小型应用程式加入全文检索功能。后来发布在 SourceForge，2001年年底成为 Apache 软件基金会 Jakarta 的一个子项目。

Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene 是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene 提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。

Elasticsearch 是建立在全文搜索引擎 Apache Lucene(TM) 基础之上的搜索引擎，是一个分布式可扩展的实时搜索和分析引擎。当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:

- 分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。
- 实时分析的分布式搜索引擎。
- 可以扩展到上百台服务器，处理 PB 级别的结构化或非结构化数据。

Elastic 的底层是开源库 Lucene。但是，你没法直接用 Lucene，必须自己写代码去调用它的接口。Elastic 是 Lucene 的封装，提供了 REST API 的操作接口，开箱即用。

维基百科使用 Elasticsearch 来进行全文搜做并高亮显示关键词，以及提供 search-as-you-type、did-you-mean 等搜索建议功能。2014 年左右 Elasticsearch 的受欢迎程度大大超过了 Solr。

Elastic 不仅用于大型企业，它还让像 DataDog 以及 Klout 这样的创业公司将最初的想法变成可扩展的解决方案。所涉及到的每一项技术都不是创新或者革命性的，全文搜索，分析系统以及分布式数据库这些早就已经存在了。它的革命性在于将这些独立且有用的技术整合成一个一体化的、实时的应用。它对新用户的门槛很低，当然它也会跟上你技能和需求增长的步伐。

Elastic 可以在你的笔记本上运行，也可以在数以百计的服务器上处理 PB 级别的数据。

很不幸，现在大部分数据库在提取可用知识方面显得异常无能，的确，它们能够通过时间戳或者精确匹配做过滤，它们能够进行全文搜索，处理同义词和根据相关性给文档打分吗？它们能根据同一份数据生成分析和聚合的结果吗？最重要的是，它们在没有大量工作进程（线程）的情况下能做到对数据的实时处理吗？

这就是 Elasticsearch 存在的理由：鼓励你浏览并利用你的数据，而不是让它烂在数据库里，因为在数据库里实在太难查询了。

无论你是需要全文搜索，还是结构化数据的实时统计，或者两者结合，Elasticsearch 不仅仅只是全文搜索，我们还将介绍结构化搜索、数据分析、复杂的人类语言处理、地理位置和对象间关联关系等。为了充分利用 Elasticsearch 的水平伸缩性，应当学习如何建立数据模型，以及在生产环境中如何配置和监控你的集群。

Elasticsearch 的特点：

- 分布式，无需人工搭建集群（Apache Solr 就需要人为配置，使用 Zookeeper 作为注册中心）
- Restful 风格，一切 API 都遵循 REST 原则，容易上手
- 近实时搜索，数据更新在 Elasticsearch 中几乎是完全同步的。


根据官网指导安装，Windows 版自带 JDK 14 解包即用。进入解压后的目录，运行下面的命令，启动 Elastic。

    $ ./bin/elasticsearch

如果这时报错"max virtual memory areas vm.maxmapcount [65530] is too low"，要运行下面的命令。

    $ sudo sysctl -w vm.max_map_count=262144

如果一切正常，Elastic 就会在默认的9200端口运行。这时，打开另一个命令行窗口，请求该端口，会得到说明信息。

    $ curl localhost:9200
    {
      "name" : "atntrTf",
      "cluster_name" : "elasticsearch",
      "cluster_uuid" : "tf9250XhQ6ee4h7YI11anA",
      "version" : {
        "number" : "5.5.1",
        "build_hash" : "19c13d0",
        "build_date" : "2017-07-18T20:44:24.823Z",
        "build_snapshot" : false,
        "lucene_version" : "6.6.0"
      },
      "tagline" : "You Know, for Search"
    }

上面代码中，请求 9200 端口，Elastic 返回一个 JSON 对象，包含当前节点、集群、版本等信息。

按下 Ctrl + C，Elastic 就会停止运行。

默认情况下，Elastic 只允许本机访问，如果需要远程访问，可以修改 Elastic 安装目录的 config/elasticsearch.yml 文件，去掉 network.host 的注释，将它的值改成 0.0.0.0，然后重新启动 Elastic。

    network.host: 0.0.0.0

上面配置表示允许任何主机访问，线上服务不要这样设置，要设成具体的 IP。


## Concepts 基本概念

Elasticsearch 中的几个概念：

- 集群 **Cluster** 一组拥有共同的 cluster name 的节点。主节点可以通过选举产生的，主从节点是对于集群内部来说的。
- 节点 **Node** 集群中的一个 Elasticearch 实例。
- 索引 **Index** 相当于关系数据库中的 **database** 概念，一个集群中可以包含多个索引，这个是个逻辑概念。
- 主索引分片 **Primary shard** 索引的子集，索引可以切分成多个分片，分布到不同的集群节点上，对应 Lucene 中的索引，构成分布式搜索。 引创建前指定，并且索引创建后不能更改。
- 副本分片 **Replica shard** 每个主分片可以有一个或者多个副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高查询效率，ES 会自动对搜索请求进行负载均衡。
- 类型 **Type** 相当于数据库中的 **table** 概念，Mapping 是针对 Type 的，同一个索引里可以包含多个 Type。
- 映射 **Mapping** 相当于数据库中的 schema，用来约束字段的类型，不过 ES 的 Mapping 可以自动根据数据创建。
- 文档 **Document** 相当于数据库中的 **row**。
- 字段 **Field** 相当于数据库中的 **column**。
- 分配 **Allocation** 将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。

一个 Elastic 集群，概念上就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看 ES 集群，在逻辑上是个整体，你与任何一个节点的通信和与整个 ES 集群通信是等价的。

- **recovery**：代表数据恢复或叫数据重新分布，ES 在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。
- **river**：代表 ES 的一个数据源，也是其它存储方式（如：数据库）同步数据到 ES 的一个方法。它是以插件方式存在的一个 ES 服务，通过读取 river 中的数据并把它索引到 ES 中，官方的 river 有 couchDB 的，RabbitMQ 的，Twitter 的，Wikipedia 的。
- **gateway**：代表 ES 索引快照的存储方式， ES  默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。gateway 对索引快照进行存储，当这个 ES 集群关闭再重新启动时就会从 gateway 中读取索引备份数据。 ES 支持多种类型的 gateway，默认是本地文件系统，另外还有分布式文件系统，Hadoop 的 HDFS 和 amazon 的 s3 云存储服务。
- **discovery**.zen：代表 ES 的自动发现节点机制， ES 是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。
- **Transport**：代表 ES 内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。

Elasticsearch 可简单划分为集群层、索引层、分片层和最后的存储引擎层即 Lucene；集群层，一个节点作为 master，采用 bully 算法选出，负责进行 allocation、全局状态管理等；其他节点作为协调节点（gateway、query、route & merge）和数据节点；每个数据节点多个分片，分片间主从，采用 PacificA、translog 进行同步； 一个比较奇怪的点是，ES 居然是 partition by DocId（而非 term）这导致了其搜索必须采用广播形式，因此无法做到很大规模；线程模型嘛，看起来是按照任务，分为不同独立的线程池和队列，底层数据共享。


先说 Elasticsearch 的文件存储，Elasticsearch 是面向文档型数据库，一条数据在这里就是一个文档，用 JSON 作为文档序列化的格式，比如下面这条用户数据：

    {
        "name" :     "John",
        "sex" :      "Male",
        "age" :      25,
        "birthDate": "1990/05/01",
        "about" :    "I love to go rock climbing",
        "interests": [ "sports", "music" ]
    }

用 MySQL 这样的数据库存储就会容易想到建立一张 User 表，有 balabala 的字段等，在 Elasticsearch 里这就是一个文档，当然这个文档会属于一个 User 的类型，各种各样的类型存在于一个索引当中。

一个 Elasticsearch 集群可以包含多个索引(数据库)，也就是说其中包含了很多类型(表)。这些类型中包含了很多的文档(行)，然后每个文档中又包含了很多的字段(列)。Elasticsearch的交互，可以使用Java API，也可以直接使用HTTP的Restful API方式，比如我们打算插入一条记录，可以简单发送一个HTTP的请求：

    PUT /megacorp/employee/1  
    {
        "name" :     "John",
        "sex" :      "Male",
        "age" :      25,
        "about" :    "I love to go rock climbing",
        "interests": [ "sports", "music" ]
    }


如何快速检索？
Elasticsearch 是通过 Lucene 的倒排索引技术实现比关系型数据库更快的过滤。特别是它对多条件的过滤支持非常好，比如年龄在 18 和 30 之间，性别为女性这样的组合查询。倒排索引很多地方都有介绍，但是其比关系型数据库的 b-tree 索引快在哪里？到底为什么快呢？

笼统的来说，b-tree 索引是为写入优化的索引结构。当我们不需要支持快速的更新的时候，可以用预先排序等方式换取更小的存储空间，更快的检索速度等好处，其代价就是更新慢。


## 分布式服务发现

所有分布式系统都要解决一个问题，就是节点之间互相发现以及选主的机制，或者叫服务发现机制。如果使用了 Zookeeper/Etcd 这样的成熟的服务发现工具，这两个问题都一并解决了。但 Elasticsearch 并没有依赖这样的工具，带来的好处是部署服务的成本和复杂度降低了，不用预先依赖一个服务发现的集群，缺点当然是将复杂度带入了 Elasticsearch 内部。




# Promotion 推荐算法
- [推荐算法](https://blog.csdn.net/app_12062011/article/details/85414969)
- [推荐系统系列 - 引导 - 5类系统推荐算法](https://blog.csdn.net/u010670689/article/details/71513133/)
- [推荐热度算法和个性化推荐](https://blog.csdn.net/sinat_26811377/article/details/99266967)
- [深度优先遍历 DFS 和广度优先遍历 BFS](https://developer.51cto.com/art/202004/614590.htm)
- [个性化推荐系统学习总结](https://gitbook.cn/books/5dec69e151287f7e7f8e9a6e/index.html)

1. 什么是推荐算法
推荐算法最早在 1992 年就提出来了，但是火起来实际上是最近这些年的事情，因为互联网的爆发，有了更大的数据量可以供我们使用，推荐算法才有了很大的用武之地。

推荐算法基于数据，但是目的是解决娱乐至上的穿上时代产生的**信息过载** Information Overload 问题。机器过载，轻则宕机，重则烧坏，人类大脑接受了太多信息，也会产生过载效应，无法有效整合、组织及内化成自己需要的信息，最终影响到人们的工作、生活以及人际关系，甚至心理状态等。

大多数人对信息处理并没有太高的素养，不能分清主次，更不用说制定目标，将信息建立联系，精简信息。人类是信息的消费者，但是每个人能消费的信息是有限的。在这个信息膨胀的时代，精简信息的吸收需要努力。记住，信息并不等同于知识，把不重要的事实减到最少，才能给重要的信息留下认知的空间。个性化信息定制，需要关注与自己相关的内容，其它的内容不要强迫自己去深入了解。

而网络软文贩卖焦虑的一大批公众号，则是将这一人类心理进行了一次又一次毫无节操的营销。

而推荐算法的流行正是基于这些事实产生的，当用户不能主动过滤无用信息，那么就由软件系统来提供这个过滤功能。


2. 推荐算法的条件
现在的各种各样的推荐算法，但是不管怎么样，都绕不开几个条件，这是推荐的基本条件

1.根据和你共同喜好的人来给你推荐 
2.根据你喜欢的物品找出和它相似的来给你推荐 
3.根据你给出的关键字来给你推荐，这实际上就退化成搜索算法了 
4.根据上面的几种条件组合起来给你推荐



3. 推荐算法分类
3.1 基于流行度的推荐算法
基于流行度的推荐算法比较简单粗暴，主要是对热点商品或者信息的推荐。它主要是根据PV、UV、日均PV或分享率等数据来按某种热度排序来推荐给用户。

这种算法既有优点也有缺点。优点是简单，适用于刚注册的新用户，能够解决对新用户进行推荐的冷启动问题。缺点也很明显，它无法针对用户提供个性化的推荐。基于这种算法也可做一些优化，比如加入用户分群的流行度排序，例如把热榜上的体育内容优先推荐给体育迷，把政要热文推给热爱谈论政治的用户。

3.2 基于内容的推荐算法
基于内容的推荐是在推荐引擎出现之初应用最为广泛的推荐机制，它的核心思想是根据推荐物品或内容的元数据，发现物品或者内容的相关性，然后基于用户以往的喜好记录，推荐给用户相似的物品。比如你看了哈利波特I，基于内容的推荐算法发现哈利波特II-VI，与你以前观看的在内容上面（共有很多关键词）有很大关联性，就把后者推荐给你。

这种推荐系统多用于一些资讯类的应用上，针对文章（电影音乐）本身抽取一些tag作为该其关键词，继而可以通过这些tag来评价两篇文章的相似度。

这种推荐系统的优点在于： 1、易于实现，不需要用户数据因此不存在稀疏性和冷启动问题。 2、基于物品本身特征推荐，因此不存在过度推荐热门的问题。 然而，缺点在于：1、抽取的特征既要保证准确性又要具有一定的实际意义，否则很难保证推荐结果的相关性。豆瓣网采用人工维护tag的策略，依靠用户去维护内容的tag的准确性。2、推荐的Item可能会重复，典型的就是新闻推荐，如果你看了一则关于MH370的新闻，很可能推荐的新闻和你浏览过的，内容一致。

3.3 基于关联规则的推荐算法
基于关联规则的推荐更常见于电子商务系统中，并且也被证明行之有效。其实际的意义为购买了一些物品的用户更倾向于购买另一些物品。基于关联规则的推荐系统的首要目标是挖掘出关联规则，也就是那些同时被很多用户购买的物品集合，这些集合内的物品可以相互进行推荐。目前关联规则挖掘算法主要从Apriori和FP-Growth两个算法发展演变而来。 基于关联规则的推荐系统一般转化率较高，因为当用户已经购买了频繁集合中的若干项目后，购买该频繁集合中其他项目的可能性更高。

该机制的缺点如下： 1.计算量较大，但是可以离线计算，因此影响不大。 2.由于采用用户数据，不可避免的存在冷启动和稀疏性问题。 3.存在热门项目容易被过度推荐的问题。

3.4 基于协同过滤的推荐算法
协同过滤算法 CF - Collaborative Filtering 是很常用的一种算法，在很多电商网站上都有用到。CF 算法包括基于用户的 User-based CF 和基于物品的 Item-based CF。

基于用户的 CF 原理如下：

- 分析各个用户对 item 的评价（通过浏览记录、购买记录等）；
- 依据用户对 item 的评价计算得出所有用户之间的相似度；
- 选出与当前用户最相似的N个用户；
- 将这 N 个用户评价最高并且当前用户又没有浏览过的 item 推荐给当前用户。


基于物品的CF原理大同小异，只是主体在于物品：

- 分析各个用户对 item 的浏览记录。
- 依据浏览记录分析得出所有 item 之间的相似度；
- 对于当前用户评价高的 item，找出与之相似度最高的 N 个 item；
- 将这 N 个 item 推荐给用户。

协同过滤是一种在推荐系统中广泛采用的推荐方法。这种算法基于一个“物以类聚，人以群分”的假设，喜欢相同物品的用户更有可能具有相同的兴趣。基于协同过滤的推荐系统一般应用于有用户评分的系统之中，通过分数去刻画用户对于物品的喜好。协同过滤被视为利用集体智慧的典范，不需要对项目进行特殊处理，而是通过用户建立物品与物品之间的联系。 目前，协同过滤推荐系统被分化为两种类型：基于用户(User-based)的推荐和基于物品(Item-based)的推荐。

3.4.1 基于用户(User-based)的推荐

基于用户的协同过滤推荐的基本原理是，根据所有用户对物品或者信息偏好（评分），发现与当前用户口味和偏好相似的“邻居”用户群，在一般应用中是采用计算K近邻的算法；基于这 K个邻居的历史偏好信息，为当前用户进行推荐。 这种推荐系统的优点在于推荐物品之间在内容上可能完全不相关，因此可以发现用户的潜在兴趣，并且针对每个用户生成其个性化的推荐结果。缺点在于一般的Web系统中，用户的增长速度都远远大于物品的增长速度，因此其计算量的增长巨大，系统性能容易成为瓶颈。因此在业界中单纯的使用基于用户的协同过滤系统较少。



3.4.2 基于物品(Item-based)的推荐

基于物品的协同过滤和基于用户的协同过滤相似，它使用所有用户对物品或者信息的偏好（评分），发现物品和物品之间的相似度，然后根据用户的历史偏好信息，将类似的物品推荐给用户。基于物品的协同过滤可以看作是关联规则推荐的一种退化，但由于协同过滤更多考虑了用户的实际评分，并且只是计算相似度而非寻找频繁集，因此可以认为基于物品的协同过滤准确率较高并且覆盖率更高。 同基于用户的推荐相比，基于物品的推荐应用更为广泛，扩展性和算法性能更好。由于项目的增长速度一般较为平缓，因此性能变化不大。缺点就是无法提供个性化的推荐结果。



3.4.3 协同过滤算法总结

两种协同过滤：基于用户和基于物品两个策略中应该如何选择呢？其实基于物品的协同过滤推荐机制是Amazon 在基于用户的机制上改良的一种策略，因为在大部分的Web 站点中，物品的个数是远远小于用户的数量的，而且物品的个数和相似度相对比较稳定；同时基于物品的机制比基于用户的实时性更好。但也不是所有的场景都是这样的情况，在一些新闻推荐系统中，也许物品，也就是新闻的个数可能大于用户的个数，而且新闻的更新程度也有很快，所以它的相似度依然不稳定。所以，推荐策略的选择其实也和具体的应用场景有很大的关系。

基于协同过滤的推荐机制是现今应用最为广泛的推荐机制，它有以下几个显著的优点：

它不需要对物品或者用户进行严格的建模，而且不要求物品的描述是机器可以理解的，所以这种方法也是领域无关的。
这种方法计算出来的推荐是开放的，可以共用他人的经验，很好的支持用户发现潜在的兴趣偏好。
然后而它也存在以下几个缺点：

方法的核心是基于历史数据，所以对新物品和新用户都有“冷启动”的问题。
推荐的效果依赖于用户历史偏好数据的多少和准确性。
在大部分的实现中，用户历史偏好是用稀疏矩阵进行存储的，而稀疏矩阵上的计算有些明显的问题，包括可能少部分人的错误偏好会对推荐的准确度有很大的影响等等。
对于一些特殊品味的用户不能给予很好的推荐。
由于以历史数据为基础，抓取和建模用户的偏好后，很难利用获取的用户偏好演变，从而导致这个方法不够灵活。
3.5 基于模型的推荐算法
基于模型的方法有很多，主要是使用常用的机器学习算法对目标用户建立推荐算法模型，然后对用户的爱好进行预测推荐以及对推荐的结果打分排序等。 常用的模型包括Aspect Model，pLSA，LDA，聚类，SVD，Matrix Factorization，LR，GBDT等，这种方法训练过程比较长，但是训练完成后，推荐过程比较快且准确。因此它比较适用于实时性比较高的业务如新闻、广告等。当然，而若是需要这种算法达到更好的效果，则需要人工干预反复的进行属性的组合和筛选，也就是我们常说的 特征工程。而由于新闻的时效性，系统也需要反复更新线上的数学模型，以适应变化。

简单的以LR为例，来讲一下推荐系统的运作原理。我们通过分析系统中用户的行为和购买记录等数据，得到如下表：



表中的行是一种物品，x1~xn是影响用户行为的各种特征属性，如用户年龄段、性别、地域、物品的价格、类别等等，y则是用户对于该物品的喜好程度，可以是购买记录、浏览、收藏等等。通过大量这类的数据，我们可以回归拟合出一个函数，计算出x1~xn对应的系数，这即是各特征属性对应的权重，权重值越大则表明该属性对于用户选择商品越重要。 　　在拟合函数的时候我们会想到，单一的某种属性和另一种属性可能并不存在强关联。比如，年龄与购买护肤品这个行为并不呈强关联，性别与购买护肤品也不强关联，但当我们把年龄与性别综合在一起考虑时，它们便和购买行为产生了强关联。比如（我只是比如），20 ~ 30岁的女性用户更倾向于购买护肤品，这就叫交叉属性。通过反复测试和经验，我们可以调整特征属性的组合，拟合出最准确的回归函数。最后得出的属性权重如下：



基于模型的算法由于快速、准确，适用于实时性比较高的业务如新闻、广告等，而若是需要这种算法达到更好的效果，则需要人工干预反复的进行属性的组合和筛选，也就是常说的Feature Engineering。而由于新闻的时效性，系统也需要反复更新线上的数学模型，以适应变化。

3.6 混合推荐算法
真正的现实应用中，其实基本上很少会使用单一的推荐算法去实现推荐任务。因此，大型成熟网站的推荐系统都是基于各种推荐算法的优缺点以及适合场景分析的情况下的组合使用的“混合算法”。当然，混合策略也会是十分丰富的，例如不同策略的算法加权、不同场景和阶段使用不同的算法等等。具体的怎么混合需要结合实际的应用场景进行分析与应用。

由此可见推荐算法的类型还是相当之多的，尤其当应用场景发生变化时，推荐算法往往也需要作出较大的变动。接下来将会对以上的诸多算法作出适当的详解与实战。

