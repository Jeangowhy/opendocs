

# 🚩 资源参考


- 给区块链爱好者的奥地利经济学 https://www.bilibili.com/video/BV1D54y1r7SG

- Andreas Antonopoulos 提了个好问题：钱是什么？比特币是什么 

    https://www.bilibili.com/video/BV1eo4y1o7zK

    1992 年人们如何评论互联网？ 毒品交易、罪犯、杀手，现在人们也这样评论比特币。钱是什么？从最基本
    的层面来讲，钱并不是价值，而是一种语言，一种控制体系。

    Andreas Antonopoulos 说到：真正令人兴奋的并不是区块链，它不过是这个协议创造出来的人工
    数据库罢了。真正重要的，是彼此不信任的各方从此无需任何权威媒介也能实现分布式共识的能力。银行
    当然不会喜欢它，但这又何妨？它并不请求允许。互联网没有做到的，区块链将替它完成。

    Antonopoulos 出生于英国伦敦，在希腊雅典长大。2012年，Antonopoulos接触到比特币并很快理解了
    其潜力。据他介绍，比特币可能比互联网更具革命性。毫不犹豫，他放弃了原有工作，选择了比特币。他将
    经济学，心理学，技术和博弈论与当前事件、个人轶事和历史相结合，给予了区块链爱好者强有力的演讲。
    他有一种理解复杂技术细微差别的天赋，并以极其简单易懂的术语解释它们。

    他还是一位高产的作家，有着奶牛一般的产量，著有包括《精通比特币》、《精通以太坊》和《精通区块链编程》
    等在内的 15 本区块链相关书籍。

- 比特币和加密货币技术

    普林斯顿大学 Arvind Narayanan，斯坦福大学 Joseph Bonneau，普林斯顿大学 Edward Felten
    和伊利诺伊大学厄巴纳 - 香槟分校的 Andrew Miller。这门课程在 2015 年普林斯顿大学讲授。

    本课程由“比特币和加密货币技术”一书的作者讲授，该书是该领域最受欢迎的教科书之一。该课程包括完整
    的视频讲座，编程作业和教科书的免费出版前版本。它侧重于比特币，略微触及山寨币及其周围的生态系统。
    这是 Coursera 课程的免费版本。
    链接：https://www.coursera.org/learn/cryptocurrency

- 比特币和加密货币

    Dan Boneh 和 Joseph Bonneau。斯坦福大学。2016

    该课程涵盖了加密货币的各个方面。除比特币外，该课程还包括智能合约和以及以太坊分叉为例。它还包括
    匿名，零知识证明以及量子计算机时代的加密货币。
    链接：http://cs251crypto.stanford.edu/18au-cs251/

- 加密货币

    Max Fang，Philip Hayes和Sunny Aggarwal。2017年加州大学伯克利分校。

    除了比特币和以太坊之外，还提供完整的视频讲座和关于扩展问题的讲义，以Lightning Network，Monero
    的匿名作为示例，以及政府法规。
    https://blockchain.berkeley.edu/decal/fa18/fund/

- 加密货币安全

    Andrew Miller。2016年伊利诺伊大学厄巴纳 - 香槟分校。

    本课程涵盖比特币，比特币挖掘，智能合约和以太坊，隐私，托管和加密货币以及比特币P2P网络等主题，
    所有这些都是从安全角度出发的。它还涵盖了门头沟事件作为安全失败的一个例子。
    http://soc1024.ece.illinois.edu/teaching/ece598am/fall2016/

- IBM 区块链开发

    Ant Cole和Dave Gorman。IBM通过Coursera。始于2018/01/15。

    本课程适合对区块链开发感兴趣的软件开发人员。本课程包括视频讲座。
    https://www.coursera.org/learn/ibm-blockchain-essentials-for-developers

- 商业区块链 - Hyperledger 技术简介

    Navroop Sahdev，Nathalie Salami， Alexandra Groetsema，Robert Schwentker 和 
    Arianna Groetsema。2017 年 Linux 基金会开放在 edX 平台。

    本课程通过视频讲座涵盖商业和企业环境中的区块链，适用于技术和非技术受众。它涵盖了 Hyperledger
    项目以及 Hyperledger Sawtooth 和 Hyperledger Fabric 框架，以及如何在这些框架之上构建
    应用程序。
    https://www.edx.org/course/blockchain-for-business-an-introduction-to-hyperledger-technologies

- 比特币

    Zulfikar Ramzan，2013年可汗学院。

    本课程包括9个关于比特币的10分钟视频讲座。每个简短的视频讲座都涵盖了比特币背后的一个关键概念。
    https://www.khanacademy.org/economics-finance-domain/core-finance/money-and-banking/bitcoin/v/bitcoin-what-is-it

- 比特币和区块链技术

    Jeremy Clark,2017年Concordia University。

    课程涵盖密码学，哈希函数，数字签名，比特币和区块链技术以及以太坊。
    http://users.encs.concordia.ca/~clark/courses/1703-6630/index.html

- 网络和计算机安全

    Ronald L. Rivest，2017年麻省理工学院。

    本课程介绍网络和计算机安全的技术背景及其在加密货币中的应用。
    http://courses.csail.mit.edu/6.857/2017/


# 🚩 Blockchain Tutorial 区块链教程
- [Blockchain Demo](https://github.com/anders94/blockchain-demo/)
- [Blockchain Demo Home Site](https://andersbrownworth.com/blockchain)
- [Blockchain Demo @anders94 区块与链的数据结构及算法](https://www.bilibili.com/video/BV1JW411p7tV)
- [Blockchain Demo @anders94 RSA 非对称加密系统 公钥、私钥以及签名](https://www.bilibili.com/video/BV1dW41137tn)
- [3Blue1Brown 电子加密货币原理](https://www.bilibili.com/video/av12465079/)
- [Blockchain Tutorial with Golang](https://github.com/nosequeldeebee/blockchain-tutorial)

Code your own blockchain in less than 200 lines of Go!

Read our blog post first to see a walkthrough of the code.
https://medium.com/@mycoralhealth/code-your-own-blockchain-in-less-than-200-lines-of-go-e296282bcffc

Check out our follow-up tutorials:

- [Networking](https://github.com/mycoralhealth/blockchain-tutorial/tree/master/networking)
- [Proof of Work](https://github.com/mycoralhealth/blockchain-tutorial/tree/master/proof-work)
- [Proof of Stake](https://github.com/mycoralhealth/blockchain-tutorial/tree/master/proof-stake)
- [IPFS](https://medium.com/@mycoralhealth/learn-to-securely-share-files-on-the-blockchain-with-ipfs-219ee47df54c)
- [P2P](https://medium.com/coinmonks/code-a-simple-p2p-blockchain-in-go-46662601f417)
- [Advanced Concepts for Beginners](https://medium.com/@mycoralhealth/advanced-blockchain-concepts-for-beginners-32887202afad)
- [Start your own Hyperledger blockchain the Easy Way!](https://medium.com/@mycoralhealth/start-your-own-hyperledger-blockchain-the-easy-way-5758cb4ed2d1)
- [Build a DApp on Hyperledger the Easy Way!](https://medium.com/@mycoralhealth/build-a-dapp-on-hyperledger-the-easy-way-178c39e503fa)
- [Build your own Blockchain Twitter recorder](https://github.com/mycoralhealth/twitter-blockchain)

Deployment steps:

- `git clone https://github.com/mycoralhealth/blockchain-tutorial.git`
- navigate to this directory and rename the example file `mv example.env .env`
- `go run main.go`
- open a web browser and visit `http://localhost:8080/`
- to write new blocks, send a `POST` request to `http://localhost:8080/` with a 
  JSON payload with `BPM` as the key and an integer as the value. For example `{"BPM":50}`:
- Send as many requests as you like and refresh your browser to see your blocks grow! Use your actual heart rate (Beats Per Minute) to track it over time.


例子可以学到什么：

- 对 blockchain 有基本的了解
- 创建自己的 blockchain
- 理解哈希算法是怎样保证 blockchain 的完整性
- 理解新块是如何被添加的
- 如何解决多个节点竞争问题
- 通过浏览器来查看你的 blockchain
- 写新的 blocks

学会基本的区块链技术后，可以扩展一致性算法，即共识算法 Raft 等应用：

- 拜占庭容错技术 BFT - Byzantine Fault Tolerance
- 实用拜占庭容错算法 PBFT - Practical Byzantine Fault Tolerance
- 工作证明 PoW - Proof of Work
- 权益证明 PoS - Proof of Stake
- 行动证明 PoA - Proof of Activity 算法是一个区块链的共识算法，基本原理是结合 PoW, PoS 算法的特点进行工作
- 委任权益证明 DPoS -Delegated Proof of Stake
- Ripple 共识算法。
- 智能合约 Smart Contracts
- Dapps
- Side Chains and more.

Block 用于保存要写入的区块链中的数据，每一个字段的意思如下：

- **Index** 表示区块号，Block Height 区块高度；
- **Timestamp** 自动产生的表示该块的生成时间；
- **BPM** 可以理解为写入区块的数据，对应比特币中的 Transaction 转账交易数据；
- **Hash** 本区块的哈希值；
- **PrevHash** 前一个区块的哈希值；

I like to use [Postman](https://www.getpostman.com/apps)

使用 POSTMAN 或 CURL 发送 JSON 数据测试添加新区块：

    >curl -d "{""BPM"":123}" -X POST http://127.0.0.1:8080/
    {
      "Index": 1,
      "Timestamp": "2020-08-11 14:14:21.8927356 +0800 CST m=+9624.498117301",
      "BPM": 123,
      "Hash": "41cdbd5ea3b711640b926018768aac59bd5b132a61d8c9ca7cbcef455cc05ad2",
      "PrevHash": "f1534392279bddbf9d43dde8701cb5be14b82f76ec6607bf8d6ad557f60f304e"
    }

    >curl http://127.0.0.1:8080
    [
      {
        "Index": 0,
        "Timestamp": "2020-08-11 11:33:57.399615 +0800 CST m=+0.004996701",
        "BPM": 0,
        "Hash": "f1534392279bddbf9d43dde8701cb5be14b82f76ec6607bf8d6ad557f60f304e",
        "PrevHash": ""
      },
      {
        "Index": 1,
        "Timestamp": "2020-08-11 14:14:21.8927356 +0800 CST m=+9624.498117301",
        "BPM": 123,
        "Hash": "41cdbd5ea3b711640b926018768aac59bd5b132a61d8c9ca7cbcef455cc05ad2",
        "PrevHash": "f1534392279bddbf9d43dde8701cb5be14b82f76ec6607bf8d6ad557f60f304e"
      }
    ]


# 🚩 Blockchain 基本概念
- [共识算法之争 PBFT，Raft，PoW，PoS，DPoS，Ripple](https://www.cnblogs.com/X-knight/p/9157814.html)
- https://lamport.azurewebsites.net/pubs/paxos-simple.pdf
- [区块链技术指南](https://yeasy.gitbooks.io/blockchain_guide/content/)
- [IBM Blockchain Platform](https://www.ibm.com/cn-zh/cloud/blockchain-platform)
- [Hyperledger Fabric](https://hyperledger-fabric.readthedocs.io/en/latest/whatis.html)
- [Hyperledger Fabric 架构详解](https://www.taohui.pub/2018/05/26/区块链开源实现hyperledger-fabric架构详解/)
- [区块链的那些事，你知道和不知道的都在这里！](https://developer.aliyun.com/article/65264)
- [Nervos 基金会 MUTA - a high-performance blockchain framework](https://github.com/nervosnetwork/muta)
- [Nervos CKB Muta 框架](https://www.hellobtc.com/kp/bi/12/2575_2.html)
- [Muta Guides](https://docs.muta.dev/guides/)
- [PoA - Proof of Activity 算法](https://www.jianshu.com/p/747397652b75)


Hyperledger Fabric 分布式帐本是区块链中联盟链的优秀实现，主要代码由 IBM、Intel、各大银行等贡献，目前 v1.1 版的 kafka 共识方式可达到 1000/s 次的吞吐量。

哈希摘要算法和 RSA 非对称算法是区块链的基础技术。

为什么要对数据进行哈希化，有两个主要原因：

- 节省空间，哈希值由区块中所有数据计算而来，假如我们的区块中数据很多，用哈希值做标识明显更有效率；
- 保护区块完整性，记录中保存前一个区块的哈希值，可以检查到前一个区块有没有被篡改；

一个优秀的 Hash 算法，将能满足：

- 正向快速：给定原文和 Hash 算法，在有限时间和有限资源内能计算得到 Hash 值；
- 逆向困难：给定（若干）Hash 值，在有限时间内无法（基本不可能）逆推出原文；
- 输入敏感：原始输入信息发生任何改变，新产生的 Hash 值都应该发生很大变化；
- 碰撞避免：很难找到两段内容不同的明文，使得它们的 Hash 值一致（即发生碰撞）。

碰撞避免有时候又被称为“抗碰撞性”，可分为“弱抗碰撞性”和“强抗碰撞性”。给定原文前提下，无法找到与之碰撞的其它原文，则算法具有“弱抗碰撞性”；更一般地，如果无法找到任意两个可碰撞的原文，则称算法具有“强抗碰撞性”。

很多场景下，也往往要求算法对于任意长的输入内容，输出为定长的 Hash 结果


从技术角度，一般认为，区块链具有如下特点：

- 分布式容错性：分布式账本网络极其鲁棒，能够容忍部分节点的异常状态；
- 不可篡改性：共识提交后的数据会一直存在，不可被销毁或修改；
- 隐私保护性：密码学保证了数据隐私，即便数据泄露，也无法解析。

随之带来的业务特性将可能包括：

- 可信任性：区块链技术可以提供天然可信的分布式账本平台，不需要额外第三方中介机构参与；
- 降低成本：跟传统技术相比，区块链技术可能通过自动化合约执行带来更快的交易，同时降低维护成本；
- 增强安全：区块链技术将有利于安全、可靠的审计管理和账目清算，减少犯罪风险。


区块链的基本原理理解起来并不复杂。首先来看三个基本概念：

- 交易 **Transaction**：一次对账本的操作，导致账本状态的一次改变，如添加一条转账记录；
- 区块 **Block**：记录一段时间内发生的所有交易和状态结果等，是对当前账本状态的一次共识；
- 链 **Chain**：由区块按照发生顺序串联而成，是整个账本状态变化的日志记录。

如果把区块链系统作为一个状态机，则每次交易意味着一次状态改变；生成的区块，就是参与者对其中交易导致状态改变结果的共识。

区块链的目标是实现一个分布的数据记录账本，这个账本**只允许添加、不允许删除**。账本底层的基本结构是一个线性的链表。链表由一个个区块串联组成，后继区块中记录前导区块的哈希 Hash 值。某个区块以及块里的交易是否合法，可通过计算哈希值的方式进行快速检验。网络中节点可以提议添加一个新的区块，但必须经过共识机制来对区块达成确认。


根据参与者的不同，可以分为：

- 公有链 Public 或 Permissionless
- 联盟链 Consortium 或 Permissioned
- 私有链 Private

公有链，顾名思义，任何人都可以参与使用和维护，参与者多为匿名。典型的如比特币和以太坊区块链，信息是完全公开的。

如果进一步引入许可机制，可以实现私有链和联盟链两种类型。

私有链，由集中管理者进行管理限制，只有内部少数人可以使用，信息不公开。一般认为跟传统中心化记账系统的差异不明显。

联盟链则介于两者之间，由若干组织一起合作（如供应链机构或银行联盟等）维护一条区块链，该区块链的使用必须是带有权限的限制访问，相关信息会得到保护，典型如超级账本项目。在架构上，现有大部分区块链在实现都至少包括了网络层、共识层、智能合约和应用层等分层结构，联盟链实现往还会引入额外的权限管理机制。


以比特币网络为例，来看其中如何使用了区块链技术。

首先，用户通过比特币客户端发起一项交易，消息广播到比特币网络中等待确认。网络中的节点会将收到的等待确认的交易请求打包在一起，添加上前一个区块头部的哈希值等信息，组成一个区块结构。然后，试图找到一个 nonce 串（随机串）放到区块里，使得区块结构的哈希结果满足一定条件（比如小于某个值）。这个计算 nonce 串的过程，即俗称的“挖矿”。nonce 串的查找需要花费一定的计算力。

一旦节点找到了满足条件的 nonce 串，这个区块在格式上就“合法”了，成为候选区块。节点将其在网络中广播出去。其它节点收到候选区块后进行验证，发现确实合法，就承认这个区块是一个新的合法区块，并添加到自己维护的本地区块链结构上。当大部分节点都接受了该区块后，意味着区块被网络接受，区块中所包括的交易也就得到确认。

这里比较关键的步骤有两个，一个是完成对一批交易的共识（创建合法区块结构）；一个是新的区块添加到链结构上，被网络认可，确保未来无法被篡改。当然，在实现上还会有很多额外的细节。

比特币的这种基于算力（寻找 nonce 串）的共识机制被称为工作量证明（Proof of Work，PoW）。这是因为要让哈希结果满足一定条件，并无已知的快速启发式算法，只能对 nonce 值进行逐个尝试的蛮力计算。尝试的次数越多（工作量越大），算出来的概率越大。

通过调节对哈希结果的限制条件，比特币网络控制平均约 10 分钟产生一个合法区块。算出区块的节点将得到区块中所有交易的管理费和协议固定发放的奖励费（目前是 12.5 比特币，每四年减半）。


工作量证明，通过计算来猜测一个数值（nonce），使得拼凑上交易数据后内容的 Hash 值满足规定的上限（来源于 hashcash）。由于 Hash 难题在目前计算模型下需要大量的计算，这就保证在一段时间内，系统中只能出现少数合法提案。反过来，能够提出合法提案，也证明提案者确实已经付出了一定的工作量。

同时，这些少量的合法提案会在网络中进行广播，收到的用户进行验证后，会基于用户认为的最长链基础上继续难题的计算。因此，系统中可能出现链的分叉（Fork），但最终会有一条链成为最长的链。

Hash 问题具有不可逆的特点，因此，目前除了暴力计算外，还没有有效的算法进行解决。反之，如果获得符合要求的 nonce，则说明在概率上是付出了对应的算力。谁的算力多，谁最先解决问题的概率就越大。当掌握超过全网一半算力时，从概率上就能控制网络中链的走向。这也是所谓 51% 攻击的由来。

参与 PoW 计算比赛的人，将付出不小的经济成本（硬件、电力、维护等）。当没有最终成为首个算出合法 nonce 值的“幸运儿”时，这些成本都将被沉没掉。这也保障了，如果有人尝试恶意破坏，需要付出大量的经济成本。也有设计试图将后算出结果者的算力按照一定比例折合进下一轮比赛考虑。


## 👉 区块链分布系统核心技术
- https://yeasy.gitbooks.io/blockchain_guide/content/04_distributed_system/


一致性问题是分布式领域最基础、最重要的问题，也是半个世纪以来的研究热点。

随着业务场景越来越复杂，计算规模越来越庞大，单点系统往往难以满足高可扩展（Scalability）和高容错（Fault-tolerance）两方面的需求。此时就需要多台服务器通过组成集群，构建更加强大和稳定的“虚拟超级服务器”。

任务量越大，处理集群的规模越大，设计和管理的挑战也就越高。谷歌公司的全球搜索集群系统，包括数十万台服务器，每天响应百亿次的互联网搜索请求。

集群系统要实现一致性不是一件容易的事。不同节点可能处于不同的状态，不同时刻收到不同的请求，而且随时可能有节点出现故障。要保持对外响应的“一致性”，好比训练一群鸭子齐步走，难度可想而知。

定义： 一致性（Consistency），早期也叫（Agreement），在分布式系统领域中是指对于多个服务节点，给定一系列操作，在约定协议的保障下，使得它们对处理结果达成“某种程度”的协同。

理想情况（不考虑节点故障）下，如果各个服务节点严格遵循相同的处理协议（即构成相同的状态机逻辑），则在给定相同的初始状态和输入序列时，可以确保处理过程中的每个步骤的执行结果都相同。因此，传统分布式系统中讨论一致性，往往是指在外部任意发起请求（如向多个节点发送不同请求）的情况下，确保系统内大部分节点实际处理请求序列的一致，即对请求进行全局排序。

那么，为什么说一致性问题十分重要呢？

举个现实生活中的例子，多个售票处同时出售某线路上的火车票，该线路上存在多个经停站，怎么才能保证在任意区间都不会出现超售（同一个座位卖给两个人）的情况？

这个问题看起来似乎没那么难，现实生活中经常通过分段分站售票的机制。然而，要支持海量的用户进行并行购票，并非易事（参考 12306 的案例）。特别是计算机系统往往需要达到远超物理世界的高性能和高可扩展性需求，挑战会变得更大。这也是为何每年到了促销季，各大电商平台都要提前完善系统。


规范来看，分布式系统达成一致的过程，应该满足：

- 可终止性（Termination）：一致的结果在有限时间内能完成；
- 约同性（Agreement）：不同节点最终完成决策的结果是相同的；
- 合法性（Validity）：决策的结果必须是某个节点提出的提案。

可终止性很容易理解。有限时间内完成，意味着可以保障提供服务（Liveness）。这是计算机系统可以被正常使用的前提。需要注意，在现实生活中这点并不是总能得到保障的。例如取款机有时候会出现“服务中断”；拨打电话有时候是“无法连接”的。

约同性看似容易，实际上暗含了一些潜在信息。决策的结果相同，意味着算法要么不给出结果，任何给出的结果必定是达成了共识的，即安全性（Safety）。挑战在于算法必须要考虑的是可能会处理任意的情形。凡事一旦推广到任意情形，往往就不像看起来那么简单。例如现在就剩一张某区间（如北京 --> 南京）的车票了，两个售票处也分别刚通过某种方式确认过这张票的存在。这时，两家售票处几乎同时分别来了一个乘客要买这张票，从各自“观察”看来，自己一方的乘客都是先到的……这种情况下，怎么能达成对结果的共识呢？看起来很容易，卖给物理时间上率先提交请求的乘客即可。然而，对于两个来自不同位置的请求来说，要判断在时间上的“先后”关系并不是那么容易。两个车站的时钟时刻可能是不一致的；时钟计时可能不精确的……根据相对论的观点，不同空间位置的时间是不一致的。因此追求绝对时间戳的方案是不可行的，能做的是要对事件的发生进行排序。

事件发生的相对先后顺序（逻辑时钟）十分重要，确定了顺序，就没有了分歧。这也是解决分布式系统领域很多问题的核心秘诀：把不同时空发生的多个事件进行全局唯一排序，而且这个顺序还得是大家都认可的。

如果存在可靠的物理时钟，实现排序往往更为简单。高精度的石英钟的漂移率为 ，最准确的原子震荡时钟的漂移率为 。Google 曾在其分布式数据库 Spanner 中采用基于原子时钟和 GPS 的“TrueTime”方案，能够将不同数据中心的时间偏差控制在 10ms 置信区间。在不考虑成本的前提下，这种方案简单、有效。然而，计算机系统的时钟误差要大得多，这就造成分布式系统达成一致顺序十分具有挑战。

注：Leslie Lamport 在 1978 年发表的论文《Time, Clocks and the Ordering of Events in a Distributed System》中将分布式系统中顺序与相对论进行对比，提出了偏序关系的观点。而根据相对论，并不存在绝对的时间。因此，先后顺序可能更有意义。

最后的合法性看似绕口，但其实比较容易理解，即达成的结果必须是节点执行操作的结果。仍以卖票为例，如果两个售票处分别决策某张票出售给张三和李四，那么最终达成一致的结果要么是张三，要么是李四，而不能是其他人。


共识算法
共识（Consensus），很多时候会见到与一致性（Consistency）术语放在一起讨论。严谨地讲，两者的含义并不完全相同。

一致性的含义比共识宽泛，在不同场景（基于事务的数据库、分布式系统等）下意义不同。具体到分布式系统场景下，一致性指的是多个副本对外呈现的状态。如前面提到的顺序一致性、线性一致性，描述了多节点对数据状态的共同维护能力。而共识，则特指在分布式系统中多个节点之间对某个事情（例如多个事务请求，先执行谁？）达成一致看法的过程。因此，达成某种共识并不意味着就保障了一致性。

实践中，要保障系统满足不同程度的一致性，往往需要通过共识算法来达成。

共识算法解决的是分布式系统对某个提案（Proposal），大部分节点达成一致意见的过程。提案的含义在分布式系统中十分宽泛，如多个事件发生的顺序、某个键对应的值、谁是主节点……等等。可以认为任何可以达成一致的信息都是一个提案。

对于分布式系统来讲，各个节点通常都是相同的确定性状态机模型（又称为状态机复制问题，State-Machine Replication），从相同初始状态开始接收相同顺序的指令，则可以保证相同的结果状态。因此，系统中多个节点最关键地是对多个事件的顺序进行共识，即排序。



FLP 不可能原理：在网络可靠，但允许节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性共识算法（No completely asynchronous consensus protocol can tolerate even a single unannounced process death）。

提出并证明该定理的论文《Impossibility of Distributed Consensus with One Faulty Process》是由 Fischer，Lynch 和 Patterson 三位科学家于 1985 年发表，该论文后来获得了 Dijkstra（就是发明最短路径算法的那位计算机科学家）奖。

FLP 不可能原理告诉我们，不要浪费时间，去试图为异步分布式系统设计面向任意场景的共识算法。

科学告诉你什么是不可能的；工程则告诉你，付出一些代价，可以把它变成可行。

这就是科学和工程不同的魅力。FLP 不可能原理告诉大家不必浪费时间去追求完美的共识方案，而要根据实际情况设计可行的工程方案。



CAP 原理：分布式系统无法同时确保一致性 Consistency、可用性 Availability 和分区容忍性 Partition，设计中往往需要弱化对某个特性的需求。

一致性、可用性和分区容忍性的具体含义如下：

- 一致性 **Consistency**：任何事务应该都是原子的，所有副本上的状态都是事务成功提交后的结果，并保持强一致；
- 可用性 **Availability**：系统（非失败节点）能在有限时间内完成对操作请求的应答；
- 分区容忍性 **Partition**：系统中的网络可能发生分区故障，即节点之间的通信无法保障，但网络故障不应该影响到系统正常服务。

CAP 原理认为，分布式系统最多只能保证三项特性中的两项特性。


ACID 原则

ACID，即 Atomicity（原子性）、Consistency（一致性）、Isolation（隔离性）、Durability（持久性）四种特性的缩写。

ACID 也是一种比较出名的描述一致性的原则，通常出现在分布式数据库等基于事务过程的系统中。

具体来说，ACID 原则描述了分布式数据库需要满足的一致性需求，同时允许付出可用性的代价。

Atomicity：每次事务是原子的，事务包含的所有操作要么全部成功，要么全部不执行。一旦有操作失败，则需要回退状态到执行事务之前；
Consistency：数据库的状态在事务执行前后的状态是一致的和完整的，无中间状态。即只能处于成功事务提交后的状态；
Isolation：各种事务可以并发执行，但彼此之间互相不影响。按照标准 SQL 规范，从弱到强可以分为未授权读取、授权读取、可重复读取和串行化四种隔离等级；
Durability：状态的改变是持久的，不会失效。一旦某个事务提交，则它造成的状态变更就是永久性的。
与 ACID 相对的一个原则是 eBay 技术专家 Dan Pritchett 提出的 BASE（Basic Availability，Soft-state，Eventual Consistency）原则。BASE 原则面向大型高可用分布式系统，主张牺牲掉对强一致性的追求，而实现最终一致性，来换取一定的可用性。

注：ACID 和 BASE 在英文中分别是“酸”和“碱”，看似对立，实则是对 CAP 三特性的不同取舍。


## 👉 Turing Mechine
- [什么是图灵完备？](https://www.zhihu.com/question/20115374)

在可计算性理论里，如果一系列操作数据的规则，如指令集、编程语言、细胞自动机可以用来模拟单带图灵机，那么它是 Turing completeness 图灵完备的。这个词源于引入图灵机概念的数学家艾伦·图灵。虽然图灵机会受到储存能力的物理限制，图灵完全性通常指“具有无限存储能力的通用物理机器或编程语言”。

图灵机 Turing Machine 是图灵在 1936 年发表的 "On Computable Numbers, with an Application to the Entscheidungsproblem" 《论可计算数及其在判定性问题上的应用》 中提出的数学模型。

在文章中图灵描述了它是什么，并且证明了，只要图灵机可以被实现，就可以用来解决任何可计算问题。

图灵机的结构包括以下几个部分：

- 一条无限长的纸带 tape ，纸带被分成一个个相邻的格子 square，每个格子都可以写上至多一个字符 symbol。
- 一个字符表 alphabet，即字符的集合，它包含纸带上可能出现的所有字符。其中包含一个特殊的空白字符 blank，意思是此格子没有任何字符。
- 一个读写头 head，可理解为指向其中一个格子的指针。它可以读取/擦除/写入当前格子的内容，此外也可以每次向左/右移动一个格子。
- 一个状态寄存器 state register，它追踪着每一步运算过程中，整个机器所处的状态 运行/终止 。当这个状态从运行变为终止，则运算结束，机器停机并交回控制权。如果你了解有限状态机，它便对应着有限状态机里的状态。
- 一个有限的指令集 instructions table，它记录着读写头在特定情况下应该执行的行为。可以想象读写头随身有一本操作指南，里面记录着很多条类似于“当你身处编号 53 的格子并看到其内容为 0 时，擦除，改写为 1，并向右移一格。此外，令下一状态为运行。”这样的命令。其实某种意义上，这个指令集就对应着程序员所写下的程序了。

图灵机结构

在计算开始前，纸带可以是完全空白，也可以在某些格子里预先就有写上部分字符作为输入。运算开始时，读写头从某一位置开始，严格按照此刻的配置 configuration ，即：

- 当前所处位置
- 当前格子内容

来一步步的对照着指令集去进行操作，直到状态变为停止，运算结束。而后纸带上留下的信息，即字符的序列 比如类似“...011001...” 便作为输出，由人来解码为自然语言。
要重申一下，以上只是图灵机模型的内容，而非具体的实现。所谓的纸带和读写头都只是图灵提出的抽象概念。为便于理解打一个比方。算盘虽然不是图灵机 因为它没有无限长的纸带，即无限的存储空间 ，但它的行为与图灵机一致。每一串算珠都是纸带上的一格，一串算珠上展示的数字便记录着当前格中的字符（可以是空白，可以是 12345  。人类的手即是读写头，可以更改每串算珠的状态。算盘的运行遵循人脑中的算法，当算法结束，算盘停机。

## 👉 double spending
- [Bitcoin Fork - 什么是双花攻击？](https://zhuanlan.zhihu.com/p/37985803)

双花攻击指同一笔款两次花费，在一名矿工短暂控制了超过 50% 的算力，向交易所发起转账，同时把同一笔 BTG 转账给自己。因为手头有足够的算力，所以两笔交易都被写进区块，成为合法交易。

理论上的攻击思路

- 伪造交易签名
- 拒绝服务攻击
- 双花攻击
- 零确认双花攻击（bitcoin要求6次确认，所以在bitcoin网络里不存在）

伪造交易签名，就是 A 没有转账给 B，但用伪造的 A 签名在这笔不存在的交易上签名，只要 A 没有公开自己私钥的话。这种攻击只在理论上存在，因为在非对称加密里不知道私钥情况下，产生相同签名，短期内，不会出现。

拒绝服务，比如 A 十分厌恶 C，同时运行 bitcoin 节点，决定所有 C 的交易都过滤掉，不写入区块。几乎不可能发生，因为只要网络里有诚实节点存在，并且并不长期占少数，则该交易不可能发生。

双花 double spending，即 A 转账给 D，同时也用把相同的币转账给自己，通俗讲，就是把钱花两次，或者多次。依据最长链原则，节点会认可并延长当前最长链，如果当攻击者拥有超过 50% 算力，并且成功把交易写进区块，则双花发生并且合法。

中本聪 Bitcoin 的应对方案

- 通过区块比特币奖励，鼓励更多人挖矿。诚实节点越多或者说独立节点越多，网络约安全。
- 6次确认，以避免零确认攻击。（理论上，确认次数越多，双花攻击几率越小）

比特币网络的进化机制

- 币值越高，挖矿人越少，系统越稳健、交易越安全，同时进而促进币值增加。
- 反之，任何一环出问题，都会摧毁这种网络里的进化机制。

有算力在手的人可以这么作恶：

- 比特币挖矿，平均每个区块的挖矿时间是十分钟，设计者中本聪在设计之初，考虑到了算力的变动，所以算力是动态调节的。同样，所有分叉币也有同样的调节机制。
- 每两周调节难度，适应当前算力，以保证区块生成速度在 10min 左右。

除了双花攻击，所以，如果有足够多的算力，持有者还可以：

- 低难度入场，低成本迅速挖矿，挖矿难度下一回合自动提升。
- 高难度退场，难度已提升，但网络算力已经显著下降，下一回合，难度自动下降。

而且，事实上，也确实有人这么做。

XXXX 利用 BCH 的算力动态调整来进行挖矿，通过 BCH 挖矿难度上升后暴力撤出算力，降低难度，然后又进驻算力的方法来获得暴利，利用这个预留的系统偷偷挖了十几万个 BCH，后来 BCH 进行修改后去掉了该系统。


# 🚩 Bitcoin 与区块链
- Bitcoin Core https://bitcoin.org/en/bitcoin-core/
- Bitcoin Core - Github https://github.com/bitcoin/bitcoin
- Bitcoin Getting Started https://bitcoin.org/en/getting-started
- Bitcoin Wallet app https://github.com/bitcoin-wallet/bitcoin-wallet
- Bitcoin 白皮书 https://bitcoin.org/zh_CN/bitcoin-paper
- 比特币入门指南 https://bitcoin.org/zh_CN/getting-started
- BitCoin CLI https://www.npmjs.com/package/bitcoin-cli
- BitCoin Wiki https://en.bitcoin.it/wiki/Main_Page
- [RSA算法原理（一）阮一峰](http://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html)
- [RSA算法原理（二）阮一峰](http://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html)
- ECDSA算法如何保护数据 https://zhuanlan.zhihu.com/p/97953640
- Bitcoin and Cryptocurrency Technologies http://bitcoinbook.cs.princeton.edu
- Blockchain Tutorial: Learn Blockchain Technology https://www.guru99.com/blockchain-tutorial.html
- Mastering Ethereum by Andreas M. Antonopoulos, Gavin Wood https://github.com/ethereumbook/ethereumbook
- [译]区块链技术全解析入门版 https://zhuanlan.zhihu.com/p/43851267
- 精通比特币（第二版） https://www.8btc.com/book/281955
- Bitcoin 词汇表 https://www.8btc.com/books/834/masterbitcoin2cn/_book/glossary.html
- Mastering Bitcoin https://github.com/bitcoinbook/bitcoinbook
- Bitcoin Glossary https://support.blockchain.com/hc/en-us/articles/213276463-Bitcoin-Glossary
- Crypto 加密模块 https://nodejs.org/docs/latest-v12.x/api/crypto.html
- [What is a Digital Signature? An introduction to Digital Signatures, by David Youd](http://www.youdzone.com/signature.html)
- 信息安全技术 SM2 椭圆曲线公钥密码算法 http://www.gb688.cn/bzgk/gb/std_list?p.p1=0&p.p90=circulation_date&p.p91=desc&p.p2=32918
- SM系列国密算法 https://www.cnblogs.com/lyh523329053/p/10238260.html
- 央行数字货币双离线支付原理、难点与技术方案 https://www.chainnews.com/articles/659853554625.htm

数字加密货币是当下热门技术，央行也公布了数字货币 DCEP - Digital Currency Electronic Payment，
它是具有价值特征的数字支付工具，即不需要账户就可以实现支付。

其中最值得关注的是双离线支付实现，可以采取本地进行信用消费，联网后再进行验证，需要解决双花问题 
double spend。为控制风险，钱包可能限制离线条件下的交易次数或 UTXO 流转次数。

付款方在离线状态下构造交易报文并签名，将已签名的交易报文通过近场通信交给收款方，并在后续联网时提交
给央行数字货币登记系统入账。该过程可以类比为付款方现场开具支票，收款方事后凭支票去银行兑现。双离线支付
的最关键问题是解决已签名交易报文的防伪识别，包括验证数字货币本身的真伪，以及验证签发该交易的付款方
是否为该数字货币的属主。

据专利描述的设计思路是，需在数字货币客户端中标识为待重复支付验证，一旦联到网络，则自动向数字货币系统
进行重复支付验证申请。数字货币系统收到验证申请执行相应操作，在登记中心补录交易流水，更新数字货币的属主。
换句话说，双离线支付之后“待重复支付验证”的那笔交易资金在联网验证之前是不能再流通到市场的。

与纸钞没有属主标识不同，央行数字货币具有属主标识，并由央行数字货币登记系统的中心化账本维护数字货币的
属主标识。由于央行数字货币的所有权，最终是由央行数字货币登记系统予以确权，央行数字货币的主流交易形态，
应当是联网交易，而双离线交易，是联网交易的补充。

根据工信部 2016 年指导发布的《区块链技术和应用发展白皮书》的解释：狭义的讲，区块链是一种按照时间顺序
将数据区块以顺序相连的方式组合成的一种链式数据结构，并以密码学方式保证不可篡改和不可伪造的分布式账本；
广义来讲，区块链技术是利用链式数据结构来验证和存储数据、利用分布式节点共识算法来生成和更新数据、利用
密码学的方式保证数据传输和访问的安全性、利用由自动化脚本代码组成的智能合约来编程和操作数据的一种全新的
分布式基础架构与计算模式。

区块链发展历史：

- 区块链 1.0：电子货币；
- 区块链 2.0：智能合约；
- 区块链 3.0 Dapps - Decentralized Applications 分布式应用；

Bitcoin 作为典型的代表，它一种分布式完全点对点 Peer-to-Peer 支付的电子货币系统，允许在线支付，
从一方直接发送到另一方，而不需要通过一个金融机构。数字签名提供了部分解决方案，不需基于信任的第三方来
防止双重支付，这是电子货币的主要优点。

Bitcoin 是在 2008 年由署名 Satoshi Nakamoto 的牛人发明的，他发布一篇文章提出了这种基于去
中心化信任网络的电子货币，“Bitcoin：A Peer-to-Peer Electronic Cash System”。

当初中本聪是先开发了比特币软件，之后才完成了大名鼎鼎的 Satoshi Whitepaper，中本聪考虑是发布
白皮书之前先确保系统能够正常工作。为了与其他修改版本软件区别，原始这个软件现在称为 Bitcoin Core
比特币核心，是比特币系统的参考实现，这意味着它是所有技术实现的权威参考。Bitcoin Core 实现了比特币
的所有方面，包括钱包，交易和区块验证引擎，以及 P2P 网络中的全节点。

UTXO - Unspent Transaction Outputs 是未花费的交易输出，它是比特币交易生成及验证的一个核心概念。
交易构成了一组链式结构，所有合法的比特币交易都可以追溯到前向一个或多个交易的输出，这些链条的源头都是
挖矿奖励，即造币过程，末端则是当前未花费的交易输出。

通读 Andreas M. Antonopoulos 的《精通比特币》后，你应该可以理解，比特币不单单是一种数字货币，
更核心的还是一种给货币及其他很多东西提供基础的信任网络，对的，比特币的本质不是货币，而是去中心化信任网络。


![Bitcoin Core 架构图](https://github.com/bitcoinbook/bitcoinbook/raw/develop/images/mbc2_0301.png)

    ┌──────────────────────────────────────────────────────────────────────────────────────┐
    │  ┌────────────────┐                                                                  │ ┌─────────────┐
    │  │ Peer           ◄──────────────────────────────────────────────────────────────────┼─► P2P Network │
    │  │ Discovery      ◄───────┐                                                          │ └─────────────┘
    │  └───▲────────────┘       │         ┌─────────────────────────────┐                  │
    │      │                    │         │                             │                  │
    │   ┌──▼────┐       ┌───────▼─────────▼──┐      ┌─────────┐     ┌───▼──┐               │ ┌─────┐
    │   │ Peers │     ┌─► Connection Manager ◄──────► Wallet  ◄─────► RPC  ◄───────────────┼─► APP │
    │   └───────┘     │ └─────────────────▲──┘      └────▲────┘     └───▲──┘               │ └─────┘
    │                 │                   │              │              │                  │
    │            ┌────▼───┐          ┌────▼───┐          │              │                  │
    │            │  TXs   ◄──────────► Blocks │          │              │                  │
    │            └───▲────┘          └───▲────┘          │              │                  │
    │                │                   │               │            ┌─▼─────────┐        │
    │            ┌───▼────┐     ┌────────▼──────────┐    └────────────► Storage   │        │
    │            │ Mempool◄─────► Validation Engine ◄─────────────────► Engine    │        │
    │            └───▲────┘     └────────▲──────────┘                 └─▲─────────┘        │
    │ Bitcoin        │                   │                ┌─────────────┼────────────┐     │
    │ Core       ┌───▼────┐              │           ┌────▼────┐   ┌────▼────┐   ┌───▼───┐ │
    │            │ Miner  ◄──────────────┘           │ Headers │   │ Blocks  │   │ Coins │ │
    │            └────────┘                          └─────────┘   └─────────┘   └───────┘ │
    └──────────────────────────────────────────────────────────────────────────────────────┘

Bitcoin 系统组成：

- 一个基于 bitcoin protocol 的分布式点对点网络；
- 区块链，即公共交易分户账簿，Public Transaction Ledger；
- 一套基于共识规则 Consensus Rules 的独立交易验证和货币发行规则；
- 在有效区块链上，基于工作证明算法 POW - Proof-of-Work Algorithm 达成全局分散共识的机制；

区块链技术离不开构成信息安全技术体系的三类基本算法：

- 哈希信息摘要算法，Message Digest Algorithm，单向算法，防数据纂改、防数据损坏；
- 对称加密算法，Symmetric-key Algorithm，代表是高级加密标准 AES - Advanced Encryption Standard；
- 非对称加密算法，Asymmetric Cryptographic Algorithm (RSA)，名字来源于三位作者，是现代密码学的基石。

`素数幂运算`和`椭圆曲线乘法`这些数学函数都是不可逆的， 就是说很容易向一个方向计算，但不可以向相
反方向倒推。基于这些数学函数的密码学，使得生成数字密钥和不可伪造的数字签名成为可能，比特币正是使用
椭圆曲线乘法作为其密码学的基础。

素数也就是质数，任意一个正整数都可以写成一系列质数的积，所以，选取任意两个大的素数计求积很容易，
但要分解这个积极其困难，这是 RSA 算法的基本数学原理。

椭圆曲线密码学 ECC - Elliptic curve cryptography 是一种建立公开密钥加密的算法，基于椭圆曲线
数学，使用比 RSA 加密算法更小的密钥就可以提供相当的或更高等级的安全，因此同样安全等级 ECC 比 RSA 
的性能更高。美国国家标准与技术局和 ANSI X9 设定的最小密钥长度的要求中，RSA、DSA 1024bit，ECC 160bit。

ECC 建立在基于椭圆曲线的离散对数问题上的密码体制，给定椭圆曲线上的一个点 P，一个整数 k，求解 Q=kP 
很容易；给定一个点 P、Q，知道 Q=kP，求整数 k 是一个难题。

椭圆曲线乘法是一种密码学家称之为`陷阱门`的函数：在一个方向（乘法）很容易计算，而在相反的方向（除法）
是不可能计算出来的。私钥的所有者可以容易地创建公钥，然后与世界共享，但没有人可以从公钥反向计算出私钥。 
这个数学技巧成为证明比特币资金所有权不可伪造和安全的数字签名的基础。

其中 ECC 应用于数字签名，即`椭圆曲线数字签名算法` ECDSA - Elliptic Curve Digital Signature Algorithm
是一种无法伪造的数字签名算法。数字签名是一种数学方案 mathematical scheme，由两部分组成的：

- 第一部分是使用私钥（签名密钥）从消息（交易）创建签名；
- 第二部分是允许任何人依据给定的消息和公钥验证签名。

在区块链领域 ECC 有着特殊的地位，比特币使用 ECC 来生成地址和私钥的，其中公钥经过两次 Hash 摘要
运算得到比特币地址。


理清 `Hash`、`Block`、`Chain` 三者的关系是学习区块链的第一步。

哈希 Hashing 是将任意长的原文通过单向不可逆转算法生成加密数据，单向加密意味着无法解密哈希值来
获取原始数据，因此又称为指纹 Finger Print、信息摘要算法 Message Digest Algorithm，就像
通过指纹来识别一个人，但无法通过指纹来求解一个人的 DNA 一样。

事实上，哈希作为一类单向加密函数，有很多实现方式，而旧式的 MD5 因为算法缺陷，已经被王小云教授破解，
证明可以通过高效的碰撞算法来制造出相同指纹的明文。目前最常用的哈希算法有 SHA-256，是 
Secure Hash Algorithm 2 的一种。密码散列函数算法标准，由美国国家安全局研发，属于 SHA 算法之一，
是 SHA-1 的后继者。SHA-2 可再分为六个不同的算法标准，SHA-256 是其中一般长度的摘要算法，结果是
256 bits，即 32Bytes，用 Hex 表达就是 64 个十六字符。

哈希函数最大的特点就是可以验证明文是否被纂改，这一特性用在`区块` Block 上保证区块的信息不被纂改，
同时区块上的 Hash 相互关联，上一个区块和下一个区块相互之间有 Hash 关系，任何一方的变动都会导致
验证失败，这样的一种链式关联就是`区块链` Block。 

在区块链中，每个区块中都有前一个区块的哈希值，前一个区块叫做当前区块的`父区块`。由于每个区块都有
前一个区块的哈希值，当修改当前区块的任意数据会导致区块的哈希值发生变化。区块链的第一个区块叫做 Genesis
`创世区块`。

当前区块中有父区块的地址，如果需要修改当前区块的数据，就需要对父区块链进行修改。如果只有两个区块就
比较好修改数据，但事实上区块链上有很多的区块。

区块头哈希 Block Header Hash 有时也被称为`区块哈希`，它可以唯一的标识一个区块，该信息可以随时
被计算，并存储在子区块的 Previous Block Hash 中，这种 Hash 引用关系是区块成链的必要条件。

`区块高度` Block Height 即区块在区块链中的位置，第几个区块。每个区块对应一个唯一的高度，但同一
高度下可能临时存在多个区块，这种分叉的情况和挖矿有关。早期区块高度不会存储在区块中，仅由每个节点
自己动态维护，在比特币改进方案 BIP-34 中提出利用软分叉在 coinbase 的解锁脚本中添加块高度信息，
并将块 Version 变为 2，从 227835 块之后全部块的 Version 已经为 2，即包含块高度信息。

区块链的第一个区块被称为`创世区块`，高度为 0，比特币的创世区块在 2009 年创建，现在比特币的所有
区块都可以反向追溯到创世区块。

创世区块被静态植入比特币核心客户端中，不能被修改，所有比特币节点都将从创世区块开始构建区块链。

创世区块的 Hash 000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f

中本聪在创世区块中引用一段文字，是英国泰晤士报当天的头条新闻标题，一方面证明区块的创建真实时间，
一方面暗讽中心化金融系统。

    “The Times 03/Jan/2009 Chancellor on brink of second bailout for banks”


得益于非对称加密算法体系，在网络中可以公布密钥对中的`公钥` Public Key，而`私钥` Private Key 
由所有者秘密保存。当其它人使用公钥加密信息，私钥持有者就可以用私钥进行解密。反过来，使用私钥加密一段
数据即为`签名` Signature，因为其它人可以通过公钥验证，密钥对的这两种用途在网络中非常强大！

在比特币交易的情境中，假设三方参与转账，Charles -> Alice -> Bob 转账 5 BTC。

以中间位置进行分析，Alice 为何能给 Bob 转这 5 BTC 呢？因为 Alice 能够用自己的私钥解锁这 5 BTC。
而且 Charles 在向 Alice 转账时，使用 Alice 的公钥锁定了这 5 BTC。同样，Alice 接收到 Charles 
的转账后，使用 Bob 的公钥锁定这 5 BTC，然后，只有 Bob 才能解锁并接收转账。

所以，比特币系统里很智慧的一点：就是把一个人的公钥当作这个人的收款账号（或收款地址）。这样当你在给
别人转账时，你输入了别人的收款账号，比特币系统会自动帮你把这笔款用那对方的公钥锁定。这样这笔钱就
属于他了，将来他必须用他的私钥解锁，才能使用这笔钱。这样也就达到了`只有我的授权才能支付`目的。

所有比特币区块数据结构中，都有 inputs 和 out 两个部分，对应了支付方和接收方，交易数据可以在 
Blockchain Data API 上找到。

支付方信息在 inputs 保存，也即发起方，以 Alice 为例，主要包括：

- ScriptSig 签名脚本 是由支付方 Alice 生成的数字签名数据，该数据几乎总是被用作满足公钥脚本的变量。
- txn - 交易序号，代表 Alice 从哪笔交易得到 5 BTC，在那笔交易里，Alice 是接收方，交易的 outputs 
  里面有 Alice 的公钥地址。

接受方的信息在 out 保存，即 Bob 的相关信息，主要包括：

- Amount 本次交易金额。
- ScriptPubKey 公钥脚本 是包含在交易输出中的脚本。该脚本设置了比特币花费需满足的条件，满足条件的
  数据可以由签名脚本提供。用 Bob 公钥生成的一段锁定脚本，里面包含着 Bob 公钥的特征，将这笔金额锁定后，
  只有含有 Bob 私钥才能够解锁。

通过这个链式数据结构，顺藤摸瓜找到上一个交易，Alice 接收 5 BTC 的区块中的 ScriptPubKey，相当于
是公钥，然后进行对私钥和公钥匹配验证，验证通过后，Alice 才有权使用这 5 BTC，这样 Alice 账户才有
资产给 Bob 转账。

最常见的交易形式：

- Coinbase Transaction 创币交易，是区块中的第一笔交易，是一笔笔特殊交易，有一个输出，支付到所属矿工的比特币地址。
- Common Transation 从一个地址到另一个地址的简单支付，还包含给支付者的“找零”，这类交易有一个输入和两个输出；
- Aggregating Transation 归集多个输入到一个输出，这相当于生活中零钱兑大额面钞。这样的交易由钱包应用产生，来整理在支付过程收到的许多小额的找零。
- Distributing Transation 将一个输入分配给多个输出，即多个接收者的交易。这类交易有时被商业机构用作分配资金，例如给多个雇员发工资的情形。


比特币白皮书解析了网络运行的步骤如下：

- 向所有节点广播所有新的交易；
- 每个节点将新交易打包到一个区块；
- 每个节点开始为此区块找一个具备难度的工作证明；
- 当某个节点找到其工作证明，它就要将此区块广播给所有节点；
- 其他节点验证区块中所有的交易都是有效的，且未被双重支付，这时才会接受这个区块；
- 节点向网络表示自己接受这个区块的方法是，在创建下一个区块的时候，把被接受区块的哈希当作新区块之前的哈希。

节点始终认为最长链是正确的那个，且会不断向其添加新数据。若是有两个节点同时向网络广播了两个不同版本的
“下一个区块”，有些节点会先接收到其中一个，而另外一些节点会先接收到另外一个。这种情况下，节点将在它们
先接收到的那个区块上继续工作，但也会把另外一个分支保存下来，以防后者成为最长链。当下一个工作证明被找到，
而其中的一个分支成为更长的链之后，这个暂时的分歧会被打消，在另外一个分支上工作的节点们会切换到更长的链上。


## 👉 Merkle Tree 默克尔树
- Merkle Tree理解起来并不难 https://www.sohu.com/a/230312547_100123121

比特币网络中所有产生的交易均打包进区块中，一般情况下，一个区块中包含几百上千笔交易是很常见的，即涉及
大量数据处理。

而有效的方式是使用 Merkle Tree 默克尔树，通常也被称作 Hash Tree，就是存储 hash 值的一棵二叉树，
树的叶子是数据块，例如文件 hash 值，非叶节点是其对应子节点串联字符串的 hash。

在 Blockchain Data API 中查询到的交易账单数据中，所有交易数据都在 tx 中保存，里面的 `inputs`
`out` 两部分就是 Hash Tree 的数据，每个区块都有一个 Merkle Root。

对于比特币网络来说，使用 Merkle 树来存储交易信息的目的是为了高效的查找和校验某笔交易的信息是否存在，
Merkle Tree 可以用来进行快速查找和检验大规模数据完整性。

当 N 个数据元素经过加密，使用两次 SHA-256 算法即 Double-SHA-256，至多计算 2log2(N) 次就能
检查出任意某元素是否在树中，所以重新组织区块链中的块 Hash 处理能大大减少运算量。

由于默克尔树本质上是由哈希值构成的树状数据结构，因此也继承了哈希值用于保证数据安全隐私和校验数据
准确和完整性的功能，主要应用于点对点下载，例如 BT 下载、开源分布式控制系统 Git、比特币和以太坊
区块链等场景中。因为我们难以保证这些去中心化系统中的每个节点都会提供真实可信的数据，也难以避免数据
在传输过程中出现丢失、损坏等情况，所以需要引入数据加密和校验机制。

默克尔树其实就是将数据分割成多个小块，进行多次哈希运算，搭建出的一个树状数据结构。那为什么要对数据
进行拆分，计算出多个哈希值用于校验呢？这不是增加工作量了吗？但其实这样做是为了提高数据验证的灵活性，
数据量越大，默克尔树的这一优势会体现得越明显。

假设我们有 A B C D 四笔交易字段。

- 首先需要 Hashing 这四个数据 H(a)、H(b)、H(c)、H(d)；
- 然后这些 Hash 数据串联相邻叶子节点的哈希值后再哈希化，H(H(a)+H(b))、H(H(c)+H(d))；
- 再逐级 Hashing 节点的串联 hash 字符串，直到顶层生成一个 Hash Root；

叶子节点必须是偶数（平衡树），如果遇到奇数的情况，把最后一个节点自身复制一个，凑偶；

下表显示了 Merkle 树的效率，是证明区块中存在某笔交易所需转化为 Merkle 路径的数据量：

    | 交易数量  | 区块的近似大小  | 路径大小  | 哈希（路径大小） |
    |----------|----------------|----------|------------------|
    |       16 | 4KB            | 4 个哈希  | 128 bytes        |
    |      512 | 128KB          | 9 个哈希  | 288 bytes        |
    |     2048 | 512KB          | 11 个哈希 | 352 bytes        |
    |    65535 | 16MB           | 16 个哈希 | 512 bytes        |

可以发现，即使区块容量达到 16MB 规模，为证明交易存在的 Merkle 路径长度增长也极其缓慢，2log2(N)，
幂指数增长取对数变为线性增长。

Merkle 应用于简单支付验证节点 SPV - Simple Payment Verification，每当一笔新的交易产生的时候，
必须验证这笔交易是否真的存在。在 SPV 节点中，不保存区块链，仅仅保存区块头，使用认证路径或者 Merkle 
路径来验证交易是否存在于区块中。

例如，一个 SPV 节点需要处理一笔支付，它需要验证这笔交易在某个区块中是否存在，才能决定是不是把这笔
交易添加到这个区块中，那么它只需要接收少于 1KB 大小的，有关区块头和 Merkle 路径的信息，比接收
完整区块（大约 1MB）大小少了 1 千倍。简单来说，可以想象，Merkle 树类似一个数组，这也是哈希表的
最简单表示，下标是区块字段，下标对应数组存储的内容是这笔交易是否存在的值 True or False。


## 👉 PoW - Proof of Work 工作量证明

Bitcoin 交易需要解决重复支付或者伪造交易的问题：

- 收款方通过查询区块链是否有对应的转账记录来检查转款是否到账；
- 在区块链记录一笔转账交易前，先查询这笔钱是否已经在区块链记录中转给其它账户，如果已经转过，
  则认定当前转账非法而拒绝记录该转账。

不像传统的银行交易系统中的账本，区块链的账本由多人或团体共同维护，即去中心化。共同维护，意味着网络
成员节点都可以往区块链账本中记账，这带来新的问题：怎么保证每个记账人都会诚实的记账，即防止伪造交易。

假设 A 消费时没有向网络广播这一事件，并想通过伪造区块来掩盖这一事件，这是可能发生的，与被消费的
一方会就会存在一个区块生成的竞争。

解决伪造交易的就是俗称的`挖矿` Mine，即通过工作量证明 PoW - Proof Of Work 也就是模拟掷骰子解迷，
就是不停尝试找到一随机值 Nonce，使得这个随机值和区块头其它信息合在一起后计算出来的哈希值小于指定的值。
这个值和难度直接相关，值越小，寻找的难度越大，这个过程证明矿工生成区块平均花费了规定的时间。

难度值是一个随着区块链网络总的计算能力动态调整的值，每产生 2016 个新的区块进行一次统计，如果平均
每个区块产生的时间少于 10 分钟，难度就会增加一点，目标 Hash 值减小，会看到 Hash 开头的 0 越多。

调整前缀零的数量，很容易控制挖矿的难度，难度越大耗费电力就越多成本就越高。在十六进制值中有 16 个
可能的字符，所以每增加一个 0 字符的难度相当于 16 倍增量。在 Blockchain Demo 的测试中，6 的
难度需要最大超过 500000000 个随机数。

在当前的通用的计算机性能中，不同难度需要的随机数生成时间参考如下：

    | digits |           nonce           |   time estimate   |
    |--------|---------------------------|-------------------|
    |      4 | 500,000                   | 15 minutes        |
    |      5 | 8,000,000                 | 4 hours           |
    |      6 | 128,000,000               | 3 days            |
    |      7 | 2,048,000,000             | a month           |
    |      8 | 32,768,000,000            | 2 years           |
    |      9 | 524,288,000,000           | 30 years          |
    |     10 | 8,388,608,000,000         | 481 years         |
    |     11 | 134,217,728,000,000       | 7,690 years       |
    |     12 | 2,147,483,648,000,000     | 123,036 years     |
    |     13 | 34,359,738,368,000,000    | 1,968,581 years   |
    |     14 | 549,755,813,888,000,000   | 31,497,291 years  |
    |     15 | 8,796,093,022,208,000,000 | 503,956,662 years |


区块链的算法让每个记账的人都要花费一定的代价才能记账，同时给记账人奖励。这里的代价是计算时间，奖励
包括两部分：一是从每笔交易抽取的佣金，二是由系统新产生的比特币奖励，这就是把记账称为挖矿的原因。

区块链记账以区块为单位，把最新的交易记录写入一个区块，未入账的区块有很多，但以最长的链为准。记账人
拥有的计算设备，专门用于挖矿的矿机，每次创建一个区块记账前都要先完成一道难题，谁先完成就获得记账的
权利和获得`块奖励` Block Reward，大家也就以他生成的区块作为最新的交易记录追加到之前的账本。

假设有人伪造一笔交易，就需要自己伪造多个区块，由于之前已经存在正确的区块，伪造区块很有可能不被承认，
从而损失挖矿收入。即使存在着某些愿意做损人不利己买卖的记账人，能凭借自身先进、快速的计算设备产生区块
来修改账本，它也无法和整个区块链网络对抗。因为正确的区块链在不断增长，而区块链网络总是以最长的区块链
为正确的账本。只要有 51% 的记账人，假设每个记账人有同样的计算设备，觉得挖矿比抢银行靠谱，区块链网络
就能正常运作下去。

截止 2021/02/27，`区块奖励` Block Reward 为 6.25000000 BTC。比特币以一个确定的但不断衰减的
速率被挖出来，大约每十分钟产生一个新区块，每一个新区块都伴随着一定数量从无到有的全新比特币；每开采
210000 个区块其奖励减半，其周期为四年。从比特币发明最初的 50 个比特币/区块到 2012/2016/2020 
年依次减半 Havling 到 6.25 个比特币/区块，并会在 2040 年达到总数接近 2100 万个比特币，在那之后
新的区块不再包含比特币奖励，矿工的收益全部来自交易费。

查看比特币区块信息时，可以看到交易数据中有类似以下的信息：

    (174.312 sat/B - 79.516 sat/WU - 536 bytes)

对应的是按字节或权重摊派的费率：

- Fee per byte: 91.583 sat/B
- Fee per weight unit: 36.147 sat/WU

比特币的最小单位是 SAT 即 Satoshi Nakamoto 名字的前缀，比特币的最小单位为以科学计数形式表达
为 1.0 * 10^-8，也就是说 1 比特币为 1 亿 SATs。以 2021 年的币价趋势，似乎 SAT 想要和 $ 划等号！

另外，区块信息中还有两个概念，`Confirmation` 和 `Difficulty`，具体可以参考 Bitcoin Glossary，

Confirmation `状态确认` 即被后续区块确认的数量，这是一个变化值。意味着比特币交易已经通过网络验证，
这一过程称为挖掘。交易一经确认，就不能冲销或双花 Double Spend 即重复支出，交易事务包含在块中。
确认表示交易被网络验证并不会被回滚，一个确认就已经相当安全。但是对于大额转账，例如 1000 美金或以上，
用户可以等待一个交易得到更多的确认，6 次确认是一个比较通用的数量，每一次确认都降低了交易回滚的风险。

Difficulty `挖矿难度` 与比特币挖掘 Mining 以及验证比特币网络中的块有多困难直接相关。比特币每 
2016 个区块调整一次验证区块的挖掘难度。难度会自动调整，使块验证时间保持在 10 分钟。差不多每两周会
调整一下难度值，因为计算的算力是变化的，为了维持 10 分钟出一个区块的节奏，难度要跟随算力变化而调整。
新难度值=当前难度值×最近周期/20160分钟。



## 👉 PoS - Proof of Stake 权益证明

随着参与比特币挖矿的人越来越多，PoW 证明的方式出现许多问题，例如随着算力竞争迅速加剧，获取代币需要
消耗的能源大量增加，记账权也逐渐向聚集了大量算力的矿池集中。

PoS 的概念在最早的数字币项目中曾被提及，但由于稳健性等原因没被使用。PoS 提出了币龄的概念，币龄是
持有的代币与持有时间乘积的累加。利用币龄竞争取代算力竞争，使区块链的证明不再仅仅依靠工作量，有效地
解决了 PoW 的资源浪费问题。

权益证明是以与系统相关的权益通证 Token 作为分红和选取记账者的考量因素，持有通证的数量越多时间越长，
即通证天数，即持有量 * 持有时间越大，越容易被选为用户代表来进行记账。因为通证对持有者来说就是他在
区块链系统的权益，所以这种方法被称为基于权益的证明，类似于股票的分红制度。

为了获得出块权和奖励，PoW 拼的是节点的计算机的算力，而 PoS 不需要节点有那么高的算力，因为 PoS 
拼的是权益。在 PoS 共识机制中，节点通过质押一定数量的代币参与共识。当节点质押的代币数量越多，那么
就意味着这个节点的权益越大，这个节点就越能够被选中成为出块的节点。而某一节点如果违反规则，它就会受
到严厉惩罚。

`权益证明` PoS 是工作量证明的替代解决方案，主要作为原始协议一些被认知缺陷的防护措施。它由 
QuantumMechanic 在 2011 年的比特币论坛讲座上首次提出，从那时起研发了几种可实际使用的模型。
权益证明的工作原理类似于工作量证明，它也是一种机制，可以决定在一个给定区块中，谁有交易的签署权，
有别于 PoW 要依靠哈希算力，它用所有权作为决定因素。简单来说，如果 Alice 持有 5% 的币数，那么她
将拥有开采所有区块数量中的 5% 区块的权利。

理论上，权益证明通过加大达到 51％ 攻击的难度来提高网络安全性。为了做到这一点，某人或某矿池必须控制
超过一半的现有币数，这比控制 51% 哈希算力要难得多，虽然这也不是不可能的事儿——比如，一个大型集中池
可以通过将自有币数与借贷相结合的方式，形成并控制一半以上的流通币数。

但从实际来说，在权益证明的情况下，大型集中池将没有多大的经济意义去达到这种类型的攻击。它只是大幅度
减弱网络安全的可信度，并有可能导致价格暴跌；恶意矿池搞垮巨资投入的币的价值的行为，基本上就是搬起石
头砸自己的脚。在某种程度上这也是发生在工作量证明方案上的真实情况，但权益证明的抑制措施更强。

PoS 的优点是：

- 第一，耗能少，相对于PoW来说，不需要大量能源的消耗；
- 第二，作恶成本高，想要攻击网络，必须要有51%的通证天数，不但需要大量的通证，还要持有足够长的时间；
- 第三，达成共识的时间短，网络环境好的话，可实现毫秒级速度。

PoS 的缺点有两个：

- 第一，通证趋于集中化，因为收益的分配取决于通证的持有量和持有时间，为了获得更多的通证，通证就会逐渐集中起来；
- 第二，流动性变差，持有通证便会有收益分配，持有者没有套现的动力，导致通证的流动性变差。

工作量证明和权益证明机制虽然都可以解决区块链数据的一致性问题，但正如上面提到的工作量证明机制存在算力
集中于矿池的问题，而权益证明机制根据保证金的数量来调节生产区块难度的方式则会导致马太效应的出现，
强者愈强弱者愈弱，也就是拥有大量代币的账户权利会越来越大，有可能支配记账权。

为了解决前两者的问题，后来又有人提出了基于权益证明机制的改进算法，DPoS - Delegated Proof of Stake
`委托权益证明`，在这种共识机制里，系统中的每个持币用户都可以投票给某些代表，最终得票率在前 101 
名的代表可以获得系统的记账权。这些代表按照既定时间来锻造区块，并且获取锻造区块的收益。授权权益证明机制
既可以提高共识的效率，相比较比特币每 10 分钟生产一个区块，这种机制可以实现 10 秒以内生产一个区块，
又避免了能源的浪费和马太效应，因此成为了很多新兴公链的选择，比如 EOS。



## 👉 Smart Contract 智能合约
- [以太坊 Ethereum 基础](https://zhuanlan.zhihu.com/p/37438888)
- [搭建自己的私有区块链-以太坊-Ethereum基础2](https://zhuanlan.zhihu.com/p/37760114)
- [以太坊 Ethereum 创世揭秘](https://zhuanlan.zhihu.com/p/29028693)
- [什么是智能合约 Smart Contract](https://zhuanlan.zhihu.com/p/32784359)
- [理解智能合约 Smart Contract](https://zhuanlan.zhihu.com/p/33261321)


例如在现实生活中，我们要去买房，这时候要签订购房合同，里面会规定我们的权利以及义务，完了要盖章。
但是这个会有一定问题，例如印章的伪造，合同的遗失，被修改，不智能化等等。在区块链中，就相当于把
这个文本的合同做成了一段计算机可以理解的程序。且这个程序需要具备和合同一样的 不可抵赖，不可修改，
内容可靠以及有一定的保护，这个就是智能合约了。智能合约的内容本身是共识的，就是相关方都认为是合法的，
承认其行为是本人做出的，并且合约执行的结果存在区块链中是不可篡改性。还有就是智能合约是自动化的，
在达到一定条件会自动执行做出相应的行为。所以一句话概括，智能合约就是一个程序化的，能自动执行的合同。

提到智能合约就不能不提以太坊 Ethereum，一个美籍俄罗斯小伙子创造的基于比特区块链技术的区块链平台，
在这个平台上诞生了两个神奇的东西，一个就以太坊的通用货币，以太币，另一个是作为货币标记的货币 Token。

以太坊 Ethereum 是一个基于区块链技术，允许任何人构建和使用去中心化应用的区块链平台。像比特币一样，
以太坊是开源的，并由来自全世界的支持者们共同维护。与比特币仅提供了有限功能的脚本不同，以太坊提供了
一个“图灵完备”的虚拟机，称为`以太坊虚拟机` EVM - Ethereum Virtual Machine，用户可以在 EVM 
上创建智能合约 Smart Contract。以太坊平台中的通用货币为以太币 Ether，简称 ETH，以太币可用于
账号间的转账交易或者为 EVM 上运行的合约消耗的资源付费。

**智能合约** Smart Contract 是以太坊生态系统搭建的关键角色，当有人想要在以太坊完成某项任务时，
他们会与一个或多个人发起一个智能合约。 这个合约其实是一系列的指令，使用编程语言 solidity 编写，
这些语言在 IFTTT，也就是 IF-THIS-THEN-THAT 逻辑的基础上工作。 基本上，如果第一组指令已经完成，
那么执行下一个功能，然后继续下一个功能，直到达到合同结束。

了解这个最好的方法就是想像一台自动售货机。 你所采取的每一步都像是下一步执行本身的触发器。 这有点像
多米诺骨牌效应。 那么，让我们来看看在与自动售货机进行交互时所要采取的步骤：

- Step 1: 你往自动售卖机里投币
- Step 2: 你按下希望购买货物所对应的按钮
- Step 3: 货物滚落，你收集货物

现在看看所有这些步骤，并考虑一下，如果前一个步骤没有执行，任何步骤都可以工作吗？ 这些步骤中的每一步
都与前一步直接相关。 还有一个要考虑的因素，它是智能合约的一个组成部分。在与自动售货机的整个交互过程中，
你（请求者）仅仅是与机器（提供者）一起工作。 绝对没有第三方参与。

那么，现在这个交易看起来如果发生在以太坊网络上呢？ 假设你刚刚在 Ethereum 网络的自动售货机上买了
一些东西，那么这些步骤将如何？

- Step 1: 向自动售货机投钱，这被 Ethereum 网络中的所有节点记录下来，交易在分类账中得到更新。
- Step 2: 按下与您想要的项目对应的按钮，并在 Ethereum 网络和分类帐中更新记录。
- Step 3: 项目出来，你收集它，这就是被记录的所有节点和总账

可以看出你通过智能合约进行的每笔交易都将通过网络进行记录和更新。 这样做的目的是让参与合同的每个人
都对自己的行为负责。 它通过使整个网络的透明化，公正度使得每一个交易行为都可以避免人类的贪婪和恶意。


智能合约是 1990s 年代由尼克萨博提出的理念，几乎与互联网同龄。由于缺少可信的执行环境，智能合约并
没有被应用到实际产业中，自比特币诞生后，人们认识到比特币的底层技术区块链天生可以为智能合约提供可信的
执行环境，以太坊首先看到了区块链和智能合约的契合，发布了白皮书《以太坊：下一代智能合约和去中心话应用平台》，
并一直致力于将以太坊打造成最佳智能合约平台，所以比特币引领区块链，以太坊复活智能合约。

也就是说，智能合约概念并不是随着区块链技术诞生的。区块链技术天然给智能合约带来得天独厚的应用前提。
如果说区块链落地应用，比特币和以太坊就是最大的应用了。

智能合约：

- 是一段但不仅是一个可以自动执行的计算机程序：它自己就是一个系统参与者。它对接收到的信息进行回应，
  它可以接收和储存价值，也可以向外发送信息和价值。
- 这个程序就像一个可以被信任的人，可以临时保管资产，总是按照事先的规则执行操作。
- 智能合约是传统合约的数字化版本，它们是在区块链数据库上运行的计算机程序，可以在满足其源代码中写入的
  条件时自行执行。智能合约一旦编写好就可以被用户信赖，合约条款不能被改变，因此合约是不可更改的。

下面这个示意图就是一个智能合约模型：一段代码（智能合约），被部署在分享的、复制的账本上，它可以维持
自己的状态，控制自己的资产和对接收到的外界信息或者资产进行回应。

![Smart Contract](https://pic4.zhimg.com/80/v2-02a67fb27c2397eae956b5477fa8ab59_1440w.jpg)

智能合约模型：它是运行在可复制、共享的账本上的计算机程序，可以处理信息，接收、储存和发送价值。

现实世界是怎么样应用智能合约的呢？开发人员会为智能合约撰写代码。智能合约可用于交易和（或）两方／多方
之间的任何交换行为。该代码包含一些会触发合约自动执行的条件。一旦编码完成，智能合约就会被上传到区块链
网络上，即它们被发送到所有连接到网络的设备上。一旦将数据上传到所有设备上，用户就可以与执行程序代码的
结果达成协议。然后更新数据库以记录合约的执行情况，并监督合约的条款以检查合规性。

Solidity 是一种语法类似 JavaScript 的智能合约高级语言，它被设计成以编译的方式生成 以太坊虚拟机代码。

它的语法接近于 JavaScript，是一种面向对象的语言。但作为一种真正意义上运行在网络上的去中心合约，
它又有很多的不同，下面列举一些：

- 以太坊底层是基于帐户，而非 UTXO 的，所以有一个特殊的Address的类型。用于定位用户，定位合约，定位合约的代码（合约本身也是一个帐户）。
- 由于语言内嵌框架是支持支付的，所以提供了一些关键字，如payable，可以在语言层面直接支持支付。
- 存储是使用网络上的区块链，数据的每一个状态都可以永久存储，所以需要确定变量使用内存，还是区块链。
- 运行环境是在去中心化的网络上，会比较强调合约或函数执行的调用的方式。因为原来一个简单的函数调用变为了一个网络上的节点中的代码执行。
- 最后一个非常大的不同则是它的异常机制，一旦出现异常，所有的执行都将会被回撤，这主要是为了保证合约执行的原子性，以避免中间状态出现的数据不一致。




## 👉 bitcoin-cli

截至 2020/01/24 12:32 比特币共有 614272 个区块，如果想要修改第 614272 个区块的数据，其对应的
Hash 值就会改变，那么 614271 区块的哈希地址就会发生改变，但是修改所有 614271 个区块的哈希值
是不可能的，因此区块链中数据的不可篡改和可信赖的。

安装好 bitcoin 客户端之后，会在 Home 目录下面生成一个配置文件 bitcoin.conf，默认路径如下:

- Linux `$HOME/.bitcoin/bitcoin.conf`
- Windows `%APPDATA%\bitcoin\bitcoin.conf`
- Mac `$HOME/Library/Application Support/Bitcoin/bitcoin.conf`

利用 BitCoin CLI 工具的 GetBlockHash 命令获取指定高度区块的哈希，返回在本地最优链中指定高度
区块的哈希。

    yarn global add bitcoin-cli
    npm install --global bitcoin-cli


下面的命令返回高度为 614272 的区块的哈希值：

    bitcoin-cli -testnet getblockhash 614272

输出结果如下：

    00000000a0faf83ab5799354ae9c11da2a2bd6db44058e03c528851dee0a3fff

BitCoin Address 比特币地址是类似 1dice8EMZmqKvrGE4Qc9bUFf9PX3xaYDp 这样的字符串，通过
公钥加密而来。地址就好比银行卡号一样，用来表示一个账户，只有拥有私钥的用户才能解密地址。如果你需要
发送比特币给我，你就需要知道我的比特币地址，才能向我发送比特币。创建比特币地址和相对应的私钥这一操作，
可以通过比特币客户端完成，每个人可以拥有的比特币地址是没有数量限制的。


# 🚩 Consensus & Paxos 一致性理论基础模型
- 分布式系统理论基础 - CAP https://www.cnblogs.com/bangerlee/p/5328888.html
- 分布式理论基础 - 一致性方案 2PC 3PC https://www.cnblogs.com/bangerlee/p/5268485.html
- 分布式系统理论进阶 - Paxos https://www.cnblogs.com/bangerlee/p/5655754.html
- 可靠分布式系统 Paxos 的直观解释 https://blog.openacid.com/algo/paxos/
- 后分布式时代: 多数派读写的’少数派’实现 https://blog.openacid.com/algo/quorum/
- SlimTrie: 单机百亿文件的极致索引实现 https://blog.openacid.com/tech/algorithm/slimtrie-impl/
- Paxos 算法原理与推导 https://www.cnblogs.com/linbingdong/p/6253479.html
- Paxos Made Simple https://www.microsoft.com/en-us/research/publication/paxos-made-simple
- The Part-Time Parliament https://www.microsoft.com/en-us/research/publication/part-time-parliament/
- Mastering Bitcoin 精通比特币 https://github.com/bitcoinbook/bitcoinbook
- 精通比特币（第二版） https://www.8btc.com/book/281955
- 比特币词汇表 https://www.8btc.com/books/834/masterbitcoin2cn/_book/glossary.html

分布式系统的基础问题是`一致性`即共识 Consensus，是指对每个节点一个数据的更新，整个集群都知道更新，并且是一致的。

假设一个具有 N 个节点的分布式系统，当其满足以下条件时，我们说这个系统满足一致性：

- `全认同`: 所有 N 个节点都认同一个结果
- `值合法`: 该结果必须由 N 个节点中的过半节点提出
- `可结束`: 决议过程在一定时间内结束，不会无休止地进行下去

面临着的问题

- `消息传递异步无序`: 现实网络不是一个可靠的信道，存在消息延时、丢失，节点间消息传递做不到同步有序
- `节点宕机`: 节点持续宕机，不会恢复
- `节点宕机恢复`: 节点宕机一段时间后恢复，在分布式系统中最常见
- `网络分化`: 网络链路出现问题，将N个节点隔离成多个部分
- `拜占庭将军问题`: 节点或宕机或逻辑失败，甚至不按套路出牌抛出干扰决议的信息

分布式系统一致性的三个基本原则，统称 CAP 原则，三者不可得兼得。

CAP 是 Eric Brewer 在 2000 年 PODC 会议上提出，在 Inktomi 期间研发搜索引擎、分布式 Web 缓存时得出的关于数据一致性、服务可用性、分区容错性的猜想，即三者不可同时实现：

- `Consistency` ：写操作成功，后续操作都必须能读到这个新数据；写操作失败，后续操作都不能读到这个数据，对调用者而言数据具有强一致性，又叫原子性 Atomic。
- `Availability`：所有读写请求在一定时间内得到响应，可终止、不会一直等待。
- `Partition Tolerance`：分区容错要求在网络分区的情况下，分隔的节点仍能正常对外服务。

系统实现最多只能满足 CAP 其中两个，和 FLP 定理一样，CAP 定理也指示了一个不可达的结果 Impossibility Result：

- 如果某时刻满足 AP，分隔的节点同时对外服务但不能相互通信，将导致状态不一致，即不能满足 C；
- 如果某时刻满足 CP，网络分区的情况下为达成 C，请求只能一直等待，即不满足A；
- 如果某时刻满足 CA，在一定时间内要达到节点状态一致，要求不能出现网络分区，则不能满足 P。

`网络分区`因网络因素将系统分隔为多个单独的部分，是一个分布式系统的必要成分。网络节点丢包的情况也符合此定义，另外节点宕机，其他节点发往宕机节点的包也将丢失，这种情况同样符合网络分区。现实中的网络就是一个不可靠的网络、有一定概率宕机的设备，这两个因素都会导致 Partition，因而分布式系统实现中 P 是一个必须项，而不是可选项。

主要的算法：

- 2PC - Two Phase Commitment Protocol 二阶提交协议，有准备阶段（投票阶段）和提交阶段（执行阶段）；（选择提交或者回滚）；
- 3PC - Three Phase Commitment Protocol 三阶提交协议，有 `CanCommit`、`PreCommit`、`DoCommit` 三个阶段；
- Paxos 理论模型；

两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做。如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送`回滚消息` Rollback；否则，发送`提交消息` Commit；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。

2PC 先由一方，即 `coordinator` 进行 `propose` 并收集其他节点的 `vote`，再根据反馈决定 `commit` 或 `abort` 事务，其他参与决议节点称为 `participants`, 或 `cohorts`。

在异步环境并且没有节点宕机(fail-stop)的模型下，2PC 可以满足全认同、值合法、可结束，是解决一致性问题的一种协议。但如果再加上节点宕机(fail-recover)的考虑，2PC是否还能解决一致性问题呢？

如果 coordinator 在发起提议后宕机，那么 participant 将进入阻塞状态、一直等待回应以完成该次决议。这时需要另一角色把系统从不可结束的状态中带出来，新增的这一角色叫协调者备份 coordinator watchdog。协调者宕机一定时间后，watchdog 接替其工作，通过问询各 participant 的状态，决定阶段 2 是提交还是中止。这也要求 coordinator/participant 记录历史状态，以备宕机后 watchdog 对 participant 查询、宕机恢复后重新找回状态。

所以，可以总结 2PC 的缺点：

- 同步阻塞；
- 单点故障；
- 数据不一致；
- 宕机导致事务状态未知；

3PC 对 2PC 的改进：

- 引入超时机制，同时在协调者和参与者中都引入超时机制。 
- 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的。

如果 participant 在不同阶段宕机，3PC 如何应对：

- 阶段 1: 未收到 vote，直接中止事务；宕机的 participant 恢复后，读取 logging 发现未发出赞成 vote，自行中止该次事务。
- 阶段 2: 未收到 precommit ACK，但因为之前已经收到 vote 反馈，进行 commit；participant 恢复后发现收到 precommit 或已经发出赞成 vote，则自行 commit 该次事务。
- 阶段 3: 未收到 commit ACK，结束该次事务；participant 恢复后发现收到 commit 或者 precommit，也将自行 commit 该次事务。

因为有了准备提交阶段 Prepare to Commit，3PC 的事务处理延时也增加了 1 RTT 变为 3 RTT (Round-Trip Time 往返时延)，但是它防止 participant 宕机后整个系统进入阻塞态，增强了系统的可用性，对一些现实业务场景是非常值得的。


由 Fischer，Lynch 和 Patterson 三位科学家于 1985 年发表《Impossibility of Distributed Consensus with One Faulty Process》提出并证明 FLP 不可能定理，该论文后来获得了 Dijkstra 奖。FLP 不可能原理告诉我们，不要浪费时间，去试图为异步分布式系统设计面向任意场景的共识算法。在网络可靠，但允许节点失效的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性共识算法。

无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题，世上只有一种一致性算法，那就是 Paxos，所有其他一致性算法都是 Paxos 算法的不完整版。

学术研究，往往考虑地是数学和物理意义上理想化的情形，很多时候现实世界要稳定得多，不必如此悲观。工程实现上某次共识失败，再尝试几次，很大可能就成功了。科学告诉你什么是不可能的；工程则告诉你，付出一些代价，可以把它变成可行。


图灵奖获得者 Lamport 是分布式系统的关键性奠基人之一，有面包店算法，拜占庭将军问题，Paxos 理论模型等著名成果。

Paxos 算法是一种基于消息传递且具有高度容错特性的一致性算法，分布式系统中的节点通信存在两种模型: `共享内存`和`消息传递`。基于消息传递通信模型的分布式系统，不可避免会发生进程变慢被杀死，消息延迟、丢失、重复等问题，Paxos 算法就是在存在以上异常的情况下仍能保持一致性的协议。

Paxos 算法模型使用一个希腊故事来描述，在 Paxos 城市中存在三种角色：

- `Proposor` 提议者用来发出提案 Proposal。
- `Acceptor` 接受者可以接受或拒绝提案。
- `Learner` 学习者学习被选定的提案，当提案被超过半数的 Acceptor 接受后为被批准。

简单而言，一致性问题是在节点宕机、消息无序等场景可能出现的情况下，相互独立的节点之间如何达成决议的问题。作为解决一致性问题的协议，Paxos 的核心是节点间如何确定并只确定一个值 Value。这个值看似无足轻重，但是在 Paxos 协议里确定一个值是确定多值的基础。

Paxos 的两个原则：

- 安全原则，保证不能做错的事，只能有一个值被批准，不能出现第二个值把第一个覆盖的情况。
- 存活原则，只要有多数服务器存活并且彼此间可以通信，最终会批准某个被提议的值。


以下从简单模型到复杂逐步推演，从 Basic Paxos 构建 Multi Paxos。

假如只有一个 Proposer 发起提议，并且节点不宕机、消息不丢包，那么 Acceptor 做到以下这点就可以确定一个值：

- P1. 一个 acceptor 接受它收到的第一项提议。
 
当然上面要求的前提条件有些严苛，尝试放宽条件，假设多个 Proposer 可以同时发起提议，又怎样才能做到确定并只确定一个值呢？

首先 proposer 和 acceptor 需要满足以下两个条件：

1. proposer 发起的每项提议分别用一个 ID 标识，提议的组成因此变为(ID, value)
2. acceptor 可以接受(accept)不止一项提议，当多数(quorum) acceptor 接受一项提议时该提议被确定(chosen)

约定后面发起的提议的 ID 为递增的编号生成器，并假设可以有多项提议被确定，为做到确定并只确定一个值，Acceptor 节点要做到以下这点：

- P2. 如果一项值为 v 的提议被确定，那么后续只确定值为 v 的提议。

由于一项提议被确定(chosen)前必须先被多数派 Acceptor 接受，为实现 P2，实质上 Acceptor 需要做到：

- P2a. 如果一项值为 v 的提议被确定，那么 Acceptor 后续只接受值为 v 的提议。

满足 P2a 则 P2 成立 (P2a => P2)。

目前在多个 Proposer 可以同时发起提议的情况下，满足 P1、P2a 即能做到确定并只确定一个值。如果再加上节点宕机恢复、消息丢包的考量呢？

假设 Acceptor c 宕机一段时间后恢复，由于宕机 c 并不知晓其他 Acceptor 已经确定了一项值为 v 的决议。恢复后如果有 proposer 马上发起一项值不是 v 的提议，c 依据条件 P1 接受该提议，但这与 P2a 矛盾。为了避免这样的情况出现，进一步对 proposer 作约束：

- P2b. 如果一项值为 v 的提议被确定，那么 proposer 后续只发起值为 v 的提议

满足 P2b 则 P2a 成立 (P2b => P2a => P2)。

P2b 约束的是提议被确定(chosen)后 Proposer 的行为，我们更关心提议被确定前 Proposer 应该怎么做：

- P2c. 对于提议(n,v)，Acceptor 多数派中，如果存在最近一次接受的提议的值为 v'，即 ID 值最大，那么要求 v = v'，否则 v 可为任意值。

满足 P2c 则 P2b 成立 (P2c => P2b => P2a => P2)。

条件 P2c 是 Basic Paxos 的核心，光看 P2c 的描述可能会觉得一头雾水，我们通过 The Part-Time Parliament Fig. 1. 加深理解：

    ID  decree  quorum and voters
    2   α       A   B   Γ   x   -
    5   β       A   B   x   -   E
    14  α       -   x   -   ∆   x
    27  β       x   -   x   x   -
    29  β       -   x   Γ   ∆   -

Fig. 1. Paxon manuscript showing a set B, consisting of five ballots, that satisfies conditions B1(ß)–B3(ß).

假设 5 个 Acceptor A/B/Γ/∆/E，- 表示因宕机等原因缺席当次决议，x 表示接受提议；多数派接受提议后提议被确定，以上表格对应的决议过程如下：

- ID 2 提议，最早提出，根据 P2c 其提议值 α 不成立。
- ID 4 提议，多数派 A/B/Γ/E 在之前的决议中没有接受(accept)任何提议，因而提议不成立。
- ID 14 提议，B/∆/E，只有 ∆ 曾接受 ID 2 提议，根据 P2c，该轮提议的值必须与 ID 2 提议的值相同。
- ID 27 提议，A/Γ/∆ 多数派接受提议，其中 ∆ 曾接受 ID 2 提议、Γ 最近接受 ID 5 提议，根据 P2c，该轮提议的值必须为 ID 5 提议的值。
- ID 29 提议，B/Γ/∆ 之前都接受过提议，相比之下 Γ、∆ 曾接受最大的 ID 号为 27，该轮 ID 29 的提议的值必须与 ID 27 提议相同。

以上提到的各项约束条件可以归纳为 3 点，如果节点满足下面 3 点，那么在少数节点宕机、网络分化隔离的情况下，在“确定并只确定一个值”这件事情上可以保证一致性：

- B1(ß): ß 中每一轮决议都有唯一的ID标识
- B2(ß): 如果决议 B 被多数派接受，则确定决议 B
- B3(ß): 对于 ß 中的任意提议 B(n,v)，多数派中如果存在最近一次接受的提议的值为 v'，即 ID 值最大，那么要求 v = v'，否则 v 可为任意值

注: 希腊字母 ß 表示多轮决议的集合，字母 B 表示一轮决议。


有一个问题需要考量，假如 proposer A 发起 ID n 的提议，在提议未完成前 proposer B 又发起 ID n+1 的提议，同样 proposer C 又发起 ID n+2 的提议，如此 acceptor 不能完成决议、`形成活锁` livelock。虽然这不影响一致性，但我们一般不想让这样的情况发生。解决的方法是选出一个 leader 统一发起提议。

再引入一个新的角色 learner 依附于 acceptor，用于习得已确定的决议。以上决议过程都只要求 acceptor 多数派参与，而我们希望尽量所有 acceptor 的状态一致。如果部分 acceptor 因宕机等原因未知晓已确定决议，宕机恢复后可经本机 learner 采用 pull 的方式从其他 acceptor 习得。

其实不断地进行“确定一个值”的过程、再为每个过程编上序号，就能得到具有全序关系(total order)的系列值，进而能应用在数据库副本存储等很多场景。把单次“确定一个值”的过程称为实例(instance)，它由 proposer/acceptor/learner 组成。不同序号的实例之间互相不影响，输入相同、过程实质等同于执行相同序列的状态机(state machine)指令，因而将得到一致的结果。

引入 Proposer Leader 到 Multi Paxos 有助于提升性能，常态下统一由 leader 发起提议，可节省 prepare 步骤。leader 不用问询 acceptor 曾接受过最大 ID 的提议、只有 leader 提议也不需要 acceptor 进行 promise，直至发生 leader 宕机、重新选主。

在 Basic Paxos 协议中，每一次执行过程都需要经历 Prepare->Promise->Accept->Accepted 这四个步骤，这样就会导致消息太多，从而影响分布式系统的性能。 如果 Leader 足够稳定的话，Phase 1 里面的 Prepare->Promise 完全可以省略掉，从而使用同一个 Leader 去发送 Accept 消息。


## 👉 Raft Consensus Algorithm 共识机制
- [The Raft Consensus Algorithm](https://raft.github.io/)
- [Raft 动画交互演示](http://thesecretlivesofdata.com/raft/)
- [Raft 共识算法](https://www.jianshu.com/p/8e4bbe7e276c)
- [CoreOS 实战：剖析 etcd 共识算法](http://www.infoq.com/cn/articles/coreos-analyse-etcd)
- 分布式系统理论基础 - 选举、多数派和租约 https://www.cnblogs.com/bangerlee/p/5767845.html

`选举` election 是分布式系统实践中常见的一致性问题，通过打破节点间的对等关系，选得的 leader 或叫 master、coordinator 有助于实现事务原子性、提升决议效率。`多数派` Majority 的思路帮助我们在网络分化的情况下达成决议一致性，对多数派再进一步抽象化，称为 Quorum。`租约` lease 在一定期限内给予领导节点特定权利，也可以用于实现 leader 选举。

拜占庭将军问题假想：

曾经的拜占庭国土辽阔，为了抵御来自各个方向的敌人，军队之间分隔很远，他们之间只能通过信使互相传递消息。一场新的战役即将爆发，有 5 支拜占庭军队要共同进退，5 个将军都是平级的，他们要怎么达成一起进攻或者一起撤退的共识呢？

最简单的办法就是投票，每个将军都派出信使将自己的意见发给其他四个将军。对每个将军来说，算上自己的票数，如果进攻票超过 2 票就会发起进攻，如果少于或者等于 2 票就撤退。这是最简单的情况，很合逻辑。

假如，将军中有一个是奸细，其他 4 个将军有两个赞成进攻，2 个反对，这个将军给其中 2 个发去了进攻的意见，给另外 2 个却是撤退，结果是 2 支军队进攻，2 支军队撤退，没有达成共识。可能有一个或者多个信使被暗杀，或者被策反。

在这两种情况下，投票的结果不能代表大多数将军的意见。

以上，可以总结出拜占庭将军问题：在可能有叛徒的情况下，其余忠诚的将军如何不受其影响达成一致的协议？

根据相关研究得出的一般性的结论：如果叛徒的数量大于或等于三分之一 ，那么拜占庭问题不可解，这个三分之一也被称为`拜占庭容错`，三模冗余是完全无法容错的，也就是说无解，不可能保持一致性。

将拜占庭将军的故事映射到分布式系统上，每个将军代表一台计算机，信使代表通信系统，单台计算机可能遭受恶意攻击后向其他计算机发送错误信息，通信网络可能会阻塞、断开，通信内容可能被截取、替换，在这些情况下，正常运行的计算机怎么达成一致执行任务呢？

共识 Consensus，它是指分布式网络中节点对某一事实达成一致意见的过程。

2013 年图灵奖得主 Leslie Lamport 在 1980 年的论文 The Byzantine Generals Problem 中提出的分布式领域的容错问题，这是分布式领域最复杂、最严格的容错模型。


根据常见的工作上的问题，和基于非对称加密技术，对拜占庭将军问题进行简化：假设将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成一致性决定？

对于这个简化后的问题，有许多解决方案，第一个被证明的共识算法是 Paxos，由拜占庭将军问题的作者 Leslie Lamport 在 1990 年提出，最初以论文难懂而出名，又在 2001 重新发了一篇简单版的论文 Paxos Made Simple，然而还是挺难懂的。

因为 Paxos 难懂，难实现，所以斯坦福大学的教授在 2014 年发表了新的分布式协议 The Raft Consensus Algorithm。与 Paxos 相比，Raft 有着基本相同运行效率，但是更容易理解，也更容易被用在系统开发上。


Raft 的解决方案大概可以理解成，先在所有将军中选出一个大将军，所有的决定由大将军来做。选举环节：比如说现在一共有 3 个将军 A, B, C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就会把自己当成大将军候选人，然后派信使去问其他几个将军，能不能选我为总将军？假设现在 A 倒计时结束了，他派信使传递选举投票的信息给 B 和 C，如果 B 和 C 还没把自己当成候选人，假设各自还处于倒计时中，并且没有把选举票投给其他，他们把票投给将军 A，将军 A 知道自己收到了足够的票数，成为了大将军。在这之后，是否要进攻就由大将军决定，然后派信使去通知另外两个将军，如果在一段时间后还没有收到回复，可能信使被暗杀，那就再重派一个信使，直到收到回复。


求解拜占庭将军问题，隐含要满足以下两个条件：

- 每个忠诚的将军必须收到相同的、第 i 个将军的命 vi。
- 如果第 i 个将军是忠诚的，那么他发送的命令和每个忠诚将军收到的 vi 相同。

于是，拜占庭将军问题的可以描述为：一个发送命令的将军要发送一个命令给其余 n-1 个将军，使得：

- IC1 所有忠诚的接收命令的将军遵守相同的命令；
- IC2 如果发送命令的将军是忠诚的，那么所有忠诚的接收命令的将军遵守所接收的命令。

Lamport 对拜占庭将军问题的研究表明，叛徒个数 m 和将军总数 n 的关系为 n>3m 时，通过口头同步通信（假设通信是可靠的），可以构造同时满足 IC1 和 IC2 的解决方案，即将军们可以达成一致的命令。但如果通信是可认证、防篡改伪造的（如采用 PKI 认证，消息签名等），则在任意多的叛徒（至少得有两个忠诚将军）的情况下都可以找到解决方案。

而在异步通信情况下，情况就没有这么乐观。Fischer-Lynch-Paterson 定理证明了，只要有一个叛徒存在，拜占庭将军问题就无解。翻译成分布式计算语言，在一个多进程异步系统中，只要有一个进程不可靠，那么就不存在一个协议，此协议能保证有限时间内使所有进程达成一致。

由此可见，拜占庭将军问题在一个分布式系统中，是一个非常有挑战性的问题。因为分布式系统不能依靠同步通信，否则性能和效率将非常低。因此寻找一种实用的解决拜占庭将军问题的算法一直是分布式计算领域中的一个重要问题。

在这里，我们先给出分布式计算中有关拜占庭缺陷和故障的两个定义：

- 拜占庭缺陷 Byzantine Fault：任何观察者从不同角度看，表现出不同症状的缺陷。
- 拜占庭故障 Byzantine Failure：在需要共识的系统中由于拜占庭缺陷导致丧失系统服务。　

在分布式系统中，不是所有的缺陷或故障都能称作拜占庭缺陷或故障。像死机、丢消息等缺陷或故障不能算为拜占庭缺陷或故障。拜占庭缺陷或故障是最严重缺陷或故障，拜占庭缺陷有不可预测、任意性的缺陷，例如遭黑客破坏，中木马的服务器就是一个拜占庭服务器。

在一个有拜占庭缺陷存在的分布式系统中，所有的进程都有一个初始值。在这种情况下，共识问题 Consensus Problem，就是要寻找一个算法和协议，使得该协议满足以下三个属性。

- 一致性 Agreement：所有的非缺陷进程都必须同意同一个值。
- 正确性 Validity：如果所有的非缺陷的进程有相同的初始值，那么所有非缺陷的进程所同意的值必须是同一个初始值。
- 可结束性 Termination：每个非缺陷的进程必须最终确定一个值。


根据 Fischer-Lynch-Paterson 的理论，在异步通信的分布式系统中，只要有一个拜占庭缺陷的进程，就不可能找到一个共识算法，可同时满足上述要求的一致性、正确性和可结束性要求。在实际情况下，根据不同的假设条件，有很多不同的共识算法被设计出来。这些算法各有优势和局限。

算法的假设条件有以下几种情况：

- 故障模型：非拜占庭故障/拜占庭故障。
- 通信类型：同步/异步。
- 通信网络连接：节点间直连数。
- 信息发送者身份：实名/匿名。
- 通信通道稳定性：通道可靠/不可靠。
- 消息认证性：认证消息/非认证消息。

在出现比特币之前，解决分布式系统一致性问题主要是 Lamport 提出的 Paxos 算法或其衍生算法。Paxos 类算法仅适用于中心化的分布式系统，这样的系统的没有不诚实的节点，不会发送虚假错误消息，但允许出现网络不通或宕机出现的消息延迟。


中本聪在比特币中创造性的引入了**工作量证明** PoW - Proof of Work 来解决这个问题。

通过工作量证明就增加了发送信息的成本，降低节点发送消息速率，这样就以保证在一个时间只有一个节点，或是很少节点在进行广播，同时在广播时会附上自己的签名。

这个过程就像一位将军 A 在向其他的将军发起一个进攻提议一样，其它将军看到将军 A 签过名的进攻提议书，如果是诚实的将军就会立刻同意进攻提议，而不会发起自己新的进攻提议。

在比特币设计的 PoW 共识机制中，节点通过解决一个需要大量算力的数学难题来将交易打包成合法区块，这就是PoW。某个节点解决了这道难题，这个节点就获得了比特币网络的下一个打包出块权，因此该节点就能获得一定的比特币奖励，像现在一个块的奖励就是12.5个比特币。

但是呢，计算这道数学难题是有门槛的，那就是节点需要耗费大量的算力和电力来将这道难题计算出来，这些高昂的成本会让节点只会打包正确的交易上链，而不会打包不合法的交易上链，对节点来讲，作恶成本是非常高的，从而保证了区块链网络的安全。

为了获得出块权和奖励，PoW 拼的是节点的计算机的算力，而 PoS 不需要节点有那么高的算力，因为 PoS 拼的是权益。在 PoS 共识机制中，节点通过质押一定数量的代币参与共识。当节点质押的代币数量越多，那么就意味着这个节点的权益越大，这个节点就越能够被选中成为出块的节点。而某一节点如果违反规则，它就会受到严厉惩罚。

Bentov, Lee, Mizrahi, Rosenfeld 联合编写的论文，则提出了第三个选择，`行动证明` PoA - Proof of Activity。行动证明 PoA 认为，权益证明、工作量证明都不是完美无瑕的，并力求吸收两者的长处。

PoA 算法是一个区块链的共识算法，基本原理是结合 PoW, PoS 算法的特点进行工作。PoA 算法的一个理想的基本流程是，类似于 PoW 协议，矿工构造出一个符合难度要求的块头，通过矿工得到的块头计算衍生出 N 个币的编号，从区块链中追溯可以得到这几个币目前所述的参与者。矿工将这个块头发送给这 N 个参与者，其中前 N-1 个参与者对这个块进行校验和签名，最后第 N 个参与者校验并将交易加入到该块中，将这个区块发布出去，即完成一个区块的出块。

在实际运行中，无法保证网络上所有参与者都在线，而不在线的参与者则无法进行校验和签名，这个无法被校验和签名的块头则会被废弃。

即在实际运行中，应该是一个矿工构造出块头后广播给各个参与者签名，同时继续重新构造新的块头，以免上一个块头衍生的N个参与者存在有某一个没有在线，而导致块头被废弃。

因此，在这种情况下，一个块是否被确认不仅与矿工的计算能力有关同时也与网络上的在线比例有关。

在与比特币 PoW 同样 10 分钟出一个块的情况下，PoA 由于会有参与者不在线而产生的损耗，因此，10 分钟内矿工可以构造的块的数量会更多，即块头的难度限制会降低，那么矿工在挖矿过程中会造成的能量损耗也会降低。
与纯 PoS 相比，可以看到 PoA 的出块流程并不会将构造区块过程中的相关信息上链，可以明显减少区块链上用于维护协议产生的冗余信息的量。

行动证明的白皮书 Proof of Activity: Extending Bitcoin’s Proof of Work via Proof of Stake，此文含金量高，但它非常透彻，我强烈推荐那些对证明法有兴趣的人儿一读。

以太坊的 PoA - Proof of Authority 怎么回事？


从技术的角度讲讲 Raft 的原理。

从拜占庭将军的故事映射到分布式系统上，每个将军相当于一个分布式网络节点，每个 Raft 节点状态可以互相转换：

- `Follower` 追随者；
- `Candidate` 备选者；
- `Leader` 领导者；

每个节点上都有一个选举倒计时器 Election Timeout，时间随机在 150ms 到 300ms 之间。

有几种情况会重设 Timeout：

- 收到选举的请求；
- 收到 Leader 的 Heartbeat 信号；

在 Raft 运行过程中，最主要进行两个活动：

- 选主 Leader Election
- 记录复制 Log Replication，翻译成日志复制容易误解

由选主程序产生的领导节点时，状态由 Candidate 变成了 Leader，并间隔地给所有的 Follower 发送一个 Heartbeat 信号以保持所有节点的状态，Follower 收到 Heartbeat 后重设 Timeout。

Leader 出故障挂掉了，其他 Follower 将会在 Timeout 时间后恢复备选者状态，并进行重新选主。在选出一个新的 Leader 后，如果原来的 Leader 恢复了又重新加入了，这个时候怎么处理？在 Raft 里，第几轮选举是有记录的，重新加入的 Leader 是第一轮选举 Term 1 选出来的，查询到现在的 Leader 是 Term 2，那么原来的 Leader 会自觉降级为 Follower。

如果有多个 Follower 同时 Timeout，都变成了 Candidate 开始选举，并且获得同票时，本轮选举没有胜出者无结果，会进入下一轮选举。

Raft 在实际应用场景中的一致性更多的是体现在不同节点之间的数据一致性，客户端发送请求到任何一个节点都能收到一致的返回，当一个节点出故障后，其他节点仍然能以已有的数据正常进行。在选主之后的复制日志就是为了达到这个目的，制造出来的冗余数据可以抗伪造。




# 🚩 Hyperledger Fabric
- [What's news](https://hyperledger-fabric.readthedocs.io/zh_CN/latest/whatis.html)
- [Hyperledger Fabric Wiki](https://wiki.hyperledger.org/display/fabric)
- [Hyperledger Fabric v2.x docs](https://hyperledger-fabric.readthedocs.io/en/release-2.2/whatsnew.html)
- [Hyperledger Project Lifecycle](https://toc.hyperledger.org/governing-documents/project-lifecycle.html)
- [Hyperledger Introduction](https://hyperledger-fabric.readthedocs.io/en/release-2.5/whatis.html)
- [Blockchain 关键概念介绍](https://hyperledger-fabric.readthedocs.io/zh_CN/latest/blockchain.html)

Hyperledger Fabric 是一个企业级分布式账本平台，提供模块化和多功能性适用于广泛的行业用例集。
通过即插即用组件体系结构适应企业的多样性，如共识、隐私和会员服务。

区块链不是万能的，但是在某些方向，尤其是对敏感信息加密共享有旺盛需求的领域，确实有其优势。当前主要
区块链项目的发展和应用状况：公共链领域，比特币依然一骑绝尘，以太坊紧跟其后，企业级商用方案百花齐放，
但是 IMB 的 Hyperledger 正在逐渐成为联盟链方案的首选。

Hyperledger Project 由 Linux 基金会创办于 2015 年 10 月，是一个开源的区块链研发孵化项目，
致力于提供可协同开发以区块链为底层的分布式账本。旗下的 Fabric 由其核心成员之一 IBM “捐赠”。
Fabric 项目由 Go 语言编写，目标为打造一个提供分布式账本解决方案的联盟链平台。


[Hyperledger Fabric Key Concepts](https://hyperledger-fabric.readthedocs.io/en/release-2.5/key_concepts.html)

01. [Introduction](https://hyperledger-fabric.readthedocs.io/en/release-2.5/blockchain.html)
02. [Hyperledger Fabric Model](https://hyperledger-fabric.readthedocs.io/en/release-2.5/fabric_model.html)
03. [How Fabric networks are structured](https://hyperledger-fabric.readthedocs.io/en/release-2.5/network/network.html)
04. [Identity](https://hyperledger-fabric.readthedocs.io/en/release-2.5/identity/identity.html)
05. [Membership Service Provider (MSP)](https://hyperledger-fabric.readthedocs.io/en/release-2.5/membership/membership.html)
06. [Policies](https://hyperledger-fabric.readthedocs.io/en/release-2.5/policies/policies.html)
    - [Policies in Hyperledger Fabric](https://hyperledger-fabric.readthedocs.io/en/release-2.5/policies.html)
07. [Peers](https://hyperledger-fabric.readthedocs.io/en/release-2.5/peers/peers.html)
08. [Ledger](https://hyperledger-fabric.readthedocs.io/en/release-2.5/ledger/ledger.html)
09. [The Ordering Service](https://hyperledger-fabric.readthedocs.io/en/release-2.5/orderer/ordering_service.html)
10. [Smart Contracts and Chaincode](https://hyperledger-fabric.readthedocs.io/en/release-2.5/smartcontract/smartcontract.html)
11. [Fabric chaincode lifecycle](https://hyperledger-fabric.readthedocs.io/en/release-2.5/chaincode_lifecycle.html)
12. [Private data](https://hyperledger-fabric.readthedocs.io/en/release-2.5/private-data/private-data.html)
13. [Channel capabilities](https://hyperledger-fabric.readthedocs.io/en/release-2.5/capabilities_concept.html)
14. [Security Model](https://hyperledger-fabric.readthedocs.io/en/release-2.5/security_model.html)
15. [Use Cases](https://hyperledger-fabric.readthedocs.io/en/release-2.5/usecases.html)

Fabric 应用构架组成：

01. **Prerequisite software**: 前置软件运行环境，如 Docker。
02. **Fabric and Fabric samples**: Fabric 可以执行程序，运行一个 Fabric 网络以及示例。
03. **Contract APIs**: 提供接口用于开发智能合约，并在 Fabric 网络上执行它。
04. **Application APIs**: 应用接口用于开发区块链应用。
05. **The Application**: 开发者的区块链应用，利用 SDK 调用 Fabric 网络上运行的智能合约。

Fabric Application Stack

                 +==================+
                 | The Application  |
                 +==================+
                          v          
                +====================+
                |  Application SDK   |
                +====================+
                          v          
             +==========================+
             |     Contract APIs        |
             +==========================+
                          v          
         +==================================+
         |    Fabric and Fabric samples     |
         +==================================+
                          v          
    +=============================================+
    |           Prerequisite software             |
    +=============================================+


区块链技术本质是信任，Code is law，代码即法律！为了在一个充满陌生因素的网络中实现这一点，需要
共识算法来让网络的参与者对某一项事务达成一致，并以不可篡改的分布式账本记录下来。

Blockchain 的基本构成要素：

- **A Distributed Ledger** 区块链的核心是分布式账本，记录网络中发生的交易；
- **Smart Contracts** 智能合约实现**一致性的信息更新**，更新过程也被账本记录下来；
- **Consensus** 共识，即信任机器，保证交易同步到网络中所有分布式账本中；

分布式即去中心化，**distributed** =  **decentralized**，因为交易数据会在网络中多个参与者
之间进行复制，以共识为前提，保证交易记录一致有效，并且不可篡改，众多的参与者各自都在维护中合作。

区块链划分，通常包括公链、联盟链和私有链。更为严谨的定义，即 permissionless（or public）chain
和 permissioned chain。两者的本质还是 SMR（state-machine replication）状态机复制，这是
分布式系统中最重要的一个概念。

公有链是指任何人都可以参与区块链数据的维护和读取、任何人都能发送交易且交易能获得有效确认、任何人
都能参与其中共识过程、不受单个中央机构控制、数据完全开放透明（如比特币系统、以太坊系统等）。
公有链被认为是完全去中心化的。大部分公有链环境下，主要通过共识算法、激励或者惩罚机制、对等网络的
数据同步保证最终一致性。

私链是指，其写入权限仅在一个组织手里的区块链。读取权限或者对外开放，或者被任意程度地进行了限制。
相关的应用囊括数据库管理、审计、甚至一个公司，尽管在有些情况下希望它能有公共的可审计性，但在很多
的情形下，公共的可读性并非是必须的。

私链特性：

1. 交易速度快，因为就算少量的节点也都具有很高的信任度，并不需要每个节点来验证一个交易。
2. 隐私性好，私有链在区块链上的数据受到隐私政策保护。
3. 交易成本低，可以进行完全免费或者至少说是非常廉价的交易。
为了解决缺乏隐私和机密性的问题来满足企业业务需求，区块链平台采用了多种方法。所有方法都需要权衡利弊。

加密数据是提供保密性的一种方法；然而，在利用 PoW 达成共识的非许可网络中，加密数据位于每个节点上。
如果有足够的时间和计算资源，加密可能会被破解。对于许多企业业务而言，不能接受信息可能受损的风险。

联盟链（consortium blockchain）由机构间根据自行商定的协议建立而成。成员节点参与区块链运行需要
根据规则获得访问和编写的权限。联盟链由成员节点共同维护，提供成员管理，认证，授权，监控，审计等功能。

Fabric 与其他一些区块链系统的不同之处在于，它是私有的，加入网络需要经过许可。 Fabric 网络的成员
不是一个允许未知身份参与网络的开放式无权限系统，这种网络需要“工作证明”等协议来验证交易并保护。

Fabric 采用的是可信的会员服务提供商 Membership Service Provider（MSP）注册制度。通过依赖
参与者的身份，私有区块链可以使用更传统的崩溃容错（CFT）或拜占庭容错（BFT）共识协议，而不需要
昂贵经济代价的挖矿行为。同时降低了参与者故意通过智能合约引入恶意代码的风险。首先，参与者彼此了解
对方以及所有的操作，无论是提交交易、修改网络配置还是部署智能合约，都根据网络中已经确定的背书策略
和相关交易类型被记录在区块链上。与完全匿名相比，很容易识别犯罪方，并根据治理模式的条款进行处理。


零知识证明 Zero Knowledge Proof (ZKP) 是解决数据隐私的方法，这项研究最早始于 1985 年，由
MIT 教授 Shafi Goldwasser， Silvio Micali 和 密码学大师 Charles 在其论文中提出，
The Knowledge Complexity of Interactive Proof-Systems。

正是零知识证明这个伟大概念的提出，并逐步成为了现代密码学理论的根基之一，而 Shafi Goldwasser 
和 Silvio Micali 也于 2012 年获得了有“计算机界诺贝尔奖”之称的图灵奖。零知识证明系统所要完成
的任务是「证明某一个事实并且不泄露知识」，这个过程就是零知识证明。

听起来还是有些晦涩难懂？讲个简单的例子：

劫匪相得到进入山洞的咒语，就抓住了阿里巴巴进行拷问。但是聪明的阿里巴巴知道，如果把咒语告诉了劫匪，
那么他也就彻底没有了价值，肯定会将他杀掉，死活不说，那么也会杀掉他，于是他想到一个好办法，即能不
泄露咒语，又能让劫匪相信他知道咒语。

阿里巴巴说：“你们离我一箭远，然后用弓箭指着我，当你们举右手我会念咒语打开石门，当你们举左手我会
念咒语关上石门，如果我逃跑或没有做到，证明我不知道咒语，你们可以一箭杀掉我。”劫匪同意了这个提议，
多次尝试后阿里巴巴都成功按照指示让石门打开或关上了，但是由于有一定距离，他们听不清楚咒语到底是什么，
就这样，阿里巴巴没有透露任何消息就向劫匪证明了他的真实性。

自从这个概念被提出来后，人们就将其应用到了各个领域，比如身份认证系统、存证系统、数据共享、水印检测，
密钥交换等等，在隐私数据越来越受到大家关注的今天，零知识证明在隐私数据保护的应用中大放异彩。


Fabric 将智能合约称之为“链码”，chaincode，作为受信任的分布式应用程序，从区块链中获得信任，
在节点中达成基本共识，它是区块链应用的业务逻辑。

智能合约有三个关键点，尤其是应用于平台时：

- 多个智能合约在网络中同时运行，
- 它们可以动态部署（很多情况下任何人都可以部署），
- 应用代码应视为不被信任的，甚至可能是恶意的。

大多数现有的具有智能合约能力的区块链平台遵循 **order-execute** 架构，其中共识协议：

- 验证并将交易排序，然后将它们传播到所有的节点，
- 每个节点按顺序执行交易。

Fabric 针对交易引入了一种新的架构，称为**执行-排序-验证**模型，解决了**顺序执行**模型面临的
弹性、灵活性、可伸缩性、性能和机密性问题，它将交易流分为三个步骤：

- **execute**：执行一个交易并检查其正确性，从而给它背书，
- **order**：通过（可插拔的）共识协议将交易排序，
- **validate**：提交交易到账本前先根据特定应用程序的背书策略验证交易。

这种设计与顺序执行模式完全不同，Fabric 在交易顺序达成最终一致前执行交易。

Fabric 中特定应用程序的背书策略，可以指定需要哪些节点或多少节点，来保证给定的智能合约正确执行。
因此，每个交易只需要由满足交易的背书策略所必需的节点的子集来执行（背书）。这样可以并行执行，从而
提高系统的整体性能和规模。第一阶段也消除了任何非确定性，因为在排序之前可以过滤掉不一致的结果。

因为 Fabric 已经消除了非确定性，Fabric 是第一个能使用标准编程语言的区块链技术。


Fabric 设计了排序服务以支持**可插拔式共识**，交易的排序委托给模块化组件以达成共识，该组件在逻辑
上与执行交易和维护帐本的节点解耦。具体来说，就是**排序服务**。由于共识是模块化的，可以根据特定部署或
解决方案的信任假设来定制其实现。这种模块化架构允许平台依赖完善的工具包进行 CFT 或 BFT 的排序。

- 崩溃容错 Crash Fault Tolerance (CFT) 容忍分布式节点中存在故障，但不能容忍搞破坏。
- 拜占庭容错 Byzantine fault-tolerant (BFT) 同时可以容忍节点故障以及部分节点搞破坏。

Fabric 目前提供了一种基于 Raft 协议的 etcd 库实现的 CFT 排序服务。etcd 是轻量、专用、强一致性、
分布式、可靠的关键值存储，用于存储分布式系统中最关键的数据，使用 Raft 共识算法来保持数据一致性。

- https://github.com/etcd-io/etcd
- [`etcd` library](https://coreos.com/etcd/) 
- [Raft protocol](https://raft.github.io/raft.pdf)

另外，请注意，这些并不相互排斥。一个 Fabric 网络中可以有多种排序服务以支持不同的应用或应用需求。

Fabric 代码库当前嵌入的共识插件如下：

- **Solo**: A single node orderer, useful for development, testing and proof of concepts.
- **Kafka**: Several ordering nodes relay transactions into an Apache Kafka system, 
             pull transactions back in the same order and then cut them into 
             identical blocks via synchronization messages also sent through Kafka.
- **Raft**: Several ordering nodes run the Raft protocol by embedding the Raft library of etcd.

除了官方的 Fabric 共识实现之外，还有一个 Fabric 分支实现了名为 SmartBFT 的 BFT 库。

- https://github.com/SmartBFT-Go/fabric
- https://github.com/SmartBFT-Go/consensus


排序服务在 Fabric 网络的排序节点中运行，和 Peer 节点一样，所有排序节点都必须属于已存在的组织。
**组织** Orgnization 是 Fabric 网络的管理单元。

组织拥有成员服务提供者（MSP），而 CA（Certificate Authority）专门为组织创建证书和 MSP。
成员服务提供者（MSP）是 Fabric 的一个组件，旨在提供抽象的成员操作。具体的，MSP 将分发证书、
验证证书和用户授权背后的所有加密机制和协议抽象出来。MSP 可以定义它们自己的身份概念。同样还可以
定义管理(身份验证)和认证(签名生成和验证)这些身份的规则。

一个 Fabric 区块链网络可以由一个或多个 MSP 管理。这提供了成员操作的模块和不同成员标准和架构
之间的互操作性。


Fabric 2.0 中使用 Kafka 消息系统来实现交易消息的排序，最新版本从 Kafka 迁移到了 Raft 共识。
Orderer v3: Kafka consesus remove (#3533)

- orderer/consensus/kafka/chain.go
- fabric\docs\source\kafka.rst
- fabric\docs\source\kafka_raft_migration.md
- https://github.com/hyperledger/fabric-rfcs/blob/main/text/orderer-v3.md
- https://hyperledger-fabric.readthedocs.io/zh_CN/latest/raft_configuration.html
- https://hyperledger-fabric.readthedocs.io/zh_CN/latest/kafka.html
- https://hyperledger-fabric.readthedocs.io/zh_CN/latest/kafka_raft_migration.html
- https://hyperledger-fabric.readthedocs.io/zh_CN/latest/pluggable_endorsement_and_validation.html
- [The ABCs of Kafka in Hyperledger Fabric](https://codeburst.io/the-abcs-of-kafka-in-hyperledger-fabric-81e6dc18da56)

旧版本中 kafka 共识当中，每个排序节点是消息的生产者，同时也是消费者。每个 channel 对应一个 topic，
并且为了保证顺序性，只设置了一个 patition。


## 👉 Fabric Installation
- [Hyperledger Fabric](https://github.com/hyperledger/fabric)
- [Hyperledger Fabric CA](https://github.com/hyperledger/fabric-ca)
- [Samples for Hyperledger Fabric](https://github.com/hyperledger/fabric-samples)

Linux 或者 Windows WSL 软件环境要求：

- https://hyperledger-fabric.readthedocs.io/zh_CN/latest/prereqs.html
- https://hyperledger-fabric.readthedocs.io/zh_CN/latest/install.html
- 安装 Git，如果还没安装，下载最新版本的 git，否则运行 curl 命令有问题。
- 安装 cURL，如果尚未安装 cURl 或在服务器上运行 curl 命令出错时请下载最新版本的 cURL 工具。
- 安装 Docker 和 Docker Compose。
- 可选安装 jq，这是一个轻量的 JSON 字符串处理命令工具。

请确保 docker 服务处于运行状态，后面拉取 FABRIC_IMAGES: peer orderer ccenv tools baseos
等映像文件需要。下边的命令适用于 Linux 系统：

```sh
docker --version
# 确保运行 docker daemon。
sudo systemctl start docker
# 手动启动 docker daemon 进程。
sudo dockerd
# 可选：如果你希望 docker daemon 在系统启动的时候会自动启动的话，使用下边的命令：
sudo systemctl enable docker
# 将你的用户添加到 docker 组。
sudo usermod -a -G docker <username>
```

Linux 终端运行命令任务的几种操作：

- 在命令末尾加上 & 符号，就可以让程序在后台运行，关闭终端时会结束运行；
- 使用 nohup 让程序始终在后台执行，即使关闭当前的终端。如 `nohup bash example.sh &`
- 使用 Ctrl+z 可以暂停任务运行，将前台运行的程序挂起；
- 使用 jobs 命令查询当前挂起的任务；
- 使用 bg %[number] 命令把指定序号的任务放到后台运行；
- 使用 fg %[number] 指令把一个程序掉到前台；
- 使用 kill 命令终止任务，kill %num 终止指定序号的任务，或者 kill pid 终止指定进程；
- 使用 ps 命令可以查询进程 ID，如 `ps all`；
- 直接 Ctrl+c 终止前台进程；


Docker 服务运行时，会创建 /var/run/docker.sock 网络套接文件，客户端会通过它请求映像文件。
如果，后续执行安装脚本出现以下权限问题，请使用 sudo 执行安装脚本：

    dial unix /var/run/docker.sock: connect: permission denied

Docker Daemon 守护进程负责监听 Docker Client 请求，用户通过命令行与服务端通信，进行 Docker
相关操作。

UNIX 域套接字是默认方式，会通过 /var/run/docker.sock 文件与本地进程之间的通讯。这种方式相比于
网络套接字效率更高，但局限性就是只能被本地的客户端访问。

Windows 系统中监听的是 npipe:////./pipe/docker_engine 命名管道。

通过配置，可以改变网络通信来实现 Docker Client 和 daemon 之间的通信。服务端指定 -H IP:PORT
监听 TCP 端口，Docker 默认网络端口为 2375，TLS 方式默认端口为 2376。

客户端通过指定的 IP 和端口访问服务端：`docker -H IP:PORT`，从而在服务端的服务器上创建容器。


在 Windows 10 上，应该使用本地 Docker 发行版，并且可以使用 PowerShell。但是仍需要可用的
uname 命令以便成功运行二进制命令。可以通过 Git 来得到它，但是只支持 64 位的版本。

在运行任何``git clone``命令前，运行如下命令，以避免不同系统换行符号、长路径支持差异带来问题：

    git config --global core.autocrlf false
    git config --global core.longpaths true

    git config --get core.autocrlf
    git config --get core.longpaths

它们必须分别是 false 和 true。


确定计算机上安装好了软件运行环境，接下来的安装脚本将按以下步骤执行命令：

01. 克隆 hyperledger/fabric-samples 仓库到本地
02. checkout 检出适当的版本标签
03. 将指定版本的 Fabric 平台特定二进制文件和配置文件安装到 fabric-samples 下的 /bin 和 /config 目录中
04. 下载指定版本的 Fabric docker 镜像

安装必备组件后，即可下载并安装 HyperLedger Fabric。在开发真正的 Fabric 程序之前，使用安装脚本，
可以安装示例、二进制文件和 Docker 镜像到当前的系统中。该脚本还将 Docker 镜像下载到本地注册表。

Hyperledger Fabric 提供了一个可选的证书授权服务，可以选择使用该服务生成证书和密钥材料，以配置
和管理区块链网络中的身份。然而，任何可以生成 ECDSA 证书的 CA 都是可以使用的，Fabric CA 是可选项。

在下载完 Fabric 示例以及 Docker 镜像到你本机之后，就可以跟着文档教程使用 Fabric 的测试网络。

准备好了之后，进入到将要安装 Fabric 示例和二进制的路径下，执行命令来下载二进制文件和镜像：

```sh
# curl -sSL https://bit.ly/2ysbOFE | bash -s -- <fabric_version> <fabric-ca_version>
# curl -sSL https://bit.ly/2ysbOFE | bash -s
# curl -sSL https://bit.ly/2ysbOFE | bash -s -- 2.2.0 1.4.7
curl -sSL https://raw.githubusercontent.com/hyperledger/fabric/master/scripts/bootstrap.sh | bash -s

# export PATH=path/to/fabric/bin:$PATH
# echo "export PATH=path/to/fabric/bin:\$PATH" >> ~/.profile
# source ~/.profile

Clone hyperledger/fabric-samples repo

==> Already in fabric-samples repo
===> Checking out v2.4.7 of hyperledger/fabric-samples

Pull Hyperledger Fabric binaries

===> Downloading version 2.4.7 platform specific fabric binaries
===> Downloading:  https://github.com/hyperledger/fabric/releases/download/v2.4.7/hyperledger-fabric-linux-amd64-2.4.7.tar.gz
===> Downloading version 1.5.5 platform specific fabric-ca-client binary
===> Downloading:  https://github.com/hyperledger/fabric-ca/releases/download/v1.5.5/hyperledger-fabric-ca-linux-amd64-1.5.5.tar.gz
```

如果你想要最新的生产发布版本，忽略所有的版本标识符。如果你想要一个指定的发布版本，传入一个 Fabric、
Fabric-ca 和第三方 Docker 镜像的版本标识符。

脚本中演示了指定 Fabric v2.4.7 和 Fabric CA v1.5.5。已经安装二进制文件，可以使用 -b -s 跳过：

```sh
printHelp() {
    echo "Usage: bootstrap.sh [version [ca_version]] [options]"
    echo
    echo "options:"
    echo "-h : this help"
    echo "-d : bypass docker image download"
    echo "-s : bypass fabric-samples repo clone"
    echo "-b : bypass download of platform-specific binaries"
    echo
    echo "e.g. bootstrap.sh 2.4.7 1.5.5 -s"
    echo "will download docker images and binaries for Fabric v2.4.7 and Fabric CA v1.5.5"
}
```

如果运行上述 curl 命令时出错，则可能是旧版本的 curl 不能处理重定向或环境不支持。升级 curl 或者
访问未缩写的安装脚本的 URL。或者是国内网络环境影响，可以多尝试几次。

上面的命令下载并执行一个 bash 脚本，该脚本将下载并提取设置网络所需的所有特定于平台的二进制文件，
并将它们放入在前面创建的克隆仓库的 bin 子目录中。

你可能希望将其添加到 PATH 环境变量中，使用 export 导出路径，以便在不需要指定每个二进制文件的绝对
路径的情况下获取这些命令。

最后，该脚本会将从 Docker Hub 上下载 Hyperledger Fabric docker 镜像到本地 Docker 注册表中，
并将其标记为 ‘latest’。

查看每个镜像的名称；这些组件最终将构成我们的 Hyperledger Fabric 网络。你还会注意到，有两个具有
相同镜像 ID 的实例。在 1.2.0 之前，根据 `uname -m` 命令输出内容中指示的平台信息来确定下载的镜像，
一个标记类似 “amd64-1.x.x”，另一个标记为 “latest”，具体平台架构将由当前系统体系架构决定。

最后，该脚本列出了结束时安装的 Docker 镜像。

    ===> List out hyperledger docker images
    hyperledger/fabric-tools     2.4       545af418d284   4 months ago   489MB
    hyperledger/fabric-tools     2.4.7     545af418d284   4 months ago   489MB
    hyperledger/fabric-tools     latest    545af418d284   4 months ago   489MB
    hyperledger/fabric-peer      2.4       d77dd7cfbcd7   4 months ago   64.2MB
    hyperledger/fabric-peer      2.4.7     d77dd7cfbcd7   4 months ago   64.2MB
    hyperledger/fabric-peer      latest    d77dd7cfbcd7   4 months ago   64.2MB
    hyperledger/fabric-orderer   2.4       77c489caa81b   4 months ago   36.7MB
    hyperledger/fabric-orderer   2.4.7     77c489caa81b   4 months ago   36.7MB
    hyperledger/fabric-orderer   latest    77c489caa81b   4 months ago   36.7MB
    hyperledger/fabric-ccenv     2.4       4eb7ee7f4af5   4 months ago   520MB
    hyperledger/fabric-ccenv     2.4.7     4eb7ee7f4af5   4 months ago   520MB
    hyperledger/fabric-ccenv     latest    4eb7ee7f4af5   4 months ago   520MB
    hyperledger/fabric-baseos    2.4       b20d2dde6941   4 months ago   6.82MB
    hyperledger/fabric-baseos    2.4.7     b20d2dde6941   4 months ago   6.82MB
    hyperledger/fabric-baseos    latest    b20d2dde6941   4 months ago   6.82MB
    hyperledger/fabric-ca        1.5       93f19fa873cb   7 months ago   76.5MB
    hyperledger/fabric-ca        1.5.5     93f19fa873cb   7 months ago   76.5MB
    hyperledger/fabric-ca        latest    93f19fa873cb   7 months ago   76.5MB


## 👉 Network 网络概念及命令使用
- [Samples for Hyperledger Fabric](https://github.com/hyperledger/fabric-samples)
- [Fabric 网络测试](https://hyperledger-fabric.readthedocs.io/zh_CN/latest/test_network.html)
- [Fabric Documentation i18n](https://github.com/hyperledger/fabric-docs-i18n)
- [Fabric CA User’s Guide](https://hyperledger-fabric-ca.readthedocs.io/en/latest/users-guide.html)
- [BDoS: Blockchain Denial-of-Service Attacks](https://arxiv.org/pdf/1912.07497.pdf)
- [区块链毕业设计必读论文](http://blog.hubwiz.com/2020/03/15/block-paper-14/)
- [Policies in Hyperledger Fabric](https://hyperledger-fabric.readthedocs.io/en/release-2.5/policies.html)

在示范项目仓库``fabric-samples``中，提供了一个 `test-network` 项目，它用来对 Fabric v2.0
网络进行测试，供学习了解基本的 Fabric 网络概念。有了 Fabric 网络，才可以进行各种实验测试。

代码库中提供了 network.sh 脚本来部署测试网络，有经验的开发人员可以使用 `test-network` 项目
测试其智能合约和应用程序。该测试网络在 Fabric v2.0 中引入作为旧版本的 first-network 示例的
长期替代。

该示例网络使用 Docker Compose 部署了一个 Fabric 网络。这些节点隔离在 Docker Compose 网络中，
测试网络没有配置 channel 以连接到其他正在运行的 fabric 节点。

然后，通过执行以下命令来启动、关闭 Fabric 网络，以下命令需要进入测试网络的目录下运行：

```sh
> cd fabric-samples/test-network
> ./network.sh -h
# Usage:
#   network.sh <Mode> [Flags]
#     Modes:
#       up - Bring up Fabric orderer and peer nodes. No channel is created
#       up createChannel - Bring up fabric network with one channel
#       createChannel - Create and join a channel after the network is created
#       deployCC - Deploy a chaincode to a channel (defaults to asset-transfer-basic)
#       down - Bring down the network

> ./network.sh up
> ./network.sh down
```

使用 `./network.sh up` 命令创建一个由两个对等节点和一个排序节点组成的 Fabric 网络。 没有创建
任何 channel，虽然脚本提供这个功能。如果命令执行成功，可以使用 docker 查询到节点的日志信息：

```sh
$ docker ps --all --format "table {{.ID}}\t{{.Command}}\t{{.Names}}\t{{.Image}}\t{{.Status}}"
CONTAINER ID   COMMAND                  NAMES                      IMAGE                               STATUS
2a558cea798e   "/bin/bash"              cli                        hyperledger/fabric-tools:latest     Up 35 seconds
f0d20f53b828   "peer node start"        peer0.org1.example.com     hyperledger/fabric-peer:latest      Up 36 seconds
09aaa8b7ab73   "orderer"                orderer.example.com        hyperledger/fabric-orderer:latest   Up 36 seconds
048dba3424f3   "peer node start"        peer0.org2.example.com     hyperledger/fabric-peer:latest      Up 36 seconds
```

默认情况下，使用 Fabric 自带的 cryptogen 工具来生成证书以建立网络。生产环境中可以通过证书颁发
机构建立网络，它们是对等的工具，只是 CA 服务是一种动态的证书生产环境。开发、测试阶段不需要部署 CA，
使用证书生成工具生成证书更简便。当然在生产环境中也可以不使用 CA 服务器，继续使用 `cryptogen`。

Fabric CA 是证书授权中心 Certificate Authority (CA)，包含客户、服务端。

- `fabric-ca-client` 客户端命令用来管理身份（包括属性管理）和证书（包括回复和撤销）。
- `fabric-ca-server` 服务端命令用来初始化和启动服务进程，以便于管理一个或多个 CA。

证书的默认签名算法为 ECDSA，Hash 算法为 SHA-256。

Fabric 设计中考虑了三种类型的证书：

- 登记证书（Enrollment Certificate）颁发给注册用户或节点等实体，代表网络中身份。一般长期有效。
- 交易证书（Transaction Certificate）颁发给用户，控制每个交易的权限，实现匿名性。短期有效。
- 保障通信链路安全的 TLS 证书，验证远端实体身份，防止窃听。

目前，在实现上，主要通过 ECert 来对实体身份进行检验，通过检查签名来实现权限管理。TCert 功能暂未
实现，用户可以使用 idemix 机制来实现部分匿名性。

Fabric CA 数字证书认证中心，它提供了如下功能：

- 用户信息的注册
- 数字证书的发行
- 数字证书的延期与吊销

并且，Fabric CA 服务端提供了 RESTful 接口供客户端工具和 HFC SDK 访问。


Fabric 基于微服务构架开发，Service Discovery CLI 发现服务使用 YAML 配置文件来对包括证书和
私钥路径以及成员服务提供者身份证（MSP ID）在内的属性进行维持。

发现服务使用 `discover` 命令提供以下四种操作，发现对端、以及链码背书人：

- peers [<flags>]    Discover peers
- config [<flags>]    Discover channel config
- endorsers [<flags>]    Discover chaincode endorsers
- saveConfig    Save the config passed by flags into the file specified by --configFile

`peer channel` 命令用于执行 peer 节点上的管理通道相关的操作，比如加入通道，或者列出当前节点
加入的通道。

`configtxlator` 命令用于转换 fabric 数据结构，protobuf 与 JSON 之间进行转换，并创建配置更新。
该命令可以启动 REST 服务器，并通过 HTTP 公开，可以直接用作命令行工具。

`configtxgen` 命令用于创建和查看 channel 配置相关构件，生成内容取决于 `configtx.yaml` 配置文件。

命令中的 tx 表示的是 Transaction 交易的意思。

管理员可以通过 `peer node` 命令来启动 Peer 节点，将节点中的所有通道重置为创世区块，或者将某个
通道回滚到给定区块号。

```sh
# Available peer node commands:
  peer node start --peer-chaincodedev   # Starts the node.
  peer node reset [flags]   # Resets the node.
  peer node pause [flags]   # Pauses a channel on the peer.
  peer node resume -c ch1   # Resumes a channel on the peer.
  peer node rollback -c ch1 -b 150  # Rolls back a channel.
  peer node unjoin -c ch1   # Unjoin the peer from a channel.
  peer node rebuild-dbs     # Rebuilds databases.
  peer node upgrade-dbs     # Upgrades databases.
```

节点重置会将 peer 节点中的所有通道重置为创世块，即通道中的第一个区块。 重置命令还会记录文件系统中
每个通道重置前的高度。 在 peer 节点执行重置后启动时，peer 节点将为每个通道获取因重置命令而移除的
区块，从其他 peer 节点或排序节点获取，并提交这些区块直到重置前的高度。所有通道达到重置前的高度之前，
peer 节点不会背书任何交易。

从指定的区块号回滚通道时，节点必须是离线的。当节点在回滚之后启动时，它将会从排序节点或者其他 Peer 
节点获取回滚过程中删除的区块，并重建区块存储和状态数据库。

以开发者模式启动 Peer 节点。一般来说链码容器由 Peer 节点启动和维护。但是在链码的开发者模式下，
链码通过用户来编译和启动，这个模式在链码开发阶段很有帮助。


命令参考文档：

- fabric\docs\source\command_ref.rst
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/peercommand.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/peerchaincode.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/peerlifecycle.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/peerchannel.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/peersnapshot.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/peerversion.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/peernode.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/osnadminchannel.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/configtxgen.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/configtxlator.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/cryptogen.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/ledgerutil.html
- https://hyperledger-fabric.readthedocs.io/en/latest/discovery-cli.html
- https://hyperledger-fabric.readthedocs.io/en/latest/commands/fabric-ca-commands.html



节点 Node 是 Fabric 网络中的实体，根据功能差异分为多种节点类型：

- CA 证书服务节点，可选，为 Fabric 网络成员提供数字证书身份证。
- peer 对端节点，布署链码实现对区块链的操作。
- orderer 排序节点对交易进行排序，批量打包，生成区块发给 Peer 节点。
- 客户端节点，最终用户与 Fabric 网络交互，实现对区块链的操作。

- **Endorser Peer** 背书节点对客户端发送交易提案时进行签名背书。
- **Leader Peer** 主节点负责与排序节点通信，获取区块及在本组织进行同步。主节点的产生可以动态选举或者指定。
- **Committer Peer** 记账节点对区块及区块交易进行验证，验证通过后将区块写入账本中。
- **Anchor Peer** 锚节点主要负责与其他组织的锚节点进行通信。

背书(Endorsement)是指特定 Peer 节点执行交易，并向生成交易提案的客户端应用程序返回 YES/NO 响应
的过程。背书节点是动态的角色在链码实例化时设置背书策略(Endorsement policy)，指定哪些节点对交易
背书才有效。只有在背书时是背书节点，其他时刻是普通节点。背书策略和 Channel 两个概念的引入，使得
Hyperledger Fabric 区别于其它区块链应用，如 Ethereum or Bitcoin。


在最基本的层面上，背书策略，是一组定义如何做出决策和取得具体成果的结构规则。为此，策略通常描述
**谁**和**什么**。例如个人对**资产**的访问或权利。我们可以看到，政策在我们的日常生活中被用来保护
对我们有价值的资产，包括汽车租赁、健康、住房等等。

例如，保险单定义了保险支付的条件、条款、限额和到期日。保单由投保人和保险公司同意，并规定了各方的权利
和责任。


Fabric 当前有两种策略：

1. **SignaturePolicy**: This policy type is the most powerful, and
   specifies the policy as a combination of evaluation rules for MSP
   Principals. It supports arbitrary combinations of *AND*, *OR*, and
   *NOutOf*, allowing the construction of extremely powerful rules like:
   "An admin of org A and 2 other admins, or 11 of 20 org admins".
2. **ImplicitMetaPolicy**: This policy type is less flexible than
   SignaturePolicy, and is only valid in the context of configuration.
   It aggregates the result of evaluating policies deeper in the
   configuration hierarchy, which are ultimately defined by
   SignaturePolicies. It supports good default rules like "A majority of
   the organization admin policies".

Peer 节点上部署 chaincode，它对账本进行读写操作。Peer 节点可以充当多种角色，如背书者 endorser，
提交者 committer。

一个 Fabric 区块链网络中可以有一个或多个 Peer 节点，以及一个或多个 Orderer 节点。

Orderer 排序节点们共同提供排序服务，排序服务以插件形式实现可插拔式共识。目前，已经提供多种共识选择，
从一个中心化的服务，Solo，用于开发和测试，到分布式协议，如 Kafka。


Fabric 引入了通道概念，一般情况下，一个 Fabric 区块链网路的子链结构为“1个通道+ 1个账本+ N个成员”。
创建通道是为了限制信息传播的范围，和某一个账本关联，每个交易都和唯一的通道关联。这会明确地定义哪些实体，
组织及其成员，会关注这个交易。

设想一个标准的资产交换中的交易机制，该场景包含两个客户端 A 和 B，分别代表萝卜的买卖双方。他们在
Fabric 网络上通过 peerA 和 peerB 节点来发送交易和与账本交互。

- [Fabric 交易流程](https://hyperledger-fabric.readthedocs.io/zh_CN/latest/txflow.html)
- [商业票据 - 流程和数据设计](https://hyperledger-fabric.readthedocs.io/zh_CN/latest/developapps/architecture.html)

假设该流程中：

- Fabric 网络已经设置了一个通道，并且该通道正常运行。
- 应用程序的用户已经使用组织的 CA 注册和登记完成，并且拿到了用于在网络中用确认身份的加密材料。
- 链码中的逻辑定义了萝卜的交易和定价规则，并且设置一个背书策略：每一笔交易都必须被 peerA 和 peerB 都签名。
- 链码（包含了萝卜商店初始状态的键值对）已经安装在 Peer 节点上并在通道上完成了实例化。

那么，当 A 客户发起一笔交易时，将按以下逻辑执行：

1. A 客户发起交易 **Client A initiates a transaction**
2. 验证签名并执行交易 **Endorsing peers verify signature & execute the transaction**
3. 检查提案响应 **Proposal responses are inspected**
4. 封装背书结果 **Target peer assembles endorsements into a transaction**
5. 确认有效交易 **Transaction is validated and committed**
6. 更新分布式账本  **Ledger updated**


![Fabric 交易流程泳道图](https://hyperledger-fabric.readthedocs.io/en/release-1.4/_images/flow-4.png)
<!-- fabric\docs\source\images\flow-4.png -->

Fabric 交易流程图如图所示，复述以上交易过程如下：

- A 客户端发起交易，SDK 构建交易提案（proposal）并发送给一个或多个背书节点。

- 背书节点模拟执行交易及签名。

    背书节点（endorser）收到交易提案后，验证签名并确定提交者是否有权执行操作。背书节点将交易提案
    的参数作为输入，在当前状态 Key-Value 数据库上执行交易，生成包含执行返回值、读操作集和写操作集
    的交易结果（此时不会更新账本）。交易结果集、背书节点的签名和背书结果（支持/拒绝）作为提案的结果
    返回给客户端。

    读写集：
    对于交易 k 读取的每个密钥，将对 (k,s(k).version) 添加到 readset。
    对于交易 k 修改为新值的每个键 v'，(k,v') 都会添加对 writeset。
    请注意，背书在此步骤中不会更改其状态，由交易模拟生成的更新不会影响状态！

- 客户端把交易发送到排序服务节点。

    客户端收到背书（Endorser）节点返回的信息后，判断提案结果是否一致，以及是否参照指定的背书策略
    执行，如果没有足够的背书，则中止处理；否则，A 客户端把数据打包到一起组成一个交易并签名，发送给
    Orderers。

- 排序节点进行共识排序，生成新区块，并发送给记账节点 (Committer) 节点确认交易。

    Orderers 对接收到的交易进行共识排序，然后按照区块生成策略，将一批交易打包到一起，生成新的区块，
    发送给记账节点验证生成区块中的每笔交易，检查交易依赖的输入输出是否符合当前区块链的状态，完成后
    将区块追加到本地的区块链，并修改世界状态。



## 👉 Fabric SDKs
- [Fabric SDKs](https://wiki.hyperledger.org/display/fabric/Hyperledger+Fabric+SDKs)
- [Fabric Node SDK 文档](https://hyperledger.github.io/fabric-sdk-node/)
- [Fabric Java SDK 文档](https://hyperledger.github.io/fabric-gateway-java/)
- [Fabric Client SDK for Go](https://github.com/hyperledger/fabric-sdk-go)
- [Fabric SDK Node.js](https://github.com/hyperledger/fabric-sdk-node)
- [Fabric SDK Java](https://github.com/hyperledger/fabric-gateway-java)
- [Fabric SDK Py](https://github.com/hyperledger/fabric-sdk-py)



# 🚩 ZooKeeper 分布式服务协调器
- https://zookeeper.apache.org/doc/r3.5.5/zookeeperOver.html

在微服务横行的当下，分布式算法也被大量应用于各种工具中，如 Java 平台中的 Spring Cloud 微服务
工具包中的各种工具。

其中 ZooKeeper 是一个开放源码的分布式应用程序协调服务，其本身提供中心化的服务，是 Google Chubby
分布式的文件系统的一个开源实现，是 Hadoop 和 Hbase 的重要组件。它是一个为分布式应用提供一致性
服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。

    ZooKeeper: A Distributed Coordination Service for Distributed Applications

Paxos 算法存在活锁的问题，即当有多个 proposer 交错提交时，有可能互相排斥导致没有一个 proposer
能提交成功。

而 ZooKeeper 以 Fast Paxos 算法为基础，它做了一些优化，通过选举产生一个 leader，只有它才能
提交 proposer，具体算法可见 Fast Paxos。

Zookeeper 中的角色：

- 领导者 leader：负责进行投票的发起和决议，更新系统状态。
- 跟随者 follower：用于接收客户端请求并给客户端返回结果，在选主过程中进行投票。
- 观察者 observer：可以接受客户端连接，将写请求转发给 leader，但是 observer 不参加投票的过程，
  只是为了扩展系统，提高读取的速度。

Zookeeper设计目的

- `最终一致性`：不论 Client 连接到哪个 Server，展示给它都是同一个视图，这是最重要的性能。 
- `可靠性`：具有简单、健壮、良好的性能，如果消息被到一台服务器接受，那么它将被所有的服务器接受。 
- `实时性`：保证客户端在一个间隔内获得服务器的更新、失效的信息，如果需要最新数据，应该在读数据之前调用 `sync()` 接口。
- `等待无关` wait-free：慢的或者失效的 Client 请求不得干预快速的请求，使得每个 Client 都能有效的等待。 
- `原子性`：更新只能成功或者失败，没有中间状态。 
- `顺序性`：指如果在一台服务器上消息 a 在消息 b 前发布，则在所有 Server 上消息 a 都在消息 b 前被发布。

Follower 角色主要有四个功能： 

- 向 Leader 发送消息，PING、REQUEST、ACK、REVALIDATE；
- 接收 Leader 消息并进行处理；
- 接收 Client 的请求，如果为写请求，发送给 Leader 进行投票；
- 返回 Client 结果。 


Follower 的消息循环处理如下几种来自 Leader 的消息： 

- `PING`： 心跳消息；
- `PROPOSAL`：Leader 发起的提案，要求 Follower 投票；
- `COMMIT`：服务器端最新一次提案的信息；
- `UPTODATE`：表明同步完成；
- `REVALIDATE`：根据 Leader 的 REVALIDATE 结果决定关闭待重新生效的 session 还是允许其接受消息；
- `SYNC`：返回 SYNC 结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。



# 🚩 Apache Kafka 消息系统
- [Apache Kafka](https://kafka.apache.org)
- [Kafka 简介](https://www.cnblogs.com/qingyunzong/p/9004509.html)
- [Kafka 入门一篇](https://zhuanlan.zhihu.com/p/74063251)
- [Kafka 背景及架构介绍](https://www.infoq.cn/article/kafka-analysis-part-1)
- [Kafka是怎么做到那么快？怎样高效读写数据？](https://juejin.cn/post/6974256806654640135)
- [再过半小时，你就能明白kafka的工作原理了](https://zhuanlan.zhihu.com/p/68052232)


Kafka 最初由 Linkedin 公司开发，是一个分布式、分区的、多副本的、多订阅者，基于 zookeeper 协调的
分布式日志系统，常见可以用于 web/nginx 日志、访问日志，消息服务等等。Linkedin 于 2010 年将其
贡献给了 Apache 基金会，并成为顶级开源项目。许多公司将它作为多种类型的数据管道和消息系统使用。

Kafka 是一种分布式的，基于发布 / 订阅的消息系统。主要设计目标如下：

01. 消息持久化实现时间复杂度为 O(1)，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。
02. 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。
03. 支持服务器间消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。
04. 同时支持离线数据处理和实时数据处理。
05. Scale out：支持在线水平扩展。

Kafka 读取特定消息的时间复杂度为 O(1)，即与文件大小无关，Kafka 为什么这么快，理由如下：

01. Partition 并行处理。
02. 顺序写磁盘，充分利用磁盘特性。
03. 利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率。
04. 采用了零拷贝技术。
05. 消息生产者持久化数据到 broker，采用 mmap 文件映射，实现顺序的快速写入。
06. 消息消费者从 broker 读取数据，采用 sendfile 读取到 OS 内核缓冲区，NIO buffer 进行网络发送，减少 CPU 消耗。

由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于
Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的
不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。

任何发布到 Partition 的消息都会被追加到 Partition 数据文件的尾部，这样的顺序写磁盘操作让 Kafka
的效率非常高。经验证，顺序写磁盘效率比随机写内存还要高，这是 Kafka 高吞吐率的一个很重要的保证。

Kafka 基础概念：

- 概念一：客户端有两种基本类型：生产者（Producer）和消费者（Consumer）。
- 概念二：主题（Topic）与分区（Partition）
- 概念三：Broker 和集群（Cluster）
- 概念四：多集群

作为一个消息系统，消息的生成和消费是两种基本行为，生产者（发布者）创建消息，而消费者（订阅者）负责
消费 or 读取消息。此外还有用来做数据集成的 Kafka Connect API 和流式处理的 Kafka Streams 等
高阶客户端，但这些高阶客户端底层仍然是生产者和消费者 API，它们只不过是在上层做了封装。

消息以主题（Topic）来分类，每一个主题都对应一个「消息队列」，这有点儿类似于数据库中的表。如果把所有
同类的消息都塞入到一个“中心”队列中，势必缺少可伸缩性，无论是生产者/消费者数目的增加，还是消息数量
的增加，都可能耗尽系统的性能或存储。

一个 Kafka 服务器也称为 Broker，它接受生产者发送的消息并存入磁盘；Broker 同时服务消费者拉取
分区消息的请求，返回目前已经提交的消息。使用特定的机器硬件，一个 Broker 每秒可以处理成千上万的
分区和百万量级的消息。

若干个 Broker 组成一个集群（Cluster），其中某一个会成为集群控制器（Cluster Controller），
它负责管理集群，包括分配分区到 Broker、监控 Broker 故障等。集群内，一个分区由一个 Broker 负责，
这个 Broker 也称为这个分区的 Leader；当然一个分区可以被复制到多个 Broker 上来实现冗余，当存在
Broker 故障时可以将其分区重新分配到其他 Broker 来负责。

随着业务发展，我们往往需要多集群，通常处于下面几个原因：

01. 基于数据的隔离；
02. 基于安全的隔离；
03. 多数据中心（容灾）

当构建多个数据中心时，往往需要实现消息互通。举个例子，假如用户修改了个人资料，那么后续的请求无论被
哪个数据中心处理，这个更新需要反映出来。又或者，多个数据中心的数据需要汇总到一个总控中心来做数据分析。

上面说的分区复制冗余机制只适用于同一个 Kafka 集群内部，对于多个 Kafka 集群消息同步可以使用 Kafka
提供的 MirrorMaker 工具。本质上来说，MirrorMaker 只是一个 Kafka 消费者和生产者，并使用一个
队列连接起来而已。它从一个集群中消费消息，然后往另一个集群生产消息。




# 🚩 Docker 虚拟化部署
- [Linux 容器化技术前世今生: 虚拟化、容器化、Docker](https://juejin.cn/post/6844904160651902984)
- [Docker 基础知识](https://juejin.im/post/5d4522c1f265da03e05af5f5)
- [The Convergence of DevOps](https://itrevolution.com/articles/the-convergence-of-devops/)
- [Docker architecture](https://docs.docker.com/get-started/overview/)

虚拟化技术中，有两个适用于现代网络的框架：虚拟机和容器，Virtual Machines vs. Continers。
两者相通不互斥，都便于将一个物理设备的内容移动到另一个物理设备。在容器技术流行之前，虚拟机就是虚拟
技术的代表，主要有 VMWare 和 OpenStack。

虚拟机的应用程序、存储箱和库，以及客户操作系统为其提供了硬件级别的虚拟化，虚拟机占用 GB 级别的内存。

容器的关键区别和优势在于它们的大小，或者说没有大小，又或者说可以很小很轻便。相比虚拟机，容器通常只
包含一个应用程序，并且占用的空间 MB 为单位。

没有计算虚拟化技术的年代，部署一个应用程序非常麻烦，传统的物理服务器部署应用缺点如下：

01. 部署非常慢：先准备硬件服务器，安装操作系统，再部署应用程序，以及处理应用程序依赖。
02. 成本非常高：主要是物理器成本太高，即使是部署一个简单的应用，也需要一台服务器。
03. 资源浪费：如果应用太简单，也容易浪费硬件资源，比如 CPU 和内存。
04. 迁移和扩展太慢：如果需要迁移应用，或者扩展应用，都要再准备其他的物理服务器，过程很麻烦且慢。

虚拟机是重量级单元，其重要吸引力在于 DevOps 中的应用，所以在不同平台之间存储和迁移应用程序的能力
至关重要。填补这一空白的是虚拟化的轻量级虚拟化技术：容器。

单个物理设备可以通过虚拟机管理程序包含多个隔离的虚拟环境，其优势包括降低开销、方便移动性和可扩展性。
容器化是解决传统虚拟化带来的障碍的解决方案，容器技术的引入，使得虚拟机(VM)能够做到事半功倍。

Docker 解决以上罗列的这些问题的虚拟化技术，Docker 是码头工人的意思，本身是软件容器平台。容器和
虚拟机一样，都拥有环境隔离的能力，但它比虚拟机更加轻量级，可以使资源更大化地得到应用。容器英文单词
container 也有另外的一个意思就是“集装箱”。

Docker 容器虚拟化是指操作系统而不是硬件，容器之间共享同一套操作系统资源，但是相比于虚拟机，容器的
隔离级别会稍微低一些。从使用者的角度看，容器就是虚拟化的操作系统。


DevOps 是一个完整的面向 IT 运维的工作流，以 IT 自动化以及持续集成（CI）、持续部署（CD）为基础，
来优化程式开发、测试、系统运维等所有环节。

微服务体系结构允许软件开发人员生成由几个独立的可部署服务组成的应用程序。而容器技术非常适合这种构架，
容器中托管的应用程序的不同组件是可伸缩的，并且可以在不中断其他服务的情况下进行更新。还可以搭配容器
编排平台可实现自动化管理，如 Kubernetes (K8S)。

K8S 是基于容器的集群管理平台，一套管理系统，可以对 Docker 及容器进行更高级更灵活的管理。

Docker 的使用流程就是 “Build, Ship and Run”，也就是，“搭建、发送、运行”，三板斧。
Docker 第二句口号就是：“Build once，Run anywhere”。

Docker技术的三大核心概念，分别是：

- 镜像（Image）包含容器运行时所需的程序、库、资源、配置，以及运行时配置参数，镜像内容只读。
- 容器（Container）容器是镜像运行时的实体，可以对容器进行创建、启动、停止、删除、暂停等操作。
- 仓库（Repository）是集中存储和分发镜像的服务。

![Docker architecture](https://docs.docker.com/engine/images/architecture.svg)

Docker 使用 Golang 语言开发，技术核心是 Linux 内核的 Namespace、Cgroup 和 AUFS 等文件系统。
Docker 通过这些底层的技术，对进程进行封装隔离，而被隔离的进程也称为容器，完全独立于宿主机的进程。

Namespace 作为 Linux 内核的组成部分大约出现于 2002 年，随着时间的推移，Linux 内核添加了更多的
工具和 namespace 类型。然而，直到 2013 年，Linux 内核才添加了真正的容器支持。

命名空间是许多编程语言使用的一种代码组织的形式，通过命名空间来分类，区别不同的代码功能，避免不同的
代码片段，通常由不同的人协同工作或调用已有的代码片段，同时使用时由于不同代码间变量名相同而造成冲突。

Linux 内核引入 Namespace 概念做封装抽象，限制，隔离，使得命名空间内的进程拥有自己的全局资源。

Linux 内核中实现的 6 种 Namespace：

| Namespaces |   Kernel  |                      Isolates                     |
|------------|-----------|---------------------------------------------------|
| Mount      | 2.4       | 隔离文件系统挂载点                                |
| IPC        | 2.6       | 隔离 System V IPC 和 POSIX 消息队列               |
| Network    | 2.6       | 隔离网络资源 Network devices, stacks, ports, etc. |
| PID        | 2.6       | 隔离进程ID                                        |
| Time       | -         | Boot and monotonic clocks                         |
| UTS        | 2.6       | 隔离主机名和域名 Hostname and NIS domain name     |
| User       | 2.6 - 3.8 | 隔离用户和用户组                                  |
| Cgroup     | 4.6       | Cgroup root directory 管理资源的分配、限制        |


Linux manual page

- https://man7.org/linux/man-pages/man7/namespaces.7.html
- https://man7.org/linux/man-pages/man7/mount_namespaces.7.html
- https://man7.org/linux/man-pages/man7/ipc_namespaces.7.html
- https://man7.org/linux/man-pages/man7/network_namespaces.7.html
- https://man7.org/linux/man-pages/man7/pid_namespaces.7.html
- https://man7.org/linux/man-pages/man7/time_namespaces.7.html
- https://man7.org/linux/man-pages/man7/uts_namespaces.7.html
- https://man7.org/linux/man-pages/man7/user_namespaces.7.html
- https://man7.org/linux/man-pages/man7/cgroup_namespaces.7.html
- https://man7.org/linux/man-pages/man7/cgroups.7.html

Linux 早期的版本中就实现了部分的 namespace，随着 Linux 自身的发展以及容器技术持续发展带来的需求，
会有新的 namespace 支持，比如在内核 4.6 中就添加了 Cgroup namespace。

Control groups (Cgroup) 内核功能用来限制、控制与分离进程组的资源，如 CPU、内存、磁盘 I/O 等。
它由 Google 两位工程师开发，自 2008 年 1 月正式发布的 Linux 内核 v2.6.24 开始提供此能力。


AUFS 是一种 Union File System，就是把不同物理位置的目录合并 mount 到同一个目录中。比如，一张
CD/DVD 和一个硬盘目录联合 mount 在一起，然后就可以对存于硬盘上的目录里的文件进行读写。

AUFS 几度改名，但还是没有并入 Linux 内核，从开始的 Another UnionFS，Alternative UnionFS，
最后直接改为 Advance UnionFS。它是对 Linux 原生 UnionFS 的重写和改进。但是，可以在 Ubuntu 和
Debian 这些发行版上使用它。

AUFS 在使用上全兼容 UnionFS，而且在稳定性和性能上都要好很多，后来 UnionFS 2.x 开始抄其功能。
但是没有将它并入 Linux 主干，因为 Linus 不让，基本上是因为代码量比较多，而且写得烂。相对于只有
3000 行的 union mount 和 10000 行的 UnionFS，以及其它平均下来只有 6000 行代码左右的 VFS，
AUFS 居然有 30000 行代码。所以，岡島不断地改进代码质量，不断地提交，不断地被 Linus 拒绝。

历史上，有一个 Linux 发行版叫 Knoppix，主要用于 Linux 光盘教学、系统急救，以及商业产品的演示，
不需要硬盘安装，直接在一个可写的存储设备上运行 CD/DVD 上的映像，比如 U 盘，就可以提供读写能力。
其实，也就是把 CD/DVD 这个文件系统和 USB 这个可写的系统给联合 mount 起来，对 CD/DVD 映像做
任何改动都会在被应用在 U 盘上。于是乎，就像可以对 CD/DVD 上的内容进行任意的修改。

我们可以再发挥一下想像力，你也可以把一个目录，比如你的源代码，作为一个只读的template，和另一个你的working directory给union在一起，然后你就可以做各种修改而不用害怕会把源代码改坏了。有点像一个ad hoc snapshot。

Docker 对 UnionFS 的想像力发挥到了容器的镜像文件，用 UnionFS 这样的技术做出分层的镜像来。其中
Container Layer 可读取，Image Layer 只读。

Docker 官方文档中展示了用 UnionFS 搭建的分层镜像结构。
[Storage drivers versus Docker volumes](https://docs.docker.com/storage/storagedriver/)

![Container Image Layers](https://docs.docker.com/storage/storagedriver/images/container-layers.jpg)

Docker 使用存储驱动程序来存储图像层，并将数据存储在容器的可写层中。删除容器后，可写层不会持久化，
但适合存储运行时生成的临时数据。存储驱动程序针对空间效率进行了优化，但写入速度低于本机文件系统性能，
特别是对于使用写时复制文件系统的存储驱动程序。写密集型应用程序（如数据库存储）会受到性能开销的影响，
特别是在只读层中存在预先存在的数据时。

Docker Volume 用于写入密集型数据、必须在容器生命周期之外保存的数据以及必须在容器之间共享的数据。
卷是保存 Docker 容器生成和使用的数据的首选机制。

Windows 10 目前已经通过 WSL 子系统支持 Linux 环境，Docker Desktop 也自带了 WSL 2 运行环境。
在支持 WSL 2 的系统上，只要安装 Docker Desktop for Windows，就会默认启用。用户也可以修改配置
选项 Use WSL 2 based engine。

- [Docker Desktop WSL 2 backend on Windows](https://docs.docker.com/desktop/windows/wsl/)
- [Using Docker in WSL 2](https://code.visualstudio.com/blogs/2020/03/02/docker-in-wsl2)
- [Using Dev Containers in WSL 2](https://code.visualstudio.com/blogs/2020/07/01/containers-wsl)

WSL 2 为 Windows 提供了对 Linux 发行版的支持，其中每个发行版的行为都像一个 VM，只是它们都运行
在一个共享的 Linux 内核之上。通过修改配置，Resources - WSL Integration，可以将 Docker 环境
集成到 Windows 系统自带的 WSL。使用 wsl 命令可以查询当前系统已安装 WSL 映像：

```sh
> wsl -l -v
  NAME                   STATE           VERSION
* Ubuntu-20.04           Running         2
  docker-desktop         Running         2
  docker-desktop-data    Running         2
> wsl -d docker-desktop

> uname -a
Linux DESKTOP-CBSK60R 5.10.102.1-microsoft-standard-WSL2 #1 SMP Wed Mar 2 00:30:59 UTC 2022 x86_64 Linux

> whereis wsl-bootstrap
wsl-bootstrap: /usr/local/bin/wsl-bootstrap

> ps all | grep docker
   18 root      0:07 wsl-bootstrap run --base-image /mnt/host/c/Docker/resources/wsl/docker-for-wsl.iso --cli-iso /mnt/host/c/Docker/resources/wsl/docker-wsl-cli.iso
  757 root      0:00 /usr/bin/containerd-shim-runc-v2 -namespace services.linuxkit -id docker -address /run/containerd/containerd.sock
  783 root      0:00 /usr/bin/docker-init /usr/bin/entrypoint.sh
 1281 root      0:00 /usr/bin/trim-after-delete -- /sbin/fstrim /var/lib/docker
 1334 root      0:00 /usr/bin/logwrite -n dockerd /usr/local/bin/dockerd --containerd /var/run/desktop-containerd/containerd.sock --pidfile /run/desktop/docker.pid --swarm-default-advertise-addr=eth0 --host-gateway-ip 192.168.65.2
 1339 root      0:04 /usr/local/bin/dockerd --containerd /var/run/desktop-containerd/containerd.sock --pidfile /run/desktop/docker.pid --swarm-default-advertise-addr=eth0 --host-gateway-ip 192.168.65.2
```

安装 Docker 后并运行服务进程，执行以下命令开始布置、运行一个用于学习的教程项目：

```sh
    # sudo dockerd
    # https://github.com/docker/getting-started
    docker run -d -p 80:80 docker/getting-started
    docker run -dp 80:80 docker/getting-started
```

此命令运行一个叫做 getting-started 的映像，参数说明如下，在浏览器打开 localhost:80 就可以
看到教程内容。Docker 检测到映像未安装时，会自动从仓库中拉取映像文件并创建容器运行它：

- `-d` - run the container in detached mode (in the background)
- `-p` 80:80 - map port 80 of the host to port 80 in the container
- `docker/getting-started` - the image to use

如果安装了 Docker Desktop 图形化管理工具，Docker Dashboard 中可以看到映像和容器以及卷的信息。

- [Docker Desktop Manual](https://docs.docker.com/desktop/)
- [Explore Images](https://docs.docker.com/desktop/use-desktop/images/)
- [Explore Volumes](https://docs.docker.com/desktop/use-desktop/volumes/)
- [How is a vulnerability's severity determined?](https://support.snyk.io/hc/en-us/articles/360001040078)

Images 视图显示 Docker 映像列表，允许将映像文件运行在容器中，Docker Hub 上可以获取最新版本的
映像，并对图像进行检查。还显示了使用 Snyk 依赖性安全漏洞扫描工具提供的报告摘要。

映像视图下显示的详细信息包括：

01. Image history
02. Image ID
03. Date the image was created
04. Size of the image
05. Layers making up the image
06. Base images used
07. Vulnerabilities found
08. Packages inside the image

其中比较重要的内容有，Image Hierarchy、Layers 和 Vulnerabilities，通过它们可以大概了解一个
映像文件的依赖层次结构以及安全性问题。

映像文件可能依赖一个或多个映像，罗列在 Image Hierarchy 层次结构下。这意味着映像的作者在构建时
使用另一个映像作为起点。通常，这些基本映像要么是 Debian、Ubuntu 和 Alpine 等操作系统映像，要么
是 PHP、Python 和 Java 等编程语言映像。选择 ALL 行将重新选择整个图像的所有图层和基础图像。右侧
Packages 显示了映像所依赖的软件包。

安全问题通过一个带有感叹号的红色盾牌表示，右侧 Vulnerabilities 罗列了当前映像所包含的安全性问题，
按包分组，根据级别高低划分为 Critical、High、Medium、Low，分别简写为 C、H、M、L。

| Severity | CVSS v3 Rating |
|----------|----------------|
| Critical | 9.0 - 10.0     |
| High     | 7.0 - 8.9      |
| Medium   | 4.0 - 6.9      |
| Low      | 0.1 - 3.9      |

一个或多个基本映像可能有可用的更新，其中可能包括更新的安全修补程序，以消除映像中的漏洞。任何具有可用
更新的基础图像都会在图像层次结构的右侧显示。

Docker 映像由层组成，映像层从上到下列出，最早的层在顶部，最新的层在底部。通常，底部的是映像作者
通过 Dockerfile 命令添加的层。要查看哪些层源自基础映像，只需在“映像”层次结构下选择一个基础映像，
相关层将高亮显示。



## 👉 Go Docker 部署示例
- [Alpine 系统入门教程](https://www.cnblogs.com/yeqing112/p/10773500.html)
- [Containerize an application](https://docs.docker.com/get-started/02_our_app/)
- [Docker CLI (docker)](https://docs.docker.com/engine/reference/commandline/container_ls/)
- [Format command and log output](https://docs.docker.com/config/formatting/)

编写一个 Go Web 测试程序：

```js
    package main

    import (
        "net/http"
        "fmt"
        "log"
        "os"
    )

    func main () {
        http.HandleFunc("/", func(writer http.ResponseWriter, request *http.Request) {
            fmt.Fprint(writer, "Hello World")
        })
        http.HandleFunc("/bye", func(writer http.ResponseWriter, request *http.Request) {
            defer writer.(http.Flusher).Flush()
            fmt.Fprint(writer, "See you then")
            os.Exit(0)
        })
        log.Fatal(http.ListenAndServe(":8080", nil))
    }
```

Go Build 注意事项，编译应用的时候记得带上参数，否则使用 alpine 镜像在部署时动态编译会出现Bug。

    CGO_ENABLED=0 go build -o main

Alpine 操作系统镜像是 Docker 官方系统镜像，这是一个面向安全的轻型 Linux 发行版。目前 Docker
官方已开始推荐使用 Alpine 替代之前的 Ubuntu 做为基础镜像环境。这样会带来多个好处。包括镜像下载
速度加快，镜像安全性提高，主机之间的切换更方便，占用更少磁盘空间等。

Alpine 的特点：

01. 小巧：基于 Musl libc 和 busybox，最小的镜像只有 5MB，Ubuntu 镜像则有 88.9MB；
02. 安全：面向安全的轻量发行版；
03. 简单：提供 APK 包管理工具，软件的搜索、安装、删除、升级都非常方便。
04. 适合容器使用：由于小巧、功能完备，非常适合作为容器的基础镜像。

使用一个映射前，需要从 Docker 仓库中拉取到本地，参考以下命令：

```sh
    # List images or containers
    docker image ls
    docker images
    docker container ls
    docker ps --all
    docker ps --all --format "{{json .}}"
    docker ps --all --format "table {{.ID}}\t{{.Command}}\t{{.Names}}\t{{.Image}}\t{{.Status}}"

    docker pull alpine
    docker run -it --name myalpine alpine
    docker run --name myalpine alpine
    docker stop    myalpine
    docker restart myalpine
    docker exec    myalpine ls
    docker rm      myalpine
```

有两条命令查询当前的容器列表，可以在 ls 后面指定 --all 参数以相询包括不在运行状态的容器。
其中 run 命令的 -it 参数表示执行一个具有 TTY 交互的容器，方便用户执行容器内的命令，也可以使用
exec 执行正在运行的容器内的命令。


编写 Dockerfile 配置文件：

```sh
    FROM alpine:latest
    # FROM centos:latest

    MAINTAINER Abc <abc@gmail.com>
    LABEL Description="This is the golang development base on centOS"

    WORKDIR /

    ADD main /

    EXPOSE 3000

    ENTRYPOINT ["./main"]

    #Reconfig timezone
    #RUN echo "Asia/Shanghai" > /etc/timezone

    #env
    ENV PATH /usr/local/go/bin:$PATH 
    ENV GOROOT /usr/local/go
    ENV GOPATH /home/go

    # install golang
    ADD install_go.sh /
    RUN chmod +x /install_go.sh \
        &&  /install_go.sh \
        &&  echo "Asia/Shanghai" > /etc/timezone
```

- FROM 指定要依赖的映射，可以是 alpine，也可以是 Centos 等等 Linux；
- 设置工作路径
- 把上文编译好的main文件添加到镜像里
- 暴露容器内部端口
- ENTRYPOINT 配置入口程序，

配套的 Go 安装脚本 install_go.sh 文件参考如下：

```sh
    #/bin/bash

    # install wget
    yum -y install wget

    mkdir /home/go

    # Download & install Golang
    wget https://dl.google.com/go/go1.10.1.linux-amd64.tar.gz
    tar -C /usr/local -zxf go1.10.1.linux-amd64.tar.gz

    # Set GOROOT & GOPATH
    echo export GOROOT=/usr/local/go >> /etc/profile
    echo export GOPATH=/home/go >> /etc/profile

    echo "export PATH=$PATH:/usr/local/go/bin" >> /etc/profile

    rm -f go1.10.1.linux-amd64.tar.gz

    # Test Golang installation
    go version
```

以下 docker 命令按当前目录下的 Dockerfile 配置构建镜像，-t 参数标记应用的镜像标签名：

    docker build -t myapp:v1 .

构建完成后就可以在本地容器列表找到，然后运行容器，将本地端口映射到容器映像端口：

    docker run --rm -it -d -p 3000:8080 myapp
    docker run myapp:v1

本机打开 localhost:3000 端口进行访问和测试。



# 🚩 ArcBlock 开发者指南
- ABT 区块基石行情 https://www.feixiaohao.com/currencies/arcblock/
- ArcBlock Platform https://www.arcblock.io/zh/platform
- ABT Node Overview https://docs.arcblock.io/en/abtnode/introduction/abtnode-overview
- ABT 开发者指南 https://docs.arcblock.io/abtnode/zh/developer
- ABT 节点技术预览版入门 https://www.arcblock.io/blog/zh/post/2020/05/19/abt-node-technical-preview-introduction
- ArcBlock WhitePaper https://www.arcblock.io/zh/whitepaper/
- MIT Silvio Micali 教授提出可扩展的新共识算法 Algorand https://www.8btc.com/article/121880
- Gitpod 浏览器扩展 https://github.com/gitpod-io/gitpod
- 区块链核心概念 https://docs.arcblockio.cn/forgecli/zh/5-manipulate-wallets-accounts
- 普林斯顿大学开设的公开课 Bitcoin and Cryptocurrency Technologies https://www.coursera.org/learn/cryptocurrency

名字解析：

- ABT Node：去中心化应用的容器，为各种应用提供标准的运行环境、管理功能、常见用户功能的封装
- Blocklet：可以安装到节点、解决某类实际业务问题的软件包，可以是小游戏、WEB 应用、小工具
- DApp 去中心化应用，分布式应用，本质就是使用分布算法的应用程序。
- ArcBlock 去中心开发环境，包括区块链开发框架、运行时和 Blocklet `基石程序`生态，简化 DApp 开发。
- ABT Wallet 数字钱包
- Play Wallet 另一个数字钱包，由 Wallet Playground 示范应用中使用的测试用数据钱包。
- AUSD 测试用的虚拟USD
- LBD 本地区块币
- Block Height 区块高度指在区块链中一个区块和创世区块之间的块数。

本地启动 ABT Node 必要条件，还需要你准备如下内容：

- iOS 或者 Linux 系统；
- Node.js v12.x 及以上版本
- 下载安装和使用 @abtnode/cli，启动节点就是用的它
- 下载并设置好 ABT Wallet

如果没有 ABT 节点怎么办？

直接在 Gitpod 云原生 IDE 中打开部署 ABT Node。Gitpod 服务将启动并为你运行基于 docker 的云开发环境。通过这一部署，自动安装 ABT Node 的开发者版本。但是，这仅用于开发，开发进程结束后，ABT 节点将自动关闭。

https://gitpod.io/#https://github.com/blocklet/react-demo

或者，你可以使用 “Play With Docker” 服务立即免费启动测试 ABT Node。只需要一个 Docker 帐户，该服务将为你提供 3 个小时的免费实例。

Forge SDK 是一套专门为开发者设计的开发组件，是 Forge 框架中不可或缺的一部分。开发者可以通过 Forge SDK 轻松构建区块链和去中心化应用（DApps）。



## 👉 ArcBlock Coding Test

🚩 题目内容

编写 1 个可以部署到 ABT Node 的 Blocklet，需要实现的功能如下：

- 主界面包含输入框，用户输入某个比特币的 `Block Hash` 后能查询并展示对应 Block 中包含的所有 `Transaction`
- 根据 `Block Hash` 拿到 `区块数据`可以使用这个 API，API 介绍见这里
- 把比特币 `Block` 和 `Transaction` 数据渲染成 Bitcoin Explore 显示的样式，只需要包含`区块摘要`和`分页`的`交易列表`即可，网页的 Header 和 Footer 可以忽略
- 项目不要只支持渲染某个特定的 Block，而是可以`任意`输入 `Block Hash` 来查看结果

- rawblock JSON 区块数据 https://blockchain.info/rawblock/00000000000000000007878ec04bb2b2e12317804810f4c26033585b3f81ffaa
- Blockchain Data API https://www.blockchain.com/api/blockchain_api
- Bitcoin Explorer - Block https://www.blockchain.com/btc/block/00000000000000000007878ec04bb2b2e12317804810f4c26033585b3f81ffaa
- Get started with ABT Node  https://www.arcblock.io/en/get-started
- Blocklet 规范 https://github.com/blocklet/blocklet-specification/blob/main/docs/meta.md
- ABT Wallet https://abtwallet.io/zh/

- Kitchen Sink Demo https://github.com/blocklet/kitchen-sink-demo
- Demo - Install on my ABT Node https://github.com/blocklet/react-demo

- Install on ABT Node https://install.arcblock.io/?action=blocklet-install&meta_url=https://github.com/blocklet/react-demo/releases/download/0.1.4/blocklet.json


🚩 其他要求或建议：

- 应该编写测试，并且测试能全部通过
- 应该包含 README.md 来告知面试官项目采用的技术栈，以及如何启动、构建项目，运行测试
- 基本界面和交互外，你可以自由发挥，目标是更好的展示区块链上的数据

🚩 步骤建议

- 先使用你熟悉的框架、工具和库搭建出 Blocklet 骨架并添加基本功能，建议前端使用 create-react-app，后端使用 express.js。
- 启动 ABT Node 本地实例，安装试用官方 Marketplace 里面的 Blocklet，了解 Blocklet 在 ABT Node 里面的运行环境，Blocklet 规范参见文档。
- 参照 React Demo 将你的应用变成 Blocklet，使其能运行在本地的 ABT Node 环境中，`blocklet.yml` 可以用 `blocklet init` 创建。
- 如果你的 Blocklet 不包含后端代码，group 建议选择 static 类型，main 建议选择 create-react-app 默认的 build 目录。


🚩 加分项

如果你能参照 Kitchen Sink Demo 中 CI 的配置，让你的 Blocklet 仓库支持 `Install on ABT Node` 功能（安装之后要能够正常启动、访问），将获得额外加分。




## 👉 ABT Node CLI
- https://docs.arcblock.io/abtnode/zh/developer/abtnode-cli
- https://github.com/ArcBlock/abt-node

安装，初始化并启动 ABT Node 进行配置：

    yarn global add @abtnode/cli
    npm install -g @abtnode/cli

    abtnode init
    abtnode start

使用中遇到权限问题，启动 ABT Node 后，blocklet 也不能顺利安装：

    {
        errno: -13,
        code: 'EACCES',
        syscall: 'rename',
        path: '/home/jeango/.nvm/versions/node/v15.9.0/lib/node_modules/@abtnode/cli',
        dest: '/home/jeango/.nvm/versions/node/v15.9.0/lib/node_modules/@abtnode/.cli-V32Ka8cV'
    }

试以 root 身份运行安装命令。

    sudo npm install -g @abtnode/cli 
    sudo npm install --unsafe-perm=true -g @abtnode/cli
    sudo npm install --unsafe-perm=true --allow-root -g @abtnode/cli

以上安装方式对我的开发环境还是不起作用，系统是 Windows WSL Ubuntu，Node.js v15.9.0。

下面开始源代码补丁模式，修改 `@abtnode\core\lib\blocklet\manager\disk.js` 代码文件 Line 1800，将 fs.move 方法调用改成 fs.copy 方式，总共 2 处：

    async _resolveDownload(cwd, tarFile, originalMeta) {
         ...
        // await fs.move(downloadDir, installDir, { overwrite: true });
        logger.info('🚩======= move: ', {downloadDir, installDir});
        await fs.copy(downloadDir, installDir, { overwrite: true });
        fs.removeSync(downloadDir);
    }

安装完成后，启动 ABT Node，使用你的 ABT 钱包并扫描二维码登录。

    bundle [options]           Bundle a blocklet that can run in ABT Node
    start [options]            Start ABT Node Daemon
    init                       Init ABT Node config
    status                     Show ABT Node and blocklet status
    logs                       Show ABT Node and blocklet logs
    stop|kill [options]        Stop ABT Node and blocklets
    info [options]             Get environment information for debugging and
                               issue reporting
    deploy [options] <folder>  Deploy blocklet from local directory to ABT Node
    blocklet:init              Create an empty blocklet project
    upgrade                    Self-Upgrade ABTNode
    help [command]             display help for command

ABT Node v1.2.0 里面包含了 Breaking Change，安装 @abtnode/cli 后会产生两个全局的命令行工具 `abtnode` 和 `blocklet`，前者用来管理 ABT Node，后者用来操作 Blocklet：

- abtnode deploy 变成了 blocklet deploy
- abtnode bundle 变成了 blocklet bundle
- abtnode blocklet:* 变成了 blocklet *

ABT Node 默认的 Blocklet Registry 变更为 https://booster.registry.arcblock.io 新 Registry 启用了 AWS 的全球 CDN 加速，下载速度会更快。


使用 yarn 安装，请导出 `~/.yarn/bin` 目录以正常使用 abtnode 命令。

修改 `~/.bashrc` `~/.profile` `~/.zshrc` 之一个，以自动查找 nvm 命令：

    export NVM_DIR="$HOME/.yarn/bin"


## 👉 ABT 节点配置文件
- https://docs.arcblock.io/abtnode/zh/developer/configuration

参考配置 `.abtnode.yml` 内容如下：

    node:
      # ABT 节点描述信息
      name: 'ABT Node'
      description: 'Container of official ArcBlock blocklets'

      # ABT 节点 sk, pk, did 属性
      sk: '0x39231d873687551460595848ee9fe32292f9ea44213a995fa5e5e15329e81e0748c6ee9a36c0db6dabd29f64e4e916b030c7060f937008eed0793f2e20845238'
      pk: '0x48c6ee9a36c0db6dabd29f64e4e916b030c7060f937008eed0793f2e20845238'
      did: 'zNKqM4yhZg39gd5KUuVNiDzq6HrwPSK6YFeA'

      # 在哪里存储 ABT 节点数据: 改变这个到你的主文件夹，在 mac 通常:/Users/YOUR_NAME/.abtnode
      dataDir: /home/work/.abtnode

      # ABT 节点控制台访问地址
      domain: 192.168.1.2
      # ABT 节点控制台访问端口
      port: 8089
      https: false
      # ABT 节点控制台 session 秘钥
      secret: 'weilru4j2oi34u*(#U$IORQWRjk'

      # ABT 节点拥有者信息
      owner:
        pk: ''
        did: ''

    blocklet:
      # 指定 Blocklet 监听的端口
      port: 8090
      # 指定从哪获取可用的 Blocklets
      registry: https://blocklet.arcblockio.cn
      owner:
        pk: ''
        did: ''

对于节点密钥和 did 部分，如果你只是测试，使用上面的值配置应该没问题，如果你想定义自己的，你可以生成如下:

    npm install -g @arcblock/forge-cli
    forge wallet:create
    # 依次选择 `ROLE_APPLICATION`, `SHA3`, `ED25519`
    # 复制 `sk`, `pk`, `address` 到 abtnode.yml 中，对应 sk, pk, did


## 👉 Blocklet 规范
- https://github.com/blocklet/blocklet-specification/blob/main/docs/meta.md
- Blocklet 规范 https://docs.arcblock.io/abtnode/zh/developer/blocklet-spec
- ArcBlock Blocklets Public Repo https://github.com/blocklet

Blocklet 是无服务器软件单元，包含已编译的代码以及能够轻松部署应用、组件和库所需的任何依赖项。Blocklet 可以连接到区块链和其他数据源，让用户能够轻松执行链上和链下计算。

Blocklet 是一种应用协议，同时也是一种软件架构。

- 作为一个协议，它描述了构建 ABT 节点平台的方式；
- 作为一个软件架构, 一个独立的 Blocklet 是一个可重用的软件模块，可能是一个 HTTP 服务，也可能是一个函数库等等；

当多个 Blocklet 在一起运行时，需要一个平台将它们组合起来，共同构成一个独立的服务，比如 ABT 节点（ABT Node）。

配置文件 `blocklet.yml` 可以用 `blocklet init` 命令创建：

    name: react-demo
    version: 0.1.4
    homepage: 'https://github.com/blocklet/react-demo'
    files:
      - build
    description: Blocklet from local react-demo
    group: static
    main: build
    author:
      name: ArcBlock
    scripts:
      dev: npm run start
    specVersion: 1.0.1
    did: z8iZvpvLdpfxkvTFdawCF3s5UJdUSkP2NXqPC
    community: ''
    documentation: ''
    license: ''
    interfaces:
      - type: web
        name: publicUrl
        path: /
        prefix: '*'
        port: BLOCKLET_PORT
        protocol: tcp
    environments: []
    screenshots: []
    timeout:
      start: 10

命令交互中需要输入以上部分信息，对于没有后端的应用，可以设置 `group` 为 static 类型，然后 `entry point` 指定静态文件生成的目录，如 `build`。

还有提示 `public interface of the blocklet`，这个设置参考 Blocklet Definition：

|      Field      |      Type     | Required? |       Description       |                Memo                | Status |
|-----------------|---------------|-----------|-------------------------|------------------------------------|--------|
| interfaces      | [Object]      | Yes       |                         |                                    | Final  |
| ~.type          | Enum          | Yes       | 接口类型                | web or service 二选一              | Final  |
| ~.name          | String        | Yes       | 接口名称                | Must be unique within the blocklet | Final  |
| ~.path          | String        | Yes       | 接口路径                | Default to /                       | Final  |
| ~.prefix        | String        | No        | 是否支持动态路径前缀     | 可以是 * 即动态匹配路径或其它字符  | Final  |
| ~.port          | String/Object | No        | blocklet 接口的服务端口  | 字符串值，默认为 BLOCKLET_PORT     | Final  |
| ~.port.internal | Number        | No        | blocklet 接口的服务端口  | 字符串值，指定端口                 | Final  |
| ~.port.external | Number        | No        | blocklet 接口的外部端口  |                                    | Final  |


Blocklet 的基本信息：

- `group` 分为 dapp 和 static 两种类型。dapp 就是常规的 dapp，static 是一中只包含了前端静态资源的 Web 应用，ABT 节点内部会用一个 HTTP Server 来 serve static Blocklet。

定义运行时设置：

- `main` 描述 Blocklet 如何开始运行，即入口文件的描述，指定 dapp 类型的 Blocklet 的入口文件或静态资源目录。
- `requiredEnvironments` 声明 Blocklet 运行时需要的环境变量。有 4 个属性描述 1 个环境变量：name, description, required, default。设置为 required 的变量，并且没有提供默认值时，用户必须在启动前设置该变量。比如，Blocklet 依赖 MongoDB 数据库，就可以要求用户填写 MongoDB 的连接字符串。
- `capabilities` 用来告知 ABT Node 当前 Blocklet 的能力，比如如果你的 Blocklet 不能运行在任意动态的路由前缀下面，可以如下设置：

        "capabilities": {
            "dynamicPathPrefix": false
        }

其他可选配置：

- `provider` 是声明 Blocklet 的来源，可选值有两个：arcblock community 代表 ArcBlock 官方开发的，或者是社区开发的。
- `public_url` 是 Blocklet 可公开访问的地址。
- `admin_url` 是 Blocklet 管理端地址。
- `config_url` 是 Blocklet 配置页面地址。
- `doc_url` 是 Blocklet 的文档地址，如果这个地址不存在，ABT 节点会使用 Blocklet 的 README 作为文档页面。

在 ABT 节点中, Blocklet 完整的生命周期包括四个阶段：

- 安装（或部署）Install or Deploy
- 启动 Start
- 停止 Stop
- 卸载 Uninstall

因为可以通过两种方式来安装 Blocklet, 分别是在市场中下载安装，另外一种是直接在本地用 ABT Node CLI 部署安装，安装目录是 `/.abtnode/blocklets/`。用 CLI 部署主要是为了开发测试，所以在生命周期的第一阶段中存在安装、部署两种情况。

在这几个阶段中，ABT 节点提供了以下这几个 Hook：

- pre-deploy
- post-install
- pre-start
- pre-stop
- pre-install
- pre-uninstall

用来在执行生命周期的过程中做一些事情，比如，某个 Blocklet 对于运行的机器有硬件要求：内存不能低于 1G，可用磁盘容量不能低于 500 MB。这个时候就可以利用 pre-install hook 来检测目标机器是否已满足需求，如果满足，正常安装，否则抛出错误消息，并终止安装。

hook 其实是一些 Shell 脚本，而这些脚本可能会引用 Blocklet 中的文件，而在打包 Blocklet 的过程中，ABT 节点打包工具(ABT Node CLI)会将 hook 用到的文件单独打包，所以，开发者需要在 hookFiles 中声明哪些文件被 hooks 引用了。


## 👉 Blocklet 开发
- Blocklets 模板 https://github.com/arcblock/blocklets

ABT Node CLI 提供了 `blocklet init` 命令来帮助开发者快速创建一个 Blocklet 项目，自动创建相关的配置文件和目录。

ABT 节点当前只支持 Node.js 的 Blocklet 项目，所以 Blocklet 的描述信息一般会包含包含两部分：Node.js 的 `package.json` 和 Blocklet 的 `blocklet.json`。当然，Blocklet 也允许将 `blocklet.json` 的内容放到 package.json 的 `blocklet` 字段中。

Node.js 的 package.json 文件中也包含 `name`, `description`, `version` 这些信息。对于 Blocklet 来说，这部分重复的信息是等价的，ABT 节点会优先读取 blocklet.json 的配置，如果没有，才会去读取 package.json 中的。

Blocklet 环境变量配置好之后的开发工作就是一个普通的 Web 应用开发了。因为 Blocklet 是运行在 ABT 节点之中，所以 Blocklet 会依赖于 ABT 节点的环境。ABT 节点现在提供了一些环境变量供开发使用。

私有环境变量

- BLOCKLET_PORT
- BLOCKLETAPPDIR
- BLOCKLETDATADIR
- BLOCKLETLOGDIR
- BLOCKLETCACHEDIR
- BLOCKLETAPPSK
- BLOCKLETAPPID

全局环境变量

- ABTNODEDID
- ABTNODEPK
- ABTNODEURL
- ABTNODEDOMAIN
- ABTNODEPROTOCOL

这些变量都是字面意思，在开发 Blocklet 过程中可以从环境变量中读取这变量的些值。


Blocklet 开发完成后需要 ABT CLI 提供的 `blocklet bundle` 命令来打包源码，打包后才能进行部署。另外，在生成 blocklet.json 配置时，也会生成 `screenshots` 目录，这里放置几张用于 Blocklets 市集中展示的图片，文件名可以按序号前缀加有说明意义的名字组成。

Blocklet 生命周期的部署（Deploy）阶段，`blocklet deploy` 这个命令可以将打包好的项目部署到本地 ABT 节点中，用来测试 Blocklet。本地部署时，至少需要指定 blocklet bundle 所在目录。


如何发布 Blocklet？

首先，将开发好的 Blocklet 发布到 NPM。`blocklet bundle` 命令打包好的代码会放到当前的 `.blocklet` 目录中，在发布或者测试时，需要将 `.blocklet/bundle` 中代码打包发布。

然后复刻 https://github.com/arcblock/blocklets 仓库，修改项目的 `registry.yml` 文件，将自己的 Blocklet NPM 包地址放到注册列表中。然后给 ArcBlock 的仓库： https://github.com/arcblock/blocklets 提一个 Pull Request。

经检查确认没问题后，会将上面创建的 PR 合并到 Blocklet 仓库的主分支，从而完成发布。

这种代码合作方式目的是为了开发者更容易提到当前可用的 blocklets，包括 ArcBlock 官方和社区开发者的都会在 Blocklets 集市站点 blocklet.arcblock.io 列表出来。


## 👉 Forge 框架
- ArcBlock SDK https://www.arcblock.io/zh/forge-sdk
- Forge 框架 https://docs.arcblock.io/forge/zh/intro
- Forge 安装指南 https://docs.arcblock.io/forge/zh/instruction/install
- Forge CLI 使用手册 https://docs.arcblockio.cn/forgecli/zh/
- Forge CLI Handbook https://github.com/ArcBlock/forge-cli-handbook
- Forge Tools https://docs.arcblock.io/forge/zh/tools
- Forge 基本概念 https://docs.arcblock.io/forge/zh/intro/concepts

区块链领域中的概念和术语很多，但是核心的几个是：账户、交易、区块、链，正确理解这几个核心概念能够帮助我们在后面的实践中进行的更顺畅。

- `Forge` 用于构建和开发去中心化应用的基础框架；
- `账户` 创建和查看链上活动都是围绕着账户展开的，使用数据结构 `WalletInfo`；
- `交易` 用户可以在链上做的行为；
- `资产` 用于将数据保存一种更易于操作、控制和记录变化的形式，资产 Asset 本质是区块数据，使用数据结构 `AssetState`；
- `多重签名` 一条交易可以需要多重签名验证；

区块链是账本，业内常将其比作银行系统，那么银行系统中存在的概念在区块链系统中也会存在，可以用银行账本中的概念来类比理解区块链的核心概念：

- 账户 `Account` 是用户在银行的户头+密码的组合，在区块链世界中也是如此，不论是比特币还是以太坊的账户都由地址、公钥、私钥 3 部分构成，其中地址相当于用户名，而公钥+私钥相当于密码，尤其是私钥，丢失或者泄露就意味着失去账户（敏感信息、资金）的控制权
- 交易 `Transaction` 是账本中的任意一条收支记录，在区块链世界中可以指两个账户之间的转账交易、或者智能合约调用请求；- 
- 区块 `Block` 是账本中的一页，账本的每页可能包含多笔收入和支出，同样，区块链中的每个区块都可能包含多笔交易；
- 区块链 `Blockchain` 是装订成册的多页账本，账本不同页按照记录时间先后顺序组织，区块链中不同区块按被矿工打包的时间先后组织。

关于区块怎么生产，怎么实现不可篡改的实现机制、交易的有效性验证涉及到密码学知识，感兴趣的同学可以参考相关资源。

查看链上交易？换币服务中跟原生币有关的交易全部都存储在 ArcBlock 资产链上，除了在 ABT 钱包里面查看之外，也可以到资产链区块浏览器上查看：

- 全球访问地址 https://xenon.abtnetwork.io/
- 大陆访问地址 https://xenon.network.arcblockio.cn/

Forge 发行版本可以认为是一个容器，容器里面装着 Forge 内核以及围绕其开发的各种工具，从开始的只包含 Forge 内核，到现在包含如下组件：

- Forge 内核: 交易处理引擎、和共识引擎、数据存储层的交互，每周会有大小版本发布
- 核心智能合约: Forge 内置的交易合约，能够帮助开发者解决 99% 的账户、交易、跨链、链上治理等业务逻辑，随着 Forge 同步发版
- Forge Desktop：桌面版链节点，随着 Forge 同步发版
- Forge Web: Forge 链节点的 Web 管理界面和区块浏览器，使用方法参考这里，随着 Forge 内核同步发版
- Forge SDK: 各种语言的 SDK，目前支持的语言包括 Elixir、Javascript、Java、Python、Rust，除 Elixir 与 Forge 同步发版之外，其他语言的 SDK 采用的是跟随发版
- Forge Simulator：流量模拟器，使用方法参考这里
- dApp Workshop：dApp 原型工坊，跟随 Forge 发版
- Forge Patron：集成测试工具，目前尚未公开发布
- Forge Deploy：生产环境大规模部署的工具内部使用 Ansible，，目前只支持部署私链，可以从 ArcBlock/forge-deploy-public 获取源码
- Forge Compiler：智能合约编译工具，跟随 Forge 发版，在 Forge CLI 里面可用，具体参见这里


关于 Forge 发行版本有以下几个重要事实：

- Forge 发行版本目前只支持 MacOS、CentOS、Ubuntu 等 Linux 系统，不支持 Windows
- Forge 发行版本里面只包括各个工具的可执行文件或者编译后的代码，不包括源代码
- Forge 发行版本存储在 releases.arcblock.io 上供开发者下载使用
- Forge 发行版本的最新版可以从 latest.json 查到
- Forge 发行版本的完整历史可以从 versions.json 查到
- 部分 Forge 工具箱的组件还不包含在 Forge 发行版本中，比如 Forge Deploy、Forge Patron
- 为保障中国大陆开发者的下载速度，我们在阿里云上做了发行版的镜像 releases.arcblockio.cn

## 👉 Forge 安装
- 配置指南 https://docs.arcblock.io/forge/zh/instruction/configuration
- 快速上手 https://docs.arcblock.io/forge/zh/intro/quickstart

目前 Forge 支持的操作系统有：Mac OS、Centos、Ubuntu，对于其他平台，建议使用 docker 镜像。

在 ubuntu 16.04，您需要安装 erlang crypto，确保 erlang 版本可和您安装的 openssl 一起使用：

    sudo apt-get install -y erlang-crypto

如果错过这一步，Forge 版本会崩溃，且会出现以下错误信息：

    libcrypto.so.1.1: cannot open shared object file: No such file or directory

确认使用最新的 Node.js 及 OpenSSL 版本：

    $ openssl version

    OpenSSL 1.1.1 11 Sep 2018

    $ node -v

    v11.12.0

尽管 nodejs 提供 npm，但强烈推荐您安装 yarn。

    sudo apt-get update && sudo apt-get install -y yarn

使用 yarn 安装 forge cli，完成后得到 forge 命令，并用它来安装 Forge 框架：

    sudo yarn global add @arcblock/forge-cli
    sudo npm install -g @arcblock/forge-cli --unsafe-perm

    forge install
    forge install 1.0.0
    forge install --mirror https://releases.arcblockio.cn

对于中国大陆的用户，可以使用阿里云的镜像来加速安装。默认安装最新版本，可以安装指定版本号，如 forge 1.0.0。 

    Commands:
      account <address>                Get an account info by address
      asset <address>                  Get asset info by address
      block [options] [height]         Get the block info from the running node
      blocklet:init [options]          Init a blocklet project
      blocklet:use [options]           Download and install a blocklet
      chain:config [options] [action]  Read/write chain/node config
      chain:create [chainName]         Create a new chain instance
      chain:ls                         List all chains
      chain:remove <chainName>         Remove chain state and config
      chain:reset <chainName>          Reset chain state, but keeps the config
      chain:validator [options]        Update(add, remove, change) or list validators
      config [options] [key] [value]   Config forge cli configs
      declare:node [options]           Declare the current node to be a validator candidate
      deploy:prepare [options]         Prepare node for deploying a multi-node chain
      download [options] [version]     Download a forge release without activate it
      help [subcommand]                Show help of a sub command
      install [options] [version]      Download and setup forge release on this machine
      join <endpoint>                  Join a network by providing a valid forge web graphql endpoint
      logs [type]                      Show logs for various forge components
      ls                               List forge releases installed locally
      ls:remote                        List remote forge releases available for install
      ps                               List running forge component processes
      remote [shellName]               Connects to the running system via a remote shell
      simulator [action]               Start/stop simulator and generate random traffic
      start [options] [<chainName>]    Start the forge and forge web deamon
      status [type]                    List info of the running chain/node
      stop [options] [<chainName>]     Stop the forge daemon and all related services
      tx [hash]                        Get a tx detail and display
      tx:ls                            List latest transactions
      upgrade [<chainName>]            Upgrade chain node to new version without reset
      use [version]                    Activate an already downloaded forge release
      version [<chainName>]            Output version for all forge components
      wallet:create                    Create a local wallet and dump its public/private key
      web [action]                     Open the web interface of running forge chain/node

    Examples:

      Please install a forge-release before running any other commands
      > forge install latest
      > forge install --mirror https://releases.arcblockio.cn

      Curious about how to use a subcommand?
      > forge help install

安装好了所有环境，接下来就创建一条链：

    forge chain:create

链创建好之后，terminal 会提示该条链配置信息的保存路径，你可以通过直接修改这个配置文件来进一步配置链的具体信息，比如：

- 区块生成的间隔
- 具体交易设置
- 具体币的数量的设置等

在运行你创建好的链之前，要确保链的配置已经完成，因为一旦链开始运行，这部分配置信息将不可改动。

确保一切配置信息都符合你的要求后，运行你的链：

    forge start [your-chain]

执行以下命令查看区块浏览器，区块浏览器里面能看到链的基本信息：

    forge web open

- 链的名称显示在左上角
- 链的块高、交易数量、账户数量、验证人节点数量显示在仪表盘上
- 如果你刷新这个页面，会看到块高在不停的变大，是因为即使没有交易的时候 forge 也在出空块


到这里，我们的单节点的链已经启动了，怎么确定这个链的状态是正常的呢？执行 `forge status` 即可看到当前的链块高是多少。如果想查看链上币的配置，可以执行 `forge status core`，在输出结果中查找 token 信息，如下图：


Forge CLI 创建出来每一条链都会有自己对应的 `forge_release.toml` 配置。每条链创建成功后会出现如下信息提示配置文件的位置，用户可以直接在文件里修改。

    ✔ Config file /Users/.forge_chains/forge_test1/forge_release.toml is updated!

Forge 的配置信息主要有两种：

- `链的配置` 主要包括对链本身的设置，一旦链启动过，这些配置信息会被记录在链的状态中，并在所有节点间同步，因此 链的配置 的信息在链首次启动后就不可更改。
- `节点配置` 主要包括对节点自身的设置，因此即使在链启动后也可以随时更改，只不过需要重启节点才能生效。

带方括号的内容代表示分区，不重复的，如：`[forge]` 下的配置代表这些配置属于 forge，`[forge.transaction]` 下的配置代表这些配置属于 forge.transaction。

如果某项配置在 forge_release.toml 中没有出现，则 Forge 会使用默认值，否则将以 forge_release.toml 中的配置为准。



## 👉 Forge 原理
- Forge 原理 https://docs.arcblock.io/forge/zh/reference
- 创建新的 SDK https://docs.arcblock.io/forge/zh/instruction/sdk/create
- 如何写一个智能合约 https://docs.arcblock.io/forge/zh/reference/txs/how_to_write_a_smart_contract
- 基于 ABT Wallet 实现原子互换 https://docs.arcblock.io/forge/zh/reference/txs/atomic-swap/wallet-usage
- 同构链跨链 - 原子交换 Atomic Swap https://docs.arcblock.io/forge/zh/reference/txs/atomic-swap/what_is_atomic_swap

从架构视角看，`Forge` 链是应用状态存储的一种有效方式，而 Forge SDK 是链接状态和应用的桥梁。

Forge SDK 的目的是为 Forge 构建的链简化互动，所有 SDK API 都分为以下类别：

- 提供链相关的 API
- 链上数据统计相关的 API
- 链上创建钱包账户相关的 API
- 查询链上状态信息的 API
- 订阅某种交易的 API

Forge 在设计的时候，尽可能的保证了各层、各面的可扩展性。不论什么语言的 Forge SDK，都服务于以下 3 个目标：

- 支持基本的区块链数据操作，比如哈希、签名、加密、解密等
- 支持基本的链上数据读写，将应用代码和 Forge 链链接起来
- 尽可能简化第一个目标中开发者需要做的各种操作

模块化，以及模块的高内聚和低耦合是实现软件可扩展性和可维护性的重要手段。

为完成上述目标，Forge SDK 需要的功能模块划分如下：

- 协议层：定义了各种数据结构，使用 `Protocol Buffers`、数据变化方式（哈希、签名、加解密等）、 DID 生成过程；
- 类库层：定义如何组装 Forge 能识别的消息，怎么解码从 Forge 拿回来的数据，比如对钱包的封装、对 Forge 能收发的交易消息的封装；
- 客户端：定义如何连接 Forge 链节点，支持 gRPC 和 GraphQL，如何执行常见的链上操作等；

不同语言应用的领域会有很大不同，对应的 SDK 实现也有侧重点，比如：

- 如果是偏后端的语言 SDK，侧重实现 gRPC 就可以了
- 如果不需要支持 ABT Wallet 交互的逻辑处理，不需要实现 DID 认证相关逻辑
- 如果不需要支持丰富的数据哈希、加解密、签名算法，支持 Forge 选取的标准算法即可，标准算法指的是：哈希算法使用 SHA3、非对称加密算法使用 ED25519、地址编码使用 base58btc


理解数据结构和数据流转是彻底理解复杂系统的两个基石。

数据类型 Forge Types 
- https://docs.arcblock.io/forge/zh/reference/types

- `Enum` 是 ArcBlock 框架中定义好的数据类型。 
- `State` 是 ArcBlock 框架中支持的状态的数据类型。
- `Type` 是 ArcBlock 框架中使用的基本数据类型。 
- `Trace Type` 是主要供网络 API 使用的数据类型。


Forge 中的交易类型
- https://docs.arcblock.io/forge/zh/reference/txs

交易是 Forge 支持的链上发生的最小活动，支持交易的代码名为交易协议。Forge 交易的交易协议相当于以太坊交易的智能合约。

默认情况下，Forge 包含一套核心交易协议——每个协议都覆盖一组典型用例。应用程序开发者可以决定安装所有协议或只选择希望支持的协议。


Forge 支持的接口
- https://docs.arcblock.io/forge/zh/reference/rpc

ArcBlock SDK 提供 `gRPC` 和 `GraphQL` 两种 API，它们都采用了类似的接口。

Forge 的状态码
- https://docs.arcblock.io/forge/zh/reference/code

各种操作返回的状态信息：

- `ok` Everything is good.
- `invalid_wallet` This wallet is invalid.
- ...


## 👉 Forge Javascript SDK
- JavaScript SKD https://docs.arcblock.io/forge/zh/instruction/sdk/js
- Forge Javascript SDK https://forge-js.netlify.app/en/packages/
- GraphQLClient 高级示例 https://github.com/ArcBlock/forge-js/tree/master/forge/graphql-client/examples
- GRpcClient 高级示例 https://github.com/ArcBlock/forge-js/tree/master/forge/grpc-client/examples

Forge Javascript SDK 方便开发者在 forge 上构建应用程序，它提供精炼简单的 api，帮助开发者完成以下任务：

- 创建并操控钱包：`@arcblock/mcrypto`，`@arcblock/forge-wallet`
- 通过 `GraphQLClient` 或 `GRpcClient` 读/写链上数据
- 导出/验证在不同 forge 成分中广泛使用的 DID：`@arcblock/did`，`@arcblock/did-util`
- 组装/编码/签署可发送至任何 forge 支持的区块链的交易

通过 Forge JavaScript SDK 可以实现简化的区块链程序，而且这些程序在其他区块链平台上可能需要数天或数周才能完成：

- 在 forge 支持的区块链上创建两个用户账户（Alice和Bob），您可通过Forge CLI轻松设置并运行；
- 为新创建的账户获取 25 个 代币
- 从Alice向Bob转移 5 个代币，检查余额

整个流程覆盖典型网络应用程序可进行的所有任务，例如：

- 设置数据库，每个区块链都是一个公共可验证的数据库
- 创建用户账户（注册/登录）
- 为用户升级状态（代币/资产）
- 用户间交易（转移/交换）





