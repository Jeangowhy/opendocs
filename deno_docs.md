


/. 🚀 Standard Library API Docs
===================================================

此文档包含或将要包含以下文档，官方或非官方：

* https://docs.deno.com/runtime/tutorials
* https://docs.deno.com/runtime/manual
* https://docs.deno.com/deploy/tutorials
* https://docs.deno.com/deploy/manual
* https://docs.deno.com/kv/tutorials
* https://docs.deno.com/kv/manual
* [Deno by Example](https://examples.deno.land/)
* [Fresh Framework](https://fresh.deno.dev/docs)
* [Deno Standard Library](https://deno.land/std?doc)
* [Runtime APIs](https://deno.land/api@v1.38.2?unstable=true)
* https://github.com/denoland/deno/releases/download/v1.38.3/lib.deno.d.ts

Deno 1.38.2 标准库文档合并使用以下 Python 脚本，数据源自 deno doc 输出的 JSON。
Deno doc 工具使用 Rust 语言实现，它用于抽取 TypeScript 源代码中的 JSDoc 注解形成文档。
官方提供了基于 WebAssembly 的编译版本，包含 TypeScript 声明文件：

*  https://deno.land/x/deno_doc@0.73.3/types.d.ts
*  https://docs.rs/jsdoc/latest/jsdoc/all.html
*  https://docs.rs/deno_doc/latest/deno_doc/struct.DocNode.html

每个模块文档 JSON 相当于是一个 `NamespaceDef` 定义的命令空间，包含一组文档节点。
`DocNode` 是文档中的数据节点类型（类型并集），根据所表达 TypeScript 类型信息定义了多个字段。
这些数据归属于各种 `DocNode` 子类型，节点接口 `DocNodeBase` 定义 kind 字段来判断其子类型，
并且使用相应的字段来引用相应的子类型数据结构：

    export type DocNode =   =>   export type DocNodeKind =
      | DocNodeModuleDoc    =>     | "moduleDoc"     =>      JsDoc
      | DocNodeFunction     =>     | "function"      =>      FunctionDef
      | DocNodeVariable     =>     | "variable"      =>      VariableDef
      | DocNodeEnum         =>     | "enum"          =>      EnumDef
      | DocNodeClass        =>     | "class"         =>      ClassDef
      | DocNodeTypeAlias    =>     | "typeAlias"     =>      TypeAliasDef
      | DocNodeNamespace    =>     | "namespace"     =>      NamespaceDef
      | DocNodeInterface    =>     | "interface"     =>      InterfaceDef
      | DocNodeImport;      =>     | "import";       =>      ImportDef

    interface DocNodeBase {
      kind: DocNodeKind;
      name: string;
      location: Location;
      declarationKind: DeclarationKind;
      jsDoc?: JsDoc;
    }

`JsDoc` 类型主要用于描述文档注解内容，通过 `JsDocTag` （类型并集）来表达各种类型的文档数据，
这些类型都继承 `JsDocTagBase` 接口的 kind (`JsDocTagKind`) 指明这些文档的分类。

    export interface JsDoc {
      doc?: string;
      tags?: JsDocTag[];
    }

    export interface JsDocTagBase {
      kind: JsDocTagKind;
    }

    export type JsDocTag =       export type JsDocTagKind = 
      | JsDocTagOnly          =>   | "constructor" | "ignore" | "module" | "public" | "private" | "protected" | "readonly" 
      | JsDocTagDoc           =>   | "category" | "deprecated" | "example" 
      | JsDocTagNamed         =>   | "callback" | "template" 
      | JsDocTagValued        =>   | "default" 
      | JsDocTagTyped         =>   | "enum"     | "extends" | "this" | "type" 
      | JsDocTagNamedTyped    =>   | "property" | "typedef" 
      | JsDocTagParam         =>   | "param" 
      | JsDocTagReturn        =>   | "return" 
      | JsDocTagTags          =>   | "tags" 
      | JsDocTagUnsupported;  =>   | "unsupported"; 


描述函数、类方法参数列表的类型有 `ParamDef` 和 `TsTypeDef` 两个类型并集，处理起来比较
复杂一点，因为涉及 TypeScript 各种类型的描述，需要用它们来描述各种 TypeSCript “体操”。
类似地使用 `TsTypeDefKind` 来指示数据所描述的 TypeScript 类型信息。

    export type TsTypeDef =            export type TsTypeDefKind =
      | TsTypeKeywordDef          =>     | "keyword"
      | TsTypeDefLiteral          =>     | "literal"
      | TsTypeTypeRefDef          =>     | "typeRef"
      | TsTypeUnionDef            =>     | "union"      
      | TsTypeIntersectionDef     =>     | "intersection"
      | TsTypeArrayDef            =>     | "array"
      | TsTypeTupleDef            =>     | "tuple"
      | TsTypeTypeOperatorDef     =>     | "typeOperator"
      | TsTypeParenthesizedDef    =>     | "parenthesized"
      | TsTypeRestDef             =>     | "rest"
      | TsTypeOptionalDef         =>     | "optional"
      | TsTypeQueryDef            =>     | "typeQuery"      
      | TsTypeThisDef             =>     | "this"     
      | TsTypeFnOrConstructorDef  =>     | "fnOrConstructor"                
      | TsTypeConditionalDef      =>     | "conditional"            
      | TsTypeImportTypeDef       =>     | "importType"           
      | TsTypeInferDef            =>     | "infer"      
      | TsTypeIndexedAccessDef    =>     | "indexedAccess"              
      | TsTypeMappedDef           =>     | "mapped"       
      | TsTypeTypeLiteralDef      =>     | "typeLiteral"            
      | TsTypeTypePredicateDef;   =>     | "typePredicate";

    interface TsTypeDefBase {          export interface TsTypeParamDef {
      repr: string;                      name: string;
      kind: TsTypeDefKind;               constraint?: TsTypeDef;
    }                                    default?: TsTypeDef;
                                       }
    export type ParamDef =            
      | ParamArrayDef                 
      | ParamAssignDef                
      | ParamIdentifierDef            
      | ParamObjectDef                
      | ParamRestDef;

文档中，有两个用于描述参数的接口和类型，一个接口是 `TsTypeParamDef` 用于描述 TypeScript
类型的参数，另一个是类型并集 `ParamDef` 用于描述参数列表，它不仅描述函数参数列表，还用于描述
接口定义、类定义、成员方法、属性访问器，以及部分字面量类型，都会使用到它：

* InterfaceDef
* InterfaceMethodDef
* InterfacePropertyDef
* ClassDef
* ClassConstructorDef
* FunctionDef
* LiteralIndexSignatureDef
* LiteralMethodDef
* LiteralPropertyDef

其中，有两个类型特别注意下，`TsTypeTypeRefDef` 和 `TsTypeRefdef` 两者全称上十分
容易混淆，前者定义的是引用类型，后者是引用类型的参数列表描述。

    export interface TsTypeTypeRefDef extends TsTypeDefBase {
      kind: "typeRef";
      typeRef: TsTypeRefDef;
    }

    export interface TsTypeRefDef {
      typeParams?: TsTypeDef[];
      typeName: string;
    }

可以使用 Python 脚本处理 Deno doc --json 提供的数据，但是使用 TypeScript 则可以
直接利用官方提供的类型声明文件：

```ts
import { doc } from "https://deno.land/x/deno_doc@0.73.2/mod.ts";

const entries = await doc("https://deno.land/std@0.207.0/crypto/mod.ts");

for (const entry of entries) {
  console.log(`name: ${entry.name} kind: ${entry.kind}`);
}
```

```py
#! /usr/bin/env python
import os
import sys
from json import JSONDecoder
from glob import glob
from io import BufferedWriter, StringIO
from subprocess import PIPE, Popen


def print_title (title):
    print (f"""

{'='.rjust(52, '=')}
/. 🚀 {title}
{'='.rjust(52, '=')}

""")


def parseJSON(lib:str, json:str):
    dec = JSONDecoder()
    docs = list(dec.decode(json))
    for it in docs:
        print(it['name'], it['kind'], it.keys())


def toc():
    return [it for it in glob("./*/") if not it.startswith('.\\_')]


def combine():
    print_title ("Docs combine script")

    print ('''

.. code-block:: python

''')
    sc = open(sys.argv[0], encoding='utf8')
    print ("    ".join(["", *sc.readlines()]))

    lib='crypto'
    deno = 'c:/ProgramData/chocolatey/bin/deno.exe'
    args = ['deno', 'doc', '--json', f'--name={lib}', f'{lib}/mod.ts']
    # os.system('deno --version')
    # deno doc --json --name=crypto crypto/mod.ts
    # os.spawnv(os.P_WAIT, deno, args)
    ps = Popen(' '.join(args), stdout=PIPE)
    if ps.stdout is not None:
        parseJSON(lib, ps.stdout.read().decode())

combine()
```

[deno_doc.ts](deno_doc.ts) 脚本用于将 Deno Doc 转换 Markdown 格式，图案符号说明：

1.  🟠 Interface 接口符号标记
2.  🟢 Class     类型符号标记
3.  🟡 Class [Abstract] 抽象类型符号标记
4.  🟩 Function  函数符号标记
5.  🟥 Constructor 构建器符号标记
6.  🟨 Method    类成员方法符号标记
7.  🟦 Getter    类属性读取方法符号标记
8.  🟧 Setter    类属性写入方法符号标记



/. 🚀 Docs combine script
===================================================

文档合并脚本中使用了 sed 流式编辑器、awk 结构化数据编辑器，使用教程参考 OpenDocs： 

1. [Sed in 5 Minutes](https://github.com/Jeangowhy/opendocs/blob/main/sed.info)
2. [AWK in 5 Minutes](https://github.com/Jeangowhy/opendocs/blob/main/sed.info)

.. code-block:: bash

    #! /usr/bin/env bash
    
    print_title () {
        printf '\n%.0s' {1..2};
        printf "\n/. 🚀 $1\n"
        printf '=%.0s' {1..51};
        printf '\n%.0s' {1..2};
    }
    
    function filter {
        local parent=`echo $1 | sed -n 's/[^/\]\+$//p'`
        echo $1
        for it in `sed -n "/^.. toctree::/,/^\S/{ s/^ \+[^:]\+$/\0/p }" $1 | sed -n 's|.*<\(.*\)>|\1|;p'`
        do
            doc="$parent$it"
            filter $doc
        done
    }
    
    function toc() {
        cat << EOF
        README.md
        deno-1.38.2/README.md
        deno_std-0.207.0/README.md
        runtime/index.mdx
        runtime/manual/index.mdx
        runtime/manual/help.md
        runtime/manual/basics/index.md
        runtime/manual/getting_started/index.md
        runtime/manual/getting_started/command_line_interface.md
        runtime/manual/getting_started/configuration_file.md
        runtime/manual/getting_started/first_steps.md
        runtime/manual/getting_started/installation.md
        runtime/manual/getting_started/setup_your_environment.md
        runtime/manual/getting_started/web_frameworks.md
        runtime/manual/basics/permissions.md
        runtime/manual/basics/standard_library.md
        runtime/manual/basics/env_variables.md
        runtime/manual/basics/import_maps.md
        runtime/manual/basics/debugging_your_code.md
        runtime/manual/basics/connecting_to_databases.md
        runtime/manual/basics/react.md
        runtime/manual/basics/modules/index.md
        runtime/manual/basics/modules/integrity_checking.md
        runtime/manual/basics/modules/private.md
        runtime/manual/basics/modules/proxies.md
        runtime/manual/basics/modules/reloading_modules.md
        runtime/manual/basics/testing/index.md
        runtime/manual/basics/testing/assertions.md
        runtime/manual/basics/testing/behavior_driven_development.md
        runtime/manual/basics/testing/coverage.md
        runtime/manual/basics/testing/documentation.md
        runtime/manual/basics/testing/mocking.md
        runtime/manual/basics/testing/sanitizers.md
        runtime/manual/basics/testing/snapshot_testing.md
        runtime/manual/advanced/index.md
        runtime/manual/advanced/publishing/index.md
        runtime/manual/advanced/publishing/dnt.md
        runtime/manual/advanced/embedding_deno.md
        runtime/manual/advanced/language_server/index.md
        runtime/manual/advanced/language_server/imports.md
        runtime/manual/advanced/language_server/overview.md
        runtime/manual/advanced/language_server/testing_api.md
        runtime/manual/advanced/continuous_integration.md
        runtime/manual/advanced/typescript/configuration.md
        runtime/manual/advanced/typescript/faqs.md
        runtime/manual/advanced/typescript/migration.md
        runtime/manual/advanced/typescript/overview.md
        runtime/manual/advanced/typescript/types.md
        runtime/manual/advanced/jsx_dom/index.md
        runtime/manual/advanced/jsx_dom/css.md
        runtime/manual/advanced/jsx_dom/deno_dom.md
        runtime/manual/advanced/jsx_dom/jsdom.md
        runtime/manual/advanced/jsx_dom/jsx.md
        runtime/manual/advanced/jsx_dom/linkedom.md
        runtime/manual/advanced/jsx_dom/overview.md
        runtime/manual/advanced/jsx_dom/twind.md
        runtime/manual/advanced/deploying_deno/index.md
        runtime/manual/advanced/deploying_deno/aws_lightsail.md
        runtime/manual/advanced/deploying_deno/cloudflare_workers.md
        runtime/manual/advanced/deploying_deno/digital_ocean.md
        runtime/manual/advanced/deploying_deno/google_cloud_run.md
        runtime/manual/advanced/deploying_deno/kinsta.md
        runtime/manual/node/index.md
        runtime/manual/node/npm_specifiers.md
        runtime/manual/node/how_to_with_npm/index.md
        runtime/manual/node/how_to_with_npm/apollo.md
        runtime/manual/node/how_to_with_npm/express.md
        runtime/manual/node/how_to_with_npm/mongoose.md
        runtime/manual/node/how_to_with_npm/mysql2.md
        runtime/manual/node/how_to_with_npm/planetscale.md
        runtime/manual/node/how_to_with_npm/prisma.md
        runtime/manual/node/how_to_with_npm/react.md
        runtime/manual/node/how_to_with_npm/redis.md
        runtime/manual/node/how_to_with_npm/vue.md
        runtime/manual/node/node_specifiers.md
        runtime/manual/node/package_json.md
        runtime/manual/node/cdns.md
        runtime/manual/node/compatibility.mdx
        runtime/manual/node/faqs.md
        runtime/manual/node/migrate.md
        runtime/manual/references/index.md
        runtime/manual/references/cheatsheet.md
        runtime/manual/references/contributing/index.md
        runtime/manual/references/contributing/architecture.md
        runtime/manual/references/contributing/building_from_source.md
        runtime/manual/references/contributing/profiling.md
        runtime/manual/references/contributing/release_schedule.md
        runtime/manual/references/contributing/style_guide.md
        runtime/manual/references/contributing/web_platform_tests.md
        runtime/manual/references/vscode_deno/index.md
        runtime/manual/references/vscode_deno/testing_api.md
        runtime/manual/runtime/index.md
        runtime/manual/runtime/builtin_apis.md
        runtime/manual/runtime/ffi_api.md
        runtime/manual/runtime/http_server_apis.md
        runtime/manual/runtime/import_meta_api.md
        runtime/manual/runtime/location_api.md
        runtime/manual/runtime/permission_apis.md
        runtime/manual/runtime/program_lifecycle.md
        runtime/manual/runtime/stability.md
        runtime/manual/runtime/web_platform_apis.md
        runtime/manual/runtime/web_storage_api.md
        runtime/manual/runtime/workers.md
        runtime/manual/runtime/webassembly/index.md
        runtime/manual/runtime/webassembly/using_streaming_wasm.md
        runtime/manual/runtime/webassembly/using_wasm.md
        runtime/manual/runtime/webassembly/wasm_resources.md
        runtime/manual/tools/index.md
        runtime/manual/tools/init.md
        runtime/manual/tools/bundler.md
        runtime/manual/tools/benchmarker.md
        runtime/manual/tools/compiler.md
        runtime/manual/tools/script_installer.md
        runtime/manual/tools/jupyter.md
        runtime/manual/tools/dependency_inspector.md
        runtime/manual/tools/documentation_generator.md
        runtime/manual/tools/formatter.md
        runtime/manual/tools/linter.md
        runtime/manual/tools/repl.md
        runtime/manual/tools/task_runner.md
        runtime/manual/tools/vendor.md
        runtime/tutorials/index.md
        runtime/tutorials/hello_world.md
        runtime/tutorials/manage_dependencies.md
        runtime/tutorials/fetch_data.md
        runtime/tutorials/read_write_files.md
        runtime/tutorials/hashbang.md
        runtime/tutorials/word_finder.md
        runtime/tutorials/unix_cat.md
        runtime/tutorials/http_server.md
        runtime/tutorials/file_server.md
        runtime/tutorials/tcp_echo.md
        runtime/tutorials/chat_app.md
        runtime/tutorials/tcp_server.md
        runtime/tutorials/subprocess.md
        runtime/tutorials/os_signals.md
        runtime/tutorials/file_system_events.md
        runtime/tutorials/module_metadata.md
        runtime/tutorials/how_to_with_npm/apollo.md
        runtime/tutorials/how_to_with_npm/express.md
        runtime/tutorials/how_to_with_npm/mongoose.md
        runtime/tutorials/how_to_with_npm/mysql2.md
        runtime/tutorials/how_to_with_npm/planetscale.md
        runtime/tutorials/how_to_with_npm/prisma.md
        runtime/tutorials/how_to_with_npm/react.md
        runtime/tutorials/how_to_with_npm/redis.md
        runtime/tutorials/how_to_with_npm/vue.md
        deploy/index.md
        deploy/tutorials/index.md
        deploy/tutorials/discord-slash.md
        deploy/tutorials/fresh.md
        deploy/tutorials/simple-api.md
        deploy/tutorials/static-site.md
        deploy/tutorials/tutorial-blog-fresh.md
        deploy/tutorials/tutorial-dynamodb.md
        deploy/tutorials/tutorial-faunadb.md
        deploy/tutorials/tutorial-firebase.md
        deploy/tutorials/tutorial-http-server.md
        deploy/tutorials/tutorial-hugo-blog.md
        deploy/tutorials/tutorial-postgres.md
        deploy/tutorials/tutorial-wordpress-frontend.md
        deploy/tutorials/vite.md
        deploy/manual/index.mdx
        deploy/manual/ci_github.md
        deploy/manual/custom-domains.md
        deploy/manual/deployctl.md
        deploy/manual/deployments.md
        deploy/manual/dynamodb.md
        deploy/manual/environment-variables.md
        deploy/manual/fair-use-policy.md
        deploy/manual/faunadb.md
        deploy/manual/firebase.md
        deploy/manual/how-to-deploy.md
        deploy/manual/logs.md
        deploy/manual/middleware.md
        deploy/manual/organizations.md
        deploy/manual/playgrounds.md
        deploy/manual/postgres.md
        deploy/manual/pricing-and-limits.md
        deploy/manual/privacy-policy.md
        deploy/manual/regions.md
        deploy/manual/running-scripts-locally.md
        deploy/manual/security.md
        deploy/manual/subhosting/index.md
        deploy/manual/subhosting/domains.md
        deploy/manual/subhosting/getting_started.md
        deploy/manual/subhosting/projects_and_deployments.md
        deploy/manual/use-cases.md
        deploy/api/index.md
        deploy/api/compression.md
        deploy/api/rest/index.md
        deploy/api/rest/deployments.md
        deploy/api/rest/domains.md
        deploy/api/rest/organizations.md
        deploy/api/rest/projects.md
        deploy/api/runtime-broadcast-channel.md
        deploy/api/runtime-fetch.md
        deploy/api/runtime-fs.md
        deploy/api/runtime-headers.md
        deploy/api/runtime-node.md
        deploy/api/runtime-request.md
        deploy/api/runtime-response.md
        deploy/api/runtime-sockets.md
        kv/index.md
        kv/manual/_admonition.mdx
        kv/manual/index.mdx
        kv/tutorials/index.md
        kv/tutorials/schedule_notification.md
        kv/tutorials/webhook_processor.md
        kv/manual/key_space.mdx
        kv/manual/key_expiration.mdx
        kv/manual/backup.mdx
        kv/manual/data_modeling_typescript.mdx
        kv/manual/on_deploy.mdx
        kv/manual/operations.mdx
        kv/manual/queue_overview.md
        kv/manual/secondary_indexes.mdx
        kv/manual/transactions.mdx
    EOF
    }
    
    function doc(){
        cat << EOF
    文档合并脚本中使用了 sed 流式编辑器、awk 结构化数据编辑器，使用教程参考 OpenDocs： 
    
    1. [Sed in 5 Minutes](https://github.com/Jeangowhy/opendocs/blob/main/sed.info)
    2. [AWK in 5 Minutes](https://github.com/Jeangowhy/opendocs/blob/main/sed.info)
    
    EOF
    }
    
    function combine() {
        print_title "Docs combine script"
        doc
        echo '.. code-block:: bash'
    
        echo ''
        cat $0 | sed -n 's/^/    /p'
    
        echo ''
        echo "Docs Count: `find ./ -name "*.md*" | wc -l` ::"
        echo ''
        # find ./ -name "*.md*" | sed -n 's/.*/    \0/p' | grep -v library
    
        while read -r it
        do 
            # echo $it
            print_title "$it"
            cat $it
        done << EOF
    `toc`
    EOF
    }
    
    out=/c/opendocs/deno_docs.md
    combine > $out
    subl $out

Docs Count: 218 ::




/. 🚀 README.md
===================================================

# Deno Docs

This repository contains the website running
[docs.deno.com](https://docs.deno.com). The intent of this project is to
eventually centralize all official Deno documentation content in a single
website. The Deno Docs site is built using
[Docusaurus 2](https://docusaurus.io/), a static site generator optimized for
documentation websites.

The `docs.deno.com` website is hosted on [Deno Deploy](https://deno.com/deploy),
where it is fronted by a [Hono](https://hono.dev/) web server that handles
redirects and other dynamic content requests as they become necessary.

## Local development

Since Docusaurus is built and maintained using Node.js, it is recommended to
have [Node.js and npm](https://nodejs.org/en/download) installed for local
development. Once Node and npm are installed, install Docusaurus' dependencies
with:

```
npm install
```

You can then start the local development server with:

```
npm start
```

This will launch a browser window open to
[localhost:3000](http://localhost:3000), where you will see any doc content
changes you make update live.

To test the generated static site in a production configuration, run:

```
npm run build
```

This will generate a static site to the `build` folder locally. To test the
production server (through the actual Deno / Hono server), run this command:

```
npm run serve
```

This will start a Deno server on [localhost:8000](http://localhost:8000), where
you can preview the site as it will run on Deno Deploy.

Sometimes, after making a Docusaurus config change, you will run into an error
and need to clean Docusaurus' generated assets. You can do this by running:

```
npm run clear
```

This will solve most errors you encounter while refactoring the site. Static
assets will be rebuilt from scratch the next time you run `npm run build` or
`npm start`.

## Editing content

The actual content of the docs site is found mostly in these three folders:

- `runtime` - docs for the Deno CLI / runtime
- `deploy` - docs for the Deno Deploy cloud service
- `kv` - docs for Deno KV, Deno's integrated database

Most files are [markdown](https://docusaurus.io/docs/markdown-features), but
even markdown files are processed with [MDX](https://mdxjs.com/), which enables
you to use JSX syntax within your markdown files.

Left navigation for the different doc sections are configured in one of these
files:

- `sidebars/runtime.js` - sidebar config for the Runtime section
- `sidebars/deploy.js` - sidebar config for the Deno Deploy section
- `sidebars/kv.js` - sidebar config for the KV section

Static files (like screenshots) can be included directly in the `runtime`,
`deploy`, or `kv` folders, and referenced by relative URLs in your markdown.

Docusaurus provides a number of nice extensions to markdown you might want to
use, like tabs, admonitions, and code blocks.
[Refer to the Docusaurus docs](https://docusaurus.io/docs/markdown-features) for
more details.

## Versioning docs content

Philosophically, we want to maintain as few discrete versions of the
documentation as possible. This will reduce confusion for users (reduce the
number of versions they need to think about), improve search indexing, and help
us maintain the docs by keeping our build times faster.

In general, we should only version the documentation **when we want to
concurrently maintain several versions of the docs**, like for major/LTS
versions. For example - the [Node.js docs](https://nodejs.org/en/docs) are only
versioned for major releases, like `20.x` and `19.x`. We will adopt this pattern
as well, and won't have versioned docs for patch or feature releases.

For additive changes, it should usually be sufficient to indicate which version
a feature or API was released in. For example - in the Node 20 docs, the
[register function](https://nodejs.org/dist/latest-v20.x/docs/api/module.html#moduleregister)
is marked as being added in version `20.6.0`.

When we do want to maintain versioned docs for major releases, we currently plan
to use [Docusaurus versions](https://docusaurus.io/docs/versioning).

## Including version numbers in code and content

It may occasionally be desirable to dynamically include the current Deno CLI or
standard library version in content or code samples. We can accomplish this
using the `replacements.json` file at the root of this repository.

Any values you would like to change once, and then have appear dynamically in a
number of generated files, should be included in `replacements.json`.

In code samples (fenced with backticks), you can include a `$` character,
followed by the replacement variable name, directly within the code sample. When
the markdown is transformed, the current version number will be replaced within
it.

```ts
import { copy } from "https://deno.land/std@$STD_VERSION/fs/copy.ts";
```

To include version number in markdown / MDX content, we recommend using the
`<Replacement />` component:

```mdx
import Replacement from "@site/src/components/Replacement";

The current CLI version is **<Replacement for="CLI_VERSION"/>**.
```

If you are writing inline JSX, you can also use the replacements object directly
like so:

```mdx
import { replacements } from "@site/src/components/Replacement";

<p>
  The current CLI version is <code>{ replacements.CLI_VERSION }</code>.
</p>
```

## Server-side code and redirects

The Deno code that serves the site in production is in the `src-deno` folder.
When the `npm run build` command is executed for a production Docusaurus build,
it also copies the contents of the `src-deno` folder (unchanged) into the
resulting `build` folder, which will be our project root for Deno Deploy.

Right now, there is just a very thin [Hono](https://hono.dev/) server sitting on
top of the static assets generated by Docusaurus. The only interesting job the
Hono app has right now is handling redirects, of which there are several from
the previous Deno doc sites.

To add a redirect, open `src-deno/redirects.ts` and configure a new route in the
default exported function. The default status code of `301` should be sufficient
for most cases.

## New release process for Deno runtime

Let's say that a new minor release is ready for Deno, with CLI version `1.99`
and standard library version `0.999.0`. Here's how I would recommend approaching
the docs for this release right now.

- Create a feature branch for the release, like `release_1_99` or similar
- Update `replacements.json` with the upcoming CLI and standard lib versions
- As the release is developed, add docs changes to this branch
- When the release is ready, submit a PR to the `main` branch from this feature
  branch
- When the branch is merged, create a `v1.99` tag from the new `main` branch

For patch releases, I would recommend simply submitting pull requests to the
`main` branch with relevant updates to `replacements.json` as required.

If we decide we'd like to have "canary" docs for upcoming versions, we can
discuss how to make that possible with
[Docusaurus versions](https://docusaurus.io/docs/versioning).

## Contribution

We are very grateful for any help you can offer to improve Deno's documentation!
For any small copy changes or fixes, please feel free to
[submit a pull request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request)
directly to the `main` branch of this repository.

For larger changes, please
[create a GitHub issue first](https://github.com/denoland/deno-docs/issues) to
describe your proposed updates. It will be better to get feedback on your
concept first before going to the trouble of writing a large number of docs!

Over time, we will add more in the way of linting and formatting to the pull
request process. But for now, you should merely ensure that `npm run build`
succeeds without error before submitting a pull request. This will ensure that
there are no broken links or invalid MDX syntax in the content you have
authored.

## Special thanks for historical contributions

This repository was created using content from the
[Deno Manual](https://github.com/denoland/manual), a project contributed to by
hundreds of developers since 2018. You can view a list of historical
contributors to the Deno documentation in this repository and the manual with
this command:

```
git shortlog -s -n
```

## Deployment

The `docs.deno.com` site is updated with every push to the `main` branch, which
should be done via pull request to this repository.

## License

MIT



/. 🚀 deno-1.38.2/README.md
===================================================

# Deno

[![](https://img.shields.io/crates/v/deno.svg)](https://crates.io/crates/deno)
[![Twitter badge][]][Twitter link] [![Discord badge][]][Discord link]
[![YouTube badge][]][YouTube link]

<img align="right" src="https://deno.land/logo.svg" height="150px" alt="the deno mascot dinosaur standing in the rain">

[Deno](https://deno.com/runtime) is a _simple_, _modern_ and _secure_ runtime
for **JavaScript** and **TypeScript** that uses V8 and is built in Rust.

### Features

- [Secure by default.](https://deno.land/manual/basics/permissions) No file,
  network, or environment access, unless explicitly enabled.
- Provides
  [web platform functionality and APIs](https://deno.land/manual/runtime/web_platform_apis),
  e.g. using ES modules, web workers, and `fetch()`.
- Supports
  [TypeScript out of the box](https://deno.land/manual/advanced/typescript).
- Ships only a single executable file.
- [Built-in tooling](https://deno.land/manual/tools#built-in-tooling) including
  `deno test`, `deno fmt`, `deno bench`, and more.
- Includes [a set of reviewed standard modules](https://deno.land/std/)
  guaranteed to work with Deno.
- [Supports npm.](https://deno.land/manual/node)

### Install

Shell (Mac, Linux):

```sh
curl -fsSL https://deno.land/install.sh | sh
```

PowerShell (Windows):

```powershell
irm https://deno.land/install.ps1 | iex
```

[Homebrew](https://formulae.brew.sh/formula/deno) (Mac):

```sh
brew install deno
```

[Chocolatey](https://chocolatey.org/packages/deno) (Windows):

```powershell
choco install deno
```

[Scoop](https://scoop.sh/) (Windows):

```powershell
scoop install deno
```

Build and install from source using [Cargo](https://crates.io/crates/deno):

```sh
# Install build dependencies
apt install -y cmake protobuf-compiler # Linux
brew install cmake protobuf # macOS

# Build and install Deno
cargo install deno --locked
```

See
[deno_install](https://github.com/denoland/deno_install/blob/master/README.md)
and [releases](https://github.com/denoland/deno/releases) for other options.

### Getting Started

Try [running a simple program](https://examples.deno.land/hello-world):

```sh
deno run https://examples.deno.land/hello-world.ts
```

Or [setup a simple HTTP server](https://examples.deno.land/http-server):

```ts
Deno.serve((_req) => new Response("Hello, World!"));
```

[More Examples](https://examples.deno.land)

### Additional Resources

- **[The Deno Manual](https://deno.land/manual)** is a great starting point for
  [additional examples](https://deno.land/manual/examples),
  [setting up your environment](https://deno.land/manual/getting_started/setup_your_environment),
  [using npm](https://deno.land/manual/node), and more.
- **[Runtime API reference](https://deno.land/api)** documents all APIs built
  into Deno CLI.
- **[Deno Standard Modules](https://deno.land/std)** do not have external
  dependencies and are reviewed by the Deno core team.
- **[deno.land/x](https://deno.land/x)** is the registry for third party
  modules.
- **[Blog](https://deno.com/blog)** is where the Deno team shares important
  product updates and “how to”s about solving technical problems.

### Contributing

We appreciate your help!

To contribute, please read our
[contributing instructions](https://deno.land/manual/references/contributing/).

[Build status - Cirrus]: https://github.com/denoland/deno/workflows/ci/badge.svg?branch=main&event=push
[Build status]: https://github.com/denoland/deno/actions
[Twitter badge]: https://img.shields.io/twitter/follow/deno_land.svg?style=social&label=Follow
[Twitter link]: https://twitter.com/intent/follow?screen_name=deno_land
[YouTube badge]: https://img.shields.io/youtube/channel/subscribers/UCqC2G2M-rg4fzg1esKFLFIw?style=social
[YouTube link]: https://www.youtube.com/@deno_land
[Discord badge]: https://img.shields.io/discord/684898665143206084?logo=discord&style=social
[Discord link]: https://discord.gg/deno



/. 🚀 deno_std-0.207.0/README.md
===================================================

# Deno Standard Library

[![codecov](https://codecov.io/gh/denoland/deno_std/branch/main/graph/badge.svg?token=w6s3ODtULz)](https://codecov.io/gh/denoland/deno_std)
[![ci](https://github.com/denoland/deno_std/actions/workflows/ci.yml/badge.svg)](https://github.com/denoland/deno_std/actions/workflows/ci.yml)

High-quality APIs for [Deno](https://deno.com/) and the web. Use fearlessly.

## Get Started

```ts
import { copy } from "https://deno.land/std@$STD_VERSION/fs/copy.ts";

await copy("./foo", "./bar");
```

See [here](#recommended-usage) for recommended usage patterns.

## Documentation

Check out the documentation [here](https://deno.land/std?doc).

## Recommended Usage

1. Include the version of the library in the import specifier.

   Good:
   ```ts
   import { copy } from "https://deno.land/std@$STD_VERSION/fs/copy.ts";
   ```

1. Only import modules that you require.

   Bad (when using only one function):
   ```ts
   import * as fs from "https://deno.land/std@$STD_VERSION/fs/mod.ts";
   ```

   Good (when using only one function):
   ```ts
   import { copy } from "https://deno.land/std@$STD_VERSION/fs/copy.ts";
   ```

   Good (when using multiple functions):
   ```ts
   import * as fs from "https://deno.land/std@$STD_VERSION/fs/mod.ts";
   ```

1. Do not import symbols with an underscore in the name.

   Bad:
   ```ts
   import { _format } from "https://deno.land/std@$STD_VERSION/path/_common/format.ts";
   ```

1. Do not import modules with an underscore in the path.

   Bad:
   ```ts
   import { filterInPlace } from "https://deno.land/std@$STD_VERSION/collections/_utils.ts";
   ```

1. Do not import test modules or test data.

   Bad:
   ```ts
   import { test } from "https://deno.land/std@$STD_VERSION/front_matter/test.ts";
   ```

## Stability

| Sub-module   | Status     |
| ------------ | ---------- |
| archive      | Unstable   |
| assert       | Stable     |
| async        | Stable     |
| bytes        | Stable     |
| collections  | Stable     |
| console      | Unstable   |
| csv          | Stable     |
| datetime     | Unstable   |
| dotenv       | Unstable   |
| encoding     | Unstable   |
| flags        | Unstable   |
| fmt          | Stable     |
| front_matter | Unstable   |
| fs           | Stable     |
| html         | Unstable   |
| http         | Unstable   |
| io           | Deprecated |
| json         | Stable     |
| jsonc        | Stable     |
| log          | Unstable   |
| media_types  | Stable     |
| msgpack      | Unstable   |
| path         | Unstable   |
| permissions  | Deprecated |
| regexp       | Unstable   |
| semver       | Unstable   |
| signal       | Deprecated |
| streams      | Unstable   |
| testing      | Stable     |
| toml         | Stable     |
| ulid         | Unstable   |
| url          | Unstable   |
| uuid         | Stable     |
| yaml         | Stable     |

> For background and discussions regarding the stability of the following
> sub-modules, see [#3489](https://github.com/denoland/deno_std/issues/3489).

## Deprecation Policy

We deprecate the APIs in the Standard Library when they get covered by new
JavaScript language APIs or new Web Standard APIs. These APIs are usually
removed after 3 minor versions.

If you still need to use such APIs after the removal for some reason (for
example, the usage in Fresh island), please use the URL pinned to the version
where they are still available.

For example, if you want to keep using `readableStreamFromIterable`, which was
deprecated and removed in favor of `ReadableStream.from` in `v0.195.0`, please
use the import URL pinned to `v0.194.0`:

```ts
import { readableStreamFromIterable } from "https://deno.land/std@0.194.0/streams/readable_stream_from_iterable.ts";
```

## Contributing

Check out the contributing guidelines [here](.github/CONTRIBUTING.md).

## Releases

The Standard Library is versioned independently of the Deno CLI. This will
change once the Standard Library is stabilized. See
[here](https://raw.githubusercontent.com/denoland/dotland/main/versions.json)
for the compatibility of different versions of the Deno Standard Library and the
Deno CLI.

A new minor version of the Standard Library is published at the same time as
every new version of the Deno CLI (including patch versions).



/. 🚀 runtime/index.mdx
===================================================

---
sidebar_position: 1
sidebar_label: Quick Start
displayed_sidebar: runtime
---

This page is redirected in production to [/runtime/manual](./manual/index.mdx).



/. 🚀 runtime/manual/index.mdx
===================================================

---
displayed_sidebar: runtimeGuideHome
sidebar_position: 1
pagination_next: manual/getting_started/installation
---

* https://docs.deno.com/runtime/tutorials
* https://docs.deno.com/runtime/manual

import { replacements } from "@site/src/components/Replacement";

# Deno Runtime Quick Start

[Deno](https://www.deno.com)
([/ˈdiːnoʊ/](http://ipa-reader.xyz/?text=%CB%88di%CB%90no%CA%8A), pronounced
`dee-no`) is a JavaScript, TypeScript, and WebAssembly runtime with secure
defaults and a great developer experience. It's built on [V8](https://v8.dev/),
[Rust](https://www.rust-lang.org/), and [Tokio](https://tokio.rs/). 

Deno is free and open source software under the 
[MIT license](https://github.com/denoland/deno/blob/main/LICENSE.md).

Let's create and run your first Deno program in under five minutes, and 
introduce you to a few key features of the runtime.

## Install Deno

Install the Deno runtime on your system using one of the terminal commands
below.

import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="macOS" default>

```sh
curl -fsSL https://deno.land/x/install/install.sh | sh
```

</TabItem>
  <TabItem  value="windows" label="Windows">

```powershell
irm https://deno.land/install.ps1 | iex
```

</TabItem>
  <TabItem value="linux" label="Linux">

```sh
curl -fsSL https://deno.land/x/install/install.sh | sh
```

</TabItem>
</Tabs>

[Additional installation options can be found here](./getting_started/installation.md).
After installation, you should have the `deno` executable available on your
system path. You can confirm this is the case by running this command in your
terminal:

```sh
deno --version
```

## Create and run a TypeScript program

While you are welcome to use pure JavaScript, Deno has built-in support for
[TypeScript](https://www.typescriptlang.org/) as well. In your terminal, create
a new file called `hello.ts`, and include the following code.

```ts title="hello.ts"
interface Person {
  firstName: string,
  lastName: string
}

function sayHello(p: Person): string {
  return `Hello, ${p.firstName}!`;
}

const ada: Person = {
  firstName: "Ada",
  lastName: "Lovelace"
};

console.log(sayHello(ada));
```

This program declares an
[interface](https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#interfaces)
for a Person, and defines a function that prints a message to the console using
this data type. You can execute the code in this example using the `deno run`
command.

```
deno run -A hello.ts
```

You can
[learn more about using TypeScript in Deno here](./advanced/typescript/overview.md).

## Built-in web APIs and the Deno namespace

Deno aims to provide a browser-like programming environment,
[implementing web standard APIs](./runtime/web_platform_apis.md) that exist in
front-end JavaScript. For example, the
[`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) API is
available in the global scope, just as in the browser. To see this in action,
replace the contents of `hello.ts` with the following code.

```ts
const site = await fetch("https://www.deno.com");
console.log(await site.text());
```

And then run it with:

```
deno run -A hello.ts
```

For APIs that don't exist as a web standard (like accessing variables from the
system environment, or manipulating the file system), those APIs are exposed in
the [`Deno` namespace](./runtime/builtin_apis.md). Replace the contents of
`hello.ts` with the following code, which will start
[an HTTP server](https://deno.land/api?s=Deno.serve) on
[localhost:8000](http://localhost:8000).

```ts
Deno.serve((_request: Request) => {
  return new Response("Hello, world!");
});
```

Run the script above with:

```
deno run -A hello.ts
```

Learn more about the [web-standard APIs](./runtime/web_platform_apis.md) built
in to Deno and the [`Deno` namespace APIs](./runtime/builtin_apis.md).

## Runtime security

A major feature of Deno is
[runtime security by default](./basics/permissions.md), meaning that you as the
developer must explicitly allow your code to access potentially sensitive APIs
like file system access, network connectivity, and access to environment
variables.

So far, we've been running all of our scripts with the `-A` flag, which grants
all runtime feature access to our scripts. This is the most permissive mode to
run a Deno program, but usually you'll want to grant your code only the
permissions it needs to run.

To see this in action, let's replace the contents of `hello.ts` again with the
`fetch` example from earlier.

```ts
const site = await fetch("https://www.deno.com");
console.log(await site.text());
```

Run this program **without** the `-A` flag - what happens then?

```bash
deno run hello.ts
```

Without any permission flags passed in, you'll see security prompts that look
something like this:

```
kevin@kevin-deno scratchpad % deno run index.ts
✅ Granted net access to "www.deno.com".
┌ ⚠️  Deno requests net access to "deno.com".
├ Requested by `fetch()` API.
├ Run again with --allow-net to bypass this prompt.
└ Allow? [y/n/A] (y = yes, allow; n = no, deny; A = allow all net permissions) >
```

In the prompt, you might have noticed that it mentions the CLI flag you'd need to run your code with permission to access the network - the `--allow-net` flag. If you run the script again using this flag, you won't be prompted to interactively grant network access to your script:

```bash
deno run --allow-net hello.ts
```

For simplicity, we will sometimes show examples that use `deno run -A ...`, but
whenever possible (and in your production or CI environments), we'd encourage
you to take advantage of Deno's full suite of
[configurable runtime security options](./basics/permissions.md).

## Importing JavaScript modules

Most of the time, you will want to break up your program into multiple files.
Again favoring web standards and a browser-like programming model, Deno supports
this through
[ECMAScript modules](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules).
Consider the earlier TypeScript example we showed you:

```ts title="hello.ts"
interface Person {
  firstName: string,
  lastName: string
}

function sayHello(p: Person): string {
  return `Hello, ${p.firstName}!`;
}

const ada: Person = {
  firstName: "Ada",
  lastName: "Lovelace"
};

console.log(sayHello(ada));
```

You might want to break this program up such that the `Person` interface and the
`sayHello` function are in a separate module. To do this, create a new file in
the same directory called `person.ts` and include the following code:

```ts title="person.ts"
export default interface Person {
  firstName: string,
  lastName: string
}

export function sayHello(p: Person): string {
  return `Hello, ${p.firstName}!`;
}
```

This module creates a
[named export](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules#exporting_module_features)
for the `sayHello` function, and a
[default export](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules#default_exports_versus_named_exports)
for the `Person` interface.

Back in `hello.ts`, you would consume this module using the `import` keyword.

```ts title="hello.ts"
import Person, { sayHello } from "./person.ts";

const ada: Person = {
  lastName: "Lovelace",
  firstName: "Ada",
};

console.log(sayHello(ada));
```

:::info File extensions required in imports

Note that **file extensions are required** when importing modules - import logic
in Deno works as it does in the browser, where you would include the full file
name of your imports.

:::

[You can learn more about the module system in Deno here](./basics/modules/index.md).

## Remote modules and the Deno standard library

Deno supports loading and executing code from URLs, much as you would using a
`<script>` tag in the browser. In Deno 1.x, the
[standard library](https://deno.land/std) and most
[third-party modules](https://deno.land/x) are distributed on HTTPS URLs.

To see this in action, let's create a test for the `person.ts` module we created
above. Deno provides a [built-in test runner](./basics/testing/index.md), which
uses an assertion module distributed via HTTPS URL.

```ts title="person_test.ts"
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import Person, { sayHello } from "./person.ts";

Deno.test("sayHello function", () => {
  const grace: Person = {
    lastName: "Hopper",
    firstName: "Grace",
  };

  assertEquals("Hello, Grace!", sayHello(grace));
});
```

Run this test with:

```
deno test person_test.ts
```

The output should look something like this:

```
kevin@kevin-deno scratchpad % deno test person_test.ts
Check file:///Users/kevin/dev/denoland/scratchpad/person_test.ts
running 1 test from ./person_test.ts
sayHello function ... ok (4ms)

ok | 1 passed | 0 failed (66ms)
```

There's much more to explore with [the standard library](https://deno.land/std)
and [third-party modules](https://deno.land/x) - be sure to check them out!

## Configure your project with deno.json

Deno projects don't require a configuration file by default, but sometimes it's
convenient to store settings, admin scripts, and dependency configuration in a
well-known location. In Deno, that file is
[`deno.json` or `deno.jsonc`](./getting_started/configuration_file.md). This
file acts a bit like a `package.json` file in Node.js.

One of the things you can use `deno.json` for is configuring an
[import map](./basics/import_maps.md), which will let you set up aliases for
frequently used modules. 

<p>
  To demonstrate, let's pin the version of the standard library we want to 
  use in our project to version <code>{ replacements.STD_VERSION }</code>.
</p>

Create a `deno.jsonc` file with the following contents.

```js title="deno.jsonc"
{
  "imports": {
    // The dollar sign in front of "std" isn't special - it's an optional
    // convention to show that $std is an alias set up in an import map
    "$std/": "https://deno.land/std@$STD_VERSION/"
  }
}
```

Now, open up your test file from before, and change it to use this import alias.

```ts title="person_test.ts"
import { assertEquals } from "$std/assert/mod.ts";
import Person, { sayHello } from "./person.ts";

Deno.test("sayHello function", () => {
  const grace: Person = {
    lastName: "Hopper",
    firstName: "Grace",
  };

  assertEquals("Hello, Grace!", sayHello(grace));
});
```

Running the test with `deno test person_test.ts` should work just as before, but
you might notice that Deno downloads a few extra files and generates a
`deno.lock` file, specifying a set of files depended on by your code. Both
`deno.jsonc` and `deno.lock` can be checked in to source control.

Learn more about
[configuring your project here](./getting_started/configuration_file.md).

## Node.js APIs and npm packages

Deno provides a compatibility layer that enables your code to use
[Node.js built-in modules and third-party modules from npm](./node/index.md).
Using Node and npm modules in your code looks a lot like using standard Deno
modules, except you'll use either a `node:` or `npm:` specifier when importing
Node built-ins or npm modules, respectively.

To see how it works, create a file called `server.js` and include the
following - a simple HTTP server using the popular
[Express](https://expressjs.com) framework.

```js
import express from "npm:express@4";

const app = express();

app.get("/", (request, response) => {
  response.send("Hello from Express!");
});

app.listen(3000);
```

With `node:` and `npm:` specifiers, you can bring the best of the Node.js
ecosystem with you to Deno.
[Learn more about Node and npm support](./node/index.md).

## Configure your IDE

Deno development is supported in a number of 
[major IDEs](./getting_started/setup_your_environment.md). A popular option is
**Visual Studio Code**, with an 
[official extension](./references/vscode_deno/index.md) maintained by the Deno
team. 
[Install the extension](https://marketplace.visualstudio.com/items?itemName=denoland.vscode-deno)
and enable it in your VS Code workspace by choosing the 
`Deno: Initialize Workspace Configuration` option in the 
[command palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette).

<!-- ![command palette setup](./images/command_palette.png) -->
![command palette setup](https://docs.deno.com/assets/images/command_palette-dd2a85f903f65636307b8a9d526cd773.png)


Not a VS Code user? Find an integration for your favorite editor 
[here](./getting_started/setup_your_environment.md).

## Web application frameworks

A common use case for Deno is building data-driven web applications. Doing that
usually requires use of a higher-level web framework, for which many options
exist in the Deno ecosystem. Here are a few of the most popular choices.

### Deno-native frameworks

- [Deno Fresh](https://fresh.deno.dev) - Fresh is a web framework designed for
  Deno. Pages are server-rendered by default, with the option to include
  interactive islands that run JavaScript on the client. If you're new to Deno
  and looking for a place to start, we recommend trying Fresh first!
- [Hono](https://hono.dev/getting-started/deno) - Hono is a light-weight web 
  framework in the tradition of [Express](https://expressjs.com). Great for 
  API servers and simple web applications.

### Deno-compatible frameworks

- [Astro](https://astro.build/) - Astro is a modern web framework that was
  originally designed for Node.js, but runs great on Deno as well. We recommend
  starting with
  [this template](https://github.com/denoland/deno-astro-template).
- [SvelteKit](https://kit.svelte.dev/) - SvelteKit is another more
  runtime-agnostic web framework that can be used with Deno. We recommend 
  starting with [this template](https://github.com/denoland/deno-sveltekit-template).
- [Nuxt (Vue)](https://nuxt.com/) - Nuxt is a hybrid SSR and client-side
  framework that works with Deno. We recommend 
  starting with [this template](https://github.com/denoland/deno-nuxt-template).

Many more frameworks support Deno than are listed here, but we'd recommend these
as a great starting point.

## Deploying to production

When you're ready to move into production, your easiest option will be
[Deno Deploy](/deploy/manual). Deno Deploy makes it easy to create fast,
globally distributed serverless applications with Deno.

You can also host Deno
[in almost any cloud environment](./advanced/deploying_deno/index.md).

## Next Steps

We've only just scratched the surface of what's possible with Deno. Here are a
few resources you might want to check out next.

- [Install & Setup](./getting_started/installation.md) - options for installing
  and configuring Deno
- [Tutorials and Examples](../tutorials/index.md) - Sample code and use cases
  for Deno
- [Deno by Example](https://examples.deno.land) - Code snippets to learn Deno by
  example



/. 🚀 runtime/manual/help.md
===================================================

# Where To Get Help

Stuck? Lost? Get Help from the Community.

## [Community Discord](https://discord.gg/deno)

Ask questions and chat with community members in real-time.

## [Stack Overflow](https://stackoverflow.com/questions/tagged/deno)

Stack Overflow is a popular forum to ask code-level questions or if you're stuck
with a specific error.
[ask your own!](https://stackoverflow.com/questions/ask?tags=deno)

## [DEV's Deno Community](https://dev.to/t/deno)

A great place to find interesting articles about best practices, application
architecture and new learnings. Post your articles with the tag `deno`.



/. 🚀 runtime/manual/basics/index.md
===================================================

# Basics

In this chapter, you will find Deno basics, including:

- [Modules](./modules)
- [Standard Library](./standard_library.md)
- [Permissions](./permissions.md)
- [Connecting to Databases](./connecting_to_databases.md)
- [Using React with Deno](./react.md)
- [Environment Variables](./env_variables.md)
- [Testing](./testing)
- [Debugging Your Code](./debugging_your_code.md)



/. 🚀 runtime/manual/getting_started/index.md
===================================================

# Getting Started

In this chapter we'll discuss:

- [Installing Deno](./installation.md)
- [Setting Up Your Environment](./setup_your_environment.md)
- [Running a `Hello World` Script](./first_steps.md)
- [Command Line Interface](./command_line_interface.md)
- [Configuration File](./configuration_file.md)
- [Web Frameworks](./web_frameworks.md)



/. 🚀 runtime/manual/getting_started/command_line_interface.md
===================================================

---
sidebar_position: 4
---

# Command Line Interface

Deno is a command line program. You should be familiar with some simple commands
having followed the examples thus far and already understand the basics of shell
usage.

There are multiple ways of viewing the main help text:

```shell
# Using the subcommand.
deno help

# Using the short flag -- outputs the same as above.
deno -h

# Using the long flag -- outputs more detailed help text where available.
deno --help
```

Deno's CLI is subcommand-based. The above commands should show you a list of
subcommands supported, such as `deno compile`. To see subcommand-specific help,
for example for `compile`, you can similarly run one of:

```shell
deno help compile
deno compile -h
deno compile --help
```

Detailed guides for each subcommand can be found [here](../index.mdx).

## Script source

Deno can grab the scripts from multiple sources, a filename, a url, and '-' to
read the file from stdin. The latter is useful for integration with other
applications.

```shell
deno run main.ts
deno run https://mydomain.com/main.ts
cat main.ts | deno run -
```

## Script arguments

Separately from the Deno runtime flags, you can pass user-space arguments to the
script you are running by specifying them **after** the script name:

```shell
deno run main.ts a b -c --quiet
```

```ts
// main.ts
console.log(Deno.args); // [ "a", "b", "-c", "--quiet" ]
```

**Note that anything passed after the script name will be passed as a script
argument and not consumed as a Deno runtime flag.** This leads to the following
pitfall:

```shell
# Good. We grant net permission to net_client.ts.
deno run --allow-net net_client.ts

# Bad! --allow-net was passed to Deno.args, throws a net permission error.
deno run net_client.ts --allow-net
```

Some see it as unconventional that:

> a non-positional flag is parsed differently depending on its position.

However:

1. This is the most logical and ergonomic way of distinguishing between runtime
   flags and script arguments.
2. This is, in fact, the same behaviour as that of any other popular runtime.
   - Try `node -c index.js` and `node index.js -c`. The first will only do a
     syntax check on `index.js` as per Node's `-c` flag. The second will
     _execute_ `index.js` with `-c` passed to `require("process").argv`.

---

There exist logical groups of flags that are shared between related subcommands.
We discuss these below.

## Watch mode

You can supply the `--watch` flag to `deno run`, `deno test`, `deno compile`,
and `deno fmt` to enable the built-in file watcher. The files that are watched
depend on the subcommand used:

- for `deno run`, `deno test`, and `deno compile` the entrypoint, and all local
  files the entrypoint(s) statically import(s) will be watched.
- for `deno fmt` all local files and directories specified as command line
  arguments (or the working directory if no specific files/directories is
  passed) are watched.

Whenever one of the watched files is changed on disk, the program will
automatically be restarted / formatted / tested / bundled.

```shell
deno run --watch main.ts
deno test --watch
deno fmt --watch
```

## Hot Module Replacement mode

You can use `--unstable-hmr` flag with `deno run` to enable the hot module
replacement mode. Instead of restarting the program, the runtime will try to
update the program in-place. If updating in-place fails, the program will still
be restarted.

```shell
deno run --unstable-hmr main.ts
```

When a hot module replacement is triggered, the runtime will dispatch a
`CustomEvent` of type `hmr` that will include `path` property in its `detail`
object. You can listen for this event and perform any additional logic that you
need to do when a module is updated (eg. notify a browser over a WebSocket
connection).

```ts
addEventListener("hmr", (e) => {
  console.log("HMR triggered", e.detail.path);
});
```

## Integrity flags (lock files)

Affect commands which can download resources to the cache: `deno cache`,
`deno run`, `deno test`, `deno doc`, and `deno compile`.

```terminal
--lock <FILE>    Check the specified lock file
--lock-write     Write lock file. Use with --lock.
```

Find out more about these [here](../basics/modules/integrity_checking.md).

## Cache and compilation flags

Affect commands which can populate the cache: `deno cache`, `deno run`,
`deno test`, `deno doc`, and `deno compile`. As well as the flags above, this
includes those which affect module resolution, compilation configuration etc.

```terminal
--config <FILE>               Load configuration file
--import-map <FILE>           Load import map file
--no-remote                   Do not resolve remote modules
--reload=<CACHE_BLOCKLIST>    Reload source code cache (recompile TypeScript)
--unstable                    Enable unstable APIs
```

## Runtime flags

Affect commands which execute user code: `deno run` and `deno test`. These
include all of the above as well as the following.

### Type checking flags

You can type-check your code (without executing it) using the command:

```shell
> deno check main.ts
```

You can also type-check your code before execution by using the `--check`
argument to deno run:

```shell
> deno run --check main.ts
```

This flag affects `deno run`, `deno eval`, `deno repl` and `deno cache`. The
following table describes the type-checking behavior of various subcommands.
Here "Local" means that only errors from local code will induce type-errors,
modules imported from https URLs (remote) may have type errors that are not
reported. (To turn on type-checking for all modules, use `--check=all`.)

| Subcommand     | Type checking mode |
| -------------- | ------------------ |
| `deno bench`   | 📁 Local           |
| `deno cache`   | ❌ None            |
| `deno check`   | 📁 Local           |
| `deno compile` | 📁 Local           |
| `deno eval`    | ❌ None            |
| `deno repl`    | ❌ None            |
| `deno run`     | ❌ None            |
| `deno test`    | 📁 Local           |

### Permission flags

These are listed [here](../basics/permissions.md#permissions-list).

### Other runtime flags

More flags which affect the execution environment.

```terminal
--cached-only                Require that remote dependencies are already cached
--inspect=<HOST:PORT>        activate inspector on host:port ...
--inspect-brk=<HOST:PORT>    activate inspector on host:port and break at ...
--inspect-wait=<HOST:PORT>   activate inspector on host:port and wait for ...
--location <HREF>            Value of 'globalThis.location' used by some web APIs
--prompt                     Fallback to prompt if required permission wasn't passed
--seed <NUMBER>              Seed Math.random()
--v8-flags=<v8-flags>        Set V8 command line options. For help: ...
```

## Autocomplete

You can get IDE-style autocompletions for Deno with [Fig](https://fig.io/)
<a href="https://fig.io/" target="_blank"><img src="https://fig.io/badges/Logo.svg" width="15" height="15"/></a>.
It works in bash, zsh, and fish.

To install, run:

```shell
brew install fig
```



/. 🚀 runtime/manual/getting_started/configuration_file.md
===================================================

# Configuration File

Deno supports a configuration file that allows you to customize the built-in
TypeScript compiler, formatter, and linter.

The configuration file supports `.json` and `.jsonc` extensions.
[Since v1.18](https://deno.com/blog/v1.18#auto-discovery-of-the-config-file),
Deno will automatically detect a `deno.json` or `deno.jsonc` configuration file
if it's in your current working directory or parent directories. The `--config`
flag can be used to specify a different configuration file.

:::info Version notes

- Before Deno v1.23, you needed to supply an explicit `--config` flag.
- Starting with Deno v1.34, globs are supported in `include` and `exclude`
  fields. You can use `*` to match any number of characters, `?` to match a
  single character, and `**` to match any number of directories.

:::

## `imports` and `scopes`

Since version 1.30, the `deno.json` configuration file acts as an
[import map](../basics/import_maps.md) for resolving bare specifiers.

```jsonc
{
  "imports": {
    "std/": "https://deno.land/std@$STD_VERSION/"
  },
  "tasks": {
    "dev": "deno run --watch main.ts"
  }
}
```

See [the import map section](../basics/import_maps.md) for more information on
import maps.

Then your script can use the bare specifier `std`:

```js, ignore
import { assertEquals } from "std/assert/mod.ts";

assertEquals(1, 2);
```

The top-level `deno.json` option `importMap` along with the `--importmap` flag
can be used to specify the import map in other files.

## `tasks`

Similar to `package.json`'s `script` field. Essentially shortcuts for command
line invocations.

```json
{
  "tasks": {
    "start": "deno run -A --watch=static/,routes/,data/ dev.ts"
  }
}
```

Using `deno task start` will run the command. See also
[`deno task`](../tools/task_runner.md).

## `lint`

Configuration for [`deno lint`](../tools/linter.md).

```json
{
  "lint": {
    "include": ["src/"],
    "exclude": ["src/testdata/", "data/fixtures/**/*.ts"],
    "rules": {
      "tags": ["recommended"],
      "include": ["ban-untagged-todo"],
      "exclude": ["no-unused-vars"]
    }
  }
}
```

## `fmt`

Configuration for [`deno fmt`](../tools/formatter.md)

```json
{
  "fmt": {
    "useTabs": true,
    "lineWidth": 80,
    "indentWidth": 4,
    "semiColons": true,
    "singleQuote": true,
    "proseWrap": "preserve",
    "include": ["src/"],
    "exclude": ["src/testdata/", "data/fixtures/**/*.ts"]
  }
}
```

## `lock`

Used to specify a different file name for the lockfile. By default deno will use
`deno.lock` and place it alongside the configuration file.

## `nodeModulesDir`

Used to enable or disable the `node_modules` directory when using npm packages.

## `npmRegistry`

Used to specify a custom npm registry for npm specifiers.

## `compilerOptions`

`deno.json` can also act as a TypeScript configuration file and supports
[most of the TS compiler options](https://www.typescriptlang.org/tsconfig).

Deno encourages users to use the default TypeScript configuration to help
sharing code.

See also
[Configuring TypeScript in Deno](../advanced/typescript/configuration.md).

## Full example

```json
{
  "compilerOptions": {
    "allowJs": true,
    "lib": ["deno.window"],
    "strict": true
  },
  "lint": {
    "include": ["src/"],
    "exclude": ["src/testdata/", "data/fixtures/**/*.ts"],
    "rules": {
      "tags": ["recommended"],
      "include": ["ban-untagged-todo"],
      "exclude": ["no-unused-vars"]
    }
  },
  "fmt": {
    "useTabs": true,
    "lineWidth": 80,
    "indentWidth": 4,
    "semiColons": false,
    "singleQuote": true,
    "proseWrap": "preserve",
    "include": ["src/"],
    "exclude": ["src/testdata/", "data/fixtures/**/*.ts"]
  },
  "lock": false,
  "nodeModulesDir": true,
  "npmRegistry": "https://mycompany.net/artifactory/api/npm/virtual-npm",
  "test": {
    "include": ["src/"],
    "exclude": ["src/testdata/", "data/fixtures/**/*.ts"]
  },
  "tasks": {
    "start": "deno run --allow-read main.ts"
  },
  "imports": {
    "oak": "https://deno.land/x/oak@v12.4.0/mod.ts"
  }
}
```

## JSON schema

A JSON schema file is available for editors to provide autocompletion. The file
is versioned and available at:
https://deno.land/x/deno/cli/schemas/config-file.v1.json



/. 🚀 runtime/manual/getting_started/first_steps.md
===================================================

# First Steps

This page contains some examples to teach you about the fundamentals of Deno.

This document assumes that you have some prior knowledge of JavaScript,
especially about `async`/`await`. If you have no prior knowledge of JavaScript,
you might want to follow a guide
[on the basics of JavaScript](https://developer.mozilla.org/en-US/docs/Learn/JavaScript)
before attempting to start with Deno.

## Hello World

Deno is a runtime for JavaScript/TypeScript which tries to be web compatible and
use modern features wherever possible.

Browser compatibility means a `Hello World` program in Deno is the same as the
one you can run in the browser.

Create a file locally called `first_steps.ts` and copy and paste the code line
below:

```ts
console.log("Welcome to Deno!");
```

## Running Deno programs

Now to run the program from the terminal:

```shell
deno run first_steps.ts
```

Deno also has the ability to execute scripts from URLs. Deno
[hosts a library](https://examples.deno.land/) of example code, one of which is
a `Hello World` program. To run that hosted code, do:

```shell
deno run https://examples.deno.land/hello-world.ts
```

## Making an HTTP request

Many programs use HTTP requests to fetch data from a web server. Let's write a
small program that fetches a file and prints its contents out to the terminal.
Just like in the browser you can use the web standard
[`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) API to
make HTTP calls.

In the `first_steps.ts` file you created above, paste the code below:

```ts
const res = await fetch("https://deno.com");
const body = await res.text();
console.log(body);
```

Let's walk through what this application does:

1. We make a request to the `https://deno.com`, await the response, and store it
   in the `res` constant.
1. We parse the response body as a text and store in the `body` constant.
1. We write the contents of the `body` constant to the console.

Try it out:

```shell
deno run first_steps.ts
```

Or, try this script hosted at `https://deno.land/std@0.198.0/examples/curl.ts`:

```shell
deno run https://deno.land/std@0.198.0/examples/curl.ts https://deno.com
```

The program will display a prompt like this:

```shell
┌ ⚠️  Deno requests net access to "deno.com".
├ Requested by `fetch()` API.
├ Run again with --allow-net to bypass this prompt.
└ Allow? [y/n/A] (y = yes, allow; n = no, deny; A = allow all net permissions) >
```

You might remember from the introduction that Deno is a runtime that is secure
by default. This means you need to explicitly give programs permission to do
certain 'privileged' actions, such as access the network.

You can answer 'y' to the prompt, or try it out again with the correct
permission flag:

```shell
deno run --allow-net=deno.com first_steps.ts
```

Or, using the curl script:

```shell
deno run --allow-net=deno.com https://deno.land/std@0.198.0/examples/curl.ts https://deno.com
```

## Reading a file

Deno also provides APIs that do not come from the web. These are all contained
in the `Deno` global. You can find documentation for these built-in APIs here at
[`/api`](https://deno.land/api).

Filesystem APIs for example do not have a web standard form, so Deno provides
its own API.

In this program, each command-line argument is assumed to be a filename, the
file is opened, and printed to stdout.

```ts
const filenames = Deno.args;
for (const filename of filenames) {
  const file = await Deno.open(filename);
  await file.readable.pipeTo(Deno.stdout.writable, { preventClose: true });
}
```

The `ReadableStream.pipeTo(writable)` method here actually makes no more than
the necessary kernel→userspace→kernel copies. That is, the same memory from
which data is read from the file is written to stdout. This illustrates a
general design goal for I/O streams in Deno.

Again, here, we need to give --allow-read access to the program.

Try the program:

```shell
# macOS / Linux
deno run --allow-read https://deno.land/std@0.198.0/examples/cat.ts /etc/hosts

# Windows
deno run --allow-read https://deno.land/std@0.198.0/examples/cat.ts "C:\Windows\System32\Drivers\etc\hosts"
```

## Putting it all together in an HTTP server

One of the most common use cases for Deno is building an HTTP Server.

Create a new file called `http_server.ts` and copy and paste the code below:

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

const handler = async (_request: Request): Promise<Response> => {
  const resp = await fetch("https://api.github.com/users/denoland", {
    // The init object here has a headers object containing a
    // header that indicates what type of response we accept.
    // We're not specifying the method field since by default
    // fetch makes a GET request.
    headers: {
      accept: "application/json",
    },
  });

  return new Response(resp.body, {
    status: resp.status,
    headers: {
      "content-type": "application/json",
    },
  });
};

serve(handler);
```

Let's walk through what this program does.

1. Import the http server from `std/http` (standard library)
2. HTTP servers need a handler function. This function is called for every
   request that comes in. It must return a `Response`. The handler function can
   be asynchronous (it may return a `Promise`).
3. Use `fetch` to fetch the url.
4. Return the GitHub response as a response to the handler.
5. Finally, to start the server on the default port, call `serve` with the
   handler.

Now run the server. Note that you need to give network permissions.

```shell
deno run --allow-net http_server.ts
```

With the server listening on port `8000`, make a GET request to that endpoint.

```shell
curl http://localhost:8000
```

You will see a JSON response from the Deno GitHub page.

## More examples

You can find more examples in the [Tutorials](/runtime/tutorials) section and at
[Deno by Example](https://examples.deno.land/).



/. 🚀 runtime/manual/getting_started/installation.md
===================================================

# Installation

Deno works on macOS, Linux, and Windows. Deno is a single binary executable. It
has no external dependencies. On macOS, both M1 (arm64) and Intel (x64)
executables are provided. On Linux and Windows, only x64 is supported.

## Download and install

[deno_install](https://github.com/denoland/deno_install) provides convenience
scripts to download and install the binary.

import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="macOS" default>

Using Shell:

```shell
curl -fsSL https://deno.land/x/install/install.sh | sh
```

Using [Homebrew](https://formulae.brew.sh/formula/deno):

```shell
brew install deno
```

Using [MacPorts](https://ports.macports.org/port/deno/):

```shell
sudo port install deno
```

Using [Nix](https://nixos.org/download.html):

```shell
nix-shell -p deno
```

Using [asdf](https://asdf-vm.com/):

```shell
asdf plugin-add deno https://github.com/asdf-community/asdf-deno.git
asdf install deno latest

# To install globally
asdf global deno latest

# To install locally (current project only)
asdf local deno latest
```

</TabItem>
  <TabItem  value="windows" label="Windows">

Using PowerShell (Windows):

```powershell
irm https://deno.land/install.ps1 | iex
```

Using [Scoop](https://scoop.sh/):

```shell
scoop install deno
```

Using [Chocolatey](https://chocolatey.org/packages/deno):

```shell
choco install deno
```

Using [Winget](https://github.com/microsoft/winget-cli):

```shell
winget install deno
```

</TabItem>
  <TabItem value="linux" label="Linux">

Using Shell:

```shell
curl -fsSL https://deno.land/x/install/install.sh | sh
```

Using [Nix](https://nixos.org/download.html):

```shell
nix-shell -p deno
```

Using [asdf](https://asdf-vm.com/):

```shell
asdf plugin-add deno https://github.com/asdf-community/asdf-deno.git
asdf install deno latest

# To install globally
asdf global deno latest

# To install locally (current project only)
asdf local deno latest
```

</TabItem>
</Tabs>

You can also build and install from source using
[Cargo](https://crates.io/crates/deno):

```shell
cargo install deno --locked
```

Deno binaries can also be installed manually, by downloading a zip file at
[github.com/denoland/deno/releases](https://github.com/denoland/deno/releases).
These packages contain just a single executable file. You will have to set the
executable bit on macOS and Linux.

## Docker

For more information and instructions on the official Docker images:
[https://github.com/denoland/deno_docker](https://github.com/denoland/deno_docker)

## Testing your installation

To test your installation, run `deno --version`. If this prints the Deno version
to the console the installation was successful.

Use `deno help` to see help text documenting Deno's flags and usage. Get a
detailed guide on the CLI [here](./command_line_interface.md).

## Updating

To update a previously installed version of Deno, you can run:

```shell
deno upgrade
```

Or using [Winget](https://github.com/microsoft/winget-cli) (Windows):

```shell
winget upgrade deno
```

This will fetch the latest release from
[github.com/denoland/deno/releases](https://github.com/denoland/deno/releases),
unzip it, and replace your current executable with it.

You can also use this utility to install a specific version of Deno:

```shell
deno upgrade --version 1.0.1
```

## Building from source

Information about how to build from source can be found in the
[`Contributing`](../references/contributing/building_from_source.md) chapter.



/. 🚀 runtime/manual/getting_started/setup_your_environment.md
===================================================

# Set Up Your Environment

The Deno CLI contains a lot of the tools that are commonly needed for developing
applications, including a full language server to help power your IDE of choice.
[Installing](./installation.md) is all you need to do to make these
[tools](./command_line_interface.md) available to you.

Outside using Deno with your favorite IDE, this section also documents
[shell completions](#shell-completions) and
[environment variables](#environment-variables).

## Using an editor/IDE

There is broad support for Deno in editors/IDEs. The following sections provide
information about how to use Deno with editors. Most editors integrate directly
into Deno using the Language Server Protocol and the language server that is
integrated into the Deno CLI.

If you are trying to write or support a community integration to the Deno
language server, there is some
[documentation](https://github.com/denoland/deno/tree/main/cli/lsp#deno-language-server)
located in the Deno CLI code repository, but also feel free to join the
[Discord community](https://discord.gg/deno) in the `#dev-lsp` channel.

### Visual Studio Code

There is an official extension for
[Visual Studio Code](https://code.visualstudio.com/) called
[vscode_deno](https://marketplace.visualstudio.com/items?itemName=denoland.vscode-deno).
When installed, it will connect to the language server built into the Deno CLI.

Because most people work in mixed environments, the extension does not enable a
workspace as _Deno enabled_ by default, and it requires that the `"deno.enable"`
flag to be set. You can change the settings yourself, or you can choose
`Deno: Initialize Workspace Configuration` from the command palette to enable
your project.

More information can be found in the
[Using Visual Studio Code](../references/vscode_deno/index.md) section of the
manual.

### JetBrains IDEs

You can get support for Deno in WebStorm and other
[JetBrains IDEs](https://www.jetbrains.com/products/#type=ide), including
PhpStorm, IntelliJ IDEA Ultimate, and PyCharm Professional. For this, install
the [official Deno plugin](https://plugins.jetbrains.com/plugin/14382-deno) from
_Preferences / Settings | Plugins - Marketplace_.

Check out
[this blog post](https://blog.jetbrains.com/webstorm/2020/06/deno-support-in-jetbrains-ides/)
to learn more about how to get started with Deno.

### Vim/Neovim via plugins

Deno is well-supported on both [Vim](https://www.vim.org/) and
[Neovim](https://neovim.io/) via
[coc.nvim](https://github.com/neoclide/coc.nvim),
[vim-easycomplete](https://github.com/jayli/vim-easycomplete) and
[ALE](https://github.com/dense-analysis/ale). coc.nvim offers plugins to
integrate to the Deno language server while ALE supports it _out of the box_.

### Neovim 0.6+ using the built-in language server

To use the Deno language server install
[nvim-lspconfig](https://github.com/neovim/nvim-lspconfig/) and follow the
instructions to enable the
[supplied Deno configuration](https://github.com/neovim/nvim-lspconfig/blob/master/doc/server_configurations.md#denols).

Note that if you also have `tsserver` as an LSP client, you may run into issues
where both `tsserver` and `denols` are attached to your current buffer. To
resolve this, make sure to set some unique `root_dir` for both `tsserver` and
`denols`. You may also need to set `single_file_support` to `false` for
`tsserver` to prevent it from running in `single file mode`. Here is an example
of such a configuration:

```lua
local nvim_lsp = require('lspconfig')
nvim_lsp.denols.setup {
  on_attach = on_attach,
  root_dir = nvim_lsp.util.root_pattern("deno.json", "deno.jsonc"),
}

nvim_lsp.tsserver.setup {
  on_attach = on_attach,
  root_dir = nvim_lsp.util.root_pattern("package.json"),
  single_file_support = false
}
```

For Deno, the example above assumes a `deno.json` or `deno.jsonc` file exists at
the root of the project.

#### coc.nvim

Once you have
[coc.nvim](https://github.com/neoclide/coc.nvim/wiki/Install-coc.nvim)
installed, you need to install the required
[coc-deno](https://github.com/fannheyward/coc-deno) via `:CocInstall coc-deno`.

Once the plugin is installed, and you want to enable Deno for a workspace, run
the command `:CocCommand deno.initializeWorkspace` and you should be able to
utilize commands like `gd` (goto definition) and `gr` (go/find references).

#### ALE

ALE supports Deno via the Deno language server out of the box and in many uses
cases doesn't require additional configuration. Once you have
[ALE installed](https://github.com/dense-analysis/ale#installation) you can
perform the command
[`:help ale-typescript-deno`](https://github.com/dense-analysis/ale/blob/master/doc/ale-typescript.txt)
to get information on the configuration options available.

For more information on how to setup ALE (like key bindings) refer to the
[official documentation](https://github.com/dense-analysis/ale#usage).

#### Vim-EasyComplete

Vim-EasyComplete supports Deno without any other configuration. Once you have
[vim-easycomplete installed](https://github.com/jayli/vim-easycomplete#installation),
you need install deno via `:InstallLspServer deno` if you haven't installed
deno. You can get more information from
[official documentation](https://github.com/jayli/vim-easycomplete).

### Emacs

#### lsp-mode

Emacs supports Deno via the Deno language server using
[lsp-mode](https://emacs-lsp.github.io/lsp-mode/). Once
[lsp-mode is installed](https://emacs-lsp.github.io/lsp-mode/page/installation/)
it should support Deno, which can be
[configured](https://emacs-lsp.github.io/lsp-mode/page/lsp-deno/) to support
various settings.

#### eglot

You can also use built-in Deno language server by using
[`eglot`](https://github.com/joaotavora/eglot).

An example configuration for Deno via eglot:

```elisp
(add-to-list 'eglot-server-programs '((js-mode typescript-mode) . (eglot-deno "deno" "lsp")))

  (defclass eglot-deno (eglot-lsp-server) ()
    :documentation "A custom class for deno lsp.")

  (cl-defmethod eglot-initialization-options ((server eglot-deno))
    "Passes through required deno initialization options"
    (list :enable t
    :lint t))
```

### Pulsar

The [Pulsar editor, formerly known as Atom](https://pulsar-edit.dev/) supports
integrating with the Deno language server via the
[atom-ide-deno](https://web.pulsar-edit.dev/packages/atom-ide-deno) package.
`atom-ide-deno` requires that the Deno CLI be installed and the
[atom-ide-base](https://web.pulsar-edit.dev/packages/atom-ide-base) package to
be installed as well.

### Sublime Text

[Sublime Text](https://www.sublimetext.com/) supports connecting to the Deno
language server via the [LSP package](https://packagecontrol.io/packages/LSP).
You may also want to install the
[TypeScript package](https://packagecontrol.io/packages/TypeScript) to get full
syntax highlighting.

Once you have the LSP package installed, you will want to add configuration to
your `.sublime-project` configuration like the below:

```jsonc
{
  "settings": {
    "LSP": {
      "deno": {
        "command": ["deno", "lsp"],
        "initializationOptions": {
          // "config": "", // Sets the path for the config file in your project
          "enable": true,
          // "importMap": "", // Sets the path for the import-map in your project
          "lint": true,
          "unstable": false
        },
        "enabled": true,
        "languages": [
          {
            "languageId": "javascript",
            "scopes": ["source.js"],
            "syntaxes": [
              "Packages/Babel/JavaScript (Babel).sublime-syntax",
              "Packages/JavaScript/JavaScript.sublime-syntax"
            ]
          },
          {
            "languageId": "javascriptreact",
            "scopes": ["source.jsx"],
            "syntaxes": [
              "Packages/Babel/JavaScript (Babel).sublime-syntax",
              "Packages/JavaScript/JavaScript.sublime-syntax"
            ]
          },
          {
            "languageId": "typescript",
            "scopes": ["source.ts"],
            "syntaxes": [
              "Packages/TypeScript-TmLanguage/TypeScript.tmLanguage",
              "Packages/TypeScript Syntax/TypeScript.tmLanguage"
            ]
          },
          {
            "languageId": "typescriptreact",
            "scopes": ["source.tsx"],
            "syntaxes": [
              "Packages/TypeScript-TmLanguage/TypeScriptReact.tmLanguage",
              "Packages/TypeScript Syntax/TypeScriptReact.tmLanguage"
            ]
          }
        ]
      }
    }
  }
}
```

### Nova

The [Nova editor](https://nova.app) can integrate the Deno language server via
the
[Deno extension](https://extensions.panic.com/extensions/jaydenseric/jaydenseric.deno).

### GitHub Codespaces

[GitHub Codespaces](https://github.com/features/codespaces) allows you to
develop fully online or remotely on your local machine without needing to
configure or install Deno. It is currently in early access.

If a project is a Deno enabled project and contains the `.devcontainer`
configuration as part of the repository, opening the project in GitHub
Codespaces should just "work". If you are starting a new project, or you want to
add Deno support to an existing code space, it can be added by selecting the
`Codespaces: Add Development Container Configuration Files...` from the command
pallet and then selecting `Show All Definitions...` and then searching for the
`Deno` definition.

Once selected, you will need to rebuild your container so that the Deno CLI is
added to the container. After the container is rebuilt, the code space will
support Deno.

### Kakoune

[Kakoune](http://kakoune.org/) supports connecting to the Deno language server
via the [kak-lsp](https://github.com/kak-lsp/kak-lsp) client. Once
[kak-lsp is installed](https://github.com/kak-lsp/kak-lsp#installation) an
example of configuring it up to connect to the Deno language server is by adding
the following to your `kak-lsp.toml`:

```toml
[language.typescript]
filetypes = ["typescript", "javascript"]
roots = [".git"]
command = "deno"
args = ["lsp"]
[language.typescript.settings.deno]
enable = true
lint = true
```

## Shell completions

Built into the Deno CLI is support to generate shell completion information for
the CLI itself. By using `deno completions <shell>`, the Deno CLI will output to
stdout the completions. Current shells that are supported:

- bash
- elvish
- fish
- powershell
- zsh

### bash example

Output the completions and add them to the environment:

```shell
> deno completions bash > /usr/local/etc/bash_completion.d/deno.bash
> source /usr/local/etc/bash_completion.d/deno.bash
```

### PowerShell example

Output the completions:

```shell
> deno completions powershell >> $profile
> .$profile
```

This will create a Powershell profile at
`$HOME\Documents\WindowsPowerShell\Microsoft.PowerShell_profile.ps1`, and it
will be run whenever you launch the PowerShell.

### zsh example

You should have a directory where the completions can be saved:

```shell
> mkdir ~/.zsh
```

Then output the completions:

```shell
> deno completions zsh > ~/.zsh/_deno
```

And ensure the completions get loaded in your `~/.zshrc`:

```shell
fpath=(~/.zsh $fpath)
autoload -Uz compinit
compinit -u
```

If after reloading your shell and completions are still not loading, you may
need to remove `~/.zcompdump/` to remove previously generated completions and
then `compinit` to generate them again.

### zsh example with ohmyzsh and antigen

[ohmyzsh](https://github.com/ohmyzsh/ohmyzsh) is a configuration framework for
zsh and can make it easier to manage your shell configuration.
[antigen](https://github.com/zsh-users/antigen) is a plugin manager for zsh.

Create the directory to store the completions and output the completions:

```shell
> mkdir ~/.oh-my-zsh/custom/plugins/deno
> deno completions zsh > ~/.oh-my-zsh/custom/plugins/deno/_deno
```

Then your `.zshrc` might look something like this:

```shell
source /path-to-antigen/antigen.zsh

# Load the oh-my-zsh's library.
antigen use oh-my-zsh

antigen bundle deno
```

### fish example

Output the completions to a `deno.fish` file into the completions directory in
the fish config folder:

```shell
> deno completions fish > ~/.config/fish/completions/deno.fish
```

## Environment variables

There are several environment variables which can impact the behavior of Deno:

- `DENO_AUTH_TOKENS` - a list of authorization tokens which can be used to allow
  Deno to access remote private code. See the
  [Private modules and repositories](../basics/modules/private.md) section for
  more details.
- `DENO_TLS_CA_STORE` - a list of certificate stores which will be used when
  establishing TLS connections. The available stores are `mozilla` and `system`.
  You can specify one, both or none. Certificate chains attempt to resolve in
  the same order in which you specify them. The default value is `mozilla`. The
  `mozilla` store will use the bundled Mozilla certs provided by
  [`webpki-roots`](https://crates.io/crates/webpki-roots). The `system` store
  will use your platform's
  [native certificate store](https://crates.io/crates/rustls-native-certs). The
  exact set of Mozilla certs will depend on the version of Deno you are using.
  If you specify no certificate stores, then no trust will be given to any TLS
  connection without also specifying `DENO_CERT` or `--cert` or specifying a
  specific certificate per TLS connection.
- `DENO_CERT` - load a certificate authority from a PEM encoded file. This
  "overrides" the `--cert` option. See the
  [Proxies](../basics/modules/proxies.md) section for more information.
- `DENO_DIR` - this will set the directory where cached information from the CLI
  is stored. This includes items like cached remote modules, cached transpiled
  modules, language server cache information and persisted data from local
  storage. This defaults to the operating system's default cache location and
  then under the `deno` path.
- `DENO_INSTALL_ROOT` - When using `deno install` where the installed scripts
  are stored. This defaults to `$HOME/.deno/bin`.
- `DENO_NO_PACKAGE_JSON` - Set to disable auto-resolution of package.json files.
- `DENO_NO_PROMPT` - Set to disable permission prompts on access (alternative to
  passing `--no-prompt` on invocation).
- `DENO_NO_UPDATE_CHECK` - Set to disable checking if a newer Deno version is
  available.
- `DENO_WEBGPU_TRACE` - The directory to use for WebGPU traces.
- `HTTP_PROXY` - The proxy address to use for HTTP requests. See the
  [Proxies](../basics/modules/proxies.md) section for more information.
- `HTTPS_PROXY` - The proxy address to use for HTTPS requests. See the
  [Proxies](../basics/modules/proxies.md) section for more information.
- `NO_COLOR` - If set, this will prevent the Deno CLI from sending ANSI color
  codes when writing to stdout and stderr. See the website
  <https://no-color.org/> for more information on this _de facto_ standard. The
  value of this flag can be accessed at runtime without permission to read the
  environment variables by checking the value of `Deno.noColor`.
- `NO_PROXY` - Indicates hosts which should bypass the proxy set in the other
  environment variables. See the [Proxies](../basics/modules/proxies.md) section
  for more information.
- `NPM_CONFIG_REGISTRY` - The npm registry to use when loading modules via
  [npm specifiers](../node/npm_specifiers.md)



/. 🚀 runtime/manual/getting_started/web_frameworks.md
===================================================

---
pagination_next: manual/basics/permissions
---

# Web Frameworks

Most likely, if you're building a more complex application, you'll be
interacting with Deno through a web framework. There are two kinds of web
frameworks that Deno supports:

- **Node.js native frameworks/tools/libraries.** Some of the most popular
  tooling, for example esbuild, explicitly supports both Node.js and Deno. The
  drawback here is that you might not get the best experience or performance.
- **Deno native frameworks/tools/libraries.** We present some of these below.

## Deno-native frameworks

### Fresh

[Fresh](https://fresh.deno.dev/) is the most popular web framework for Deno. It
uses a model where you send no JavaScript to clients by default. The majority of
rendering is done on a server, and the client is only responsible for
re-rendering small
[islands of interactivity](https://jasonformat.com/islands-architecture/). This
means the developer explicitly opts in to client side rendering for specific
components.

### Aleph

[Aleph.js](https://alephjs.org/docs/get-started) is the second most popular web
framework for Deno. It gives you the same sort of quick-start with React as
Create-React-App. Like Next.js, Aleph provides SSR and SSG out of the box in
order to allow developers to create SEO-friendly apps. In addition, Aleph
provides some other built-in features that don't come out of the box in Next.js,
such as:

- Hot Reloading (Using React Fast Refresh)
- ESM Import Syntax (No need for webpack)
- TypeScript-Readys

### Ultra

[Ultra](https://ultrajs.dev/) is a modern streaming React framework for Deno
that is another alternative to Aleph. It's a way to use React to build dynamic
media-rich websites, similar to Next.js.

Deno itself supports JSX and TypeScript out-of-the-box (and therefore Ultra does
as well), but they don't work in the browser. Ultra takes over the task of
transpiling JSX and TypeScript to regular JavaScript.

Other highlights of Ultra include:

- written in Deno.
- powered by import maps.
- 100% esm.
- uses import maps in both development and production, which massively
  simplifies toolchains - you don't have to deal with heaps of bundling and
  transpilation.
- source code is shipped in production, similar to how it's written.
- imports, exports, work as they do in development.

### Lume

[Lume](https://lume.land/) is a static site generator for Deno that is inspired
by other static site generators such Jekyll or Eleventy. It's simple to use and
configure, while being super flexible. Highlights include:

- Support for multiple file formats like Markdown, YAML, JavaScript, TypeScript,
  JSX, Nunjucks.
- You can hook in any processor to transform assets, for example sass or postcss
  for CSS.
- No need to install thousand of packages in `node_modules` or complex bundlers.

### Oak

[Oak](https://deno.land/x/oak) is a web application framework for Deno, similar
to Express in Node.js.

As a middleware framework, Oak is the glue between your frontend application and
a potential database or other data sources (e.g. REST APIs, GraphQL APIs). Just
to give you an idea, the following is a list of common tech stacks to build
client-server architectures:

- React.js (Frontend) + Oak (Backend) + PostgreSQL (Database)
- Vue.js (Frontend) + Oak (Backend) + MongoDB (Database)
- Angular.js (Frontend) + Oak (Backend) + Neo4j (Database)

Oak offers additional functionality over the native Deno HTTP server, including
a basic router, JSON parser, middlewares, plugins, etc.



/. 🚀 runtime/manual/basics/permissions.md
===================================================

# Permissions

Deno is secure by default. Therefore, unless you specifically enable it, a
program run with Deno has no file, network, or environment access. Access to
security sensitive functionality requires that permissions have been granted to
an executing script through command line flags, or a runtime permission prompt.
This is a major difference from Node, where dependencies are automatically
granting full access to everything, introducing hidden vulnerabilities in your
project.

## Run untrusted code with confidence

Since Deno provides no I/O access by default, it's useful for running untrusted
code and auditing third-party code. If you're building or extending a platform
that runs user generated code, you can use Deno for running third-party code
securely and host this code through
[Deno Subhosting](https://deno.com/subhosting) or any other cloud platform of
your choice.

For the following example `mod.ts` has been granted read-only access to the file
system. It cannot write to the file system, or perform any other security
sensitive functions.

```shell
deno run --allow-read mod.ts
```

## Permissions list

The following permissions are available:

- **--allow-env=\<VARIABLE_NAME\>** Allow environment access for things like
  getting and setting of environment variables. Since Deno 1.9, you can specify
  an optional, comma-separated list of environment variables to provide an
  allow-list of allowed environment variables.
- **--allow-sys=\<API_NAME\>** Allow access to APIs that provide information
  about user's operating system, eg. `Deno.osRelease()` and
  `Deno.systemMemoryInfo()`. You can specify a comma-separated list of allowed
  interfaces from the following list: `hostname`, `osRelease`, `osUptime`,
  `loadavg`, `networkInterfaces`, `systemMemoryInfo`, `uid`, and `gid`. These
  strings map to functions in the `Deno` namespace that provide OS info, like
  [Deno.systemMemoryInfo](https://deno.land/api?s=Deno.SystemMemoryInfo).
- **--allow-hrtime** Allow high-resolution time measurement. High-resolution
  time can be used in timing attacks and fingerprinting.
- **--allow-net=\<IP/HOSTNAME\>** Allow network access. You can specify an
  optional, comma-separated list of IP addresses or hostnames (optionally with
  ports) to provide an allow-list of allowed network addresses.
- **--allow-ffi=\<PATH\>** Allow loading of dynamic libraries. You can specify
  an optional, comma-separated list of directories or files to provide an
  allow-list of allowed dynamic libraries to load. Be aware that dynamic
  libraries are not run in a sandbox and therefore do not have the same security
  restrictions as the Deno process. Therefore, use with caution. Please note
  that --allow-ffi is an unstable feature.
- **--allow-read=\<PATH\>** Allow file system read access. You can specify an
  optional, comma-separated list of directories or files to provide an
  allow-list of allowed file system access.
- **--allow-run=\<PROGRAM_NAME\>** Allow running subprocesses. Since Deno 1.9,
  You can specify an optional, comma-separated list of subprocesses to provide
  an allow-list of allowed subprocesses. Be aware that subprocesses are not run
  in a sandbox and therefore do not have the same security restrictions as the
  Deno process. Therefore, use with caution.
- **--allow-write=\<PATH\>** Allow file system write access. You can specify an
  optional, comma-separated list of directories or files to provide an
  allow-list of allowed file system access.
- **-A, --allow-all** Allow all permissions. This enables all security sensitive
  functions. Use with caution.

Starting with Deno 1.36 following flags are available:

- **--deny-env=\<VARIABLE_NAME\>** Deny environment access for things like
  getting and setting of environment variables. You can specify an optional,
  comma-separated list of environment variables to provide an allow-list of
  allowed environment variables. Any environment variables specified here will
  be denied access, even if they are specified in --allow-env.
- **--deny-sys=\<API_NAME\>** Deny access to APIs that provide information about
  user's operating system.
- **--deny-hrtime** Disable high-resolution time measurement. High-resolution
  time can be used in timing attacks and fingerprinting.
- **--deny-net=\<IP/HOSTNAME\>** Disable network access. You can specify an
  optional, comma-separated list of IP addresses or hostnames (optionally with
  ports) to provide a deny-list of network addresses. Any addresses specified
  here will be denied access, even if they are specified in --allow-net.
- **--deny-ffi=\<PATH\>** Deny loading of dynamic libraries. You can specify an
  optional, comma-separated list of directories or files to provide a deny-list
  of allowed dynamic libraries to load. Any libraries specified here will be
  denied access, even if they are specified in --allow-ffi. Please note that
  --deny-ffi is an unstable feature.
- **--deny-read=\<PATH\>** Deny file system read access. You can specify an
  optional, comma-separated list of directories or files to provide a deny-list
  of allowed file system access. Any paths specified here will be denied access,
  even if they are specified in --allow-read.
- **--deny-run=\<PROGRAM_NAME\>** Deny running subprocesses. You can specify an
  optional, comma-separated list of subprocesses to provide a deny-list of
  allowed subprocesses. Be aware that subprocesses are not run in a sandbox and
  therefore do not have the same security restrictions as the Deno process.
  Therefore, use with caution. Any programs specified here will be denied
  access, even if they are specified in --allow-run.
- **--deny-write=\<PATH\>** Deny file system write access. You can specify an
  optional, comma-separated list of directories or files to provide a deny-list
  of allowed file system access. Any paths specified here will be denied access,
  even if they are specified in --allow-write.

## Configurable permissions

Some permissions allow you to grant access to a specific list of entities
(files, servers, etc) rather than to everything.

### File system access

This example restricts file system access by allowing read-only access to the
`/usr` directory. In consequence the execution fails as the process was
attempting to read a file in the `/etc` directory:

```shell
$ deno run --allow-read=/usr https://deno.land/std@0.198.0/examples/cat.ts /etc/passwd
error: Uncaught PermissionDenied: read access to "/etc/passwd", run again with the --allow-read flag
► $deno$/dispatch_json.ts:40:11
    at DenoError ($deno$/errors.ts:20:5)
    ...
```

Try it out again with the correct permissions by allowing access to `/etc`
instead:

```shell
deno run --allow-read=/etc https://deno.land/std@0.198.0/examples/cat.ts /etc/passwd
```

You can further restrict some sub-paths to not be accessible, using
`--deny-read` flag:

```shell
deno run --allow-read=/etc --deny-read=/etc/hosts https://deno.land/std@0.198.0/examples/cat.ts /etc/passwd
deno run --allow-read=/etc --deny-read=/etc/hosts https://deno.land/std@0.198.0/examples/cat.ts /etc/hosts
error: Uncaught PermissionDenied: read access to "/etc/hosts"...
```

`--allow-write` works the same as `--allow-read`.

> Note for Windows users: the `/etc` and `/usr` directories and the
> `/etc/passwd` file do not exist on Windows. If you want to run this example
> yourself, replace `/etc/passwd` with `C:\Windows\System32\Drivers\etc\hosts`,
> and `/usr` with `C:\Users`.

### Network access

```js
// fetch.js
const result = await fetch("https://deno.land/");
```

This is an example of how to allow network access to specific hostnames or IP
addresses, optionally locked to a specified port:

```shell
# Multiple hostnames, all ports allowed
deno run --allow-net=github.com,deno.land fetch.js

# A hostname at port 80:
deno run --allow-net=deno.land:80 fetch.js

# An IPv4 address on port 443
deno run --allow-net=1.1.1.1:443 fetch.js

# An IPv6 address, all ports allowed
deno run --allow-net=[2606:4700:4700::1111] fetch.js
```

You can restrict certain domains to never be accessible by using the
`--deny-net` flag:

```shell
# Allow to make network connections to all addresses except myserver.com.
deno run --allow-net --deny-net=myserver.com fetch.js
```

If `fetch.js` tries to establish network connections to any hostname or IP not
explicitly allowed, the relevant call will throw an exception.

Allow net calls to any hostname/IP:

```shell
deno run --allow-net fetch.js
```

### Environment variables

```js
// env.js
Deno.env.get("HOME");
```

This is an example of how to allow access to environment variables:

```shell
# Allow all environment variables
deno run --allow-env env.js

# Allow access to only the HOME env var
deno run --allow-env=HOME env.js
```

> Note for Windows users: environment variables are case insensitive on Windows,
> so Deno also matches them case insensitively (on Windows only).

You can restrict certain env vars to never be accessible by using the
`--deny-env` flag:

```shell
# Allow all environment variables except AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.
deno run --allow-env --deny-env=AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY env.js
```

### Subprocess permissions

Subprocesses are very powerful, and can be a little scary: they access system
resources regardless of the permissions you granted to the Deno process that
spawns them. The `cat` program on unix systems can be used to read files from
disk. If you start this program through the `Deno.run` API it will be able to
read files from disk even if the parent Deno process can not read the files
directly. This is often referred to as privilege escalation.

Because of this, make sure you carefully consider if you want to grant a program
`--allow-run` access: it essentially invalidates the Deno security sandbox. If
you really need to spawn a specific executable, you can reduce the risk by
limiting which programs a Deno process can start by passing specific executable
names to the `--allow-run` flag.

```js
// run.js
const proc = Deno.run({ cmd: ["whoami"] });
```

```shell
# Allow only spawning a `whoami` subprocess:
deno run --allow-run=whoami run.js

# Allow running any subprocess:
deno run --allow-run run.js
```

You can only limit the executables that are allowed; if permission is granted to
execute it then any parameters can be passed. For example if you pass
`--allow-run=cat` then the user can use `cat` to read any file.

You can restrict certain executables to never be accessible by using the
`--deny-run` flag:

```shell
# Disallow spawning `git`.
deno run --allow-run --deny-run=git run.js
```



/. 🚀 runtime/manual/basics/standard_library.md
===================================================

# Standard Library

Deno provides a set of standard modules that are audited by the core team and
are guaranteed to work with Deno.

Standard library is available at: https://deno.land/std

## Versioning and stability

Standard library is not yet stable and therefore it is versioned differently
than Deno. For latest release consult https://deno.land/std or
https://deno.land/std/version.ts. The standard library is released each time
Deno is released.

We strongly suggest to always use imports with pinned version of standard
library to avoid unintended changes. For example, rather than linking to the
default branch of code, which may change at any time, potentially causing
compilation errors or unexpected behavior:

```typescript
// import the latest release, this should be avoided
import { copy } from "https://deno.land/std/fs/copy.ts";
```

instead, use a version of the std library which is immutable and will not
change:

```typescript
// imports from v$STD_VERSION of std, never changes
import { copy } from "https://deno.land/std@$STD_VERSION/fs/copy.ts";
```



/. 🚀 runtime/manual/basics/env_variables.md
===================================================

# Environment variables

There are a few ways to use environment variables in Deno:

## Built-in `Deno.env`

The Deno runtime offers built-in support for environment variables with
[`Deno.env`](https://deno.land/api@v1.25.3?s=Deno.env).

`Deno.env` has getter and setter methods. Here is example usage:

```ts
Deno.env.set("FIREBASE_API_KEY", "examplekey123");
Deno.env.set("FIREBASE_AUTH_DOMAIN", "firebasedomain.com");

console.log(Deno.env.get("FIREBASE_API_KEY")); // examplekey123
console.log(Deno.env.get("FIREBASE_AUTH_DOMAIN")); // firebasedomain.com
console.log(Deno.env.has("FIREBASE_AUTH_DOMAIN")); // true
```

## `.env` file

You can also put environment variables in a `.env` file and retrieve them using
`dotenv` in the standard library.

Let's say you have an `.env` file that looks like this:

```sh
PASSWORD=Geheimnis
```

To access the environment variables in the `.env` file, import the `load`
function from the standard library. Then, import the configuration using it.

```ts
import { load } from "https://deno.land/std@$STD_VERSION/dotenv/mod.ts";

const env = await load();
const password = env["PASSWORD"];

console.log(password);
// "Geheimnis"
```

## `std/flags`

The Deno standard library has a
[`std/flags` module](https://deno.land/std/flags/mod.ts) for parsing command
line arguments.

## Special environment variables

The Deno runtime has these special environment variables.

| name                 | description                                                                                                                                                                       |
| -------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| DENO_AUTH_TOKENS     | A semi-colon separated list of bearer tokens and hostnames to use when fetching remote modules from private repositories<br />(e.g. `abcde12345@deno.land;54321edcba@github.com`) |
| DENO_TLS_CA_STORE    | Comma-separated list of order dependent certificate stores.<br />Possible values: `system`, `mozilla`. Defaults to `mozilla`.                                                     |
| DENO_CERT            | Load certificate authority from PEM encoded file                                                                                                                                  |
| DENO_DIR             | Set the cache directory                                                                                                                                                           |
| DENO_INSTALL_ROOT    | Set deno install's output directory (defaults to `$HOME/.deno/bin`)                                                                                                               |
| DENO_REPL_HISTORY    | Set REPL history file path History file is disabled when the value is empty <br />(defaults to `$DENO_DIR/deno_history.txt`)                                                      |
| DENO_NO_PACKAGE_JSON | Disables auto-resolution of `package.json`                                                                                                                                        |
| DENO_NO_PROMPT       | Set to disable permission prompts on access<br />(alternative to passing `--no-prompt` on invocation)                                                                             |
| DENO_NO_UPDATE_CHECK | Set to disable checking if a newer Deno version is available                                                                                                                      |
| DENO_V8_FLAGS        | Set V8 command line options                                                                                                                                                       |
| DENO_JOBS            | Number of parallel workers used for the `--parallel` flag with the test subcommand.<br />Defaults to number of available CPUs.                                                    |
| HTTP_PROXY           | Proxy address for HTTP requests (module downloads, fetch)                                                                                                                         |
| HTTPS_PROXY          | Proxy address for HTTPS requests (module downloads, fetch)                                                                                                                        |
| NPM_CONFIG_REGISTRY  | URL to use for the npm registry.                                                                                                                                                  |
| NO_COLOR             | Set to disable color                                                                                                                                                              |
| NO_PROXY             | Comma-separated list of hosts which do not use a proxy (module downloads, fetch)                                                                                                  |

You can also view the same content with `deno --help`.



/. 🚀 runtime/manual/basics/import_maps.md
===================================================

# Import Maps

In order for Deno to resolve a _bare specifier_ like `"react"` or `"lodash"`, it
needs to be told where to look for it. Does `"lodash"` refer to an npm module or
does it map to an https URL?

```ts, ignore
import lodash from "lodash";
```

Node and npm use `package.json` and the `node_modules` folder to do this
resolution. Deno, on the other hand, uses the
[import map](https://github.com/WICG/import-maps) standard.

To make the above `import lodash from "lodash"` work, add the following to the
[`deno.json` configuration file](../getting_started/configuration_file.md).

```json
{
  "imports": {
    "lodash": "https://esm.sh/lodash@4.17.21"
  }
}
```

The `deno.json` file is auto-discovered and acts (among other things) as an
import map.
[Read more about `deno.json` here](../getting_started/configuration_file.md).

This also works with npm specifiers. Instead of the above, we could have also
written something similar in our `deno.json` configuration file:

```json
{
  "imports": {
    "lodash": "npm:lodash@^4.17"
  }
}
```

## Example - Using deno_std's fmt module via `fmt/`

```json title="deno.json"
{
  "imports": {
    "fmt/": "https://deno.land/std@$STD_VERSION/fmt/"
  }
}
```

```ts title="color.ts"
import { red } from "fmt/colors.ts";

console.log(red("hello world"));
```

## Example - Using project root for absolute imports

To use your project root for absolute imports:

```json title="deno.json"
{
  "imports": {
    "/": "./",
    "./": "./"
  }
}
```

```ts title="main.ts"
import { MyUtil } from "/util.ts";
```

This causes import specifiers starting with `/` to be resolved relative to the
import map's URL or file path.

## Overriding imports

The other situation where import maps can be very useful is to override imports
in specific modules.

Let's say you want to override the deno_std import from 0.177.0 to the latest in
all of your imported modules, but for the `https://deno.land/x/example/` module
you want to use files in a local `patched` directory. You can do this by using a
scope in the import map that looks something like this:

```json
{
  "imports": {
    "https://deno.land/std@0.177.0/": "https://deno.land/std@$STD_VERSION/"
  },
  "scopes": {
    "https://deno.land/x/example/": {
      "https://deno.land/std@0.177.0/": "./patched/"
    }
  }
}
```

## Import Maps are for Applications

It is important to note that import map configuration files are
[only applied for Deno applications][scope], not in the various libraries that
your application code may import. This lets you, the application author, have
final say about what versions of libraries get included in your project.

If you are developing a library, you should instead prefer to use the `deps.ts`
pattern discussed in [Managing Dependencies].

[scope]: https://github.com/WICG/import-maps#scope
[Managing Dependencies]: ../../tutorials/manage_dependencies.md



/. 🚀 runtime/manual/basics/debugging_your_code.md
===================================================

# Debugging Your Code

Deno supports the [V8 Inspector Protocol](https://v8.dev/docs/inspector) used by
Chrome, Edge and Node.js. This makes it possible to debug Deno programs using
Chrome DevTools or other clients that support the protocol (for example VSCode).

To activate debugging capabilities run Deno with the `--inspect`,
`--inspect-wait` or `--inspect-brk` flags.

The `--inspect` flag allows attaching the debugger at any point in time,
`--inspect-wait` will wait for debugger to attach and start executing code,
while `--inspect-brk` will wait for the debugger to attach and will pause
execution on the first line of code.

> ⚠️ If you use `--inspect` flag, the code will start executing immediately. If
> your program is short, you might not have enough time to connect the debugger
> before the program finishes execution. In such cases, try running with
> `--inspect-wait` or `--inspect-brk` flag instead, or add a timeout at the end
> of your code.

## Chrome Devtools

Let's try debugging a program using Chrome Devtools. For this, we'll use
[file_server.ts](https://deno.land/std/http/file_server.ts) from `std`, a static
file server.

Use the `--inspect-brk` flag to break execution on the first line:

```shell
$ deno run --inspect-brk --allow-read --allow-net https://deno.land/std@$STD_VERSION/http/file_server.ts
Debugger listening on ws://127.0.0.1:9229/ws/1e82c406-85a9-44ab-86b6-7341583480b1
Download https://deno.land/std@$STD_VERSION/http/file_server.ts
Compile https://deno.land/std@$STD_VERSION/http/file_server.ts
...
```

In a Chromium derived browser such as Google Chrome or Microsoft Edge, open
`chrome://inspect` and click `Inspect` next to target:

![chrome://inspect](https://docs.deno.com/assets/images/debugger2-391f30776ae57a27d27a32c3fc58d6e3.jpg)
<!-- ![chrome://inspect](../images/debugger1.jpg) -->

It might take a few seconds after opening the DevTools to load all modules.

![DevTools opened](https://docs.deno.com/assets/images/debugger2-391f30776ae57a27d27a32c3fc58d6e3.jpg)
<!-- ![DevTools opened](../images/debugger2.jpg) -->

You might notice that DevTools pauses execution on the first line of
`_constants.ts` instead of `file_server.ts`. This is expected behavior caused by
the way ES modules are evaluated in JavaScript (`_constants.ts` is left-most,
bottom-most dependency of `file_server.ts` so it is evaluated first).

At this point all source code is available in the DevTools, so let's open up
`file_server.ts` and add a breakpoint there; go to "Sources" pane and expand the
tree:

![Open file_server.ts](https://docs.deno.com/assets/images/debugger3-bd89269a568e9c71dce86723655de75f.jpg)
<!-- ![Open file_server.ts](../images/debugger3.jpg) -->

_Looking closely you'll find duplicate entries for each file; one written
regularly and one in italics. The former is compiled source file (so in the case
of `.ts` files it will be emitted JavaScript source), while the latter is a
source map for the file._

Next, add a breakpoint in the `listenAndServe` method:

![Break in file_server.ts](https://docs.deno.com/assets/images/debugger4-ad620845f4400f7a26f9483dd0617913.jpg)
<!-- ![Break in file_server.ts](../images/debugger4.jpg) -->

As soon as we've added the breakpoint, DevTools automatically opens up the
source map file, which allows us step through the actual source code that
includes types.

Now that we have our breakpoints set, we can resume the execution of our script
so that we can inspect an incoming request. Hit the "Resume script execution"
button to do so. You might even need to hit it twice!

Once our script is running, try send a request and inspect it in Devtools:

```
$ curl http://0.0.0.0:4507/
```

![Break in request handling](https://docs.deno.com/assets/images/debugger5-a7a90f533f7d921b690ac5db709238ca.jpg)
<!-- ![Break in request handling](../images/debugger5.jpg) -->

At this point we can introspect the contents of the request and go step-by-step
to debug the code.

## VSCode

Deno can be debugged using VSCode. This is best done with help from the official
`vscode_deno` extension. Documentation for this can be found
[here](../references/vscode_deno#using-the-debugger).

## JetBrains IDEs

_**Note**: make sure you have
[this Deno plugin](https://plugins.jetbrains.com/plugin/14382-deno) installed
and enabled in Preferences / Settings | Plugins. For more information, see
[this blog post](https://blog.jetbrains.com/webstorm/2020/06/deno-support-in-jetbrains-ides/)._

You can debug Deno using your JetBrains IDE by right-clicking the file you want
to debug and selecting the `Debug 'Deno: <file name>'` option.

![Debug file](https://docs.deno.com/assets/images/jb-ide-debug-6d6eb72fefc9e9bf9710249343993560.png)
<!-- ![Debug file](../images/jb-ide-debug.png) -->

This will create a run/debug configuration with no permission flags set. If you
want to configure them, open your run/debug configuration and add the required
flags to the `Command` field.

## Other

Any client that implements the DevTools protocol should be able to connect to a
Deno process.



/. 🚀 runtime/manual/basics/connecting_to_databases.md
===================================================

# Connecting to databases

The Deno community has published a number of third-party modules that make it
easy to connect to popular databases like MySQL, Postgres, and MongoDB.

They are hosted at Deno's third-party module site
[deno.land/x](https://deno.land/x).

## MySQL

[deno_mysql](https://deno.land/x/mysql) is a MySQL and MariaDB database driver
for Deno.

### Connect to MySQL with deno_mysql

```ts, ignore
import { Client } from "https://deno.land/x/mysql/mod.ts";

const client = await new Client().connect({
  hostname: "127.0.0.1",
  username: "root",
  db: "dbname",
  password: "password",
});
```

## Postgres

[postgresjs](https://deno.land/x/postgresjs) is a full featured Postgres client
for Node.js and Deno.

### Connect to Postgres with postgresjs

```js, ignore
import postgres from "https://deno.land/x/postgresjs/mod.js";

const sql = postgres("postgres://username:password@host:port/database");
```

## MongoDB

[deno_mongo](https://deno.land/x/mongo) is a MongoDB database driver developed
for Deno.

### Connect to MongoDB with deno_mongo

```ts, ignore
import { MongoClient } from "https://deno.land/x/mongo@LATEST_VERSION/mod.ts";

const client = new MongoClient();

// Connecting to a Local Database
await client.connect("mongodb://127.0.0.1:27017");

// Connecting to a Mongo Atlas Database
await client.connect({
  db: "<db_name>",
  tls: true,
  servers: [
    {
      host: "<db_cluster_url>",
      port: 27017,
    },
  ],
  credential: {
    username: "<username>",
    password: "<password>",
    db: "<db_name>",
    mechanism: "SCRAM-SHA-1",
  },
});

// Connect using srv url
await client.connect(
  "mongodb+srv://<username>:<password>@<db_cluster_url>/<db_name>?authMechanism=SCRAM-SHA-1",
);
```

## SQLite

There are two primary solutions to connect to SQLite in Deno:

### Connect to SQLite with the FFI Module

[sqlite3](https://deno.land/x/sqlite3) provides JavaScript bindings to the
SQLite3 C API, using [Deno FFI](../runtime/ffi_api.md).

```ts, ignore
import { Database } from "https://deno.land/x/sqlite3@LATEST_VERSION/mod.ts";

const db = new Database("test.db");

db.close();
```

### Connect to SQLite with the WASM-Optimized Module

[sqlite](https://deno.land/x/sqlite) is a SQLite module for JavaScript and
TypeScript. The wrapper made specifically for Deno and uses a version of SQLite3
compiled to WebAssembly (WASM).

```ts, ignore
import { DB } from "https://deno.land/x/sqlite/mod.ts";

const db = new DB("test.db");

db.close();
```

## Firebase

To connect to Firebase with Deno, import the
[firestore npm module](https://firebase.google.com/docs/firestore/quickstart)
with the [skypak CDN](https://www.skypack.dev/). To learn more about using npm
modules in Deno with a CDN, see [Using npm packages with CDNs](../node/cdns.md).

### Connect to Firebase with the firestore npm module

```js, ignore
import { initializeApp } from "https://www.gstatic.com/firebasejs/9.8.1/firebase-app.js";

import {
  addDoc,
  collection,
  connectFirestoreEmulator,
  deleteDoc,
  doc,
  Firestore,
  getDoc,
  getDocs,
  getFirestore,
  query,
  QuerySnapshot,
  setDoc,
  where,
} from "https://www.gstatic.com/firebasejs/9.8.1/firebase-firestore.js";

import { getAuth } from "https://www.gstatic.com/firebasejs/9.8.1/firebase-auth.js";

const app = initializeApp({
  apiKey: Deno.env.get("FIREBASE_API_KEY"),
  authDomain: Deno.env.get("FIREBASE_AUTH_DOMAIN"),
  projectId: Deno.env.get("FIREBASE_PROJECT_ID"),
  storageBucket: Deno.env.get("FIREBASE_STORAGE_BUCKET"),
  messagingSenderId: Deno.env.get("FIREBASE_MESSING_SENDER_ID"),
  appId: Deno.env.get("FIREBASE_APP_ID"),
  measurementId: Deno.env.get("FIREBASE_MEASUREMENT_ID"),
});
const db = getFirestore(app);
const auth = getAuth(app);
```

## Supabase

To connect to Supabase with Deno, import the
[supabase-js npm module](https://supabase.com/docs/reference/javascript) with
the [esm.sh CDN](https://esm.sh/). To learn more about using npm modules in Deno
with a CDN, see [Using npm packages with CDNs](../node/cdns.md).

### Connect to Supabase with the supabase-js npm module

```js, ignore
import { createClient } from "https://esm.sh/@supabase/supabase-js";

const options = {
  schema: "public",
  headers: { "x-my-custom-header": "my-app-name" },
  autoRefreshToken: true,
  persistSession: true,
  detectSessionInUrl: true,
};

const supabase = createClient(
  "https://xyzcompany.supabase.co",
  "public-anon-key",
  options,
);
```

## ORMs

Object-Relational Mappings (ORM) define your data models as classes that you can
persist to a database. You can read and write data in your database through
instances of these classes.

Deno supports multiple ORMs, including Prisma and DenoDB.

### DenoDB

[DenoDB](https://deno.land/x/denodb) is a Deno-specific ORM.

#### Connect to DenoDB

```ts, ignore
import {
  Database,
  DataTypes,
  Model,
  PostgresConnector,
} from "https://deno.land/x/denodb/mod.ts";

const connection = new PostgresConnector({
  host: "...",
  username: "user",
  password: "password",
  database: "airlines",
});

const db = new Database(connection);
```

## GraphQL

GraphQL is an API query language often used to compose disparate data sources
into client-centric APIs. To set up a GraphQL API, you should first set up a
GraphQL server. This server exposes your data as a GraphQL API that your client
applications can query for data.

### Server

You can use [gql](https://deno.land/x/gql), an universal GraphQL HTTP middleware
for Deno, to run a GraphQL API server in Deno.

#### Run a GraphQL API server with gql

```ts, ignore
import { Server } from "https://deno.land/std@$STD_VERSION/http/server.ts";
import { GraphQLHTTP } from "https://deno.land/x/gql/mod.ts";
import { makeExecutableSchema } from "https://deno.land/x/graphql_tools@0.0.2/mod.ts";
import { gql } from "https://deno.land/x/graphql_tag@0.0.1/mod.ts";

const typeDefs = gql`
  type Query {
    hello: String
  }
`;

const resolvers = {
  Query: {
    hello: () => `Hello World!`,
  },
};

const schema = makeExecutableSchema({ resolvers, typeDefs });

const s = new Server({
  handler: async (req) => {
    const { pathname } = new URL(req.url);

    return pathname === "/graphql"
      ? await GraphQLHTTP<Request>({
        schema,
        graphiql: true,
      })(req)
      : new Response("Not Found", { status: 404 });
  },
  port: 3000,
});

s.listenAndServe();

console.log(`Started on http://localhost:3000`);
```

### Client

To make GraphQL client calls in Deno, import the
[graphql npm module](https://www.npmjs.com/package/graphql) with the
[esm CDN](https://esm.sh/). To learn more about using npm modules in Deno via
CDN read [here](../node/cdns.md).

#### Make GraphQL client calls with the graphql npm module

```js, ignore
import { buildSchema, graphql } from "https://esm.sh/graphql";

const schema = buildSchema(`
type Query {
  hello: String
}
`);

const rootValue = {
  hello: () => {
    return "Hello world!";
  },
};

const response = await graphql({
  schema,
  source: "{ hello }",
  rootValue,
});

console.log(response);
```



/. 🚀 runtime/manual/basics/react.md
===================================================

# Using React with Deno

To use React with Deno, we recommend using one of the third-party frameworks
below.

If you want to better understand how JSX and Deno interface under the hood, read
on [here](../advanced/jsx_dom).

Note: Fresh and Aleph.js provide a framework for developing React-like websites.
However, Fresh uses an alternative foundational technology, Preact to provide a
better, more performant experience.

## Fresh

[Fresh](https://fresh.deno.dev/) is the most popular React framework for Deno.
It uses a model where you send no JavaScript to clients by default. The majority
of rendering is done on a server, and the client is only responsible for
re-rendering small
[islands of interactivity](https://jasonformat.com/islands-architecture/). This
means the developer explicitly opts in to client side rendering for specific
components.

## Aleph

[Aleph.js](https://alephjs.org/docs/get-started) is the second most popular
React framework for Deno. It gives you the same sort of quick-start with React
as Create-React-App. Like Next.js, Aleph provides SSR and SSG out of the box in
order to allow developers to create SEO-friendly apps. In addition, Aleph
provides some other built-in features that don't come out of the box in Next.js,
such as:

- Hot Reloading (Using React Fast Refresh)
- ESM Import Syntax (No need for webpack)
- TypeScript-Ready



/. 🚀 runtime/manual/basics/modules/index.md
===================================================

# ECMAScript Modules in Deno

## Concepts

- [import](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import)
  allows you to include and use modules held elsewhere, on your local file
  system or remotely.
- Imports are URLs or file system paths.
- [export](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/export)
  allows you to specify which parts of your module are accessible to users who
  import your module.

## Overview

Deno by default standardizes the way modules are imported in both JavaScript and
TypeScript using the ECMAScript 6 `import/export` standard.

It adopts browser-like module resolution, meaning that file names must be
specified in full. You may not omit the file extension and there is no special
handling of `index.js`.

```js, ignore
import { add, multiply } from "./arithmetic.ts";
```

Dependencies are also imported directly, there is no package management
overhead. Local modules are imported in exactly the same way as remote modules.
As the examples show below, the same functionality can be produced in the same
way with local or remote modules.

## Local Import

In this example the `add` and `multiply` functions are imported from a local
`arithmetic.ts` module.

**Command:** `deno run local.ts`

```ts, ignore
/**
 * local.ts
 */
import { add, multiply } from "./arithmetic.ts";

function totalCost(outbound: number, inbound: number, tax: number): number {
  return multiply(add(outbound, inbound), tax);
}

console.log(totalCost(19, 31, 1.2));
console.log(totalCost(45, 27, 1.15));

/**
 * Output
 *
 * 60
 * 82.8
 */
```

## Remote Import

In the local import example above an `add` and `multiply` method are imported
from a locally stored arithmetic module. The same functionality can be created
by importing `add` and `multiply` methods from a remote module too.

In this case the Ramda module is referenced, including the version number. Also
note a JavaScript module is imported directly into a TypeScript module, Deno has
no problem handling this.

**Command:** `deno run ./remote.ts`

```ts
/**
 * remote.ts
 */
import {
  add,
  multiply,
} from "https://x.nest.land/ramda@0.27.0/source/index.js";

function totalCost(outbound: number, inbound: number, tax: number): number {
  return multiply(add(outbound, inbound), tax);
}

console.log(totalCost(19, 31, 1.2));
console.log(totalCost(45, 27, 1.15));

/**
 * Output
 *
 * 60
 * 82.8
 */
```

## Export

In the local import example above the `add` and `multiply` functions are
imported from a locally stored arithmetic module. To make this possible the
functions stored in the arithmetic module must be exported.

To do this just add the keyword `export` to the beginning of the function
signature as is shown below.

```ts
/**
 * arithmetic.ts
 */
export function add(a: number, b: number): number {
  return a + b;
}

export function multiply(a: number, b: number): number {
  return a * b;
}
```

All functions, classes, constants and variables which need to be accessible
inside external modules must be exported. Either by prepending them with the
`export` keyword or including them in an export statement at the bottom of the
file.

## FAQ

### How do I import a specific version of a module?

Specify the version in the URL. For example, this URL fully specifies the code
being run: `https://unpkg.com/liltest@0.0.5/dist/liltest.js`.

### It seems unwieldy to import URLs everywhere.

> What if one of the URLs links to a subtly different version of a library?

> Isn't it error prone to maintain URLs everywhere in a large project?

The solution is to import and re-export your external libraries in a central
`deps.ts` file (which serves the same purpose as Node's `package.json` file).
For example, let's say you were using the above assertion library across a large
project. Rather than importing `"https://deno.land/std/assert/mod.ts"`
everywhere, you could create a `deps.ts` file that exports the third-party code:

**deps.ts**

```ts
export {
  assert,
  assertEquals,
  assertStringIncludes,
} from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
```

And throughout the same project, you can import from the `deps.ts` and avoid
having many references to the same URL:

```ts, ignore
import { assertEquals, runTests, test } from "./deps.ts";
```

This design circumvents a plethora of complexity spawned by package management
software, centralized code repositories, and superfluous file formats.

### How can I trust a URL that may change?

By using a lock file (with the `--lock` command line flag), you can ensure that
the code pulled from a URL is the same as it was during initial development. You
can learn more about this [here](./integrity_checking.md).

### But what if the host of the URL goes down? The source won't be available.

This, like the above, is a problem faced by _any_ remote dependency system.
Relying on external servers is convenient for development but brittle in
production. Production software should always vendor its dependencies. In Node
this is done by checking `node_modules` into source control. In Deno this is
done by using the [`deno vendor`](../../tools/vendor.md) subcommand.



/. 🚀 runtime/manual/basics/modules/integrity_checking.md
===================================================

# Integrity Checking & Lock Files

## Introduction

Let's say your module depends on remote module `https://some.url/a.ts`. When you
compile your module for the first time `a.ts` is retrieved, compiled and cached.
It will remain this way until you run your module on a new machine (say in
production) or reload the cache (through `deno cache --reload` for example). But
what happens if the content in the remote url `https://some.url/a.ts` is
changed? This could lead to your production module running with different
dependency code than your local module. Deno's solution to avoid this is to use
integrity checking and lock files.

## Caching and lock files

Deno can store and check subresource integrity for modules using a small JSON
file. To opt into a lock file, either:

1. Create a `deno.json` file in the current or an ancestor directory, which will
   automatically create an additive lockfile at `deno.lock`.
2. Use the `--lock=deno.lock` to enable and specify lock file checking. To
   update or create a lock use `--lock=deno.lock --lock-write`. The
   `--lock=deno.lock` tells Deno what the lock file to use is, while the
   `--lock-write` is used to output dependency hashes to the lock file
   (`--lock-write` must be used in conjunction with `--lock`).

A `deno.lock` might look like this, storing a hash of the file against the
dependency:

```json
{
  "https://deno.land/std@$STD_VERSION/textproto/mod.ts": "3118d7a42c03c242c5a49c2ad91c8396110e14acca1324e7aaefd31a999b71a4",
  "https://deno.land/std@$STD_VERSION/io/util.ts": "ae133d310a0fdcf298cea7bc09a599c49acb616d34e148e263bcb02976f80dee",
  "https://deno.land/std@$STD_VERSION/async/delay.ts": "35957d585a6e3dd87706858fb1d6b551cb278271b03f52c5a2cb70e65e00c26a",
   ...
}
```

### Auto-generated lockfile

As mentioned above, when a Deno configuration file is resolved (ex. `deno.json`)
then an additive lockfile will be automatically generated. By default, the path
of this lockfile will be `deno.lock`. You can change this path by updating your
`deno.json` to specify this:

```jsonc
{
  "lock": "./lock.file"
}
```

Or disable automatically creating and validating a lockfile by specifying:

```jsonc
{
  "lock": false
}
```

### Using `--lock` and `--lock-write` flags

A typical workflow will look like this:

**src/deps.ts**

```ts, ignore
// Add a new dependency to "src/deps.ts", used somewhere else.
export { xyz } from "https://unpkg.com/xyz-lib@v0.9.0/lib.ts";
```

Then:

```shell
# Create/update the lock file "deno.lock".
deno cache --lock=deno.lock --lock-write src/deps.ts

# Include it when committing to source control.
git add -u deno.lock
git commit -m "feat: Add support for xyz using xyz-lib"
git push
```

Collaborator on another machine -- in a freshly cloned project tree:

```shell
# Download the project's dependencies into the machine's cache, integrity
# checking each resource.
deno cache --reload --lock=deno.lock src/deps.ts

# Done! You can proceed safely.
deno test --allow-read src
```

## Runtime verification

Like caching above, you can also use lock files during use of the `deno run` sub
command, validating the integrity of any locked modules during the run. Remember
that this only validates against dependencies previously added to the lock file.

You can take this a step further as well by using the `--cached-only` flag to
require that remote dependencies are already cached.

```shell
deno run --lock=deno.lock --cached-only mod.ts
```

This will fail if there are any dependencies in the dependency tree for mod.ts
which are not yet cached.

<!-- TODO - Add detail on dynamic imports -->



/. 🚀 runtime/manual/basics/modules/private.md
===================================================

# Private Modules and Repositories

There may be instances where you want to load a remote module that is located in
a _private_ repository, like a private repository on GitHub.

Deno supports sending bearer tokens when requesting a remote module. Bearer
tokens are the predominant type of access token used with OAuth 2.0, and are
broadly supported by hosting services (e.g., GitHub, GitLab, Bitbucket,
Cloudsmith, etc.).

## DENO_AUTH_TOKENS

The Deno CLI will look for an environment variable named `DENO_AUTH_TOKENS` to
determine what authentication tokens it should consider using when requesting
remote modules. The value of the environment variable is in the format of _n_
number of tokens delimited by a semi-colon (`;`) where each token is either:

- a bearer token in the format of `{token}@{hostname[:port]}` or

- basic auth data in the format of `{username}:{password}@{hostname[:port]}`

For example, a single token for `deno.land` would look something like this:

```sh
DENO_AUTH_TOKENS=a1b2c3d4e5f6@deno.land
```

or:

```sh
DENO_AUTH_TOKENS=username:password@deno.land
```

And multiple tokens would look like this:

```sh
DENO_AUTH_TOKENS=a1b2c3d4e5f6@deno.land;f1e2d3c4b5a6@example.com:8080;username:password@deno.land
```

When Deno goes to fetch a remote module, where the hostname matches the hostname
of the remote module, Deno will set the `Authorization` header of the request to
the value of `Bearer {token}` or `Basic {base64EncodedData}`. This allows the
remote server to recognize that the request is an authorized request tied to a
specific authenticated user, and provide access to the appropriate resources and
modules on the server.

## GitHub

To access private repositories on GitHub, you would need to issue yourself a
_personal access token_. You do this by logging into GitHub and going under
_Settings -> Developer settings -> Personal access tokens_:

![Personal access tokens settings on GitHub](https://docs.deno.com/assets/images/private-pat-d7ff98c43545ab0d56bf324802db4076.png)
<!-- ![Personal access tokens settings on GitHub](../../images/private-pat.png) -->

You would then choose to _Generate new token_ and give your token a description
and appropriate access:

![Creating a new personal access token on GitHub](https://docs.deno.com/assets/images/private-github-new-token-7f0fc024284acf5508d0d72f413eb5f6.png)
<!-- ![Creating a new personal access token on GitHub](../../images/private-github-new-token.png) -->

And once created GitHub will display the new token a single time, the value of
which you would want to use in the environment variable:

![Display of newly created token on GitHub](https://docs.deno.com/assets/images/private-github-token-display-df54e96df6f12169f00ea8c10b39cfb5.png)
<!-- ![Display of newly created token on GitHub](../../images/private-github-token-display.png) -->

In order to access modules that are contained in a private repository on GitHub,
you would want to use the generated token in the `DENO_AUTH_TOKENS` environment
variable scoped to the `raw.githubusercontent.com` hostname. For example:

```sh
DENO_AUTH_TOKENS=a1b2c3d4e5f6@raw.githubusercontent.com
```

This should allow Deno to access any modules that the user who the token was
issued for has access to.

When the token is incorrect, or the user does not have access to the module,
GitHub will issue a `404 Not Found` status, instead of an unauthorized status.
So if you are getting errors that the modules you are trying to access are not
found on the command line, check the environment variable settings and the
personal access token settings.

In addition, `deno run -L debug` should print out a debug message about the
number of tokens that are parsed out of the environment variable. It will print
an error message if it feels any of the tokens are malformed. It won't print any
details about the tokens for security purposes.



/. 🚀 runtime/manual/basics/modules/proxies.md
===================================================

# Proxies

Deno supports proxies for module downloads and the Web standard `fetch` API.

Proxy configuration is read from environmental variables: `HTTP_PROXY`,
`HTTPS_PROXY` and `NO_PROXY`.

In case of Windows, if environment variables are not found Deno falls back to
reading proxies from registry.



/. 🚀 runtime/manual/basics/modules/reloading_modules.md
===================================================

import { replacements } from "@site/src/components/Replacement";

# Reloading Modules

By default, a module in the cache will be reused without fetching or
re-compiling it. Sometimes this is not desirable and you can force deno to
refetch and recompile modules into the cache. You can invalidate your local
`DENO_DIR` cache using the `--reload` flag of the `deno cache` subcommand. It's
usage is described below:

## To reload everything

```bash
deno cache --reload my_module.ts
```

## To reload specific modules

Sometimes we want to upgrade only some modules. You can control it by passing an
argument to a `--reload` flag.

<p>
  To reload all <code>{ replacements.STD_VERSION }</code> standard modules:
</p>

```bash
deno cache --reload=https://deno.land/std@$STD_VERSION my_module.ts
```

To reload specific modules (in this example - colors and file system copy) use a
comma to separate URLs.

```bash
deno cache --reload=https://deno.land/std@$STD_VERSION/fs/copy.ts,https://deno.land/std@$STD_VERSION/fmt/colors.ts my_module.ts
```

<!-- Should this be part of examples? -->



/. 🚀 runtime/manual/basics/testing/index.md
===================================================

---
sidebar_position: 2
---

# Testing in Deno

Deno has a built-in test runner that you can use for testing JavaScript or
TypeScript code.

## Quickstart

Firstly, let's create a file `url_test.ts` and register a test case using
`Deno.test()` function.

```ts
// url_test.ts
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

Deno.test("url test", () => {
  const url = new URL("./foo.js", "https://deno.land/");
  assertEquals(url.href, "https://deno.land/foo.js");
});
```

Secondly, run the test using `deno test` subcommand.

```sh
$ deno test url_test.ts
running 1 test from file:///dev/url_test.js
test url test ... ok (2ms)

test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out (9ms)
```

## Writing tests

To define a test you need to register it with a call to `Deno.test` API. There
are multiple overloads of this API to allow for greatest flexibility and easy
switching between the forms (eg. when you need to quickly focus a single test
for debugging, using `only: true` option):

```ts
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

// Compact form: name and function
Deno.test("hello world #1", () => {
  const x = 1 + 2;
  assertEquals(x, 3);
});

// Compact form: named function.
Deno.test(function helloWorld3() {
  const x = 1 + 2;
  assertEquals(x, 3);
});

// Longer form: test definition.
Deno.test({
  name: "hello world #2",
  fn: () => {
    const x = 1 + 2;
    assertEquals(x, 3);
  },
});

// Similar to compact form, with additional configuration as a second argument.
Deno.test("hello world #4", { permissions: { read: true } }, () => {
  const x = 1 + 2;
  assertEquals(x, 3);
});

// Similar to longer form, with test function as a second argument.
Deno.test(
  { name: "hello world #5", permissions: { read: true } },
  () => {
    const x = 1 + 2;
    assertEquals(x, 3);
  },
);

// Similar to longer form, with a named test function as a second argument.
Deno.test({ permissions: { read: true } }, function helloWorld6() {
  const x = 1 + 2;
  assertEquals(x, 3);
});
```

### Async functions

You can also test asynchronous code by passing a test function that returns a
promise. For this you can use the `async` keyword when defining a function:

```ts
import { delay } from "https://deno.land/std@$STD_VERSION/async/delay.ts";

Deno.test("async hello world", async () => {
  const x = 1 + 2;

  // await some async task
  await delay(100);

  if (x !== 3) {
    throw Error("x should be equal to 3");
  }
});
```

### Test steps

The test steps API provides a way to report distinct steps within a test and do
setup and teardown code within that test.

```ts
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import { Client } from "https://deno.land/x/postgres@v0.15.0/mod.ts";

interface User {
  id: number;
  name: string;
}

interface Book {
  id: number;
  title: string;
}

Deno.test("database", async (t) => {
  const client = new Client({
    user: "user",
    database: "test",
    hostname: "localhost",
    port: 5432,
  });
  await client.connect();

  // provide a step name and function
  await t.step("insert user", async () => {
    const users = await client.queryObject<User>(
      "INSERT INTO users (name) VALUES ('Deno') RETURNING *",
    );
    assertEquals(users.rows.length, 1);
    assertEquals(users.rows[0].name, "Deno");
  });

  // or provide a test definition
  await t.step({
    name: "insert book",
    fn: async () => {
      const books = await client.queryObject<Book>(
        "INSERT INTO books (name) VALUES ('The Deno Manual') RETURNING *",
      );
      assertEquals(books.rows.length, 1);
      assertEquals(books.rows[0].title, "The Deno Manual");
    },
    ignore: false,
    // these default to the parent test or step's value
    sanitizeOps: true,
    sanitizeResources: true,
    sanitizeExit: true,
  });

  // nested steps are also supported
  await t.step("update and delete", async (t) => {
    await t.step("update", () => {
      // even though this test throws, the outer promise does not reject
      // and the next test step will run
      throw new Error("Fail.");
    });

    await t.step("delete", () => {
      // ...etc...
    });
  });

  // steps return a value saying if they ran or not
  const testRan = await t.step({
    name: "copy books",
    fn: () => {
      // ...etc...
    },
    ignore: true, // was ignored, so will return `false`
  });

  // steps can be run concurrently if sanitizers are disabled on sibling steps
  const testCases = [1, 2, 3];
  await Promise.all(testCases.map((testCase) =>
    t.step({
      name: `case ${testCase}`,
      fn: async () => {
        // ...etc...
      },
      sanitizeOps: false,
      sanitizeResources: false,
      sanitizeExit: false,
    })
  ));

  client.end();
});
```

Outputs:

```
test database ...
  test insert user ... ok (2ms)
  test insert book ... ok (14ms)
  test update and delete ...
    test update ... FAILED (17ms)
      Error: Fail.
          at <stack trace omitted>
    test delete ... ok (19ms)
  FAILED (46ms)
  test copy books ... ignored (0ms)
  test case 1 ... ok (14ms)
  test case 2 ... ok (14ms)
  test case 3 ... ok (14ms)
FAILED (111ms)
```

Notes:

1. Test steps **must be awaited** before the parent test/step function resolves
   or you will get a runtime error.
2. Test steps cannot be run concurrently unless sanitizers on a sibling step or
   parent test are disabled.
3. If nesting steps, ensure you specify a parameter for the parent step.
   ```ts
   Deno.test("my test", async (t) => {
     await t.step("step", async (t) => {
       // note the `t` used here is for the parent step and not the outer `Deno.test`
       await t.step("sub-step", () => {
       });
     });
   });
   ```

#### Nested test steps

## Running tests

To run the test, call `deno test` with the file that contains your test
function. You can also omit the file name, in which case all tests in the
current directory (recursively) that match the glob
`{*_,*.,}test.{ts, tsx, mts, js, mjs, jsx}` will be run. If you pass a
directory, all files in the directory that match this glob will be run.

The glob expands to:

- files named `test.{ts, tsx, mts, js, mjs, jsx}`,
- or files ending with `.test.{ts, tsx, mts, js, mjs, jsx}`,
- or files ending with `_test.{ts, tsx, mts, js, mjs, jsx}`

```shell
# Run all tests in the current directory and all sub-directories
deno test

# Run all tests in the util directory
deno test util/

# Run just my_test.ts
deno test my_test.ts

# Run test modules in parallel
deno test --parallel
```

Note that starting in Deno v1.24, some test options can be configured via
[a configuration file](../../getting_started/configuration_file.md).

> ⚠️ If you want to pass additional CLI arguments to the test files use `--` to
> inform Deno that remaining arguments are scripts arguments.

```shell
# Pass additional arguments to the test file
deno test my_test.ts -- -e --foo --bar
```

`deno test` uses the same permission model as `deno run` and therefore will
require, for example, `--allow-write` to write to the file system during
testing.

To see all runtime options with `deno test`, you can reference the command line
help:

```shell
deno help test
```

## Filtering

There are a number of options to filter the tests you are running.

### Command line filtering

Tests can be run individually or in groups using the command line `--filter`
option.

The filter flags accept a string or a pattern as value.

Assuming the following tests:

```ts, ignore
Deno.test({ name: "my-test", fn: myTest });
Deno.test({ name: "test-1", fn: test1 });
Deno.test({ name: "test-2", fn: test2 });
```

This command will run all of these tests because they all contain the word
"test".

```shell
deno test --filter "test" tests/
```

On the flip side, the following command uses a pattern and will run the second
and third tests.

```shell
deno test --filter "/test-*\d/" tests/
```

_To let Deno know that you want to use a pattern, wrap your filter with
forward-slashes like the JavaScript syntactic sugar for a REGEX._

### Including and excluding paths in the configuration file

You can also filter tests by specifying paths to include or exclude in the Deno
configuration file.

For example, if you want to only test `src/fetch_test.ts` and
`src/signal_test.ts` and exclude everything in `out/`:

```json
{
  "test": {
    "include": [
      "src/fetch_test.ts",
      "src/signal_test.ts"
    ]
  }
}
```

Or more likely:

```json
{
  "test": {
    "exclude": ["out/"]
  }
}
```

Then running `deno test` in the same directory tree as the configuration file
will take these options into account.

### Test definition filtering

Within the tests themselves, you have two options for filtering.

#### Filtering out (Ignoring these tests)

Sometimes you want to ignore tests based on some sort of condition (for example
you only want a test to run on Windows). For this you can use the `ignore`
boolean in the test definition. If it is set to true the test will be skipped.

```ts
Deno.test({
  name: "do macOS feature",
  ignore: Deno.build.os !== "darwin",
  fn() {
    // do MacOS feature here
  },
});
```

#### Filtering in (Only run these tests)

Sometimes you may be in the middle of a problem within a large test class and
you would like to focus on just that test and ignore the rest for now. For this
you can use the `only` option to tell the test framework to only run tests with
this set to true. Multiple tests can set this option. While the test run will
report on the success or failure of each test, the overall test run will always
fail if any test is flagged with `only`, as this is a temporary measure only
which disables nearly all of your tests.

```ts
Deno.test({
  name: "Focus on this test only",
  only: true,
  fn() {
    // test complicated stuff here
  },
});
```

## Failing fast

If you have a long-running test suite and wish for it to stop on the first
failure, you can specify the `--fail-fast` flag when running the suite.

```shell
deno test --fail-fast
```

## Reporters

Deno ships with three built-in reporters:

- `pretty` (default)
- `dot`
- `junit`

You can specify the reporter to use with the `--reporter` flag.

```shell
# use default pretty reporter
$ deno test

# use dot reporter with concise output
$ deno test --reporter=dot

# use JUnit reporter
$ deno test --reporter=junit
```

You can also write the output of machine-readable JUnit report to a file, while
still enjoying human-readable output in the terminal. In such situations specify
`--junit-path` flag:

```shell
$ deno test --junit-path=./report.xml
```

## Integration with testing libraries

Deno's test runner works with popular testing libraries like
[Chai](https://www.chaijs.com/), [Sinon.JS](https://sinonjs.org/) or
[fast-check](https://fast-check.dev/).

For example integration see:

- https://deno.land/std/testing/chai_example.ts
- https://deno.land/std/testing/sinon_example.ts
- https://deno.land/std/testing/fast_check_example.ts

### Example: spying on a function with Sinon

Test spies are function stand-ins that are used to assert if a function's
internal behavior matches expectations. Sinon is a widely used testing library
that provides test spies and can be used in Deno by importing it from NPM:

```js
import sinon from "npm:sinon";
```

Say we have two functions, `foo` and `bar` and want to assert that `bar` is
called during execution of `foo`. There are a few ways to achieve this with
Sinon, one is to have function `foo` take another function as a parameter:

```js
// my_file.js
export function bar() {/*...*/}

export function foo(fn) {
  fn();
}
```

This way, we can call `foo(bar)` in the application code or wrap a spy function
around `bar` and call `foo(spy)` in the testing code:

```js, ignore
import sinon from "npm:sinon";
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import { bar, foo } from "./my_file.js";

Deno.test("calls bar during execution of foo", () => {
  // create a test spy that wraps 'bar'
  const spy = sinon.spy(bar);

  // call function 'foo' and pass the spy as an argument
  foo(spy);

  assertEquals(spy.called, true);
  assertEquals(spy.getCalls().length, 1);
});
```

If you prefer not to add additional parameters for testing purposes only, you
can also use `sinon` to wrap a method on an object instead. In other JavaScript
environments `bar` might have been accessible via a global such as `window` and
callable via `sinon.spy(window, "bar")`, but in Deno this will not work and
instead you can `export` an object with the functions to be tested. This means
rewriting `my_file.js` to something like this:

```js
// my_file.js
function bar() {/*...*/}

export const funcs = {
  bar,
};

// 'foo' no longer takes a parameter, but calls 'bar' from an object
export function foo() {
  funcs.bar();
}
```

And then `import` in a test file:

```js, ignore
import sinon from "npm:sinon";
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import { foo, funcs } from "./my_file.js";

Deno.test("calls bar during execution of foo", () => {
  // create a test spy that wraps 'bar' on the 'funcs' object
  const spy = sinon.spy(funcs, "bar");

  // call function 'foo' without an argument
  foo();

  assertEquals(spy.called, true);
  assertEquals(spy.getCalls().length, 1);
});
```



/. 🚀 runtime/manual/basics/testing/assertions.md
===================================================

# Assertions

To help developers write tests the Deno standard library comes with a built-in
[assertions module](https://deno.land/std/assert/mod.ts) which can be imported
from `https://deno.land/std/assert/mod.ts`.

```js
import { assert } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

Deno.test("Hello Test", () => {
  assert("Hello");
});
```

> ⚠️ Some popular assertion libraries, like [Chai](https://www.chaijs.com/), can
> be used in Deno too, for example usage see
> https://deno.land/std/testing/chai_example.ts.

The assertions module provides 14 assertions:

- `assert(expr: unknown, msg = ""): asserts expr`
- `assertEquals(actual: unknown, expected: unknown, msg?: string): void`
- `assertExists(actual: unknown, msg?: string): void`
- `assertNotEquals(actual: unknown, expected: unknown, msg?: string): void`
- `assertStrictEquals(actual: unknown, expected: unknown, msg?: string): void`
- `assertAlmostEquals(actual: number, expected: number, epsilon = 1e-7, msg?: string): void`
- `assertInstanceOf(actual: unknown, expectedType: unknown, msg?: string): void`
- `assertStringIncludes(actual: string, expected: string, msg?: string): void`
- `assertArrayIncludes(actual: unknown[], expected: unknown[], msg?: string): void`
- `assertMatch(actual: string, expected: RegExp, msg?: string): void`
- `assertNotMatch(actual: string, expected: RegExp, msg?: string): void`
- `assertObjectMatch( actual: Record<PropertyKey, unknown>, expected: Record<PropertyKey, unknown>): void`
- `assertThrows(fn: () => void, ErrorClass?: Constructor, msgIncludes?: string | undefined, msg?: string | undefined): Error`
- `assertRejects(fn: () => Promise<unknown>, ErrorClass?: Constructor, msgIncludes?: string | undefined, msg?: string | undefined): Promise<void>`

In addition to the above assertions, the
[snapshot module](https://deno.land/std/testing/snapshot.ts) also exposes an
`assertSnapshot` function. The documentation for this module can be found
[here](./snapshot_testing.md).

## Assert

The assert method is a simple 'truthy' assertion and can be used to assert any
value which can be inferred as true.

```js
Deno.test("Test Assert", () => {
  assert(1);
  assert("Hello");
  assert(true);
});
```

## Exists

The `assertExists` can be used to check if a value is not `null` or `undefined`.

```js
assertExists("Denosaurus");
Deno.test("Test Assert Exists", () => {
  assertExists("Denosaurus");
  assertExists(false);
  assertExists(0);
});
```

## Equality

There are three equality assertions available, `assertEquals()`,
`assertNotEquals()` and `assertStrictEquals()`.

The `assertEquals()` and `assertNotEquals()` methods provide a general equality
check and are capable of asserting equality between primitive types and objects.

```js
Deno.test("Test Assert Equals", () => {
  assertEquals(1, 1);
  assertEquals("Hello", "Hello");
  assertEquals(true, true);
  assertEquals(undefined, undefined);
  assertEquals(null, null);
  assertEquals(new Date(), new Date());
  assertEquals(new RegExp("abc"), new RegExp("abc"));

  class Foo {}
  const foo1 = new Foo();
  const foo2 = new Foo();

  assertEquals(foo1, foo2);
});

Deno.test("Test Assert Not Equals", () => {
  assertNotEquals(1, 2);
  assertNotEquals("Hello", "World");
  assertNotEquals(true, false);
  assertNotEquals(undefined, "");
  assertNotEquals(new Date(), Date.now());
  assertNotEquals(new RegExp("abc"), new RegExp("def"));
});
```

By contrast `assertStrictEquals()` provides a simpler, stricter equality check
based on the `===` operator. As a result it will not assert two instances of
identical objects as they won't be referentially the same.

```js
Deno.test("Test Assert Strict Equals", () => {
  assertStrictEquals(1, 1);
  assertStrictEquals("Hello", "Hello");
  assertStrictEquals(true, true);
  assertStrictEquals(undefined, undefined);
});
```

The `assertStrictEquals()` assertion is best used when you wish to make a
precise check against two primitive types.

### Equality for numbers

When testing equality between numbers, it is important to keep in mind that some
of them cannot be accurately depicted by IEEE-754 double-precision
floating-point representation.

That's especially true when working with decimal numbers, where
`assertStrictEquals()` may work in some cases but not in others:

```ts
import {
  assertStrictEquals,
  assertThrows,
} from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

Deno.test("Test Assert Strict Equals with float numbers", () => {
  assertStrictEquals(0.25 + 0.25, 0.25);
  assertThrows(() => assertStrictEquals(0.1 + 0.2, 0.3));
  //0.1 + 0.2 will be stored as 0.30000000000000004 instead of 0.3
});
```

Instead, `assertAlmostEquals()` provides a way to test that given numbers are
close enough to be considered equals. Default tolerance is set to `1e-7` though
it is possible to change it by passing a third optional parameter.

```ts
import {
  assertAlmostEquals,
  assertThrows,
} from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

Deno.test("Test Assert Almost Equals", () => {
  assertAlmostEquals(0.1 + 0.2, 0.3);
  assertAlmostEquals(0.1 + 0.2, 0.3, 1e-16);
  assertThrows(() => assertAlmostEquals(0.1 + 0.2, 0.3, 1e-17));
});
```

### Instance types

To check if an object is an instance of a specific constructor, you can use
`assertInstanceOf()`. This has the added benefit that it lets TypeScript know
the passed in variable has a specific type:

```ts
import { assertInstanceOf } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

Deno.test("Test Assert Instance Type", () => {
  const variable = new Date() as unknown;

  assertInstanceOf(variable, Date);

  // This won't cause type errors now that
  // it's type has been asserted against.
  variable.getDay();
});
```

## Contains

There are two methods available to assert a value contains a value,
`assertStringIncludes()` and `assertArrayIncludes()`.

The `assertStringIncludes()` assertion does a simple includes check on a string
to see if it contains the expected string.

```js
Deno.test("Test Assert String Contains", () => {
  assertStringIncludes("Hello World", "Hello");
});
```

The `assertArrayIncludes()` assertion is slightly more advanced and can find
both a value within an array and an array of values within an array.

```js
Deno.test("Test Assert Array Contains", () => {
  assertArrayIncludes([1, 2, 3], [1]);
  assertArrayIncludes([1, 2, 3], [1, 2]);
  assertArrayIncludes(Array.from("Hello World"), Array.from("Hello"));
});
```

## Regex

You can assert regular expressions via `assertMatch()` and `assertNotMatch()`
assertions.

```js
Deno.test("Test Assert Match", () => {
  assertMatch("abcdefghi", new RegExp("def"));

  const basicUrl = new RegExp("^https?://[a-z.]+.com$");
  assertMatch("https://www.google.com", basicUrl);
  assertMatch("http://facebook.com", basicUrl);
});

Deno.test("Test Assert Not Match", () => {
  assertNotMatch("abcdefghi", new RegExp("jkl"));

  const basicUrl = new RegExp("^https?://[a-z.]+.com$");
  assertNotMatch("https://deno.land/", basicUrl);
});
```

## Object

Use `assertObjectMatch` to check that a JavaScript object matches a subset of
the properties of an object.

```js
// Simple subset
assertObjectMatch(
  { foo: true, bar: false },
  {
    foo: true,
  },
);
```

## Throws

There are two ways to assert whether something throws an error in Deno,
`assertThrows()` and `assertRejects()`. Both assertions allow you to check an
[Error](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error)
has been thrown, the type of error thrown and what the message was.

The difference between the two assertions is `assertThrows()` accepts a standard
function and `assertRejects()` accepts a function which returns a
[Promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise).

The `assertThrows()` assertion will check an error has been thrown, and
optionally will check the thrown error is of the correct type, and assert the
error message is as expected.

```js
Deno.test("Test Assert Throws", () => {
  assertThrows(
    () => {
      throw new Error("Panic!");
    },
    Error,
    "Panic!",
  );
});
```

The `assertRejects()` assertion is a little more complicated, mainly because it
deals with Promises. But basically it will catch thrown errors or rejections in
Promises. You can also optionally check for the error type and error message.
This can be used similar to `assertThrows()` but with async functions.

```js
Deno.test("Test Assert Throws Async", async () => {
  await assertRejects(
    () => {
      return new Promise(() => {
        throw new Error("Panic! Threw Error");
      });
    },
    Error,
    "Panic! Threw Error",
  );

  await assertRejects(
    () => {
      return Promise.reject(new Error("Panic! Reject Error"));
    },
    Error,
    "Panic! Reject Error",
  );
});
```

## Custom Messages

Each of Deno's built-in assertions allow you to overwrite the standard CLI error
message if you wish. For instance this example will output "Values Don't Match!"
rather than the standard CLI error message.

```js
Deno.test("Test Assert Equal Fail Custom Message", () => {
  assertEquals(1, 2, "Values Don't Match!");
});
```

## Custom Tests

While Deno comes with powerful
[assertions modules](https://deno.land/std/assert/mod.ts) but there is always
something specific to the project you can add. Creating
`custom assertion function` can improve readability and reduce the amount of
code.

```ts
import { AssertionError } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

function assertPowerOf(actual: number, expected: number, msg?: string): void {
  let received = actual;
  while (received % expected === 0) received = received / expected;
  if (received !== 1) {
    if (!msg) {
      msg = `actual: "${actual}" expected to be a power of : "${expected}"`;
    }
    throw new AssertionError(msg);
  }
}
```

Use this matcher in your code like this:

```js
Deno.test("Test Assert PowerOf", () => {
  assertPowerOf(8, 2);
  assertPowerOf(11, 4);
});
```



/. 🚀 runtime/manual/basics/testing/behavior_driven_development.md
===================================================

# Behavior-Driven Development

With the [bdd.ts](https://deno.land/std/testing/bdd.ts) module you can write
your tests in a familiar format for grouping tests and adding setup/teardown
hooks used by other JavaScript testing frameworks like Jasmine, Jest, and Mocha.

The `describe` function creates a block that groups together several related
tests. The `it` function registers an individual test case.

## Hooks

There are 4 types of hooks available for test suites. A test suite can have
multiples of each type of hook, they will be called in the order that they are
registered. The `afterEach` and `afterAll` hooks will be called whether or not
the test case passes. The `*All` hooks will be called once for the whole group
while the `*Each` hooks will be called for each individual test case.

- `beforeAll`: Runs before all of the tests in the test suite.
- `afterAll`: Runs after all of the tests in the test suite finish.
- `beforeEach`: Runs before each of the individual test cases in the test suite.
- `afterEach`: Runs after each of the individual test cases in the test suite.

If a hook is registered at the top level, a global test suite will be registered
and all tests will belong to it. Hooks registered at the top level must be
registered before any individual test cases or test suites.

## Focusing tests

If you would like to run only specific test cases, you can do so by calling
`it.only` instead of `it`. If you would like to run only specific test suites,
you can do so by calling `describe.only` instead of `describe`.

There is one limitation to this when using the flat test grouping style. When
`describe` is called without being nested, it registers the test with
`Deno.test`. If a child test case or suite is registered with `it.only` or
`describe.only`, it will be scoped to the top test suite instead of the file. To
make them the only tests that run in the file, you would need to register the
top test suite with `describe.only` too.

## Ignoring tests

If you would like to not run specific individual test cases, you can do so by
calling `it.ignore` instead of `it`. If you would like to not run specific test
suites, you can do so by calling `describe.ignore` instead of `describe`.

## Sanitization options

Like `Deno.TestDefinition`, the `DescribeDefinition` and `ItDefinition` have
sanitization options. They work in the same way.

- `sanitizeExit`: Ensure the test case does not prematurely cause the process to
  exit, for example via a call to Deno.exit. Defaults to true.
- `sanitizeOps`: Check that the number of async completed ops after the test is
  the same as number of dispatched ops. Defaults to true.
- `sanitizeResources`: Ensure the test case does not "leak" resources - ie. the
  resource table after the test has exactly the same contents as before the
  test. Defaults to true.

## Permissions option

Like `Deno.TestDefinition`, the `DescribeDefinition` and `ItDefinition` have a
`permissions` option. They specify the permissions that should be used to run an
individual test case or test suite. Set this to `"inherit"` to keep the calling
thread's permissions. Set this to `"none"` to revoke all permissions.

This setting defaults to `"inherit"`.

There is currently one limitation to this, you cannot use the permissions option
on an individual test case or test suite that belongs to another test suite.
That's because internally those tests are registered with `t.step` which does
not support the permissions option.

## Comparing to Deno\.test

The default way of writing tests is using `Deno.test` and `t.step`. The
`describe` and `it` functions have similar call signatures to `Deno.test`,
making it easy to switch between the default style and the behavior-driven
development style of writing tests. Internally, `describe` and `it` are
registering tests with `Deno.test` and `t.step`.

Below is an example of a test file using `Deno.test` and `t.step`. In the
following sections there are examples of how the same test could be written with
`describe` and `it` using nested test grouping, flat test grouping, or a mix of
both styles.

```ts
// https://deno.land/std/testing/bdd_examples/user_test.ts
import {
  assertEquals,
  assertStrictEquals,
  assertThrows,
} from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import {
  User,
} from "https://deno.land/std@$STD_VERSION/testing/bdd_examples/user.ts";

Deno.test("User.users initially empty", () => {
  assertEquals(User.users.size, 0);
});

Deno.test("User constructor", () => {
  try {
    const user = new User("Kyle");
    assertEquals(user.name, "Kyle");
    assertStrictEquals(User.users.get("Kyle"), user);
  } finally {
    User.users.clear();
  }
});

Deno.test("User age", async (t) => {
  const user = new User("Kyle");

  await t.step("getAge", () => {
    assertThrows(() => user.getAge(), Error, "Age unknown");
    user.age = 18;
    assertEquals(user.getAge(), 18);
  });

  await t.step("setAge", () => {
    user.setAge(18);
    assertEquals(user.getAge(), 18);
  });
});
```

### Nested test grouping

Tests created within the callback of a `describe` function call will belong to
the new test suite it creates. The hooks can be created within it or be added to
the options argument for describe.

```ts
// https://deno.land/std/testing/bdd_examples/user_nested_test.ts
import {
  assertEquals,
  assertStrictEquals,
  assertThrows,
} from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import {
  afterEach,
  beforeEach,
  describe,
  it,
} from "https://deno.land/std@$STD_VERSION/testing/bdd.ts";
import {
  User,
} from "https://deno.land/std@$STD_VERSION/testing/bdd_examples/user.ts";

describe("User", () => {
  it("users initially empty", () => {
    assertEquals(User.users.size, 0);
  });

  it("constructor", () => {
    try {
      const user = new User("Kyle");
      assertEquals(user.name, "Kyle");
      assertStrictEquals(User.users.get("Kyle"), user);
    } finally {
      User.users.clear();
    }
  });

  describe("age", () => {
    let user: User;

    beforeEach(() => {
      user = new User("Kyle");
    });

    afterEach(() => {
      User.users.clear();
    });

    it("getAge", function () {
      assertThrows(() => user.getAge(), Error, "Age unknown");
      user.age = 18;
      assertEquals(user.getAge(), 18);
    });

    it("setAge", function () {
      user.setAge(18);
      assertEquals(user.getAge(), 18);
    });
  });
});
```

### Flat test grouping

The `describe` function returns a unique symbol that can be used to reference
the test suite for adding tests to it without having to create them within a
callback. The gives you the ability to have test grouping without any extra
indentation in front of the grouped tests.

```ts
// https://deno.land/std/testing/bdd_examples/user_flat_test.ts
import {
  assertEquals,
  assertStrictEquals,
  assertThrows,
} from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import {
  describe,
  it,
} from "https://deno.land/std@$STD_VERSION/testing/bdd.ts";
import {
  User,
} from "https://deno.land/std@$STD_VERSION/testing/bdd_examples/user.ts";

const userTests = describe("User");

it(userTests, "users initially empty", () => {
  assertEquals(User.users.size, 0);
});

it(userTests, "constructor", () => {
  try {
    const user = new User("Kyle");
    assertEquals(user.name, "Kyle");
    assertStrictEquals(User.users.get("Kyle"), user);
  } finally {
    User.users.clear();
  }
});

const ageTests = describe({
  name: "age",
  suite: userTests,
  beforeEach(this: { user: User }) {
    this.user = new User("Kyle");
  },
  afterEach() {
    User.users.clear();
  },
});

it(ageTests, "getAge", function () {
  const { user } = this;
  assertThrows(() => user.getAge(), Error, "Age unknown");
  user.age = 18;
  assertEquals(user.getAge(), 18);
});

it(ageTests, "setAge", function () {
  const { user } = this;
  user.setAge(18);
  assertEquals(user.getAge(), 18);
});
```

### Mixed test grouping

Both nested test grouping and flat test grouping can be used together. This can
be useful if you'd like to create deep groupings without all the extra
indentation in front of each line.

```ts
// https://deno.land/std/testing/bdd_examples/user_mixed_test.ts
import {
  assertEquals,
  assertStrictEquals,
  assertThrows,
} from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import {
  describe,
  it,
} from "https://deno.land/std@$STD_VERSION/testing/bdd.ts";
import {
  User,
} from "https://deno.land/std@$STD_VERSION/testing/bdd_examples/user.ts";

describe("User", () => {
  it("users initially empty", () => {
    assertEquals(User.users.size, 0);
  });

  it("constructor", () => {
    try {
      const user = new User("Kyle");
      assertEquals(user.name, "Kyle");
      assertStrictEquals(User.users.get("Kyle"), user);
    } finally {
      User.users.clear();
    }
  });

  const ageTests = describe({
    name: "age",
    beforeEach(this: { user: User }) {
      this.user = new User("Kyle");
    },
    afterEach() {
      User.users.clear();
    },
  });

  it(ageTests, "getAge", function () {
    const { user } = this;
    assertThrows(() => user.getAge(), Error, "Age unknown");
    user.age = 18;
    assertEquals(user.getAge(), 18);
  });

  it(ageTests, "setAge", function () {
    const { user } = this;
    user.setAge(18);
    assertEquals(user.getAge(), 18);
  });
});
```



/. 🚀 runtime/manual/basics/testing/coverage.md
===================================================

# Test Coverage

Deno will collect test coverage into a directory for your code if you specify
the `--coverage` flag when starting `deno test`.

This coverage information is acquired directly from the JavaScript engine (V8)
which is very accurate.

This can then be further processed from the internal format into well known
formats by the `deno coverage` tool.

> ⚠️ To ensure consistent coverage results, make sure to process coverage data
> immediately after running tests. Otherwise source code and collected coverage
> data might get out of sync and unexpectedly show uncovered lines.

```bash
# Go into your project's working directory
git clone https://github.com/oakserver/oak && cd oak

# Collect your coverage profile with deno test --coverage=<output_directory>
deno test --coverage=cov_profile

# From this you can get a pretty printed diff of uncovered lines
deno coverage cov_profile

# Or generate an lcov report
deno coverage cov_profile --lcov --output=cov_profile.lcov

# Which can then be further processed by tools like genhtml
genhtml -o cov_profile/html cov_profile.lcov
```

By default, `deno coverage` will exclude any files matching the regular
expression `test\.(ts|tsx|mts|js|mjs|jsx|cjs|cts)` and only consider including
specifiers matching the regular expression `^file:` - ie. remote files will be
excluded from coverage report.

These filters can be overridden using the `--exclude` and `--include` flags. A
module specifier must _match_ the include_regular expression and _not match_ the
exclude_ expression for it to be a part of the report.



/. 🚀 runtime/manual/basics/testing/documentation.md
===================================================

# Documentation Tests

Deno supports type-checking your documentation examples.

This makes sure that examples within your documentation are up to date and
working.

The basic idea is this:

````ts
/**
 * # Examples
 *
 * ```ts
 * const x = 42;
 * ```
 */
````

The triple backticks mark the start and end of code blocks, the language is
determined by the language identifier attribute which may be any of the
following:

- `js`
- `jsx`
- `ts`
- `tsx`

If no language identifier is specified then the language is inferred from media
type of the source document that the code block is extracted from.

If this example was in a file named foo.ts, running `deno test --doc foo.ts`
will extract this example, and then type-check it as a standalone module living
in the same directory as the module being documented.

To document your exports, import the module using a relative path specifier:

````ts
/**
 * # Examples
 *
 * ```ts
 * import { foo } from "./foo.ts";
 * ```
 */
export function foo(): string {
  return "foo";
}
````



/. 🚀 runtime/manual/basics/testing/mocking.md
===================================================

# Mocking

Test spies are function stand-ins that are used to assert if a function's
internal behavior matches expectations. Test spies on methods keep the original
behavior but allow you to test how the method is called and what it returns.
Test stubs are an extension of test spies that also replaces the original
method's behavior.

## Spying

Say we have two functions, `square` and `multiply`, if we want to assert that
the `multiply` function is called during execution of the `square` function we
need a way to spy on the `multiply` function. There are a few ways to achieve
this with Spies, one is to have the `square` function take the `multiply` as a
parameter.

```ts
// https://deno.land/std/testing/mock_examples/parameter_injection.ts
export function multiply(a: number, b: number): number {
  return a * b;
}

export function square(
  multiplyFn: (a: number, b: number) => number,
  value: number,
): number {
  return multiplyFn(value, value);
}
```

This way, we can call `square(multiply, value)` in the application code or wrap
a spy function around the `multiply` function and call
`square(multiplySpy, value)` in the testing code.

```ts
// https://deno.land/std/testing/mock_examples/parameter_injection_test.ts
import {
  assertSpyCall,
  assertSpyCalls,
  spy,
} from "https://deno.land/std@$STD_VERSION/testing/mock.ts";
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import {
  multiply,
  square,
} from "https://deno.land/std@$STD_VERSION/testing/mock_examples/parameter_injection.ts";

Deno.test("square calls multiply and returns results", () => {
  const multiplySpy = spy(multiply);

  assertEquals(square(multiplySpy, 5), 25);

  // asserts that multiplySpy was called at least once and details about the first call.
  assertSpyCall(multiplySpy, 0, {
    args: [5, 5],
    returned: 25,
  });

  // asserts that multiplySpy was only called once.
  assertSpyCalls(multiplySpy, 1);
});
```

If you prefer not adding additional parameters for testing purposes only, you
can use spy to wrap a method on an object instead. In the following example, the
exported `_internals` object has the `multiply` function we want to call as a
method and the `square` function calls `_internals.multiply` instead of
`multiply`.

```ts
// https://deno.land/std/testing/mock_examples/internals_injection.ts
export function multiply(a: number, b: number): number {
  return a * b;
}

export function square(value: number): number {
  return _internals.multiply(value, value);
}

export const _internals = { multiply };
```

This way, we can call `square(value)` in both the application code and testing
code. Then spy on the `multiply` method on the `_internals` object in the
testing code to be able to spy on how the `square` function calls the `multiply`
function.

```ts
// https://deno.land/std/testing/mock_examples/internals_injection_test.ts
import {
  assertSpyCall,
  assertSpyCalls,
  spy,
} from "https://deno.land/std@$STD_VERSION/testing/mock.ts";
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import {
  _internals,
  square,
} from "https://deno.land/std@$STD_VERSION/testing/mock_examples/internals_injection.ts";

Deno.test("square calls multiply and returns results", () => {
  const multiplySpy = spy(_internals, "multiply");

  try {
    assertEquals(square(5), 25);
  } finally {
    // unwraps the multiply method on the _internals object
    multiplySpy.restore();
  }

  // asserts that multiplySpy was called at least once and details about the first call.
  assertSpyCall(multiplySpy, 0, {
    args: [5, 5],
    returned: 25,
  });

  // asserts that multiplySpy was only called once.
  assertSpyCalls(multiplySpy, 1);
});
```

One difference you may have noticed between these two examples is that in the
second we call the `restore` method on `multiplySpy` function. That is needed to
remove the spy wrapper from the `_internals` object's `multiply` method. The
`restore` method is called in a finally block to ensure that it is restored
whether or not the assertion in the try block is successful. The `restore`
method didn't need to be called in the first example because the `multiply`
function was not modified in any way like the `_internals` object was in the
second example.

## Stubbing

Say we have two functions, `randomMultiple` and `randomInt`, if we want to
assert that `randomInt` is called during execution of `randomMultiple` we need a
way to spy on the `randomInt` function. That could be done with either of the
spying techniques previously mentioned. To be able to verify that the
`randomMultiple` function returns the value we expect it to for what `randomInt`
returns, the easiest way would be to replace the `randomInt` function's behavior
with more predictable behavior.

You could use the first spying technique to do that but that would require
adding a `randomInt` parameter to the `randomMultiple` function.

You could also use the second spying technique to do that, but your assertions
would not be as predictable due to the `randomInt` function returning random
values.

Say we want to verify it returns correct values for both negative and positive
random integers. We could easily do that with stubbing. The below example is
similar to the second spying technique example but instead of passing the call
through to the original `randomInt` function, we are going to replace
`randomInt` with a function that returns pre-defined values.

```ts
// https://deno.land/std/testing/mock_examples/random.ts
export function randomInt(lowerBound: number, upperBound: number): number {
  return lowerBound + Math.floor(Math.random() * (upperBound - lowerBound));
}

export function randomMultiple(value: number): number {
  return value * _internals.randomInt(-10, 10);
}

export const _internals = { randomInt };
```

The mock module includes some helper functions to make creating common stubs
easy. The `returnsNext` function takes an array of values we want it to return
on consecutive calls.

```ts
// https://deno.land/std/testing/mock_examples/random_test.ts
import {
  assertSpyCall,
  assertSpyCalls,
  returnsNext,
  stub,
} from "https://deno.land/std@$STD_VERSION/testing/mock.ts";
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import {
  _internals,
  randomMultiple,
} from "https://deno.land/std@$STD_VERSION/testing/mock_examples/random.ts";

Deno.test("randomMultiple uses randomInt to generate random multiples between -10 and 10 times the value", () => {
  const randomIntStub = stub(_internals, "randomInt", returnsNext([-3, 3]));

  try {
    assertEquals(randomMultiple(5), -15);
    assertEquals(randomMultiple(5), 15);
  } finally {
    // unwraps the randomInt method on the _internals object
    randomIntStub.restore();
  }

  // asserts that randomIntStub was called at least once and details about the first call.
  assertSpyCall(randomIntStub, 0, {
    args: [-10, 10],
    returned: -3,
  });
  // asserts that randomIntStub was called at least twice and details about the second call.
  assertSpyCall(randomIntStub, 1, {
    args: [-10, 10],
    returned: 3,
  });

  // asserts that randomIntStub was only called twice.
  assertSpyCalls(randomIntStub, 2);
});
```

## Faking time

Say we have a function that has time based behavior that we would like to test.
With real time, that could cause tests to take much longer than they should. If
you fake time, you could simulate how your function would behave over time
starting from any point in time. Below is an example where we want to test that
the callback is called every second.

```ts
// https://deno.land/std/testing/mock_examples/interval.ts
export function secondInterval(cb: () => void): number {
  return setInterval(cb, 1000);
}
```

With `FakeTime` we can do that. When the `FakeTime` instance is created, it
splits from real time. The `Date`, `setTimeout`, `clearTimeout`, `setInterval`
and `clearInterval` globals are replaced with versions that use the fake time
until real time is restored. You can control how time ticks forward with the
`tick` method on the `FakeTime` instance.

```ts
// https://deno.land/std/testing/mock_examples/interval_test.ts
import {
  assertSpyCalls,
  spy,
} from "https://deno.land/std@$STD_VERSION/testing/mock.ts";
import { FakeTime } from "https://deno.land/std@$STD_VERSION/testing/time.ts";
import { secondInterval } from "https://deno.land/std@$STD_VERSION/testing/mock_examples/interval.ts";

Deno.test("secondInterval calls callback every second and stops after being cleared", () => {
  const time = new FakeTime();

  try {
    const cb = spy();
    const intervalId = secondInterval(cb);
    assertSpyCalls(cb, 0);
    time.tick(500);
    assertSpyCalls(cb, 0);
    time.tick(500);
    assertSpyCalls(cb, 1);
    time.tick(3500);
    assertSpyCalls(cb, 4);

    clearInterval(intervalId);
    time.tick(1000);
    assertSpyCalls(cb, 4);
  } finally {
    time.restore();
  }
});
```



/. 🚀 runtime/manual/basics/testing/sanitizers.md
===================================================

# Test Sanitizers

The test runner offers several sanitizers to ensure that the test behaves in a
reasonable and expected way.

## Resource sanitizer

Certain actions in Deno create resources in the resource table
([learn more here](../../references/contributing/architecture.md)).

These resources should be closed after you are done using them.

For each test definition, the test runner checks that all resources created in
this test have been closed. This is to prevent resource 'leaks'. This is enabled
by default for all tests, but can be disabled by setting the `sanitizeResources`
boolean to false in the test definition.

```ts
Deno.test({
  name: "leaky resource test",
  async fn() {
    await Deno.open("hello.txt");
  },
  sanitizeResources: false,
});
```

## Op sanitizer

The same is true for async operation like interacting with the filesystem. The
test runner checks that each operation you start in the test is completed before
the end of the test. This is enabled by default for all tests, but can be
disabled by setting the `sanitizeOps` boolean to false in the test definition.

```ts
Deno.test({
  name: "leaky operation test",
  fn() {
    crypto.subtle.digest(
      "SHA-256",
      new TextEncoder().encode("a".repeat(100000000)),
    );
  },
  sanitizeOps: false,
});
```

## Exit sanitizer

There's also the exit sanitizer which ensures that tested code doesn't call
`Deno.exit()` signaling a false test success.

This is enabled by default for all tests, but can be disabled by setting the
`sanitizeExit` boolean to false in the test definition.

```ts
Deno.test({
  name: "false success",
  fn() {
    Deno.exit(0);
  },
  sanitizeExit: false,
});

// This test never runs, because the process exits during "false success" test
Deno.test({
  name: "failing test",
  fn() {
    throw new Error("this test fails");
  },
});
```



/. 🚀 runtime/manual/basics/testing/snapshot_testing.md
===================================================

# Snapshot Testing

The Deno standard library comes with a
[snapshot module](https://deno.land/std/testing/snapshot.ts), which enables
developers to write tests which assert a value against a reference snapshot.
This reference snapshot, is a serialized representation of the original value
and is stored alongside the test file.

Snapshot testing can be useful in many cases, as it enables catching a wide
array of bugs with very little code. It is particularly helpful in situations
where it is difficult to precisely express what should be asserted, without
requiring a prohibitive amount of code, or where the assertions a test makes are
expected to change often. It therefore lends itself especially well to use in
the development of front ends and CLIs.

## Basic usage

The `assertSnapshot` function will create a snapshot of a value and compare it
to a reference snapshot, which is stored alongside the test file in the
`__snapshots__` directory.

```ts title="example_test.ts"
import {
  assertSnapshot,
} from "https://deno.land/std@$STD_VERSION/testing/snapshot.ts";

Deno.test("isSnapshotMatch", async function (t): Promise<void> {
  const a = {
    hello: "world!",
    example: 123,
  };
  await assertSnapshot(t, a);
});
```

```js title="__snapshots__/example_test.ts.snap"
export const snapshot = {};

snapshot[`isSnapshotMatch 1`] = `
{
  example: 123,
  hello: "world!",
}
`;
```

Calling `assertSnapshot` in a test will throw an `AssertionError`, causing the
test to fail, if the snapshot created during the test does not match the one in
the snapshot file.

## Creating and updating snapshots

When adding new snapshot assertions to your test suite, or when intentionally
making changes which cause your snapshots to fail, you can update your snapshots
by running the snapshot tests in update mode. Tests can be run in update mode by
passing the `--update` or `-u` flag as an argument when running the test. When
this flag is passed, then any snapshots which do not match will be updated.

```sh
deno test --allow-all -- --update
```

Additionally, new snapshots will only be created when this flag is present.

## Permissions

When running snapshot tests, the `--allow-read` permission must be enabled, or
else any calls to `assertSnapshot` will fail due to insufficient permissions.
Additionally, when updating snapshots, the `--allow-write` permission must also
be enabled, as this is required in order to update snapshot files.

The `assertSnapshot` function will only attempt to read from and write to
snapshot files. As such, the allow list for `--allow-read` and `--allow-write`
can be limited to only include existing snapshot files, if so desired.

## Version Control

Snapshot testing works best when changes to snapshot files are committed
alongside other code changes. This allows for changes to reference snapshots to
be reviewed along side the code changes that caused them, and ensures that when
others pull your changes, their tests will pass without needing to update
snapshots locally.

## Advanced Usage

### Options

The `assertSnapshot` function can also be called with an options object which
offers greater flexibility and enables some non standard use cases.

```ts
import {
  assertSnapshot,
} from "https://deno.land/std@$STD_VERSION/testing/snapshot.ts";

Deno.test("isSnapshotMatch", async function (t): Promise<void> {
  const a = {
    hello: "world!",
    example: 123,
  };
  await assertSnapshot(t, a, {
    // options
  });
});
```

**`serializer`**

The `serializer` option allows you to provide a custom serializer function. This
will be called by `assertSnapshot` and be passed the value being asserted. It
should return a string. It is important that the serializer function is
deterministic i.e. that it will always produce the same output, given the same
input.

The result of the serializer function will be written to the snapshot file in
update mode, and in assert mode will be compared to the snapshot stored in the
snapshot file.

```ts title="example_test.ts"
import {
  assertSnapshot,
  serialize,
} from "https://deno.land/std@$STD_VERSION/testing/snapshot.ts";
import { stripColor } from "https://deno.land/std@$STD_VERSION/fmt/colors.ts";

/**
 * Serializes `actual` and removes ANSI escape codes.
 */
function customSerializer(actual: string) {
  return serialize(stripColor(actual));
}

Deno.test("Custom Serializer", async function (t): Promise<void> {
  const output = "\x1b[34mHello World!\x1b[39m";
  await assertSnapshot(t, output, {
    serializer: customSerializer,
  });
});
```

```js title="__snapshots__/example_test.ts.snap"
export const snapshot = {};

snapshot[`Custom Serializer 1`] = `"Hello World!"`;
```

Custom serializers can be useful in a variety of cases. One possible use case is
to discard information which is not relevant and/or to present the serialized
output in a more human readable form.

For example, the above code snippet shows how a custom serializer could be used
to remove ANSI escape codes (which encode font color and styles in CLI
applications), making the snapshot more readable than it would be otherwise.

Other common use cases would be to obfuscate values which are non-deterministic
or which you may not want to write to disk for other reasons. For example,
timestamps or file paths.

Note that the default serializer is exported from the snapshot module so that
its functionality can be easily extended.

**`dir` and `path`**

The `dir` and `path` options allow you to control where the snapshot file will
be saved to and read from. These can be absolute paths or relative paths. If
relative, the they will be resolved relative to the test file.

For example, if your test file is located at `/path/to/test.ts` and the `dir`
option is set to `snapshots`, then the snapshot file would be written to
`/path/to/snapshots/test.ts.snap`.

As shown in the above example, the `dir` option allows you to specify the
snapshot directory, while still using the default format for the snapshot file
name.

In contrast, the `path` option allows you to specify the directory and file name
of the snapshot file.

For example, if your test file is located at `/path/to/test.ts` and the `path`
option is set to `snapshots/test.snapshot`, then the snapshot file would be
written to `/path/to/snapshots/test.snapshot`.

If both `dir` and `path` are specified, the `dir` option will be ignored and the
`path` option will be handled as normal.

**`mode`**

The `mode` option can be either `assert` or `update`. When set, the `--update`
and `-u` flags will be ignored.

If the `mode` option is set to `assert`, then `assertSnapshot` will always
behave as though the update flag is not passed i.e. if the snapshot does not
match the one saved in the snapshot file, then an `AssertionError` will be
thrown.

If the `mode` option is set to `update`, then `assertSnapshot` will always
behave as though the update flag has been passed i.e. if the snapshot does not
match the one saved in the snapshot file, then the snapshot will be updated
after all tests have run.

**`name`**

The `name` option specifies the name of the snapshot. By default, the name of
the test step will be used. However, if specified, the `name` option will be
used instead.

```ts title="example_test.ts"
import {
  assertSnapshot,
} from "https://deno.land/std@$STD_VERSION/testing/snapshot.ts";

Deno.test("isSnapshotMatch", async function (t): Promise<void> {
  const a = {
    hello: "world!",
    example: 123,
  };
  await assertSnapshot(t, a, {
    name: "Test Name",
  });
});
```

```js title="__snapshots__/example_test.ts.snap"
export const snapshot = {};

snapshot[`Test Name 1`] = `
{
  example: 123,
  hello: "world!",
}
`;
```

When `assertSnapshot` is run multiple times with the same value for `name`, then
the suffix will be incremented as normal. i.e. `Test Name 1`, `Test Name 2`,
`Test Name 3`, etc.

**`msg`**

Allows setting a custom error message to use. This will overwrite the default
error message, which includes the diff for failed snapshots.

### Default Options

You can configure default options for `assertSnapshot`.

```ts title="example_test.ts"
import {
  createAssertSnapshot,
} from "https://deno.land/std@$STD_VERSION/testing/snapshot.ts";

const assertSnapshot = createAssertSnapshot({
  // options
});
```

When configuring default options like this, the resulting `assertSnapshot`
function will function the same as the default function exported from the
snapshot module. If passed an optional options object, this will take precedence
over the default options, where the value provided for an option differs.

It is possible to "extend" an `assertSnapshot` function which has been
configured with default options.

```ts title="example_test.ts"
import {
  createAssertSnapshot,
} from "https://deno.land/std@$STD_VERSION/testing/snapshot.ts";
import { stripColor } from "https://deno.land/std@$STD_VERSION/fmt/colors.ts";

const assertSnapshot = createAssertSnapshot({
  dir: ".snaps",
});

const assertMonochromeSnapshot = createAssertSnapshot<string>(
  { serializer: stripColor },
  assertSnapshot,
);

Deno.test("isSnapshotMatch", async function (t): Promise<void> {
  const a = "\x1b[32mThis green text has had it's colours stripped\x1b[39m";
  await assertMonochromeSnapshot(t, a);
});
```

```js title=".snaps/example_test.ts.snap"
export const snapshot = {};

snapshot[`isSnapshotMatch 1`] = `This green text has had it's colours stripped`;
```

### Serialization with `Deno.customInspect`

The default serialization behaviour can be customised in two ways. The first is
by specifying the `serializer` option. This allows you to control the
serialisation of any value which is passed to a specific `assertSnapshot` call.
See the [above documentation](#options) on the correct usage of this option.

The second option is to make use of `Deno.customInspect`. Because the default
serializer used by `assertSnapshot` uses `Deno.inspect` under the hood, you can
set property `Symbol.for("Deno.customInspect")` to a custom serialization
function.

Doing so will ensure that the custom serialization will, by default, be used
whenever the object is passed to `assertSnapshot`. This can be useful in many
cases. One example is shown in the code snippet below.

```ts title="example_test.ts"
import {
  assertSnapshot,
} from "https://deno.land/std@$STD_VERSION/testing/snapshot.ts";

class HTMLTag {
  constructor(
    public name: string,
    public children: Array<HTMLTag | string> = [],
  ) {}

  public render(depth: number) {
    const indent = "  ".repeat(depth);
    let output = `${indent}<${this.name}>\n`;
    for (const child of this.children) {
      if (child instanceof HTMLTag) {
        output += `${child.render(depth + 1)}\n`;
      } else {
        output += `${indent}  ${child}\n`;
      }
    }
    output += `${indent}</${this.name}>`;
    return output;
  }

  public [Symbol.for("Deno.customInspect")]() {
    return this.render(0);
  }
}

Deno.test("Page HTML Tree", async (t) => {
  const page = new HTMLTag("html", [
    new HTMLTag("head", [
      new HTMLTag("title", [
        "Simple SSR Example",
      ]),
    ]),
    new HTMLTag("body", [
      new HTMLTag("h1", [
        "Simple SSR Example",
      ]),
      new HTMLTag("p", [
        "Ex of customInspect for a snapshot of an SSR representation",
      ]),
    ]),
  ]);

  await assertSnapshot(t, page);
});
```

This test will produce the following snapshot.

```js title="__snapshots__/example_test.ts.snap"
export const snapshot = {};

snapshot[`Page HTML Tree 1`] = `
<html>
  <head>
    <title>
      Simple SSR Example
    </title>
  </head>
  <body>
    <h1>
      Simple SSR Example
    </h1>
    <p>
      Ex of customInspect for a snapshot of an SSR representation
    </p>
  </body>
</html>
`;
```

In contrast, when we remove the `Deno.customInspect` method, the test will
produce the following snapshot.

```js title="__snapshots__/example_test.ts.snap"
export const snapshot = {};

snapshot[`Page HTML Tree 1`] = `
HTMLTag {
  children: [
    HTMLTag {
      children: [
        HTMLTag {
          children: [
            "Simple SSR Example",
          ],
          name: "title",
        },
      ],
      name: "head",
    },
    HTMLTag {
      children: [
        HTMLTag {
          children: [
            "Simple SSR Example",
          ],
          name: "h1",
        },
        HTMLTag {
          children: [
            "Ex of customInspect for a snapshot of an SSR representation",
          ],
          name: "p",
        },
      ],
      name: "body",
    },
  ],
  name: "html",
}
`;
```

You can see that this snapshot is much less readable. This is because:

1. The keys are sorted alphabetically, so the name of the element is displayed
   after its children
2. It includes a lot of extra information, causing the snapshot to be more than
   twice as long
3. It is not an accurate serialization of the HTML which the data represents

Note that in this example it would be entirely possible to achieve the same
result by calling:

```ts, ignore
await assertSnapshot(t, page.render(0));
```

However, depending on the public API you choose to expose, this may not be
practical in other cases.

It is also worth considering that this will have an impact beyond just snapshot
testing. For example, `Deno.customInspect` is also used to serialize objects
when calling `console.log` and in some other cases. This may or may not be
desirable.



/. 🚀 runtime/manual/advanced/index.md
===================================================

# Advanced Topics

In this chapter, you will find advanced Deno concepts, including:

- [Publishing Modules](./publishing/index.md)
- [Embedding Deno](./embedding_deno.md)
- [Language Server](./language_server/index.md)
- [Continuous Integration](./continuous_integration.md)
- [Using TypeScript](./typescript/overview.md)
- [Details on Using JSX and the DOM](./jsx_dom/index.md)



/. 🚀 runtime/manual/advanced/publishing/index.md
===================================================

# Publishing Modules

Deno is not prescriptive about how developers make their modules
available—modules may be imported from any source. To help publish and
distribute modules, separate standalone solutions are provided.

## Publishing on deno.land/x

A common way to publish Deno modules is via the official
[https://deno.land/x](https://deno.land/x) hosting service. It caches releases
of open source modules and serves them at one easy to remember domain.

To use it, modules must be developed and hosted in public repositories on
GitHub. Their source is then published to deno.land/x on tag creation. They can
then be accessed by using a url in the following format:

```
https://deno.land/x/<module_name>@<tag_name>/<file_path>
```

Module versions are persistent and immutable. It is thus not possible to edit or
delete a module (or version), to prevent breaking programs that rely on this
module. Modules may be removed if there is a legal reason to do so (for example
copyright infringement).

For more details, see [Adding a Module](https://deno.land/add_module).

## Auto-generating documentation for modules

When a module is published, the contents of the module is analyzed. An automated
process identifies modules that contain code that Deno understands and generates
documentation based on the code. For each path, including the root path, it
attempts to identify the default module. In order of preference it looks for
`mod`, `lib`, `main`, or `index` files with an extension that Deno understands
(ts,tsx,js,jsx,mjs, or mts). When viewing the documentation for the module for a
path, the default module will shown.

If a default module cannot be identified, a list of modules that can be
documented will be provided instead. When generating the documentation, not only
is the actual code parsed to generate it, inline documentation, in the form of
JSDoc (/** */) is used to enrich the documentation. Many JSDoc tags are
supported. To provide module level documentation (which also becomes the path
level documentation when it is included in a default module), use the @module
tag at the end of the first JSDoc block in the module.

## Publishing Deno modules for Node.js/npm

We have built a tool that assists in the process of taking Deno specific code
and publishing it to npm to work under Node.js or other parts of the JavaScript
ecosystem. See [dnt - Deno to Node.js Transform](./dnt.md).



/. 🚀 runtime/manual/advanced/publishing/dnt.md
===================================================

# Cross-runtime modules with dnt

Library authors may want to make their Deno modules available to Node.js users.
This is possible by using the [dnt](https://github.com/denoland/dnt) build tool.

dnt allows you to develop your Deno module mostly as-is and use a single Deno
script to build, type check, and test an npm package in an output directory.
Once built, you only need to `npm publish` the output directory to distribute it
to Node.js users.

For more details, see https://github.com/denoland/dnt



/. 🚀 runtime/manual/advanced/embedding_deno.md
===================================================

# Embedding Deno

Deno consists of multiple parts, one of which is `deno_core`. This is a Rust
crate that can be used to embed a JavaScript runtime into your Rust application.
Deno is built on top of `deno_core`.

The Deno crate is hosted on [crates.io](https://crates.io/crates/deno_core).

You can view the API on [docs.rs](https://docs.rs/deno_core).

<!-- TODO(lucacasonato): better docs -->



/. 🚀 runtime/manual/advanced/language_server/index.md
===================================================

# The Language Server

The Deno CLI comes with a built in language server that can provide an
intelligent editing experience as well as a way to easily access the other tools
that come built in with Deno. For most users, using the language server would be
via your editor like [Visual Studio Code](../../references/vscode_deno/index.md)
or [other editors](../../getting_started/setup_your_environment.md). This
section of the manual is designed for those creating integrations to the
language server or providing a package registry for Deno that integrates
intelligently.

In this section we will cover:

- [An Overview of the Language Server](./overview.md)
- [Import Completions and Intelligent Package Registries](./imports.md)



/. 🚀 runtime/manual/advanced/language_server/imports.md
===================================================

# Import Completions and Intelligent Registries

The language server, supports completions for URLs.

## Local import completions

When attempting to import a relative module specifier (one that starts with `./`
or `../`), import completions are provided for directories and files that Deno
thinks it can run (ending with the extensions `.ts`, `.js`, `.tsx`, `.jsx`, or
`.mjs`).

## Workspace import completions

When attempting to import a remote URL that isn't configured as a registry (see
below), the extension will provide remote modules that are already part of the
workspace.

## Module registry completions

Module registries that support it can be configured for auto completion. This
provides a handy way to explore a module registry from the "comfort" of your
IDE.

### Auto-discovery

The Deno language server, by default, will attempt to determine if a server
supports completion suggestions. If the host/origin has not been explicitly
configured, it will check the server, and if it supports completion suggestions
you will be prompted to choose to enable it or not.

You should only enable this for registries you trust, as the remote server could
provide suggestions for modules which are an attempt to get you to run
un-trusted code.

### Configuration

Settings for configuring registries for auto completions:

- `deno.suggest.imports.autoDiscover` - If enabled, when the language server
  discovers a new origin that isn't explicitly configured, it will check to see
  if that origin supports import completions and prompt you to enable it or not.
  This is `true` by default.
- `deno.suggest.imports.hosts` - These are the _origins_ that are configured to
  provide import completions. The target host needs to support Deno import
  completions (detailed below). The value is an object where the key is the host
  and the value is if it is enabled or not. For example:

  ```json
  {
    "deno.suggest.imports.hosts": {
      "https://deno.land": true
    }
  }
  ```

### How does it work?

On startup of the extension and language server, Deno will attempt to fetch
`/.well-known/deno-import-intellisense.json` from any of the hosts that are
configured and enabled. This file provides the data necessary to form auto
completion of module specifiers in a highly configurable way (meaning you aren't
tied into any particular module registry in order to get a rich editor
experience).

As you build or edit your module specifier, Deno will go and fetch additional
parts of the URL from the host based on what is configured in the JSON
configuration file.

When you complete the module specifier, if it isn't already cached locally for
you, Deno will attempt to fetch the completed specifier from the registry.

### Does it work with all remote modules?

No, as the extension and Deno need to understand how to _find_ modules. The
configuration file provides a highly flexible way to allow people to describe
how to build up a URL, including supporting things like semantic versioning if
the module registry supports it.

## Registry support for import completions

In order to support having a registry be discoverable by the Deno language
server, the registry needs to provide a few things:

- A schema definition file. This file needs to be located at
  `/.well-known/deno-import-intellisense.json`. This file provides the
  configuration needed to allow the Deno language server _query_ the registry
  and construct import specifiers.
- A series of API endpoints that provide the values to be provided to the user
  to complete an import specifier.

### Configuration schema

The JSON response to the schema definition needs to be an object with two
required properties:

- `"version"` - a number, which must be equal to `1` or `2`.
- `"registries"` - an array of registry objects which define how the module
  specifiers are constructed for this registry.

[There is a JSON Schema document which defines this
schema available as part of the CLI's source code.](https://deno.land/x/deno/cli/schemas/registry-completions.v2.json)

While the v2 supports more features than v1 did, they were introduced in a
non-breaking way, and the language server automatically handles v1 or v2
versions, irrespective of what version is supplied in the `"version"` key, so
technically a registry could profess itself to be v1 but use all the v2
features. This is not recommended though, because while there is no specific
branches in code to support the v2 features currently, that doesn't mean there
will not be in the future in order to support a _v3_ or whatever.

### Registries

In the configuration schema, the `"registries"` property is an array of
registries, which are objects which contain two required properties:

- `"schema"` - a string, which is an Express-like path matching expression,
  which defines how URLs are built on the registry. The syntax is directly based
  on [path-to-regexp](https://github.com/pillarjs/path-to-regexp). For example,
  if the following was the specifier for a URL on the registry:

  ```
  https://example.com/a_package@v1.0.0/mod.ts
  ```

  The schema value might be something like this:

  ```json
  {
    "version": 1,
    "registries": [
      {
        "schema": "/:package([a-z0-9_]*)@:version?/:path*"
      }
    ]
  }
  ```

- `"variables"` - for the keys defined in the schema, a corresponding variable
  needs to be defined, which informs the language server where to fetch
  completions for that part of the module specifier. In the example above, we
  had 3 variables of `package`, `version` and `path`, so we would expect a
  variable definition for each.

### Variables

In the configuration schema, the `"variables"` property is an array of variable
definitions, which are objects with two required properties:

- `"key"` - a string which matches the variable key name specifier in the
  `"schema"` property.
- `"documentation"` - An optional URL where the language server can fetch the
  documentation for an individual variable entry. Variables can be substituted
  in to build the final URL. Variables with a single brace format like
  `${variable}` will be added as matched out of the string, and those with
  double format like `${{variable}}` will be percent-encoded as a URI component
  part.
- `"url"` - A URL where the language server can fetch the completions for the
  variable. Variables can be substituted in to build the URL. Variables with a
  single brace format like `${variable}` will be added as matched out of the
  string, and those with double format like `${{variable}}` will be
  percent-encoded as a URI component part. If the variable the value of the
  `"key"` is included, then the language server will support incremental
  requests for partial modules, allowing the server to provide completions as a
  user types part of the variable value. If the URL is not fully qualified, the
  URL of the schema file will be used as a base. In our example above, we had
  three variables and so our variable definition might look like:

  ```json
  {
    "version": 1,
    "registries": [
      {
        "schema": "/:package([a-z0-9_]*)@:version?/:path*",
        "variables": [
          {
            "key": "package",
            "documentation": "https://api.example.com/docs/packages/${package}",
            "url": "https://api.example.com/packages/${package}"
          },
          {
            "key": "version",
            "url": "https://api.example.com/packages/${package}/versions"
          },
          {
            "key": "path",
            "documentation": "https://api.example.com/docs/packages/${package}/${{version}}/paths/${path}",
            "url": "https://api.example.com/packages/${package}/${{version}}/paths/${path}"
          }
        ]
      }
    ]
  }
  ```

#### URL endpoints

The response from each URL endpoint needs to be a JSON document that is an array
of strings or a _completions list_:

```typescript
interface CompletionList {
  /** The list (or partial list) of completion items. */
  items: string[];
  /** If the list is a partial list, and further queries to the endpoint will
   * change the items, set `isIncomplete` to `true`. */
  isIncomplete?: boolean;
  /** If one of the items in the list should be preselected (the default
   * suggestion), then set the value of `preselect` to the value of the item. */
  preselect?: string;
}
```

Extending our example from above the URL `https://api.example.com/packages`
would be expected to return something like:

```json
[
  "a_package",
  "another_package",
  "my_awesome_package"
]
```

Or something like this:

```json
{
  "items": [
    "a_package",
    "another_package",
    "my_awesome_package"
  ],
  "isIncomplete": false,
  "preselect": "a_package"
}
```

And a query to `https://api.example.com/packages/a_package/versions` would
return something like:

```json
[
  "v1.0.0",
  "v1.0.1",
  "v1.1.0",
  "v2.0.0"
]
```

Or:

```json
{
  "items": [
    "v1.0.0",
    "v1.0.1",
    "v1.1.0",
    "v2.0.0"
  ],
  "preselect": "v2.0.0"
}
```

And a query to
`https://api.example.com/packages/a_package/versions/v1.0.0/paths` would return
something like:

```json
[
  "a.ts",
  "b/c.js",
  "d/e.ts"
]
```

Or:

```json
{
  "items": [
    "a.ts",
    "b/c.js",
    "d/e.ts"
  ],
  "isIncomplete": true,
  "preselect": "a.ts"
}
```

#### Multi-part variables and folders

Navigating large file listings can be a challenge for the user. With the
registry V2, the language server has some special handling of returned items to
make it easier to complete a path to file in sub-folders easier.

When an item is returned that ends in `/`, the language server will present it
to the client as a "folder" which will be represented in the client. So a
registry wishing to provide sub-navigation to a folder structure like this:

```
examples/
└─┬─ first.ts
  └─ second.ts
sub-mod/
└─┬─ mod.ts
  └─ tests.ts
mod.ts
```

And had a schema like `/:package([a-z0-9_]*)@:version?/:path*` and an API
endpoint for `path` like
`https://api.example.com/packages/${package}/${{version}}/${path}` would want to
respond to the path of `/packages/pkg/1.0.0/` with:

```json
{
  "items": [
    "examples/",
    "sub-mod/",
    "mod.ts"
  ],
  "isIncomplete": true
}
```

And to a path of `/packages/pkg/1.0.0/examples/` with:

```json
{
  "items": [
    "examples/first.ts",
    "examples/second.ts"
  ],
  "isIncomplete": true
}
```

This would allow the user to select the folder `examples` in the IDE before
getting the listing of what was in the folder, making it easier to navigate the
file structure.

#### Documentation endpoints

Documentation endpoints should return a documentation object with any
documentation related to the requested entity:

```typescript
interface Documentation {
  kind: "markdown" | "plaintext";
  value: string;
}
```

For extending the example from above, a query to
`https://api.example.com/packages/a_package` would return something like:

```json
{
  "kind": "markdown",
  "value": "some _markdown_ `documentation` here..."
}
```

### Schema validation

When the language server is started up (or the configuration for the extension
is changed) the language server will attempt to fetch and validate the schema
configuration for the domain hosts specifier in the configuration.

The validation attempts to make sure that all registries defined are valid, that
the variables contained in those schemas are specified in the variables, and
that there aren't extra variables defined that are not included in the schema.
If the validation fails, the registry won't be enabled and the errors will be
logged to the Deno Language Server output in vscode.

If you are a registry maintainer and need help, advice, or assistance in setting
up your registry for auto-completions, feel free to open up an
[issue](https://github.com/denoland/deno/issues/new?labels=lsp&title=lsp%3A%20registry%20configuration)
and we will try to help.

## Known registries

The following is a list of registries known to support the scheme. All you need
to do is add the domain to `deno.suggest.imports.hosts` and set the value to
`true`:

- `https://deno.land/` - both the 3rd party `/x/` registry and the `/std/`
  library registry are available.
- `https://nest.land/` - a module registry for Deno on the blockweave.
- `https://crux.land/` - a free open-source registry for permanently hosting
  small scripts.



/. 🚀 runtime/manual/advanced/language_server/overview.md
===================================================

# Language Server Overview

The Deno Language Server provides a server implementation of the
[Language Server Protocol](https://microsoft.github.io/language-server-protocol/)
which is specifically tailored to provide a _Deno_ view of code. It is
integrated into the command line and can be started via the `lsp` sub-command.

Most users will never interact with the server directly, but instead will via
[`vscode_deno`](../../references/vscode_deno/index.md) or another
[editor extension](../../getting_started/setup_your_environment.md). This
documentation is for those implementing a editor client.

## Structure

When the language server is started, a `LanguageServer` instance is created
which holds all of the state of the language server. It also defines all of the
methods that the client calls via the Language Server RPC protocol.

## Settings

There are several settings that the language server supports for a workspace:

- `deno.enable`
- `deno.enablePaths`
- `deno.cache`
- `deno.certificateStores`
- `deno.config`
- `deno.importMap`
- `deno.internalDebug`
- `deno.codeLens.implementations`
- `deno.codeLens.references`
- `deno.codeLens.referencesAllFunctions`
- `deno.codeLens.test`
- `deno.suggest.completeFunctionCalls`
- `deno.suggest.names`
- `deno.suggest.paths`
- `deno.suggest.autoImports`
- `deno.suggest.imports.autoDiscover`
- `deno.suggest.imports.hosts`
- `deno.lint`
- `deno.tlsCertificate`
- `deno.unsafelyIgnoreCertificateErrors`
- `deno.unstable`

There are settings that are supported on a per resource basis by the language
server:

- `deno.enable`
- `deno.enablePaths`
- `deno.codeLens.test`

There are several points in the process where Deno analyzes these settings.
First, when the `initialize` request from the client, the
`initializationOptions` will be assumed to be an object that represents the
`deno` namespace of options. For example, the following value:

```json
{
  "enable": true,
  "unstable": true
}
```

Would enable Deno with the unstable APIs for this instance of the language
server.

When the language server receives a `workspace/didChangeConfiguration`
notification, it will assess if the client has indicated if it has a
`workspaceConfiguration` capability. If it does, it will send a
`workspace/configuration` request which will include a request for the workspace
configuration as well as the configuration of all URIs that the language server
is currently tracking.

If the client has the `workspaceConfiguration` capability, the language server
will send a configuration request for the URI when it received the
`textDocument/didOpen` notification in order to get the resources specific
settings.

If the client does not have the `workspaceConfiguration` capability, the
language server will assume the workspace setting applies to all resources.

## Commands

There are several commands that might be issued by the language server to the
client, which the client is expected to implement:

- `deno.cache` - This is sent as a resolution code action when there is an
  un-cached module specifier that is being imported into a module. It will be
  sent with and argument that contains the resolved specifier as a string to be
  cached.
- `deno.showReferences` - This is sent as the command on some code lenses to
  show locations of references. The arguments contain the specifier that is the
  subject of the command, the start position of the target and the locations of
  the references to show.
- `deno.test` - This is sent as part of a test code lens to, of which the client
  is expected to run a test based on the arguments, which are the specifier the
  test is contained in and the name of the test to filter the tests on.

## Requests

The LSP currently supports the following custom requests. A client should
implement these in order to have a fully functioning client that integrates well
with Deno:

- `deno/cache` - This command will instruct Deno to attempt to cache a module
  and all of its dependencies. If a `referrer` only is passed, then all
  dependencies for the module specifier will be loaded. If there are values in
  the `uris`, then only those `uris` will be cached.

  It expects parameters of:

  ```ts, ignore
  interface CacheParams {
    referrer: TextDocumentIdentifier;
    uris: TextDocumentIdentifier[];
  }
  ```
- `deno/performance` - Requests the return of the timing averages for the
  internal instrumentation of Deno.

  It does not expect any parameters.
- `deno/reloadImportRegistries` - Reloads any cached responses from import
  registries.

  It does not expect any parameters.
- `deno/virtualTextDocument` - Requests a virtual text document from the LSP,
  which is a read only document that can be displayed in the client. This allows
  clients to access documents in the Deno cache, like remote modules and
  TypeScript library files built into Deno. The Deno language server will encode
  all internal files under the custom schema `deno:`, so clients should route
  all requests for the `deno:` schema back to the `deno/virtualTextDocument`
  API.

  It also supports a special URL of `deno:/status.md` which provides a markdown
  formatted text document that contains details about the status of the LSP for
  display to a user.

  It expects parameters of:

  ```ts, ignore
  interface VirtualTextDocumentParams {
    textDocument: TextDocumentIdentifier;
  }
  ```

- `deno/task` - Requests the return of available deno tasks, see
  [task_runner](../../tools/task_runner.md).

  It does not expect any parameters.

## Notifications

There is currently one custom notification that is sent from the server to the
client:

- `deno/registryState` - when `deno.suggest.imports.autoDiscover` is `true` and
  an origin for an import being added to a document is not explicitly set in
  `deno.suggest.imports.hosts`, the origin will be checked and the notification
  will be sent to the client of the status.

  When receiving the notification, if the param `suggestion` is `true`, the
  client should offer the user the choice to enable the origin and add it to the
  configuration for `deno.suggest.imports.hosts`. If `suggestion` is `false` the
  client should add it to the configuration of as `false` to stop the language
  server from attempting to detect if suggestions are supported.

  The params for the notification are:

  ```ts
  interface RegistryStatusNotificationParams {
    origin: string;
    suggestions: boolean;
  }
  ```

## Language IDs

The language server supports diagnostics and formatting for the following
[text document language IDs](https://microsoft.github.io/language-server-protocol/specifications/specification-current/#textDocumentItem):

- `"javascript"`
- `"javascriptreact"`
- `"jsx"` _non standard, same as `javascriptreact`_
- `"typescript"`
- `"typescriptreact"`
- `"tsx"` _non standard, same as `typescriptreact`_

The language server supports only formatting for the following language IDs:

- `"json"`
- `"jsonc"`
- `"markdown"`



/. 🚀 runtime/manual/advanced/language_server/testing_api.md
===================================================

# Testing API

The Deno language server supports a custom set of APIs to enable testing. These
are built around providing information to enable the
[vscode's Testing API](https://code.visualstudio.com/api/extension-guides/testing)
but can be used by other language server clients to provide a similar interface.

## Capabilities

Both the client and the server should support the experimental `testingApi`
capability:

```ts
interface ClientCapabilities {
  experimental?: {
    testingApi: boolean;
  };
}
```

```ts
interface ServerCapabilities {
  experimental?: {
    testingApi: boolean;
  };
}
```

When a version of Deno that supports the testing API encounters a client which
supports the capability, it will initialize the code which handles the test
detection and will start providing the notifications which enable it.

It should also be noted that when the testing API capabilities are enabled, the
testing code lenses will no longer be sent to the client.

## Settings

There are specific settings which change the behavior of the language server:

- `deno.testing.args` - An array of strings which will be provided as arguments
  when executing tests. This works in the same fashion as the `deno test`
  subcommand.
- `deno.testing.enable` - A binary flag that enables or disables the testing
  server

## Notifications

The server will send notifications to the client under certain conditions.

### `deno/testModule`

When a module containing tests is discovered by the server, it will notify the
client by sending a `deno/testModule` notification along with a payload of
`TestModuleParams`.

Deno structures in this fashion:

- A module can contain _n_ tests.
- A test can contain _n_ steps.
- A step can contain _n_ steps.

When Deno does static analysis of a test module, it attempts to identify any
tests and test steps. Because of the dynamic way tests can be declared in Deno,
they cannot always be statically identified and can only be identified when the
module is executed. The notification is designed to handle both of these
situations when updating the client. When tests are discovered statically, the
notification `kind` will be `"replace"`, when tests or steps are discovered at
execution time, the notification `kind` will be `"insert"`.

As a test document is edited in the editor, and `textDocument/didChange`
notifications are received from the client, the static analysis of those changes
will be performed server side and if the tests have changed, the client will
receive a notification.

When a client receives a `"replace"` notification, it can safely "replace" a
test module representation, where when an `"insert"` it received, it should
recursively try to add to existing representations.

For test modules the `textDocument.uri` should be used as the unique ID for any
representation (as it the string URL to the unique module). `TestData` items
contain a unique `id` string. This `id` string is a SHA-256 hash of identifying
information that the server tracks for a test.

```ts, ignore
interface TestData {
  /** The unique ID for this test/step. */
  id: string;

  /** The display label for the test/step. */
  label: string;

  /** Any test steps that are associated with this test/step */
  steps?: TestData[];

  /** The range of the owning text document that applies to the test. */
  range?: Range;
}

interface TestModuleParams {
  /** The text document identifier that the tests are related to. */
  textDocument: TextDocumentIdentifier;

  /** A indication if tests described are _newly_ discovered and should be
   * _inserted_ or if the tests associated are a replacement for any existing
   * tests. */
  kind: "insert" | "replace";

  /** The text label for the test module. */
  label: string;

  /** An array of tests that are owned by this test module. */
  tests: TestData[];
}
```

### `deno/testModuleDelete`

When a test module is deleted that the server is observing, the server will
issue a `deno/testModuleDelete` notification. When receiving the notification
the client should remove the representation of the test module and all of its
children tests and test steps.

```ts, ignore
interface TestModuleDeleteParams {
  /** The text document identifier that has been removed. */
  textDocument: TextDocumentIdentifier;
}
```

### `deno/testRunProgress`

When a [`deno/testRun`](#denotestrun) is requested from the client, the server
will support progress of that test run via the `deno/testRunProgress`
notification.

The client should process these messages and update any UI representation.

The state change is represented in the `.message.kind` property of the
`TestRunProgressParams`. The states are:

- `"enqueued"` - A test or test step has been enqueued for testing.
- `"skipped"` - A test or test step was skipped. This occurs when the Deno test
  has the `ignore` option set to `true`.
- `"started"` - A test or test step has started.
- `"passed"` - A test or test step has passed.
- `"failed"` - A test or test step has failed. This is intended to indicate an
  error with the test harness instead of the test itself, but Deno currently
  does not support this distinction.
- `"errored"` - The test or test step has errored. Additional information about
  the error will be in the `.message.messages` property.
- `"end"` - The test run has ended.

```ts, ignore
interface TestIdentifier {
  /** The test module the message is related to. */
  textDocument: TextDocumentIdentifier;

  /** The optional ID of the test. If not present, then the message applies to
   * all tests in the test module. */
  id?: string;

  /** The optional ID of the step. If not present, then the message only applies
   * to the test. */
  stepId?: string;
}

interface TestMessage {
  /** The content of the message. */
  message: MarkupContent;

  /** An optional string which represents the expected output. */
  expectedOutput?: string;

  /** An optional string which represents the actual output. */
  actualOutput?: string;

  /** An optional location related to the message. */
  location?: Location;
}

interface TestEnqueuedStartedSkipped {
  /** The state change that has occurred to a specific test or test step.
   *
   * - `"enqueued"` - the test is now enqueued to be tested
   * - `"started"` - the test has started
   * - `"skipped"` - the test was skipped
   */
  type: "enqueued" | "started" | "skipped";

  /** The test or test step relating to the state change. */
  test: TestIdentifier;
}

interface TestFailedErrored {
  /** The state change that has occurred to a specific test or test step.
   *
   * - `"failed"` - The test failed to run properly, versus the test erroring.
   *   currently the Deno language server does not support this.
   * - `"errored"` - The test errored.
   */
  type: "failed" | "errored";

  /** The test or test step relating to the state change. */
  test: TestIdentifier;

  /** Messages related to the state change. */
  messages: TestMessage[];

  /** An optional duration, in milliseconds from the start to the current
   * state. */
  duration?: number;
}

interface TestPassed {
  /** The state change that has occurred to a specific test or test step. */
  type: "passed";

  /** The test or test step relating to the state change. */
  test: TestIdentifier;

  /** An optional duration, in milliseconds from the start to the current
   * state. */
  duration?: number;
}

interface TestOutput {
  /** The test or test step has output information / logged information. */
  type: "output";

  /** The value of the output. */
  value: string;

  /** The associated test or test step if there was one. */
  test?: TestIdentifier;

  /** An optional location associated with the output. */
  location?: Location;
}

interface TestEnd {
  /** The test run has ended. */
  type: "end";
}

type TestRunProgressMessage =
  | TestEnqueuedStartedSkipped
  | TestFailedErrored
  | TestPassed
  | TestOutput
  | TestEnd;

interface TestRunProgressParams {
  /** The test run ID that the progress message applies to. */
  id: number;

  /** The message*/
  message: TestRunProgressMessage;
}
```

## Requests

The server handles two different requests:

### `deno/testRun`

To request the language server to perform a set of tests, the client sends a
`deno/testRun` request, which includes that ID of the test run to be used in
future responses to the client, the type of the test run, and any test modules
or tests to include or exclude.

Currently Deno only supports the `"run"` kind of test run. Both `"debug"` and
`"coverage"` are planned to be supported in the future.

When there are no test modules or tests that are included, it implies that all
discovered tests modules and tests should be executed. When a test module is
included, but not any test ids, it implies that all tests within that test
module should be included. Once all the tests are identified, any excluded tests
are removed and the resolved set of tests are returned in the response as
`"enqueued"`.

It is not possible to include or exclude test steps via this API, because of the
dynamic nature of how test steps are declared and run.

```ts, ignore
interface TestRunRequestParams {
  /** The id of the test run to be used for future messages. */
  id: number;

  /** The run kind. Currently Deno only supports `"run"` */
  kind: "run" | "coverage" | "debug";

  /** Test modules or tests to exclude from the test run. */
  exclude?: TestIdentifier[];

  /** Test modules or tests to include in the test run. */
  include?: TestIdentifier[];
}

interface EnqueuedTestModule {
  /** The test module the enqueued test IDs relate to */
  textDocument: TextDocumentIdentifier;

  /** The test IDs which are now enqueued for testing */
  ids: string[];
}

interface TestRunResponseParams {
  /** Test modules and test IDs that are now enqueued for testing. */
  enqueued: EnqueuedTestModule[];
}
```

### `deno/testRunCancel`

If a client wishes to cancel a currently running test run, it sends a
`deno/testRunCancel` request with the test ID to cancel. The response back will
be a boolean of `true` if the test is cancelled or `false` if it was not
possible. Appropriate test progress notifications will still be sent as the test
is being cancelled.

```ts
interface TestRunCancelParams {
  /** The test id to be cancelled. */
  id: number;
}
```



/. 🚀 runtime/manual/advanced/continuous_integration.md
===================================================

# Continuous Integration

Deno's built-in tools make it easy to set up Continuous Integration (CI)
pipelines for your projects. Testing, linting and formatting of code can all be
done with the corresponding commands `deno test`, `deno lint` and `deno fmt`. In
addition, you can generate code coverage reports from test results with
`deno coverage` in pipelines.

On this page we will discuss:

- [Setting up a basic pipeline](#setting-up-a-basic-pipeline)
- [Cross-platform workflows](#cross-platform-workflows)
- [Speeding up Deno pipelines](#speeding-up-deno-pipelines)
  - [Reducing repetition](#reducing-repetition)
  - [Caching dependencies](#caching-dependencies)

## Setting up a basic pipeline

This page will show you how to set up basic pipelines for Deno projects in
GitHub Actions. The concepts explained on this page largely apply to other CI
providers as well, such as Azure Pipelines, CircleCI or GitLab.

Building a pipeline for Deno generally starts with checking out the repository
and installing Deno:

```yaml
name: Build

on: push

jobs:
  build:
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v3
      - uses: denoland/setup-deno@v1
        with:
          deno-version: v1.x # Run with latest stable Deno.
```

To expand the workflow just add any of the `deno` subcommands that you might
need:

```yaml
      # Check if the code is formatted according to Deno's default
      # formatting conventions.
      - run: deno fmt --check

      # Scan the code for syntax errors and style issues. If
      # you want to use a custom linter configuration you can add a configuration file with --config <myconfig>
      - run: deno lint

      # Run all test files in the repository and collect code coverage. The example
      # runs with all permissions, but it is recommended to run with the minimal permissions your program needs (for example --allow-read).
      - run: deno test --allow-all --coverage=cov/

      # This generates a report from the collected coverage in `deno test --coverage`. It is
      # stored as a .lcov file which integrates well with services such as Codecov, Coveralls and Travis CI.
      - run: deno coverage --lcov cov/ > cov.lcov
```

## Cross-platform workflows

As a Deno module maintainer, you probably want to know that your code works on
all of the major operating systems in use today: Linux, MacOS and Windows. A
cross-platform workflow can be achieved by running a matrix of parallel jobs,
each one running the build on a different OS:

```yaml
jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ ubuntu-22.04, macos-12, windows-2022 ]
    steps:
      - run: deno test --allow-all --coverage cov/
```

> Note: GitHub Actions has a known
> [issue](https://github.com/actions/checkout/issues/135) with handling
> Windows-style line endings (CRLF). This may cause issues when running
> `deno fmt` in a pipeline with jobs that run on `windows`. To prevent this,
> configure the Actions runner to use Linux-style line endings before running
> the `actions/checkout@v3` step:
>
> ```
> git config --system core.autocrlf false
> git config --system core.eol lf
> ```

If you are working with experimental or unstable Deno APIs, you can include a
matrix job running the canary version of Deno. This can help to spot breaking
changes early on:

```yaml
jobs:
  build:
    runs-on: ${{ matrix.os }}
    continue-on-error: ${{ matrix.canary }} # Continue in case the canary run does not succeed
    strategy:
      matrix:
        os: [ ubuntu-22.04, macos-12, windows-2022 ]
        deno-version: [ v1.x ]
        canary: [ false ]
        include: 
          - deno-version: canary
            os: ubuntu-22.04
            canary: true
```

## Speeding up Deno pipelines

### Reducing repetition

In cross-platform runs, certain steps of a pipeline do not need to run for each
OS necessarily. For example, generating the same test coverage report on Linux,
MacOS and Windows is a bit redundant. You can use the `if` conditional keyword
of GitHub Actions in these cases. The example below shows how to run code
coverage generation and upload steps only on the `ubuntu` (Linux) runner:

```yaml
- name: Generate coverage report
  if: matrix.os == 'ubuntu-22.04'
  run: deno coverage --lcov cov > cov.lcov

- name: Upload coverage to Coveralls.io
  if: matrix.os == 'ubuntu-22.04'
  # Any code coverage service can be used, Coveralls.io is used here as an example.
  uses: coverallsapp/github-action@master
  with:
    github-token: ${{ secrets.GITHUB_TOKEN }} # Generated by GitHub.
    path-to-lcov: cov.lcov
```

### Caching dependencies

As a project grows in size, more and more dependencies tend to be included. Deno
will download these dependencies during testing and if a workflow is run many
times a day, this can become a time-consuming process. A common solution to
speed things up is to cache dependencies so that they do not need to be
downloaded anew.

[Deno stores dependencies locally in a cache directory](https://deno.land/manual/linking_to_external_code).
In a pipeline the cache can be preserved between workflows by setting the
`DENO_DIR` environment variable and adding a caching step to the workflow:

```yaml
# Set DENO_DIR to an absolute or relative path on the runner.
env:
  DENO_DIR: my_cache_directory

steps:
  - name: Cache Deno dependencies 
    uses: actions/cache@v2
    with:
      path: ${{ env.DENO_DIR }}
      key: my_cache_key
```

At first, when this workflow runs the cache is still empty and commands like
`deno test` will still have to download dependencies, but when the job succeeds
the contents of `DENO_DIR` are saved and any subsequent runs can restore them
from cache instead of re-downloading.

There is still an issue in the workflow above: at the moment the name of the
cache key is hardcoded to `my_cache_key`, which is going to restore the same
cache every time, even if one or more dependencies are updated. This can lead to
older versions being used in the pipeline even though you have updated some
dependencies. The solution is to generate a different key each time the cache
needs to be updated, which can be achieved by using a lockfile and by using the
`hashFiles` function provided by GitHub Actions:

```yaml
key: ${{ hashFiles('deno.lock') }}
```

To make this work you will also need a have a lockfile in your Deno project,
which is discussed in detail [here](../basics/modules/integrity_checking.md).
Now, if the contents of `deno.lock` are changed, a new cache will be made and
used in subsequent pipeline runs thereafter.

To demonstrate, let's say you have a project that uses the logger from
`deno.land/std`:

```ts
import * as log from "https://deno.land/std@$STD_VERSION/log/mod.ts";
```

In order to increment this version, you can update the `import` statement and
then reload the cache and update the lockfile locally:

```
deno cache --reload --lock=deno.lock --lock-write deps.ts
```

You should see changes in the lockfile's contents after running this. When this
is committed and run through the pipeline, you should then see the `hashFiles`
function saving a new cache and using it in any runs that follow.

#### Clearing the cache

Occasionally you may run into a cache that has been corrupted or malformed,
which can happen for various reasons. It is possible to clear a cache from the
GitHub Actions UI, or you can simply change the name of the cache key. A
practical way of doing so without having to forcefully change your lockfile is
to add a variable to the cache key name, which can be stored as a GitHub secret
and can be changed if a new cache is needed:

```yaml
key: ${{ secrets.CACHE_VERSION }}-${{ hashFiles('deno.lock') }}
```



/. 🚀 runtime/manual/advanced/typescript/configuration.md
===================================================

# Configuring TypeScript in Deno

TypeScript comes with a lot of different options that can be configured, but
Deno strives to make it easy to use TypeScript with Deno. Lots of different
options frustrates that goal. To make things easier, Deno configures TypeScript
to "just work" and shouldn't require additional configuration.

That being said, Deno does support using a TypeScript configuration file. To use
a TypeScript configuration file with Deno, you may provide a path on the command
line, or use the default. For example:

```
> deno run --config ./deno.json main.ts
```

> ⚠️ Do consider though that if you are creating libraries that require a
> configuration file, all of the consumers of your modules will require that
> configuration file too if you distribute your modules as TypeScript. In
> addition, there could be settings you do in the configuration file that make
> other TypeScript modules incompatible. Honestly it is best to use the Deno
> defaults and to think long and hard about using a configuration file.

> ⚠️ Deno v1.14 started supporting a more general configuration file that is no
> longer confined to specifying TypeScript compiler settings. Using
> `tsconfig.json` as a file name will still work, but we recommend to use
> `deno.json` or `deno.jsonc`, as an automatic lookup of this file is planned
> for an upcoming release.

## How Deno uses a configuration file

Deno does not process a TypeScript configuration file like `tsc` does, as there
are lots of parts of a TypeScript configuration file that are meaningless in a
Deno context or would cause Deno to not function properly if they were applied.

Deno only looks at the `compilerOptions` section of a configuration file, and
even then it only considers certain compiler options, with the rest being
ignored.

Here is a table of compiler options that can be changed, their default in Deno
and any other notes about that option:

| Option                           | Default                 | Notes                                                                                                                                     |
| -------------------------------- | ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| `allowJs`                        | `true`                  | This almost never needs to be changed                                                                                                     |
| `allowUnreachableCode`           | `false`                 |                                                                                                                                           |
| `allowUnusedLabels`              | `false`                 |                                                                                                                                           |
| `checkJs`                        | `false`                 | If `true` causes TypeScript to type check JavaScript                                                                                      |
| `jsx`                            | `"react"`               |                                                                                                                                           |
| `jsxFactory`                     | `"React.createElement"` |                                                                                                                                           |
| `jsxFragmentFactory`             | `"React.Fragment"`      |                                                                                                                                           |
| `keyofStringsOnly`               | `false`                 |                                                                                                                                           |
| `lib`                            | `[ "deno.window" ]`     | The default for this varies based on other settings in Deno. If it is supplied, it overrides the default. See below for more information. |
| `noErrorTruncation`              | `false`                 |                                                                                                                                           |
| `noFallthroughCasesInSwitch`     | `false`                 |                                                                                                                                           |
| `noImplicitAny`                  | `true`                  |                                                                                                                                           |
| `noImplicitReturns`              | `false`                 |                                                                                                                                           |
| `noImplicitThis`                 | `true`                  |                                                                                                                                           |
| `noImplicitUseStrict`            | `true`                  |                                                                                                                                           |
| `noStrictGenericChecks`          | `false`                 |                                                                                                                                           |
| `noUnusedLocals`                 | `false`                 |                                                                                                                                           |
| `noUnusedParameters`             | `false`                 |                                                                                                                                           |
| `noUncheckedIndexedAccess`       | `false`                 |                                                                                                                                           |
| `reactNamespace`                 | `React`                 |                                                                                                                                           |
| `strict`                         | `true`                  |                                                                                                                                           |
| `strictBindCallApply`            | `true`                  |                                                                                                                                           |
| `strictFunctionTypes`            | `true`                  |                                                                                                                                           |
| `strictPropertyInitialization`   | `true`                  |                                                                                                                                           |
| `strictNullChecks`               | `true`                  |                                                                                                                                           |
| `suppressExcessPropertyErrors`   | `false`                 |                                                                                                                                           |
| `suppressImplicitAnyIndexErrors` | `false`                 |                                                                                                                                           |
| `useUnknownInCatchVariables`     | `false`                 |                                                                                                                                           |

For a full list of compiler options and how they affect TypeScript, please refer
to the
[TypeScript Handbook](https://www.typescriptlang.org/docs/handbook/compiler-options.html).

## What an implied tsconfig.json looks like

It is impossible to get `tsc` to behave like Deno. It is also difficult to get
the TypeScript language service to behave like Deno. This is why we have built a
language service directly into Deno. That being said, it can be useful to
understand what is implied.

If you were to write a `tsconfig.json` for Deno, it would look something like
this:

```json
{
  "compilerOptions": {
    "allowJs": true,
    "esModuleInterop": true,
    "experimentalDecorators": true,
    "inlineSourceMap": true,
    "isolatedModules": true,
    "jsx": "react",
    "lib": ["deno.window"],
    "module": "esnext",
    "moduleDetection": "force",
    "strict": true,
    "target": "esnext",
    "useDefineForClassFields": true
  }
}
```

You can't copy paste this into a configuration file and get it to work,
specifically because of the built-in type libraries that are custom to Deno
which are provided to the TypeScript compiler. This can somewhat be mocked by
running `deno types` on the command line and piping the output to a file and
including that in the files as part of the program, removing the `"lib"` option,
and setting the `"noLib"` option to `true`.

If you use the `--unstable` flag, Deno will change the `"lib"` option to
`[ "deno.window", "deno.unstable" ]`. If you are trying to load a worker, that
is type checked with `"deno.worker"` instead of `"deno.window"`. See
[Type Checking Web Workers](./types.md#type-checking-web-workers) for more
information on this.

## Using the "lib" property

Deno has several libraries built into it that are not present in other
platforms, like `tsc`. This is what enables Deno to properly check code written
for Deno. In some situations though, this automatic behavior can cause
challenges, for example like writing code that is intended to also run in a
browser. In these situations the `"lib"` property of a `compilerOptions` can be
used to modify the behavior of Deno when type checking code.

The built-in libraries that are of interest to users:

- `"deno.ns"` - This includes all the custom `Deno` global namespace APIs plus
  the Deno additions to `import.meta`. This should generally not conflict with
  other libraries or global types.
- `"deno.unstable"` - This includes the addition unstable `Deno` global
  namespace APIs.
- `"deno.window"` - This is the "default" library used when checking Deno main
  runtime scripts. It includes the `"deno.ns"` as well as other type libraries
  for the extensions that are built into Deno. This library will conflict with
  libraries like `"dom"` and `"dom.iterable"` that are standard TypeScript
  libraries.
- `"deno.worker"` - This is the library used when checking a Deno web worker
  script. For more information about web workers, check out
  [Type Checking Web Workers](./types.md#type-checking-web-workers).
- `"dom.asynciterable"` - TypeScript currently does not include the DOM async
  iterables that Deno implements (plus several browsers), so we have implemented
  it ourselves until it becomes available in TypeScript.

These are common libraries that Deno doesn't use, but are useful when writing
code that is intended to also work in another runtime:

- `"dom"` - The main browser global library that ships with TypeScript. The type
  definitions conflict in many ways with `"deno.window"` and so if `"dom"` is
  used, then consider using just `"deno.ns"` to expose the Deno specific APIs.
- `"dom.iterable"` - The iterable extensions to the browser global library.
- `"scripthost"` - The library for the Microsoft Windows Script Host.
- `"webworker"` - The main library for web workers in the browser. Like `"dom"`
  this will conflict with `"deno.window"` or `"deno.worker"`, so consider using
  just `"deno.ns"` to expose the Deno specific APIs.
- `"webworker.importscripts"` - The library that exposes the `importScripts()`
  API in the web worker.
- `"webworker.iterable"` - The library that adds iterables to objects within a
  web worker. Modern browsers support this.

### Targeting Deno and the Browser

A common use case is writing code that works in Deno and the browser: using a
conditional check to determine the environment in which the code is executing
before using any APIs which are exclusive to one or the other. If that is the
case, a common configuration of a `compilerOptions` would look like this:

```json
{
  "compilerOptions": {
    "target": "esnext",
    "lib": ["dom", "dom.iterable", "dom.asynciterable", "deno.ns"]
  }
}
```

This should allow most code to be type checked properly by Deno.

If you expect to run the code in Deno with the `--unstable` flag, then you will
want to add that library to the mix as well:

```json
{
  "compilerOptions": {
    "target": "esnext",
    "lib": [
      "dom",
      "dom.iterable",
      "dom.asynciterable",
      "deno.ns",
      "deno.unstable"
    ]
  }
}
```

Typically when you use the `"lib"` option in TypeScript, you need to include an
"es" library as well. In the case of `"deno.ns"` and `"deno.unstable"`, they
automatically include `"esnext"` when you bring them in.

The biggest "danger" when doing something like this, is that the type checking
is significantly looser, and there is no way to validate that you are doing
sufficient and effective feature detection in your code, which may lead to what
could be trivial errors becoming runtime errors.

## Using the "types" property

The `"types"` property in `"compilerOptions"` can be used to specify arbitrary
type definitions to include when type checking a program. For more information
on this see
[Using ambient or global types](./types.md#using-ambient-or-global-types).



/. 🚀 runtime/manual/advanced/typescript/faqs.md
===================================================

# FAQs about TypeScript in Deno

## Can I use TypeScript not written for Deno?

Maybe. That is the best answer, we are afraid. For lots of reasons, Deno has
chosen to have fully qualified module specifiers. In part this is because it
treats TypeScript as a first class language. Also, Deno uses explicit module
resolution, with no _magic_. This is effectively the same way browsers
themselves work, though they don't obviously support TypeScript directly. If the
TypeScript modules use imports that don't have these design decisions in mind,
they may not work under Deno.

Also, in recent versions of Deno (starting with 1.5), we have started to use a
Rust library to do transformations of TypeScript to JavaScript in certain
scenarios. Because of this, there are certain situations in TypeScript where
type information is required, and therefore those are not supported under Deno.
If you are using `tsc` as stand-alone, the setting to use is `"isolatedModules"`
and setting it to `true` to help ensure that your code can be properly handled
by Deno.

One of the ways to deal with the extension and the lack of Node.js non-standard
resolution logic is to use [import maps](../../basics/import_maps.md) which
would allow you to specify "packages" of bare specifiers which then Deno could
resolve and load.

## What version(s) of TypeScript does Deno support?

Deno is built with a specific version of TypeScript. To find out what this is,
type the following on the command line:

```shell
> deno --version
```

The TypeScript version (along with the version of Deno and v8) will be printed.
Deno tries to keep up to date with general releases of TypeScript, providing
them in the next patch or minor release of Deno.

## There was a breaking change in the version of TypeScript that Deno uses, why did you break my program?

We do not consider changes in behavior or breaking changes in TypeScript
releases as breaking changes for Deno. TypeScript is a generally mature language
and breaking changes in TypeScript are almost always "good things" making code
more sound, and it is best that we all keep our code sound. If there is a
blocking change in the version of TypeScript and it isn't suitable to use an
older release of Deno until the problem can be resolved, then you should be able
to use `--no-check` to skip type checking all together.

In addition you can utilize `@ts-ignore` to _ignore_ a specific error in code
that you control. You can also replace whole dependencies, using
[import maps](../../basics/import_maps.md), for situations where a dependency of
a dependency isn't being maintained or has some sort of breaking change you want
to bypass while waiting for it to be updated.

## How do I write code that works in Deno and a browser, but still type checks?

You can do this by using a configuration file with the `--config` option on the
command line and adjusting the `"lib"` option in the `"compilerOptions"` in the
file. For more information see
[Targeting Deno and the Browser](./configuration.md#targeting-deno-and-the-browser).

## Why are you forcing me to use isolated modules, why can't I use const enums with Deno, why do I need to do export type?

As of Deno 1.5 we defaulted to _isolatedModules_ to `true` and in Deno 1.6 we
removed the options to set it back to `false` via a configuration file. The
_isolatedModules_ option forces the TypeScript compiler to check and emit
TypeScript as if each module would stand on its own. TypeScript has a few _type
directed emits_ in the language at the moment. While not allowing type directed
emits into the language was a design goal for TypeScript, it has happened
anyways. This means that the TypeScript compiler needs to understand the
erasable types in the code to determine what to emit, which when you are trying
to make a fully erasable type system on top of JavaScript, that becomes a
problem.

When people started transpiling TypeScript without `tsc`, these type directed
emits became a problem, since the likes of Babel simply try to erase the types
without needing to understand the types to direct the emit.

So instead of trying to get every user to understand when and how we could
support the type directed emits, we made the decision to disable the use of them
by forcing the _isolatedModules_ option to `true`. This means that even when we
are using the TypeScript compiler to emit the code, it will follow the same
"rules" that the Rust based emitter follows.

This means that certain language features are not supportable. Those features
are:

- Re-exporting of types is ambiguous and requires knowing if the source module
  is exporting runtime code or just type information. Therefore, it is
  recommended that you use `import type` and `export type` for type only imports
  and exports. This will help ensure that when the code is emitted, that all the
  types are erased.
- `const enum` is not supported. `const enum`s require type information to
  direct the emit, as `const enum`s get written out as hard coded values.
  Especially when `const enum`s get exported, they are a type system only
  construct.
- `export =` and `import =` are legacy TypeScript syntax which we do not
  support.
- Only `declare namespace` is supported. Runtime `namespace` is legacy
  TypeScript syntax that is not supported.

## Why don't you support language service plugins or transformer plugins?

While `tsc` supports language service plugins, Deno does not. Deno does not
always use the built-in TypeScript compiler to do what it does, and the
complexity of adding support for a language service plugin is not feasible.
TypeScript does not support emitter plugins, but there are a few community
projects which _hack_ emitter plugins into TypeScript. First, we wouldn't want
to support something that TypeScript doesn't support, plus we do not always use
the TypeScript compiler for the emit, which would mean we would need to ensure
we supported it in all modes, and the other emitter is written in Rust, meaning
that any emitter plugin for TypeScript wouldn't be available for the Rust
emitter.

## How do I combine Deno code with non-Deno code in my IDE?

The Deno language server supports the ability to have a "per-resource"
configuration of enabling Deno or not. This also requires a client IDE to
support this ability. For Visual Studio Code the official
[Deno extension](https://marketplace.visualstudio.com/items?itemName=denoland.vscode-deno)
supports the vscode concept of
[multi-root workspace](https://code.visualstudio.com/docs/editor/multi-root-workspaces).
This means you just need to add folders to the workspace and set the
`deno.enable` setting as required on each folder.

For other IDEs, the client extensions needs to support the similar IDE concepts.



/. 🚀 runtime/manual/advanced/typescript/migration.md
===================================================

# Migrating to and from JavaScript

One of the advantages of Deno is that it treats TypeScript and JavaScript pretty
equally. This might mean that transitioning from JavaScript to TypeScript or
even from TypeScript to JavaScript is something you want to accomplish. There
are several features of Deno that can help with this.

## Type checking JavaScript

You might have some JavaScript that you would like to ensure is more type sound
but you don't want to go through a process of adding type annotations
everywhere.

Deno supports using the TypeScript type checker to type check JavaScript. You
can mark any individual file by adding the check JavaScript pragma to the file:

```js
// @ts-check
```

This will cause the type checker to infer type information about the JavaScript
code and raise any issues as diagnostic issues.

These can be turned on for all JavaScript files in a program by providing a
configuration file with the check JS option enabled:

```json
{
  "compilerOptions": {
    "checkJs": true
  }
}
```

And setting the `--config` option on the command line.

## Using JSDoc in JavaScript

If you are type checking JavaScript, or even importing JavaScript into
TypeScript you can use JSDoc in JavaScript to express more types information
than can just be inferred from the code itself. Deno supports this without any
additional configuration, you simply need to annotate the code in line with the
supported
[TypeScript JSDoc](https://www.typescriptlang.org/docs/handbook/jsdoc-supported-types.html).
For example to set the type of an array:

```js
/** @type {string[]} */
const a = [];
```

## Skipping type checking

You might have TypeScript code that you are experimenting with, where the syntax
is valid but not fully type safe. You can always bypass type checking for a
whole program by passing the `--no-check`.

You can also skip whole files being type checked, including JavaScript if you
have check JS enabled, by using the no-check pragma:

```js
// @ts-nocheck
```

## Just renaming JS files to TS files

While this might work in some cases, it has some severe limits in Deno. This is
because Deno, by default, runs type checking in what is called _strict mode_.
This means a lot of unclear or ambiguous situations where are not caught in
non-strict mode will result in diagnostics being generated, and JavaScript is
nothing but unclear and ambiguous when it comes to types.



/. 🚀 runtime/manual/advanced/typescript/overview.md
===================================================

# Overview of TypeScript in Deno

One of the benefits of Deno is that it treats TypeScript as a first class
language, just like JavaScript or Web Assembly, when running code in Deno. What
that means is you can run or import TypeScript without installing anything more
than the Deno CLI.

_But wait a minute, does Deno really run TypeScript?_ you might be asking
yourself. Well, depends on what you mean by run. One could argue that in a
browser you don't actually _run_ JavaScript either. The JavaScript engine in the
browser translates the JavaScript to a series of operation codes, which it then
executes in a sandbox. So it translates JavaScript to something close to
assembly. Even Web Assembly goes through a similar translation, in that Web
Assembly is architecture agnostic while it needs to be translated into the
machine specific operation codes needed for the particular platform architecture
it is running on. So when we say TypeScript is a first class language in Deno,
we mean that we try to make the user experience in authoring and running
TypeScript as easy and straightforward as JavaScript and Web Assembly.

Behind the scenes, we use a combination of technologies, in Rust and JavaScript,
to provide that experience.

## How does it work?

At a high level, Deno converts TypeScript (as well as TSX and JSX) into
JavaScript. It does this via a combination of the
[TypeScript compiler](https://github.com/microsoft/TypeScript), which we build
into Deno, and a Rust library called [swc](https://swc.rs/). When the code has
been type checked and transformed, it is stored in a cache, ready for the next
run without the need to convert it from its source to JavaScript again.

You can see this cache location by running `deno info`:

```shell
> deno info
DENO_DIR location: "/path/to/cache/deno"
Remote modules cache: "/path/to/cache/deno/deps"
TypeScript compiler cache: "/path/to/cache/deno/gen"
```

If you were to look in that cache, you would see a directory structure that
mimics that source directory structure and individual `.js` and `.meta` files
(also potentially `.map` files). The `.js` file is the transformed source file
while the `.meta` file contains meta data we want to cache about the file, which
at the moment contains a _hash_ of the source module that helps us manage cache
invalidation. You might also see a `.buildinfo` file as well, which is a
TypeScript compiler incremental build information file, which we cache to help
speed up type checking.

## Type Checking

One of the main advantages of TypeScript is that you can make code more type
safe, so that what would be syntactically valid JavaScript becomes TypeScript
with warnings about being "unsafe".

You can type-check your code (without executing it) using the following command:

```shell
deno check module.ts
# or also type check remote modules and npm packages
deno check --all module.ts
```

Type checking can take a significant amount of time, especially if you are
working on a code base where you are making a lot of changes. We have tried to
optimize type checking, but it still comes at a cost. **Therefore, by default,
TypeScript modules are not type-checked before they are executed.**

```shell
deno run module.ts
```

When using the command above, Deno will simply transpile the module before
executing it, ignoring any potential type-related issues. In order to perform a
type-check of the module before execution occurs, the `--check` argument must be
used with `deno run`:

```shell
deno run --check module.ts
# or also type check remote modules and npm packages
deno run --check=all module.ts
```

While `tsc` will (by default) still emit JavaScript when encountering diagnostic
(type-checking) issues, Deno currently treats them as terminal. When using
`deno run` _with_ the `--check` argument, type-related diagnostics will prevent
the program from running: it will halt on these warnings, and exit the process
before executing the code.

In order to avoid this, you will either need to resolve the issue, utilise the
`// @ts-ignore` or `// @ts-expect-error` pragmas, or skip type checking all
together.

You can learn more about type-checking arguments
[here](../../getting_started/command_line_interface.md#type-checking-flags).

## Determining the type of file

Since Deno supports JavaScript, TypeScript, JSX, TSX modules, Deno has to make a
decision about how to treat each of these kinds of files. For local modules,
Deno makes this determination based fully on the extension. When the extension
is absent in a local file, it is assumed to be JavaScript.

For remote modules, the media type (mime-type) is used to determine the type of
the module, where the path of the module is used to help influence the file
type, when it is ambiguous what type of file it is.

For example, a `.d.ts` file and a `.ts` file have different semantics in
TypeScript as well as have different ways they need to be handled in Deno. While
we expect to convert a `.ts` file into JavaScript, a `.d.ts` file contains no
"runnable" code, and is simply describing types (often of "plain" JavaScript).
So when we fetch a remote module, the media type for a `.ts.` and `.d.ts` file
looks the same. So we look at the path, and if we see something that has a path
that ends with `.d.ts` we treat it as a type definition only file instead of
"runnable" TypeScript.

### Supported media types

The following table provides a list of media types which Deno supports when
identifying the type of file of a remote module:

| Media Type                 | How File is Handled                                         |
| -------------------------- | ----------------------------------------------------------- |
| `application/typescript`   | TypeScript (with path extension influence)                  |
| `text/typescript`          | TypeScript (with path extension influence)                  |
| `video/vnd.dlna.mpeg-tts`  | TypeScript (with path extension influence)                  |
| `video/mp2t`               | TypeScript (with path extension influence)                  |
| `application/x-typescript` | TypeScript (with path extension influence)                  |
| `application/javascript`   | JavaScript (with path extensions influence)                 |
| `text/javascript`          | JavaScript (with path extensions influence)                 |
| `application/ecmascript`   | JavaScript (with path extensions influence)                 |
| `text/ecmascript`          | JavaScript (with path extensions influence)                 |
| `application/x-javascript` | JavaScript (with path extensions influence)                 |
| `application/node`         | JavaScript (with path extensions influence)                 |
| `text/jsx`                 | JSX                                                         |
| `text/tsx`                 | TSX                                                         |
| `text/plain`               | Attempt to determine that path extension, otherwise unknown |
| `application/octet-stream` | Attempt to determine that path extension, otherwise unknown |

## Strict by default

Deno type checks TypeScript in _strict_ mode by default, and the TypeScript core
team recommends _strict_ mode as a sensible default. This mode generally enables
features of TypeScript that probably should have been there from the start, but
as TypeScript continued to evolve, would be breaking changes for existing code.

## Mixing JavaScript and TypeScript

By default, Deno does not type check JavaScript. This can be changed, and is
discussed further in [Configuring TypeScript in Deno](./configuration.md). Deno
does support JavaScript importing TypeScript and TypeScript importing
JavaScript, in complex scenarios.

An important note though is that when type checking TypeScript, by default Deno
will "read" all the JavaScript in order to be able to evaluate how it might have
an impact on the TypeScript types. The type checker will do the best it can to
figure out what the types are of the JavaScript you import into TypeScript,
including reading any JSDoc comments. Details of this are discussed in detail in
the [Types and type declarations](./types.md) section.

## Type resolution

One of the core design principles of Deno is to avoid non-standard module
resolution, and this applies to type resolution as well. If you want to utilise
JavaScript that has type definitions (e.g. a `.d.ts` file), you have to
explicitly tell Deno about this. The details of how this is accomplished are
covered in the [Types and type declarations](./types.md) section.



/. 🚀 runtime/manual/advanced/typescript/types.md
===================================================

# Types and Type Declarations

One of the design principles of Deno is no non-standard module resolution. When
TypeScript is type checking a file, it only cares about the types for the file,
and the `tsc` compiler has a lot of logic to try to resolve those types. By
default, it expects _ambiguous_ module specifiers with an extension, and will
attempt to look for the file under the `.ts` specifier, then `.d.ts`, and
finally `.js` (plus a whole other set of logic when the module resolution is set
to `"node"`). Deno deals with explicit specifiers.

This can cause a couple problems though. For example, let's say I want to
consume a TypeScript file that has already been transpiled to JavaScript along
with a type definition file. So I have `mod.js` and `mod.d.ts`. If I try to
import `mod.js` into Deno, it will only do what I ask it to do, and import
`mod.js`, but that means my code won't be as well type checked as if TypeScript
was considering the `mod.d.ts` file in place of the `mod.js` file.

In order to support this in Deno, Deno has two solutions, of which there is a
variation of a solution to enhance support. The two main situations you come
across would be:

- As the importer of a JavaScript module, I know what types should be applied to
  the module.
- As the supplier of the JavaScript module, I know what types should be applied
  to the module.

The latter case is the better case, meaning you as the provider or host of the
module, everyone can consume it without having to figure out how to resolve the
types for the JavaScript module, but when consuming modules that you may not
have direct control over, the ability to do the former is also required.

## Providing types when importing

If you are consuming a JavaScript module and you have either created types (a
`.d.ts` file) or have otherwise obtained the types, you want to use, you can
instruct Deno to use that file when type checking instead of the JavaScript file
using the `@deno-types` compiler hint. `@deno-types` needs to be a single line
double slash comment, where when used impacts the next import or re-export
statement.

For example if I have a JavaScript modules `coolLib.js` and I had a separate
`coolLib.d.ts` file that I wanted to use, I would import it like this:

```ts, ignore
// @deno-types="./coolLib.d.ts"
import * as coolLib from "./coolLib.js";
```

When type checking `coolLib` and your usage of it in the file, the
`coolLib.d.ts` types will be used instead of looking at the JavaScript file.

The pattern matching for the compiler hint is somewhat forgiving and will accept
quoted and non-question values for the specifier as well as it accepts
whitespace before and after the equals sign.

## Providing types when hosting

If you are in control of the source code of the module, or you are in control of
how the file is hosted on a web server, there are two ways to inform Deno of the
types for a given module, without requiring the importer to do anything special.

### Using the triple-slash reference directive

Deno supports using the triple-slash reference `types` directive, which adopts
the reference comment used by TypeScript in TypeScript files to _include_ other
files and applies it only to JavaScript files.

For example, if I had created `coolLib.js` and along side of it I had created my
type definitions for my library in `coolLib.d.ts` I could do the following in
the `coolLib.js` file:

```js, ignore
/// <reference types="./coolLib.d.ts" />

// ... the rest of the JavaScript ...
```

When Deno encounters this directive, it would resolve the `./coolLib.d.ts` file
and use that instead of the JavaScript file when TypeScript was type checking
the file, but still load the JavaScript file when running the program.

> ℹ️ _Note_ this is a repurposed directive for TypeScript that only applies to
> JavaScript files. Using the triple-slash reference directive of `types` in a
> TypeScript file works under Deno as well, but has essentially the same
> behavior as the `path` directive.

### Using X-TypeScript-Types header

Similar to the triple-slash directive, Deno supports a header for remote modules
that instructs Deno where to locate the types for a given module. For example, a
response for `https://example.com/coolLib.js` might look something like this:

```
HTTP/1.1 200 OK
Content-Type: application/javascript; charset=UTF-8
Content-Length: 648
X-TypeScript-Types: ./coolLib.d.ts
```

When seeing this header, Deno would attempt to retrieve
`https://example.com/coolLib.d.ts` and use that when type checking the original
module.

## Using ambient or global types

Overall it is better to use module/UMD type definitions with Deno, where a
module expressly imports the types it depends upon. Modular type definitions can
express
[augmentation of the global scope](https://www.typescriptlang.org/docs/handbook/declaration-files/templates/global-modifying-module-d-ts.html)
via the `declare global` in the type definition. For example:

```ts
declare global {
  var AGlobalString: string;
}
```

This would make `AGlobalString` available in the global namespace when importing
the type definition.

In some cases though, when leveraging other existing type libraries, it may not
be possible to leverage modular type definitions. Therefore there are ways to
include arbitrary type definitions when type checking programmes.

### Using a triple-slash directive

This option couples the type definitions to the code itself. By adding a
triple-slash `types` directive near the type of a module, type checking the file
will include the type definition. For example:

```ts, ignore
/// <reference types="./types.d.ts" />
```

The specifier provided is resolved just like any other specifier in Deno, which
means it requires an extension, and is relative to the module referencing it. It
can be a fully qualified URL as well:

```ts, ignore
/// <reference types="https://deno.land/x/pkg@1.0.0/types.d.ts" />
```

### Using a configuration file

Another option is to use a configuration file that is configured to include the
type definitions, by supplying a `"types"` value to the `"compilerOptions"`. For
example:

```json
{
  "compilerOptions": {
    "types": [
      "./types.d.ts",
      "https://deno.land/x/pkg@1.0.0/types.d.ts",
      "/Users/me/pkg/types.d.ts"
    ]
  }
}
```

Like the triple-slash reference above, the specifier supplied in the `"types"`
array will be resolved like other specifiers in Deno. In the case of relative
specifiers, it will be resolved relative to the path to the config file. Make
sure to tell Deno to use this file by specifying `--config=path/to/file` flag.

## Type Checking Web Workers

When Deno loads a TypeScript module in a web worker, it will automatically type
check the module and its dependencies against the Deno web worker library. This
can present a challenge in other contexts like `deno cache` or in editors. There
are a couple of ways to instruct Deno to use the worker libraries instead of the
standard Deno libraries.

### Using triple-slash directives

This option couples the library settings with the code itself. By adding the
following triple-slash directives near the top of the entry point file for the
worker script, Deno will now type check it as a Deno worker script, irrespective
of how the module is analyzed:

```ts, ignore
/// <reference no-default-lib="true" />
/// <reference lib="deno.worker" />
```

The first directive ensures that no other default libraries are used. If this is
omitted, you will get some conflicting type definitions, because Deno will try
to apply the standard Deno library as well. The second instructs Deno to apply
the built-in Deno worker type definitions plus dependent libraries (like
`"esnext"`).

When you run a `deno cache` or `deno bundle` command or use an IDE which uses
the Deno language server, Deno should automatically detect these directives and
apply the correct libraries when type checking.

The one disadvantage of this, is that it makes the code less portable to other
non-Deno platforms like `tsc`, as it is only Deno which has the `"deno.worker"`
library built into it.

### Using a configuration file

Another option is to use a configuration file that is configured to apply the
library files. A minimal file that would work would look something like this:

```json
{
  "compilerOptions": {
    "target": "esnext",
    "lib": ["deno.worker"]
  }
}
```

Then when running a command on the command line, you would need to pass the
`--config path/to/file` argument, or if you are using an IDE which leverages the
Deno language server, set the `deno.config` setting.

If you also have non-worker scripts, you will either need to omit the `--config`
argument, or have one that is configured to meet the needs of your non-worker
scripts.

## Important points

### Type declaration semantics

Type declaration files (`.d.ts` files) follow the same semantics as other files
in Deno. This means that declaration files are assumed to be module declarations
(_UMD declarations_) and not ambient/global declarations. It is unpredictable
how Deno will handle ambient/global declarations.

In addition, if a type declaration imports something else, like another `.d.ts`
file, its resolution follow the normal import rules of Deno. For a lot of the
`.d.ts` files that are generated and available on the web, they may not be
compatible with Deno.

To overcome this problem, some solution providers, like the
[Skypack CDN](https://www.skypack.dev/), will automatically bundle type
declarations just like they provide bundles of JavaScript as ESM.

### Deno Friendly CDNs

There are CDNs which host JavaScript modules that integrate well with Deno.

- [esm.sh](https://esm.sh) is a CDN which provides type declarations by default
  (via the `X-TypeScript-Types` header). It can be disabled by appending
  `?no-dts` to the import URL:

  ```ts
  import React from "https://esm.sh/react?no-dts";
  ```
- [Skypack.dev](https://docs.skypack.dev/skypack-cdn/code/deno) is another CDN
  which also provides type declarations (via the `X-TypeScript-Types` header)
  when you append `?dts` as a query string to your remote module import
  statements. Here's an example:

  ```ts
  import React from "https://cdn.skypack.dev/react?dts";
  ```

## Behavior of JavaScript when type checking

If you import JavaScript into TypeScript in Deno and there are no types, even if
you have `checkJs` set to `false` (the default for Deno), the TypeScript
compiler will still access the JavaScript module and attempt to do some static
analysis on it, to at least try to determine the shape of the exports of that
module to validate the import in the TypeScript file.

This is usually never a problem when trying to import a "regular" ES module, but
in some cases if the module has special packaging, or is a global _UMD_ module,
TypeScript's analysis of the module can fail and cause misleading errors. The
best thing to do in this situation is provide some form of types using one of
the methods mention above.

### Internals

While it isn't required to understand how Deno works internally to be able to
leverage TypeScript with Deno well, it can help to understand how it works.

Before any code is executed or compiled, Deno generates a module graph by
parsing the root module, and then detecting all of its dependencies, and then
retrieving and parsing those modules, recursively, until all the dependencies
are retrieved.

For each dependency, there are two potential "slots" that are used. There is the
code slot and the type slot. As the module graph is filled out, if the module is
something that is or can be emitted to JavaScript, it fills the code slot, and
type only dependencies, like `.d.ts` files fill the type slot.

When the module graph is built, and there is a need to type check the graph,
Deno starts up the TypeScript compiler and feeds it the names of the modules
that need to be potentially emitted as JavaScript. During that process, the
TypeScript compiler will request additional modules, and Deno will look at the
slots for the dependency, offering it the type slot if it is filled before
offering it the code slot.

This means when you import a `.d.ts` module, or you use one of the solutions
above to provide alternative type modules for JavaScript code, that is what is
provided to TypeScript instead when resolving the module.



/. 🚀 runtime/manual/advanced/jsx_dom/index.md
===================================================

# Using JSX and the DOM

This chapter covers more configuration details about using JSX and the DOM in
Deno, including:

- [Overview of JSX and the DOM in Deno](./overview.md)
- [Configuring JSX in Deno](./jsx.md)
- [Using LinkeDOM with Deno](./linkedom.md)
- [Using deno-dom with Deno](./deno_dom.md)
- [Using JSDOM with Deno](./jsdom.md)
- [Parsing and Stringifying CSS](./css.md)
- [Using Twind with Deno](./twind.md)



/. 🚀 runtime/manual/advanced/jsx_dom/css.md
===================================================

# Parsing and Stringifying CSS

If you want to parse CSS to a abstract syntax tree (AST) then there are two
solutions you might want to consider:

- [reworkcss/css](https://github.com/reworkcss/css)
- [deno_css](https://deno.land/x/css)

`reworkcss/css` was written originally for Node.js but work well when consumed
from a CDN. Importing from `esm.sh` also automatically combines the type
definitions from DefinitelyTyped. It should be noted though that types on
DefinitelyTyped are not _very good_ as many union types that should be tagged
union types are just union types which leave the types very ambiguous and
require a lot of type casting.

Also, if you want to take an AST and generate CSS, `reworkcss/css` also provides
capability to stringify the AST it generates.

`deno_css` is authored in TypeScript specifically for Deno and is available on
`deno.land/x`.

## Basic example with `reworkcss/css`

In this example, we will parse some CSS into an AST and make a modification to
the `background` declaration of the `body` rule, to change the color to `white`.
Then we will stringify the modified CSS AST and output it to the console:

```ts, ignore
import * as css from "https://esm.sh/css@3.0.0";
import { assert } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

declare global {
  interface AbortSignal {
    reason: unknown;
  }
}

const ast = css.parse(`
body {
  background: #eee;
  color: #888;
}
`);

assert(ast.stylesheet);
const body = ast.stylesheet.rules[0] as css.Rule;
assert(body.declarations);
const background = body.declarations[0] as css.Declaration;
background.value = "white";

console.log(css.stringify(ast));
```

## A basic example with `deno_css`

In this example, we will parse some CSS into an AST and log out the `background`
declaration of the `body` rule to the console.

```ts
import * as css from "https://deno.land/x/css@0.3.0/mod.ts";

const ast = css.parse(`
body {
  background: #eee;
  color: #888;
}
`);

const [body] = ast.stylesheet.rules;
const [background] = body.declarations;

console.log(JSON.stringify(background, undefined, "  "));
```



/. 🚀 runtime/manual/advanced/jsx_dom/deno_dom.md
===================================================

# Using deno-dom with Deno

[deno-dom](https://deno.land/x/deno_dom) is an implementation of DOM and HTML
parser in Deno. It is implemented in Rust (via Wasm) and TypeScript. There is
also a "native" implementation, leveraging the FFI interface.

deno-dom aims for specification compliance, like jsdom and unlike LinkeDOM.
Currently, deno-dom is slower than LinkeDOM for things like parsing data
structures, but faster at some manipulation operations. Both deno-dom and
LinkeDOM are significantly faster than jsdom.

As of deno_dom v0.1.22-alpha supports running on Deno Deploy. So if you want
strict standards alignment, consider using deno-dom over LinkeDOM.

## Basic example

This example will take a test string and parse it as HTML and generate a DOM
structure based on it. It will then query that DOM structure, picking out the
first heading it encounters and print out the text content of that heading:

```ts
import { DOMParser } from "https://deno.land/x/deno_dom/deno-dom-wasm.ts";
import { assert } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

const document = new DOMParser().parseFromString(
  `<!DOCTYPE html>
  <html lang="en">
    <head>
      <title>Hello from Deno</title>
    </head>
    <body>
      <h1>Hello from Deno</h1>
      <form>
        <input name="user">
        <button>
          Submit
        </button>
      </form>
    </body>
  </html>`,
  "text/html",
);

assert(document);
const h1 = document.querySelector("h1");
assert(h1);

console.log(h1.textContent);
```

> Note: the example uses an unpinned version from `deno_land/x`, which you
> likely don't want to do, because the version can change and cause unexpected
> outcomes. You should use the latest version of available of
> [deno-dom](https://deno.land/x/deno_dom).

## Faster startup

Just importing the `deno-dom-wasm.ts` file bootstraps the Wasm code via top
level await. The problem is that top level await blocks the module loading
process. Especially with big Wasm projects, it is a lot more performant to
initialize the Wasm after module loading is complete.

_deno-dom_ has the solution for that, they provide an alternative version of the
library that does not automatically init the Wasm, and requires you to do it in
the code:

```ts
import {
  DOMParser,
  initParser,
} from "https://deno.land/x/deno_dom/deno-dom-wasm-noinit.ts";

(async () => {
  // initialize when you need it, but not at the top level
  await initParser();

  const doc = new DOMParser().parseFromString(
    `<h1>Lorem ipsum dolor...</h1>`,
    "text/html",
  );
})();
```

In addition, using the `deno-dom-native.ts` (which requires the `--allow-ffi`
flag) will bypass the Wasm startup penalty as well as will not require the
`init()` startup time. This would only work with the Deno CLI and not Deploy.



/. 🚀 runtime/manual/advanced/jsx_dom/jsdom.md
===================================================

# Using jsdom with Deno

[jsdom](https://github.com/jsdom/jsdom) is a pure JavaScript implementation of
many web standards, notably the WHATWG DOM and HTML Standards. It's main goal is
to be comprehensive and standards compliant and does not specifically consider
performance.

If you are interested in server side rendering, then both
[deno-dom](./deno_dom.md) and [LinkeDOM](./linkedom.md) are better choices. If
you are trying to run code in a "virtual" browser that needs to be standards
based, then it is possible that jsdom is suitable for you.

While jsdom works under the Deno CLI, it does not type check. This means you
have to use the `--no-check=remote` option on the command line to avoid
diagnostics stopping the execution of your programme.

Having sound typing in an editor requires some changes to the workflow as well,
as the way jsdom types are provided are declared as a global type definition
with a globally named module, as well as leveraging the built in types from the
built-in DOM libraries.

This means if you want strong typing and intelligent auto-completion in your
editor while using the Deno language server, you have to perform some extra
steps.

### Defining an `import_map.json`

You need to map the bare specifier `"jsdom"` to the imported version of jsdom.
This allows Deno to correctly apply the types to the import in the way they were
specified.

```json
{
  "jsdom": "https://esm.sh/jsdom"
}
```

### Setting up a configuration file

You will want to set up a `deno.jsonc` configuration file in the root of your
workspace with both TypeScript library information as well as specifying the
import map defined above:

```jsonc
{
  "compilerOptions": {
    "lib": [
      "deno.ns",
      "dom",
      "dom.iterable",
      "dom.asynciterable"
    ]
  },
  "importMap": "./import_map.json"
}
```

> Note: we are using an unpinned version of jsdom above. You should consider
> pinning the version to the version you know you want to use.

## Basic example

This example will take a test string and parse it as HTML and generate a DOM
structure based on it. It will then query that DOM structure, picking out the
first heading it encounters and print out the text content of that heading:

```ts, ignore
import { JSDOM } from "jsdom";
import { assert } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

const { window: { document } } = new JSDOM(
  `<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Hello from Deno</title>
  </head>
  <body>
    <h1>Hello from Deno</h1>
    <form>
      <input name="user">
      <button>
        Submit
      </button>
    </form>
  </body>
</html>`,
  {
    url: "https://example.com/",
    referrer: "https://example.org/",
    contentType: "text/html",
    storageQuota: 10000000,
  },
);

const h1 = document.querySelector("h1");
assert(h1);

console.log(h1.textContent);
```



/. 🚀 runtime/manual/advanced/jsx_dom/jsx.md
===================================================

# Configuring JSX in Deno

Deno has built-in support for JSX in both `.jsx` files and `.tsx` files. JSX in
Deno can be handy for server-side rendering or generating code for consumption
in a browser.

## Default configuration

The Deno CLI has a default configuration for JSX that is different than the
defaults for `tsc`. Effectively Deno uses the following
[TypeScript compiler](https://www.typescriptlang.org/docs/handbook/compiler-options.html)
options by default:

```json
{
  "compilerOptions": {
    "jsx": "react",
    "jsxFactory": "React.createElement",
    "jsxFragmentFactory": "React.Fragment"
  }
}
```

## JSX import source

In React 17, the React team added what they called
[the _new_ JSX transforms](https://reactjs.org/blog/2020/09/22/introducing-the-new-jsx-transform.html).
This enhanced and modernized the API for JSX transforms as well as provided a
mechanism to automatically import a JSX library into a module, instead of having
to explicitly import it or make it part of the global scope. Generally this
makes it easier to use JSX in your application.

As of Deno 1.16, initial support for these transforms was added. Deno supports
both the JSX import source pragma as well as configuring a JSX import source in
a [configuration file](../../getting_started/configuration_file.md).

### JSX runtime

When using the automatic transforms, Deno will try to import a JSX runtime
module that is expected to conform to the _new_ JSX API and is located at either
`jsx-runtime` or `jsx-dev-runtime`. For example if a JSX import source is
configured to `react`, then the emitted code will add this to the emitted file:

```jsx, ignore
import { jsx as _jsx } from "react/jsx-runtime";
```

Deno generally works off explicit specifiers, which means it will not try any
other specifier at runtime than the one that is emitted. Which means to
successfully load the JSX runtime, `"react/jsx-runtime"` would need to resolve
to a module. Saying that, Deno supports remote modules, and most CDNs resolve
the specifier easily.

For example, if you wanted to use [Preact](https://preactjs.com/) from the
[esm.sh](https://esm.sh/) CDN, you would use `https://esm.sh/preact` as the JSX
import source, and esm.sh will resolve `https://esm.sh/preact/jsx-runtime` as a
module, including providing a header in the response that tells Deno where to
find the type definitions for Preact.

### Using the JSX import source pragma

Whether you have a JSX import source configured for your project, or if you are
using the default "legacy" configuration, you can add the JSX import source
pragma to a `.jsx` or `.tsx` module, and Deno will respect it.

The `@jsxImportSource` pragma needs to be in the leading comments of the module.
For example to use Preact from esm.sh, you would do something like this:

```jsx, ignore
/** @jsxImportSource https://esm.sh/preact */

export function App() {
  return (
    <div>
      <h1>Hello, world!</h1>
    </div>
  );
}
```

### Using JSX import source in a configuration file

If you want to configure a JSX import source for a whole project, so you don't
need to insert the pragma on each module, you can use the `"compilerOptions"` in
a [configuration file](../../getting_started/configuration_file.md) to specify
this. For example if you were using Preact as your JSX library from esm.sh, you
would configure the following, in the configuration file:

```jsonc
{
  "compilerOptions": {
    "jsx": "react-jsx",
    "jsxImportSource": "https://esm.sh/preact"
  }
}
```

### Using an import map

In situations where the import source plus `/jsx-runtime` or `/jsx-dev-runtime`
is not resolvable to the correct module, an import map can be used to instruct
Deno where to find the module. An import map can also be used to make the import
source "cleaner". For example, if you wanted to use Preact from skypack.dev and
have skypack.dev include all the type information, you could setup an import map
like this:

```json
{
  "imports": {
    "preact/jsx-runtime": "https://cdn.skypack.dev/preact/jsx-runtime?dts",
    "preact/jsx-dev-runtime": "https://cdn.skypack.dev/preact/jsx-dev-runtime?dts"
  }
}
```

And then you could use the following pragma:

```jsx, ignore
/** @jsxImportSource preact */
```

Or you could configure it in the compiler options:

```json
{
  "compilerOptions": {
    "jsx": "react-jsx",
    "jsxImportSource": "preact"
  }
}
```

You would then need to pass the `--import-map` option on the command line (along
with the `--config` option is using a config file) or set the `deno.importMap`
option (and `deno.config` option) in your IDE.

### Current limitations

There are two current limitations of the support of the JSX import source:

- A JSX module that does not have any imports or exports is not transpiled
  properly when type checking (see:
  [microsoft/TypeScript#46723](https://github.com/microsoft/TypeScript/issues/46723)).
  Errors will be seen at runtime about `_jsx` not being defined. To work around
  the issue, add `export {}` to the file or use the `--no-check` flag which will
  cause the module to be emitted properly.
- Using `"jsx-reactdev"` compiler option is not supported with
  `--no-emit`/bundling/compiling (see:
  [swc-project/swc#2656](https://github.com/swc-project/swc/issues/2656)).
  Various runtime errors will occur about not being able to load `jsx-runtime`
  modules. To work around the issue, use the `"jsx-react"` compiler option
  instead, or don't use `--no-emit`, bundling or compiling.



/. 🚀 runtime/manual/advanced/jsx_dom/linkedom.md
===================================================

# Using LinkeDOM with Deno

[LinkeDOM](https://github.com/WebReflection/linkedom) is a DOM-like namespace to
be used in environments, like Deno, which don't implement the DOM.

LinkeDOM focuses on being fast and implementing features useful for server side
rendering. It may allow you to do things that are invalid DOM operations.
[deno-dom](./deno_dom.md) and [jsdom](./jsdom.md) focus on correctness. While
currently deno-dom is slower than LinkeDOM in some cases, both are significantly
faster than jsdom, so if you require correctness or features not related to
server side rendering, consider deno-dom.

While LinkeDOM works under the Deno CLI, it does not type check. While the
provided types work well when using an editor like VSCode, attempting to
strictly type check them, like Deno does by default, at runtime, it will fail.
This is the same if you were to use `tsc` to type check the code. The maintainer
has indicated they aren't interested in
[fixing this issue](https://github.com/WebReflection/linkedom/issues/87). This
means for Deno, you need to use the `--no-check=remote` to avoid diagnostics
stopping the execution of your programme.

LinkedDOM runs under Deno Deploy, along with deno_dom, but jsdom does not.

## Basic example

This example will take a test string and parse it as HTML and generate a DOM
structure based on it. It will then query that DOM structure, picking out the
first heading it encounters and print out the text content of that heading:

```ts
import { DOMParser } from "https://esm.sh/linkedom";
import { assert } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

const document = new DOMParser().parseFromString(
  `<!DOCTYPE html>
  <html lang="en">
    <head>
      <title>Hello from Deno</title>
    </head>
    <body>
      <h1>Hello from Deno</h1>
      <form>
        <input name="user">
        <button>
          Submit
        </button>
      </form>
    </body>
  </html>`,
  "text/html",
);

assert(document);
const h1 = document.querySelector("h1");
assert(h1);

console.log(h1.textContent);
```

## Alternative API

For the `parseHTML()` can be better suited for certain SSR workloads. This is
similar to jsdom's `JSDOM()` function, in the sense it gives you a "sandbox" of
a `window` scope you can use to access API's outside of the scope of the
`document`. For example:

```ts, ignore
import { parseHTML } from "https://esm.sh/linkedom";

const { document, customElements, HTMLElement } = parseHTML(`<!DOCTYPE html>
  <html lang="en">
    <head>
      <title>Hello from Deno</title>
    </head>
    <body>
      <h1>Hello from Deno</h1>
      <form>
        <input name="user">
        <button>
          Submit
        </button>
      </form>
    </body>
  </html>`);

customElements.define(
  "custom-element",
  class extends HTMLElement {
    connectedCallback() {
      console.log("it works 🥳");
    }
  },
);

document.body.appendChild(document.createElement("custom-element"));

document.toString(); // the string of the document, ready to send to a client
```



/. 🚀 runtime/manual/advanced/jsx_dom/overview.md
===================================================

# Overview of JSX and DOM in Deno

One of the common use cases for Deno is to handle workloads as part of web
applications. Because Deno includes many of the browser APIs built-in, there is
a lot of power in being able to create isomorphic code that can run both in Deno
and in the browser. A powerful workload that can be handled by Deno is
performing _server side rendering_ (SSR), where application state is used
_server side_ to dynamically render HTML and CSS to be provided to a client.

Server side rendering, when used effectively, can dramatically increase the
performance of a web application by offloading heavy calculations of dynamic
content to a server process allowing an application developer to minimize the
JavaScript and application state that needs to be shipped to the browser.

A web application is generally made up of three key technologies:

- JavaScript
- HTML
- CSS

As well as increasingly, [Web Assembly](../../runtime/webassembly/index.md)
might play a part in a web application.

These technologies combine to allow a developer to build an application in a
browser using the web platform. While Deno supports a lot of web platform APIs,
it generally only supports web APIs that are usable in a _server-side_ context,
but in a client/browser context, the main "display" API is the Document Object
Model (or DOM). There are APIs that are accessible to application logic via
JavaScript that manipulate the DOM to provide a desired outcome, as well as HTML
and CSS are used to structure and style the _display_ of a web application.

In order to facilitate manipulation of the DOM server side and the ability to
generate HTML and CSS dynamically, there are some key technologies and libraries
that can be used with Deno to achieve this, which we will explore in this
chapter.

We will be exploring fairly low-level enabling libraries and technologies,
versus a full solution or framework for server side generation of websites.

## JSX

Created by the React team at Facebook, JSX is a popular DSL (domain specific
language) for embedding HTML-like syntax in JavaScript. The TypeScript team also
added support for the JSX syntax into TypeScript. JSX has become popular with
developers as it allows mixing imperative programming logic with a declarative
syntax that looks a lot like HTML.

An example of what a JSX "component" might look like:

```jsx
export function Greeting({ name }) {
  return (
    <div>
      <h1>Hello {name}!</h1>
    </div>
  );
}
```

The main challenge with JSX is that it isn't JavaScript nor is it HTML. It
requires transpiling to pure JavaScript before it can be used in a browser,
which then has to process that logic to manipulate the DOM in the browser. This
is probably less efficient than having a browser render static HTML.

This is where Deno can play a role. Deno supports JSX in both `.jsx` and `.tsx`
modules and combined with a JSX runtime, Deno can be used to dynamically
generate HTML to be sent to a browser client, without the need of shipping the
un-transpiled source file, or the JSX runtime library to the browser.

Read the [Configuring JSX in Deno](./jsx.md) section for information on how to
customize the configuration of JSX in Deno.

## Document Object Model (DOM)

The DOM is the main way a user interface is provided in a browser, and it
exposes a set of APIs that allow it to be manipulated via JavaScript, but also
allows the direct use of HTML and CSS.

While Deno has a lot of web platform APIs, it does not support most of the DOM
APIs related to visual representation. Having said that though, there are a few
libraries that provide a lot of the APIs needed to take code that was designed
to run in a web browser to be able to run under Deno, in order to generate HTML
and CSS which can be shipped to a browser "pre-rendered". We will cover those in
the following sections:

- [Using LinkeDOM with Deno](./linkedom.md)
- [Using deno-dom with Deno](./deno_dom.md)
- [Using jsdom with Deno](./jsdom.md)

## CSS

Cascading Style Sheets (CSS) provide styling for HTML within the DOM. There are
tools which make working with CSS in a server side context easier and powerful.

- [Parsing and stringifying CSS](./css.md)
- [Using Twind with Deno](./twind.md)



/. 🚀 runtime/manual/advanced/jsx_dom/twind.md
===================================================

# Using Twind with Deno

[Twind](https://twind.style/) is a _tailwind-in-js_ solution for using
[Tailwind](https://tailwindcss.com/). Twind is particularly useful in Deno's
server context, where Tailwind and CSS can be easily server side rendered,
generating dynamic, performant and efficient CSS while having the usability of
styling with Tailwind.

## Basic example

In the following example, we will use twind to server side render an HTML page
and log it to the console. It demonstrates using grouped tailwind classes and
have it rendered using only the styles specified in the document and no client
side JavaScript to accomplish the _tailwind-in-js_:

```ts
import { extract, install } from "https://esm.sh/@twind/core@1.1.3";
import presetTailwind from "https://esm.sh/@twind/preset-tailwind@1.1.4";

install({
  presets: [
    presetTailwind(),
    {
      theme: {
        fontFamily: {
          sans: ["Helvetica", "sans-serif"],
          serif: ["Times", "serif"],
        },
      },
    },
  ],
});

function renderBody() {
  return `<!DOCTYPE html>
    <html lang="en">
      <head>
        <title>Hello from Deno</title>
      </head>
      <body class="font-sans">
        <h1 class="text(3xl blue-500)">Hello from Deno</h1>
        <form>
          <input name="user">
          <button class="text(2xl red-500)">
            Submit
          </button>
        </form>
      </body>
    </html>
  `;
}

function ssr() {
  const body = renderBody();
  const { html, css } = extract(body);
  return html.replace("</head>", `<style data-twind>${css}</style></head>`);
}

console.log(ssr());
```

https://twind.style/packages/@twind/core#extract



/. 🚀 runtime/manual/advanced/deploying_deno/index.md
===================================================

# Run Deno in the Cloud

Often times, we don't want to maintain hardware for our Deno scripts or apps to
run. This section describes various ways to deploy Deno into the cloud.

Though the easiest and fastest way to deploy Deno is with
[Deno Deploy](https://deno.com/deploy), you can deploy Deno into any virtual
private server.

This section contains How To guides on how to deploy Deno to different
platforms.

- [Digital Ocean](./digital_ocean.md)
- [AWS Lightsail](./aws_lightsail.md)
- [Google Cloud Run](./google_cloud_run.md)
- [Cloudflare Workers](./cloudflare_workers.md)
- [Kinsta](./kinsta.md)



/. 🚀 runtime/manual/advanced/deploying_deno/aws_lightsail.md
===================================================

    curl -s https://docs.deno.com/runtime/manual/advanced/deploying_deno/cloudflare_workers | sed -n 's/</\n/p' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|p'

# Deploy Deno to Amazon Lightsail

[Amazon Lightsail](https://aws.amazon.com/lightsail/) is the easiest and
cheapest way to get started with Amazon Web Services. It allows you to host
virtual machines and even entire container services.

This How To guide will show you how to deploy a Deno app to Amazon Lightsail
using Docker, Docker Hub, and GitHub Actions.

Before continuing, make sure you have:

- [`docker` CLI](https://docs.docker.com/engine/reference/commandline/cli/)
- a [Docker Hub account](https://hub.docker.com)
- a [GitHub account](https://github.com)
- an [AWS account](https://aws.amazon.com/)

## Create Dockerfile and docker-compose.yml

To focus on the deployment, our app will simply be a `main.ts` file that returns
a string as an HTTP response:

```ts, ignore
import { Application } from "https://deno.land/x/oak/mod.ts";

const app = new Application();

app.use((ctx) => {
  ctx.response.body = "Hello from Deno and AWS Lightsail!";
});

await app.listen({ port: 8000 });
```

Then, we'll create two files -- `Dockerfile` and `docker-compose.yml` -- to
build the Docker image.

In our `Dockerfile`, let's add:

```Dockerfile, ignore
FROM denoland/deno

EXPOSE 8000

WORKDIR /app

ADD . /app

RUN deno cache main.ts

CMD ["run", "--allow-net", "main.ts"]
```

Then, in our `docker-compose.yml`:

```yml, ignore
version: '3'

services:
  web:
    build: .
    container_name: deno-container
    image: deno-image
    ports:
      - "8000:8000"
```

Let's test this locally by running `docker compose -f docker-compose.yml build`,
then `docker compose up`, and going to `localhost:8000`.

<!-- ![hello world from localhost](../../images/how-to/aws-lightsail/hello-world-from-localhost.png) -->
![hello world from localhost](https://docs.deno.com/assets/images/hello-world-from-localhost-c44ccccdb3bf78c4faf816bf4c5e72b0.png)

It works!

## Build, Tag, and Push to Docker Hub

First, let's sign into [Docker Hub](https://hub.docker.com/repositories) and
create a repository. Let's name it `deno-on-aws-lightsail`.

Then, let's tag and push our new image, replacing `username` with yours:

Then, let's build the image locally. Note our `docker-compose.yml` file will
name the build `deno-image`.

```shell, ignore
docker compose -f docker-compose.yml build
```

Let's [tag](https://docs.docker.com/engine/reference/commandline/tag/) the local
image with `{{ username }}/deno-on-aws-lightsail`:

```shell, ignore
docker tag deno-image {{ username }}/deno-on-aws-lightsail
```

We can now push the image to Docker Hub:

```shell, ignore
docker push {{ username }}/deno-on-aws-lightsail
```

After that succeeds, you should be able to see the new image on your Docker Hub
repository:

<!-- ![new image on docker hub](../../images/how-to/aws-lightsail/new-image-on-docker-hub.png) -->
![new image on docker hub](https://docs.deno.com/assets/images/new-image-on-docker-hub-540bd4e42490b163c0bee995a6d4ff11.png)

## Create and Deploy to a Lightsail Container

Let's head over to
[the Amazon Lightsail console](https://lightsail.aws.amazon.com/ls/webapp/home/container-services).

Then click "Containers" and "Create container service". Half way down the page,
click "Setup your first Deployment" and select "Specify a custom deployment".

You can write whatever container name you'd like.

In `Image`, be sure to use `{{ username }}/{{ image }}` that you have set in
your Docker Hub. For this example, it is `lambtron/deno-on-aws-lightsail`.

Let's click `Add open ports` and add `8000`.

Finally, under `PUBLIC ENDPOINT`, select the container name that you just
created.

The full form should look like below:

<!-- ![create container service interface](../../images/how-to/aws-lightsail/create-container-service-on-aws.png) -->
![create container service interface](https://docs.deno.com/assets/images/create-container-service-on-aws-2ae5eca02be134dde00aa5eec9b97c3c.png)

When you're ready, click "Create container service".

After a few moments, your new container should be deployed. Click on the public
address and you should see your Deno app:

<!-- ![Hello world from Deno and AWS Lightsail](../../images/how-to/aws-lightsail/hello-world-from-deno-and-aws-lightsail.png) -->
![Hello world from Deno and AWS Lightsail](https://docs.deno.com/assets/images/hello-world-from-deno-and-aws-lightsail-9268528211f36171cf5c3ae37622db85.png)

## Automate using GitHub Actions

In order to automate that process, we'll use the `aws` CLI with the
[`lightsail` subcommand](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lightsail/push-container-image.html).

The steps in our GitHub Actions workflow will be:

1. Checkout the repo
2. Build our app as a Docker image locally
3. Install and authenticate AWS CLI
4. Push local Docker image to AWS Lightsail Container Service via CLI

Pre-requisites for this GitHub Action workflow to work:

- an AWS Lightsail Container Instance is created (see section above)
- IAM user and relevant permissions set.
  ([See here to learn more about managing access to Amazon Lightsail for an IAM user.](https://github.com/awsdocs/amazon-lightsail-developer-manual/blob/master/doc_source/amazon-lightsail-managing-access-for-an-iam-user.md))
- `AWS_ACCESS_KEY_ID` and `AWS_SUCCESS_ACCESS_KEY` for your permissioned user.
  (Follow
  [this AWS guide](https://lightsail.aws.amazon.com/ls/docs/en_us/articles/lightsail-how-to-set-up-access-keys-to-use-sdk-api-cli)
  to get generate an `AWS_ACCESS_KEY_ID` and `AWS_SUCCESS_ACCESS_KEY`.)

Let's create a new file `container.template.json`, which contains configuration
for how to make the service container deployment. Note the similarities these
option values have with the inputs we entered manually in the previous section.

```json, ignore
{
  "containers": {
    "app": {
      "image": "",
      "environment": {
        "APP_ENV": "release"
      },
      "ports": {
        "8000": "HTTP"
      }
    }
  },
  "publicEndpoint": {
    "containerName": "app",
    "containerPort": 8000,
    "healthCheck": {
      "healthyThreshold": 2,
      "unhealthyThreshold": 2,
      "timeoutSeconds": 5,
      "intervalSeconds": 10,
      "path": "/",
      "successCodes": "200-499"
    }
  }
}
```

Let's add the below to your `.github/workflows/deploy.yml` file:

```yml, ignore
name: Build and Deploy to AWS Lightsail

on:
  push:
    branches:
      - main

env:
  AWS_REGION: us-west-2
  AWS_LIGHTSAIL_SERVICE_NAME: container-service-2
jobs:
  build_and_deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest
    steps:
      - name: Checkout main
        uses: actions/checkout@v2

      - name: Install Utilities
        run: |
          sudo apt-get update
          sudo apt-get install -y jq unzip
      - name: Install AWS Client
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install || true
          aws --version
          curl "https://s3.us-west-2.amazonaws.com/lightsailctl/latest/linux-amd64/lightsailctl" -o "lightsailctl"
          sudo mv "lightsailctl" "/usr/local/bin/lightsailctl"
          sudo chmod +x /usr/local/bin/lightsailctl
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-region: ${{ env.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      - name: Build Docker Image
        run: docker build -t ${{ env.AWS_LIGHTSAIL_SERVICE_NAME }}:release .
      - name: Push and Deploy
        run: |
          service_name=${{ env.AWS_LIGHTSAIL_SERVICE_NAME }}
          aws lightsail push-container-image \
            --region ${{ env.AWS_REGION }} \
            --service-name ${service_name} \
            --label ${service_name} \
            --image ${service_name}:release
          aws lightsail get-container-images --service-name ${service_name} | jq --raw-output ".containerImages[0].image" > image.txt
          jq --arg image $(cat image.txt) '.containers.app.image = $image' container.template.json > container.json
          aws lightsail create-container-service-deployment --service-name ${service_name} --cli-input-json file://$(pwd)/container.json
```

Whoa there is a lot going on here! The last two steps are most important:
`Build Docker Image` and `Push and Deploy`.

```shell, ignore
docker build -t ${{ env.AWS_LIGHTSAIL_SERVICE_NAME }}:release .
```

This command builds our Docker image with the name `container-service-2` and
tags it `release`.

```shell, ignore
aws lightsail push-container-image ...
```

This command pushes the local image to our Lightsail container.

```shell, ignore
aws lightsail get-container-images --service-name ${service_name} | jq --raw-output ".containerImages[0].image" > image.txt
```

This command retrieves the image information and, using
[`jq`](https://stedolan.github.io/jq/), parses it and saves the image name in a
local file `image.txt`.

```shell, ignore
jq --arg image $(cat image.txt) '.containers.app.image = $image' container.template.json > container.json
```

This command uses the image name saved in `image.txt` and
`container.template.json` and creates a new options file called
`container.json`. This options file will be passed to `aws lightsail` for the
final deployment in the next step.

```shell, ignore
aws lightsail create-container-service-deployment --service-name ${service_name} --cli-input-json file://$(pwd)/container.json
```

Finally, this command creates a new deployment using the `service_name`, along
with the config settings in `container.json`.

When you push to GitHub and the Action succeeds, you'll be able to see your new
Deno app on AWS:

<!-- ![deno on aws](../../images/how-to/aws-lightsail/hello-world-from-deno-and-aws-lightsail.png) -->
![deno on aws](https://docs.deno.com/assets/images/hello-world-from-deno-and-aws-lightsail-9268528211f36171cf5c3ae37622db85.png)



/. 🚀 runtime/manual/advanced/deploying_deno/cloudflare_workers.md
===================================================

    curl -s https://docs.deno.com/runtime/manual/advanced/deploying_deno/cloudflare_workers | sed -n 's/</\n/p' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|p'

# Deploying Deno to Cloudflare Workers

Cloudflare Workers allows you to run JavaScript on Cloudflare's edge network.

This is a short How To guide on deploying a Deno function to Cloudflare Workers.

Note: You would only be able to deploy
[Module Workers](https://developers.cloudflare.com/workers/learning/migrating-to-module-workers/)
instead of web servers or apps.

## Setup `denoflare`

In order to deploy Deno to Cloudflare, we'll use this community created CLI
[`denoflare`](https://denoflare.dev/).

[Install it](https://denoflare.dev/cli/#installation):

```shell, ignore
deno install --unstable --allow-read --allow-net --allow-env --allow-run --name denoflare --force \
https://raw.githubusercontent.com/skymethod/denoflare/v0.5.11/cli/cli.ts
```

## Create your function

In a new directory, let's create a `main.ts` file, which will contain our Module
Worker function:

```ts, ignore
export default {
  fetch(request: Request): Response {
    return new Response("Hello, world!");
  },
};
```

At the very minimum, a Module Worker function must `export default` an object
that exposes a `fetch` function, which returns a `Response` object.

You can test this locally by running:

```shell, ignore
denoflare serve main.ts
```

If you go to `localhost:8080` in your browser, you'll see the response will say:

```
Hello, world!
```

## Configure `.denoflare`

The next step is to create a `.denoflare` config file. In it, let's add:

```json
{
  "$schema": "https://raw.githubusercontent.com/skymethod/denoflare/v0.5.11/common/config.schema.json",
  "scripts": {
    "main": {
      "path": "/absolute/path/to/main.ts",
      "localPort": 8000
    }
  },
  "profiles": {
    "myprofile": {
      "accountId": "abcxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
      "apiToken": "abcxxxxxxxxx_-yyyyyyyyyyyy-11-dddddddd"
    }
  }
}
```

You can find your `accountId` by going to your
[Cloudflare dashboard](https://dash.cloudflare.com/), clicking "Workers", and
finding "Account ID" on the right side.

You can generate an `apiToken` from your
[Cloudflare API Tokens settings](https://dash.cloudflare.com/profile/api-tokens).
When you create an API token, be sure to use the template "Edit Cloudflare
Workers".

After you add both to your `.denoflare` config, let's try pushing it to
Cloudflare:

```
denoflare push main
```

Next, you can view your new function in your Cloudflare account:

<!-- ![New function on Cloudflare Workers](../../images/how-to/cloudflare-workers/main-on-cloudflare.png) -->
![New function on Cloudflare Workers](https://docs.deno.com/assets/images/main-on-cloudflare-8f45e51ee8f7d50124886f4ee77706b8.png)

Boom!



/. 🚀 runtime/manual/advanced/deploying_deno/digital_ocean.md
===================================================

    curl -s https://docs.deno.com/runtime/manual/advanced/deploying_deno/digital_ocean | sed -n 's/</\n/p' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|p'

# How to Deploy Deno to Digital Ocean

Digital Ocean is a popular cloud infrastructure provider offering a variety of
hosting services ranging from networking, to compute, to storage.

Here's a step by step guide to deploying a Deno app to Digital Ocean using
Docker and GitHub Actions.

The pre-requisite for this is:

- [`docker` CLI](https://docs.docker.com/engine/reference/commandline/cli/)
- a [GitHub account](https://github.com)
- a [Digital Ocean account](https://digitalocean.com)
- [`doctl` CLI](https://docs.digitalocean.com/reference/doctl/how-to/install/)

## Create Dockerfile and docker-compose.yml

To focus on the deployment, our app will simply be a `main.ts` file that returns
a string as an HTTP response:

```ts, ignore
import { Application } from "https://deno.land/x/oak/mod.ts";

const app = new Application();

app.use((ctx) => {
  ctx.response.body = "Hello from Deno and Digital Ocean!";
});

await app.listen({ port: 8000 });
```

Then, we'll create two files -- `Dockerfile` and `docker-compose.yml` -- to
build the Docker image.

In our `Dockerfile`, let's add:

```Dockerfile, ignore
FROM denoland/deno

EXPOSE 8000

WORKDIR /app

ADD . /app

RUN deno cache main.ts

CMD ["run", "--allow-net", "main.ts"]
```

Then, in our `docker-compose.yml`:

```yml, ignore
version: '3'

services:
  web:
    build: .
    container_name: deno-container
    image: deno-image
    ports:
      - "8000:8000"
```

Let's test this locally by running `docker compose -f docker-compose.yml build`,
then `docker compose up`, and going to `localhost:8000`.

<!-- ![Hello from localhost](../../images/how-to/digital-ocean/hello-world-from-localhost.png) -->
![Hello from localhost](https://docs.deno.com/assets/images/hello-world-from-localhost-5d39622d6fcf29ae20174d9af7b5954e.png)

It works!

## Build, Tag, and Push your Docker image to Digital Ocean Container Registry

Digital Ocean has its own private Container Registry, with which we can push and
pull Docker images. In order to use this registry, let's
[install and authenticate `doctl` on the command line](https://docs.digitalocean.com/reference/doctl/how-to/install/).

After that, we'll create a new private registry named `deno-on-digital-ocean`:

```shell, ignore
doctl registry create deno-on-digital-ocean
```

Using our Dockerfile and docker-compose.yml, we'll build a new image, tag it,
and push it to the registry. Note that `docker-compose.yml` will name the build
locally as `deno-image`.

```shell, ignore
docker compose -f docker-compose.yml build
```

Let's [tag](https://docs.docker.com/engine/reference/commandline/tag/) it with
`new`:

```shell, ignore
docker tag deno-image registry.digitalocean.com/deno-on-digital-ocean/deno-image:new
```

Now we can push it to the registry.

```shell, ignore
docker push registry.digitalocean.com/deno-on-digital-ocean/deno-image:new
```

You should see your new `deno-image` with the `new` tag in your
[Digital Ocean container registry](https://cloud.digitalocean.com/registry):

<!-- ![New deno image on Digital Ocean container registry](../../images/how-to/digital-ocean/new-deno-image-on-digital-ocean-container-registry.png) -->
![New deno image on Digital Ocean container registry](https://docs.deno.com/assets/images/new-deno-image-on-digital-ocean-container-registry-e1dac0bf1bcc1c2328c05c0e4089c543.png)

Perfect!

## Deploy to Digital Ocean via SSH

Once our `deno-image` is in the registry, we can run it anywhere using
`docker run`. In this case, we'll run it while in our
[Digital Ocean Droplet](https://www.digitalocean.com/products/droplets), their
hosted virtual machine.

While on your [Droplet page](https://cloud.digitalocean.com/droplets), click on
your Droplet and then `console` to SSH into the virtual machine. (Or you can
[ssh directly from your command line](https://docs.digitalocean.com/products/droplets/how-to/connect-with-ssh/).)

To pull down the `deno-image` image and run it, let's run:

```shell, ignore
docker run -d --restart always -it -p 8000:8000 --name deno-image registry.digitalocean.com/deno-on-digital-ocean/deno-image:new
```

Using our browser to go to the Digital Ocean address, we now see:

<!-- ![Hello from Deno and Digital Ocean](../../images/how-to/digital-ocean/hello-from-deno-and-digital-ocean.png) -->
![Hello from Deno and Digital Ocean](https://docs.deno.com/assets/images/hello-from-deno-and-digital-ocean-e290fb243511d81cdc61adf006e33113.png)

Boom!

## Automate the Deployment via GitHub Actions

Let's automate that entire process with GitHub actions.

First, let's get all of our environmental variables needed for logging into
`doctl` and SSHing into the Droplet:

- [DIGITALOCEAN_ACCESS_TOKEN](https://docs.digitalocean.com/reference/api/create-personal-access-token/)
- DIGITALOCEAN_HOST (the IP address of your Droplet)
- DIGITALOCEAN_USERNAME (the default is `root`)
- DIGITALOCEAN_SSHKEY (more on this below)

### Generate `DIGITALOCEAN_SSHKEY`

The `DIGITALOCEAN_SSHKEY` is a private key where its public counterpart exists
on the virtual machine in its `~/.ssh/authorized_keys` file.

To do this, first let's run `ssh-keygen` on your local machine:

```shell, ignore
ssh-keygen
```

When prompted for an email, **be sure to use your GitHub email** for the GitHub
Action to authenticate properly. Your final output should look something like
this:

```
Output
Your identification has been saved in /your_home/.ssh/id_rsa
Your public key has been saved in /your_home/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:/hk7MJ5n5aiqdfTVUZr+2Qt+qCiS7BIm5Iv0dxrc3ks user@host
The key's randomart image is:
+---[RSA 3072]----+
|                .|
|               + |
|              +  |
| .           o . |
|o       S   . o  |
| + o. .oo. ..  .o|
|o = oooooEo+ ...o|
|.. o *o+=.*+o....|
|    =+=ooB=o.... |
+----[SHA256]-----+
```

Next, we'll have to upload the newly generated public key to your Droplet. You
can either use [`ssh-copy-id`](https://www.ssh.com/academy/ssh/copy-id) or
manually copy it, ssh into your Droplet, and pasting it to
`~/.ssh/authorized_keys`.

Using `ssh-copy-id`:

```shell, ignore
ssh-copy-id {{ username }}@{{ host }}
```

This command will prompt you for the password. Note that this will automatically
copy `id_rsa.pub` key from your local machine and paste it to your Droplet's
`~/.ssh/authorized_keys` file. If you've named your key something other than
`id_rsa`, you can pass it with the `-i` flag to the command:

```shell, ignore
ssh-copy-id -i ~/.ssh/mykey {{ username }}@{{ host }}
```

To test whether this is done successfully:

```shell, ignore
ssh -i ~/.ssh/mykey {{ username }}@{{ host }}
```

Awesome!

### Define the yml File

The final step is to put this all together. We're basically taking each step
during the manual deployment and adding them to a GitHub Actions workflow yml
file:

```yml, ignore
name: Deploy to Digital Ocean

on:
  push:
    branches:
      - main

env:
  REGISTRY: "registry.digitalocean.com/deno-on-digital-ocean"
  IMAGE_NAME: "deno-image"

jobs:
  build_and_push:
    name: Build, Push, and Deploy
    runs-on: ubuntu-latest
    steps:
    - name: Checkout main
      uses: actions/checkout@v2

    - name: Set $TAG from shortened sha
      run: echo "TAG=`echo ${GITHUB_SHA} | cut -c1-8`" >> $GITHUB_ENV

    - name: Build container image
      run: docker compose -f docker-compose.yml build

    - name: Tag container image
      run: docker tag ${{ env.IMAGE_NAME }} ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.TAG }}

    - name: Install `doctl`
      uses: digitalocean/action-doctl@v2
      with:
        token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

    - name: Log in to Digital Ocean Container Registry
      run: doctl registry login --expiry-seconds 600

    - name: Push image to Digital Ocean Container Registry
      run: docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.TAG }}

    - name: Deploy via SSH
      uses: appleboy/ssh-action@master
      with:
        host: ${{ secrets.DIGITALOCEAN_HOST }}
        username: ${{ secrets.DIGITALOCEAN_USERNAME }}
        key: ${{ secrets.DIGITALOCEAN_SSHKEY }}
        script: |
          # Login to Digital Ocean Container Registry
          docker login -u ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }} -p ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }} registry.digitalocean.com
          # Stop and remove a running image.
          docker stop ${{ env.IMAGE_NAME }}
          docker rm ${{ env.IMAGE_NAME }}
          # Run a new container from a new image
          docker run -d --restart always -it -p 8000:8000 --name ${{ env.IMAGE_NAME }} ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.TAG }}
```

When you push to GitHub, this yml file is automatically detected, triggering the
Deploy action.



/. 🚀 runtime/manual/advanced/deploying_deno/google_cloud_run.md
===================================================

    curl -s https://docs.deno.com/runtime/manual/advanced/deploying_deno/google_cloud_run | sed -n 's/</\n/p' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|p'

# How to Deploy to Google Cloud Run

[Google Cloud Run](https://cloud.google.com/run) is a managed compute platform
that lets you run containers on Google's scalable infrastructure.

This How To guide will show you how to use Docker to deploy your Deno app to
Google Cloud Run.

First, we'll show you how to deploy manually, then we'll show you how to
automate it with GitHub Actions.

Pre-requisites:

- [Google Cloud Platform account](https://cloud.google.com/gcp)
- [`docker` CLI](https://docs.docker.com/engine/reference/commandline/cli/)
  installed
- [`gcloud`](https://cloud.google.com/sdk/gcloud) installed

## Manual Deployment

### Create `Dockerfile` and `docker-compose.yml`

To focus on the deployment, our app will simply be a `main.ts` file that returns
a string as an HTTP response:

```ts, ignore
import { Application } from "https://deno.land/x/oak/mod.ts";

const app = new Application();

app.use((ctx) => {
  ctx.response.body = "Hello from Deno and Google Cloud Run!";
});

await app.listen({ port: 8000 });
```

Then, we'll create two files -- `Dockerfile` and `docker-compose.yml` -- to
build the Docker image.

In our `Dockerfile`, let's add:

```Dockerfile, ignore
FROM denoland/deno

EXPOSE 8000

WORKDIR /app

ADD . /app

RUN deno cache main.ts

CMD ["run", "--allow-net", "main.ts"]
```

Then, in our `docker-compose.yml`:

```yml, ignore
version: '3'

services:
  web:
    build: .
    container_name: deno-container
    image: deno-image
    ports:
      - "8000:8000"
```

Let's test this locally by running `docker compose -f docker-compose.yml build`,
then `docker compose up`, and going to `localhost:8000`.

<!-- ![Hello from localhost](../../images/how-to/google-cloud-run/hello-world-from-localhost.png) -->
![Hello from localhost](https://docs.deno.com/assets/images/hello-world-from-localhost-d56e15e0b84a511616a1be799237c8ea.png)

It works!

### Set up Artifact Registry

Artifact Registry is GCP's private registry of Docker images.

Before we can use it, go to GCP's
[Artifact Registry](https://console.cloud.google.com/artifacts) and click
"Create repository". You'll be asked for a name (`deno-repository`) and a region
(`us-central1`). Then click "Create".

<!-- ![New repository in Google Artifact Repository](../../images/how-to/google-cloud-run/new-repository-in-google-artifact-repository.png) -->
![New repository in Google Artifact Repository](https://docs.deno.com/assets/images/new-repository-in-google-artifact-repository-09d8fc4519cc95279bc53bbe37720143.png)

### Build, Tag, and Push to Artifact Registry

Once we've created a repository, we can start pushing images to it.

First, let's add the registry's address to `gcloud`:

```shell, ignore
gcloud auth configure-docker us-central1-docker.pkg.dev
```

Then, let's build your Docker image. (Note that the image name is defined in our
`docker-compose.yml` file.)

```shell, ignore
docker compose -f docker-compose.yml build
```

Then, [tag](https://docs.docker.com/engine/reference/commandline/tag/) it with
the new Google Artifact Registry address, repository, and name. The image name
should follow this structure:
`{{ location }}-docker.pkg.dev/{{ google_cloudrun_project_name }}/{{ repository }}/{{ image }}`.

```shell, ignore
docker tag deno-image us-central1-docker.pkg.dev/deno-app-368305/deno-repository/deno-cloudrun-image
```

If you don't specify a tag, it'll use `:latest` by default.

Next, push the image:

```shell, ignore
docker push us-central1-docker.pkg.dev/deno-app-368305/deno-repository/deno-cloudrun-image
```

_[More info on how to push and pull images to Google Artifact Registry](https://cloud.google.com/artifact-registry/docs/docker/pushing-and-pulling)._

Your image should now appear in your Google Artifact Registry!

<!-- ![Image in Google Artifact Registry](../../images/how-to/google-cloud-run/image-in-google-artifact-registry.png) -->
![Image in Google Artifact Registry](https://docs.deno.com/assets/images/image-in-google-artifact-registry-bc0a760a5226c28400db8de27a2ef9b3.png)

### Create a Google Cloud Run Service

We need an instance where we can build these images, so let's go to
[Google Cloud Run](https://console.cloud.google.com/run) and click "Create
Service".

Let's name it "hello-from-deno".

Select "Deploy one revision from an existing container image". Use the drop down
to select the image from the `deno-repository` Artifact Registry.

Select "allow unauthenticated requests" and then click "Create service". Make
sure the port is `8000`.

When it's done, your app should now be live:

<!-- ![Hello from Google Cloud Run](../../images/how-to/google-cloud-run/hello-from-google-cloud-run.png) -->
![Hello from Google Cloud Run](https://docs.deno.com/assets/images/hello-from-google-cloud-run-e99cc7bc36a24b1d997503737e62a8a3.png)

Awesome!

### Deploy with `gcloud`

Now that it's created, we'll be able to deploy to this service from the `gcloud`
CLI. The command follows this structure:
`gcloud run deploy {{ service_name }} --image={{ image }} --region={{ region }} --allow-unauthenticated`.
Note that the `image` name follows the structure from above.

For this example, the command is:

```shell, ignore
gcloud run deploy hello-from-deno --image=us-central1-docker.pkg.dev/deno-app-368305/deno-repository/deno-cloudrun-image --region=us-central1 --allow-unauthenticated
```

<!-- ![Hello from Google Cloud Run](../../images/how-to/google-cloud-run/hello-from-google-cloud-run.png) -->
![Hello from Google Cloud Run](https://docs.deno.com/assets/images/hello-from-google-cloud-run-e99cc7bc36a24b1d997503737e62a8a3.png)

Success!

## Automate Deployment with GitHub Actions

In order for automation to work, we first need to make sure that these both have
been created:

- the Google Artifact Registry
- the Google Cloud Run service instance

(If you haven't done that, please see the section before.)

Now that we have done that, we can automate it with a GitHub workflow. Here's
the yaml file:

```yml, ignore
name: Build and Deploy to Cloud Run

on:
  push:
    branches:
      - main

env:
  PROJECT_ID: {{ PROJECT_ID }}
  GAR_LOCATION: {{ GAR_LOCATION }}
  REPOSITORY: {{ GAR_REPOSITORY }}
  SERVICE: {{ SERVICE }}
  REGION: {{ REGION }}

jobs:
  deploy:
    name: Deploy
    permissions:
      contents: 'read'
      id-token: 'write'

    runs-on: ubuntu-latest
    steps:
    - name: CHeckout
      uses: actions/checkout@v3

    - name: Google Auth
      id: auth
      uses: 'google-github-actions/auth@v0'
      with:
        credentials_json: '${{ secrets.GCP_CREDENTIALS }}'

    - name: Login to GAR
      uses: docker/login-action@v2.1.0
      with:
        registry: ${{ env.GAR_LOCATION }}-docker.pkg.dev
        username: _json_key
        password: ${{ secrets.GCP_CREDENTIALS }}

    - name: Build and Push Container
      run: |-
        docker build -t "${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.SERVICE }}:${{ github.sha }}" ./
        docker push "${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.SERVICE }}:${{ github.sha }}"

    - name: Deploy to Cloud Run
      id: deploy
      uses: google-github-actions/deploy-cloudrun@v0
      with:
        service: ${{ env.SERVICE }}
        region: ${{ env.REGION }}
        image: ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.SERVICE }}:${{ github.sha }}

    - name: Show Output
      run: echo ${{ steps.deploy.outputs.url }}
```

The environment variables that we need to set are (the examples in parenthesis
are the ones for this repository)

- `PROJECT_ID`: your project id (`deno-app-368305`)
- `GAR_LOCATION`: the location your Google Artifact Registry is set
  (`us-central1`)
- `GAR_REPOSITORY`: the name you gave your Google Artifact Registry
  (`deno-repository`)
- `SERVICE`: the name of the Google Cloud Run service (`hello-from-deno`)
- `REGION`: the region of your Google Cloud Run service (`us-central1`)

The secret variables that we need to set are:

- `GCP_CREDENTIALS`: this is the
  [service account](https://cloud.google.com/iam/docs/service-accounts) json
  key. When you create the service account, be sure to
  [include the roles and permissions necessary](https://cloud.google.com/iam/docs/granting-changing-revoking-access#granting_access_to_a_user_for_a_service_account)
  for Artifact Registry and Google Cloud Run.

[Check out more details and examples of deploying to Cloud Run from GitHub Actions.](https://github.com/google-github-actions/deploy-cloudrun)

For reference:
https://github.com/google-github-actions/example-workflows/blob/main/workflows/deploy-cloudrun/cloudrun-docker.yml



/. 🚀 runtime/manual/advanced/deploying_deno/kinsta.md
===================================================

# How to Deploy Deno on Kinsta

[Kinsta Application Hosting](https://kinsta.com/application-hosting) is a
service that lets you build and deploy your web apps directly from your Git
repository.

## Preparing your application

At **Kinsta**, we recommend using the
[`deno-bin`](https://www.npmjs.com/package/deno-bin) package to run Deno
applications.

To do so, your `package.json` should look like this:

```json
{
  "name": "deno app",
  "scripts": {
    "start": "deno run --allow-net index.js --port=${PORT}"
  },
  "devDependencies": {
    "deno-bin": "^1.28.2"
  }
}
```

## Example application

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";
import { parse } from "https://deno.land/std@$STD_VERSION/flags/mod.ts";

const { args } = Deno;
const argPort = parse(args).port ? Number(parse(args).port) : 8000;

serve((_req) => new Response("Hello, world"), { port: argPort });
```

The application itself is self-explanatory. It's crucial not to hardcode the
`PORT` but use the environmental variable **Kinsta** provides.

There is also a [repository](https://github.com/kinsta/hello-world-deno) that
should help you to get started.

## Deployment

1. Register on
   [Kinsta Application Hosting](https://kinsta.com/signup/?product_type=app-db)
   or login directly to [My Kinsta](https://my.kinsta.com/) admin panel.
2. Go to the Applications tab.
3. Connect your GitHub repository.
4. Press the **Add service > Application button**.
5. Follow the wizard steps.



/. 🚀 runtime/manual/node/index.md
===================================================

# Node and npm modules

Many people will want to leverage code and libraries that are built for
[Node](https://nodejs.org/), in particular the large set of packages available
on the [npm](https://npmjs.com/) registry.

There are currently several ways to do this:

- Using [`npm:` specifiers](./npm_specifiers.md) and
  [`node:` specifiers](./node_specifiers.md)
- [package.json compatibility](./package_json.md)
- Using [CDNs](./cdns.md)



/. 🚀 runtime/manual/node/npm_specifiers.md
===================================================

    curl -s -L https://docs.deno.com/runtime/manual/node/npm_specifiers | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# `npm:` specifiers

Since version 1.28, Deno has native support for importing npm packages. This is
done by importing using `npm:` specifiers. For example the following code:

```ts
import { emojify } from "npm:node-emoji@2";

console.log(emojify(":t-rex: :heart: NPM"));
```

Can be run with:

```sh
$ deno run main.js
🦖 ❤️ NPM
```

When doing this, no `npm install` is necessary and no `node_modules` folder is
created. These packages are also subject to the same
[permissions](../basics/permissions.md) as other code in Deno.

npm specifiers have the following format:

```
npm:<package-name>[@<version-requirement>][/<sub-path>]
```

For examples with popular libraries, please refer to our
[tutorial section](/runtime/tutorials).

## TypeScript types

Many packages ship with types out of the box, you can import those and use them
with types easily:

```ts
import chalk from "npm:chalk@5";
```

Some packages do not though, but you can specify their types with a
[`@deno-types`](../advanced/typescript/types.md) directive. For example, using a
[`@types`](https://www.typescriptlang.org/docs/handbook/2/type-declarations.html#definitelytyped--types)
package:

```ts
// @deno-types="npm:@types/express@^4.17"
import express from "npm:express@^4.17";
```

### Module resolution

The official TypeScript compiler `tsc` supports different
[moduleResolution](https://www.typescriptlang.org/tsconfig#moduleResolution)
settings. Deno only supports the modern `node16` resolution. Unfortunately many
NPM packages fail to correctly provide types under node16 module resolution,
which can result in `deno check` reporting type errors, that `tsc` does not
report.

If a default export from an `npm:` import appears to have a wrong type (with the
right type seemingly being available under the `.default` property), it's most
likely that the package provides wrong types under node16 module resolution for
imports from ESM. You can verify this by checking if the error also occurs with
`tsc --module node16` and `"type": "module"` in `package.json` or by consulting
the [Are the types wrong?](https://arethetypeswrong.github.io/) website
(particularly the "node16 from ESM" row).

If you want to use a package that doesn't support TypeScript's node16 module
resolution, you can:

1. Open an issue at the issue tracker of the package about the problem. (And
   perhaps contribute a fix :) (Although there unfortunately currently is a lack
   of tooling for packages to support both ESM and CJS, since default exports
   require different syntaxes, see also
   [microsoft/TypeScript#54593](https://github.com/microsoft/TypeScript/issues/54593))
2. Use a [CDN](./cdns.md), that rebuilds the packages for Deno support, instead
   of an `npm:` identifier.
3. Ignore the type errors you get in your code base with `// @ts-expect-error`
   or `// @ts-ignore`.

### Including Node types

Node ships with many built-in types like `Buffer` that might be referenced in an
npm package's types. To load these you must add a types reference directive to
the `@types/node` package:

```ts
/// <reference types="npm:@types/node" />
```

Note that it is fine to not specify a version for this in most cases because
Deno will try to keep it in sync with its internal Node code, but you can always
override the version used if necessary.

## npm executable scripts

npm packages with `bin` entries can be executed from the command line without an
`npm install` using a specifier in the following format:

```
npm:<package-name>[@<version-requirement>][/<binary-name>]
```

For example:

```sh
$ deno run --allow-read npm:cowsay@1.5.0 Hello there!
 ______________
< Hello there! >
 --------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

$ deno run --allow-read npm:cowsay@1.5.0/cowthink What to eat?
 ______________
( What to eat? )
 --------------
        o   ^__^
         o  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
```

## `--node-modules-dir` flag

npm specifiers resolve npm packages to a central global npm cache. This works
well in most cases and is ideal since it uses less space and doesn't require a
node_modules directory. That said, you may find cases where an npm package
expects itself to be executing from a `node_modules` directory. To improve
compatibility and support those packages, you can use the `--node-modules-dir`
flag.

For example, given `main.ts`:

```ts
import chalk from "npm:chalk@5";

console.log(chalk.green("Hello"));
```

Running this script with a `--node-modules-dir` like so...

```sh
deno run --node-modules-dir main.ts
```

...will create a `node_modules` folder in the current directory with a similar
folder structure to npm.

```sh
+-- node_nodules
| +-- .deno
| +-- chalk
|   +-- source
|   +-- license
|   +-- package.json
|   +-- readme.md
+--main.ts
```
<!-- ![](../images/node_modules_dir.png) -->

Note that this is all done automatically when calling deno run and there is no
separate install command necessary.

Alternatively, if you wish to disable the creation of a `node_modules` directory
entirely, you can set this flag to false (ex. `--node-modules-dir=false`) or add
a `"nodeModulesDir": false` entry to your deno.json configuration file to make
the setting apply to the entire directory tree.

In the case where you want to modify the contents of the `node_modules`
directory before execution, you can run `deno cache` with `--node-modules-dir`,
modify the contents, then run the script.

For example:

```sh
deno cache --node-modules-dir main.ts
deno run --allow-read=. --allow-write=. scripts/your_script_to_modify_node_modules_dir.ts
deno run --node-modules-dir main.ts
```



/. 🚀 runtime/manual/node/how_to_with_npm/index.md
===================================================

# How To guides with npm

Here's a collection of How To guides to help you get started using a particular
npm module with Deno.

## Data Persistence

- [Prisma](./prisma.md)
- [Mongoose](./mongoose.md)
- [MySQL2](./mysql2.md)
- [Redis](./redis.md)
- [Apollo](./apollo.md)
- [PlanetScale](./planetscale.md)

## Frameworks

- [React](./react.md)
- [Vue](./vue.md)
- [Express](./express.md)



/. 🚀 runtime/manual/node/how_to_with_npm/apollo.md
===================================================

# How to use Apollo with Deno

[Apollo Server](https://www.apollographql.com/) is a GraphQL server that you can
set up in minutes and use with your existing data source (or REST API). You can
then connect any GraphQL client to it to receive the data and take advantage of
GraphQL benefits, such as type-checking and efficient fetching.

We're going to get a simple Apollo server up and running that will allow us to
query some local data. We're only going to need three files for this:

1. `schema.ts` to set up our data model
2. `resolvers.ts` to set up how we're going to populate the data fields in our
   schema
3. Our `main.ts` where the server is going to launch

We'll start by creating them:

```shell, ignore
touch schema.ts resolvers.ts main.ts
```

Let's go through setting up each.

[View source here.](https://github.com/denoland/examples/tree/main/with-apollo)

## schema.ts

Our `schema.ts` file describes our data. In this case, our data is a list of
dinosaurs. We want our users to be able to get the name and a short description
of each dino. In GraphQL language, this means that `Dinosaur` is our **type**,
and `name` and `description` are our **fields**. We can also define the data
type for each field. In this case, both are strings.

This is also where we describe the queries we allow for our data, using the
special **Query** type in GraphQL. We have two queries:

- `dinosaurs` which gets a list of all dinosaurs
- `dinosaur` which takes in the `name` of a dinosaur as an argument and returns
  information about that one type of dinosaur.

We're going to export all this within our `typeDefs` type definitions, variable:

```tsx, ignore
export const typeDefs = `
  type Dinosaur {
    name: String
    description: String
  }

  type Query {
    dinosaurs: [Dinosaur]
		dinosaur(name: String): Dinosaur
  }
`;
```

If we wanted to write data, this is also where we would describe the
**Mutation** to do so. Mutations are how you write data with GraphQL. Because we
are using a static dataset here, we won't be writing anything.

## resolvers.ts

A resolver is responsible for populating the data for each query. Here we have
our list of dinosaurs and all the resolver is going to do is either a) pass that
entire list to the client if the user requests the `dinosaurs` query, or pass
just one if the user requests the `dinosaur` query.

```tsx, ignore
const dinosaurs = [
  {
    name: "Aardonyx",
    description: "An early stage in the evolution of sauropods.",
  },
  {
    name: "Abelisaurus",
    description: '"Abel\'s lizard" has been reconstructed from a single skull.',
  },
];

export const resolvers = {
  Query: {
    dinosaurs: () => dinosaurs,
    dinosaur: (_: any, args: any) => {
      return dinosaurs.find((dinosaur) => dinosaur.name === args.name);
    },
  },
};
```

With the latter, we pass the arguments from the client into a function to match
the name to a name in our dataset.

## main.ts

In our `main.ts` we're going to import the `ApolloServer` as well as `graphql`
and our `typeDefs` from the schema and our resolvers:

```tsx, ignore
import { ApolloServer } from "npm:@apollo/server@^4.1";
import { startStandaloneServer } from "npm:@apollo/server@4.1/standalone";
import { graphql } from "npm:graphql@16.6";
import { typeDefs } from "./schema.ts";
import { resolvers } from "./resolvers.ts";

const server = new ApolloServer({
  typeDefs,
  resolvers,
});

const { url } = await startStandaloneServer(server, {
  listen: { port: 8000 },
});

console.log(`Server running on: ${url}`);
```

We pass our `typeDefs` and `resolvers` to `ApolloServer` to spool up a new
server. Finally, `startStandaloneServer` is a helper function to get the server
up and running quickly.

## Running the server

All that is left to do now is run the server:

```shell, ignore
deno run --allow-net --allow-read --allow-env main.ts
```

You should see `Server running on: 127.0.0.1:8000` in your terminal. If you go
to that address you will see the Apollo sandbox where we can enter our
`dinosaurs` query:

```graphql, ignore
query {
  dinosaurs {
    name
    description
  }
}
```

This will return our dataset:

```graphql
{
  "data": {
    "dinosaurs": [
      {
        "name": "Aardonyx",
        "description": "An early stage in the evolution of sauropods."
      },
      {
        "name": "Abelisaurus",
        "description": "\"Abel's lizard\" has been reconstructed from a single skull."
      }
    ]
  }
}
```

Or if we want just one `dinosaur`:

```graphql, ignore
query {
  dinosaur(name:"Aardonyx") {
    name
    description
  }
}
```

Which returns:

```graphql, ignore
{
  "data": {
    "dinosaur": {
      "name": "Aardonyx",
      "description": "An early stage in the evolution of sauropods."
    }
  }
}
```

Awesome!

[Learn more about using Apollo and GraphQL in their tutorials](https://www.apollographql.com/tutorials/).



/. 🚀 runtime/manual/node/how_to_with_npm/express.md
===================================================

# How to use Express with Deno

[Express](https://expressjs.com/) is a popular web framework known for being
simple and unopinionated with a large ecosystem of middleware.

This How To guide will show you how to create a simple API using Express and
Deno.

[View source here.](https://github.com/denoland/examples/tree/main/with-express)

## Create `main.ts`

Let's create `main.ts`:

```
touch main.ts
```

In `main.ts`, let's create a simple server:

```ts, ignore
// @deno-types="npm:@types/express@4.17.15"
import express from "npm:express@4.18.2";

const app = express();

app.get("/", (req, res) => {
  res.send("Welcome to the Dinosaur API!");
});

app.listen(8000);
```

Let's run this server:

```
deno run -A main.ts
```

And point our browser to `localhost:8000`. You should see:

```
Welcome to the Dinosaur API!
```

## Add data and routes

The next step here is to add some data. We'll use this Dinosaur data that we
found from [this article](https://www.thoughtco.com/dinosaurs-a-to-z-1093748).
Feel free to
[copy it from here](https://github.com/denoland/examples/blob/main/with-express/data.json).

Let's create `data.json`:

```
touch data.json
```

And paste in the dinosaur data.

Next, let's import that data into `main.ts`. Let's add this line at the top of
the file:

```ts, ignore
import data from "./data.json" assert { type: "json" };
```

Then, we can create the routes to access that data. To keep it simple, let's
just define `GET` handlers for `/api/` and `/api/:dinosaur`. Add the below after
the `const app = express();` line:

```ts, ignore
app.get("/", (req, res) => {
  res.send("Welcome to the Dinosaur API!");
});

app.get("/api", (req, res) => {
  res.send(data);
});

app.get("/api/:dinosaur", (req, res) => {
  if (req?.params?.dinosaur) {
    const found = data.find(item => item.name.toLowerCase() === req.params.dinosaur.toLowerCase());
    if (found) {
      res.send(found)
    } else {
      res.send("No dinosaurs found.");
    }
  }
});

app.listen(8000);
```

Let's run the server with `deno run -A main.ts` and check out
`localhost:8000/api`. You should see a list of dinosaurs:

```json, ignore
[
  {
    "name": "Aardonyx",
    "description": "An early stage in the evolution of sauropods."
  },
  {
    "name": "Abelisaurus",
    "description": "\"Abel's lizard\" has been reconstructed from a single skull."
  },
  {
    "name": "Abrictosaurus",
    "description": "An early relative of Heterodontosaurus."
  },
...
```

And when we go to `localhost:8000/api/aardonyx`:

```json, ignore
{
  "name": "Aardonyx",
  "description": "An early stage in the evolution of sauropods."
}
```

Great!



/. 🚀 runtime/manual/node/how_to_with_npm/mongoose.md
===================================================

# How to use Mongoose with Deno

[Mongoose](https://mongoosejs.com/) is a popular, schema-based library that
models data for [MongoDB](https://www.mongodb.com/). It simplifies writing
MongoDB validation, casting, and other relevant business logic.

This tutorial will show you how to setup Mongoose and MongoDB with your Deno
project.

[View source](https://github.com/denoland/examples/tree/main/with-mongoose) or
[check out the video guide](https://youtu.be/dmZ9Ih0CR9g).

## Creating a Mongoose Model

Let's create a simple app that connects to MongoDB, creates a `Dinosaur` model,
and adds and updates a dinosaur to the database.

First, we'll create the necessary files and directories:

```
$ touch main.ts && mkdir model && touch model/Dinosaur.ts
```

In `/model/Dinosaur.ts`, we'll import `npm:mongoose`, define the [schema], and
export it:

```ts, ignore
import { model, Schema } from "npm:mongoose@^6.7";

// Define schema.
const dinosaurSchema = new Schema({
  name: { type: String, unique: true },
  description: String,
  createdAt: { type: Date, default: Date.now },
  updatedAt: { type: Date, default: Date.now },
});

// Validations
dinosaurSchema.path("name").required(true, "Dinosaur name cannot be blank.");
dinosaurSchema.path("description").required(
  true,
  "Dinosaur description cannot be blank.",
);

// Export model.
export default model("Dinosaur", dinosaurSchema);
```

## Connecting to MongoDB

Now, in our `main.ts` file, we'll import mongoose and the `Dinosaur` schema, and
connect to MongoDB:

```ts, ignore
import mongoose from "npm:mongoose@^6.7";
import Dinosaur from "./model/Dinosaur.ts";

await mongoose.connect("mongodb://localhost:27017");

// Check to see connection status.
console.log(mongoose.connection.readyState);
```

Because Deno supports top-level `await`, we're able to simply
`await mongoose.connect()`.

Running this, we should expect a log of `1`:

```shell, ignore
$ deno run --allow-read --allow-sys --allow-env --allow-net main.ts
1
```

It worked!

## Manipulating Data

Let's add an instance [method](https://mongoosejs.com/docs/guide.html#methods)
to our `Dinosaur` schema in `/model/Dinosaur.ts`:

```ts, ignore
// ./model/Dinosaur.ts

// Methods.
dinosaurSchema.methods = {
  // Update description.
  updateDescription: async function (description: string) {
    this.description = description;
    return await this.save();
  },
};

// ...
```

This instance method, `updateDescription`, will allow you to update a record's
description.

Back in `main.ts`, let's start adding and manipulating data in MongoDB.

```ts, ignore
// main.ts

// Create a new Dinosaur.
const deno = new Dinosaur({
  name: "Deno",
  description: "The fastest dinosaur ever lived.",
});

// // Insert deno.
await deno.save();

// Find Deno by name.
const denoFromMongoDb = await Dinosaur.findOne({ name: "Deno" });
console.log(
  `Finding Deno in MongoDB -- \n  ${denoFromMongoDb.name}: ${denoFromMongoDb.description}`,
);

// Update description for Deno and save it.
await denoFromMongoDb.updateDescription(
  "The fastest and most secure dinosaur ever lived.",
);

// Check MongoDB to see Deno's updated description.
const newDenoFromMongoDb = await Dinosaur.findOne({ name: "Deno" });
console.log(
  `Finding Deno (again) -- \n  ${newDenoFromMongoDb.name}: ${newDenoFromMongoDb.description}`,
);
```

Running the code, we get:

```
Finding Deno in MongoDB --
  Deno: The fastest dinosaur ever lived.
Finding Deno (again) --
  Deno: The fastest and most secure dinosaur ever lived.
```

Boom!

For more info on using Mongoose, please refer to
[their documentation](https://mongoosejs.com/docs/guide.html).



/. 🚀 runtime/manual/node/how_to_with_npm/mysql2.md
===================================================

# How to use MySQL2 with Deno

[MySQL](https://www.mysql.com/) is the most popular database in the
[2022 Stack Overflow Developer Survey](https://survey.stackoverflow.co/2022/#most-popular-technologies-database)
and counts Facebook, Twitter, YouTube, and Netflix among its users.

[View source here.](https://github.com/denoland/examples/tree/main/with-mysql2)

You can manipulate and query a MySQL database with Deno using the `mysql2` node
package and importing via `npm:mysql2`. This allows us to use its Promise
wrapper and take advantage of top-level await.

```tsx, ignore
import mysql from "npm:mysql2@^2.3.3/promise";
```

## Connecting to MySQL

We can connect to our MySQL server using the `createConnection()` method. You
need the host (`localhost` if you are testing, or more likely a cloud database
endpoint in production) and the user and password:

```tsx, ignore
const connection = await mysql.createConnection({
  host: "localhost",
  user: "root",
  password: "password",
});
```

You can also optionally specify a database during the connection creation. Here
we are going to use `mysql2` to create the database on the fly.

## Creating and populating the database

Now that you have the connection running, you can use `connection.query()` with
SQL commands to create databases and tables as well as insert the initial data.

First we want to generate and select the database to use:

```tsx, ignore
await connection.query("CREATE DATABASE denos");
await connection.query("use denos");
```

Then we want to create the table:

```tsx, ignore
await connection.query(
  "CREATE TABLE `dinosaurs` (   `id` int NOT NULL AUTO_INCREMENT PRIMARY KEY,   `name` varchar(255) NOT NULL,   `description` varchar(255) )",
);
```

After the table is created we can populate the data:

```tsx, ignore
await connection.query(
  "INSERT INTO `dinosaurs` (id, name, description) VALUES (1, 'Aardonyx', 'An early stage in the evolution of sauropods.'), (2, 'Abelisaurus', 'Abels lizard has been reconstructed from a single skull.'), (3, 'Deno', 'The fastest dinosaur that ever lived.')",
);
```

We now have all the data ready to start querying.

## Querying MySQL

We can use the same connection.query() method to write our queries. First we try
and get all the data in our `dinosaurs` table:

```tsx, ignore
const results = await connection.query("SELECT * FROM `dinosaurs`");
console.log(results);
```

The result from this query is all the data in our database:

```tsx, ignore
[
  [
    {
      id: 1,
      name: "Aardonyx",
      description: "An early stage in the evolution of sauropods."
    },
    {
      id: 2,
      name: "Abelisaurus",
      description: `Abel's lizard" has been reconstructed from a single skull.`
    },
    { id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." }
  ],
```

If we want to just get a single element from the database, we can change our
query:

```tsx, ignore
const [results, fields] = await connection.query(
  "SELECT * FROM `dinosaurs` WHERE `name` = 'Deno'",
);
console.log(results);
```

Which gives us a single row result:

```tsx, ignore
[{ id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." }];
```

Finally, we can close the connection:

```tsx, ignore
await connection.end();
```

For more on `mysql2`, check out their documentation
[here](https://github.com/sidorares/node-mysql2).



/. 🚀 runtime/manual/node/how_to_with_npm/planetscale.md
===================================================

# How to use Planetscale with Deno

Planetscale is a MySQL-compatible serverless database that is designed with a
developer workflow where developers can create, branch, and deploy databases
from the command line.

[View source here.](https://github.com/denoland/examples/tree/main/with-planetscale)

We'll use the Planetscale serverless driver, `@planetscale/database`, to work
with Deno. First we want to create `main.ts` and import the connect method from
this package:

```tsx, ignore
import { connect } from "npm:@planetscale/database@^1.4";
```

## Configuring our connection

The connection requires three credentials: host, username, and password. These
are database-specific, so we first need to create a database in Planetscale. You
can do that by following the initial instructions
[here](https://planetscale.com/docs/tutorials/planetscale-quick-start-guide).
Don't worry about adding the schema—we can do that through
`@planetscale/database`.

Once you have created the database, head to Overview, click "Connect", and
choose "Connect with `@planetscale/database`" to get the host and username. Then
click through to Passwords to create a new password for your database. Once you
have all three you can plug them in directly, or better, store them as
environment variables:

```bash
export HOST=<host>
export USERNAME=<username>
export PASSWORD=<password>
```

Then call them using `Deno.env`:

```tsx, ignore
const config = {
  host: Deno.env.get("HOST"),
  username: Deno.env.get("USERNAME"),
  password: Deno.env.get("PASSWORD"),
};

const conn = connect(config);
```

This will also work on Deno Deploy if you set the environment variables in the
dashboard. Run with:

```shell, ignore
deno run --allow-net --allow-env main.ts
```

The `conn` object is now an open connection to our Planetscale database.

## Creating and populating our database table

Now that you have the connection running, you can `conn.execute()` with SQL
commands to create tables and insert the initial data:

```tsx, ignore
await conn.execute(
  "CREATE TABLE dinosaurs (id int NOT NULL AUTO_INCREMENT PRIMARY KEY, name varchar(255) NOT NULL, description varchar(255) NOT NULL);",
);
await conn.execute(
  "INSERT INTO `dinosaurs` (id, name, description) VALUES (1, 'Aardonyx', 'An early stage in the evolution of sauropods.'), (2, 'Abelisaurus', 'Abels lizard has been reconstructed from a single skull.'), (3, 'Deno', 'The fastest dinosaur that ever lived.')",
);
```

## Querying Planetscale

We can use same `conn.execute()` to also write our queries. Let's get a list of
all our dinosaurs:

```tsx, ignore
const results = await conn.execute("SELECT * FROM `dinosaurs`");
console.log(results.rows);
```

The result:

```tsx, ignore
[
  {
    id: 1,
    name: "Aardonyx",
    description: "An early stage in the evolution of sauropods.",
  },
  {
    id: 2,
    name: "Abelisaurus",
    description: "Abels lizard has been reconstructed from a single skull.",
  },
  { id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." },
];
```

We can also get just a single row from the database by specifying a dinosaur
name:

```tsx, ignore
const result = await conn.execute(
  "SELECT * FROM `dinosaurs` WHERE `name` = 'Deno'",
);
console.log(result.rows);
```

Which gives us a single row result:

```tsx, ignore
[{ id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." }];
```

You can find out more about working with Planetscale in their
[docs](https://planetscale.com/docs).



/. 🚀 runtime/manual/node/how_to_with_npm/prisma.md
===================================================

    curl -s -L https://docs.deno.com/runtime/manual/node/how_to_with_npm/prisma | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to create a RESTful API with Prisma and Oak

[Prisma](https://prisma.io) has been one of our top requested modules to work
with in Deno. The demand is understandable, given that Prisma's developer
experience is top notch and plays well with so many persistent data storage
technologies.

We're excited to show you how to use Prisma with Deno.

In this How To guide, we'll setup a simple RESTful API in Deno using Oak and
Prisma.

Let's get started.

[View source](https://github.com/denoland/examples/tree/main/with-prisma) or
[check out the video guide](https://youtu.be/P8VzA_XSF8w).

## Setup the application

Let's create the folder `rest-api-with-prisma-oak` and navigate there:

```shell, ignore
mkdir rest-api-with-prisma-oak
cd rest-api-with-prisma-oak
```

Then, let's run `prisma init` with Deno:

```shell, ignore
deno run --allow-read --allow-env --allow-write npm:prisma@^4.5 init
```

This will generate
[`prisma/schema.prisma`](https://www.prisma.io/docs/concepts/components/prisma-schema).
Let's update it with the following:

```ts, ignore
generator client {
  provider = "prisma-client-js"
  previewFeatures = ["deno"]
  output = "../generated/client"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Dinosaur {
  id          Int     @id @default(autoincrement())
  name        String  @unique
  description String
}
```

Prisma should also have generated a `.env` file with `DATABASE_URL`. Let's
assign `DATABASE_URL` to a PostreSQL connection string. In this example, we'll
use a free [PostgreSQL database from Supabase](https://supabase.com/database).

Next, let's create the database schema:

```shell, ignore
deno run -A npm:prisma@^4.5 db push
```

After that's complete, we'll need to generate a Prisma client for Data Proxy:

```shell, ignore
deno run -A --unstable npm:prisma@^4.5 generate --data-proxy
```

## Setup Prisma Data Platform

In order to use Prisma Data Platform, we'll have to create and connect a GitHub
repo. So let's initialize the repository, create a new GitHub repo, add the
remote origin, and push the repo.

Next, sign up for a free
[Prisma Data Platform account](https://cloud.prisma.io/).

Click **New Project** and select **Import a Prisma Repository**.

It'll ask for your PostgreSQL connection string, which you have in your `.env`.
Paste it here. Then click **Create Project**.

You'll receive a new connection string that begins with `prisma://`. Let's grab
that and assign it to `DATABASE_URL` in your `.env` file, replacing your
PostgreSQL string from Supabase.

Next, let's create a seed script to seed the database.

## Seed your Database

Create `./prisma/seed.ts`:

```shell, ignore
touch prisma/seed.ts
```

And in `./prisma/seed.ts`:

```ts, ignore
import { Prisma, PrismaClient } from "../generated/client/deno/edge.ts";
import { load } from "https://deno.land/std@$STD_VERSION/dotenv/mod.ts";

const envVars = await load();

const prisma = new PrismaClient({
  datasources: {
    db: {
      url: envVars.DATABASE_URL,
    },
  },
});

const dinosaurData: Prisma.DinosaurCreateInput[] = [
  {
    name: "Aardonyx",
    description: "An early stage in the evolution of sauropods.",
  },
  {
    name: "Abelisaurus",
    description: "Abel's lizard has been reconstructed from a single skull.",
  },
  {
    name: "Acanthopholis",
    description: "No, it's not a city in Greece.",
  },
];

/**
 * Seed the database.
 */

for (const u of dinosaurData) {
  const dinosaur = await prisma.dinosaur.create({
    data: u,
  });
  console.log(`Created dinosaur with id: ${dinosaur.id}`);
}
console.log(`Seeding finished.`);

await prisma.$disconnect();
```

We can now run `seed.ts` with:

```shell, ignore
deno run -A prisma/seed.ts
```

After doing so, your Prisma dashboard should show the new dinosaurs:

<!-- ![New dinosaurs are in Prisma dashboard](../../images/how-to/prisma/1-dinosaurs-in-prisma.png) -->
![New dinosaurs are in Prisma dashboard](https://docs.deno.com/assets/images/1-dinosaurs-in-prisma-825f3e2dafb04cb0c73f26cdf535e450.png)

## Create your API routes

We'll use [`oak`](https://deno.land/x/oak) to create the API routes. Let's keep
them simple for now.

Let's create a `main.ts` file:

```shell, ignore
touch main.ts
```

Then, in your `main.ts` file:

```ts, ignore
import { PrismaClient } from "./generated/client/deno/edge.ts";
import { Application, Router } from "https://deno.land/x/oak@v11.1.0/mod.ts";
import { load } from "https://deno.land/std@$STD_VERSION/dotenv/mod.ts";

const envVars = await load();

/**
 * Initialize.
 */

const prisma = new PrismaClient({
  datasources: {
    db: {
      url: envVars.DATABASE_URL,
    },
  },
});
const app = new Application();
const router = new Router();

/**
 * Setup routes.
 */

router
  .get("/", (context) => {
    context.response.body = "Welcome to the Dinosaur API!";
  })
  .get("/dinosaur", async (context) => {
    // Get all dinosaurs.
    const dinosaurs = await prisma.dinosaur.findMany();
    context.response.body = dinosaurs;
  })
  .get("/dinosaur/:id", async (context) => {
    // Get one dinosaur by id.
    const { id } = context.params;
    const dinosaur = await prisma.dinosaur.findUnique({
      where: {
        id: Number(id),
      },
    });
    context.response.body = dinosaur;
  })
  .post("/dinosaur", async (context) => {
    // Create a new dinosaur.
    const { name, description } = await context.request.body("json").value;
    const result = await prisma.dinosaur.create({
      data: {
        name,
        description,
      },
    });
    context.response.body = result;
  })
  .delete("/dinosaur/:id", async (context) => {
    // Delete a dinosaur by id.
    const { id } = context.params;
    const dinosaur = await prisma.dinosaur.delete({
      where: {
        id: Number(id),
      },
    });
    context.response.body = dinosaur;
  });

/**
 * Setup middleware.
 */

app.use(router.routes());
app.use(router.allowedMethods());

/**
 * Start server.
 */

await app.listen({ port: 8000 });
```

Now, let's run it:

```shell, ignore
deno run -A main.ts
```

Let's visit `localhost:8000/dinosaurs`:

<!-- ![List of all dinosaurs from REST API](../../images/how-to/prisma/2-dinosaurs-from-api.png) -->
![List of all dinosaurs from REST API](https://docs.deno.com/assets/images/2-dinosaurs-from-api-0d0ab9ee1a88f4be4739dbeb4876afbf.png)

Next, let's `POST` a new user with this `curl` command:

```shell, ignore
curl -X POST http://localhost:8000/dinosaur -H "Content-Type: application/json" -d '{"name": "Deno", "description":"The fastest, most secure, easiest to use Dinosaur ever to walk the Earth."}'
```

And in your Prisma dashboard, you should see a new row:

<!-- ![New dinosaur Deno in Prisma](../../images/how-to/prisma/3-new-dinosaur-in-prisma.png) -->
![New dinosaur Deno in Prisma](https://docs.deno.com/assets/images/3-new-dinosaur-in-prisma-fa50b01627f33bac17bcc79b551da043.png)

Nice!

## What's next?

Building your next app will be more productive and fun with Deno and Prisma,
since both technologies deliver an intuitive developer experience with data
modeling, type-safety, and robust IDE support.

If you're interested in connecting Prisma to Deno Deploy,
[check out this awesome guide](https://www.prisma.io/docs/guides/deployment/deployment-guides/deploying-to-deno-deploy).



/. 🚀 runtime/manual/node/how_to_with_npm/react.md
===================================================

    curl -s -L https://docs.deno.com/runtime/manual/node/how_to_with_npm/react | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to use React with Deno

[React](https://reactjs.org) is the most widely used JavaScript frontend
framework. It popularized a declarative approach towards designing user
interfaces, with a reactive data model. Due to its popularity, it's not
surprising that it's the most requested framework when it comes to building web
apps with Deno.

This is a tutorial that walks you through building a simple React app with Deno
in less than five minutes. The app will display a list of dinosaurs. When you
click on one, it'll take you to a dinosaur page with more details.

![demo of the app](https://docs.deno.com/assets/images/react-dinosaur-app-demo-57edc99edd80a5573d71fe81d9e4187c.gif)
<!-- ![demo of the app](../../images/how-to/react/react-dinosaur-app-demo.gif) -->

[View source](https://github.com/denoland/examples/tree/main/with-react) or
[follow the video guide](https://www.youtube.com/watch?v=eStwt_2THd8).

## Create Vite Extra

This tutorial will use [Vite](https://vitejs.dev/) to quickly scaffold a Deno
and React app. Let's run:

```shell, ignore
deno run --allow-env --allow-read --allow-write npm:create-vite-extra
```

We'll name our project "dinosaur-react-app". Then, `cd` into the newly created
project folder.

## Add a backend

The next step is to add a backend API. We'll create a very simple API that
returns information about dinosaurs.

In the directory, let's create an `api` folder. In that folder, we'll create a
`main.ts` file, which will run the server, and a `data.json`, which is the hard
coded data.

```shell, ignore
mkdir api && touch api/data.json && touch api/main.ts
```

Copy and paste
[this json file](https://github.com/denoland/deno-vue-example/blob/main/api/data.json)
into your `api/data.json`.

Then, let's update `api/main.ts`:

```ts, ignore
import { Application, Router } from "https://deno.land/x/oak@v11.1.0/mod.ts";
import { oakCors } from "https://deno.land/x/cors@v1.2.2/mod.ts";
import data from "./data.json" assert { type: "json" };

const router = new Router();
router
  .get("/", (context) => {
    context.response.body = "Welcome to dinosaur API!";
  })
  .get("/api", (context) => {
    context.response.body = data;
  })
  .get("/api/:dinosaur", (context) => {
    if (context?.params?.dinosaur) {
      const found = data.find((item) =>
        item.name.toLowerCase() === context.params.dinosaur.toLowerCase()
      );
      if (found) {
        context.response.body = found;
      } else {
        context.response.body = "No dinosaurs found.";
      }
    }
  });

const app = new Application();
app.use(oakCors()); // Enable CORS for All Routes
app.use(router.routes());
app.use(router.allowedMethods());

await app.listen({ port: 8000 });
```

This is a very simple API server using [`oak`](https://deno.land/x/oak) that
will return dinosaur information based on the route. Let's start the API server:

```shell, ignore
deno run --allow-env --allow-net api/main.ts
```

If we go to `localhost:8000`, we see:

![json response of dinosaurs](https://docs.deno.com/assets/images/dinosaur-api-55fa3c52ba37583dba5b513aa6d3e6b8.png)
<!-- ![json response of dinosaurs](../../images/how-to/react/dinosaur-api.png) -->

Lookin' good so far.

## Add a router

Our app will have two routes: `/` and `/:dinosaur`.

We'll use [`react-router-dom`](https://reactrouter.com/en/main) for our routing
logic. Let's add that to our dependencies in `vite.config.mjs`:

```mjs, ignore
import { defineConfig } from "npm:vite@^3.1.3";
import react from "npm:@vitejs/plugin-react@^2.1";

import "npm:react@^18.2";
import "npm:react-dom@^18.2/client";
import "npm:react-router-dom@^6.4"; // Add this line

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [react()],
});
```

Once we add the dependencies there, we can import them without `npm:` specifier
throughout our React app.

Next, let's go to `src/App.jsx` and add our routing logic:

```jsx, ignore
import React from "react";
import {
  BrowserRouter as Router,
  Navigate,
  Route,
  Routes,
} from "react-router-dom";
import Index from "./pages/Index.jsx";
import Dinosaur from "./pages/Dinosaur.jsx";

export default function App(props) {
  return (
    <Router>
      <Routes>
        <Route exact path="/" element={<Index />} />
        <Route exact path="/:dinosaur" element={<Dinosaur />} />
        <Route path="*" element={<Navigate to="/" />} />
      </Routes>
    </Router>
  );
}
```

Next, let's add the `<Index>` and `<Dinosaur>` pages.

## Add pages

There will be two pages in this app:

- `src/pages/Index.jsx`: our index page, which lists all of the dinosaurs
- `src/pages/Dinosaur.jsx`: our dinosaur page, which shows details of the
  dinosaur

We'll create a `src/pages` folder and create the `.jsx` files:

```shell, ignore
mkdir src/pages && touch src/pages/Index.jsx src/pages/Dinosaur.jsx
```

Let's start with `<Index>`. This page will `fetch` at `localhost:8000/api` and
render that through JSX.

```jsx, ignore
import React, { useEffect, useState } from "react";
import { Link, useParams } from "react-router-dom";

const Index = () => {
  const [dinos, setDinos] = useState([]);
  useEffect(() => {
    fetch(`http://localhost:8000/api/`)
      .then(async (res) => await res.json())
      .then((json) => setDinos(json));
  }, []);

  return (
    <div>
      <h1>Welcome to the Dinosaur app</h1>
      <p>
        Click on a dinosaur below to learn more.
      </p>
      <div>
        {dinos.map((dino) => {
          return (
            <div>
              <Link to={`/${dino.name.toLowerCase()}`}>{dino.name}</Link>
            </div>
          );
        })}
      </div>
    </div>
  );
};

export default Index;
```

Next, in `<Dinosaur>`, we'll do the same except for
`localhost:8000/api/${dinosaur}`:

```jsx, ignore
import React, { useEffect, useState } from "react";
import { Link, useParams } from "react-router-dom";

const Dinosaur = () => {
  const { dinosaur } = useParams();
  const [dino, setDino] = useState({});
  useEffect(() => {
    fetch(`http://localhost:8000/api/${dinosaur}`)
      .then(async (res) => await res.json())
      .then((json) => setDino(json));
  }, []);

  return (
    <div>
      <h1>{dino.name}</h1>
      <p>
        {dino.description}
      </p>
      <Link to="/">See all</Link>
    </div>
  );
};

export default Dinosaur;
```

Let's start the React app:

```
deno task start
```

And click through the app:

![demo of the app](https://docs.deno.com/assets/images/react-dinosaur-app-demo-57edc99edd80a5573d71fe81d9e4187c.gif)
<!-- ![demo of the app](../../images/how-to/react/react-dinosaur-app-demo.gif) -->

Huzzah!



/. 🚀 runtime/manual/node/how_to_with_npm/redis.md
===================================================

    curl -s -L https://docs.deno.com/runtime/manual/node/how_to_with_npm/redis | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to Use Redis with Deno

[Redis](https://redis.io/) is an in-memory data store you can use for caching,
as a message broker, or for streaming data.

[View source here.](https://github.com/denoland/examples/tree/main/with-redis)

Here we're going to set up Redis to cache data from an API call to speed up any
subsequent requests for that data. We're going to:

- Set up a Redis client to save data from every API call in memory
- Set up a Deno server so we can easily request certain data
- Call the Github API within the server handler to get the data on first request
- Serve data from Redis on every subsequent request

We can do this within a single file, `main.ts`.

## Connecting to a Redis client

We need two modules. The first is the Deno server. We'll use this to get the
information from the user to query our API. The second is Redis. We can grab the
node package for Redis using the `npm:` modifier:

```tsx, ignore
import { Server } from "https://deno.land/std@$STD_VERSION/http/server.ts";
import { createClient } from "npm:redis@^4.5";
```

We create a Redis client using `createClient` and connect to our local Redis
server:

```tsx, ignore
// make a connection to the local instance of redis
const client = createClient({
  url: "redis://localhost:6379",
});

await client.connect();
```

You can also set host, user, password, and port individually in this
[configuration](https://github.com/redis/node-redis/blob/master/docs/client-configuration.md)
object.

## Setting up the server

Our server is going to act as a wrapper around the Github API. A client can call
our server with a Github username in the URL pathname, such as
`http://localhost:3000/{username}`.

Parsing out the pathname and calling the Github API will take place inside a
handler function in our server. We strip the leading slash so we are left with a
variable we can pass to the Github API as a username. We'll then pass the
response back to the user.

```tsx, ignore
const server = new Server({
  handler: async (req) => {
    const { pathname } = new URL(req.url);
    // strip the leading slash
    const username = pathname.substring(1);
    const resp = await fetch(`https://api.github.com/users/${username}`);
    const user = await resp.json();
    return new Response(JSON.stringify(user), {
        headers: {
          "content-type": "application/json",
        },
      });
    }
  },

  port: 3000,
});

server.listenAndServe();
```

We'll run this with:

```tsx, ignore
deno run --allow-net main.ts
```

If we then go to [http://localhost:3000/ry](http://localhost:3000/ry) in
Postman, we'll get the Github response:

![uncached-redis-body.png](https://docs.deno.com/assets/images/uncached-redis-body-2c0927c35c634d44b937de9626abf533.png)
<!-- ![uncached-redis-body.png](../../images/how-to/redis/uncached-redis-body.png) -->

Let's cache this response using Redis.

## Checking the cache

Once we have our response from the Github API, we can cache this within Redis
using `client.set`, with our username as the key and the user object as the
value:

```tsx, ignore
await client.set(username, JSON.stringify(user));
```

Next time we request the same username, we can use `client.get` to get the
cached user:

```tsx, ignore
const cached_user = await client.get(username);
```

This returns null if the key doesn't exist. So we can use it in some flow
control. When we get the username, we'll initially check whether we already have
that user in the cache. If we do we'll serve the cached result. If not, we'll
call the Github API to get the user, cache it, the serve the API result. In both
cases, we'll add a custom header to show which version we're serving:

```tsx, ignore
const server = new Server({
  handler: async (req) => {
    const { pathname } = new URL(req.url);
    // strip the leading slash
    const username = pathname.substring(1);
    const cached_user = await client.get(username);
    if (cached_user) {
      return new Response(cached_user, {
        headers: {
          "content-type": "application/json",
          "is-cached": "true",
        },
      });
    } else {
      const resp = await fetch(`https://api.github.com/users/${username}`);
      const user = await resp.json();
      await client.set(username, JSON.stringify(user));
      return new Response(JSON.stringify(user), {
        headers: {
          "content-type": "application/json",
          "is-cached": "false",
        },
      });
    }
  },

  port: 3000,
});

server.listenAndServe();
```

Running this first time gives us the same response as above, and we'll see the
`is-cached` header set to `false`:

![uncached-redis-header.png](https://docs.deno.com/assets/images/uncached-redis-header-282d783adf41bd48a9ebb94aaeaf073b.png)
<!-- ![uncached-redis-header.png](../../images/how-to/redis/uncached-redis-header.png) -->

But call with the same username again, and we get the cached result. The body is
identical:

![cached-redis-body.png](https://docs.deno.com/assets/images/cached-redis-body-28873d1de299497a3b2ebc7112458e8e.png)
<!-- ![cached-redis-body.png](../../images/how-to/redis/cached-redis-body.png) -->

But the header shows we have the cache:

![cached-redis-header.png](https://docs.deno.com/assets/images/cached-redis-header-c1e1f82d4797dbed7b0df541107be40e.png)
<!-- ![cached-redis-header.png](../../images/how-to/redis/cached-redis-header.png) -->

We can also see that the response was ~200ms quicker!

You can check out the Redis documentation [here](https://redis.io/docs/) and the
Redis node package [here](https://github.com/redis/node-redis).



/. 🚀 runtime/manual/node/how_to_with_npm/vue.md
===================================================

    curl -s -L https://docs.deno.com/runtime/manual/node/how_to_with_npm/vue | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to use Vue with Deno

[Vue](https://vuejs.org/) is a progressive front-end JavaScript framework, built
for performance and versatility.

This How To guide will show you how to create a simple app using Deno, Vite, and
Vue.

[View source](https://github.com/denoland/examples/tree/main/with-vue) or
[follow the video guide](https://www.youtube.com/watch?v=MDPauM8fZDE).

## Run `npm:create-vite-extra`

We'll use Vite to scaffold our Vue app. First, run:

```shell, ignore
deno run --allow-read --allow-write --allow-env npm:create-vite-extra@latest
```

Name your project, then select "deno-vue".

Then, `cd` into your new project and run:

```shell, ignore
deno task dev
```

You should now be able to view your default Deno and Vue app in your browser:

![default vue app](https://docs.deno.com/assets/images/default-vue-app-8a0ffbc131c2cba6f591435fee912689.png)
<!-- ![default vue app](../../images/how-to/vue/default-vue-app.png) -->

## Add a backend

The next step is to add a backend API. We'll create a very simple API that
returns information about dinosaurs.

In the directory, let's create an `api` folder. In that folder, we'll create a
`main.ts` file, which will run the server, and a `data.json`, which is the hard
coded data.

```shell, ignore
mkdir api && touch api/data.json && touch api/main.ts
```

Copy and paste
[this json file](https://github.com/denoland/deno-vue-example/blob/main/api/data.json)
into your `api/data.json`.

Then, let's update `api/main.ts`:

```ts, ignore
import { Application, Router } from "https://deno.land/x/oak/mod.ts";
import { oakCors } from "https://deno.land/x/cors/mod.ts";
import data from "./data.json" assert { type: "json" };

const router = new Router();
router
  .get("/", (context) => {
    context.response.body = "Welcome to dinosaur API!";
  })
  .get("/api", (context) => {
    context.response.body = data;
  })
  .get("/api/:dinosaur", (context) => {
    if (context?.params?.dinosaur) {
      const found = data.find(item => item.name.toLowerCase() === context.params.dinosaur.toLowerCase());
      if (found) {
        context.response.body = found;
        } else {
        context.response.body = "No dinosaurs found.";
      }
    }
  });

const app = new Application();
app.use(oakCors()); // Enable CORS for All Routes
app.use(router.routes());
app.use(router.allowedMethods());

await app.listen({ port: 8000 });
```

This is a very simple API server using [`oak`](https://deno.land/x/oak) that
will return dinosaur information based on the route. Let's start the API server:

```shell, ignore
deno run --allow-env --allow-net api/main.ts
```

If we go to `localhost:8000/api`, we see:

![json response of dinosaurs](https://docs.deno.com/assets/images/api-response-25c9245e09d56ade97ec4ee03def8d17.png)
<!-- ![json response of dinosaurs](../../images/how-to/vue/api-response.png) -->

Lookin' good so far.

## Add Vue components

Let's update `src/components`. We'll add the files:

- `HomePage.vue`, the component for the home page
- `Dinosaurs.vue`, the component that lists all dinosaur names as anchor links,
  and
- `Dinosaur.vue`, the component that shows an individual dinosaur's name and
  description

```shell, ignore
touch src/components/HomePage.vue src/components/Dinosaurs.vue src/components/Dinosaur.vue
```

Before we create the components, let's add some state management.

## Maintain state with `store`

In order to maintain state across our `<Dinosaur>` and `<Dinosaurs>` components,
we'll use
[Vue store](https://vuejs.org/manual/scaling-up/state-management.html). Note for
more complex state management, check out the Vue-endorsed
[Pinia](https://pinia.vuejs.org/) library.

Create a `src/store.js` file:

```shell, ignore
touch src/store.js
```

And in it, let's add:

```js, ignore
import { reactive } from "vue";

export const store = reactive({
  dinosaur: {},
  setDinosaur(name, description) {
    this.dinosaur.name = name;
    this.dinosaur.description = description;
  },
});
```

We'll import `store` into both `Dinosaurs.vue` and `Dinosaur.vue` to set and
retrieve dinosaur name and description.

## Update Vue components

In `Dinosaurs.vue`, we'll do three things:

- send a `GET` request to our API and return that as `dinosaurs`
- iterate through `dinosaurs` and render each `dinosaur` in `<router-link>` that
  points to the `<Dinosaur>` component
- add `store.setDinosaur()` to `@click` on each `dinosaur`, which will set the
  `store`

Here is the complete code below:

```tsx, ignore
<script>
import { ref } from 'vue'
import { store } from '../store.js'
export default ({
  async setup() {
    const res = await fetch("http://localhost:8000/api")
    const dinosaurs = await res.json();
    return {
      dinosaurs
    }
  },
  data() {
    return {
      store
    }
  }
})
</script>

<template>
  <div class="container">
    <div v-for="dinosaur in dinosaurs" class="dinosaur-wrapper">
      <span class="dinosaur">
        <router-link :to="{ name: 'Dinosaur', params: { dinosaur: `${dinosaur.name.toLowerCase()}` }}">
          <span @click="store.setDinosaur(dinosaur.name, dinosaur.description)">
            {{dinosaur.name}}
          </span>
        </router-link>
      </span>
    </div>
  </div>
</template>

<style scoped>
.dinosaur {
}
.dinosaur-wrapper {
  display: inline-block;
  margin: 0.15rem 1rem;
  padding: 0.15rem 1rem;
}
.container {
  text-align: left;
}
</style>
```

In `Dinosaur.vue`, we'll add:

- importing `store`
- rendering `store.dinosaur` in the HTML

```tsx, ignore
<script>
import { store } from '../store.js';
export default {
  data() {
    return {
      store
    }
  }
}
</script>

<template>
  Name: {{ store.dinosaur.name }}
  <br />
  Description: {{ store.dinosaur.description }}
</template>
```

Next, we'll update `HomePage.vue`. Since the `Dinosaurs` component needs to
fetch the data from the API, we'll use
[`<Suspense>`](https://vuejs.org/manual/built-ins/suspense.html), which manages
async dependencies in a component tree.

```tsx, ignore
<script>
import { ref } from 'vue'
import Dinosaurs from './Dinosaurs.vue'
export default {
  components: {
    Dinosaurs
  }
}
</script>

<template>
  <Suspense>
    <template #default>
      <Dinosaurs />
    </template>
    <template #fallback>
      <div>Loading...</div>
    </template>
  </Suspense>

  <p>
    Check out
    <a href="https://vuejs.org/manual/quick-start.html#local" target="_blank"
      >create-vue</a
    >, the official Vue + Vite starter
  </p>
  <p class="read-the-docs">Learn more about using Deno and Vite.</p>
</template>

<style scoped>
.read-the-docs {
  color: #888;
}
</style>
```

Tying it all together, let's update `src/App.vue`:

```tsx, ignore
<template>
  <router-view/>
</template>
```

## Add routing

You'll notice that we have used `<router-link>` and `<router-view>`. These
components are part of the [`vue-router` library](https://router.vuejs.org/),
which we'll have to setup and configure in another file.

First, let's import `vue-router` in our `vite.config.mjs` file:

```ts, ignore
import { defineConfig } from "npm:vite@^3.1.3";
import vue from "npm:@vitejs/plugin-vue@^3.2.39";

import "npm:vue@^3.2.39";
import "npm:vue-router@4";

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [vue()],
});
```

Next, let's create a folder named `router`. In it, let's create `index.ts`:

```
mkdir router && touch router/index.ts
```

In `router/index.ts`, we'll create `router`, which contains information about
each route and their component, and export it. For more information on using
`vue-router`, check out their [guide](https://router.vuejs.org/guide).

```ts, ignore
import { createRouter, createWebHistory } from "vue-router";
import HomePage from "../components/HomePage.vue";
import Dinosaur from "../components/Dinosaur.vue";

const routes = [
  {
    path: "/",
    name: "Home",
    component: HomePage,
  },
  {
    path: "/:dinosaur",
    name: "Dinosaur",
    component: Dinosaur,
    props: true,
  },
];

const router = createRouter({
  history: createWebHistory("/"),
  routes,
});

export default router;
```

Next, in our `src/main.ts` file, which contains all of the logic for the
frontend app, we'll have to import and use `router`:

```ts, ignore
import { createApp } from "vue";
import "./style.css";
import App from "./App.vue";
import router from "./router/index.ts";

const app = createApp(App);
app.use(router);
app.mount("#app");
```

Let's run it and see what we get so far:

![Clicking on a dinosaur to get to an individual dinosaur page](https://docs.deno.com/assets/images/vue-demo-f7efdc8c961fd0a77f2d1ebf36558380.gif)
<!-- ![Clicking on a dinosaur to get to an individual dinosaur page](../../images/how-to/vue/vue-demo.gif) -->

Awesome!



/. 🚀 runtime/manual/node/node_specifiers.md
===================================================

# `node:` specifiers

Deno supports using Node.js built-in modules such as
[fs](https://nodejs.org/api/fs.html#file-system),
[path](https://nodejs.org/api/path.html#path),
[process](https://nodejs.org/api/process.html#process), and many more via
`node:` specifiers.

```ts
import { readFileSync } from "node:fs";

console.log(readFileSync("deno.json", { encoding: "utf8" }));
```

Take note that importing via a bare specifier (ex.
`import { readFileSync } from "fs";`) is not supported. If you attempt to do so
and the bare specifier matches a Node.js built-in module not found in an import
map, Deno will provide a helpful error message asking if you meant to import
with the `node:` prefix. Additionally the LSP provides a quick fix to update to
a `node:` specifier.

If you are using code both with Deno and Node.js, the `node:` scheme will work
in both runtimes and it's recommended to update to them for your Node.js code.



/. 🚀 runtime/manual/node/package_json.md
===================================================

# package.json compatibility

Deno supports resolving dependencies based on a `package.json` file in the
current or ancestor directories. This is similar to how Node.js resolves
dependencies. We recommend using import maps with `deno.json` which is explained
[here](../basics/import_maps.md).

```json title="package.json"
{
  "name": "@deno/my-example-project",
  "description": "An example app created with Deno",
  "type": "module",
  "scripts": {
    "dev": "deno run --allow-env --allow-sys main.ts"
  },
  "dependencies": {
    "chalk": "^5.2"
  }
}
```

```ts title="main.ts"
import chalk from "chalk";

console.log(chalk.green("Hello from Deno!"));
```

Then we can run this script:

```shell
> deno run --allow-env --allow-sys main.ts
Hello from Deno!
```

Or also execute package.json scripts via `deno task`:

```shell
> deno task dev
Hello from Deno!
```



/. 🚀 runtime/manual/node/cdns.md
===================================================

# npm via CDNs

Most developers currently use npm modules in Deno by importing them using one of
many CDNs. You can reference the CDN URL in your Deno code or directly in your
browser as an ES Module. These CDN URLs are reusable - they also provide
instructions on how to be used in Deno, the browser, etc.

**Starting with Deno release 1.28**, Deno also offers stabilized support for
[`npm:` specifiers](./npm_specifiers.md), which are a new way of using npm
modules in Deno.

**Starting with Deno release 1.31**, Deno supports resolving npm dependencies
[from package.json](./package_json.md) if it exists.

### esm.sh

[esm.sh](https://esm.sh/) is a CDN that was specifically designed for Deno,
though addressing the concerns for Deno also makes it a general purpose CDN for
accessing npm packages as ES Module bundles. esm.sh uses
[esbuild](https://esbuild.github.io/) to take an arbitrary npm package and
ensure that it is consumable as an ES Module. In many cases you can just import
the npm package into your Deno application:

```tsx
import React from "https://esm.sh/react";

export default class A extends React.Component {
  render() {
    return <div></div>;
  }
}
```

esm.sh supports the use of both specific versions of packages, as well as
[semver](https://semver.npmjs.com/) versions of packages, so you can express
your dependency in a similar way you would in a `package.json` file when you
import it. For example, to get a specific version of a package:

```tsx
import React from "https://esm.sh/react@17.0.2";
```

Or to get the latest patch release of a minor release:

```tsx
import React from "https://esm.sh/react@~16.13.0";
```

Or to get a submodule:

```tsx
import { renderToString } from "https://esm.sh/react-dom/server";
```

Or to import regular files:

```tsx, ignore
import "https://esm.sh/tailwindcss/dist/tailwind.min.css";
```

esm.sh also automatically sets a header which Deno recognizes that allows Deno
to be able to retrieve type definitions for the package/module. See
[Using `X-TypeScript-Types` header](../advanced/typescript/types.md). in this
manual for more details on how this works.

esm.sh also provides information on
[self hosting the CDN](https://github.com/ije/esm.sh/blob/main/HOSTING.md).

Check out the [esm.sh homepage](https://esm.sh/) for more detailed information
on how the CDN can be used and what features it has.

### UNPKG

[UNPKG](https://unpkg.com/) is the most well known CDN for npm packages. For
packages that include an ES Module distribution for things like the browsers,
many of them can be used directly off of UNPKG. That being said, everything
available on UNPKG is available on more Deno friendly CDNs.

### JSPM

The [jspm.io](https://jspm.io) CDN is specifically designed to provide npm and
other registry packages as ES Modules in a way that works well with import maps.
While it doesn't currently cater to Deno, the fact that Deno can utilize import
maps, allows you to use the [JSPM.io generator](https://generator.jspm.io/) to
generate an import-map of all the packages you want to use and have them served
up from the CDN.



/. 🚀 runtime/manual/node/compatibility.mdx
===================================================

# Node API Compatibility List

Deno provides polyfills for a number of built-in Node.js modules and globals.
Node compatibility is an ongoing project - help us identify gaps and let us know
which modules you need by
[opening an issue on GitHub](https://github.com/denoland/deno).

## Built-in module support

<div style={{
  display: "flex",
  flexDirection: "row",
  gap: "10px",
  flexWrap: "wrap",
  marginBottom: "10px"
}}>
  <div>✅ = Full support</div>
  <div>ℹ️ = Partial support</div>
  <div>❌ = Stubs only</div>
</div>

<details>
  <summary>
    <code>node:assert</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/assert.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:async_hooks</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    <code>AsyncLocalStorage</code> is supported. <code>AsyncResource</code>,{" "}
    <code>executionAsyncId</code>, and <code>createHook</code> are
    non-functional stubs.
  </p>
  <p>
    <a href="https://nodejs.org/api/async_hooks.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:buffer</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/buffer.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:child_process</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    The <code>ipc</code> and <code>overlapped</code> stdio options are missing.
    Passing file descriptors by an integer value is missing.
  </p>
  <p>
    <a href="https://nodejs.org/api/child_process.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:cluster</code>
    <div style={{ float: "right" }}>
      <span>❌</span>
    </div>
  </summary>
  <p>All exports are non-functional stubs.</p>
  <p>
    <a href="https://nodejs.org/api/cluster.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:console</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/console.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:crypto</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>Certificate</code> class,{" "}
    <code>crypto.Cipheriv.prototype.setAutoPadding</code>,{" "}
    <code>crypto.Decipheriv.prototype.setAutoPadding</code>,{" "}
    <code>crypto.getCipherInfo</code>, <code>crypto.publicDecrypt</code>,{" "}
    <code>crypto.ECDH.prototype.convertKey</code>,{" "}
    <code>crypto.diffieHellman</code>, <code>x448</code> option for{" "}
    <code>generateKeyPair</code>, <code>crypto.KeyObject</code>,{" "}
    <code>safe</code>, <code>add</code> and <code>rem</code> options for{" "}
    <code>generatePrime</code>, <code>crypto.Sign.prototype.sign</code> and{" "}
    <code>crypto.Verify.prototype.verify</code> with non <code>BinaryLike</code>{" "}
    input, <code>crypto.secureHeapUsed</code>, <code>crypto.setEngine</code>,
    legacy methods of <code>crypto.X509Certificate</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/crypto.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:dgram</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Some <code>dgram.Socket</code> instance methods are non-functional stubs:
    <ul>
        <li><code>addMembership</code></li>
        <li><code>addSourceSpecificMembership</code></li>
        <li><code>dropMembership</code></li>
        <li><code>dropSourceSpecificMembership</code></li>
        <li><code>setBroadcast</code></li>
        <li><code>setMulticastInterface</code></li>
        <li><code>setMulticastLoopback</code></li>
        <li><code>setMulticastTtl</code></li>
        <li><code>setTtl</code></li>
        <li><code>ref</code></li>
        <li><code>unref</code></li>
    </ul>
  </p>
  <p>
    <a href="https://nodejs.org/api/dgram.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:diagnostics_channel</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/diagnostics_channel.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:dns</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>dns.resolve*</code> with <code>ttl</code> option.
  </p>
  <p>
    <a href="https://nodejs.org/api/dns.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:domain</code>
    <div style={{ float: "right" }}>
      <span>❌</span>
    </div>
  </summary>
  <p>All exports are non-functional stubs.</p>
  <p>
    <a href="https://nodejs.org/api/domain.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:events</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/events.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:fs</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <h5>
    <code>node:fs</code>
  </h5>
  <p>
    Missing <code>utf16le</code>, <code>latin1</code> and <code>ucs2</code>{" "}
    encoding for <code>fs.writeFile</code> and <code>fs.writeFileSync</code>.
    Missing <code>Dirent.isBlockDevice</code>,{" "}
    <code>Dirent.isCharacterDevice</code>, <code>Dirent.isFIFO</code>,{" "}
    <code>Dirent.isSocket</code>, <code>FSWatcher.ref</code>,{" "}
    <code>FSWatcher.unref</code>.
  </p>
  <h5>
    <code>node:fs/promises</code>
  </h5>
  <p>
    Missing <code>lchmod</code>, <code>lchown</code>, <code>lutimes</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/fs.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:http</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    <code>createConnection</code> option is currently not supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/http.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:http2</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Partially supported, major work in progress to enable <code>grpc-js</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/http2.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:https</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>https.Server.opts.cert</code> and{" "}
    <code>https.Server.opts.key</code> array type.
  </p>
  <p>
    <a href="https://nodejs.org/api/https.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:inspector</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    <code>console</code> is supported. Other APIs are stubs and will throw an
    error. Due to security implications the Deno team does not plan to polyfill
    these APIs.
  </p>
  <p>
    <a href="https://nodejs.org/api/inspector.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:module</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/module.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:net</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>net.Socket.prototype.constructor</code> with <code>fd</code>{" "}
    option.
  </p>
  <p>
    <a href="https://nodejs.org/api/net.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:os</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/os.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:path</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/path.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:perf_hooks</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>perf_hooks.eventLoopUtilization</code>,{" "}
    <code>perf_hooks.timerify</code>,{" "}
    <code>perf_hooks.monitorEventLoopDelay</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/perf_hooks.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:punycode</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/punycode.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:process</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>disconnect</code>, <code>message</code>,{" "}
    <code>multipleResolves</code>, <code>rejectionHandled</code> and{" "}
    <code>worker</code> events.
  </p>
  <p>
    <a href="https://nodejs.org/api/process.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:querystring</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/querystring.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:readline</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/readline.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:repl</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    <code>builtinModules</code> and <code>_builtinLibs</code> are supported.
    Missing <code>REPLServer.prototype.constructor</code> and{" "}
    <code>start()</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/repl.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:stream</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/stream.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:string_decoder</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing decoding of <code>ascii</code>, <code>latin1</code> and{" "}
    <code>utf16le</code> decoding options.
  </p>
  <p>
    <a href="https://nodejs.org/api/string_decoder.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:sys</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/util.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:test</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Currently only <code>test</code> API is supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/test.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:timers</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/timers.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:tls</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>createSecurePair</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/tls.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:trace_events</code>
    <div style={{ float: "right" }}>
      <span>❌</span>
    </div>
  </summary>
  <p>All exports are non-functional stubs.</p>
  <p>
    <a href="https://nodejs.org/api/tracing.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:tty</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>ReadStream</code> and <code>WriteStream</code> implementation.
  </p>
  <p>
    <a href="https://nodejs.org/api/tty.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:util</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/util.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:url</code>
    <div style={{ float: "right" }}>
      <span>✅</span>
    </div>
  </summary>
  <p>
    Fully supported.
  </p>
  <p>
    <a href="https://nodejs.org/api/url.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:v8</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    <code>cachedDataVersionTag</code> and <code>getHeapStatistics</code> are
    supported. <code>setFlagsFromStrings</code> is a noop. Other APIs are not
    supported and will throw and error. The other APIs <em>could</em> be
    polyfilled, but due inherent lack of format stability between the V8
    versions, the Deno team is considering requiring a special flag to use them.
  </p>
  <p>
    <a href="https://nodejs.org/api/v8.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:vm</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    <code>runInThisContext</code> is supported. Other APIs are not polyfilled
    and will throw and error.
  </p>
  <p>
    <a href="https://nodejs.org/api/vm.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:wasi</code>
    <div style={{ float: "right" }}>
      <span>❌</span>
    </div>
  </summary>
  <p>All exports are non-functional stubs.</p>
  <p>
    <a href="https://nodejs.org/api/wasi.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:worker_threads</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>parentPort.emit</code>,{" "}
    <code>parentPort.removeAllListeners</code>,{" "}
    <code>markAsUntransferable</code>, <code>moveMessagePortToContext</code>,{" "}
    <code>receiveMessageOnPort</code>,{" "}
    <code>Worker.prototype.getHeapSnapshot</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/worker_threads.html">Node.js docs</a>
  </p>
</details>

<details>
  <summary>
    <code>node:zlib</code>
    <div style={{ float: "right" }}>
      <span>ℹ️</span>
    </div>
  </summary>
  <p>
    Missing <code>Options.prototype.constructor</code>,{" "}
    <code>BrotliOptions.prototype.constructor</code>,{" "}
    <code>BrotliDecompress.prototype.constructor</code>,{" "}
    <code>ZlibBase.prototype.constructor</code>.
  </p>
  <p>
    <a href="https://nodejs.org/api/zlib.html">Node.js docs</a>
  </p>
</details>

## Globals

This is the list of Node globals that Deno supports. These globals are only
available in the `npm` package scope. In your own code you can use them by
importing them from the relevant `node:` module.

| Global name                                                                                                      | Status |
| ---------------------------------------------------------------------------------------------------------------- | ------ |
| [`AbortController`](https://nodejs.org/api/globals.html#class-abortcontroller)                                   | ✅     |
| [`AbortSignal`](https://nodejs.org/api/globals.html#class-abortsignal)                                           | ✅     |
| [`Blob`](https://nodejs.org/api/globals.html#class-blob)                                                         | ✅     |
| [`Buffer`](https://nodejs.org/api/globals.html#class-buffer)                                                     | ✅     |
| [`ByteLengthQueuingStrategy`](https://nodejs.org/api/globals.html#class-bytelengthqueuingstrategy)               | ✅     |
| [`__dirname`](https://nodejs.org/api/globals.html#__dirname)                                                     | ✅     |
| [`__filename`](https://nodejs.org/api/globals.html#__filename)                                                   | ✅     |
| [`atob`](https://nodejs.org/api/globals.html#atobdata)                                                           | ✅     |
| [`BroadcastChannel`](https://nodejs.org/api/globals.html#broadcastchannel)                                       | ✅     |
| [`btoa`](https://nodejs.org/api/globals.html#btoadata)                                                           | ✅     |
| [`clearImmediate`](https://nodejs.org/api/globals.html#clearimmediateimmediateobject)                            | ✅     |
| [`clearInterval`](https://nodejs.org/api/globals.html#clearintervalintervalobject)                               | ✅     |
| [`clearTimeout`](https://nodejs.org/api/globals.html#cleartimeouttimeoutobject)                                  | ✅     |
| [`CompressionStream`](https://nodejs.org/api/globals.html#class-compressionstream)                               | ✅     |
| [`console`](https://nodejs.org/api/globals.html#console)                                                         | ✅     |
| [`CountQueuingStrategy`](https://nodejs.org/api/globals.html#class-countqueuingstrategy)                         | ✅     |
| [`Crypto`](https://nodejs.org/api/globals.html#crypto)                                                           | ✅     |
| [`CryptoKey`](https://nodejs.org/api/globals.html#cryptokey)                                                     | ✅     |
| [`CustomEvent`](https://nodejs.org/api/globals.html#customevent)                                                 | ✅     |
| [`CustomEvent`](https://nodejs.org/api/globals.html#customevent)                                                 | ✅     |
| [`DecompressionStream`](https://nodejs.org/api/globals.html#class-decompressionstream)                           | ✅     |
| [`Event`](https://nodejs.org/api/globals.html#event)                                                             | ✅     |
| [`EventTarget`](https://nodejs.org/api/globals.html#eventtarget)                                                 | ✅     |
| [`exports`](https://nodejs.org/api/globals.html#exports)                                                         | ✅     |
| [`fetch`](https://nodejs.org/api/globals.html#fetch)                                                             | ✅     |
| [`fetch`](https://nodejs.org/api/globals.html#fetch)                                                             | ✅     |
| [`File`](https://nodejs.org/api/globals.html#class-file)                                                         | ✅     |
| [`File`](https://nodejs.org/api/globals.html#class-file)                                                         | ✅     |
| [`FormData`](https://nodejs.org/api/globals.html#class-formdata)                                                 | ✅     |
| [`global`](https://nodejs.org/api/globals.html#global)                                                           | ✅     |
| [`Headers`](https://nodejs.org/api/globals.html#class-headers)                                                   | ✅     |
| [`MessageChannel`](https://nodejs.org/api/globals.html#messagechannel)                                           | ✅     |
| [`MessageEvent`](https://nodejs.org/api/globals.html#messageevent)                                               | ✅     |
| [`MessagePort`](https://nodejs.org/api/globals.html#messageport)                                                 | ✅     |
| [`module`](https://nodejs.org/api/globals.html#module)                                                           | ✅     |
| [`PerformanceEntry`](https://nodejs.org/api/globals.html#performanceentry)                                       | ✅     |
| [`PerformanceMark`](https://nodejs.org/api/globals.html#performancemark)                                         | ✅     |
| [`PerformanceMeasure`](https://nodejs.org/api/globals.html#performancemeasure)                                   | ✅     |
| [`PerformanceObserver`](https://nodejs.org/api/globals.html#performanceobserver)                                 | ✅     |
| [`PerformanceObserverEntryList`](https://nodejs.org/api/globals.html#performanceobserverentrylist)               | ❌     |
| [`PerformanceResourceTiming`](https://nodejs.org/api/globals.html#performanceresourcetiming)                     | ❌     |
| [`performance`](https://nodejs.org/api/globals.html#performance)                                                 | ✅     |
| [`process`](https://nodejs.org/api/globals.html#process)                                                         | ✅     |
| [`queueMicrotask`](https://nodejs.org/api/globals.html#queuemicrotaskcallback)                                   | ✅     |
| [`ReadableByteStreamController`](https://nodejs.org/api/globals.html#class-readablebytestreamcontroller)         | ✅     |
| [`ReadableStream`](https://nodejs.org/api/globals.html#class-readablestream)                                     | ✅     |
| [`ReadableStreamBYOBReader`](https://nodejs.org/api/globals.html#class-readablestreambyobreader)                 | ✅     |
| [`ReadableStreamBYOBRequest`](https://nodejs.org/api/globals.html#class-readablestreambyobrequest)               | ✅     |
| [`ReadableStreamDefaultController`](https://nodejs.org/api/globals.html#class-readablestreamdefaultcontroller)   | ✅     |
| [`ReadableStreamDefaultReader`](https://nodejs.org/api/globals.html#class-readablestreamdefaultreader)           | ✅     |
| [`require`](https://nodejs.org/api/globals.html#require)                                                         | ✅     |
| [`Response`](https://nodejs.org/api/globals.html#response)                                                       | ✅     |
| [`Request`](https://nodejs.org/api/globals.html#request)                                                         | ✅     |
| [`setImmediate`](https://nodejs.org/api/globals.html#setimmediatecallback-args)                                  | ✅     |
| [`setInterval`](https://nodejs.org/api/globals.html#setintervalcallback-delay-args)                              | ✅     |
| [`setTimeout`](https://nodejs.org/api/globals.html#settimeoutcallback-delay-args)                                | ✅     |
| [`structuredClone`](https://nodejs.org/api/globals.html#structuredclonevalue-options)                            | ✅     |
| [`structuredClone`](https://nodejs.org/api/globals.html#structuredclonevalue-options)                            | ✅     |
| [`SubtleCrypto`](https://nodejs.org/api/globals.html#subtlecrypto)                                               | ✅     |
| [`DOMException`](https://nodejs.org/api/globals.html#domexception)                                               | ✅     |
| [`TextDecoder`](https://nodejs.org/api/globals.html#textdecoder)                                                 | ✅     |
| [`TextDecoderStream`](https://nodejs.org/api/globals.html#class-textdecoderstream)                               | ✅     |
| [`TextEncoder`](https://nodejs.org/api/globals.html#textencoder)                                                 | ✅     |
| [`TextEncoderStream`](https://nodejs.org/api/globals.html#class-textencoderstream)                               | ✅     |
| [`TransformStream`](https://nodejs.org/api/globals.html#class-transformstream)                                   | ✅     |
| [`TransformStreamDefaultController`](https://nodejs.org/api/globals.html#class-transformstreamdefaultcontroller) | ✅     |
| [`URL`](https://nodejs.org/api/globals.html#url)                                                                 | ✅     |
| [`URLSearchParams`](https://nodejs.org/api/globals.html#urlsearchparams)                                         | ✅     |
| [`URLSearchParams`](https://nodejs.org/api/globals.html#urlsearchparams)                                         | ✅     |
| [`WebAssembly`](https://nodejs.org/api/globals.html#webassembly)                                                 | ✅     |
| [`WritableStream`](https://nodejs.org/api/globals.html#class-writablestream)                                     | ✅     |
| [`WritableStreamDefaultController`](https://nodejs.org/api/globals.html#class-writablestreamdefaultcontroller)   | ✅     |
| [`WritableStreamDefaultWriter`](https://nodejs.org/api/globals.html#class-writablestreamdefaultwriter)           | ✅     |



/. 🚀 runtime/manual/node/faqs.md
===================================================

# Frequently Asked Questions

## Getting type errors like cannot find `document` or `HTMLElement`

The library you are using has dependencies on the DOM. This is common for
packages that are designed to run in a browser as well as server-side. By
default, Deno only includes the libraries that are directly supported. Assuming
the package properly identifies what environment it is running in at runtime it
is "safe" to use the DOM libraries to type check the code. For more information
on this, check out the
[Targeting Deno and the Browser](../advanced/typescript/configuration.md#targeting-deno-and-the-browser)
section of the manual.



/. 🚀 runtime/manual/node/migrate.md
===================================================

# Migrating from Node.js to Deno

To migrate an existing Node.js program to Deno, there are a number of
differences to take into account between the Node and Deno runtimes. This guide
will attempt to call out several of those differences, and describe how you can
begin to migrate your Node.js project to work on Deno.

:::info About Node.js Compatibility

Node.js compatibility is an ongoing project in Deno - you may encounter some
modules or packages on npm that do not work as you expect. If you do run into a
problem with Node.js compatibility, please let us know by
[opening an issue on GitHub](https://github.com/denoland/deno/issues).

:::

## Module imports and exports

Deno supports [ECMAScript modules](../basics/modules/index.md) exclusively,
rather than a combination of ESM and
[CommonJS](https://nodejs.org/api/modules.html), as found in Node. If your
Node.js code uses `require`, you should update it to use `import` statements
instead. If your internal code uses CommonJS-style exports, those will need to
be changed as well.

Consider the following two files in a Node.js program, located in the same
directory:

```js title="index.js"
const addNumbers = require("./add_numbers");
console.log(addNumbers(2, 2));
```

```js title="add_numbers.js"
module.exports = function addNumbers(num1, num2) {
  return num1 + num2;
};
```

Running `node index.js` with the files above works fine in Node.js 20 and
earlier. However, this code will not run unchanged if you attempt to use
`deno run index.js` instead. You will need to change both the code that is
consuming the module, and how you export functionality from the `add_numbers`
module.

### Replace `require` with `import`

Replace `require` statements with an `import`, like so:

```js
import addNumbers from "./add_numbers.js";
```

This statement uses the ES6 module standard, but does pretty much the same
thing. Also, note that we **include the full file extension when importing
modules**, much as you would in the browser. There is also no special handling
of files named `index.js`.

### Replace `module.exports` with `export default`

In the `add_numbers.js` file that exports the function, we would use a default
export from ES6 modules rather than the `module.exports` provided by CommonJS.

```js title="add_numbers.js"
export default function addNumbers(num1, num2) {
  return num1 + num2;
}
```

After making those two changes, this code would run successfully with
`deno run index.js`. Learn more about
[ES modules in Deno here](../basics/modules/index.md).

## Node.js built-ins

In Node.js 20 and earlier, built-in modules in the Node.js standard library
could be imported with "bare specifiers". Consider the Node program below with a
`.mjs` extension:

```js title="index.mjs"
import * as os from "os";
console.log(os.cpus());
```

The [`os` module](https://nodejs.org/api/os.html#oscpus) is built in to the
Node.js runtime, and can be imported using a bare specifier as above.

:::info .mjs extensions not required in Deno

The `.mjs` file extension is supported but not required in Deno. Because Node
doesn't support ESM by default, it requires you to name any files that use ESM
with a `.mjs` file extension.

:::

Deno provides a compatibility layer that allows the use of Node.js built-in APIs
within Deno programs. However, in order to use them, you will need to add the
[`node:` specifier](./node_specifiers.md) to any import statements that use
them.

For example - if you update the code above to be this instead:

```js
import * as os from "node:os";
console.log(os.cpus());
```

And run it with `deno run index.mjs` - you will notice you get the same output
as running the program in Node.js. Updating any imports in your application to
use `node:` specifiers should enable any code using Node built-ins to function
as it did in Node.js.

## Runtime permissions in Deno

Deno features [runtime security by default](../basics/permissions.md), meaning
that you as the developer must opt in to giving your code access to the
filesystem, network, system environment, and more. Doing this prevents supply
chain attacks and other potential vulnerabilities in your code. By comparison,
Node.js has no concept of runtime security, with all code executed with the same
level of permission as the user running the code.

### Running your code with only the necessary flags

When you run a Node.js project ported to Deno for the first time, the runtime
will likely prompt you for access to the permissions it needs to execute your
code. Consider the following simple [express](https://expressjs.com/) server:

```js
import express from "npm:express@4";

const app = express();

app.get("/", function (_req, res) {
  res.send("hello");
});

app.listen(3000, () => {
  console.log("Express listening on :3000");
});
```

If you run it with `deno run server.js`, it would prompt you for a number of
permissions required to execute the code and its dependencies. These prompts can
show you what runtime permission flags need to be passed in to grant the access
you need. Running the code above with the necessary permissions provided would
look like this:

```shell
deno run --allow-net --allow-read --allow-env server.js
```

### Reusing runtime flag configuration with `deno task`

A common pattern for configuring a set of runtime flags is to set up scripts to
be run with [`deno task`](../tools/task_runner.md). The following `deno.json`
file has a task called `dev` which will run the express server from above with
all the necessary flags.

```json
{
  "tasks": {
    "dev": "deno run --allow-net --allow-read --allow-env server.js"
  }
}
```

You can then run the task with `deno task dev`.

### Running with all permissions enabled

It is possible, but not recommended in production or sensitive environments, to
run your programs with all runtime permissions enabled. This would be the
default behavior of Node, which lacks a permission system. To run a program with
all permissions enabled, you can do so with:

```shell
deno run -A server.js
```

## Running scripts from `package.json`

Many Node.js projects make use of
[npm scripts](https://docs.npmjs.com/cli/v9/using-npm/scripts) to drive local
development. In Deno, you can continue to use your existing npm scripts while
migrating over time to [`deno task`](../tools/task_runner.md).

### Running npm scripts in Deno

One of the ways [Deno supports existing `package.json` files](./package_json.md)
is by executing any scripts configured there with `deno task`. Consider the
following Node.js project with a package.json and a script configured within it.

```js title="bin/my_task.mjs"
console.log("running my task...");
```

```json title="package.json"
{
  "name": "test",
  "scripts": {
    "start": "node bin/my_task.mjs"
  }
}
```

You can execute this script with Deno by running `deno task start`.

## Using and managing npm dependencies

Deno supports
[managing npm dependencies through a `package.json` file](./package_json.md).
Note that unlike using npm at the command line, you can simply run your project
with `deno run`, and the first time your script runs, Deno will cache all the
necessary dependencies for your application.

Going forward, we'd recommend that you manage dependencies through
[`deno.json`](../getting_started/configuration_file.md) instead, which supports
other types of imports as well.

When importing npm packages, you would use the `npm:` specifier, much like you
would the `node:` specifier for any built-in Node modules.

```js
import express from "npm:express@4";

const app = express();

app.get("/", function (_req, res) {
  res.send("hello");
});

app.listen(3000, () => {
  console.log("Express listening on :3000");
});
```

## Node.js global objects

In Node.js, there are a number of
[global objects](https://nodejs.org/api/globals.html) that are available in the
scope of all programs, like the `process` object or `__dirname` and
`__filename`.

Deno does not add additional objects and variables to the global scope, other
than the [`Deno` namespace](../runtime/builtin_apis.md). Any API that doesn't
exist as a web standard browser API will be found in this namespace.

The equivalent Deno expression for every Node.js built-in global object will
vary, but it should be possible to accomplish everything you can do in Node
using a slightly different method in Deno. For example, the
[process.cwd()](https://nodejs.org/api/process.html#processcwd) function in
Node.js exists in Deno as [Deno.cwd()](https://www.deno.com/api?s=Deno.cwd).



/. 🚀 runtime/manual/references/index.md
===================================================

# References

This chapter contains links to reference manuals and sheets, including:

- [Deno Standard APIs](https://deno.land/api)
- [Standard Library](https://deno.land/std?doc)
- [Deno-native third party modules](https://deno.land/x)
- [Full Guide to Using Visual Studio Code](./vscode_deno/index.md)
- [Node to Deno Cheatsheet](./cheatsheet.md)
- [Contributing to Deno](./contributing/index.md)



/. 🚀 runtime/manual/references/cheatsheet.md
===================================================

# Node.js -> Deno cheatsheet

| Node.js                                | Deno                                           |
| -------------------------------------- | ---------------------------------------------- |
| `node file.js`                         | `deno run file.js`                             |
| `ts-node file.ts`                      | `deno run file.ts`                             |
| `node -e`                              | `deno eval`                                    |
| `npm i -g`                             | `deno install`                                 |
| `npm i` / `npm install`                | _n/a_ ¹                                        |
| `npm run`                              | `deno task`                                    |
| `eslint`                               | `deno lint`                                    |
| `prettier`                             | `deno fmt`                                     |
| `package.json`                         | `deno.json` / `deno.jsonc` / `import_map.json` |
| `tsc`                                  | `deno check` ²                                 |
| `typedoc`                              | `deno doc`                                     |
| `jest` / `ava` / `mocha` / `tap` / etc | `deno test`                                    |
| `nodemon`                              | `deno run/lint/test --watch`                   |
| `nexe` / `pkg`                         | `deno compile`                                 |
| `npm explain`                          | `deno info`                                    |
| `nvm` / `n` / `fnm`                    | `deno upgrade`                                 |
| `tsserver`                             | `deno lsp`                                     |
| `nyc` / `c8` / `istanbul`              | `deno coverage`                                |
| benchmarks                             | `deno bench`                                   |

¹ See [Modules](../basics/modules/index.md), the runtime downloads and caches
the code on first use.

² Type checking happens automatically, TypeScript compiler is built into the
`deno` binary.



/. 🚀 runtime/manual/references/contributing/index.md
===================================================

# Contributing

We welcome and appreciate all contributions to Deno.

This page serves as a helper to get you started on contributing.

## Projects

There are numerous repositories in the [`denoland`](https://github.com/denoland)
organization that are part of the Deno ecosystem.

Repositories have different scopes, use different programming languages and have
varying difficulty level when it comes to contributions.

To help you decide which repository might be the best to start contributing
(and/or falls into your interest), here's a short comparison (**codebases
primarily comprise the languages in bold**):

### [`deno`](https://github.com/denoland/deno)

This is the main repository that provides the `deno` CLI.

If you want to fix a bug or add a new feature to `deno` this is the repository
you want to contribute to.

Some systems, including a large part of the Node.js compatibility layer are
implemented in JavaScript and TypeScript modules. These are a good place to
start if you are looking to make your first contribution.

While iterating on such modules it is recommended to include
`--features __runtime_js_sources` in your `cargo` flags. This is a special
development mode where the JS/TS sources are not included in the binary but read
at runtime, meaning the binary will not have to be rebuilt if they are changed.

```sh
# cargo build
cargo build --features __runtime_js_sources

# cargo run -- run hello.ts
cargo run --features __runtime_js_sources -- run hello.ts

# cargo test integration::node_unit_tests::os_test
cargo test --features __runtime_js_sources integration::node_unit_tests::os_test
```

Also remember to reference this feature flag in your editor settings. For VSCode
users, combine the following into your workspace file:

```json
{
  "settings": {
    "rust-analyzer.cargo.features": ["__runtime_js_sources"]
  }
}
```

Languages: **Rust**, **JavaScript**, **TypeScript**

### [`deno_std`](https://github.com/denoland/deno_std)

The standard library for Deno.

Languages: **TypeScript**, WebAssembly

### [`fresh`](https://github.com/denoland/fresh)

The next-gen web framework.

Languages: **TypeScript**, TSX

### [`deno_lint`](https://github.com/denoland/deno_lint)

Linter that powers `deno lint` subcommand.

Languages: **Rust**

### [`deno_doc`](https://github.com/denoland/deno_doc)

Documentation generator that powers `deno doc` subcommand and
https://doc.deno.land

Languages: **Rust**

### [`docland`](https://github.com/denoland/docland)

Frontend for documentation generator: https://doc.deno.land

Languages: **TypeScript**, TSX, CSS

### [`rusty_v8`](https://github.com/denoland/rusty_v8)

Rust bindings for the V8 JavaScript engine. Very technical and low-level.

Languages: **Rust**

### [`serde_v8`](https://github.com/denoland/deno_core/tree/main/serde_v8)

Library that provides bijection layer between V8 and Rust objects. Based on
[`serde`](https://crates.io/crates/serde) library. Very technical and low-level.

Languages: **Rust**

### [`deno_docker`](https://github.com/denoland/deno_docker)

Official Docker images for Deno.

## General remarks

- Read the [style guide](./style_guide.md).

- Please don't make [the benchmarks](https://deno.land/benchmarks) worse.

- Ask for help in the [community chat room](https://discord.gg/deno).

- If you are going to work on an issue, mention so in the issue's comments
  _before_ you start working on the issue.

- If you are going to work on a new feature, create an issue and discuss with
  other contributors _before_ you start working on the feature; we appreciate
  all contributions but not all proposed features will be accepted. We don't
  want you to spend hours working on code that might not be accepted.

- Please be professional in the forums. We follow
  [Rust's code of conduct](https://www.rust-lang.org/policies/code-of-conduct)
  (CoC). Have a problem? Email [ry@tinyclouds.org](mailto:ry@tinyclouds.org).

## Submitting a pull request

Before submitting a PR to any of the repos, please make sure the following is
done:

1. Give the PR a descriptive title.

Examples of good PR title:

- fix(std/http): Fix race condition in server
- docs(console): Update docstrings
- feat(doc): Handle nested re-exports

Examples of bad PR title:

- fix #7123
- update docs
- fix bugs

2. Ensure there is a related issue and that it is referenced in the PR text.
3. Ensure there are tests that cover the changes.

## Submitting a PR to [`deno`](https://github.com/denoland/deno)

In addition to the above make sure that:

1. `cargo test` passes - this will run full test suite for `deno` including unit
   tests, integration tests and Web Platform Tests

1. Run `./tools/format.js` - this will format all of the code to adhere to the
   consistent style in the repository

1. Run `./tools/lint.js` - this will check Rust and JavaScript code for common
   mistakes and errors using `clippy` (for Rust) and `dlint` (for JavaScript)

## Submitting a PR to [`deno_std`](https://github.com/denoland/deno_std)

In addition to the above make sure that:

1. All of the code you wrote is in `TypeScript` (ie. don't use `JavaScript`)

1. `deno test --unstable --allow-all` passes - this will run full test suite for
   the standard library

1. Run `deno fmt` in the root of repository - this will format all of the code
   to adhere to the consistent style in the repository.

1. Run `deno lint` - this will check TypeScript code for common mistakes and
   errors.

## Submitting a PR to [`fresh`](https://github.com/denoland/fresh)

First, please be sure to
[install Puppeteer](https://github.com/lucacasonato/deno-puppeteer#installation).
Then, please ensure `deno task ok` is run and successfully passes.

## Documenting APIs

It is important to document all public APIs and we want to do that inline with
the code. This helps ensure that code and documentation are tightly coupled
together.

### JavaScript and TypeScript

All publicly exposed APIs and types, both via the `deno` module as well as the
global/`window` namespace should have JSDoc documentation. This documentation is
parsed and available to the TypeScript compiler, and therefore easy to provide
further downstream. JSDoc blocks come just prior to the statement they apply to
and are denoted by a leading `/**` before terminating with a `*/`. For example:

```ts
/** A simple JSDoc comment */
export const FOO = "foo";
```

Find more at: https://jsdoc.app/

### Rust

Use
[this guide](https://doc.rust-lang.org/rustdoc/how-to-write-documentation.html)
for writing documentation comments in Rust code.



/. 🚀 runtime/manual/references/contributing/architecture.md
===================================================

# Internal Details

## Deno and Linux analogy

|                       **Linux** | **Deno**                         |
| ------------------------------: | :------------------------------- |
|                       Processes | Web Workers                      |
|                        Syscalls | Ops                              |
|           File descriptors (fd) | [Resource ids (rid)](#resources) |
|                       Scheduler | Tokio                            |
| Userland: libc++ / glib / boost | https://deno.land/std/           |
|                 /proc/\$\$/stat | [Deno.metrics()](#metrics)       |
|                       man pages | deno types                       |

### Resources

Resources (AKA `rid`) are Deno's version of file descriptors. They are integer
values used to refer to open files, sockets, and other concepts. For testing it
would be good to be able to query the system for how many open resources there
are.

```ts
console.log(Deno.resources());
// { 0: "stdin", 1: "stdout", 2: "stderr" }
Deno.close(0);
console.log(Deno.resources());
// { 1: "stdout", 2: "stderr" }
```

### Metrics

Metrics is Deno's internal counter for various statistics.

```shell
> console.table(Deno.metrics())
┌─────────────────────────┬───────────┐
│          (idx)          │  Values   │
├─────────────────────────┼───────────┤
│      opsDispatched      │    9      │
│    opsDispatchedSync    │    0      │
│   opsDispatchedAsync    │    0      │
│ opsDispatchedAsyncUnref │    0      │
│      opsCompleted       │    9      │
│    opsCompletedSync     │    0      │
│    opsCompletedAsync    │    0      │
│ opsCompletedAsyncUnref  │    0      │
│    bytesSentControl     │   504     │
│      bytesSentData      │    0      │
│      bytesReceived      │   856     │
└─────────────────────────┴───────────┘
```

## Conference

- Ryan Dahl. (May 27, 2020).
  [An interesting case with Deno](https://www.youtube.com/watch?v=1b7FoBwxc7E).
  Deno Israel.
- Bartek Iwańczuk. (Oct 6, 2020).
  [Deno internals - how modern JS/TS runtime is
  built](https://www.youtube.com/watch?v=AOvg_GbnsbA&t=35m13s). Paris Deno.



/. 🚀 runtime/manual/references/contributing/building_from_source.md
===================================================

# Building `deno` from Source

Below are instructions on how to build Deno from source. If you just want to use
Deno you can download a prebuilt executable (more information in the
[`Getting Started`](../../getting_started/installation.md#download-and-install)
chapter).

## Cloning the Repository

> Deno uses submodules, so you must remember to clone using
> `--recurse-submodules`.

**Linux**/**Mac**:

```shell
git clone --recurse-submodules https://github.com/denoland/deno.git
```

**Windows**:

1. [Enable "Developer Mode"](https://www.google.com/search?q=windows+enable+developer+mode)
   (otherwise symlinks would require administrator privileges).
2. Make sure you are using git version 2.19.2.windows.1 or newer.
3. Set `core.symlinks=true` before the checkout:
   ```shell
   git config --global core.symlinks true
   git clone --recurse-submodules https://github.com/denoland/deno.git
   ```

## Prerequisites

### Rust

> Deno requires a specific release of Rust. Deno may not support building on
> other versions, or on the Rust Nightly Releases. The version of Rust required
> for a particular release is specified in the `rust-toolchain.toml` file.

[Update or Install Rust](https://www.rust-lang.org/tools/install). Check that
Rust installed/updated correctly:

```
rustc -V
cargo -V
```

### Native Compilers and Linkers

> Many components of Deno require a native compiler to build optimized native
> functions.

**Linux**:

```sh
apt install --install-recommends -y clang-16 lld-16 cmake libglib2.0-dev
```

**Mac**:

Mac users must have the _XCode Command Line Tools_ installed.
([XCode](https://developer.apple.com/xcode/) already includes the _XCode Command
Line Tools_. Run `xcode-select --install` to install it without XCode.)

[CMake](https://cmake.org/) is also required, but does not ship with the
_Command Line Tools_.

```
brew install cmake
```

**Mac M1/M2**:

For Apple aarch64 users `lld` must be installed.

```
brew install llvm
# Add /opt/homebrew/opt/llvm/bin/ to $PATH
```

**Windows**:

1. Get [VS Community 2019](https://www.visualstudio.com/downloads/) with the
   "Desktop development with C++" toolkit and make sure to select the following
   required tools listed below along with all C++ tools.

   - Visual C++ tools for CMake
   - Windows 10 SDK (10.0.17763.0)
   - Testing tools core features - Build Tools
   - Visual C++ ATL for x86 and x64
   - Visual C++ MFC for x86 and x64
   - C++/CLI support
   - VC++ 2015.3 v14.00 (v140) toolset for desktop

2. Enable "Debugging Tools for Windows".
   - Go to "Control Panel" → "Programs" → "Programs and Features"
   - Select "Windows Software Development Kit - Windows 10"
   - → "Change" → "Change" → Check "Debugging Tools For Windows" → "Change"
     →"Finish".
   - Or use:
     [Debugging Tools for Windows](https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/)
     (Notice: it will download the files, you should install
     `X64 Debuggers And Tools-x64_en-us.msi` file manually.)

### Protobuf Compiler

> Building Deno requires the
> [Protocol Buffers compiler](https://grpc.io/docs/protoc-installation/).

**Linux**:

```sh
apt install -y protobuf-compiler
protoc --version  # Ensure compiler version is 3+
```

**Mac**:

```sh
brew install protobuf
protoc --version  # Ensure compiler version is 3+
```

**Windows**

Windows users can download the latest binary release from
[GitHub](https://github.com/protocolbuffers/protobuf/releases/latest).

## Python 3

> Deno requires [Python 3](https://www.python.org/downloads) for running WPT
> tests. Ensure that a suffix-less `python`/`python.exe` exists in your `PATH`
> and it refers to Python 3.

## Building Deno

The easiest way to build Deno is by using a precompiled version of V8:

```
cargo build -vv
```

However, you may also want to build Deno and V8 from source code if you are
doing lower-level V8 development, or using a platform that does not have
precompiled versions of V8:

```
V8_FROM_SOURCE=1 cargo build -vv
```

When building V8 from source, there may be more dependencies. See
[rusty_v8's README](https://github.com/denoland/rusty_v8) for more details about
the V8 build.

## Building

Build with Cargo:

```shell
# Build:
cargo build -vv

# Build errors?  Ensure you have latest main and try building again, or if that doesn't work try:
cargo clean && cargo build -vv

# Run:
./target/debug/deno run cli/tests/testdata/run/002_hello.ts
```



/. 🚀 runtime/manual/references/contributing/profiling.md
===================================================

# Profiling

## Perf profiling:

Tools that can be used to generate/ visualise perf results:

- flamegraph-rs (https://github.com/flamegraph-rs/flamegraph)
- flamescope (https://github.com/Netflix/flamescope)

Example using perf on `micro_bench_ops` and visualising using flamescope:

```sh
# build `examples/micro_bench_ops`
cargo build --release --example micro_bench_ops

# run `examples/micro_bench_ops` using perf
sudo perf record -F 49 -a -g -- ./target/release/examples/micro_bench_ops
sudo perf script --header > micro_bench_ops_perf

# now open the file using flamescope
```

Example running `deno_tcp.ts` in combination with flamegraph (`script.sh`):

```sh
sudo flamegraph -o flamegraph.svg target/debug/deno run --allow-net cli/bench/deno_tcp.ts &
sleep 1
./third_party/prebuilt/linux64/wrk http://localhost:4500/
sleep 1
kill `pgrep perf`
```

## v8 profiling:

Example using v8 profiling on `micro_bench_ops`:

```sh
# build `examples/micro_bench_ops`
cargo build --release --example micro_bench_ops

# run `examples/micro_bench_ops`
./target/release/examples/micro_bench_ops --prof
```

Example using v8 profiling on `deno_tcp.ts`:

```sh
# build `deno`
cargo build --release

# run `deno_tcp.ts`
./target/release/deno --v8-flags=--prof --allow-net cli/bench/deno_tcp.ts &
sleep 1
./third_party/prebuilt/linux64/wrk http://localhost:4500/
sleep 1
kill `pgrep deno`
```

V8 will write a file in the current directory that looks like this:
`isolate-0x7fad98242400-v8.log`. To examine this file:

```sh
node --prof-process isolate-0x7fad98242400-v8.log > prof.log
```

`prof.log` will contain information about tick distribution of different calls.

To view the log with Web UI, generate JSON file of the log:

Open `rusty_v8/v8/tools/profview/index.html` in your browser, and select
`prof.json` to view the distribution graphically.

Useful V8 flags during profiling:

- --prof
- --log-internal-timer-events
- --log-timer-events
- --track-gc
- --log-source-code
- --track-gc-object-stats

To learn more about profiling, check out the following links:

- [https://v8.dev/docs/profile](https://v8.dev/docs/profile)

## Debugging with LLDB

To debug the deno binary, we can use `rust-lldb`. It should come with `rustc`
and is a wrapper around LLDB.

```shell
$ rust-lldb -- ./target/debug/deno run --allow-net tests/http_bench.ts
# On macOS, you might get warnings like
# `ImportError: cannot import name _remove_dead_weakref`
# In that case, use system python by setting PATH, e.g.
# PATH=/System/Library/Frameworks/Python.framework/Versions/2.7/bin:$PATH
(lldb) command script import "/Users/kevinqian/.rustup/toolchains/1.36.0-x86_64-apple-darwin/lib/rustlib/etc/lldb_rust_formatters.py"
(lldb) type summary add --no-value --python-function lldb_rust_formatters.print_val -x ".*" --category Rust
(lldb) type category enable Rust
(lldb) target create "../deno/target/debug/deno"
Current executable set to '../deno/target/debug/deno' (x86_64).
(lldb) settings set -- target.run-args  "tests/http_bench.ts" "--allow-net"
(lldb) b op_start
(lldb) r
```

## V8 flags

V8 has many many internal command-line flags:

```shell
$ deno run --v8-flags=--help _
SSE3=1 SSSE3=1 SSE4_1=1 SSE4_2=1 SAHF=1 AVX=1 FMA3=1 BMI1=1 BMI2=1 LZCNT=1 POPCNT=1 ATOM=0
Synopsis:
  shell [options] [--shell] [<file>...]
  d8 [options] [-e <string>] [--shell] [[--module] <file>...]

  -e        execute a string in V8
  --shell   run an interactive JavaScript shell
  --module  execute a file as a JavaScript module

Note: the --module option is implicitly enabled for *.mjs files.

The following syntax for options is accepted (both '-' and '--' are ok):
  --flag        (bool flags only)
  --no-flag     (bool flags only)
  --flag=value  (non-bool flags only, no spaces around '=')
  --flag value  (non-bool flags only)
  --            (captures all remaining args in JavaScript)

Options:
  --use-strict (enforce strict mode)
        type: bool  default: false
  --es-staging (enable test-worthy harmony features (for internal use only))
        type: bool  default: false
  --harmony (enable all completed harmony features)
        type: bool  default: false
  --harmony-shipping (enable all shipped harmony features)
        type: bool  default: true
  --harmony-regexp-sequence (enable "RegExp Unicode sequence properties" (in progress))
        type: bool  default: false
  --harmony-weak-refs-with-cleanup-some (enable "harmony weak references with FinalizationRegistry.prototype.cleanupSome" (in progress))
        type: bool  default: false
  --harmony-regexp-match-indices (enable "harmony regexp match indices" (in progress))
        type: bool  default: false
  --harmony-top-level-await (enable "harmony top level await")
        type: bool  default: false
  --harmony-namespace-exports (enable "harmony namespace exports (export * as foo from 'bar')")
        type: bool  default: true
  --harmony-sharedarraybuffer (enable "harmony sharedarraybuffer")
        type: bool  default: true
  --harmony-import-meta (enable "harmony import.meta property")
        type: bool  default: true
  --harmony-dynamic-import (enable "harmony dynamic import")
        type: bool  default: true
  --harmony-promise-all-settled (enable "harmony Promise.allSettled")
        type: bool  default: true
  --harmony-promise-any (enable "harmony Promise.any")
        type: bool  default: true
  --harmony-private-methods (enable "harmony private methods in class literals")
        type: bool  default: true
  --harmony-weak-refs (enable "harmony weak references")
        type: bool  default: true
  --harmony-string-replaceall (enable "harmony String.prototype.replaceAll")
        type: bool  default: true
  --harmony-logical-assignment (enable "harmony logical assignment")
        type: bool  default: true
  --lite-mode (enables trade-off of performance for memory savings)
        type: bool  default: false
  --future (Implies all staged features that we want to ship in the not-too-far future)
        type: bool  default: false
  --assert-types (generate runtime type assertions to test the typer)
        type: bool  default: false
  --allocation-site-pretenuring (pretenure with allocation sites)
        type: bool  default: true
  --page-promotion (promote pages based on utilization)
        type: bool  default: true
  --always-promote-young-mc (always promote young objects during mark-compact)
        type: bool  default: true
  --page-promotion-threshold (min percentage of live bytes on a page to enable fast evacuation)
        type: int  default: 70
  --trace-pretenuring (trace pretenuring decisions of HAllocate instructions)
        type: bool  default: false
  --trace-pretenuring-statistics (trace allocation site pretenuring statistics)
        type: bool  default: false
  --track-fields (track fields with only smi values)
        type: bool  default: true
  --track-double-fields (track fields with double values)
        type: bool  default: true
  --track-heap-object-fields (track fields with heap values)
        type: bool  default: true
  --track-computed-fields (track computed boilerplate fields)
        type: bool  default: true
  --track-field-types (track field types)
        type: bool  default: true
  --trace-block-coverage (trace collected block coverage information)
        type: bool  default: false
  --trace-protector-invalidation (trace protector cell invalidations)
        type: bool  default: false
  --feedback-normalization (feed back normalization to constructors)
        type: bool  default: false
  --enable-one-shot-optimization (Enable size optimizations for the code that will only be executed once)
        type: bool  default: false
  --unbox-double-arrays (automatically unbox arrays of doubles)
        type: bool  default: true
  --interrupt-budget (interrupt budget which should be used for the profiler counter)
        type: int  default: 147456
  --jitless (Disable runtime allocation of executable memory.)
        type: bool  default: false
  --use-ic (use inline caching)
        type: bool  default: true
  --budget-for-feedback-vector-allocation (The budget in amount of bytecode executed by a function before we decide to allocate feedback vectors)
        type: int  default: 1024
  --lazy-feedback-allocation (Allocate feedback vectors lazily)
        type: bool  default: true
  --ignition-elide-noneffectful-bytecodes (elide bytecodes which won't have any external effect)
        type: bool  default: true
  --ignition-reo (use ignition register equivalence optimizer)
        type: bool  default: true
  --ignition-filter-expression-positions (filter expression positions before the bytecode pipeline)
        type: bool  default: true
  --ignition-share-named-property-feedback (share feedback slots when loading the same named property from the same object)
        type: bool  default: true
  --print-bytecode (print bytecode generated by ignition interpreter)
        type: bool  default: false
  --enable-lazy-source-positions (skip generating source positions during initial compile but regenerate when actually required)
        type: bool  default: true
  --stress-lazy-source-positions (collect lazy source positions immediately after lazy compile)
        type: bool  default: false
  --print-bytecode-filter (filter for selecting which functions to print bytecode)
        type: string  default: *
  --trace-ignition-codegen (trace the codegen of ignition interpreter bytecode handlers)
        type: bool  default: false
  --trace-ignition-dispatches (traces the dispatches to bytecode handlers by the ignition interpreter)
        type: bool  default: false
  --trace-ignition-dispatches-output-file (the file to which the bytecode handler dispatch table is written (by default, the table is not written to a file))
        type: string  default: nullptr
  --fast-math (faster (but maybe less accurate) math functions)
        type: bool  default: true
  --trace-track-allocation-sites (trace the tracking of allocation sites)
        type: bool  default: false
  --trace-migration (trace object migration)
        type: bool  default: false
  --trace-generalization (trace map generalization)
        type: bool  default: false
  --turboprop (enable experimental turboprop mid-tier compiler.)
        type: bool  default: false
  --concurrent-recompilation (optimizing hot functions asynchronously on a separate thread)
        type: bool  default: true
  --trace-concurrent-recompilation (track concurrent recompilation)
        type: bool  default: false
  --concurrent-recompilation-queue-length (the length of the concurrent compilation queue)
        type: int  default: 8
  --concurrent-recompilation-delay (artificial compilation delay in ms)
        type: int  default: 0
  --block-concurrent-recompilation (block queued jobs until released)
        type: bool  default: false
  --concurrent-inlining (run optimizing compiler's inlining phase on a separate thread)
        type: bool  default: false
  --max-serializer-nesting (maximum levels for nesting child serializers)
        type: int  default: 25
  --trace-heap-broker-verbose (trace the heap broker verbosely (all reports))
        type: bool  default: false
  --trace-heap-broker-memory (trace the heap broker memory (refs analysis and zone numbers))
        type: bool  default: false
  --trace-heap-broker (trace the heap broker (reports on missing data only))
        type: bool  default: false
  --stress-runs (number of stress runs)
        type: int  default: 0
  --deopt-every-n-times (deoptimize every n times a deopt point is passed)
        type: int  default: 0
  --print-deopt-stress (print number of possible deopt points)
        type: bool  default: false
  --opt (use adaptive optimizations)
        type: bool  default: true
  --turbo-sp-frame-access (use stack pointer-relative access to frame wherever possible)
        type: bool  default: false
  --turbo-control-flow-aware-allocation (consider control flow while allocating registers)
        type: bool  default: true
  --turbo-filter (optimization filter for TurboFan compiler)
        type: string  default: *
  --trace-turbo (trace generated TurboFan IR)
        type: bool  default: false
  --trace-turbo-path (directory to dump generated TurboFan IR to)
        type: string  default: nullptr
  --trace-turbo-filter (filter for tracing turbofan compilation)
        type: string  default: *
  --trace-turbo-graph (trace generated TurboFan graphs)
        type: bool  default: false
  --trace-turbo-scheduled (trace TurboFan IR with schedule)
        type: bool  default: false
  --trace-turbo-cfg-file (trace turbo cfg graph (for C1 visualizer) to a given file name)
        type: string  default: nullptr
  --trace-turbo-types (trace TurboFan's types)
        type: bool  default: true
  --trace-turbo-scheduler (trace TurboFan's scheduler)
        type: bool  default: false
  --trace-turbo-reduction (trace TurboFan's various reducers)
        type: bool  default: false
  --trace-turbo-trimming (trace TurboFan's graph trimmer)
        type: bool  default: false
  --trace-turbo-jt (trace TurboFan's jump threading)
        type: bool  default: false
  --trace-turbo-ceq (trace TurboFan's control equivalence)
        type: bool  default: false
  --trace-turbo-loop (trace TurboFan's loop optimizations)
        type: bool  default: false
  --trace-turbo-alloc (trace TurboFan's register allocator)
        type: bool  default: false
  --trace-all-uses (trace all use positions)
        type: bool  default: false
  --trace-representation (trace representation types)
        type: bool  default: false
  --turbo-verify (verify TurboFan graphs at each phase)
        type: bool  default: false
  --turbo-verify-machine-graph (verify TurboFan machine graph before instruction selection)
        type: string  default: nullptr
  --trace-verify-csa (trace code stubs verification)
        type: bool  default: false
  --csa-trap-on-node (trigger break point when a Node.js with given id is created in given stub. The format is: StubName,NodeId)
        type: string  default: nullptr
  --turbo-stats (print TurboFan statistics)
        type: bool  default: false
  --turbo-stats-nvp (print TurboFan statistics in machine-readable format)
        type: bool  default: false
  --turbo-stats-wasm (print TurboFan statistics of wasm compilations)
        type: bool  default: false
  --turbo-splitting (split nodes during scheduling in TurboFan)
        type: bool  default: true
  --function-context-specialization (enable function context specialization in TurboFan)
        type: bool  default: false
  --turbo-inlining (enable inlining in TurboFan)
        type: bool  default: true
  --max-inlined-bytecode-size (maximum size of bytecode for a single inlining)
        type: int  default: 500
  --max-inlined-bytecode-size-cumulative (maximum cumulative size of bytecode considered for inlining)
        type: int  default: 1000
  --max-inlined-bytecode-size-absolute (maximum cumulative size of bytecode considered for inlining)
        type: int  default: 5000
  --reserve-inline-budget-scale-factor (maximum cumulative size of bytecode considered for inlining)
        type: float  default: 1.2
  --max-inlined-bytecode-size-small (maximum size of bytecode considered for small function inlining)
        type: int  default: 30
  --max-optimized-bytecode-size (maximum bytecode size to be considered for optimization; too high values may cause the compiler to hit (release) assertions)
        type: int  default: 61440
  --min-inlining-frequency (minimum frequency for inlining)
        type: float  default: 0.15
  --polymorphic-inlining (polymorphic inlining)
        type: bool  default: true
  --stress-inline (set high thresholds for inlining to inline as much as possible)
        type: bool  default: false
  --trace-turbo-inlining (trace TurboFan inlining)
        type: bool  default: false
  --turbo-inline-array-builtins (inline array builtins in TurboFan code)
        type: bool  default: true
  --use-osr (use on-stack replacement)
        type: bool  default: true
  --trace-osr (trace on-stack replacement)
        type: bool  default: false
  --analyze-environment-liveness (analyze liveness of environment slots and zap dead values)
        type: bool  default: true
  --trace-environment-liveness (trace liveness of local variable slots)
        type: bool  default: false
  --turbo-load-elimination (enable load elimination in TurboFan)
        type: bool  default: true
  --trace-turbo-load-elimination (trace TurboFan load elimination)
        type: bool  default: false
  --turbo-profiling (enable basic block profiling in TurboFan)
        type: bool  default: false
  --turbo-profiling-verbose (enable basic block profiling in TurboFan, and include each function's schedule and disassembly in the output)
        type: bool  default: false
  --turbo-verify-allocation (verify register allocation in TurboFan)
        type: bool  default: false
  --turbo-move-optimization (optimize gap moves in TurboFan)
        type: bool  default: true
  --turbo-jt (enable jump threading in TurboFan)
        type: bool  default: true
  --turbo-loop-peeling (Turbofan loop peeling)
        type: bool  default: true
  --turbo-loop-variable (Turbofan loop variable optimization)
        type: bool  default: true
  --turbo-loop-rotation (Turbofan loop rotation)
        type: bool  default: true
  --turbo-cf-optimization (optimize control flow in TurboFan)
        type: bool  default: true
  --turbo-escape (enable escape analysis)
        type: bool  default: true
  --turbo-allocation-folding (Turbofan allocation folding)
        type: bool  default: true
  --turbo-instruction-scheduling (enable instruction scheduling in TurboFan)
        type: bool  default: false
  --turbo-stress-instruction-scheduling (randomly schedule instructions to stress dependency tracking)
        type: bool  default: false
  --turbo-store-elimination (enable store-store elimination in TurboFan)
        type: bool  default: true
  --trace-store-elimination (trace store elimination)
        type: bool  default: false
  --turbo-rewrite-far-jumps (rewrite far to near jumps (ia32,x64))
        type: bool  default: true
  --stress-gc-during-compilation (simulate GC/compiler thread race related to https://crbug.com/v8/8520)
        type: bool  default: false
  --turbo-fast-api-calls (enable fast API calls from TurboFan)
        type: bool  default: false
  --reuse-opt-code-count (don't discard optimized code for the specified number of deopts.)
        type: int  default: 0
  --turbo-nci (enable experimental native context independent code.)
        type: bool  default: false
  --turbo-nci-as-highest-tier (replace default TF with NCI code as the highest tier for testing purposes.)
        type: bool  default: false
  --print-nci-code (print native context independent code.)
        type: bool  default: false
  --trace-turbo-nci (trace native context independent code.)
        type: bool  default: false
  --turbo-collect-feedback-in-generic-lowering (enable experimental feedback collection in generic lowering.)
        type: bool  default: false
  --optimize-for-size (Enables optimizations which favor memory size over execution speed)
        type: bool  default: false
  --untrusted-code-mitigations (Enable mitigations for executing untrusted code)
        type: bool  default: false
  --expose-wasm (expose wasm interface to JavaScript)
        type: bool  default: true
  --assume-asmjs-origin (force wasm decoder to assume input is internal asm-wasm format)
        type: bool  default: false
  --wasm-num-compilation-tasks (maximum number of parallel compilation tasks for wasm)
        type: int  default: 128
  --wasm-write-protect-code-memory (write protect code memory on the wasm native heap)
        type: bool  default: false
  --wasm-async-compilation (enable actual asynchronous compilation for WebAssembly.compile)
        type: bool  default: true
  --wasm-test-streaming (use streaming compilation instead of async compilation for tests)
        type: bool  default: false
  --wasm-max-mem-pages (maximum initial number of 64KiB memory pages of a wasm instance)
        type: uint  default: 32767
  --wasm-max-mem-pages-growth (maximum number of 64KiB pages a Wasm memory can grow to)
        type: uint  default: 65536
  --wasm-max-table-size (maximum table size of a wasm instance)
        type: uint  default: 10000000
  --wasm-max-code-space (maximum committed code space for wasm (in MB))
        type: uint  default: 1024
  --wasm-tier-up (enable tier up to the optimizing compiler (requires --liftoff to have an effect))
        type: bool  default: true
  --trace-wasm-ast-start (start function for wasm AST trace (inclusive))
        type: int  default: 0
  --trace-wasm-ast-end (end function for wasm AST trace (exclusive))
        type: int  default: 0
  --liftoff (enable Liftoff, the baseline compiler for WebAssembly)
        type: bool  default: true
  --trace-wasm-memory (print all memory updates performed in wasm code)
        type: bool  default: false
  --wasm-tier-mask-for-testing (bitmask of functions to compile with TurboFan instead of Liftoff)
        type: int  default: 0
  --wasm-expose-debug-eval (Expose wasm evaluator support on the CDP)
        type: bool  default: false
  --validate-asm (validate asm.js modules before compiling)
        type: bool  default: true
  --suppress-asm-messages (don't emit asm.js related messages (for golden file testing))
        type: bool  default: false
  --trace-asm-time (log asm.js timing info to the console)
        type: bool  default: false
  --trace-asm-scanner (log tokens encountered by asm.js scanner)
        type: bool  default: false
  --trace-asm-parser (verbose logging of asm.js parse failures)
        type: bool  default: false
  --stress-validate-asm (try to validate everything as asm.js)
        type: bool  default: false
  --dump-wasm-module-path (directory to dump wasm modules to)
        type: string  default: nullptr
  --experimental-wasm-eh (enable prototype exception handling opcodes for wasm)
        type: bool  default: false
  --experimental-wasm-simd (enable prototype SIMD opcodes for wasm)
        type: bool  default: false
  --experimental-wasm-return-call (enable prototype return call opcodes for wasm)
        type: bool  default: false
  --experimental-wasm-compilation-hints (enable prototype compilation hints section for wasm)
        type: bool  default: false
  --experimental-wasm-gc (enable prototype garbage collection for wasm)
        type: bool  default: false
  --experimental-wasm-typed-funcref (enable prototype typed function references for wasm)
        type: bool  default: false
  --experimental-wasm-reftypes (enable prototype reference type opcodes for wasm)
        type: bool  default: false
  --experimental-wasm-threads (enable prototype thread opcodes for wasm)
        type: bool  default: false
  --experimental-wasm-type-reflection (enable prototype wasm type reflection in JS for wasm)
        type: bool  default: false
  --experimental-wasm-bigint (enable prototype JS BigInt support for wasm)
        type: bool  default: true
  --experimental-wasm-bulk-memory (enable prototype bulk memory opcodes for wasm)
        type: bool  default: true
  --experimental-wasm-mv (enable prototype multi-value support for wasm)
        type: bool  default: true
  --wasm-staging (enable staged wasm features)
        type: bool  default: false
  --wasm-opt (enable wasm optimization)
        type: bool  default: false
  --wasm-bounds-checks (enable bounds checks (disable for performance testing only))
        type: bool  default: true
  --wasm-stack-checks (enable stack checks (disable for performance testing only))
        type: bool  default: true
  --wasm-math-intrinsics (intrinsify some Math imports into wasm)
        type: bool  default: true
  --wasm-trap-handler (use signal handlers to catch out of bounds memory access in wasm (currently Linux x86_64 only))
        type: bool  default: true
  --wasm-fuzzer-gen-test (generate a test case when running a wasm fuzzer)
        type: bool  default: false
  --print-wasm-code (Print WebAssembly code)
        type: bool  default: false
  --print-wasm-stub-code (Print WebAssembly stub code)
        type: bool  default: false
  --asm-wasm-lazy-compilation (enable lazy compilation for asm-wasm modules)
        type: bool  default: false
  --wasm-lazy-compilation (enable lazy compilation for all wasm modules)
        type: bool  default: false
  --wasm-lazy-validation (enable lazy validation for lazily compiled wasm functions)
        type: bool  default: false
  --wasm-atomics-on-non-shared-memory (allow atomic operations on non-shared WebAssembly memory)
        type: bool  default: true
  --wasm-grow-shared-memory (allow growing shared WebAssembly memory objects)
        type: bool  default: true
  --wasm-simd-post-mvp (allow experimental SIMD operations for prototyping that are not included in the current proposal)
        type: bool  default: false
  --wasm-code-gc (enable garbage collection of wasm code)
        type: bool  default: true
  --trace-wasm-code-gc (trace garbage collection of wasm code)
        type: bool  default: false
  --stress-wasm-code-gc (stress test garbage collection of wasm code)
        type: bool  default: false
  --wasm-max-initial-code-space-reservation (maximum size of the initial wasm code space reservation (in MB))
        type: int  default: 0
  --frame-count (number of stack frames inspected by the profiler)
        type: int  default: 1
  --stress-sampling-allocation-profiler (Enables sampling allocation profiler with X as a sample interval)
        type: int  default: 0
  --lazy-new-space-shrinking (Enables the lazy new space shrinking strategy)
        type: bool  default: false
  --min-semi-space-size (min size of a semi-space (in MBytes), the new space consists of two semi-spaces)
        type: size_t  default: 0
  --max-semi-space-size (max size of a semi-space (in MBytes), the new space consists of two semi-spaces)
        type: size_t  default: 0
  --semi-space-growth-factor (factor by which to grow the new space)
        type: int  default: 2
  --max-old-space-size (max size of the old space (in Mbytes))
        type: size_t  default: 0
  --max-heap-size (max size of the heap (in Mbytes) both max_semi_space_size and max_old_space_size take precedence. All three flags cannot be specified at the same time.)
        type: size_t  default: 0
  --initial-heap-size (initial size of the heap (in Mbytes))
        type: size_t  default: 0
  --huge-max-old-generation-size (Increase max size of the old space to 4 GB for x64 systems withthe physical memory bigger than 16 GB)
        type: bool  default: true
  --initial-old-space-size (initial old space size (in Mbytes))
        type: size_t  default: 0
  --global-gc-scheduling (enable GC scheduling based on global memory)
        type: bool  default: true
  --gc-global (always perform global GCs)
        type: bool  default: false
  --random-gc-interval (Collect garbage after random(0, X) allocations. It overrides gc_interval.)
        type: int  default: 0
  --gc-interval (garbage collect after <n> allocations)
        type: int  default: -1
  --retain-maps-for-n-gc (keeps maps alive for <n> old space garbage collections)
        type: int  default: 2
  --trace-gc (print one trace line following each garbage collection)
        type: bool  default: false
  --trace-gc-nvp (print one detailed trace line in name=value format after each garbage collection)
        type: bool  default: false
  --trace-gc-ignore-scavenger (do not print trace line after scavenger collection)
        type: bool  default: false
  --trace-idle-notification (print one trace line following each idle notification)
        type: bool  default: false
  --trace-idle-notification-verbose (prints the heap state used by the idle notification)
        type: bool  default: false
  --trace-gc-verbose (print more details following each garbage collection)
        type: bool  default: false
  --trace-gc-freelists (prints details of each freelist before and after each major garbage collection)
        type: bool  default: false
  --trace-gc-freelists-verbose (prints details of freelists of each page before and after each major garbage collection)
        type: bool  default: false
  --trace-evacuation-candidates (Show statistics about the pages evacuation by the compaction)
        type: bool  default: false
  --trace-allocations-origins (Show statistics about the origins of allocations. Combine with --no-inline-new to track allocations from generated code)
        type: bool  default: false
  --trace-allocation-stack-interval (print stack trace after <n> free-list allocations)
        type: int  default: -1
  --trace-duplicate-threshold-kb (print duplicate objects in the heap if their size is more than given threshold)
        type: int  default: 0
  --trace-fragmentation (report fragmentation for old space)
        type: bool  default: false
  --trace-fragmentation-verbose (report fragmentation for old space (detailed))
        type: bool  default: false
  --minor-mc-trace-fragmentation (trace fragmentation after marking)
        type: bool  default: false
  --trace-evacuation (report evacuation statistics)
        type: bool  default: false
  --trace-mutator-utilization (print mutator utilization, allocation speed, gc speed)
        type: bool  default: false
  --incremental-marking (use incremental marking)
        type: bool  default: true
  --incremental-marking-wrappers (use incremental marking for marking wrappers)
        type: bool  default: true
  --incremental-marking-task (use tasks for incremental marking)
        type: bool  default: true
  --incremental-marking-soft-trigger (threshold for starting incremental marking via a task in percent of available space: limit - size)
        type: int  default: 0
  --incremental-marking-hard-trigger (threshold for starting incremental marking immediately in percent of available space: limit - size)
        type: int  default: 0
  --trace-unmapper (Trace the unmapping)
        type: bool  default: false
  --parallel-scavenge (parallel scavenge)
        type: bool  default: true
  --scavenge-task (schedule scavenge tasks)
        type: bool  default: true
  --scavenge-task-trigger (scavenge task trigger in percent of the current heap limit)
        type: int  default: 80
  --scavenge-separate-stack-scanning (use a separate phase for stack scanning in scavenge)
        type: bool  default: false
  --trace-parallel-scavenge (trace parallel scavenge)
        type: bool  default: false
  --write-protect-code-memory (write protect code memory)
        type: bool  default: true
  --concurrent-marking (use concurrent marking)
        type: bool  default: true
  --concurrent-array-buffer-sweeping (concurrently sweep array buffers)
        type: bool  default: true
  --concurrent-allocation (concurrently allocate in old space)
        type: bool  default: false
  --local-heaps (allow heap access from background tasks)
        type: bool  default: false
  --stress-concurrent-allocation (start background threads that allocate memory)
        type: bool  default: false
  --parallel-marking (use parallel marking in atomic pause)
        type: bool  default: true
  --ephemeron-fixpoint-iterations (number of fixpoint iterations it takes to switch to linear ephemeron algorithm)
        type: int  default: 10
  --trace-concurrent-marking (trace concurrent marking)
        type: bool  default: false
  --concurrent-store-buffer (use concurrent store buffer processing)
        type: bool  default: true
  --concurrent-sweeping (use concurrent sweeping)
        type: bool  default: true
  --parallel-compaction (use parallel compaction)
        type: bool  default: true
  --parallel-pointer-update (use parallel pointer update during compaction)
        type: bool  default: true
  --detect-ineffective-gcs-near-heap-limit (trigger out-of-memory failure to avoid GC storm near heap limit)
        type: bool  default: true
  --trace-incremental-marking (trace progress of the incremental marking)
        type: bool  default: false
  --trace-stress-marking (trace stress marking progress)
        type: bool  default: false
  --trace-stress-scavenge (trace stress scavenge progress)
        type: bool  default: false
  --track-gc-object-stats (track object counts and memory usage)
        type: bool  default: false
  --trace-gc-object-stats (trace object counts and memory usage)
        type: bool  default: false
  --trace-zone-stats (trace zone memory usage)
        type: bool  default: false
  --zone-stats-tolerance (report a tick only when allocated zone memory changes by this amount)
        type: size_t  default: 1048576
  --track-retaining-path (enable support for tracking retaining path)
        type: bool  default: false
  --concurrent-array-buffer-freeing (free array buffer allocations on a background thread)
        type: bool  default: true
  --gc-stats (Used by tracing internally to enable gc statistics)
        type: int  default: 0
  --track-detached-contexts (track native contexts that are expected to be garbage collected)
        type: bool  default: true
  --trace-detached-contexts (trace native contexts that are expected to be garbage collected)
        type: bool  default: false
  --move-object-start (enable moving of object starts)
        type: bool  default: true
  --memory-reducer (use memory reducer)
        type: bool  default: true
  --memory-reducer-for-small-heaps (use memory reducer for small heaps)
        type: bool  default: true
  --heap-growing-percent (specifies heap growing factor as (1 + heap_growing_percent/100))
        type: int  default: 0
  --v8-os-page-size (override OS page size (in KBytes))
        type: int  default: 0
  --always-compact (Perform compaction on every full GC)
        type: bool  default: false
  --never-compact (Never perform compaction on full GC - testing only)
        type: bool  default: false
  --compact-code-space (Compact code space on full collections)
        type: bool  default: true
  --flush-bytecode (flush of bytecode when it has not been executed recently)
        type: bool  default: true
  --stress-flush-bytecode (stress bytecode flushing)
        type: bool  default: false
  --use-marking-progress-bar (Use a progress bar to scan large objects in increments when incremental marking is active.)
        type: bool  default: true
  --stress-per-context-marking-worklist (Use per-context worklist for marking)
        type: bool  default: false
  --force-marking-deque-overflows (force overflows of marking deque by reducing it's size to 64 words)
        type: bool  default: false
  --stress-compaction (stress the GC compactor to flush out bugs (implies --force_marking_deque_overflows))
        type: bool  default: false
  --stress-compaction-random (Stress GC compaction by selecting random percent of pages as evacuation candidates. It overrides stress_compaction.)
        type: bool  default: false
  --stress-incremental-marking (force incremental marking for small heaps and run it more often)
        type: bool  default: false
  --fuzzer-gc-analysis (prints number of allocations and enables analysis mode for gc fuzz testing, e.g. --stress-marking, --stress-scavenge)
        type: bool  default: false
  --stress-marking (force marking at random points between 0 and X (inclusive) percent of the regular marking start limit)
        type: int  default: 0
  --stress-scavenge (force scavenge at random points between 0 and X (inclusive) percent of the new space capacity)
        type: int  default: 0
  --gc-experiment-background-schedule (new background GC schedule heuristics)
        type: bool  default: false
  --gc-experiment-less-compaction (less compaction in non-memory reducing mode)
        type: bool  default: false
  --disable-abortjs (disables AbortJS runtime function)
        type: bool  default: false
  --randomize-all-allocations (randomize virtual memory reservations by ignoring any hints passed when allocating pages)
        type: bool  default: false
  --manual-evacuation-candidates-selection (Test mode only flag. It allows an unit test to select evacuation candidates pages (requires --stress_compaction).)
        type: bool  default: false
  --fast-promotion-new-space (fast promote new space on high survival rates)
        type: bool  default: false
  --clear-free-memory (initialize free memory with 0)
        type: bool  default: false
  --young-generation-large-objects (allocates large objects by default in the young generation large object space)
        type: bool  default: true
  --debug-code (generate extra code (assertions) for debugging)
        type: bool  default: false
  --code-comments (emit comments in code disassembly; for more readable source positions you should add --no-concurrent_recompilation)
        type: bool  default: false
  --enable-sse3 (enable use of SSE3 instructions if available)
        type: bool  default: true
  --enable-ssse3 (enable use of SSSE3 instructions if available)
        type: bool  default: true
  --enable-sse4-1 (enable use of SSE4.1 instructions if available)
        type: bool  default: true
  --enable-sse4-2 (enable use of SSE4.2 instructions if available)
        type: bool  default: true
  --enable-sahf (enable use of SAHF instruction if available (X64 only))
        type: bool  default: true
  --enable-avx (enable use of AVX instructions if available)
        type: bool  default: true
  --enable-fma3 (enable use of FMA3 instructions if available)
        type: bool  default: true
  --enable-bmi1 (enable use of BMI1 instructions if available)
        type: bool  default: true
  --enable-bmi2 (enable use of BMI2 instructions if available)
        type: bool  default: true
  --enable-lzcnt (enable use of LZCNT instruction if available)
        type: bool  default: true
  --enable-popcnt (enable use of POPCNT instruction if available)
        type: bool  default: true
  --arm-arch (generate instructions for the selected ARM architecture if available: armv6, armv7, armv7+sudiv or armv8)
        type: string  default: armv8
  --force-long-branches (force all emitted branches to be in long mode (MIPS/PPC only))
        type: bool  default: false
  --mcpu (enable optimization for specific cpu)
        type: string  default: auto
  --partial-constant-pool (enable use of partial constant pools (X64 only))
        type: bool  default: true
  --sim-arm64-optional-features (enable optional features on the simulator for testing: none or all)
        type: string  default: none
  --enable-source-at-csa-bind (Include source information in the binary at CSA bind locations.)
        type: bool  default: false
  --enable-armv7 (deprecated (use --arm_arch instead))
        type: maybe_bool  default: unset
  --enable-vfp3 (deprecated (use --arm_arch instead))
        type: maybe_bool  default: unset
  --enable-32dregs (deprecated (use --arm_arch instead))
        type: maybe_bool  default: unset
  --enable-neon (deprecated (use --arm_arch instead))
        type: maybe_bool  default: unset
  --enable-sudiv (deprecated (use --arm_arch instead))
        type: maybe_bool  default: unset
  --enable-armv8 (deprecated (use --arm_arch instead))
        type: maybe_bool  default: unset
  --enable-regexp-unaligned-accesses (enable unaligned accesses for the regexp engine)
        type: bool  default: true
  --script-streaming (enable parsing on background)
        type: bool  default: true
  --stress-background-compile (stress test parsing on background)
        type: bool  default: false
  --finalize-streaming-on-background (perform the script streaming finalization on the background thread)
        type: bool  default: false
  --disable-old-api-accessors (Disable old-style API accessors whose setters trigger through the prototype chain)
        type: bool  default: false
  --expose-gc (expose gc extension)
        type: bool  default: false
  --expose-gc-as (expose gc extension under the specified name)
        type: string  default: nullptr
  --expose-externalize-string (expose externalize string extension)
        type: bool  default: false
  --expose-trigger-failure (expose trigger-failure extension)
        type: bool  default: false
  --stack-trace-limit (number of stack frames to capture)
        type: int  default: 10
  --builtins-in-stack-traces (show built-in functions in stack traces)
        type: bool  default: false
  --experimental-stack-trace-frames (enable experimental frames (API/Builtins) and stack trace layout)
        type: bool  default: false
  --disallow-code-generation-from-strings (disallow eval and friends)
        type: bool  default: false
  --expose-async-hooks (expose async_hooks object)
        type: bool  default: false
  --expose-cputracemark-as (expose cputracemark extension under the specified name)
        type: string  default: nullptr
  --allow-unsafe-function-constructor (allow invoking the function constructor without security checks)
        type: bool  default: false
  --force-slow-path (always take the slow path for builtins)
        type: bool  default: false
  --test-small-max-function-context-stub-size (enable testing the function context size overflow path by making the maximum size smaller)
        type: bool  default: false
  --inline-new (use fast inline allocation)
        type: bool  default: true
  --trace (trace javascript function calls)
        type: bool  default: false
  --trace-wasm (trace wasm function calls)
        type: bool  default: false
  --lazy (use lazy compilation)
        type: bool  default: true
  --max-lazy (ignore eager compilation hints)
        type: bool  default: false
  --trace-opt (trace lazy optimization)
        type: bool  default: false
  --trace-opt-verbose (extra verbose compilation tracing)
        type: bool  default: false
  --trace-opt-stats (trace lazy optimization statistics)
        type: bool  default: false
  --trace-deopt (trace optimize function deoptimization)
        type: bool  default: false
  --trace-file-names (include file names in trace-opt/trace-deopt output)
        type: bool  default: false
  --always-opt (always try to optimize functions)
        type: bool  default: false
  --always-osr (always try to OSR functions)
        type: bool  default: false
  --prepare-always-opt (prepare for turning on always opt)
        type: bool  default: false
  --trace-serializer (print code serializer trace)
        type: bool  default: false
  --compilation-cache (enable compilation cache)
        type: bool  default: true
  --cache-prototype-transitions (cache prototype transitions)
        type: bool  default: true
  --parallel-compile-tasks (enable parallel compile tasks)
        type: bool  default: false
  --compiler-dispatcher (enable compiler dispatcher)
        type: bool  default: false
  --trace-compiler-dispatcher (trace compiler dispatcher activity)
        type: bool  default: false
  --cpu-profiler-sampling-interval (CPU profiler sampling interval in microseconds)
        type: int  default: 1000
  --trace-side-effect-free-debug-evaluate (print debug messages for side-effect-free debug-evaluate for testing)
        type: bool  default: false
  --hard-abort (abort by crashing)
        type: bool  default: true
  --expose-inspector-scripts (expose injected-script-source.js for debugging)
        type: bool  default: false
  --stack-size (default size of stack region v8 is allowed to use (in kBytes))
        type: int  default: 984
  --max-stack-trace-source-length (maximum length of function source code printed in a stack trace.)
        type: int  default: 300
  --clear-exceptions-on-js-entry (clear pending exceptions when entering JavaScript)
        type: bool  default: false
  --histogram-interval (time interval in ms for aggregating memory histograms)
        type: int  default: 600000
  --heap-profiler-trace-objects (Dump heap object allocations/movements/size_updates)
        type: bool  default: false
  --heap-profiler-use-embedder-graph (Use the new EmbedderGraph API to get embedder nodes)
        type: bool  default: true
  --heap-snapshot-string-limit (truncate strings to this length in the heap snapshot)
        type: int  default: 1024
  --sampling-heap-profiler-suppress-randomness (Use constant sample intervals to eliminate test flakiness)
        type: bool  default: false
  --use-idle-notification (Use idle notification to reduce memory footprint.)
        type: bool  default: true
  --trace-ic (trace inline cache state transitions for tools/ic-processor)
        type: bool  default: false
  --modify-field-representation-inplace (enable in-place field representation updates)
        type: bool  default: true
  --max-polymorphic-map-count (maximum number of maps to track in POLYMORPHIC state)
        type: int  default: 4
  --native-code-counters (generate extra code for manipulating stats counters)
        type: bool  default: false
  --thin-strings (Enable ThinString support)
        type: bool  default: true
  --trace-prototype-users (Trace updates to prototype user tracking)
        type: bool  default: false
  --trace-for-in-enumerate (Trace for-in enumerate slow-paths)
        type: bool  default: false
  --trace-maps (trace map creation)
        type: bool  default: false
  --trace-maps-details (also log map details)
        type: bool  default: true
  --allow-natives-syntax (allow natives syntax)
        type: bool  default: false
  --allow-natives-for-differential-fuzzing (allow only natives explicitly allowlisted for differential fuzzers)
        type: bool  default: false
  --parse-only (only parse the sources)
        type: bool  default: false
  --trace-sim (Trace simulator execution)
        type: bool  default: false
  --debug-sim (Enable debugging the simulator)
        type: bool  default: false
  --check-icache (Check icache flushes in ARM and MIPS simulator)
        type: bool  default: false
  --stop-sim-at (Simulator stop after x number of instructions)
        type: int  default: 0
  --sim-stack-alignment (Stack alignment in bytes in simulator (4 or 8, 8 is default))
        type: int  default: 8
  --sim-stack-size (Stack size of the ARM64, MIPS64 and PPC64 simulator in kBytes (default is 2 MB))
        type: int  default: 2048
  --log-colour (When logging, try to use coloured output.)
        type: bool  default: true
  --trace-sim-messages (Trace simulator debug messages. Implied by --trace-sim.)
        type: bool  default: false
  --async-stack-traces (include async stack traces in Error.stack)
        type: bool  default: true
  --stack-trace-on-illegal (print stack trace when an illegal exception is thrown)
        type: bool  default: false
  --abort-on-uncaught-exception (abort program (dump core) when an uncaught exception is thrown)
        type: bool  default: false
  --correctness-fuzzer-suppressions (Suppress certain unspecified behaviors to ease correctness fuzzing: Abort program when the stack overflows or a string exceeds maximum length (as opposed to throwing RangeError). Use a fixed suppression string for error messages.)
        type: bool  default: false
  --randomize-hashes (randomize hashes to avoid predictable hash collisions (with snapshots this option cannot override the baked-in seed))
        type: bool  default: true
  --rehash-snapshot (rehash strings from the snapshot to override the baked-in seed)
        type: bool  default: true
  --hash-seed (Fixed seed to use to hash property keys (0 means random)(with snapshots this option cannot override the baked-in seed))
        type: uint64  default: 0
  --random-seed (Default seed for initializing random generator (0, the default, means to use system random).)
        type: int  default: 0
  --fuzzer-random-seed (Default seed for initializing fuzzer random generator (0, the default, means to use v8's random number generator seed).)
        type: int  default: 0
  --trace-rail (trace RAIL mode)
        type: bool  default: false
  --print-all-exceptions (print exception object and stack trace on each thrown exception)
        type: bool  default: false
  --detailed-error-stack-trace (includes arguments for each function call in the error stack frames array)
        type: bool  default: false
  --adjust-os-scheduling-parameters (adjust OS specific scheduling params for the isolate)
        type: bool  default: true
  --runtime-call-stats (report runtime call counts and times)
        type: bool  default: false
  --rcs (report runtime call counts and times)
        type: bool  default: false
  --rcs-cpu-time (report runtime times in cpu time (the default is wall time))
        type: bool  default: false
  --profile-deserialization (Print the time it takes to deserialize the snapshot.)
        type: bool  default: false
  --serialization-statistics (Collect statistics on serialized objects.)
        type: bool  default: false
  --serialization-chunk-size (Custom size for serialization chunks)
        type: uint  default: 4096
  --regexp-optimization (generate optimized regexp code)
        type: bool  default: true
  --regexp-mode-modifiers (enable inline flags in regexp.)
        type: bool  default: false
  --regexp-interpret-all (interpret all regexp code)
        type: bool  default: false
  --regexp-tier-up (enable regexp interpreter and tier up to the compiler after the number of executions set by the tier up ticks flag)
        type: bool  default: true
  --regexp-tier-up-ticks (set the number of executions for the regexp interpreter before tiering-up to the compiler)
        type: int  default: 1
  --regexp-peephole-optimization (enable peephole optimization for regexp bytecode)
        type: bool  default: true
  --trace-regexp-peephole-optimization (trace regexp bytecode peephole optimization)
        type: bool  default: false
  --trace-regexp-bytecodes (trace regexp bytecode execution)
        type: bool  default: false
  --trace-regexp-assembler (trace regexp macro assembler calls.)
        type: bool  default: false
  --trace-regexp-parser (trace regexp parsing)
        type: bool  default: false
  --trace-regexp-tier-up (trace regexp tiering up execution)
        type: bool  default: false
  --testing-bool-flag (testing_bool_flag)
        type: bool  default: true
  --testing-maybe-bool-flag (testing_maybe_bool_flag)
        type: maybe_bool  default: unset
  --testing-int-flag (testing_int_flag)
        type: int  default: 13
  --testing-float-flag (float-flag)
        type: float  default: 2.5
  --testing-string-flag (string-flag)
        type: string  default: Hello, world!
  --testing-prng-seed (Seed used for threading test randomness)
        type: int  default: 42
  --testing-d8-test-runner (test runner turns on this flag to enable a check that the function was prepared for optimization before marking it for optimization)
        type: bool  default: false
  --fuzzing (Fuzzers use this flag to signal that they are ... fuzzing. This causes intrinsics to fail silently (e.g. return undefined) on invalid usage.)
        type: bool  default: false
  --embedded-src (Path for the generated embedded data file. (mksnapshot only))
        type: string  default: nullptr
  --embedded-variant (Label to disambiguate symbols in embedded data file. (mksnapshot only))
        type: string  default: nullptr
  --startup-src (Write V8 startup as C++ src. (mksnapshot only))
        type: string  default: nullptr
  --startup-blob (Write V8 startup blob file. (mksnapshot only))
        type: string  default: nullptr
  --target-arch (The mksnapshot target arch. (mksnapshot only))
        type: string  default: nullptr
  --target-os (The mksnapshot target os. (mksnapshot only))
        type: string  default: nullptr
  --target-is-simulator (Instruct mksnapshot that the target is meant to run in the simulator and it can generate simulator-specific instructions. (mksnapshot only))
        type: bool  default: false
  --minor-mc-parallel-marking (use parallel marking for the young generation)
        type: bool  default: true
  --trace-minor-mc-parallel-marking (trace parallel marking for the young generation)
        type: bool  default: false
  --minor-mc (perform young generation mark compact GCs)
        type: bool  default: false
  --help (Print usage message, including flags, on console)
        type: bool  default: true
  --dump-counters (Dump counters on exit)
        type: bool  default: false
  --dump-counters-nvp (Dump counters as name-value pairs on exit)
        type: bool  default: false
  --use-external-strings (Use external strings for source code)
        type: bool  default: false
  --map-counters (Map counters to a file)
        type: string  default:
  --mock-arraybuffer-allocator (Use a mock ArrayBuffer allocator for testing.)
        type: bool  default: false
  --mock-arraybuffer-allocator-limit (Memory limit for mock ArrayBuffer allocator used to simulate OOM for testing.)
        type: size_t  default: 0
  --gdbjit (enable GDBJIT interface)
        type: bool  default: false
  --gdbjit-full (enable GDBJIT interface for all code objects)
        type: bool  default: false
  --gdbjit-dump (dump elf objects with debug info to disk)
        type: bool  default: false
  --gdbjit-dump-filter (dump only objects containing this substring)
        type: string  default:
  --log (Minimal logging (no API, code, GC, suspect, or handles samples).)
        type: bool  default: false
  --log-all (Log all events to the log file.)
        type: bool  default: false
  --log-api (Log API events to the log file.)
        type: bool  default: false
  --log-code (Log code events to the log file without profiling.)
        type: bool  default: false
  --log-handles (Log global handle events.)
        type: bool  default: false
  --log-suspect (Log suspect operations.)
        type: bool  default: false
  --log-source-code (Log source code.)
        type: bool  default: false
  --log-function-events (Log function events (parse, compile, execute) separately.)
        type: bool  default: false
  --prof (Log statistical profiling information (implies --log-code).)
        type: bool  default: false
  --detailed-line-info (Always generate detailed line information for CPU profiling.)
        type: bool  default: false
  --prof-sampling-interval (Interval for --prof samples (in microseconds).)
        type: int  default: 1000
  --prof-cpp (Like --prof, but ignore generated code.)
        type: bool  default: false
  --prof-browser-mode (Used with --prof, turns on browser-compatible mode for profiling.)
        type: bool  default: true
  --logfile (Specify the name of the log file.)
        type: string  default: v8.log
  --logfile-per-isolate (Separate log files for each isolate.)
        type: bool  default: true
  --ll-prof (Enable low-level linux profiler.)
        type: bool  default: false
  --gc-fake-mmap (Specify the name of the file for fake gc mmap used in ll_prof)
        type: string  default: /tmp/__v8_gc__
  --log-internal-timer-events (Time internal events.)
        type: bool  default: false
  --redirect-code-traces (output deopt information and disassembly into file code-<pid>-<isolate id>.asm)
        type: bool  default: false
  --redirect-code-traces-to (output deopt information and disassembly into the given file)
        type: string  default: nullptr
  --print-opt-source (print source code of optimized and inlined functions)
        type: bool  default: false
  --vtune-prof-annotate-wasm (Used when v8_enable_vtunejit is enabled, load wasm source map and provide annotate support (experimental).)
        type: bool  default: false
  --win64-unwinding-info (Enable unwinding info for Windows/x64)
        type: bool  default: true
  --interpreted-frames-native-stack (Show interpreted frames on the native stack (useful for external profilers).)
        type: bool  default: false
  --predictable (enable predictable mode)
        type: bool  default: false
  --predictable-gc-schedule (Predictable garbage collection schedule. Fixes heap growing, idle, and memory reducing behavior.)
        type: bool  default: false
  --single-threaded (disable the use of background tasks)
        type: bool  default: false
  --single-threaded-gc (disable the use of background gc tasks)
        type: bool  default: false
```

Particularly useful ones:

```
--async-stack-traces
```



/. 🚀 runtime/manual/references/contributing/release_schedule.md
===================================================

# Release Schedule

A new minor release for the `deno` cli is released every month, on the third
Thursday of the month.

See [Milestones on Deno's GitHub](https://github.com/denoland/deno/milestones)
for the upcoming releases.

There are usually two or three patch releases (done weekly) after a minor
releases; after that a merge window for new features opens for the upcoming
minor release.

Stable releases can be found on the
[GitHub releases page](https://github.com/denoland/deno/releases).

## Canary channel

In addition to the stable channel described above, canaries are released
multiple times daily (for each commit on main). You can upgrade to the latest
canary release by running:

```
deno upgrade --canary
```

To update to a specific canary, pass the commit hash in the `--version` option:

```
deno upgrade --canary --version=973af61d8bb03c1709f61e456581d58386ed4952
```

To switch back to the stable channel, run `deno upgrade`.

Canaries can be downloaded from https://dl.deno.land.



/. 🚀 runtime/manual/references/contributing/style_guide.md
===================================================

# Deno Style Guide

> ⚠️ Note that this is the style guide for **internal runtime code** in the Deno
> runtime, and in the Deno standard library. This is not meant as a general
> style guide for users of Deno.

## Copyright Headers

Most modules in the repository should have the following copyright header:

```ts
// Copyright 2018-2023 the Deno authors. All rights reserved. MIT license.
```

If the code originates elsewhere, ensure that the file has the proper copyright
headers. We only allow MIT, BSD, and Apache licensed code.

## Use underscores, not dashes in filenames.

Example: Use `file_server.ts` instead of `file-server.ts`.

## Add tests for new features.

Each module should contain or be accompanied by tests for its public
functionality.

## TODO Comments

TODO comments should usually include an issue or the author's github username in
parentheses. Example:

```ts
// TODO(ry): Add tests.
// TODO(#123): Support Windows.
// FIXME(#349): Sometimes panics.
```

## Meta-programming is discouraged. Including the use of Proxy.

Be explicit, even when it means more code.

There are some situations where it may make sense to use such techniques, but in
the vast majority of cases it does not.

## Inclusive code

Please follow the guidelines for inclusive code outlined at
https://chromium.googlesource.com/chromium/src/+/HEAD/styleguide/inclusive_code.md.

## Rust

Follow Rust conventions and be consistent with existing code.

## TypeScript

The TypeScript portion of the code base is the standard library `std`.

### Use TypeScript instead of JavaScript.

### Do not use the filename `index.ts`/`index.js`.

Deno does not treat "index.js" or "index.ts" in a special way. By using these
filenames, it suggests that they can be left out of the module specifier when
they cannot. This is confusing.

If a directory of code needs a default entry point, use the filename `mod.ts`.
The filename `mod.ts` follows Rust's convention, is shorter than `index.ts`, and
doesn't come with any preconceived notions about how it might work.

### Exported functions: max 2 args, put the rest into an options object.

When designing function interfaces, stick to the following rules.

1. A function that is part of the public API takes 0-2 required arguments, plus
   (if necessary) an options object (so max 3 total).

2. Optional parameters should generally go into the options object.

   An optional parameter that's not in an options object might be acceptable if
   there is only one, and it seems inconceivable that we would add more optional
   parameters in the future.

3. The 'options' argument is the only argument that is a regular 'Object'.

   Other arguments can be objects, but they must be distinguishable from a
   'plain' Object runtime, by having either:

   - a distinguishing prototype (e.g. `Array`, `Map`, `Date`, `class MyThing`).
   - a well-known symbol property (e.g. an iterable with `Symbol.iterator`).

   This allows the API to evolve in a backwards compatible way, even when the
   position of the options object changes.

```ts, ignore
// BAD: optional parameters not part of options object. (#2)
export function resolve(
  hostname: string,
  family?: "ipv4" | "ipv6",
  timeout?: number,
): IPAddress[] {}
```

```ts, ignore
// GOOD.
export interface ResolveOptions {
  family?: "ipv4" | "ipv6";
  timeout?: number;
}
export function resolve(
  hostname: string,
  options: ResolveOptions = {},
): IPAddress[] {}
```

```ts, ignore
export interface Environment {
  [key: string]: string;
}

// BAD: `env` could be a regular Object and is therefore indistinguishable
// from an options object. (#3)
export function runShellWithEnv(cmdline: string, env: Environment): string {}

// GOOD.
export interface RunShellOptions {
  env: Environment;
}
export function runShellWithEnv(
  cmdline: string,
  options: RunShellOptions,
): string {}
```

```ts
// BAD: more than 3 arguments (#1), multiple optional parameters (#2).
export function renameSync(
  oldname: string,
  newname: string,
  replaceExisting?: boolean,
  followLinks?: boolean,
) {}
```

```ts
// GOOD.
interface RenameOptions {
  replaceExisting?: boolean;
  followLinks?: boolean;
}
export function renameSync(
  oldname: string,
  newname: string,
  options: RenameOptions = {},
) {}
```

```ts
// BAD: too many arguments. (#1)
export function pwrite(
  fd: number,
  buffer: ArrayBuffer,
  offset: number,
  length: number,
  position: number,
) {}
```

```ts
// BETTER.
export interface PWrite {
  fd: number;
  buffer: ArrayBuffer;
  offset: number;
  length: number;
  position: number;
}
export function pwrite(options: PWrite) {}
```

Note: When one of the arguments is a function, you can adjust the order
flexibly. See examples like [Deno.serve](https://deno.land/api?s=Deno.serve),
[Deno.test](https://deno.land/api?s=Deno.test),
[Deno.addSignalListener](https://deno.land/api?s=Deno.addSignalListener). See
also [this post](https://twitter.com/jaffathecake/status/1646798390355697664).

### Export all interfaces that are used as parameters to an exported member

Whenever you are using interfaces that are included in the parameters or return
type of an exported member, you should export the interface that is used. Here
is an example:

```ts, ignore
// my_file.ts
export interface Person {
  name: string;
  age: number;
}

export function createPerson(name: string, age: number): Person {
  return { name, age };
}

// mod.ts
export { createPerson } from "./my_file.ts";
export type { Person } from "./my_file.ts";
```

### Minimize dependencies; do not make circular imports.

Although `std` has no external dependencies, we must still be careful to keep
internal dependencies simple and manageable. In particular, be careful not to
introduce circular imports.

### If a filename starts with an underscore: `_foo.ts`, do not link to it.

There may be situations where an internal module is necessary but its API is not
meant to be stable or linked to. In this case prefix it with an underscore. By
convention, only files in its own directory should import it.

### Use JSDoc for exported symbols.

We strive for complete documentation. Every exported symbol ideally should have
a documentation line.

If possible, use a single line for the JSDoc. Example:

```ts
/** foo does bar. */
export function foo() {
  // ...
}
```

It is important that documentation is easily human-readable, but there is also a
need to provide additional styling information to ensure generated documentation
is more rich text. Therefore JSDoc should generally follow markdown markup to
enrich the text.

While markdown supports HTML tags, it is forbidden in JSDoc blocks.

Code string literals should be braced with the back-tick (\`) instead of quotes.
For example:

```ts
/** Import something from the `deno` module. */
```

Do not document function arguments unless they are non-obvious of their intent
(though if they are non-obvious intent, the API should be considered anyways).
Therefore `@param` should generally not be used. If `@param` is used, it should
not include the `type` as TypeScript is already strongly-typed.

```ts
/**
 * Function with non-obvious param.
 * @param foo Description of non-obvious parameter.
 */
```

Vertical spacing should be minimized whenever possible. Therefore, single-line
comments should be written as:

```ts
/** This is a good single-line JSDoc. */
```

And not:

```ts
/**
 * This is a bad single-line JSDoc.
 */
```

Code examples should utilize markdown format, like so:

````ts
/** A straightforward comment and an example:
 * ```ts
 * import { foo } from "deno";
 * foo("bar");
 * ```
 */
````

Code examples should not contain additional comments and must not be indented.
It is already inside a comment. If it needs further comments, it is not a good
example.

### Resolve linting problems using directives

Currently, the building process uses `dlint` to validate linting problems in the
code. If the task requires code that is non-conformant to linter use
`deno-lint-ignore <code>` directive to suppress the warning.

```typescript
// deno-lint-ignore no-explicit-any
let x: any;
```

This ensures the continuous integration process doesn't fail due to linting
problems, but it should be used scarcely.

### Each module should come with a test module.

Every module with public functionality `foo.ts` should come with a test module
`foo_test.ts`. A test for a `std` module should go in `std/tests` due to their
different contexts; otherwise, it should just be a sibling to the tested module.

### Unit Tests should be explicit.

For a better understanding of the tests, function should be correctly named as
it's prompted throughout the test command. Like:

```
test myTestFunction ... ok
```

Example of test:

```ts, ignore
import { assertEquals } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";
import { foo } from "./mod.ts";

Deno.test("myTestFunction", function () {
  assertEquals(foo(), { bar: "bar" });
});
```

### Top-level functions should not use arrow syntax.

Top-level functions should use the `function` keyword. Arrow syntax should be
limited to closures.

Bad:

```ts
export const foo = (): string => {
  return "bar";
};
```

Good:

```ts
export function foo(): string {
  return "bar";
}
```

### `std`

#### Do not depend on external code.

`https://deno.land/std/` is intended to be baseline functionality that all Deno
programs can rely on. We want to guarantee to users that this code does not
include potentially unreviewed third-party code.

#### Document and maintain browser compatibility.

If a module is browser-compatible, include the following in the JSDoc at the top
of the module:

```ts
// This module is browser-compatible.
```

Maintain browser compatibility for such a module by either not using the global
`Deno` namespace or feature-testing for it. Make sure any new dependencies are
also browser compatible.

#### Prefer `#` over `private`

We prefer the private fields (`#`) syntax over `private` keyword of TypeScript
in the standard modules codebase. The private fields make the properties and
methods private even at runtime. On the other hand, `private` keyword of
TypeScript guarantee it private only at compile time and the fields are publicly
accessible at runtime.

Good:

```ts
class MyClass {
  #foo = 1;
  #bar() {}
}
```

Bad:

```ts
class MyClass {
  private foo = 1;
  private bar() {}
}
```

#### Naming convention

Use `camelCase` for functions, methods, fields, and local variables. Use
`PascalCase` for classes, types, interfaces, and enums. Use `UPPER_SNAKE_CASE`
for static top-level items, such as `string`, `number`, `bigint`, `boolean`,
`RegExp`, arrays of static items, records of static keys and values, etc.

Good:

```ts
function generateKey() {}

let currentValue = 0;

class KeyObject {}

type SharedKey = {};

enum KeyType {
  PublicKey,
  PrivateKey,
}

const KEY_VERSION = "1.0.0";

const KEY_MAX_LENGTH = 4294967295;

const KEY_PATTERN = /^[0-9a-f]+$/;
```

Bad:

```ts
function generate_key() {}

let current_value = 0;

function GenerateKey() {}

class keyObject {}

type sharedKey = {};

enum keyType {
  publicKey,
  privateKey,
}

const key_version = "1.0.0";

const key_maxLength = 4294967295;

const KeyPattern = /^[0-9a-f]+$/;
```

When the names are in `camelCase` or `PascalCase`, always follow the rules of
them even when the parts of them are acronyms.

Note: Web APIs use uppercase acronyms (`JSON`, `URL`, `URL.createObjectURL()`
etc.). Deno Standard Library does not follow this convention.

Good:

```ts
class HttpObject {
}
```

Bad:

```ts
class HTTPObject {
}
```

Good:

```ts
function convertUrl(url: URL) {
  return url.href;
}
```

Bad:

```ts
function convertURL(url: URL) {
  return url.href;
}
```



/. 🚀 runtime/manual/references/contributing/web_platform_tests.md
===================================================

# Web Platform Test

Deno uses a custom test runner for Web Platform Tests. It can be found at
`./tools/wpt.ts`.

## Running tests

> If you are on Windows, or your system does not support hashbangs, prefix all
> `./tools/wpt.ts` commands with
> `deno run --unstable --allow-write --allow-read --allow-net --allow-env --allow-run`.

Before attempting to run WPT tests for the first time, please run the WPT setup.
You must also run this command every time the `./test_util/wpt` submodule is
updated:

```shell
./tools/wpt.ts setup
```

To run all available web platform tests, run the following command:

```shell
./tools/wpt.ts run

# You can also filter which test files to run by specifying filters:
./tools/wpt.ts run -- streams/piping/general hr-time
```

The test runner will run each web platform test and record its status (failed or
ok). It will then compare this output to the expected output of each test as
specified in the `./tools/wpt/expectation.json` file. This file is a nested JSON
structure that mirrors the `./test_utils/wpt` directory. It describes for each
test file, if it should pass as a whole (all tests pass, `true`), if it should
fail as a whole (test runner encounters an exception outside of a test or all
tests fail, `false`), or which tests it expects to fail (a string array of test
case names).

## Updating enabled tests or expectations

You can update the `./tools/wpt/expectation.json` file manually by changing the
value of each of the test file entries in the JSON structure. The alternative
and preferred option is to have the WPT runner run all, or a filtered subset of
tests, and then automatically update the `expectation.json` file to match the
current reality. You can do this with the `./wpt.ts update` command. Example:

```shell
./tools/wpt.ts update -- hr-time
```

After running this command the `expectation.json` file will match the current
output of all the tests that were run. This means that running `wpt.ts run`
right after a `wpt.ts update` should always pass.

## Subcommands

### `setup`

Validate that your environment is configured correctly, or help you configure
it.

This will check that the python3 (or `python.exe` on Windows) is actually
Python 3.

You can specify the following flags to customize behaviour:

```
--rebuild
    Rebuild the manifest instead of downloading. This can take up to 3 minutes.

--auto-config
    Automatically configure /etc/hosts if it is not configured (no prompt will be shown).
```

### `run`

Run all tests like specified in `expectation.json`.

You can specify the following flags to customize behaviour:

```
--release
    Use the ./target/release/deno binary instead of ./target/debug/deno

--quiet
    Disable printing of `ok` test cases.

--json=<file>
    Output the test results as JSON to the file specified.
```

You can also specify exactly which tests to run by specifying one of more
filters after a `--`:

```
./tools/wpt.ts run -- hr-time streams/piping/general
```

### `update`

Update the `expectation.json` to match the current reality.

You can specify the following flags to customize behaviour:

```
--release
    Use the ./target/release/deno binary instead of ./target/debug/deno

--quiet
    Disable printing of `ok` test cases.

--json=<file>
    Output the test results as JSON to the file specified.
```

You can also specify exactly which tests to run by specifying one of more
filters after a `--`:

```
./tools/wpt.ts update -- hr-time streams/piping/general
```

## FAQ

### Upgrading the wpt submodule:

```shell
cd test_util/wpt/
git fetch origin
git checkout origin/epochs/daily
cd ../../
git add ./test_util/wpt
```

All contributors will need to rerun `./tools/wpt.ts setup` after this.

Since upgrading WPT usually requires updating the expectations to cover all
sorts of upstream changes, it's best to do that as a separate PR, rather than as
part of a PR that implements a fix or feature.



/. 🚀 runtime/manual/references/vscode_deno/index.md
===================================================

    curl -s -L https://docs.deno.com/runtime/manual/references/vscode_deno | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Using Visual Studio Code

In this section we are going to go into depth about developing Deno applications
using [Visual Studio Code](https://code.visualstudio.com/) and the official
[vscode_deno](https://marketplace.visualstudio.com/items?itemName=denoland.vscode-deno)
extension.

## Installing

The vscode extension integrates directly to the Deno CLI using the language
server protocol. This helps ensure that the information you get about your code
aligns to how that code will work when you try to run it under the Deno CLI.

The Deno extension is installed like other extensions in vscode, by browsing the
extensions in vscode and choosing to install the _Deno_ extension. Or if you
have vscode installed, you can view the extension
[via this link](vscode:extension/denoland.vscode-deno) and install it if you
haven't already done so.

Once you install the extension for the first time, you should receive a _splash_
page that welcomes you to the extension. (If you missed it, or want to see it
again, just use the _Deno: Welcome_ command from the command palette.)

## Configuring the extension

The following sections will detail out how to configure the extension to work
best for you and will cover most of the settings available.

### Deno enabling a workspace

We realize that not every project you might edit with vscode is a Deno project.
By default, vscode comes with a built-in TypeScript/JavaScript language service
which is used when editing TypeScript or JavaScript files.

In order to have support for Deno APIs as well as the ability to resolve modules
as the Deno CLI does, you need to enable Deno for the workspace. The most direct
way to do this is to use the _Deno: Initialize Workspace Configuration_ from the
vscode
[command palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette).
This will activate a helper which will ask if you want to also enable linting
and the Deno unstable APIs for the project. This command will instruct vscode to
store these settings in the workspace configuration (your workspace root
`.vscode/settings.json`). Once the helper is finished, you will get a
notification that Deno is setup for the project.

These settings (and other settings) are available via the vscode
[settings](https://code.visualstudio.com/docs/getstarted/userinterface#_settings)
panel. In the panel the setting is _Deno: Enable_ and when manually editing the
JSON, the setting is `deno.enable`.

> ⚠️ vscode has user and workspace settings. You probably don't want to enable
> Deno in the user settings, as then by default, every workspace will be Deno
> enabled.

When a project is enabled, the extension will get information directly from the
installed Deno CLI. The extension will also _mute_ the built-in
TypeScript/JavaScript extension.

### Partially Deno enabling a workspace

While vscode supports [Workspace Folders](#workspace-folders), they can be
challenging to configure and use. Because of this, the option _Deno: Enable
Paths_ has been introduced (or `"deno.enablePaths"` if manually editing). In a
given workspace (or workspace folder), sub-paths can be enabled for Deno, while
code outside those paths will be not be enabled and the vscode built-in
JavaScript/TypeScript language server will be used.

For example if you have a project like this:

```
project
├── worker
└── front_end
```

Where you only want to enabled the `worker` path (and its subpaths) to be Deno
enabled, you will want to add `./worker` to the list of _Deno: Enable Paths_ in
the configuration.

### Using linting

The same engine that provides the diagnostics when using `deno lint` can also be
used via the extension. By enabling the _Deno: Lint_ setting in the settings
panel (or `deno.lint` if editing settings in JSON) the editor should start to
display lint "warnings" in your code. See the [Linter](../../tools/linter.md)
section for more information on how to use the Deno linter.

### Using import maps

It is possible to use [import maps](../../basics/import_maps.md) in the editor.
The option _Deno: Import Map_ (or `deno.importMap` if manually editing) should
be set to the value of the import map file. If the path is a relative path, it
will be resolved relative to the root of the workspace.

### Using a configuration file

Typically a configuration file is not required for a Deno project. There are a
few scenarios though where it might be useful, and if you want to have the same
settings applied as when specifying the `--config` option on the command line,
the _Deno: Config_ option can be used (or `deno.config` if manually editing).

The Deno extension will also auto-identify and apply a `deno.jsonc` or
`deno.json` by looking in the workspace root for the configuration file and
applying it. Manually specifying a _Deno: Config_ option will override this
automatic behavior.

### Using formatting

The Deno CLI comes with a built-in formatter which can be accessed using
`deno fmt` but can also be configured to be used by vscode. _Deno_ should be on
the drop down list for the _Editor: Default formatter_ setting (or if you are
editing settings manually, it would be
`"editor.defaultFormatter": "denoland.vscode-deno"`).

See the [Code formatter](../../tools/formatter.md) for more information on how
to use the formatter.

### Setting a path to the Deno CLI

The extension looks for the Deno CLI executable in the host's `PATH`, but
sometimes that isn't desirable and the _Deno: Path_ can be set (or `deno.path`
if manually editing) to point to the Deno executable. If the path provided is
relative, it will be resolved relative to the root of the workspace.

## Import suggestions

When attempting to import a module, the extension will offer suggestions to
complete the import. Local relative files will be included in the suggestions,
plus also any cached remote files.

The extension supports registry auto-completions, where a remote
registry/website of modules can optionally provide metadata that allows a client
to _discover_ modules. By default, the extension will check hosts/origins to see
if they support suggestions, and if it does, the extension will prompt you to
see if you want to enable it. This behavior can be changed by unsetting _Deno >
Suggest > Imports: Auto Discover_ (or `deno.suggest.imports.autoDiscover` if
manually editing).

Individual hosts/origins can be enabled or disabled by editing the _Deno >
Suggest > Imports: Hosts_/`deno.suggest.imports.hosts` setting in the
appropriate `settings.json`.

## Caching remote modules

Deno supports remote modules and will fetch remote modules and store them
locally in a cache. When you do something like `deno run`, `deno test`,
`deno info` or `deno cache` on the command line, the Deno CLI will go and try to
fetch any remote modules and their dependencies and populate the cache.

While developing code in the editor, if the module is not in the cache, you will
get a diagnostic like _Uncached or missing remote URL:
"`https://deno.land/example/mod.ts`"_ for any missing remote modules. Deno will
not automatically try to cache the module, unless it is a completion from a
registry import suggestion (see above).

In addition to running a command on a command line, the extension provides ways
to cache dependencies within the editor. A missing dependency will have a _quick
fix_ which is to have Deno try to cache the dependency. Fixes can be accessed by
pressing <kbd>CTRL</kbd> <kbd>.</kbd> or <kbd>⌘</kbd> <kbd>.</kbd> when the
editor is positioned in the import specifier, or hovering over the specifier and
selecting _Quick Fix..._.

There is also the _Deno: Cache Dependencies_ command in the command palette
which will attempt to cache any dependencies of the module currently active in
the editor.

## Code lenses

The language server currently supports several code lenses (actionable
contextual information interspersed in the code) that allow you to get greater
insight into the code. Most are disabled by default, but can easily be enabled:

- _Deno > Code Lens: Implementations_/`deno.codeLens.implementations` - Provides
  a lens that will list out any implementations of an item elsewhere in the
  code.
- _Deno > Code Lens: References_/`deno.codeLens.references` - Provides a lens
  that will list out any references to an item elsewhere in the code.
- _Deno > Code Lens: References All
  Functions_/`deno.codeLens.referencesAllFunctions` - Provides a lens that will
  list out all references to all functions in the code. All functions are
  excluded from just _References_ mention above.

## Testing code lens

The Deno CLI includes a [built-in testing API](../../basics/testing/index.md)
available under `Deno.test`. The extension and language server have a code lens
enabled by default which provides the ability to run a test from within the
editor.

When you have a block of code that provides a test, like:

```ts
import { assert } from "https://deno.land/std@$STD_VERSION/assert/mod.ts";

Deno.test({
  name: "a test case",
  fn() {
    let someCondition = true;
    assert(someCondition);
  },
});
```

You will see a code lens like the following just above the test:

```
▶ Run Test
```

This is a link that if you click it, the extension will start up the Deno CLI to
run the test for you and display the output. Based on your other settings, the
extension will try to run your test with the same settings. If you need to
adjust the arguments provided when doing `deno test`, you can do so by setting
the `deno.codeLens.testArgs` setting.

The extension will also try to track if in the same module you destructure the
`Deno.test` function or assign it to a variable. So you can do something like
this and still have the code lens work:

```ts
const { test: denoTest } = Deno;

denoTest({
  name: "example test",
  fn() {},
});
```

If you want to disable this feature, you can do so by unsetting the _Deno >
CodeLens: Test_/`deno.codeLens.test` setting.

## Using the debugger

The extension provides integration with the built-in VSCode debugger. You can
generate a configuration by: going to `Run and Debug` panel, clicking
`create a launch.json file` and selecting `Deno` option from the available
debugger options.

By default, the configuration will use `--inspect-wait` flag if the configured
Deno version is greater than 1.29, or `--inspect-brk` for versions older than
1.29. This ensures that the debugger has a chance to connect to your program and
register all the breakpoints specified in the code.

## Tasks

The extension communicates directly to the language server, but for some
development tasks, you might want to execute the CLI directly. The extension
provides a task definition for allowing you to create tasks that execute the
`deno` CLI from within the editor.

### Deno CLI tasks

The template for the Deno CLI tasks has the following interface, which can be
configured in a `tasks.json` within your workspace:

```ts
interface DenoTaskDefinition {
  type: "deno";
  // This is the `deno` command to run (e.g. `run`, `test`, `cache`, etc.)
  command: string;
  // Additional arguments pass on the command line
  args?: string[];
  // The current working directory to execute the command
  cwd?: string;
  // Any environment variables that should be set when executing
  env?: Record<string, string>;
}
```

Several of the commands that are useful in the editor are configured as
templates and can be added to your workspace by select _Tasks: Configure Task_
in the command palette and searching for `deno` tasks.

And example of what a `deno run mod.ts` would look like in a `tasks.json`:

```json
{
  "version": "2.0.0",
  "tasks": [
    {
      "type": "deno",
      "command": "run",
      "args": [
        "mod.ts"
      ],
      "problemMatcher": [
        "$deno"
      ],
      "label": "deno: run"
    }
  ]
}
```

## Workspace folders

The Deno language server and this extension supports
[multi-root workspaces](https://code.visualstudio.com/docs/editor/multi-root-workspaces)
configuration, where certain settings can be applied to workspace folders within
a workspace.

When you add folders to your workspace and open the settings, you will have
access to the per folder settings. If you look at the `.vscode/settings.json` in
a folder, you will see a visual indication of what settings apply to folder,
versus those that come from the workspace configuration:

```json
{
    "deno.enable": false,
    "deno.lint": true,
    "deno.unstable": false
}
```

<!-- ![screenshot of the .vscode/setting.json configured as a workspace folder](../../images/workspace_folder_config.png) -->

### Workspace folder settings

These are the settings that can be set on a workspace folder. The rest of the
settings currently only apply to the workspace:

- `deno.enable` - Controls if the Deno Language Server is enabled. When enabled,
  the extension will disable the built-in vscode JavaScript and TypeScript
  language services, and will use the Deno language server instead. _boolean,
  default `false`_
- `deno.enablePaths` - Controls if the Deno Language Server is enabled for only
  specific paths of the workspace folder. Defaults to an empty list.
- `deno.codeLens.test` - Controls if the test code lens is enabled. _boolean,
  default `true`_
- `deno.codeLens.testArgs` - The list of arguments that are passed to
  `deno test` when activating a test code lens. _string array, default
  `["--allow-all"]`_

### Mixed-Deno projects

While you can use this feature to enable mixed-Deno projects, you might want to
consider
[partially Deno enabling a workspace](#partially-deno-enabling-a-workspace). But
with this feature, you can have a mixed Deno project, where some of the
workspace folders are Deno enabled and some are not. This is useful when
creating a project that might have a front-end component, where you want a
different configuration for that front end code.

In order to support this, you would create a new workspace (or add a folder to
an existing workspace) and in the settings configure one of the folders to have
`deno.enable` set to `true` and one set to `false`. Once you save the workspace
configuration, you notice that the Deno language server only applies diagnostics
to the enabled folders, while the other folder will use the built-in TypeScript
compiler of vscode to supply diagnostics for TypeScript and JavaScript files.

## Using a development container

Using a
[development container](https://code.visualstudio.com/docs/remote/containers)
with vscode is a great way to have an isolated development environment without
having to worry about having to install the Deno CLI on your local system.

To use development containers, you need to have a few
[prerequisites installed](https://code.visualstudio.com/docs/remote/containers#_installation):

- Docker Desktop
- Visual Studio Code or Visual Studio Code Insiders
- [Remote Development extension pack](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack)

The way a development container is configured is by having a `.devcontainer`
folder as part of the workspace with configuration information in the folder. If
you are opening a project that already contains a dev container with Deno, you
will be prompted to build the dev container and access the project under that.
Everything should "just work".

If you have an existing Deno project that you would like to add dev container
support to, you will want to execute the command _Remote-Containers: Add
Development Container Configuration Files..._ in the command palette and then
choose _Show All Definitions..._ and then search for the _Deno_ definition. This
will setup a baseline `.devcontainer` configuration for you that will install
the latest version of the Deno CLI in the container.

Once added, vscode will prompt if you want to open the project in a dev
container. If you choose to, vscode will build the development container and
re-open the workspace using the development container, which will have the Deno
CLI and the `vscode_deno` extension installed in it.

## Troubleshooting

The following sections cover challenges you might face when using the extension
and try to give likely causes.

### Errors/diagnostics like `An import path cannot end with a '.ts' extension.` or `Cannot find name 'Deno'.`

This is normally a situation where Deno is not enabled on a Deno project. If you
look at the source of the diagnostic you are probably going to see a `ts(2691)`.
The `ts` indicates that it is coming from the built-in TypeScript/JavaScript
engine in vscode. You will want to check that your configuration is set properly
and the _Deno: Enable_/`deno.enable` is true.

You can also check what the Deno language server thinks is your current active
configuration by using _Deno: Language Server Status_ from the command palette.
This will display a document from the language server with a section named
_Workspace Configuration_. This will provide you with what vscode is reporting
the configuration is to the language server.

Also check if the VSCode configuration called `enableProjectDiagnostics`,
located in **TypeScript › Tsserver › Experimental: Enable Project Diagnostics**
is **disabled**. This setting allows TypeScript language server to execute in
the background to check the entire project at once and Deno cannot disable its
behaviour so the errors keep showing even when all other settings are correctly
set.

If `"enable"` is set to `true` in there, and the error message still persists,
you might want to try restarting vscode, as the part of the extension that
"mutes" the built-in TypeScript diagnostics for files is not working as
designed. If the issue still persists after a restart, you may have encountered
a bug that we didn't expect and searching the issues and reporting a bug at
https://github.com/denoland/vscode_deno is the next step.



/. 🚀 runtime/manual/references/vscode_deno/testing_api.md
===================================================

# Testing API

The `vscode_deno` extension implements a client for the vscode
[Testing API](https://code.visualstudio.com/api/extension-guides/testing) and
when using a version of Deno that supports the testing API, tests in your
project will be displayed within your IDE for Deno enabled projects.

## Test display

When both the editor and the version of Deno support the testing API, the _Test
Explorer_ view will activate represented by a beaker icon, which will provide
you with a side panel of tests that have been discovered in your project.

Also, next to tests identified in the code, there will be decorations which
allow you to run and see the status of each test, as well as there will be
entries in the command palette for tests.

## Discovering tests

Currently, Deno will only discover tests that are part of the "known" modules
inside a workspace. A module becomes "known" when it is opened in the editor, or
another module which imports that module is "known" inside the editor.

In the future, tests will be discovered in a similar fashion to the way the
`deno test` subcommand discovers tests as part of the root of the workspace.

## Running tests

You can run tests from the Test Explorer view, from the decorations next to the
tests when viewing the test code, or via the command palette. You can also use
the filter function in the Text Explorer view to exclude certain tests from a
test run.

Currently, Deno only supports the "run" test capability. We will be adding a
debug run mode as well as a coverage run mode in the future. We will also be
integrating the benchmarking tests as a _tag_, so they can be run (or excluded)
from your test runs.

The Deno language server does not spin up a new CLI subprocess. It instead
spawns a new thread and JavaScript runtime per test module to execute the tests.

## Test output

Any `console.log()` that occurs in your tests will be sent to the test output
window within vscode.

When a test fails, the failure message, including the stack trace, will be
available when inspecting the test results in vscode.

## How tests are structured

Test will be displayed in the Test Explorer at the top level with the module
that contains the test. Inside the module will be all the tests that have been
discovered, and if you are using test steps, they will be included under the
test.

In most cases, the Deno language server will be able to statically identify
tests, but if you are generating tests dynamically, Deno may not be aware of
them until runtime. In these cases it may not be possible to filter these tests
out of a run, but they will be added to the explorer view as they are
encountered.

## Configuration

By default, tests are executed in a similar fashion to if you were to use
`deno test --allow-all` on the command line. These default arguments can be
changed by setting the _Deno > Testing: Args_ option in your user or workspace
settings (or `deno.testing.args` if you are configuring manually). Add
individual arguments here which you would have used with the `deno test`
subcommand.

Based on other settings that you have, those options will be automatically
merged into the "command line" used when running tests unless explicitly
provided in the _Deno > Testing: Args_ setting. For example if you have a _Deno:
Import Map_ (`deno.importMap`) set, the value of that will be used unless you
have provided an explicit `--import-map` value in the testing args setting.

## Known limitations and caveats

Because of the way the Deno test runner runs, it is not possible to exclude (or
explicitly include) a test step. While the vscode UI will allow you to do this,
by for example, choosing to run a specific test step, all test steps in that
test will be run (but vscode will not update the results for them). So if there
are other side effects in the test case, they may occur.



/. 🚀 runtime/manual/runtime/index.md
===================================================

# Runtime

Documentation for all runtime functions (Web APIs + `Deno` global) can be found
at [`/api`](https://deno.land/api) or with adding the _unstable_ APIs which are
enabled via the `--unstable` flag at
[`/api?unstable`](https://deno.land/api?unstable=true).

## Web Platform APIs

For APIs where a web standard already exists, like `fetch` for HTTP requests,
Deno uses these rather than inventing a new proprietary API.

For more details, view the chapter on
[Web Platform APIs](./web_platform_apis.md).

## `Deno` global

All APIs that are not web standard are contained in the global `Deno` namespace.
It has the APIs for reading from files, opening TCP sockets,
[serving HTTP](./http_server_apis.md), and executing subprocesses, etc.

For more details, view the chapter on [Built-in APIs](./builtin_apis.md).

The TypeScript definitions for the Deno namespaces can be found in the
[`lib.deno.ns.d.ts`](https://github.com/denoland/deno/blob/$CLI_VERSION/cli/tsc/dts/lib.deno.ns.d.ts)
file.



/. 🚀 runtime/manual/runtime/builtin_apis.md
===================================================

# Deno namespace APIs

The global Deno namespace contains APIs that are not web standard, including
APIs for reading from files, opening TCP sockets, serving HTTP, and executing
subprocesses, etc.

For a full list of Deno Built-in APIs, see the
[reference](https://deno.land/api?s=Deno). Below we highlight some of the most
important.

## Errors

The Deno runtime comes with [20 error classes](https://deno.land/api#Errors)
that can be raised in response to a number of conditions.

Some examples are:

```sh
Deno.errors.NotFound;
Deno.errors.WriteZero;
```

They can be used as below:

```ts
try {
  const file = await Deno.open("./some/file.txt");
} catch (error) {
  if (error instanceof Deno.errors.NotFound) {
    console.error("the file was not found");
  } else {
    // otherwise re-throw
    throw error;
  }
}
```

## File System

The Deno runtime comes with
[various functions for working with files and directories](https://deno.land/api#File_System).
You will need to use --allow-read and --allow-write permissions to gain access
to the file system.

Refer to the links below for code examples of how to use the file system
functions.

- [Reading files in several different ways](https://examples.deno.land/reading-files)
- [Reading files in streams](../../tutorials/file_server.md)
- [Reading a text file (`Deno.readTextFile`)](../../tutorials/read_write_files.md#reading-a-text-file)
- [Writing a text file (`Deno.writeTextFile`)](../../tutorials/read_write_files.md#writing-a-text-file)

## I/O

The Deno runtime comes with
[built-in functions for working with resources and I/O](https://deno.land/api#I/O).

Refer to the links below for code examples for common functions.

- [Closing resources (`Deno.close`)](https://doc.deno.land/deno/stable/~/Deno.close)
- [Seeking a certain position within the resource (`Deno.seek`)](https://doc.deno.land/deno/stable/~/Deno.seek)

## Network

The Deno runtime comes with
[built-in functions for dealing with connections to network ports](https://deno.land/api#Network).

Refer to the links below for code examples for common functions.

- [Connect to the hostname and port (`Deno.connect`)](https://doc.deno.land/deno/stable/~/Deno.connect)
- [Announcing on the local transport address (`Deno.listen`)](https://doc.deno.land/deno/stable/~/Deno.listen)

## Sub Process

The Deno runtime comes with
[built-in functions for spinning up subprocesses](https://deno.land/api#Sub_Process).

Refer to the links below for code samples of how to create a subprocess.

- [Creating a subprocess (`Deno.Command`)](../../tutorials/subprocess.md)



/. 🚀 runtime/manual/runtime/ffi_api.md
===================================================

# Foreign Function Interface

As of Deno 1.13 and later, the FFI (foreign function interface) API allows users
to call libraries written in native languages that support the C ABIs (C/C++,
Rust, Zig, V, etc.) using `Deno.dlopen`.

## Usage

Here's an example showing how to call a Rust function from Deno:

```rust
// add.rs
#[no_mangle]
pub extern "C" fn add(a: isize, b: isize) -> isize {
    a + b
}
```

Compile it to a C dynamic library (`libadd.so` on Linux):

```sh
rustc --crate-type cdylib add.rs
```

In C you can write it as:

```c
// add.c
int add(int a, int b) {
  return a + b;
}
```

And compile it:

```sh
// unix
cc -c -o add.o add.c
cc -shared -W -o libadd.so add.o
// Windows
cl /LD add.c /link /EXPORT:add
```

Calling the library from Deno:

```typescript
// ffi.ts

// Determine library extension based on
// your OS.
let libSuffix = "";
switch (Deno.build.os) {
  case "windows":
    libSuffix = "dll";
    break;
  case "darwin":
    libSuffix = "dylib";
    break;
  default:
    libSuffix = "so";
    break;
}

const libName = `./libadd.${libSuffix}`;
// Open library and define exported symbols
const dylib = Deno.dlopen(
  libName,
  {
    "add": { parameters: ["isize", "isize"], result: "isize" },
  } as const,
);

// Call the symbol `add`
const result = dylib.symbols.add(35, 34); // 69

console.log(`Result from external addition of 35 and 34: ${result}`);
```

Run with `--allow-ffi` and `--unstable` flag:

```sh
deno run --allow-ffi --unstable ffi.ts
```

## Non-blocking FFI

There are many use cases where users might want to run CPU-bound FFI functions
in the background without blocking other tasks on the main thread.

As of Deno 1.15, symbols can be marked `nonblocking` in `Deno.dlopen`. These
function calls will run on a dedicated blocking thread and will return a
`Promise` resolving to the desired `result`.

Example of executing expensive FFI calls with Deno:

```c
// sleep.c
#ifdef _WIN32
#include <Windows.h>
#else
#include <time.h>
#endif

int sleep(unsigned int ms) {
  #ifdef _WIN32
  Sleep(ms);
  #else
  struct timespec ts;
  ts.tv_sec = ms / 1000;
  ts.tv_nsec = (ms % 1000) * 1000000;
  nanosleep(&ts, NULL);
  #endif
}
```

Calling it from Deno:

```typescript
// nonblocking_ffi.ts
const library = Deno.dlopen(
  "./sleep.so",
  {
    sleep: {
      parameters: ["usize"],
      result: "void",
      nonblocking: true,
    },
  } as const,
);

library.symbols.sleep(500).then(() => console.log("After"));
console.log("Before");
```

Result:

```sh
$ deno run --allow-ffi --unstable unblocking_ffi.ts
Before
After
```

## Callbacks

Deno FFI API supports creating C callbacks from JavaScript functions for calling
back into Deno from dynamic libraries. An example of how callbacks are created
and used is as follows:

```typescript
// callback_ffi.ts
const library = Deno.dlopen(
  "./callback.so",
  {
    set_status_callback: {
      parameters: ["function"],
      result: "void",
    },
    start_long_operation: {
      parameters: [],
      result: "void",
    },
    check_status: {
      parameters: [],
      result: "void",
    },
  } as const,
);

const callback = new Deno.UnsafeCallback(
  {
    parameters: ["u8"],
    result: "void",
  } as const,
  (success: number) => {},
);

// Pass the callback pointer to dynamic library
library.symbols.set_status_callback(callback.pointer);
// Start some long operation that does not block the thread
library.symbols.start_long_operation();

// Later, trigger the library to check if the operation is done.
// If it is, this call will trigger the callback.
library.symbols.check_status();
```

If an `UnsafeCallback`'s callback function throws an error, the error will get
propagated up to the function that triggered the callback to be called (above,
that would be `check_status()`) and can be caught there. If a callback returning
a value throws then Deno will return 0 (null pointer for pointers) as the
result.

`UnsafeCallback` is not deallocated by default as it can cause use-after-free
bugs. To properly dispose of an `UnsafeCallback` its `close()` method must be
called.

```typescript
const callback = new Deno.UnsafeCallback(
  { parameters: [], result: "void" } as const,
  () => {},
);

// After callback is no longer needed
callback.close();
// It is no longer safe to pass the callback as a parameter.
```

It is also possible for native libraries to setup interrupt handlers and to have
those directly trigger the callback. However, this is not recommended and may
cause unexpected side-effects and undefined behaviour. Preferably any interrupt
handlers would only set a flag that can later be polled similarly to how
`check_status()` is used above.

## Supported types

Here's a list of types supported currently by the Deno FFI API.

| FFI Type               | Deno                 | C                        | Rust                      |
| ---------------------- | -------------------- | ------------------------ | ------------------------- |
| `i8`                   | `number`             | `char` / `signed char`   | `i8`                      |
| `u8`                   | `number`             | `unsigned char`          | `u8`                      |
| `i16`                  | `number`             | `short int`              | `i16`                     |
| `u16`                  | `number`             | `unsigned short int`     | `u16`                     |
| `i32`                  | `number`             | `int` / `signed int`     | `i32`                     |
| `u32`                  | `number`             | `unsigned int`           | `u32`                     |
| `i64`                  | `number \| bigint`   | `long long int`          | `i64`                     |
| `u64`                  | `number \| bigint`   | `unsigned long long int` | `u64`                     |
| `usize`                | `number \| bigint`   | `size_t`                 | `usize`                   |
| `isize`                | `number \| bigint`   | `size_t`                 | `isize`                   |
| `f32`                  | `number \| bigint`   | `float`                  | `f32`                     |
| `f64`                  | `number \| bigint`   | `double`                 | `f64`                     |
| `void`[1]              | `undefined`          | `void`                   | `()`                      |
| `pointer`              | `{} \| null`         | `void *`                 | `*mut c_void`             |
| `buffer`[2]            | `TypedArray \| null` | `uint8_t *`              | `*mut u8`                 |
| `function`[3]          | `{} \| null`         | `void (*fun)()`          | `Option<extern "C" fn()>` |
| `{ struct: [...] }`[4] | `TypedArray`         | `struct MyStruct`        | `MyStruct`                |

As of Deno 1.25, the `pointer` type has been split into a `pointer` and a
`buffer` type to ensure users take advantage of optimizations for Typed Arrays,
and as of Deno 1.31 the JavaScript representation of `pointer` has become an
opaque pointer object or `null` for null pointers.

- [1] `void` type can only be used as a result type.
- [2] `buffer` type accepts TypedArrays as parameter, but it always returns a
  pointer object or `null` when used as result type like the `pointer` type.
- [3] `function` type works exactly the same as the `pointer` type as a
  parameter and result type.
- [4] `struct` type is for passing and returning C structs by value (copy). The
  `struct` array must enumerate each of the struct's fields' type in order. The
  structs are padded automatically: Packed structs can be defined by using an
  appropriate amount of `u8` fields to avoid padding. Only TypedArrays are
  supported as structs, and structs are always returned as `Uint8Array`s.

## deno_bindgen

[`deno_bindgen`](https://github.com/denoland/deno_bindgen) is the official tool
to simplify glue code generation of Deno FFI libraries written in Rust.

It is similar to [`wasm-bindgen`](https://github.com/rustwasm/wasm-bindgen) in
the Rust WASM ecosystem.

Here's an example showing its usage:

```rust
// mul.rs
use deno_bindgen::deno_bindgen;

#[deno_bindgen]
struct Input {
  a: i32,
  b: i32,
}

#[deno_bindgen]
fn mul(input: Input) -> i32 {
  input.a * input.b
}
```

Run `deno_bindgen` to generate bindings. You can now directly import them into
Deno:

```ts, ignore
// mul.ts
import { mul } from "./bindings/bindings.ts";
mul({ a: 10, b: 2 }); // 20
```

Any issues related to `deno_bindgen` should be reported at
https://github.com/denoland/deno_bindgen/issues



/. 🚀 runtime/manual/runtime/http_server_apis.md
===================================================

# HTTP Server APIs

Deno currently has two HTTP Server APIs:

- [`Deno.serve`](https://deno.land/api?s=Deno.serve): native, _higher-level_,
  supports HTTP/1.1 and HTTP2, this is the preferred API to write HTTP servers
  in Deno.
- [`Deno.serveHttp`](https://deno.land/api?s=Deno.serveHttp): native,
  _low-level_, supports HTTP/1.1 and HTTP2.
- [A "Hello World" server](#a-hello-world-server)
- [Inspecting the incoming request](#inspecting-the-incoming-request)
- [Responding with a response](#responding-with-a-response)
- [HTTPS support](#https-support)
- [HTTP/2 support](#http2-support)
- [Serving WebSockets](#serving-websockets)

### A "Hello World" server

To start a HTTP server on a given port, you can use the `Deno.serve` function.
This function takes a handler function that will be called for each incoming
request, and is expected to return a response (or a promise resolving to a
response).

Here is an example of a server that returns a "Hello, World!" response for each
request:

```ts
Deno.serve((_req) => {
  return new Response("Hello, World!");
});
```

> ℹ️ The handler can also return a `Promise<Response>`, which means it can be an
> `async` function.

By default `Deno.serve` will listen on port `8000`, but this can be changed by
passing in a port number in options bag as the first or second argument:

```js
// To listen on port 4242.
Deno.serve({ port: 4242 }, handler);

// To listen on port 4242 and bind to 0.0.0.0.
Deno.serve({ port: 4242, hostname: "0.0.0.0", handler });
```

### Inspecting the incoming request

Most servers will not answer with the same response for every request. Instead
they will change their answer depending on various aspects of the request: the
HTTP method, the headers, the path, or the body contents.

The request is passed in as the first argument to the handler function. Here is
an example showing how to extract various parts of the request:

```ts
Deno.serve(async (req) => {
  console.log("Method:", req.method);

  const url = new URL(req.url);
  console.log("Path:", url.pathname);
  console.log("Query parameters:", url.searchParams);

  console.log("Headers:", req.headers);

  if (req.body) {
    const body = await req.text();
    console.log("Body:", body);
  }

  return new Response("Hello, World!");
});
```

> ⚠️ Be aware that the `req.text()` call can fail if the user hangs up the
> connection before the body is fully received. Make sure to handle this case.
> Do note this can happen in all methods that read from the request body, such
> as `req.json()`, `req.formData()`, `req.arrayBuffer()`,
> `req.body.getReader().read()`, `req.body.pipeTo()`, etc.

### Responding with a response

Most servers also do not respond with "Hello, World!" to every request. Instead
they might respond with different headers, status codes, and body contents (even
body streams).

Here is an example of returning a response with a 404 status code, a JSON body,
and a custom header:

```ts
Deno.serve((req) => {
  const body = JSON.stringify({ message: "NOT FOUND" });
  return new Response(body, {
    status: 404,
    headers: {
      "content-type": "application/json; charset=utf-8",
    },
  });
});
```

Response bodies can also be streams. Here is an example of a response that
returns a stream of "Hello, World!" repeated every second:

```ts
Deno.serve((req) => {
  let timer: number;
  const body = new ReadableStream({
    async start(controller) {
      timer = setInterval(() => {
        controller.enqueue("Hello, World!\n");
      }, 1000);
    },
    cancel() {
      clearInterval(timer);
    },
  });
  return new Response(body.pipeThrough(new TextEncoderStream()), {
    headers: {
      "content-type": "text/plain; charset=utf-8",
    },
  });
});
```

> ℹ️ Note the `cancel` function here. This is called when the client hangs up the
> connection. This is important to make sure that you handle this case, as
> otherwise the server will keep queuing up messages forever, and eventually run
> out of memory.

> ⚠️ Beware that the response body stream is "cancelled" when the client hangs up
> the connection. Make sure to handle this case. This can surface itself as an
> error in a `write()` call on a `WritableStream` object that is attached to the
> response body `ReadableStream` object (for example through a
> `TransformStream`).

### HTTPS support

> ℹ️ To use HTTPS, you will need a valid TLS certificate and a private key for
> your server.

To use HTTPS, pass two extra arguments in the options bag: `cert` and `key`.
These are contents of the certificate and key files, respectively.

```js
Deno.serve({
  port: 443,
  cert: Deno.readTextFileSync("./cert.pem"),
  key: Deno.readTextFileSync("./key.pem"),
}, handler);
```

### HTTP/2 support

HTTP/2 support is "automatic" when using the HTTP server APIs with Deno. You
just need to create your server, and the server will handle HTTP/1 or HTTP/2
requests seamlessly.

HTTP/2 is also supported over cleartext with prior knowledge.

### Automatic body compression

The HTTP server has built in automatic compression of response bodies. When a
response is sent to a client, Deno determines if the response body can be safely
compressed. This compression happens within the internals of Deno, so it is fast
and efficient.

Currently Deno supports gzip and brotli compression. A body is automatically
compressed if the following conditions are true:

- The request has an
  [`Accept-Encoding`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Encoding)
  header which indicates the requester supports `br` for Brotli or `gzip`. Deno
  will respect the preference of the
  [quality value](https://developer.mozilla.org/en-US/docs/Glossary/Quality_values)
  in the header.
- The response includes a
  [`Content-Type`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type)
  which is considered compressible. (The list is derived from
  [`jshttp/mime-db`](https://github.com/jshttp/mime-db/blob/master/db.json) with
  the actual list
  [in the code](https://github.com/denoland/deno/blob/v1.21.0/ext/http/compressible.rs).)
- The response body is greater than 64 bytes.

When the response body is compressed, Deno will set the Content-Encoding header
to reflect the encoding as well as ensure the Vary header is adjusted or added
to indicate what request headers affected the response.

When is compression skipped? In addition to the logic above, there are a few
other reasons why a response won’t be compressed automatically:

- The response contains a `Content-Encoding` header. This indicates your server
  has done some form of encoding already.
- The response contains a
  [`Content-Range`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Range)
  header. This indicates that your server is responding to a range request,
  where the bytes and ranges are negotiated outside of the control of the
  internals to Deno.
- The response has a
  [`Cache-Control`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control)
  header which contains a
  [`no-transform`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control#other)
  value. This indicates that your server doesn’t want Deno or any downstream
  proxies to modify the response.

## `Deno.serveHttp`

We generally recommend that you use the `Deno.serve` API described above, as it
handles all of the intricacies of parallel requests on a single connection,
error handling, and so on. However, if you are interested creating your own
robust and performant web servers in Deno, lower-level, _native_ HTTP server
APIs are available as of Deno 1.9 and later.

> ⚠️ You should probably not be using this API, as it is not easy to get right.
> Use the `Deno.serve` API instead.

### Listening for a connection

In order to accept requests, first you need to listen for a connection on a
network port. To do this in Deno, you use `Deno.listen()`:

```ts
const server = Deno.listen({ port: 8080 });
```

> ℹ️ When supplying a port, Deno assumes you are going to listen on a TCP socket
> as well as bind to the localhost. You can specify `transport: "tcp"` to be
> more explicit as well as provide an IP address or hostname in the `hostname`
> property as well.

If there is an issue with opening the network port, `Deno.listen()` will throw,
so often in a server sense, you will want to wrap it in the `try ... catch`
block in order to handle exceptions, like the port already being in use.

You can also listen for a TLS connection (e.g. HTTPS) using `Deno.listenTls()`:

```ts
const server = Deno.listenTls({
  port: 8443,
  certFile: "localhost.crt",
  keyFile: "localhost.key",
  alpnProtocols: ["h2", "http/1.1"],
});
```

The `certFile` and `keyFile` options are required and point to the appropriate
certificate and key files for the server. They are relative to the CWD for Deno.
The `alpnProtocols` property is optional, but if you want to be able to support
HTTP/2 on the server, you add the protocols here, as the protocol negotiation
happens during the TLS negotiation with the client and server.

> ℹ️ Generating SSL certificates is outside of the scope of this documentation.
> There are many resources on the web which address this.

### Handling connections

Once we are listening for a connection, we need to handle the connection. The
return value of `Deno.listen()` or `Deno.listenTls()` is a `Deno.Listener` which
is an async iterable which yields up `Deno.Conn` connections as well as provide
a couple methods for handling connections.

To use it as an async iterable we would do something like this:

```ts
const server = Deno.listen({ port: 8080 });

for await (const conn of server) {
  // ...handle the connection...
}
```

Every connection made would yield up a `Deno.Conn` assigned to `conn`. Then
further processing can be applied to the connection.

There is also the `.accept()` method on the listener which can be used:

```ts
const server = Deno.listen({ port: 8080 });

while (true) {
  try {
    const conn = await server.accept();
    // ... handle the connection ...
  } catch (err) {
    // The listener has closed
    break;
  }
}
```

Whether using the async iterator or the `.accept()` method, exceptions can be
thrown and robust production code should handle these using `try ... catch`
blocks. Especially when it comes to accepting TLS connections, there can be many
conditions, like invalid or unknown certificates which can be surfaced on the
listener and might need handling in the user code.

A listener also has a `.close()` method which can be used to close the listener.

### Serving HTTP

Once a connection is accepted, you can use `Deno.serveHttp()` to handle HTTP
requests and responses on the connection. `Deno.serveHttp()` returns a
`Deno.HttpConn`. A `Deno.HttpConn` is like a `Deno.Listener` in that requests
the connection receives from the client are asynchronously yielded up as a
`Deno.RequestEvent`.

To deal with HTTP requests as async iterable it would look something like this:

```ts
const server = Deno.listen({ port: 8080 });

for await (const conn of server) {
  (async () => {
    const httpConn = Deno.serveHttp(conn);
    for await (const requestEvent of httpConn) {
      // ... handle requestEvent ...
    }
  })();
}
```

The `Deno.HttpConn` also has the method `.nextRequest()` which can be used to
await the next request. It would look something like this:

```ts
const server = Deno.listen({ port: 8080 });

while (true) {
  try {
    const conn = await server.accept();
    (async () => {
      const httpConn = Deno.serveHttp(conn);
      while (true) {
        try {
          const requestEvent = await httpConn.nextRequest();
          // ... handle requestEvent ...
        } catch (err) {
          // the connection has finished
          break;
        }
      }
    })();
  } catch (err) {
    // The listener has closed
    break;
  }
}
```

Note that in both cases we are using an IIFE to create an inner function to deal
with each connection. If we awaited the HTTP requests in the same function scope
as the one we were receiving the connections, we would be blocking accepting
additional connections, which would make it seem that our server was "frozen".
In practice, it might make more sense to have a separate function all together:

```ts
async function handle(conn: Deno.Conn) {
  const httpConn = Deno.serveHttp(conn);
  for await (const requestEvent of httpConn) {
    // ... handle requestEvent
  }
}

const server = Deno.listen({ port: 8080 });

for await (const conn of server) {
  handle(conn);
}
```

In the examples from this point on, we will focus on what would occur within an
example `handle()` function and remove the listening and connection
"boilerplate".

#### HTTP Requests and Responses

HTTP requests and responses in Deno are essentially the inverse of web standard
[Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API). The
Deno HTTP Server API and the Fetch API leverage the
[`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request) and
[`Response`](https://developer.mozilla.org/en-US/docs/Web/API/Response) object
classes. So if you are familiar with the Fetch API you just need to flip them
around in your mind and now it is a server API.

As mentioned above, a `Deno.HttpConn` asynchronously yields up
`Deno.RequestEvent`s. These request events contain a `.request` property and a
`.respondWith()` method.

The `.request` property is an instance of the `Request` class with the
information about the request. For example, if we wanted to know what URL path
was being requested, we would do something like this:

```ts
async function handle(conn: Deno.Conn) {
  const httpConn = Deno.serveHttp(conn);
  for await (const requestEvent of httpConn) {
    const url = new URL(requestEvent.request.url);
    console.log(`path: ${url.pathname}`);
  }
}
```

The `.respondWith()` method is how we complete a request. The method takes
either a `Response` object or a `Promise` which resolves with a `Response`
object. Responding with a basic "hello world" would look like this:

```ts
async function handle(conn: Deno.Conn) {
  const httpConn = Deno.serveHttp(conn);
  for await (const requestEvent of httpConn) {
    await requestEvent.respondWith(
      new Response("hello world", {
        status: 200,
      }),
    );
  }
}
```

Note that we awaited the `.respondWith()` method. It isn't required, but in
practice any errors in processing the response will cause the promise returned
from the method to be rejected, like if the client disconnected before all the
response could be sent. While there may not be anything your application needs
to do, not handling the rejection will cause an "unhandled rejection" to occur
which will terminate the Deno process, which isn't so good for a server. In
addition, you might want to await the promise returned in order to determine
when to do any cleanup from for the request/response cycle.

The web standard `Response` object is pretty powerful, allowing easy creation of
complex and rich responses to a client, and Deno strives to provide a `Response`
object that as closely matches the web standard as possible, so if you are
wondering how to send a particular response, checkout the documentation for the
web standard
[`Response`](https://developer.mozilla.org/en-US/docs/Web/API/Response).

### HTTP/2 Support

HTTP/2 support is effectively transparent within the Deno runtime. Typically
HTTP/2 is negotiated between a client and a server during the TLS connection
setup via
[ALPN](https://en.wikipedia.org/wiki/Application-Layer_Protocol_Negotiation). To
enable this, you need to provide the protocols you want to support when you
start listening via the `alpnProtocols` property. This will enable the
negotiation to occur when the connection is made. For example:

```ts
const server = Deno.listenTls({
  port: 8443,
  certFile: "localhost.crt",
  keyFile: "localhost.key",
  alpnProtocols: ["h2", "http/1.1"],
});
```

The protocols are provided in order of preference. In practice, the only two
protocols that are supported currently are HTTP/2 and HTTP/1.1 which are
expressed as `h2` and `http/1.1`.

Currently Deno does not support upgrading a plain-text HTTP/1.1 connection to an
HTTP/2 cleartext connection via the `Upgrade` header (see:
[#10275](https://github.com/denoland/deno/issues/10275)), so therefore HTTP/2
support is only available via a TLS/HTTPS connection.

### Serving WebSockets

Deno can upgrade incoming HTTP requests to a WebSocket. This allows you to
handle WebSocket endpoints on your HTTP servers.

To upgrade an incoming `Request` to a WebSocket you use the
`Deno.upgradeWebSocket` function. This returns an object consisting of a
`Response` and a web standard `WebSocket` object. The returned response should
be used to respond to the incoming request using the `respondWith` method. Only
once `respondWith` is called with the returned response, the WebSocket is
activated and can be used.

Because the WebSocket protocol is symmetrical, the `WebSocket` object is
identical to the one that can be used for client side communication.
Documentation for it can be found
[on MDN](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket).

> Note: We are aware that this API can be challenging to use, and are planning
> to switch to
> [`WebSocketStream`](https://github.com/ricea/websocketstream-explainer/blob/master/README.md)
> once it is stabilized and ready for use.

```ts
async function handle(conn: Deno.Conn) {
  const httpConn = Deno.serveHttp(conn);
  for await (const requestEvent of httpConn) {
    await requestEvent.respondWith(handleReq(requestEvent.request));
  }
}

function handleReq(req: Request): Response {
  const upgrade = req.headers.get("upgrade") || "";
  if (upgrade.toLowerCase() != "websocket") {
    return new Response("request isn't trying to upgrade to websocket.");
  }
  const { socket, response } = Deno.upgradeWebSocket(req);
  socket.onopen = () => console.log("socket opened");
  socket.onmessage = (e) => {
    console.log("socket message:", e.data);
    socket.send(new Date().toString());
  };
  socket.onerror = (e) => console.log("socket errored:", e);
  socket.onclose = () => console.log("socket closed");
  return response;
}
```

WebSockets are only supported on HTTP/1.1 for now. The connection the WebSocket
was created on can not be used for HTTP traffic after a WebSocket upgrade has
been performed.



/. 🚀 runtime/manual/runtime/import_meta_api.md
===================================================

# `import.meta` API

Deno supports a number of methods on the
[`import.meta`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/import.meta)
API:

- `import.meta.url`: returns the URL of the current module.
- `import.meta.main`: returns whether the current module is the entry point to
  your program.
- `import.meta.resolve`: resolve specifiers relative to the current module.

## `import.meta.resolve` Example

```ts
const worker = new Worker(import.meta.resolve("./worker.ts"));
```

The `import.meta.resolve` API takes into account the currently applied import
map, which gives you the ability to resolve "bare" specifiers as well.

With such import map loaded...

```json
{
  "imports": {
    "fresh": "https://deno.land/x/fresh@1.0.1/dev.ts"
  }
}
```

...you can now resolve:

```js
// resolve.js
console.log(import.meta.resolve("fresh"));
```

```sh
$ deno run resolve.js
https://deno.land/x/fresh@1.0.1/dev.ts
```



/. 🚀 runtime/manual/runtime/location_api.md
===================================================

# Location API

Deno supports the
[`location`](https://developer.mozilla.org/en-US/docs/Web/API/Window/location)
global from the web. Please read on.

## Location flag

There is no "web page" whose URL we can use for a location in a Deno process. We
instead allow users to emulate a document location by specifying one on the CLI
using the `--location` flag. It can be a `http` or `https` URL.

```ts
// deno run --location https://example.com/path main.ts

console.log(location.href);
// "https://example.com/path"
```

You must pass `--location <href>` for this to work. If you don't, any access to
the `location` global will throw an error.

```ts
// deno run main.ts

console.log(location.href);
// error: Uncaught ReferenceError: Access to "location", run again with --location <href>.
```

Setting `location` or any of its fields will normally cause navigation in
browsers. This is not applicable in Deno, so it will throw in this situation.

```ts
// deno run --location https://example.com/path main.ts

location.pathname = "./foo";
// error: Uncaught NotSupportedError: Cannot set "location.pathname".
```

## Extended usage

On the web, resource resolution (excluding modules) typically uses the value of
`location.href` as the root on which to base any relative URLs. This affects
some web APIs adopted by Deno.

### Fetch API

```ts
// deno run --location https://api.github.com/ --allow-net main.ts

const response = await fetch("./orgs/denoland");
// Fetches "https://api.github.com/orgs/denoland".
```

The `fetch()` call above would throw if the `--location` flag was not passed,
since there is no web-analogous location to base it onto.

### Worker modules

```ts
// deno run --location https://example.com/index.html --allow-net main.ts

const worker = new Worker("./workers/hello.ts", { type: "module" });
// Fetches worker module at "https://example.com/workers/hello.ts".
```

## Only use if necessary

For the above use cases, it is preferable to pass URLs in full rather than
relying on `--location`. You can manually base a relative URL using the `URL`
constructor if needed.

The `--location` flag is intended for those who have some specific purpose in
mind for emulating a document location and are aware that this will only work at
application-level. However, you may also use it to silence errors from a
dependency which is frivolously accessing the `location` global.



/. 🚀 runtime/manual/runtime/permission_apis.md
===================================================

# Permission APIs

Permissions are granted from the CLI when running the `deno` command. User code
will often assume its own set of required permissions, but there is no guarantee
during execution that the set of _granted_ permissions will align with this.

In some cases, ensuring a fault-tolerant program requires a way to interact with
the permission system at runtime.

## Permission descriptors

On the CLI, read permission for `/foo/bar` is represented as
`--allow-read=/foo/bar`. In runtime JS, it is represented as the following:

```ts
const desc = { name: "read", path: "/foo/bar" } as const;
```

Other examples:

```ts
// Global write permission.
const desc1 = { name: "write" } as const;

// Write permission to `$PWD/foo/bar`.
const desc2 = { name: "write", path: "foo/bar" } as const;

// Global net permission.
const desc3 = { name: "net" } as const;

// Net permission to 127.0.0.1:8000.
const desc4 = { name: "net", host: "127.0.0.1:8000" } as const;

// High-resolution time permission.
const desc5 = { name: "hrtime" } as const;
```

> ⚠️ See
> [`PermissionDescriptor`](https://deno.land/api?s=Deno.PermissionDescriptor) in
> API reference for more details.

> ⚠️ In 1.30 and onwards, synchronous API counterparts (ex.
> `Deno.permissions.querySync`) exist for all the APIs described below.

## Query permissions

Check, by descriptor, if a permission is granted or not.

```ts
// deno run --allow-read=/foo main.ts

const desc1 = { name: "read", path: "/foo" } as const;
console.log(await Deno.permissions.query(desc1));
// PermissionStatus { state: "granted", partial: false }

const desc2 = { name: "read", path: "/foo/bar" } as const;
console.log(await Deno.permissions.query(desc2));
// PermissionStatus { state: "granted", partial: false }

const desc3 = { name: "read", path: "/bar" } as const;
console.log(await Deno.permissions.query(desc3));
// PermissionStatus { state: "prompt", partial: false }
```

If `--deny-read` flag was used to restrict some of the filepaths, the result
will contain `partial: true` describing that not all subpaths have permissions
granted:

```ts
// deno run --allow-read=/foo --deny-read=/foo/bar main.ts

const desc1 = { name: "read", path: "/foo" } as const;
console.log(await Deno.permissions.query(desc1));
// PermissionStatus { state: "granted", partial: true }

const desc2 = { name: "read", path: "/foo/bar" } as const;
console.log(await Deno.permissions.query(desc2));
// PermissionStatus { state: "denied", partial: false }

const desc3 = { name: "read", path: "/bar" } as const;
console.log(await Deno.permissions.query(desc3));
// PermissionStatus { state: "prompt", partial: false }
```

## Permission states

A permission state can be either "granted", "prompt" or "denied". Permissions
which have been granted from the CLI will query to `{ state: "granted" }`. Those
which have not been granted query to `{ state: "prompt" }` by default, while
`{ state: "denied" }` reserved for those which have been explicitly refused.
This will come up in [Request permissions](#request-permissions).

## Permission strength

The intuitive understanding behind the result of the second query in
[Query permissions](#query-permissions) is that read access was granted to
`/foo` and `/foo/bar` is within `/foo` so `/foo/bar` is allowed to be read. This
hold true, unless the CLI-granted permission is _partial_ to the queried
permissions (as an effect of using a `--deny-*` flag).

We can also say that `desc1` is
_[stronger than](https://www.w3.org/TR/permissions/#ref-for-permissiondescriptor-stronger-than)_
`desc2`. This means that for any set of CLI-granted permissions:

1. If `desc1` queries to `{ state: "granted", partial: false }` then so must
   `desc2`.
2. If `desc2` queries to `{ state: "denied", partial: false }` then so must
   `desc1`.

More examples:

```ts
const desc1 = { name: "write" } as const;
// is stronger than
const desc2 = { name: "write", path: "/foo" } as const;

const desc3 = { name: "net", host: "127.0.0.1" } as const;
// is stronger than
const desc4 = { name: "net", host: "127.0.0.1:8000" } as const;
```

## Request permissions

Request an ungranted permission from the user via CLI prompt.

```ts
// deno run main.ts

const desc1 = { name: "read", path: "/foo" } as const;
const status1 = await Deno.permissions.request(desc1);
// ⚠️ Deno requests read access to "/foo". Grant? [y/n (y = yes allow, n = no deny)] y
console.log(status1);
// PermissionStatus { state: "granted", partial: false }

const desc2 = { name: "read", path: "/bar" } as const;
const status2 = await Deno.permissions.request(desc2);
// ⚠️ Deno requests read access to "/bar". Grant? [y/n (y = yes allow, n = no deny)] n
console.log(status2);
// PermissionStatus { state: "denied", partial: false }
```

If the current permission state is "prompt", a prompt will appear on the user's
terminal asking them if they would like to grant the request. The request for
`desc1` was granted so its new status is returned and execution will continue as
if `--allow-read=/foo` was specified on the CLI. The request for `desc2` was
denied so its permission state is downgraded from "prompt" to "denied".

If the current permission state is already either "granted" or "denied", the
request will behave like a query and just return the current status. This
prevents prompts both for already granted permissions and previously denied
requests.

## Revoke permissions

Downgrade a permission from "granted" to "prompt".

```ts
// deno run --allow-read=/foo main.ts

const desc = { name: "read", path: "/foo" } as const;
console.log(await Deno.permissions.revoke(desc));
// PermissionStatus { state: "prompt", partial: false }
```

What happens when you try to revoke a permission which is _partial_ to one
granted on the CLI?

```ts
// deno run --allow-read=/foo main.ts

const desc = { name: "read", path: "/foo/bar" } as const;
console.log(await Deno.permissions.revoke(desc));
// PermissionStatus { state: "prompt", partial: false }
const cliDesc = { name: "read", path: "/foo" } as const;
console.log(await Deno.permissions.revoke(cliDesc));
// PermissionStatus { state: "prompt", partial: false }
```

The CLI-granted permission, which implies the revoked permission, was also
revoked.

To understand this behaviour, imagine that Deno stores an internal set of
_explicitly granted permission descriptors_. Specifying `--allow-read=/foo,/bar`
on the CLI initializes this set to:

```ts
[
  { name: "read", path: "/foo" },
  { name: "read", path: "/bar" },
];
```

Granting a runtime request for `{ name: "write", path: "/foo" }` updates the set
to:

```ts
[
  { name: "read", path: "/foo" },
  { name: "read", path: "/bar" },
  { name: "write", path: "/foo" },
];
```

Deno's permission revocation algorithm works by removing every element from this
set which is _stronger than_ the argument permission descriptor.

Deno does not allow "fragmented" permission states, where some strong permission
is granted with exclusions of weak permissions implied by it. Such a system
would prove increasingly complex and unpredictable as you factor in a wider
variety of use cases and the `"denied"` state. This is a calculated trade-off of
granularity for security.



/. 🚀 runtime/manual/runtime/program_lifecycle.md
===================================================

# Program Lifecycle

Deno supports browser compatible lifecycle events:

- [`load`](https://developer.mozilla.org/en-US/docs/Web/API/Window/load_event#:~:text=The%20load%20event%20is%20fired,for%20resources%20to%20finish%20loading.):
  fired when the whole page has loaded, including all dependent resources such
  as stylesheets and images.
- [`beforeunload`](https://developer.mozilla.org/en-US/docs/Web/API/Window/beforeunload_event#:~:text=The%20beforeunload%20event%20is%20fired,want%20to%20leave%20the%20page.):
  fired when the event loop has no more work to do and is about to exit.
  Scheduling more asynchronous work (like timers or network requests) will cause
  the program to continue.
- [`unload`](https://developer.mozilla.org/en-US/docs/Web/API/Window/unload_event):
  fired when the document or a child resource is being unloaded.
- [`unhandledrejection`](https://developer.mozilla.org/en-US/docs/Web/API/Window/unhandledrejection_event):
  fired when a promise that has no rejection handler is rejected, ie. a promise
  that has no `.catch()` handler or a second argument to `.then()`.

You can use these events to provide setup and cleanup code in your program.

Listeners for `load` events can be asynchronous and will be awaited, this event
cannot be canceled. Listeners for `beforeunload` need to be synchronous and can
be cancelled to keep the program running. Listeners for `unload` events need to
be synchronous and cannot be cancelled.

## Example

**main.ts**

```ts, ignore
import "./imported.ts";

const handler = (e: Event): void => {
  console.log(`got ${e.type} event in event handler (main)`);
};

globalThis.addEventListener("load", handler);

globalThis.addEventListener("beforeunload", handler);

globalThis.addEventListener("unload", handler);

globalThis.onload = (e: Event): void => {
  console.log(`got ${e.type} event in onload function (main)`);
};

globalThis.onbeforeunload = (e: Event): void => {
  console.log(`got ${e.type} event in onbeforeunload function (main)`);
};

globalThis.onunload = (e: Event): void => {
  console.log(`got ${e.type} event in onunload function (main)`);
};

console.log("log from main script");
```

**imported.ts**

```ts, ignore
const handler = (e: Event): void => {
  console.log(`got ${e.type} event in event handler (imported)`);
};

globalThis.addEventListener("load", handler);
globalThis.addEventListener("beforeunload", handler);
globalThis.addEventListener("unload", handler);

globalThis.onload = (e: Event): void => {
  console.log(`got ${e.type} event in onload function (imported)`);
};

globalThis.onbeforeunload = (e: Event): void => {
  console.log(`got ${e.type} event in onbeforeunload function (imported)`);
};

globalThis.onunload = (e: Event): void => {
  console.log(`got ${e.type} event in onunload function (imported)`);
};

console.log("log from imported script");
```

A couple notes on this example:

- `addEventListener` and `onload`/`onunload` are prefixed with `globalThis`, but
  you could also use `self` or no prefix at all.
  [It is not recommended to use `window` as a prefix](https://lint.deno.land/#no-window-prefix).
- You can use `addEventListener` and/or `onload`/`onunload` to define handlers
  for events. There is a major difference between them, let's run the example:

```shell
$ deno run main.ts
log from imported script
log from main script
got load event in event handler (imported)
got load event in event handler (main)
got load event in onload function (main)
got onbeforeunload event in event handler (imported)
got onbeforeunload event in event handler (main)
got onbeforeunload event in onbeforeunload function (main)
got unload event in event handler (imported)
got unload event in event handler (main)
got unload event in onunload function (main)
```

All listeners added using `addEventListener` were run, but `onload`,
`onbeforeunload` and `onunload` defined in `main.ts` overrode handlers defined
in `imported.ts`.

In other words, you can use `addEventListener` to register multiple `"load"` or
`"unload"` event handlers, but only the last defined `onload`, `onbeforeunload`,
`onunload` event handlers will be executed. It is preferable to use
`addEventListener` when possible for this reason.

## `beforeunload` Example

```js
// beforeunload.js
let count = 0;

console.log(count);

globalThis.addEventListener("beforeunload", (e) => {
  console.log("About to exit...");
  if (count < 4) {
    e.preventDefault();
    console.log("Scheduling more work...");
    setTimeout(() => {
      console.log(count);
    }, 100);
  }

  count++;
});

globalThis.addEventListener("unload", (e) => {
  console.log("Exiting");
});

count++;
console.log(count);

setTimeout(() => {
  count++;
  console.log(count);
}, 100);
```

Running this program will print:

```sh
$ deno run beforeunload.js
0
1
2
About to exit...
Scheduling more work...
3
About to exit...
Scheduling more work...
4
About to exit...
Exiting
```

This has allowed us to polyfill `process.on("beforeExit")` in the Node
compatibility layer.

## `unhandledrejection` event Example:

This release adds support for the unhandledrejection event. This event is fired
when a promise that has no rejection handler is rejected, ie. a promise that has
no .catch() handler or a second argument to .then().

```js
// unhandledrejection.js
globalThis.addEventListener("unhandledrejection", (e) => {
  console.log("unhandled rejection at:", e.promise, "reason:", e.reason);
  e.preventDefault();
});

function Foo() {
  this.bar = Promise.reject(new Error("bar not available"));
}

new Foo();
Promise.reject();
```

Running this program will print:

```sh
$ deno run unhandledrejection.js
unhandled rejection at: Promise {
  <rejected> Error: bar not available
    at new Foo (file:///dev/unhandled_rejection.js:7:29)
    at file:///dev/unhandled_rejection.js:10:1
} reason: Error: bar not available
    at new Foo (file:///dev/unhandled_rejection.js:7:29)
    at file:///dev/unhandled_rejection.js:10:1
unhandled rejection at: Promise { <rejected> undefined } reason: undefined
```

This API will allow us to polyfill `process.on("unhandledRejection")` in the
Node compatibility layer in future releases.



/. 🚀 runtime/manual/runtime/stability.md
===================================================

# Stability

As of Deno 1.0.0, the `Deno` namespace APIs are stable. That means we will
strive to make code working under 1.0.0 continue to work in future versions.

However, not all of Deno's features are ready for production yet. Features which
are not ready, because they are still in draft phase, are locked behind the
`--unstable` command line flag.

```shell
deno run --unstable mod_which_uses_unstable_stuff.ts
```

Passing this flag does a few things:

- It enables the use of unstable APIs during runtime.
- It adds the
  [`lib.deno.unstable.d.ts`](https://doc.deno.land/https://raw.githubusercontent.com/denoland/deno/main/cli/tsc/dts/lib.deno.unstable.d.ts)
  file to the list of TypeScript definitions that are used for type checking.
  This includes the output of `deno types`.

You should be aware that many unstable APIs have **not undergone a security
review**, are likely to have **breaking API changes** in the future, and are
**not ready for production**.

## Standard modules

Deno's standard modules (https://deno.land/std) are not yet stable. We currently
version the standard modules differently from the CLI to reflect this. Note that
unlike the `Deno` namespace, the use of the standard modules do not require the
`--unstable` flag (unless the standard module itself makes use of an unstable
Deno feature).



/. 🚀 runtime/manual/runtime/web_platform_apis.md
===================================================

# Using Web Platform APIs

One way Deno simplifies web and cloud development is by using Web Platform APIs
(like `fetch`) over proprietary APIs. This means if you've ever built for the
browser, you're likely already familiar with Deno, and if you're learning Deno,
you're also investing in your knowledge of the web.

## Supported APIs

Here's a partial list of supported web platform APIs in Deno:

- [Blob](https://developer.mozilla.org/en-US/docs/Web/API/Blob)
- [BroadcastChannel](https://developer.mozilla.org/en-US/docs/Web/API/BroadcastChannel)
- [Cache](https://developer.mozilla.org/en-US/docs/Web/API/Cache)
- [Channel Messaging API](https://developer.mozilla.org/en-US/docs/Web/API/Channel_Messaging_API)
- [Compression Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Compression_Streams_API)
- [Console](https://developer.mozilla.org/en-US/docs/Web/API/Console)
- [DOM APIs](https://deno.land/api@v1.26.0#DOM_APIs)
- [DOM `CustomEvent`, `EventTarget` and `EventListener`](#customevent-eventtarget-and-eventlistener)
- [Encoding API](https://developer.mozilla.org/en-US/docs/Web/API/Encoding_API)
- [Fetch API](#fetch-api)
- [`FormData`](https://developer.mozilla.org/en-US/docs/Web/API/FormData)
- [Location API](./location_api.md)
- [`navigator.language` API](https://developer.mozilla.org/en-US/docs/Web/API/Navigator/language)
- [Performance API](https://developer.mozilla.org/en-US/docs/Web/API/Performance)
- [`setTimeout`, `setInterval`, `clearInterval`](https://developer.mozilla.org/en-US/docs/Web/API/setTimeout)
- [Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API)
- [`URL`](https://developer.mozilla.org/en-US/docs/Web/API/URL)
- [`URLPattern`](https://developer.mozilla.org/en-US/docs/Web/API/URLPattern)
- [`URLSearchParams`](https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams)
- [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API)
- [Web File API](https://developer.mozilla.org/en-US/docs/Web/API/File_API)
- [Web Storage API](./web_storage_api.md)
- [Web Workers API](https://developer.mozilla.org/en-US/docs/Web/API/Worker)
- [`WebSocket`](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)

You can find the Deno reference for these APIs [here](https://deno.land/api). To
check if a Web Platform API is available in Deno, click on
[the interface on MDN](https://developer.mozilla.org/en-US/docs/Web/API#interfaces)
and refer to
[its Browser Compatibility table](https://developer.mozilla.org/en-US/docs/Web/API/AbortController#browser_compatibility)
(link as an example).

## `fetch` API

## Overview

The `fetch` API can be used to make HTTP requests. It is implemented as
specified in the [WHATWG `fetch` spec](https://fetch.spec.whatwg.org/).

You can find documentation about this API on
[MDN](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).

## Spec deviations

- The Deno user agent does not have a cookie jar. As such, the `set-cookie`
  header on a response is not processed, or filtered from the visible response
  headers.
- Deno does not follow the same-origin policy, because the Deno user agent
  currently does not have the concept of origins, and it does not have a cookie
  jar. This means Deno does not need to protect against leaking authenticated
  data cross origin. Because of this Deno does not implement the following
  sections of the WHATWG `fetch` specification:
  - Section `3.1. 'Origin' header`.
  - Section `3.2. CORS protocol`.
  - Section `3.5. CORB`.
  - Section `3.6. 'Cross-Origin-Resource-Policy' header`.
  - `Atomic HTTP redirect handling`.
  - The `opaqueredirect` response type.
- A `fetch` with a `redirect` mode of `manual` will return a `basic` response
  rather than an `opaqueredirect` response.
- The specification is vague on how
  [`file:` URLs are to be handled](https://fetch.spec.whatwg.org/#scheme-fetch).
  Firefox is the only mainstream browser that implements fetching `file:` URLs,
  and even then it doesn't work by default. As of Deno 1.16, Deno supports
  fetching local files. See the next section for details.
- The `request` and `response` header guards are implemented, but unlike
  browsers do not have any constraints on which header names are allowed.
- The `referrer`, `referrerPolicy`, `mode`, `credentials`, `cache`, `integrity`,
  `keepalive`, and `window` properties and their relevant behaviours in
  `RequestInit` are not implemented. The relevant fields are not present on the
  `Request` object.
- Request body upload streaming is supported (on HTTP/1.1 and HTTP/2). Unlike
  the current fetch proposal, the implementation supports duplex streaming.
- The `set-cookie` header is not concatenated when iterated over in the
  `headers` iterator. This behaviour is in the
  [process of being specified](https://github.com/whatwg/fetch/pull/1346).

## Fetching local files

As of Deno 1.16, Deno supports fetching `file:` URLs. This makes it easier to
write code that uses the same code path on a server as local, as well as easier
to author code that works both with the Deno CLI and Deno Deploy.

Deno only supports absolute file URLs, this means that `fetch("./some.json")`
will not work. It should be noted though that if
[`--location`](./location_api.md) is specified, relative URLs use the
`--location` as the base, but a `file:` URL cannot be passed as the
`--location`.

To be able to fetch some resource, relative to the current module, which would
work if the module is local or remote, you would want to use `import.meta.url`
as the base. For example, something like:

```js
const response = await fetch(new URL("./config.json", import.meta.url));
const config = await response.json();
```

Notes on fetching local files:

- Permissions are applied to reading resources, so an appropriate `--allow-read`
  permission is needed to be able to read a local file.
- Fetching locally only supports the `GET` method, and will reject the promise
  with any other method.
- A file that does not exist simply rejects the promise with a vague
  `TypeError`. This is to avoid the potential of fingerprinting attacks.
- No headers are set on the response. Therefore it is up to the consumer to
  determine things like the content type or content length.
- Response bodies are streamed from the Rust side, so large files are available
  in chunks, and can be cancelled.

## `CustomEvent`, `EventTarget` and `EventListener`

## Overview

The DOM Event API can be used to dispatch and listen to events happening in an
application. It is implemented as specified in the
[WHATWG DOM spec](https://dom.spec.whatwg.org/#events).

You can find documentation about this API on
[MDN](https://developer.mozilla.org/en-US/docs/Web/API/EventTarget).

## Spec deviations

- Events do not bubble, because Deno does not have a DOM hierarchy, so there is
  no tree for Events to bubble/capture through.
- `timeStamp` property is always set to `0`.

---

## Typings

The TypeScript definitions for the implemented web APIs can be found in the
[`lib.deno.shared_globals.d.ts`](https://github.com/denoland/deno/blob/$CLI_VERSION/cli/dts/lib.deno.shared_globals.d.ts)
and
[`lib.deno.window.d.ts`](https://github.com/denoland/deno/blob/$CLI_VERSION/cli/dts/lib.deno.window.d.ts)
files.

Definitions that are specific to workers can be found in the
[`lib.deno.worker.d.ts`](https://github.com/denoland/deno/blob/$CLI_VERSION/cli/dts/lib.deno.worker.d.ts)
file.

## Deviations of other APIs from spec

### Cache API

Only the following APIs are implemented:

- [CacheStorage::open()](https://developer.mozilla.org/en-US/docs/Web/API/CacheStorage/open)
- [CacheStorage::has()](https://developer.mozilla.org/en-US/docs/Web/API/CacheStorage/has)
- [CacheStorage::delete()](https://developer.mozilla.org/en-US/docs/Web/API/CacheStorage/delete)
- [Cache::match()](https://developer.mozilla.org/en-US/docs/Web/API/Cache/match)
- [Cache::put()](https://developer.mozilla.org/en-US/docs/Web/API/Cache/put)
- [Cache::delete()](https://developer.mozilla.org/en-US/docs/Web/API/Cache/delete)

A few things that are different compared to browsers:

1. You cannot pass relative paths to the APIs. The request can be an instance of
   Request or URL or a url string.
2. `match()` & `delete()` don't support query options yet.



/. 🚀 runtime/manual/runtime/web_storage_api.md
===================================================

# Web Storage API

Deno 1.10 introduced the
[Web Storage API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API)
which provides an API for storing string keys and values. Persisting data works
similar to a browser, and has a 10MB storage limit. The global `sessionStorage`
object only persists data for the current execution context, while
`localStorage` persists data from execution to execution.

In a browser, `localStorage` persists data uniquely per origin (effectively the
protocol plus hostname plus port). As of Deno 1.16, Deno has a set of rules to
determine what is a unique storage location:

- When using the `--location` flag, the origin for the location is used to
  uniquely store the data. That means a location of `http://example.com/a.ts`
  and `http://example.com/b.ts` and `http://example.com:80/` would all share the
  same storage, but `https://example.com/` would be different.
- If there is no location specifier, but there is a `--config` configuration
  file specified, the absolute path to that configuration file is used. That
  means `deno run --config deno.jsonc a.ts` and
  `deno run --config deno.jsonc b.ts` would share the same storage, but
  `deno run --config tsconfig.json a.ts` would be different.
- If there is no configuration or location specifier, Deno uses the absolute
  path to the main module to determine what storage is shared. The Deno REPL
  generates a "synthetic" main module that is based off the current working
  directory where `deno` is started from. This means that multiple invocations
  of the REPL from the same path will share the persisted `localStorage` data.

This means, unlike versions prior to 1.16, `localStorage` is always available in
the main process.

## Example

The following snippet accesses the local storage bucket for the current origin
and adds a data item to it using `setItem()`.

```ts
localStorage.setItem("myDemo", "Deno App");
```

The syntax for reading the localStorage item is as follows:

```ts
const cat = localStorage.getItem("myDemo");
```

The syntax for removing the localStorage item is as follows:

```ts
localStorage.removeItem("myDemo");
```

The syntax for removing all the localStorage items is as follows:

```ts
localStorage.clear();
```



/. 🚀 runtime/manual/runtime/workers.md
===================================================

# Workers

Deno supports
[`Web Worker API`](https://developer.mozilla.org/en-US/docs/Web/API/Worker/Worker).

Workers can be used to run code on multiple threads. Each instance of `Worker`
is run on a separate thread, dedicated only to that worker.

Currently Deno supports only `module` type workers; thus it's essential to pass
the `type: "module"` option when creating a new worker.

Use of relative module specifiers in the main worker are only supported with
`--location <href>` passed on the CLI. This is not recommended for portability.
You can instead use the `URL` constructor and `import.meta.url` to easily create
a specifier for some nearby script. Dedicated workers, however, have a location
and this capability by default.

```ts
// Good
new Worker(new URL("./worker.js", import.meta.url).href, { type: "module" });

// Bad
new Worker(new URL("./worker.js", import.meta.url).href);
new Worker(new URL("./worker.js", import.meta.url).href, { type: "classic" });
new Worker("./worker.js", { type: "module" });
```

As with regular modules, you can use top-level `await` in worker modules.
However, you should be careful to always register the message handler before the
first `await`, since messages can be lost otherwise. This is not a bug in Deno,
it's just an unfortunate interaction of features, and it also happens in all
browsers that support module workers.

```ts, ignore
import { delay } from "https://deno.land/std@$STD_VERSION/async/delay.ts";

// First await: waits for a second, then continues running the module.
await delay(1000);

// The message handler is only set after that 1s delay, so some of the messages
// that reached the worker during that second might have been fired when no
// handler was registered.
self.onmessage = (evt) => {
  console.log(evt.data);
};
```

## Instantiation permissions

Creating a new `Worker` instance is similar to a dynamic import; therefore Deno
requires appropriate permission for this action.

For workers using local modules; `--allow-read` permission is required:

**main.ts**

```ts
new Worker(new URL("./worker.ts", import.meta.url).href, { type: "module" });
```

**worker.ts**

```ts
console.log("hello world");
self.close();
```

```shell
$ deno run main.ts
error: Uncaught PermissionDenied: read access to "./worker.ts", run again with the --allow-read flag

$ deno run --allow-read main.ts
hello world
```

For workers using remote modules; `--allow-net` permission is required:

**main.ts**

```ts
new Worker("https://example.com/worker.ts", { type: "module" });
```

**worker.ts** (at https://example.com/worker.ts)

```ts
console.log("hello world");
self.close();
```

```shell
$ deno run main.ts
error: Uncaught PermissionDenied: net access to "https://example.com/worker.ts", run again with the --allow-net flag

$ deno run --allow-net main.ts
hello world
```

## Using Deno in worker

> Starting in v1.22 the `Deno` namespace is available in worker scope by
> default. To enable the namespace in earlier versions pass
> `deno: { namespace: true }` when creating a new worker.

**main.js**

```js
const worker = new Worker(new URL("./worker.js", import.meta.url).href, {
  type: "module",
});

worker.postMessage({ filename: "./log.txt" });
```

**worker.js**

```js, ignore
self.onmessage = async (e) => {
  const { filename } = e.data;
  const text = await Deno.readTextFile(filename);
  console.log(text);
  self.close();
};
```

**log.txt**

```
hello world
```

```shell
$ deno run --allow-read main.js
hello world
```

> Starting in v1.23 `Deno.exit()` no longer exits the process with the provided
> exit code. Instead is an alias to `self.close()`, which causes only the worker
> to shutdown. This better aligns with the Web platform, as there is no way in
> the browser for a worker to close the page.

## Specifying worker permissions

> This is an unstable Deno feature. Learn more about
> [unstable features](./stability.md).

The permissions available for the worker are analogous to the CLI permission
flags, meaning every permission enabled there can be disabled at the level of
the Worker API. You can find a more detailed description of each of the
permission options [here](../basics/permissions.md).

By default a worker will inherit permissions from the thread it was created in,
however in order to allow users to limit the access of this worker we provide
the `deno.permissions` option in the worker API.

- For permissions that support granular access you can pass in a list of the
  desired resources the worker will have access to, and for those who only have
  the on/off option you can pass true/false respectively.

  ```ts
  const worker = new Worker(new URL("./worker.js", import.meta.url).href, {
    type: "module",
    deno: {
      permissions: {
        net: [
          "deno.land",
        ],
        read: [
          new URL("./file_1.txt", import.meta.url),
          new URL("./file_2.txt", import.meta.url),
        ],
        write: false,
      },
    },
  });
  ```

- Granular access permissions receive both absolute and relative routes as
  arguments, however take into account that relative routes will be resolved
  relative to the file the worker is instantiated in, not the path the worker
  file is currently in

  ```ts
  const worker = new Worker(
    new URL("./worker/worker.js", import.meta.url).href,
    {
      type: "module",
      deno: {
        permissions: {
          read: [
            "/home/user/Documents/deno/worker/file_1.txt",
            "./worker/file_2.txt",
          ],
        },
      },
    },
  );
  ```

- Both `deno.permissions` and its children support the option `"inherit"`, which
  implies it will borrow its parent permissions.

  ```ts
  // This worker will inherit its parent permissions
  const worker = new Worker(new URL("./worker.js", import.meta.url).href, {
    type: "module",
    deno: {
      permissions: "inherit",
    },
  });
  ```

  ```ts
  // This worker will inherit only the net permissions of its parent
  const worker = new Worker(new URL("./worker.js", import.meta.url).href, {
    type: "module",
    deno: {
      permissions: {
        env: false,
        hrtime: false,
        net: "inherit",
        ffi: false,
        read: false,
        run: false,
        write: false,
      },
    },
  });
  ```

- Not specifying the `deno.permissions` option or one of its children will cause
  the worker to inherit by default.

  ```ts
  // This worker will inherit its parent permissions
  const worker = new Worker(new URL("./worker.js", import.meta.url).href, {
    type: "module",
  });
  ```

  ```ts
  // This worker will inherit all the permissions of its parent BUT net
  const worker = new Worker(new URL("./worker.js", import.meta.url).href, {
    type: "module",
    deno: {
      permissions: {
        net: false,
      },
    },
  });
  ```

- You can disable the permissions of the worker all together by passing `"none"`
  to the `deno.permissions` option.

  ```ts
  // This worker will not have any permissions enabled
  const worker = new Worker(new URL("./worker.js", import.meta.url).href, {
    type: "module",
    deno: {
      permissions: "none",
    },
  });
  ```



/. 🚀 runtime/manual/runtime/webassembly/index.md
===================================================

# Using WebAssembly

Designed to be used alongside JavaScript to speed up key application components,
[WebAssembly](https://webassembly.org/) can have much higher, and more
consistent execution speed than JavaScript, similar to C, C++, or Rust. Deno can
execute WebAssembly modules with the same interfaces that
[browsers provide](https://developer.mozilla.org/en-US/docs/WebAssembly).

In this chapter we will discuss:

1. [Using WebAssembly in Deno](./using_wasm.md)
2. [Using the Streaming WebAssembly APIs](./using_streaming_wasm.md)
3. [Helpful Resources](./wasm_resources.md)



/. 🚀 runtime/manual/runtime/webassembly/using_streaming_wasm.md
===================================================

# Using the Streaming WebAssembly APIs

The
[most efficient](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WebAssembly/instantiateStreaming)
way to fetch, compile and instantiate a WebAssembly module is to use the
streaming variants of the WebAssembly API. For example, you can use
`instantiateStreaming` combined with `fetch` to perform all three steps in one
go:

```ts
const { instance, module } = await WebAssembly.instantiateStreaming(
  fetch("https://wpt.live/wasm/incrementer.wasm"),
);

const increment = instance.exports.increment as (input: number) => number;
console.log(increment(41));
```

Note that the `.wasm` file must be served with the `application/wasm` MIME type.
If you want to do additional work on the module before instantiation you can
instead use `compileStreaming`:

```ts
const module = await WebAssembly.compileStreaming(
  fetch("https://wpt.live/wasm/incrementer.wasm"),
);

/* do some more stuff */

const instance = await WebAssembly.instantiate(module);
instance.exports.increment as (input: number) => number;
```

If for some reason you cannot make use of the streaming methods you can fall
back to the less efficient `compile` and `instantiate` methods. See for example
the
[MDN docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WebAssembly/instantiate).
For a more in-depth look on what makes the streaming methods more performant,
see for example
[this post](https://hacks.mozilla.org/2018/01/making-webassembly-even-faster-firefoxs-new-streaming-and-tiering-compiler/).



/. 🚀 runtime/manual/runtime/webassembly/using_wasm.md
===================================================

# Using WebAssembly in Deno

To run WebAssembly in Deno, all you need is a binary to run. WebAssembly is a
binary data format. This means that `.wasm` files are not directly human
readable, and not intended to be written by hand. Instead a compiler for a
language like Rust, C++, or Go _emits_ `.wasm` files.

The following binary exports a `main` function that just returns `42` upon
invocation:

<!-- deno-fmt-ignore -->
```ts
const wasmCode = new Uint8Array([
  0, 97, 115, 109, 1, 0, 0, 0, 1, 133, 128, 128, 128, 0, 1, 96, 0, 1, 127,
  3, 130, 128, 128, 128, 0, 1, 0, 4, 132, 128, 128, 128, 0, 1, 112, 0, 0,
  5, 131, 128, 128, 128, 0, 1, 0, 1, 6, 129, 128, 128, 128, 0, 0, 7, 145,
  128, 128, 128, 0, 2, 6, 109, 101, 109, 111, 114, 121, 2, 0, 4, 109, 97,
  105, 110, 0, 0, 10, 138, 128, 128, 128, 0, 1, 132, 128, 128, 128, 0, 0,
  65, 42, 11
]);

const wasmModule = new WebAssembly.Module(wasmCode);

const wasmInstance = new WebAssembly.Instance(wasmModule);

const main = wasmInstance.exports.main as CallableFunction;
console.log(main().toString());
```

As the code above shows, the following steps need to be performed in order to
load WebAssembly in a JavaScript program:

1. Fetching the binary (usually in the form of a `.wasm` file, though we are
   using a simple byte array for now)
2. Compiling the binary into a `WebAssembly.Module` object
3. Instantiating the WebAssembly module

For more complex scenarios you will probably want to write in a programming
language that compiles down to WebAssembly instead of hand writing instructions.
A number of languages exist that can do this, such as
[Rust](https://www.rust-lang.org/), [Go](https://golang.org/) or
[AssemblyScript](https://www.assemblyscript.org/). As an example, a Rust program
that compiles to the aforementioned bytes would look something like this:

```rust
pub fn main() -> u32 {  // u32 stands for an unsigned integer using 32 bits of memory.
  42
}
```

Aside from the methods shown in the preceding example, it is also possible to
use the streaming methods of the WebAssembly API, as will be shown on the next
page.



/. 🚀 runtime/manual/runtime/webassembly/wasm_resources.md
===================================================

# Helpful Resources

This page contains some further information that is helpful when using and/or
developing WebAssembly modules.

## WebAssembly API

Further information on all parts of the WebAssembly API can be found on
[MDN](https://developer.mozilla.org/en-US/docs/WebAssembly).

## Working with Non-Numeric Types

The code samples in this chapter only used numeric types in the WebAssembly
modules. To run WebAssembly with more complex types (strings, classes) you will
want to use tools that generate type bindings between JavaScript and the
language used to compile to WebAssembly.

An example on how to create type bindings between JavaScript and Rust, compiling
it into a binary and calling it from a JavaScript program can be found on
[MDN](https://developer.mozilla.org/en-US/docs/WebAssembly/Rust_to_wasm).

If you plan to do a lot of work with Web APIs in Rust+WebAssembly, you may find
the [web_sys](https://rustwasm.github.io/wasm-bindgen/web-sys/index.html) and
[js_sys](https://rustwasm.github.io/wasm-bindgen/contributing/js-sys/index.html)
Rust crates useful. `web_sys` contains bindings to most of the Web APIs that are
available in Deno, while `js_sys` provides bindings to JavaScript's standard,
built-in objects.

## Optimization

For production builds it can be a good idea to perform optimizations on
WebAssembly binaries. If you're mainly serving binaries over networks then
optimizing for size can make a real difference, whereas if you're mainly
executing WebAssembly on a server to perform computationally intensive tasks,
optimizing for speed can be beneficial. You can find a good guide on optimizing
(production) builds
[here](https://rustwasm.github.io/docs/book/reference/code-size.html). In
addition, the
[rust-wasm group](https://rustwasm.github.io/docs/book/reference/tools.html) has
a list of tools that can be used to optimize and manipulate WebAssembly
binaries.



/. 🚀 runtime/manual/tools/index.md
===================================================

# Built-In Tooling

Deno provides some built-in tooling that is useful when working with JavaScript
and TypeScript:

- [start new project (`deno init`)](./init.md)
- [benchmarker (`deno bench`)](./benchmarker.md)
- [compiling executables (`deno compile`)](./compiler.md)
- [installer (`deno install`)](./script_installer.md)
- [Jupyter kernel (`deno jupyter`)](./jupyter.md)
- [dependency inspector (`deno info`)](./dependency_inspector.md)
- [documentation generator (`deno doc`)](./documentation_generator.md)
- [formatter (`deno fmt`)](./formatter.md)
- [linter (`deno lint`)](./linter.md)
- [repl (`deno repl`)](./repl.md)
- [task runner (`deno task`)](./task_runner.md)
- [test runner (`deno test`)](../basics/testing/index.md)
- [vendoring dependencies (`deno vendor`)](./vendor.md)



/. 🚀 runtime/manual/tools/init.md
===================================================

# Starting a new project

Starting a new project with Deno has always been incredibly simple: you just
need a single file to get going. No need for any configuration files, dependency
manifests, or build scripts.

Users coming from other ecosystems are often not used to this simplicity - they
often look for a tool to scaffold out a basic project structure to get them
started on the right path. `deno init` subcommand scaffolds a basic Deno
project.

```sh
$ deno init
✅ Project initialized
Run these commands to get started

  // Run the program
  deno run main.ts

  // Run the program and watch for file changes
  deno task dev

  // Run the tests
  deno test

  // Run the benchmarks
  deno bench

$ deno run main.ts
Add 2 + 3 = 5

$ deno test
Check file:///dev/main_test.ts
running 1 test from main_test.ts
addTest ... ok (6ms)

ok | 1 passed | 0 failed (29ms)
```

This subcommand will create two files (`main.ts` and `main_test.ts`). These
files provide a basic example of how to write a Deno program and how to write
tests for it. The `main.ts` file exports a `add` function that adds two numbers
together and the `main_test.ts` file contains a test for this function.

You can also specify an argument to `deno init` to initialize a project in a
specific directory:

```sh
$ deno init my_deno_project
✅ Project initialized

Run these commands to get started

  cd my_deno_project

  // Run the program
  deno run main.ts

  // Run the program and watch for file changes
  deno task dev

  // Run the tests
  deno test

  // Run the benchmarks
  deno bench
```



/. 🚀 runtime/manual/tools/bundler.md
===================================================

# Bundling static assets (deprecated)

:::caution

`deno bundle` has been deprecated and will be removed in some future release.
Use [deno_emit](https://github.com/denoland/deno_emit),
[esbuild](https://esbuild.github.io/) or [rollup](https://rollupjs.org) instead.

:::

# Bundling

`deno bundle [URL]` will output a single JavaScript file for consumption in
Deno, which includes all dependencies of the specified input. For example:

```bash
deno bundle https://deno.land/std/examples/colors.ts colors.bundle.js
Bundle https://deno.land/std/examples/colors.ts
Download https://deno.land/std/examples/colors.ts
Download https://deno.land/std/fmt/colors.ts
Emit "colors.bundle.js" (9.83KB)
```

If you omit the out file, the bundle will be sent to `stdout`.

The bundle can just be run as any other module in Deno would:

```bash
deno run colors.bundle.js
```

The output is a self contained ES Module, where any exports from the main module
supplied on the command line will be available. For example, if the main module
looked something like this:

```ts, ignore
export { foo } from "./foo.js";

export const bar = "bar";
```

It could be imported like this:

```ts, ignore
import { bar, foo } from "./lib.bundle.js";
```

## Bundling for the Web

The output of `deno bundle` is intended for consumption in Deno and not for use
in a web browser or other runtimes. That said, depending on the input it may
work in other environments.

If you wish to bundle for the web, we recommend other solutions such as
[esbuild](https://esbuild.github.io/).



/. 🚀 runtime/manual/tools/benchmarker.md
===================================================

# Benchmarking Tool

Deno has a built-in benchmark runner that you can use for checking performance
of JavaScript or TypeScript code.

## Quickstart

Firstly, let's create a file `url_bench.ts` and register a bench using the
`Deno.bench()` function.

```ts
// url_bench.ts
Deno.bench("URL parsing", () => {
  new URL("https://deno.land");
});
```

Secondly, run the benchmark using the `deno bench` subcommand.

```sh
deno bench url_bench.ts
cpu: Apple M1 Max
runtime: deno 1.21.0 (aarch64-apple-darwin)

file:///dev/deno/url_bench.ts
benchmark        time (avg)             (min … max)       p75       p99      p995
--------------------------------------------------- -----------------------------
URL parsing   17.29 µs/iter  (16.67 µs … 153.62 µs)  17.25 µs  18.92 µs  22.25 µs
```

## Writing benchmarks

To define a benchmark you need to register it with a call to the `Deno.bench`
API. There are multiple overloads of this API to allow for the greatest
flexibility and easy switching between the forms (eg. when you need to quickly
focus a single bench for debugging, using the `only: true` option):

```ts
// Compact form: name and function
Deno.bench("hello world #1", () => {
  new URL("https://deno.land");
});

// Compact form: named function.
Deno.bench(function helloWorld3() {
  new URL("https://deno.land");
});

// Longer form: bench definition.
Deno.bench({
  name: "hello world #2",
  fn: () => {
    new URL("https://deno.land");
  },
});

// Similar to compact form, with additional configuration as a second argument.
Deno.bench("hello world #4", { permissions: { read: true } }, () => {
  new URL("https://deno.land");
});

// Similar to longer form, with bench function as a second argument.
Deno.bench(
  { name: "hello world #5", permissions: { read: true } },
  () => {
    new URL("https://deno.land");
  },
);

// Similar to longer form, with a named bench function as a second argument.
Deno.bench({ permissions: { read: true } }, function helloWorld6() {
  new URL("https://deno.land");
});
```

### Async functions

You can also bench asynchronous code by passing a bench function that returns a
promise. For this you can use the `async` keyword when defining a function:

```ts
Deno.bench("async hello world", async () => {
  await 1;
});
```

### Critical sections

Sometimes the benchmark case needs to include setup and teardown code that would
taint the benchmark results. For example, if you want to measure how long it
takes to read a small file, you need to open the file, read it, and then close
it. If the file is small enough the time it takes to open and close the file
might outweigh the time it takes to read the file itself.

To help with such situations you can `Deno.BenchContext.start` and
`Deno.BenchContext.end` to tell the benchmarking tool about the critical section
you want to measure. Everything outside of the section between these two calls
will be excluded from the measurement.

```ts, ignore
import { readAll } from "https://deno.land/std@$STD_VERSION/streams/mod.ts";

Deno.bench("foo", async (b) => {
  // Open a file that we will act upon.
  const file = await Deno.open("a_big_data_file.txt");

  // Tell the benchmarking tool that this is the only section you want
  // to measure.
  b.start();

  // Now let's measure how long it takes to read all of the data from the file.
  await readAll(file);

  // End measurement here.
  b.end();

  // Now we can perform some potentially time-consuming teardown that will not
  // taint out benchmark results.
  file.close();
});
```

## Grouping and baselines

When registering a bench case, it can be assigned to a group, using
`Deno.BenchDefinition.group` option:

```ts, ignore
// url_bench.ts
Deno.bench("url parse", { group: "url" }, () => {
  new URL("https://deno.land");
});
```

It is useful to assign several cases to a single group and compare how they
perform against a "baseline" case.

In this example we'll check how performant is `Date.now()` compared to
`performance.now()`, to do that we'll mark the first case as a "baseline" using
`Deno.BenchDefinition.baseline` option:

```ts, ignore
// time_bench.ts
Deno.bench("Date.now()", { group: "timing", baseline: true }, () => {
  Date.now();
});

Deno.bench("performance.now()", { group: "timing" }, () => {
  performance.now();
});
```

```shellsesssion
$ deno bench time_bench.ts
cpu: Apple M1 Max
runtime: deno 1.21.0 (aarch64-apple-darwin)

file:///dev/deno/time_bench.ts
benchmark              time (avg)             (min … max)       p75       p99      p995
--------------------------------------------------------- -----------------------------
Date.now()         125.24 ns/iter (118.98 ns … 559.95 ns) 123.62 ns 150.69 ns 156.63 ns
performance.now()    2.67 µs/iter     (2.64 µs … 2.82 µs)   2.67 µs   2.82 µs   2.82 µs

summary
  Date.now()
   21.29x times faster than performance.now()
```

You can specify multiple groups in the same file.

## Running benchmarks

To run a benchmark, call `deno bench` with the file that contains your bench
function. You can also omit the file name, in which case all benchmarks in the
current directory (recursively) that match the glob
`{*_,*.,}bench.{ts, tsx, mts, js, mjs, jsx}` will be run. If you pass a
directory, all files in the directory that match this glob will be run.

The glob expands to:

- files named `bench.{ts, tsx, mts, js, mjs, jsx}`,
- or files ending with `.bench.{ts, tsx, mts, js, mjs, jsx}`,
- or files ending with `_bench.{ts, tsx, mts, js, mjs, jsx}`

```shell
# Run all benches in the current directory and all sub-directories
deno bench

# Run all benches in the util directory
deno bench util/

# Run just my_bench.ts
deno bench my_bench.ts
```

> ⚠️ If you want to pass additional CLI arguments to the bench files use `--` to
> inform Deno that remaining arguments are scripts arguments.

```shell
# Pass additional arguments to the bench file
deno bench my_bench.ts -- -e --foo --bar
```

`deno bench` uses the same permission model as `deno run` and therefore will
require, for example, `--allow-write` to write to the file system during
benching.

To see all runtime options with `deno bench`, you can reference the command line
help:

```shell
deno help bench
```

## Filtering

There are a number of options to filter the benches you are running.

### Command line filtering

Benches can be run individually or in groups using the command line `--filter`
option.

The filter flags accept a string or a pattern as value.

Assuming the following benches:

```ts
Deno.bench({
  name: "my-bench",
  fn: () => {/* bench function zero */},
});
Deno.bench({
  name: "bench-1",
  fn: () => {/* bench function one */},
});
Deno.bench({
  name: "bench2",
  fn: () => {/* bench function two */},
});
```

This command will run all of these benches because they all contain the word
"bench".

```shell
deno bench --filter "bench" benchmarks/
```

On the flip side, the following command uses a pattern and will run the second
and third benchmarks.

```shell
deno bench --filter "/bench-*\d/" benchmarks/
```

_To let Deno know that you want to use a pattern, wrap your filter with
forward-slashes like the JavaScript syntactic sugar for a regex._

### Bench definition filtering

Within the benches themselves, you have two options for filtering.

#### Filtering out (ignoring these benches)

Sometimes you want to ignore benches based on some sort of condition (for
example you only want a benchmark to run on Windows). For this you can use the
`ignore` boolean in the bench definition. If it is set to true the bench will be
skipped.

```ts
Deno.bench({
  name: "bench windows feature",
  ignore: Deno.build.os !== "windows",
  fn() {
    // do windows feature
  },
});
```

#### Filtering in (only run these benches)

Sometimes you may be in the middle of a performance problem within a large bench
class and you would like to focus on just that single bench and ignore the rest
for now. For this you can use the `only` option to tell the benchmark harness to
only run benches with this set to true. Multiple benches can set this option.
While the benchmark run will report on the success or failure of each bench, the
overall benchmark run will always fail if any bench is flagged with `only`, as
this is a temporary measure only which disables nearly all of your benchmarks.

```ts
Deno.bench({
  name: "Focus on this bench only",
  only: true,
  fn() {
    // bench complicated stuff
  },
});
```

## JSON output

To retrieve the output as JSON, use the `--json` flag:

```
$ deno bench --json bench_me.js
{
  "runtime": "Deno/1.31.0 x86_64-apple-darwin",
  "cpu": "Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz",
  "benches": [
    "origin": "file:///dev/bench_me.js",
    "group": null,
    "name": "Deno.UnsafePointerView#getUint32",
    "baseline": false,
    "result": {
      "ok": {
        "n": 49,
        "min": 1251.9348,
        "max": 1441.2696,
        "avg": 1308.7523755102038,
        "p75": 1324.1055,
        "p99": 1441.2696,
        "p995": 1441.2696,
        "p999": 1441.2696
      }
    }
  ]
}
```



/. 🚀 runtime/manual/tools/compiler.md
===================================================

# Compiling Executables

`deno compile [--output <OUT>] <SRC>` will compile the script into a
self-contained executable.

```
> deno compile https://deno.land/std/examples/welcome.ts
```

If you omit the `OUT` parameter, the name of the executable file will be
inferred.

## Flags

As with [`deno install`](./script_installer.md), the runtime flags used to
execute the script must be specified at compilation time. This includes
permission flags.

```
> deno compile --allow-read --allow-net https://deno.land/std/http/file_server.ts
```

[Script arguments](../getting_started/command_line_interface.md#script-arguments)
can be partially embedded.

```
> deno compile --allow-read --allow-net https://deno.land/std/http/file_server.ts -p 8080
> ./file_server --help
```

## Dynamic Imports

By default, statically analyzable dynamic imports (imports that have the string
literal within the `import("...")` call expression) will be included in the
output.

```ts, ignore
// calculator.ts and its dependencies will be included in the binary
const calculator = await import("./calculator.ts");
```

But non-statically analyzable dynamic imports won't:

```ts, ignore
const specifier = condition ? "./calc.ts" : "./better_calc.ts";
const calculator = await import(specifier);
```

To include non-statically analyzable dynamic imports, specify an
`--include <path>` flag.

```shell
deno compile --include calc.ts --include better_calc.ts main.ts
```

## Workers

Similarly to non-statically analyzable dynamic imports, code for
[workers](../runtime/workers.md) is not included in the compiled executable by
default. You must use the `--include <path>` flag to include the worker code.

```shell
deno compile --include worker.ts main.ts
```

## Cross Compilation

You can compile binaries for other platforms by adding the `--target` CLI flag.
Deno currently supports compiling to Windows x64, macOS x64, macOS ARM and Linux
x64. Use `deno compile --help` to list the full values for each compilation
target.

## Unavailable in executables

- [Web Storage API](../runtime/web_storage_api.md)



/. 🚀 runtime/manual/tools/script_installer.md
===================================================

# Script Installer

Deno provides `deno install` to easily install and distribute executable code.

`deno install [OPTIONS...] [URL] [SCRIPT_ARGS...]` will install the script
available at `URL` under the name `EXE_NAME`.

This command creates a thin, executable shell script which invokes `deno` using
the specified CLI flags and main module. It is placed in the installation root's
`bin` directory.

Example:

```shell
$ deno install --allow-net --allow-read https://deno.land/std/http/file_server.ts
[1/1] Compiling https://deno.land/std/http/file_server.ts

✅ Successfully installed file_server.
/Users/deno/.deno/bin/file_server
```

To change the executable name, use `-n`/`--name`:

```shell
deno install --allow-net --allow-read -n serve https://deno.land/std/http/file_server.ts
```

The executable name is inferred by default:

- Attempt to take the file stem of the URL path. The above example would become
  'file_server'.
- If the file stem is something generic like 'main', 'mod', 'index' or 'cli',
  and the path has no parent, take the file name of the parent path. Otherwise
  settle with the generic name.
- If the resulting name has an '@...' suffix, strip it.

To change the installation root, use `--root`:

```shell
deno install --allow-net --allow-read --root /usr/local https://deno.land/std/http/file_server.ts
```

The installation root is determined, in order of precedence:

- `--root` option
- `DENO_INSTALL_ROOT` environment variable
- `$HOME/.deno`

These must be added to the path manually if required.

```shell
echo 'export PATH="$HOME/.deno/bin:$PATH"' >> ~/.bashrc
```

You must specify permissions that will be used to run the script at installation
time.

```shell
deno install --allow-net --allow-read https://deno.land/std/http/file_server.ts -- -p 8080
```

The above command creates an executable called `file_server` that runs with
network and read permissions and binds to port 8080.

For good practice, use the [`import.meta.main`](../../tutorials/module_metadata.md)
idiom to specify the entry point in an executable script.

Example:

<!-- deno-fmt-ignore -->

```ts
// https://example.com/awesome/cli.ts
async function myAwesomeCli(): Promise<void> {
  // -- snip --
}

if (import.meta.main) {
  myAwesomeCli();
}
```

When you create an executable script make sure to let users know by adding an
example installation command to your repository:

```shell
# Install using deno install

$ deno install -n awesome_cli https://example.com/awesome/cli.ts
```

## Uninstall

You can uninstall the script with `deno uninstall` command.

```shell
$ deno uninstall file_server
deleted /Users/deno/.deno/bin/file_server
✅ Successfully uninstalled file_server
```

See `deno uninstall -h` for more details.



/. 🚀 runtime/manual/tools/jupyter.md
===================================================

    curl -s -L https://docs.deno.com/runtime/manual/tools/jupyter | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Jupyter Kernel for Deno

<p>
<span class="theme-doc-version-badge badge badge--secondary">
Available since <b>1.37.0</b>
</span>
</p>

Deno ships with a built-in Jupyter kernel that allows you to write JavaScript
and TypeScript; use Web and Deno APIs and import `npm` packages straight in your
interactive notebooks.

:::caution `deno jupyter` is currently unstable

`deno jupyter` is currently an unstable feature and thus requires the
`--unstable` flag. We intend to stabilize this feature in an upcoming release.

:::

## Quickstart

Run `deno jupyter --unstable` and follow the instructions.

You can run `deno jupyter --unstable --install` to force installation of the
kernel. Deno assumes that `jupyter` command is available in your `PATH`.

After completing the installation process, the Deno kernel will be available in the
notebook creation dialog in JupyterLab and the classic notebook:

![Jupyter notebook kernel selection](https://docs.deno.com/assets/images/jupyter_notebook-cc763c3dc5b6ccfd0df0b548a7ffbdef.png)
<!-- ![Jupyter notebook kernel selection](../images/jupyter_notebook.png) -->

You can use the Deno Jupyter kernel in any editor that supports Jupyter notebooks.

### VS Code

* Install the [VSCode Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)
* When on a new or existing Notebook, click  creating a new Jupyter Notebook select "Jupyter kernels" and then select Deno

![Selecting Deno in VS Code](https://github.com/denoland/deno-docs/assets/836375/32f0ccc3-35f7-47e5-84f4-17c20a5b5732)

### JetBrains IDEs

Jupyter Notebooks are available right out of the box.

## Rich content output

Deno Jupyter kernel allows you to display rich content in your notebooks
[using MIME types that Jupyter supports](https://docs.jupyter.org/en/latest/reference/mimetype.html).

To do that, you need to return any JavaScript object that has a
`[Symbol.for("Jupyter.display")]` method. This method should return a dictionary
mapping a MIME type to a value that should be displayed.

```ts
{
  [Symbol.for("Jupyter.display")]() {
    return {
      // Plain text content
      "text/plain": "Hello world!",

      // HTML output
      "text/html": "<h1>Hello world!</h1>",
    }
  }
}
```

Since it's _just_ a function, you can use any library you want to format the
output. This is not tied to Deno itself in any way, because we're using a
regular JavaScript symbol index.

## `jupyter console` integration

You can also use Deno Jupyter kernel in the `jupyter console` REPL. To do that,
you should launch your console with `jupyter console --kernel deno`.

![Using the Deno kernel in a CLI](https://docs.deno.com/assets/images/jupyter-cli-193dfc9c857c5a5ce2fe00287a90a943.gif)
<!-- ![Using the Deno kernel in a CLI](../images/jupyter-cli.gif) -->



/. 🚀 runtime/manual/tools/dependency_inspector.md
===================================================

# Dependency Inspector

`deno info [URL]` will inspect an ES module and all of its dependencies.

```shell
deno info https://deno.land/std@0.178.0/http/file_server.ts
Download https://deno.land/std@0.178.0/http/file_server.ts
...
local: /home/deno/.cache/deno/deps/https/deno.land/cca7626bf190e39a7fec3bc79f68f356f8010f6d78afdcb43daae4accbfd4155
type: TypeScript
dependencies: 52 unique
size: 651.67KB

https://deno.land/std@0.178.0/http/file_server.ts (19.08KB)
├─┬ https://deno.land/std@0.178.0/path/mod.ts (1.32KB)
│ ├── https://deno.land/std@0.178.0/_util/os.ts (644B)
│ ├─┬ https://deno.land/std@0.178.0/path/win32.ts (27.84KB)
│ │ ├── https://deno.land/std@0.178.0/path/_interface.ts (728B)
│ │ ├── https://deno.land/std@0.178.0/path/_constants.ts (1.97KB)
│ │ ├─┬ https://deno.land/std@0.178.0/path/_util.ts (4.9KB)
│ │ │ ├── https://deno.land/std@0.178.0/path/_interface.ts *
│ │ │ └── https://deno.land/std@0.178.0/path/_constants.ts *
│ │ └── https://deno.land/std@0.178.0/_util/asserts.ts (854B)
│ ├─┬ https://deno.land/std@0.178.0/path/posix.ts (13.53KB)
│ │ ├── https://deno.land/std@0.178.0/path/_interface.ts *
│ │ ├── https://deno.land/std@0.178.0/path/_constants.ts *
│ │ └── https://deno.land/std@0.178.0/path/_util.ts *
│ ├─┬ https://deno.land/std@0.178.0/path/common.ts (1.16KB)
│ │ └─┬ https://deno.land/std@0.178.0/path/separator.ts (259B)
│ │   └── https://deno.land/std@0.178.0/_util/os.ts *
│ ├── https://deno.land/std@0.178.0/path/separator.ts *
│ ├── https://deno.land/std@0.178.0/path/_interface.ts *
│ └─┬ https://deno.land/std@0.178.0/path/glob.ts (12.39KB)
│   ├── https://deno.land/std@0.178.0/_util/os.ts *
│   ├── https://deno.land/std@0.178.0/_util/os.ts *
│   ├── https://deno.land/std@0.178.0/path/separator.ts *
│   ├── https://deno.land/std@0.178.0/path/win32.ts *
│   └── https://deno.land/std@0.178.0/path/posix.ts *
├─┬ https://deno.land/std@0.178.0/media_types/content_type.ts (2.78KB)
│ ├─┬ https://deno.land/std@0.178.0/media_types/parse_media_type.ts (3.39KB)
│ │ └── https://deno.land/std@0.178.0/media_types/_util.ts (3.27KB)
│ ├─┬ https://deno.land/std@0.178.0/media_types/type_by_extension.ts (906B)
│ │ └─┬ https://deno.land/std@0.178.0/media_types/_db.ts (1.25KB)
│ │   ├── https://deno.land/std@0.178.0/media_types/vendor/mime-db.v1.52.0.ts (182.13KB)
│ │   └── https://deno.land/std@0.178.0/media_types/_util.ts *
│ ├─┬ https://deno.land/std@0.178.0/media_types/get_charset.ts (1.17KB)
│ │ ├── https://deno.land/std@0.178.0/media_types/parse_media_type.ts *
│ │ ├── https://deno.land/std@0.178.0/media_types/_util.ts *
│ │ └── https://deno.land/std@0.178.0/media_types/_db.ts *
│ ├─┬ https://deno.land/std@0.178.0/media_types/format_media_type.ts (1.72KB)
│ │ └── https://deno.land/std@0.178.0/media_types/_util.ts *
│ └── https://deno.land/std@0.178.0/media_types/_db.ts *
├─┬ https://deno.land/std@0.178.0/http/server.ts (21.18KB)
│ └─┬ https://deno.land/std@0.178.0/async/mod.ts (465B)
│   ├─┬ https://deno.land/std@0.178.0/async/abortable.ts (3.95KB)
│   │ └── https://deno.land/std@0.178.0/async/deferred.ts (1.51KB)
│   ├─┬ https://deno.land/std@0.178.0/async/deadline.ts (1.04KB)
│   │ └── https://deno.land/std@0.178.0/async/deferred.ts *
│   ├── https://deno.land/std@0.178.0/async/debounce.ts (2.18KB)
│   ├── https://deno.land/std@0.178.0/async/deferred.ts *
│   ├── https://deno.land/std@0.178.0/async/delay.ts (1.8KB)
│   ├─┬ https://deno.land/std@0.178.0/async/mux_async_iterator.ts (2.45KB)
│   │ └── https://deno.land/std@0.178.0/async/deferred.ts *
│   ├── https://deno.land/std@0.178.0/async/pool.ts (3.13KB)
│   ├── https://deno.land/std@0.178.0/async/tee.ts (2.1KB)
│   └── https://deno.land/std@0.178.0/async/retry.ts (2.35KB)
├── https://deno.land/std@0.178.0/http/http_status.ts (9.96KB)
├─┬ https://deno.land/std@0.178.0/flags/mod.ts (22.05KB)
│ └── https://deno.land/std@0.178.0/_util/asserts.ts *
├── https://deno.land/std@0.178.0/_util/asserts.ts *
├── https://deno.land/std@0.178.0/fmt/colors.ts (12.13KB)
├─┬ https://deno.land/std@0.178.0/http/util.ts (1020B)
│ ├── https://deno.land/std@0.178.0/http/http_status.ts *
│ └─┬ https://deno.land/std@0.178.0/collections/deep_merge.ts (10.98KB)
│   └── https://deno.land/std@0.178.0/collections/_utils.ts (790B)
├─┬ https://deno.land/std@0.178.0/crypto/crypto.ts (11.88KB)
│ ├─┬ https://deno.land/std@0.178.0/crypto/_wasm/mod.ts (1.11KB)
│ │ └── https://deno.land/std@0.178.0/crypto/_wasm/lib/deno_std_wasm_crypto.generated.mjs (238.72KB)
│ ├─┬ https://deno.land/std@0.178.0/crypto/timing_safe_equal.ts (983B)
│ │ └── https://deno.land/std@0.178.0/_util/asserts.ts *
│ └─┬ https://deno.land/std@0.178.0/crypto/_fnv/mod.ts (621B)
│   ├─┬ https://deno.land/std@0.178.0/crypto/_fnv/fnv32.ts (825B)
│   │ └── https://deno.land/std@0.178.0/crypto/_fnv/util.ts (1.44KB)
│   └─┬ https://deno.land/std@0.178.0/crypto/_fnv/fnv64.ts (1.02KB)
│     └── https://deno.land/std@0.178.0/crypto/_fnv/util.ts *
├─┬ https://deno.land/std@0.178.0/crypto/to_hash_string.ts (1021B)
│ ├── https://deno.land/std@0.178.0/encoding/hex.ts (2.23KB)
│ └── https://deno.land/std@0.178.0/encoding/base64.ts (2.48KB)
├─┬ https://deno.land/std@0.178.0/crypto/_util.ts (1.06KB)
│ └─┬ https://deno.land/std@0.178.0/crypto/mod.ts (439B)
│   ├── https://deno.land/std@0.178.0/crypto/crypto.ts *
│   ├─┬ https://deno.land/std@0.178.0/crypto/keystack.ts (5.37KB)
│   │ ├── https://deno.land/std@0.178.0/crypto/timing_safe_equal.ts *
│   │ └─┬ https://deno.land/std@0.178.0/encoding/base64url.ts (1.95KB)
│   │   └── https://deno.land/std@0.178.0/encoding/base64.ts *
│   ├── https://deno.land/std@0.178.0/crypto/timing_safe_equal.ts *
│   └── https://deno.land/std@0.178.0/crypto/to_hash_string.ts *
└── https://deno.land/std@0.178.0/version.ts (371B)
```

Dependency inspector works with any local or remote ES modules.

## Cache location

`deno info` can be used to display information about cache location:

```shell
deno info
DENO_DIR location: "/Users/deno/Library/Caches/deno"
Remote modules cache: "/Users/deno/Library/Caches/deno/deps"
TypeScript compiler cache: "/Users/deno/Library/Caches/deno/gen"
```



/. 🚀 runtime/manual/tools/documentation_generator.md
===================================================

# Documentation Generator

`deno doc` followed by a list of one or more source files will print the JSDoc
documentation for each of the module's **exported** members.

For example, given a file `add.ts` with the contents:

```ts
/**
 * Adds x and y.
 * @param {number} x
 * @param {number} y
 * @returns {number} Sum of x and y
 */
export function add(x: number, y: number): number {
  return x + y;
}
```

Running the Deno `doc` command, prints the function's JSDoc comment to `stdout`:

```shell
deno doc add.ts
function add(x: number, y: number): number
  Adds x and y. @param {number} x @param {number} y @returns {number} Sum of x and y
```

## Linting

You can use `--lint` flag to check for problems in your documentation while it's
being generated. `deno doc` will point out three kinds of problems:

1. Error for an exported type from the root module referencing a non-exported
   type.
   - Ensures API consumers have access to all the types the API uses. This can
     be suppressed by exporting the type from a root module (one of the files
     specified to `deno doc` on the command line) or by marking the type with an
     `@internal` jsdoc tag.
1. Error for missing return type or property type on a **public** type.
   - Ensures `deno doc` displays the return/property type and helps improve type
     checking performance.
1. Error for missing JS doc comment on a **public** type.
   - Ensures the code is documented. Can be suppressed by adding a jsdoc
     comment, or via an `@ignore` jsdoc tag to exclude it from the
     documentation. Alternatively, add an `@internal` tag to keep it in the
     docs, but signify it's internal.

For example:

```ts title="/mod.ts"
interface Person {
  name: string;
  // ...
}

export function getName(person: Person) {
  return person.name;
}
```

```shell
$ deno doc --lint mod.ts
Type 'getName' references type 'Person' which is not exported from a root module.
Missing JS documentation comment.
Missing return type.
    at file:///mod.ts:6:1
```

These lints are meant to help you write better documentation and speed up
type-checking in your projects. If any problems are found, the program exits
with non-zero exit code and the output is reported to standard error.

## HTML output

Use the `--html` flag to generate a static site with documentation.

```
$ deno doc --html --name="My library" ./mod.ts

$ deno doc --html --name="My library" --output=./documentation/ ./mod.ts

$ deno doc --html --name="My library" ./sub1/mod.ts ./sub2/mod.ts
```

The generated documentation is a static site with multiple pages that can be
deployed to any static site hosting service.

A client-side search is included in the generated site, but is not available if
user's browser has JavaScript disabled.

## JSON output

Use the `--json` flag to output the documentation in JSON format. This JSON
format is consumed by the
[deno doc website](https://github.com/denoland/docland) and is used to generate
module documentation.



/. 🚀 runtime/manual/tools/formatter.md
===================================================

# Code Formatter

Deno ships with a built-in code formatter that will auto-format the following
files:

| File Type  | Extension          |
| ---------- | ------------------ |
| JavaScript | `.js`              |
| TypeScript | `.ts`              |
| JSX        | `.jsx`             |
| TSX        | `.tsx`             |
| Markdown   | `.md`, `.markdown` |
| JSON       | `.json`            |
| JSONC      | `.jsonc`           |

In addition, `deno fmt` can format code snippets in Markdown files. Snippets
must be enclosed in triple backticks and have a language attribute.

```shell
# format all supported files in the current directory and subdirectories
deno fmt
# format specific files
deno fmt myfile1.ts myfile2.ts
# format all supported files in specified directory and subdirectories
deno fmt src/
# check if all the supported files in the current directory and subdirectories are formatted
deno fmt --check
# format stdin and write to stdout
cat file.ts | deno fmt -
```

## Ignoring Code

Ignore formatting code by preceding it with a `// deno-fmt-ignore` comment in
TS/JS/JSONC:

```ts
// deno-fmt-ignore
export const identity = [
    1, 0, 0,
    0, 1, 0,
    0, 0, 1,
];
```

Or ignore an entire file by adding a `// deno-fmt-ignore-file` comment at the
top of the file.

In markdown you may use a `<!-- deno-fmt-ignore -->` comment or ignore a whole
file with a `<!-- deno-fmt-ignore-file -->` comment. To ignore a section of
markdown, surround the code with `<!-- deno-fmt-ignore-start -->` and
`<!-- deno-fmt-ignore-end -->` comments.

## Configuration

> ℹ️ It is recommended to stick with default options.

Starting with Deno v1.14 a formatter can be customized using either
[a configuration file](../getting_started/configuration_file.md) or following
CLI flags:

- `--use-tabs` - Whether to use tabs. Defaults to false (using spaces).

- `--line-width` - The width of a line the printer will try to stay under. Note
  that the printer may exceed this width in certain cases. Defaults to 80.

- `--indent-width` - The number of characters for an indent. Defaults to 2.

- `--no-semicolons` - To not use semicolons except where necessary.

- `--single-quote` - Whether to use single quote. Defaults to false (using
  double quote).

- `--prose-wrap={always,never,preserve}` - Define how prose should be wrapped in
  Markdown files. Defaults to "always".

Note: In Deno versions < 1.31 you will have to prefix these flags with
`options-` (ex. `--options-use-tabs`)



/. 🚀 runtime/manual/tools/linter.md
===================================================

# Linter

Deno ships with a built-in code linter for JavaScript and TypeScript.

```shell
# lint all JS/TS files in the current directory and subdirectories
deno lint
# lint specific files
deno lint myfile1.ts myfile2.ts
# lint all JS/TS files in specified directory and subdirectories
deno lint src/
# print result as JSON
deno lint --json
# read from stdin
cat file.ts | deno lint -
```

For more detail, run `deno lint --help`.

## Available rules

For a complete list of supported rules visit
[the deno_lint rule documentation](https://lint.deno.land).

## Ignore directives

### Files

To ignore whole file `// deno-lint-ignore-file` directive should placed at the
top of the file:

```ts
// deno-lint-ignore-file

function foo(): any {
  // ...
}
```

Ignore directive must be placed before first statement or declaration:

```ts, ignore
// Copyright 2020 the Deno authors. All rights reserved. MIT license.

/**
 * Some JS doc
 */

// deno-lint-ignore-file

import { bar } from "./bar.js";

function foo(): any {
  // ...
}
```

You can also ignore certain diagnostics in the whole file

```ts
// deno-lint-ignore-file no-explicit-any no-empty

function foo(): any {
  // ...
}
```

### Diagnostics

To ignore certain diagnostic `// deno-lint-ignore <codes...>` directive should
be placed before offending line. Specifying ignored rule name is required:

```ts
// deno-lint-ignore no-explicit-any
function foo(): any {
  // ...
}

// deno-lint-ignore no-explicit-any explicit-function-return-type
function bar(a: any) {
  // ...
}
```

## Configuration

Starting with Deno v1.14 a linter can be customized using either
[a configuration file](../getting_started/configuration_file.md) or following
CLI flags:

- `--rules-tags` - List of tag names that will be run. Empty list disables all
  tags and will only use rules from `include`. Defaults to "recommended".

- `--rules-exclude` - List of rule names that will be excluded from configured
  tag sets. Even if the same rule is in `include` it will be excluded; in other
  words, `--rules-exclude` has higher precedence over `--rules-include`.

- `--rules-include` - List of rule names that will be run. If the same rule is
  in `exclude` it will be excluded.



/. 🚀 runtime/manual/tools/repl.md
===================================================

# Read-Eval-Print-Loop

`deno repl` starts a read-eval-print-loop, which lets you interactively build up
program state in the global context, it is especially useful for quick
prototyping and checking snippets of code.

> ⚠️ Deno REPL supports JavaScript as well as TypeScript, however TypeScript code
> is not type-checked, instead it is transpiled to JavaScript behind the scenes.

> ⚠️ To make it easier to copy-paste code samples, Deno REPL supports import and
> export declarations. It means that you can paste code containing
> `import ... from ...;`, `export class ...` or `export function ...` and it
> will work as if you were executing a regular ES module.

## Special variables

The REPL provides a couple of special variables, that are always available:

| Identifier | Description                          |
| ---------- | ------------------------------------ |
| _          | Yields the last evaluated expression |
| _error     | Yields the last thrown error         |

```
Deno 1.14.3
exit using ctrl+d or close()
> "hello world!"
"hello world!"
> _
"hello world!"
> const foo = "bar";
undefined
> _
undefined
```

## Special functions

The REPL provides several functions in the global scope:

| Function | Description                       |
| -------- | --------------------------------- |
| clear()  | Clears the entire terminal screen |
| close()  | Close the current REPL session    |

## `--eval` flag

`--eval` flag allows you to run some code in the runtime before you are dropped
into the REPL. This is useful for importing some code you commonly use in the
REPL, or modifying the runtime in some way:

```
$ deno repl --allow-net --eval 'import { assert } from "https://deno.land/std/assert/mod.ts"'
Deno 1.36.0
exit using ctrl+d, ctrl+c, or close()
> assert(true)
undefined
> assert(false)
Uncaught AssertionError
    at assert (https://deno.land/std@0.197.0/assert/assert.ts:7:11)
    at <anonymous>:2:1
```

## `--eval-file` flag

`--eval-file` flag allows you to run code from specified files before you are
dropped into the REPL. Like the `--eval` flag, this is useful for importing code
you commonly use in the REPL, or modifying the runtime in some way.

Files can be specified as paths or URLs. URL files are cached and can be
reloaded via the `--reload` flag.

If `--eval` is also specified, then `--eval-file` files are run before the
`--eval` code.

```
$ deno repl --eval-file=https://examples.deno.land/hello-world.ts,https://deno.land/std/encoding/ascii85.ts
Download https://examples.deno.land/hello-world.ts
Hello, World!
Download https://deno.land/std/encoding/ascii85.ts
Deno 1.20.5
exit using ctrl+d or close()
> rfc1924 // local (not exported) variable defined in ascii85.ts
"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~"
```

### Relative Import Path Resolution

If `--eval-file` specifies a code file that contains relative imports, then the
runtime will try to resolve the imports relative to the current working
directory. It will not try to resolve them relative to the code file's location.
This can cause "Module not found" errors when `--eval-file` is used with module
files:

```
$ deno repl --eval-file=https://deno.land/std/hash/md5.ts
error in --eval-file file https://deno.land/std/hash/md5.ts. Uncaught TypeError: Module not found "file:///home/encoding/hex.ts".
    at async <anonymous>:2:13
Deno 1.20.5
exit using ctrl+d or close()
> close()
$ deno repl --eval-file=https://deno.land/std/encoding/hex.ts
Download https://deno.land/std/encoding/hex.ts
Deno 1.20.5
exit using ctrl+d or close()
>
```

## Tab completions

Tab completions are crucial feature for quick navigation in REPL. After hitting
`tab` key, Deno will now show a list of all possible completions.

```
$ deno repl
Deno 1.14.3
exit using ctrl+d or close()
> Deno.read
readTextFile      readFile          readDirSync       readLinkSync      readAll           read
readTextFileSync  readFileSync      readDir           readLink          readAllSync       readSync
```

## Keyboard shortcuts

| Keystroke             | Action                                                                                           |
| --------------------- | ------------------------------------------------------------------------------------------------ |
| Ctrl-A, Home          | Move cursor to the beginning of line                                                             |
| Ctrl-B, Left          | Move cursor one character left                                                                   |
| Ctrl-C                | Interrupt and cancel the current edit                                                            |
| Ctrl-D                | If if line _is_ empty, signal end of line                                                        |
| Ctrl-D, Del           | If line is _not_ empty, delete character under cursor                                            |
| Ctrl-E, End           | Move cursor to end of line                                                                       |
| Ctrl-F, Right         | Move cursor one character right                                                                  |
| Ctrl-H, Backspace     | Delete character before cursor                                                                   |
| Ctrl-I, Tab           | Next completion                                                                                  |
| Ctrl-J, Ctrl-M, Enter | Finish the line entry                                                                            |
| Ctrl-K                | Delete from cursor to end of line                                                                |
| Ctrl-L                | Clear screen                                                                                     |
| Ctrl-N, Down          | Next match from history                                                                          |
| Ctrl-P, Up            | Previous match from history                                                                      |
| Ctrl-R                | Reverse Search history (Ctrl-S forward, Ctrl-G cancel)                                           |
| Ctrl-T                | Transpose previous character with current character                                              |
| Ctrl-U                | Delete from start of line to cursor                                                              |
| Ctrl-V                | Insert any special character without performing its associated action                            |
| Ctrl-W                | Delete word leading up to cursor (using white space as a word boundary)                          |
| Ctrl-X Ctrl-U         | Undo                                                                                             |
| Ctrl-Y                | Paste from Yank buffer                                                                           |
| Ctrl-Y                | Paste from Yank buffer (Meta-Y to paste next yank instead)                                       |
| Ctrl-Z                | Suspend (Unix only)                                                                              |
| Ctrl-_                | Undo                                                                                             |
| Meta-0, 1, ..., -     | Specify the digit to the argument. `–` starts a negative argument.                               |
| Meta-<                | Move to first entry in history                                                                   |
| Meta->                | Move to last entry in history                                                                    |
| Meta-B, Alt-Left      | Move cursor to previous word                                                                     |
| Meta-Backspace        | Kill from the start of the current word, or, if between words, to the start of the previous word |
| Meta-C                | Capitalize the current word                                                                      |
| Meta-D                | Delete forwards one word                                                                         |
| Meta-F, Alt-Right     | Move cursor to next word                                                                         |
| Meta-L                | Lower-case the next word                                                                         |
| Meta-T                | Transpose words                                                                                  |
| Meta-U                | Upper-case the next word                                                                         |
| Meta-Y                | See Ctrl-Y                                                                                       |
| Ctrl-S                | Insert a new line                                                                                |

## `DENO_REPL_HISTORY`

You can use `DENO_REPL_HISTORY` environmental variable to control where Deno
stores the REPL history file. You can set it to an empty value, Deno will not
store the history file.



/. 🚀 runtime/manual/tools/task_runner.md
===================================================

# Task Runner

`deno task` provides a cross platform way to define and execute custom commands
specific to a codebase.

To get started, define your commands in your codebase's
[Deno configuration file](../getting_started/configuration_file.md) under a
`"tasks"` key.

For example:

```jsonc
{
  "tasks": {
    "data": "deno task collect && deno task analyze",
    "collect": "deno run --allow-read=. --allow-write=. scripts/collect.js",
    "analyze": "deno run --allow-read=. scripts/analyze.js"
  }
}
```

## Listing tasks

To get an output showing all the defined tasks, run:

```sh
deno task
```

## Executing a task

To execute a specific task, run:

```shell
deno task task-name [additional args]...
```

In the example above, to run the `data` task we would do:

```shell
deno task data
```

## Specifying the current working directory

By default, `deno task` executes commands with the directory of the Deno
configuration file (ex. _deno.json_) as the current working directory. This
allows tasks to use relative paths and continue to work regardless of where in
the directory tree you happen to execute the deno task from. In some scenarios,
this may not be desired and this behavior can be overridden with the `INIT_CWD`
environment variable.

`INIT_CWD` will be set with the full path to the directory the task was run in,
if not already set. This aligns with the same behavior as `npm run`.

For example, the following task will change the current working directory of the
task to be in the same directory the user ran the task from and then output the
current working directory which is now that directory (remember, this works on
Windows too because deno task is cross platform).

```
{
  "tasks": {
    "my_task": "cd $INIT_CWD && pwd"
  }
}
```

## Getting directory `deno task` was run from

Since tasks are run using the directory of the Deno configuration file as the
current working directory, it may be useful to know the directory the
`deno task` was executed from instead. This is possible by using the `INIT_CWD`
environment variable in a task or script launched from `deno task` (works the
same way as in `npm run`, but in a cross platform way).

For example, to provide this directory to a script in a task, do the following
(note the directory is surrounded in double quotes to keep it as a single
argument in case it contains spaces):

```json
{
  "tasks": {
    "start": "deno run main.ts \"$INIT_CWD\""
  }
}
```

## Syntax

`deno task` uses a cross platform shell that's a subset of sh/bash to execute
defined tasks.

### Boolean lists

Boolean lists provide a way to execute additional commands based on the exit
code of the initial command. They separate commands using the `&&` and `||`
operators.

The `&&` operator provides a way to execute a command and if it _succeeds_ (has
an exit code of `0`) it will execute the next command:

```sh
deno run --allow-read=. --allow-write=. collect.ts && deno run --allow-read=. analyze.ts
```

The `||` operator is the opposite. It provides a way to execute a command and
only if it _fails_ (has a non-zero exit code) it will execute the next command:

```sh
deno run --allow-read=. --allow-write=. collect.ts || deno run play_sad_music.ts
```

### Sequential lists

Sequential lists are similar to boolean lists, but execute regardless of whether
the previous command in the list passed or failed. Commands are separated with a
semi-colon (`;`).

```sh
deno run output_data.ts ; deno run --allow-net server.ts
```

### Async commands

Async commands provide a way to make a command execute asynchronously. This can
be useful when starting multiple processes. To make a command asynchronous, add
an `&` to the end of it. For example the following would execute
`sleep 1 && deno run --allow-net client.ts` and `deno run --allow-net server.ts`
at the same time:

```sh
sleep 1 && deno run --allow-net client.ts & deno run --allow-net server.ts
```

Unlike in most shells, the first async command to fail will cause all the other
commands to fail immediately. In the example above, this would mean that if the
client command fails then the server command will also fail and exit. You can
opt out of this behavior by adding `|| true` to the end of a command, which will
force a `0` exit code. For example:

```sh
deno run --allow-net client.ts || true & deno run --allow-net server.ts || true
```

### Environment variables

Environment variables are defined like the following:

```sh
export VAR_NAME=value
```

Here's an example of using one in a task with shell variable substitution and
then with it being exported as part of the environment of the spawned Deno
process (note that in the JSON configuration file the double quotes would need
to be escaped with backslashes):

```sh
export VAR=hello && echo $VAR && deno eval "console.log('Deno: ' + Deno.env.get('VAR'))"
```

Would output:

```
hello
Deno: hello
```

#### Setting environment variables for a command

To specify environment variable(s) before a command, list them like so:

```
VAR=hello VAR2=bye deno run main.ts
```

This will use those environment variables specifically for the following
command.

### Shell variables

Shell variables are similar to environment variables, but won't be exported to
spawned commands. They are defined with the following syntax:

```sh
VAR_NAME=value
```

If we use a shell variable instead of an environment variable in a similar
example to what's shown in the previous "Environment variables" section:

```sh
VAR=hello && echo $VAR && deno eval "console.log('Deno: ' + Deno.env.get('VAR'))"
```

We will get the following output:

```
hello
Deno: undefined
```

Shell variables can be useful when we want to re-use a value, but don't want it
available in any spawned processes.

### Pipelines

Pipelines provide a way to pipe the output of one command to another.

The following command pipes the stdout output "Hello" to the stdin of the
spawned Deno process:

```sh
echo Hello | deno run main.ts
```

To pipe stdout and stderr, use `|&` instead:

```sh
deno eval 'console.log(1); console.error(2);' |& deno run main.ts
```

### Command substitution

The `$(command)` syntax provides a way to use the output of a command in other
commands that get executed.

For example, to provide the output of getting the latest git revision to another
command you could do the following:

```sh
deno run main.ts $(git rev-parse HEAD)
```

Another example using a shell variable:

```sh
REV=$(git rev-parse HEAD) && deno run main.ts $REV && echo $REV
```

### Negate exit code

To negate the exit code, add an exclamation point and space before a command:

```sh
# change the exit code from 1 to 0
! deno eval 'Deno.exit(1);'
```

### Redirects

Redirects provide a way to pipe stdout and/or stderr to a file.

For example, the following redirects _stdout_ of `deno run main.ts` to a file
called `file.txt` on the file system:

```sh
deno run main.ts > file.txt
```

To instead redirect _stderr_, use `2>`:

```sh
deno run main.ts 2> file.txt
```

To redirect both stdout _and_ stderr, use `&>`:

```sh
deno run main.ts &> file.txt
```

To append to a file, instead of overwriting an existing one, use two right angle
brackets instead of one:

```sh
deno run main.ts >> file.txt
```

Suppressing either stdout, stderr, or both of a command is possible by
redirecting to `/dev/null`. This works in a cross platform way including on
Windows.

```sh
# suppress stdout
deno run main.ts > /dev/null
# suppress stderr
deno run main.ts 2> /dev/null
# suppress both stdout and stderr
deno run main.ts &> /dev/null
```

Note that redirecting input and multiple redirects are currently not supported.

### Glob expansion

Glob expansion is supported in Deno 1.34 and above. This allows for specifying
globs to match files in a cross platform way.

```
# match .ts files in the current and descendant directories
echo **/*.ts
# match .ts files in the current directory
echo *.ts
# match files that start with "data", have a single number, then end with .csv
echo data[0-9].csv
```

The supported glob characters are `*`, `?`, and `[`/`]`.

## Built-in commands

`deno task` ships with several built-in commands that work the same out of the
box on Windows, Mac, and Linux.

- [`cp`](https://man7.org/linux/man-pages/man1/cp.1.html) - Copies files.
- [`mv`](https://man7.org/linux/man-pages/man1/mv.1.html) - Moves files.
- [`rm`](https://man7.org/linux/man-pages/man1/rm.1.html) - Remove files or
  directories.
  - Ex: `rm -rf [FILE]...` - Commonly used to recursively delete files or
    directories.
- [`mkdir`](https://man7.org/linux/man-pages/man1/mkdir.1.html) - Makes
  directories.
  - Ex. `mkdir -p DIRECTORY...` - Commonly used to make a directory and all its
    parents with no error if it exists.
- [`pwd`](https://man7.org/linux/man-pages/man1/pwd.1.html) - Prints the name of
  the current/working directory.
- [`sleep`](https://man7.org/linux/man-pages/man1/sleep.1.html) - Delays for a
  specified amount of time.
  - Ex. `sleep 1` to sleep for 1 second, `sleep 0.5` to sleep for half a second,
    or `sleep 1m` to sleep a minute
- [`echo`](https://man7.org/linux/man-pages/man1/echo.1.html) - Displays a line
  of text.
- [`cat`](https://man7.org/linux/man-pages/man1/cat.1.html) - Concatenates files
  and outputs them on stdout. When no arguments are provided it reads and
  outputs stdin.
- [`exit`](https://man7.org/linux/man-pages/man1/exit.1p.html) - Causes the
  shell to exit.
- [`unset`](https://man7.org/linux/man-pages/man1/unset.1p.html) - Unsets
  environment variables.
- [`xargs`](https://man7.org/linux/man-pages/man1/xargs.1p.html) - Builds
  arguments from stdin and executes a command.

If you find a useful flag missing on a command or have any suggestions for
additional commands that should be supported out of the box, then please
[open an issue](https://github.com/denoland/deno_task_shell/issues) on the
[deno_task_shell](https://github.com/denoland/deno_task_shell/) repo.

Note that if you wish to execute any of these commands in a non-cross platform
way on Mac or Linux, then you may do so by running it through `sh`:
`sh -c <command>` (ex. `sh -c cp source destination`).

## package.json support

`deno task` falls back to reading from the `"scripts"` entries in a package.json
file if it is discovered. Note that Deno does not respect or support any npm
life cycle events like `preinstall` or `postinstall`—you must explicitly run the
script entries you want to run (ex.
`deno cache main.ts && deno task postinstall`).



/. 🚀 runtime/manual/tools/vendor.md
===================================================

# Vendoring Dependencies

`deno vendor <specifiers>...` will download all remote dependencies of the
specified modules into a local `vendor` folder. For example:

```shell
# Vendor the remote dependencies of main.ts
$ deno vendor main.ts

# Example file system tree
$ tree
.
├── main.ts
└── vendor
    ├── deno.land
    ├── import_map.json
    └── raw.githubusercontent.com

# Check the directory into source control
$ git add -u vendor
$ git commit
```

To then use the vendored dependencies in your program, just add
`--import-map=vendor/import_map.json` to your Deno invocations. You can also add
`--no-remote` to your invocation to completely disable fetching of remote
modules to ensure it's using the modules in the vendor directory.

```shell
deno run --no-remote --import-map=vendor/import_map.json main.ts
```

Note that you may specify multiple modules and remote modules when vendoring.

```shell
deno vendor main.ts test.deps.ts https://deno.land/std/path/mod.ts
```

Run `deno vendor --help` for more details.



/. 🚀 runtime/tutorials/index.md
===================================================

---
displayed_sidebar: runtimeTutorialsHome
sidebar_position: 1
sidebar_label: Overview
pagination_next: tutorials/hello_world
---

* https://docs.deno.com/runtime/tutorials
* https://docs.deno.com/runtime/manual

# Examples

Here you can find some example programs that you can use to learn more about the
runtime.

## Basic

- [Hello World](./hello_world.md)
- [Manage Dependencies](./manage_dependencies.md)
- [Fetch Data](./fetch_data.md)
- [Read and Write Files](./read_write_files.md)
- [Hashbang](./hashbang.md)

## Advanced

- [Unix cat Program](./unix_cat.md)
- [HTTP Web Server](./http_server.md)
- [File Server](./file_server.md)
- [TCP echo Server](./tcp_echo.md)
- [Creating a Subprocess](./subprocess.md)
- [OS Signals](./os_signals.md)
- [File System Events](./file_system_events.md)
- [Module Metadata](./module_metadata.md)

## npm module examples

- [Apollo](./how_to_with_npm/apollo.md)
- [Express](./how_to_with_npm/express.md)
- [Mongoose](./how_to_with_npm/mongoose.md)
- [MySQL](./how_to_with_npm/mysql2.md)
- [PlanetScale](./how_to_with_npm/planetscale.md)
- [Prisma](./how_to_with_npm/prisma.md)
- [React](./how_to_with_npm/react.md)
- [Redis](./how_to_with_npm/redis.md)
- [Vue](./how_to_with_npm/vue.md)

Additional examples can by found at
[Deno by Example](https://examples.deno.land/).



/. 🚀 runtime/tutorials/hello_world.md
===================================================

# Hello World

## Concepts

- Deno can run JavaScript or TypeScript out of the box with no additional tools
  or config required.

## Overview

Deno is a secure runtime for both JavaScript and TypeScript. As the hello world
examples below highlight the same functionality can be created in JavaScript or
TypeScript, and Deno will execute both.

## JavaScript

In this JavaScript example the message `Hello [name]` is printed to the console
and the code ensures the name provided is capitalized.

**Command:** `deno run hello-world.js`

```js
/**
 * hello-world.js
 */
function capitalize(word) {
  return word.charAt(0).toUpperCase() + word.slice(1);
}

function hello(name) {
  return "Hello " + capitalize(name);
}

console.log(hello("john"));
console.log(hello("Sarah"));
console.log(hello("kai"));

/**
 * Output:
 *
 * Hello John
 * Hello Sarah
 * Hello Kai
 */
```

## TypeScript

This TypeScript example is exactly the same as the JavaScript example above, the
code just has the additional type information which TypeScript supports.

The `deno run` command is exactly the same, it just references a `*.ts` file
rather than a `*.js` file.

**Command:** `deno run hello-world.ts`

```ts
/**
 * hello-world.ts
 */
function capitalize(word: string): string {
  return word.charAt(0).toUpperCase() + word.slice(1);
}

function hello(name: string): string {
  return "Hello " + capitalize(name);
}

console.log(hello("john"));
console.log(hello("Sarah"));
console.log(hello("kai"));

/**
 * Output:
 *
 * Hello John
 * Hello Sarah
 * Hello Kai
 */
```



/. 🚀 runtime/tutorials/manage_dependencies.md
===================================================

# Managing Dependencies

## Concepts

- Deno uses URLs for dependency management.
- One convention places all these dependent URLs into a local `deps.ts` file.
  Functionality is then exported out of `deps.ts` for use by local modules.
- Continuing this convention, dev only dependencies can be kept in a
  `dev_deps.ts` file.
- See also [Modules](../manual/basics/modules/index.md)

## Overview

In Deno there is no concept of a package manager as external modules are
imported directly into local modules. This raises the question of how to manage
remote dependencies without a package manager. In big projects with many
dependencies it will become cumbersome and time consuming to update modules if
they are all imported individually into individual modules.

The standard practice for solving this problem in Deno is to create a `deps.ts`
file. All required remote dependencies are referenced in this file and the
required methods and classes are re-exported. The dependent local modules then
reference the `deps.ts` rather than the remote dependencies. If now for example
one remote dependency is used in several files, upgrading to a new version of
this remote dependency is much simpler as this can be done just within
`deps.ts`.

With all dependencies centralized in `deps.ts`, managing these becomes easier.
Dev dependencies can also be managed in a separate `dev_deps.ts` file, allowing
clean separation between dev only and production dependencies.

## Example

```ts
/**
 * deps.ts
 *
 * This module re-exports the required methods from the dependant remote Ramda module.
 */
export {
  add,
  multiply,
} from "https://x.nest.land/ramda@0.27.0/source/index.js";
```

In this example the same functionality is created as is the case in the
[local and remote import examples](../manual/basics/modules/index.md). But in
this case instead of the Ramda module being referenced directly it is referenced
by proxy using a local `deps.ts` module.

**Command:** `deno run example.ts`

```ts, ignore
/**
 * example.ts
 */

import { add, multiply } from "./deps.ts";

function totalCost(outbound: number, inbound: number, tax: number): number {
  return multiply(add(outbound, inbound), tax);
}

console.log(totalCost(19, 31, 1.2));
console.log(totalCost(45, 27, 1.15));

/**
 * Output
 *
 * 60
 * 82.8
 */
```



/. 🚀 runtime/tutorials/fetch_data.md
===================================================

# Fetch Data

## Concepts

- Like browsers, Deno implements web standard APIs such as
  [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).
- Deno is secure by default, meaning explicit permission must be granted to
  access the network.
- See also: Deno's [permissions](../manual/basics/permissions.md) model.

## Overview

When building any sort of web application developers will usually need to
retrieve data from somewhere else on the web. This works no differently in Deno
than in any other JavaScript application, just call the `fetch()` method. For
more information on fetch read the
[MDN documentation](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).

The exception with Deno occurs when running a script which makes a call over the
web. Deno is secure by default which means access to IO (Input / Output) is
prohibited. To make a call over the web Deno must be explicitly told it is ok to
do so. This is achieved by adding the `--allow-net` flag to the `deno run`
command.

## Example

**Command:** `deno run --allow-net fetch.ts`

```js
/**
 * Output: JSON Data
 */
const jsonResponse = await fetch("https://api.github.com/users/denoland");
const jsonData = await jsonResponse.json();
console.log(jsonData);

/**
 * Output: HTML Data
 */
const textResponse = await fetch("https://deno.land/");
const textData = await textResponse.text();
console.log(textData);

/**
 * Output: Error Message
 */
try {
  await fetch("https://does.not.exist/");
} catch (error) {
  console.log(error);
}
```

## Files and Streams

Like in browsers, sending and receiving large files is possible thanks to the
[Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API).
[`Deno.FsFile`](https://deno.land/api?s=Deno.FsFile) API provides two
properties: [`readable`](https://deno.land/api?s=Deno.FsFile#prop_readable) and
[`writable`](https://deno.land/api?s=Deno.FsFile#prop_writable), which can be
used to convert a Deno file into a writable or readable stream.

**Command:** `deno run --allow-read --allow-write --allow-net fetch_file.ts`

```ts
/**
 * Receiving a file
 */
const fileResponse = await fetch("https://deno.land/logo.svg");

if (fileResponse.body) {
  const file = await Deno.open("./logo.svg", { write: true, create: true });
  await fileResponse.body.pipeTo(file.writable);
}

/**
 * Sending a file
 */
const file = await Deno.open("./logo.svg", { read: true });

await fetch("https://example.com/", {
  method: "POST",
  body: file.readable,
});
```



/. 🚀 runtime/tutorials/read_write_files.md
===================================================

# Read and Write Files

## Concepts

- Deno's runtime API provides the
  [Deno.readTextFile](https://deno.land/api?s=Deno.readTextFile) and
  [Deno.writeTextFile](https://deno.land/api?s=Deno.writeTextFile) asynchronous
  functions for reading and writing entire text files.
- Like many of Deno's APIs, synchronous alternatives are also available. See
  [Deno.readTextFileSync](https://deno.land/api?s=Deno.readTextFileSync) and
  [Deno.writeTextFileSync](https://deno.land/api?s=Deno.writeTextFileSync).
- Use `--allow-read` and `--allow-write` permissions to gain access to the file
  system.

## Overview

Interacting with the filesystem to read and write files is a common requirement.
Deno provides a number of ways to do this via the
[standard library](https://deno.land/std) and the
[Deno runtime API](https://deno.land/api).

As highlighted in the [Fetch Data example](./fetch_data.md) Deno restricts
access to Input / Output by default for security reasons. Therefore when
interacting with the filesystem the `--allow-read` and `--allow-write` flags
must be used with the `deno run` command.

## Reading a text file

The Deno runtime API makes it possible to read text files via the
`Deno.readTextFile()` method, it just requires a path string or URL object. The
method returns a promise which provides access to the file's text data.

**Command:** `deno run --allow-read read.ts`

```typescript
/**
 * read.ts
 */
const text = await Deno.readTextFile("./people.json");
console.log(text);

/**
 * Output:
 *
 * [
 *   {"id": 1, "name": "John", "age": 23},
 *   {"id": 2, "name": "Sandra", "age": 51},
 *   {"id": 5, "name": "Devika", "age": 11}
 * ]
 */
```

## Writing a text file

The Deno runtime API allows developers to write text to files via the
`Deno.writeTextFile()` method. It just requires a file path and text string. The
method returns a promise which resolves when the file was successfully written.

To run the command the `--allow-write` flag must be supplied to the `deno run`
command.

**Command:** `deno run --allow-write write.ts`

```typescript
/**
 * write.ts
 */
await Deno.writeTextFile("./hello.txt", "Hello World!");
console.log("File written to ./hello.txt");

/**
 * Output: File written to ./hello.txt
 */
```

You can _append_ text to a file like this:

```typescript
await Deno.writeTextFile("./hello.txt", "This text will be appended.", {
  append: true,
});
```

By combining `Deno.writeTextFile` and `JSON.stringify` you can easily write
serialized JSON objects to a file. This example uses synchronous
`Deno.writeTextFileSync`, but this can also be done asynchronously using
`await Deno.writeTextFile`.

To execute the code the `deno run` command needs the write flag.

**Command:** `deno run --allow-write write.ts`

```typescript
/**
 * write.ts
 */
function writeJson(path: string, data: object): string {
  try {
    Deno.writeTextFileSync(path, JSON.stringify(data));

    return "Written to " + path;
  } catch (e) {
    return e.message;
  }
}

console.log(writeJson("./data.json", { hello: "World" }));

/**
 * Output: Written to ./data.json
 */
```



/. 🚀 runtime/tutorials/hashbang.md
===================================================

# Making Scripts Executable With a Hashbang (Shebang)

## Concepts

- [Deno.env] provides the environment variables.
- [env] runs a program in a modified environment.

## Overview

Making Deno scripts executable can come in handy when creating small tools.

Note: Hashbangs do not work on Windows.

## Example

In this program we give the context permission to access the environment
variables and print the Deno installation path.

```ts, ignore
#!/usr/bin/env -S deno run --allow-env

/**
 *  hashbang.ts
 */

const path = Deno.env.get("DENO_INSTALL");

console.log("Deno Install Path:", path);
```

### Permissions

You may require to give the script execution permissions.

#### Unix

```shell
chmod +x hashbang.ts
```

### Execute

Start the script by calling it like any other command:

```shell
./hashbang.ts
```

## Details

- A hashbang has to be placed in the first line.

- `-S` splits the command into arguments.

- End the file name in `.ts` for the script to be interpreted as TypeScript.

## Using hashbang in files with no extension

You may wish to not use an extension for your script's filename. In this case,
you can supply one by using the `--ext` flag:

```shell, ignore
$ cat my_script
#!/usr/bin/env -S deno run --allow-env --ext=js
console.log("Hello!");
$ ./my_script
Hello!
```

[Deno.env]: https://deno.land/api?s=Deno.env
[env]: https://www.man7.org/linux/man-pages/man1/env.1.html



/. 🚀 runtime/tutorials/word_finder.md
===================================================

    curl -s -L https://docs.deno.com/runtime/tutorials/word_finder | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Building a Word Finder App with Deno

## Getting Started

In this tutorial we'll create a simple Word Finder web application using Deno.
No prior knowledge of Deno is required.

## Introduction

Our Word Finder application will take a pattern string provided by the user and
return all words in the English dictionary that match the pattern. The pattern
can include alphabetical characters as well as `_` and `?`. The `?` can stand
for any letter that isn't present in the pattern. `_` can stand for any letter.

For example, the pattern `c?t` matches "cat" and "cut". The pattern `go?d`
matches the words "goad" and "gold" (but not "good").

![Untitled](https://docs.deno.com/assets/images/word_finder-abd6aabd5ab23cf526a394056c6eca36.png)
<!-- ![Untitled](../manual/images/word_finder.png) -->

## Building the View

The function below renders the HTML that creates the simple UI displayed above.
You can specify a pattern and list of words to customize the HTML content. If a
pattern is specified then it will show up in the search text box. If the word
list is specified, then a bulleted list of words will be rendered.

```jsx
// render.js

export function renderHtml(pattern, words) {
  let searchResultsContent = "";
  if (words.length > 0) {
    let wordList = "";
    for (const word of words) {
      wordList += `<li>${word}</li>`;
    }
    searchResultsContent = `
        <p id="search-result-count" data-count="${words.length}">Words found: ${words.length}</p>
        <ul id="search-result" name="search-results"> 
          ${wordList}
        </ul>
      `;
  }

  return `<html>
    <head>
        <title>Deno Word Finder</title>
        <meta name="version" content="1.0" />
    </head>
    <body>
        <h1>Deno Word Finder</h1>
  
        <form id="perform-search" name="perform-search" method="get" action="/api/search">
            <label for="search-text">Search text:</label>
            <input id="search-text" name="search-text" type="text" value="${pattern}" />
            <input type="submit" />
        </form>
  
        ${searchResultsContent}
  
        <h2>Instructions</h2>
  
        <p>
            Enter a word using _ and ? as needed for unknown characters. Using ? means to include letters that aren't already used (you can think of it as a "Wheel of Fortune" placeholder). Using _ will find words that contain any character (whether it's currently "revealed" or not).
            <br />
            <br />
            For example, d__d would return:
            <ul>
                <li>dand</li>
                <li>daud</li>
                <li>dead</li>
                <li>deed</li>
                <li>dird</li>
                <li>dodd</li>
                <li>dowd</li>
                <li>duad</li>
                <li>dyad</li>
            </ul>
            <br />
            And go?d would return:
            <ul>
                <li>goad</li>
                <li>gold</li>
            </ul>
        </p>
    </body>
  </html>
  `;
}
```

## Searching the Dictionary

We also need a simple search function which scans the dictionary and returns all
words that match the specified pattern. The function below takes a pattern and
dictionary and then returns all matched words.

```jsx
// search.js

export function search(pattern, dictionary) {
  // Create regex pattern that excludes characters already present in word
  let excludeRegex = "";
  for (let i = 0; i < pattern.length; i++) {
    const c = pattern[i];
    if (c != "?" && c != "_") {
      excludeRegex += "^" + c;
    }
  }
  excludeRegex = "[" + excludeRegex + "]";

  // Let question marks only match characters not already present in word
  let searchPattern = pattern.replace(/\?/g, excludeRegex);

  // Let underscores match anything
  searchPattern = "^" + searchPattern.replace(/\_/g, "[a-z]") + "$";

  // Find all words in dictionary that match pattern
  let matches = [];
  for (let i = 0; i < dictionary.length; i++) {
    const word = dictionary[i];
    if (word.match(new RegExp(searchPattern))) {
      matches.push(word);
    }
  }

  return matches;
}
```

## Running a Deno Server

[Oak](https://deno.land/x/oak@v11.1.0) is a framework that lets you easily setup
a server in Deno (analogous to JavaScript's Express) and we'll be using it to
host our application. Our server will use our search function to populate our
HTML template with data and then return the customized HTML back to the viewer.
We can conveniently rely on the `/usr/share/dict/words` file as our dictionary
which is a standard file present on most Unix-like operating systems.

```jsx, ignore
// server.js

import { Application, Router } from "https://deno.land/x/oak/mod.ts";
import { search } from "./search.js";
import { renderHtml } from "./render.js";

const dictionary = (await Deno.readTextFile("/usr/share/dict/words")).split(
  "\n",
);

const app = new Application();
const port = 8080;

const router = new Router();

router.get("/", async (ctx) => {
  ctx.response.body = renderHtml("", []);
});

router.get("/api/search", async (ctx) => {
  const pattern = ctx.request.url.searchParams.get("search-text");
  ctx.response.body = renderHtml(pattern, search(pattern, dictionary));
});

app.use(router.routes());
app.use(router.allowedMethods());

console.log("Listening at http://localhost:" + port);
await app.listen({ port });
```

We can start our server with the following command. Note we need to explicitly
grant access to the file system and network because Deno is secure by default.

```bash
deno run --allow-read --allow-net server.js
```

Now if you visit [http://localhost:8080](http://localhost:8080/) you should be
able to view the Word Finder app.

## Example Code

You can find the entire example code
[here](https://github.com/awelm/deno-word-finder).



/. 🚀 runtime/tutorials/unix_cat.md
===================================================

# An Implementation of the Unix "cat" Program

## Concepts

- Use the Deno runtime API to output the contents of a file to the console.
- [Deno.args](https://deno.land/api?s=Deno.args) accesses the command line
  arguments.
- [Deno.open](https://deno.land/api?s=Deno.open) is used to get a handle to a
  file.
- [Deno.stdout.writable](https://deno.land/api?s=Deno.stdout.writable) is used
  to get a writable stream to the console standard output.
- [Deno.FsFile.readable](https://deno.land/api?s=Deno.FsFile#prop_readable) is
  used to get a readable stream from the file. (This readable stream closes the
  file when it is finished reading, so it is not necessary to close the file
  explicitly.)
- Modules can be run directly from remote URLs.

## Example

In this program each command-line argument is assumed to be a filename, the file
is opened, and printed to stdout (e.g. the console).

```ts
/**
 * cat.ts
 */
for (const filename of Deno.args) {
  const file = await Deno.open(filename);
  await file.readable.pipeTo(Deno.stdout.writable, { preventClose: true });
}
```

To run the program:

```shell
deno run --allow-read https://deno.land/std/examples/cat.ts /etc/passwd
```



/. 🚀 runtime/tutorials/http_server.md
===================================================

# Simple HTTP Web Server

## Concepts

- Use Deno's integrated HTTP server to run your own web server.

## Overview

With just a few lines of code you can run your own HTTP web server with control
over the response status, request headers and more.

```ts title="server.ts"
const port = 8080;

const handler = (request: Request): Response => {
  const body = `Your user-agent is:\n\n${
    request.headers.get("user-agent") ?? "Unknown"
  }`;

  return new Response(body, { status: 200 });
};

console.log(`HTTP server running. Access it at: http://localhost:8080/`);
Deno.serve({ port }, handler);
```

Then run this with:

```shell
deno run --allow-net server.ts
```



/. 🚀 runtime/tutorials/file_server.md
===================================================

# File Server

## Concepts

- Use [Deno.open](https://deno.land/api?s=Deno.open) to read a file's content in
  chunks.
- Transform a Deno file into a
  [ReadableStream](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream).
- Use Deno's integrated HTTP server to run your own file server.

## Overview

Sending files over the network is a common requirement. As seen in the
[Fetch Data example](./fetch_data.md), because files can be of any size, it is
important to use streams in order to prevent having to load entire files into
memory.

## Example

**Command:** `deno run --allow-read=. --allow-net file_server.ts`

```ts
// Start listening on port 8080 of localhost.
const server = Deno.listen({ port: 8080 });
console.log("File server running on http://localhost:8080/");

for await (const conn of server) {
  handleHttp(conn).catch(console.error);
}

async function handleHttp(conn: Deno.Conn) {
  const httpConn = Deno.serveHttp(conn);
  for await (const requestEvent of httpConn) {
    // Use the request pathname as filepath
    const url = new URL(requestEvent.request.url);
    const filepath = decodeURIComponent(url.pathname);

    // Try opening the file
    let file;
    try {
      file = await Deno.open("." + filepath, { read: true });
    } catch {
      // If the file cannot be opened, return a "404 Not Found" response
      const notFoundResponse = new Response("404 Not Found", { status: 404 });
      await requestEvent.respondWith(notFoundResponse);
      continue;
    }

    // Build a readable stream so the file doesn't have to be fully loaded into
    // memory while we send it
    const readableStream = file.readable;

    // Build and send the response
    const response = new Response(readableStream);
    await requestEvent.respondWith(response);
  }
}
```

## Using the `std/http` file server

The Deno standard library provides you with a
[file server](https://deno.land/std/http/file_server.ts) so that
you don't have to write your own.

To use it, first install the remote script to your local file system. This will
install the script to the Deno installation root's bin directory, e.g.
`/home/alice/.deno/bin/file_server`.

```shell
deno install --allow-net --allow-read https://deno.land/std/http/file_server.ts
```

You can now run the script with the simplified script name. Run it:

```shell
$ file_server .
Downloading https://deno.land/std/http/file_server.ts...
[...]
HTTP server listening on http://0.0.0.0:4507/
```

Now go to [http://0.0.0.0:4507/](http://0.0.0.0:4507/) in your web browser to
see your local directory contents.

The complete list of options are available via:

```shell
file_server --help
```

Example output:

```
Deno File Server
    Serves a local directory in HTTP.
  INSTALL:
    deno install --allow-net --allow-read https://deno.land/std/http/file_server.ts
  USAGE:
    file_server [path] [options]
  OPTIONS:
    -h, --help          Prints help information
    -p, --port <PORT>   Set port
    --cors              Enable CORS via the "Access-Control-Allow-Origin" header
    --host     <HOST>   Hostname (default is 0.0.0.0)
    -c, --cert <FILE>   TLS certificate file (enables TLS)
    -k, --key  <FILE>   TLS key file (enables TLS)
    --no-dir-listing    Disable directory listing
    All TLS options are required when one is provided.
```



/. 🚀 runtime/tutorials/tcp_echo.md
===================================================

# TCP echo Server

## Concepts

- Listening for TCP port connections with
  [Deno.listen](https://deno.land/api?s=Deno.listen).
- Use [Deno.Conn.readable](https://deno.land/api?s=Deno.Conn#prop_readable) and
  [Deno.Conn.writable](https://deno.land/api?s=Deno.Conn#prop_writable) to take
  inbound data and redirect it to be outbound data.

## Example

This is an example of a server which accepts connections on port 8080, and
returns to the client anything it sends.

```ts
/**
 * echo_server.ts
 */
const listener = Deno.listen({ port: 8080 });
console.log("listening on 0.0.0.0:8080");
for await (const conn of listener) {
  conn.readable.pipeTo(conn.writable);
}
```

Run with:

```shell
deno run --allow-net echo_server.ts
```

To test it, try sending data to it with
[netcat](https://en.wikipedia.org/wiki/Netcat) (Linux/MacOS only). Below
`'hello world'` is sent over the connection, which is then echoed back to the
user:

```shell
$ nc localhost 8080
hello world
hello world
```

Like the [cat.ts example](./unix_cat.md), the `pipeTo()` method here also does
not make unnecessary memory copies. It receives a packet from the kernel and
sends back, without further complexity.



/. 🚀 runtime/tutorials/chat_app.md
===================================================

    curl -s -L https://docs.deno.com/runtime/tutorials/chat_app | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Chat application with WebSocket

In this tutorial we'll create a simple chat app using Deno. Our chat app will
allow multiple chat clients connected to the same backend to send group messages
through web sockets. After a client chooses a username, they can then start
sending group messages to other online clients. Each client also displays the
list of currently active users.

![Untitled](https://docs.deno.com/assets/images/chat_app_render-0581c4bff72718a055b81edf2c0c5097.png)
<!-- ![Untitled](../manual/images/chat_app_render.png) -->

## Building the View

We can build the simple UI shown above with the following as our `index.html`.
Note that the `app.js` script is our chat client (which will be discussed in
detail later)

```html
<!-- index.html -->

<html>
  <head>
    <title>Chat App</title>
    <script src="/public/app.js"></script>
  </head>
  <body>
    <div style="text-align: center">
      <div>
        <b>Users</b>
        <hr />
        <div id="users"></div>
        <hr class="visible-xs visible-sm" />
      </div>
      <div>
        <input id="data" placeholder="send message" />
        <hr />
        <div id="conversation"></div>
      </div>
    </div>
  </body>
</html>
```

## **WebSocket** Primer

We will rely on Deno's native support for web sockets when building our client
and server. A
[web socket](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket) is a
bidirectional communication channel that allows the both the client and server
to send messages to each other at any time. Web sockets are frequently used in
realtime applications where low latency is critical. Each of our clients will
keep a web socket connection open to our server so they can receive the latest
messages and user logins without constantly polling.

## Chat Client

The chat client `app.js` runs in the browser and listens for updates from our
server and then manipulates the DOM. Specifically our client is listening for
new messages and the list of currently active users. We need to add event
handlers to our client's web socket to specify what happens when our clients
receives a new message or event.

```jsx
// app.js

const myUsername = prompt("Please enter your name") || "Anonymous";
const socket = new WebSocket(
  `ws://localhost:8080/start_web_socket?username=${myUsername}`,
);

socket.onmessage = (m) => {
  const data = JSON.parse(m.data);

  switch (data.event) {
    case "update-users":
      // refresh displayed user list
      let userListHtml = "";
      for (const username of data.usernames) {
        userListHtml += `<div> ${username} </div>`;
      }
      document.getElementById("users").innerHTML = userListHtml;
      break;

    case "send-message":
      // display new chat message
      addMessage(data.username, data.message);
      break;
  }
};

function addMessage(username, message) {
  // displays new message
  document.getElementById(
    "conversation",
  ).innerHTML += `<b> ${username} </b>: ${message} <br/>`;
}

// on page load
window.onload = () => {
  // when the client hits the ENTER key
  document.getElementById("data").addEventListener("keypress", (e) => {
    if (e.key === "Enter") {
      const inputElement = document.getElementById("data");
      var message = inputElement.value;
      inputElement.value = "";
      socket.send(
        JSON.stringify({
          event: "send-message",
          message: message,
        }),
      );
    }
  });
};
```

## Chat Server

[oak](https://deno.land/x/oak@v11.1.0) is the Deno middleware framework that
we'll be using to set up our server. Our server will return the plain
`index.html` file previously shown when the user first navigates to the site.
Our server also exposes a `ws_endpoint/` endpoint which the chat clients will
use to create their web socket connection. Note that the client's initial HTTP
connection is converted into a WebSocket connection by the server via HTTP's
[protocol upgrade mechanism](https://developer.mozilla.org/en-US/docs/Web/HTTP/Protocol_upgrade_mechanism).
Our server will maintain web socket connections with each active client and tell
them which users are currently active. Our server will also broadcast a message
to all active clients whenever there is a new message so that each client can
display it.

```jsx
// server.js

import { Application, Router } from "https://deno.land/x/oak/mod.ts";

const connectedClients = new Map();

const app = new Application();
const port = 8080;
const router = new Router();

// send a message to all connected clients
function broadcast(message) {
  for (const client of connectedClients.values()) {
    client.send(message);
  }
}

// send updated users list to all connected clients
function broadcast_usernames() {
  const usernames = [...connectedClients.keys()];
  console.log(
    "Sending updated username list to all clients: " +
      JSON.stringify(usernames),
  );
  broadcast(
    JSON.stringify({
      event: "update-users",
      usernames: usernames,
    }),
  );
}

router.get("/start_web_socket", async (ctx) => {
  const socket = await ctx.upgrade();
  const username = ctx.request.url.searchParams.get("username");
  if (connectedClients.has(username)) {
    socket.close(1008, `Username ${username} is already taken`);
    return;
  }
  socket.username = username;
  connectedClients.set(username, socket);
  console.log(`New client connected: ${username}`);

  // broadcast the active users list when a new user logs in
  socket.onopen = () => {
    broadcast_usernames();
  };

  // when a client disconnects, remove them from the connected clients list
  // and broadcast the active users list
  socket.onclose = () => {
    console.log(`Client ${socket.username} disconnected`);
    connectedClients.delete(socket.username);
    broadcast_usernames();
  };

  // broadcast new message if someone sent one
  socket.onmessage = (m) => {
    const data = JSON.parse(m.data);
    switch (data.event) {
      case "send-message":
        broadcast(
          JSON.stringify({
            event: "send-message",
            username: socket.username,
            message: data.message,
          }),
        );
        break;
    }
  };
});

app.use(router.routes());
app.use(router.allowedMethods());
app.use(async (context) => {
  await context.send({
    root: `${Deno.cwd()}/`,
    index: "public/index.html",
  });
});

console.log("Listening at http://localhost:" + port);
await app.listen({ port });
```

We can start our server with the following command. Note we need to explicitly
grant access to the file system and network because Deno is secure by default.

```sh
deno run --allow-read --allow-net server.js
```

Now if you visit [http://localhost:8080](http://localhost:8080/) you will be
able to start a chat session. You can open 2 simultaneous windows and try
chatting with yourself.

## Example Code

You can find the entire example code
[here](https://github.com/awelm/deno-chat-app).



/. 🚀 runtime/tutorials/tcp_server.md
===================================================

# TCP server

This is an example of a server which accepts connections on port 8080, and
returns to the client anything it sends.

```ts
const hostname = "0.0.0.0";
const port = 8080;
const listener = Deno.listen({ hostname, port });
console.log(`Listening on ${hostname}:${port}`);
for await (const conn of listener) {
  conn.readable.pipeTo(conn.writable);
}
```

For security reasons, Deno does not allow programs to access the network without
explicit permission. To allow accessing the network, use a command-line flag:

```shell
deno run --allow-net https://deno.land/std/examples/echo_server.ts
```

To test it, try sending data to it with `netcat` (or `telnet` on Windows):

> Note for Windows users: netcat is not available on Windows. Instead you can
> use the built-in telnet client. The telnet client is disabled in Windows by
> default. It is easy to enable however: just follow the instructions
> [on Microsoft TechNet](https://social.technet.microsoft.com/wiki/contents/articles/38433.windows-10-enabling-telnet-client.aspx)

```shell
# Note for Windows users: replace the `nc` below with `telnet`
$ nc localhost 8080
hello world
hello world
```

Like the `cat.ts` example, the `pipeTo(writable)` method does not make a copy of
the data. The data is directly written from the readable stream to the writable
stream.



/. 🚀 runtime/tutorials/subprocess.md
===================================================

# Creating a Subprocess

## Concepts

- Deno is capable of spawning a subprocess via
  [Deno.Command](https://deno.land/api?s=Deno.Command).
- `--allow-run` permission is required to spawn a subprocess.
- Spawned subprocesses do not run in a security sandbox.
- Communicate with the subprocess via the
  [stdin](https://deno.land/api?s=Deno.stdin),
  [stdout](https://deno.land/api?s=Deno.stdout) and
  [stderr](https://deno.land/api?s=Deno.stderr) streams.

## Simple example

This example is the equivalent of running `'echo hello'` from the command line.

```ts
/**
 * subprocess_simple.ts
 */

// define command used to create the subprocess
const command = new Deno.Command(Deno.execPath(), {
  args: [
    "eval",
    "console.log('hello'); console.error('world')",
  ],
});

// create subprocess and collect output
const { code, stdout, stderr } = await command.output();

console.assert(code === 0);
console.assert("world\n" === new TextDecoder().decode(stderr));
console.log(new TextDecoder().decode(stdout));
```

Run it:

```shell
$ deno run --allow-run --allow-read ./subprocess_simple.ts
hello
```

## Security

The `--allow-run` permission is required for creation of a subprocess. Be aware
that subprocesses are not run in a Deno sandbox and therefore have the same
permissions as if you were to run the command from the command line yourself.

## Communicating with subprocesses

By default when you use `Deno.Command()` the subprocess inherits `stdin`,
`stdout` and `stderr` of the parent process. If you want to communicate with
started a subprocess you must use the `"piped"` option.

## Piping to files

This example is the equivalent of running `yes &> ./process_output` in bash.

```ts
/**
 * subprocess_piping_to_file.ts
 */

import {
  mergeReadableStreams,
} from "https://deno.land/std@$STD_VERSION/streams/merge_readable_streams.ts";

// create the file to attach the process to
const file = await Deno.open("./process_output.txt", {
  read: true,
  write: true,
  create: true,
});

// start the process
const command = new Deno.Command("yes", {
  stdout: "piped",
  stderr: "piped",
});

const process = command.spawn();

// example of combining stdout and stderr while sending to a file
const joined = mergeReadableStreams(
  process.stdout,
  process.stderr,
);

// returns a promise that resolves when the process is killed/closed
joined.pipeTo(file.writable).then(() => console.log("pipe join done"));

// manually stop process "yes" will never end on its own
setTimeout(() => {
  process.kill();
}, 100);
```

Run it:

```shell
$ deno run --allow-run --allow-read --allow-write ./subprocess_piping_to_file.ts
```



/. 🚀 runtime/tutorials/os_signals.md
===================================================

# Handle OS Signals

> ⚠️ Windows only supports listening for SIGINT and SIGBREAK as of Deno v1.23.

## Concepts

- [Deno.addSignalListener()](https://deno.land/api?s=Deno.addSignalListener) can
  be used to capture and monitor OS signals.
- [Deno.removeSignalListener()](https://deno.land/api?s=Deno.removeSignalListener)
  can be used to stop watching the signal.

## Set up an OS signal listener

APIs for handling OS signals are modelled after already familiar
[`addEventListener`](https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener)
and
[`removeEventListener`](https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/removeEventListener)
APIs.

> ⚠️ Note that listening for OS signals doesn't prevent event loop from
> finishing, ie. if there are no more pending async operations the process will
> exit.

You can use `Deno.addSignalListener()` function for handling OS signals:

```ts
/**
 * add_signal_listener.ts
 */
console.log("Press Ctrl-C to trigger a SIGINT signal");

Deno.addSignalListener("SIGINT", () => {
  console.log("interrupted!");
  Deno.exit();
});

// Add a timeout to prevent process exiting immediately.
setTimeout(() => {}, 5000);
```

Run with:

```shell
deno run add_signal_listener.ts
```

You can use `Deno.removeSignalListener()` function to unregister previously
added signal handler.

```ts
/**
 * signal_listeners.ts
 */
console.log("Press Ctrl-C to trigger a SIGINT signal");

const sigIntHandler = () => {
  console.log("interrupted!");
  Deno.exit();
};
Deno.addSignalListener("SIGINT", sigIntHandler);

// Add a timeout to prevent process existing immediately.
setTimeout(() => {}, 5000);

// Stop listening for a signal after 1s.
setTimeout(() => {
  Deno.removeSignalListener("SIGINT", sigIntHandler);
}, 1000);
```

Run with:

```shell
deno run signal_listeners.ts
```

## Async iterator example

If you prefer to handle signals using an async iterator, you can use
[`signal()`](https://deno.land/std/signal/mod.ts) API available in `deno_std`:

```ts
/**
 * async_iterator_signal.ts
 */
import { signal } from "https://deno.land/std/signal/mod.ts";

const sig = signal("SIGUSR1", "SIGINT");

// Add a timeout to prevent process exiting immediately.
setTimeout(() => {}, 5000);

for await (const _ of sig) {
  console.log("interrupt or usr1 signal received");
}
```

Run with:

```shell
deno run async_iterator_signal.ts
```



/. 🚀 runtime/tutorials/file_system_events.md
===================================================

# File System Events

## Concepts

- Use [Deno.watchFs](https://deno.land/api?s=Deno.watchFs) to watch for file
  system events.
- Results may vary between operating systems.

## Example

To poll for file system events in the current directory:

```ts
/**
 * watcher.ts
 */
const watcher = Deno.watchFs(".");
for await (const event of watcher) {
  console.log(">>>> event", event);
  // Example event: { kind: "create", paths: [ "/home/alice/deno/foo.txt" ] }
}
```

Run with:

```shell
deno run --allow-read watcher.ts
```

Now try adding, removing and modifying files in the same directory as
`watcher.ts`.

Note that the exact ordering of the events can vary between operating systems.
This feature uses different syscalls depending on the platform:

- Linux: [inotify](https://man7.org/linux/man-pages/man7/inotify.7.html)
- macOS:
  [FSEvents](https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/FSEvents_Progmanual/Introduction/Introduction.html)
- Windows:
  [ReadDirectoryChangesW](https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-readdirectorychangesw)



/. 🚀 runtime/tutorials/module_metadata.md
===================================================

# Module Metadata

## Concepts

- [import.meta](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import.meta)
  can provide information on the context of the module.
- The boolean [import.meta.main](https://deno.land/api?s=ImportMeta#prop_main)
  will let you know if the current module is the program entry point.
- The string [import.meta.url](https://deno.land/api?s=ImportMeta#prop_url) will
  give you the URL of the current module.
- The [import.meta.resolve](https://deno.land/api?s=ImportMeta#prop_resolve)
  allows you to resolve specifier relative to the current module. This function
  takes into account an import map (if one was provided on startup).
- The string [Deno.mainModule](https://deno.land/api?s=Deno.mainModule) will
  give you the URL of the main module entry point, i.e. the module invoked by
  the deno runtime.

## Example

The example below uses two modules to show the difference between
`import.meta.url`, `import.meta.main` and `Deno.mainModule`. In this example,
`module_a.ts` is the main module entry point:

```ts title="module_b.ts"
export function outputB() {
  console.log("Module B's import.meta.url", import.meta.url);
  console.log("Module B's mainModule url", Deno.mainModule);
  console.log(
    "Is module B the main module via import.meta.main?",
    import.meta.main,
  );
}
```

```ts title="module_a.ts"
import { outputB } from "./module_b.ts";

function outputA() {
  console.log("Module A's import.meta.url", import.meta.url);
  console.log("Module A's mainModule url", Deno.mainModule);
  console.log(
    "Is module A the main module via import.meta.main?",
    import.meta.main,
  );
  console.log(
    "Resolved specifier for ./module_b.ts",
    import.meta.resolve("./module_b.ts"),
  );
}

outputA();
console.log("");
outputB();
```

If `module_a.ts` is located in `/home/alice/deno` then the output of
`deno run --allow-read module_a.ts` is:

```
Module A's import.meta.url file:///home/alice/deno/module_a.ts
Module A's mainModule url file:///home/alice/deno/module_a.ts
Is module A the main module via import.meta.main? true
Resolved specifier for ./module_b.ts file:///home/alice/deno/module_b.ts

Module B's import.meta.url file:///home/alice/deno/module_b.ts
Module B's mainModule url file:///home/alice/deno/module_a.ts
Is module B the main module via import.meta.main? false
```



/. 🚀 runtime/tutorials/how_to_with_npm/apollo.md
===================================================

# How to use Apollo with Deno

[Apollo Server](https://www.apollographql.com/) is a GraphQL server that you can
set up in minutes and use with your existing data source (or REST API). You can
then connect any GraphQL client to it to receive the data and take advantage of
GraphQL benefits, such as type-checking and efficient fetching.

We're going to get a simple Apollo server up and running that will allow us to
query some local data. We're only going to need three files for this:

1. `schema.ts` to set up our data model
2. `resolvers.ts` to set up how we're going to populate the data fields in our
   schema
3. Our `main.ts` where the server is going to launch

We'll start by creating them:

```shell, ignore
touch schema.ts resolvers.ts main.ts
```

Let's go through setting up each.

[View source here.](https://github.com/denoland/examples/tree/main/with-apollo)

## schema.ts

Our `schema.ts` file describes our data. In this case, our data is a list of
dinosaurs. We want our users to be able to get the name and a short description
of each dino. In GraphQL language, this means that `Dinosaur` is our **type**,
and `name` and `description` are our **fields**. We can also define the data
type for each field. In this case, both are strings.

This is also where we describe the queries we allow for our data, using the
special **Query** type in GraphQL. We have two queries:

- `dinosaurs` which gets a list of all dinosaurs
- `dinosaur` which takes in the `name` of a dinosaur as an argument and returns
  information about that one type of dinosaur.

We're going to export all this within our `typeDefs` type definitions, variable:

```tsx, ignore
export const typeDefs = `
  type Dinosaur {
    name: String
    description: String
  }

  type Query {
    dinosaurs: [Dinosaur]
		dinosaur(name: String): Dinosaur
  }
`;
```

If we wanted to write data, this is also where we would describe the
**Mutation** to do so. Mutations are how you write data with GraphQL. Because we
are using a static dataset here, we won't be writing anything.

## resolvers.ts

A resolver is responsible for populating the data for each query. Here we have
our list of dinosaurs and all the resolver is going to do is either a) pass that
entire list to the client if the user requests the `dinosaurs` query, or pass
just one if the user requests the `dinosaur` query.

```tsx, ignore
const dinosaurs = [
  {
    name: "Aardonyx",
    description: "An early stage in the evolution of sauropods.",
  },
  {
    name: "Abelisaurus",
    description: '"Abel\'s lizard" has been reconstructed from a single skull.',
  },
];

export const resolvers = {
  Query: {
    dinosaurs: () => dinosaurs,
    dinosaur: (_: any, args: any) => {
      return dinosaurs.find((dinosaur) => dinosaur.name === args.name);
    },
  },
};
```

With the latter, we pass the arguments from the client into a function to match
the name to a name in our dataset.

## main.ts

In our `main.ts` we're going to import the `ApolloServer` as well as `graphql`
and our `typeDefs` from the schema and our resolvers:

```tsx, ignore
import { ApolloServer } from "npm:@apollo/server@^4.1";
import { startStandaloneServer } from "npm:@apollo/server@4.1/standalone";
import { graphql } from "npm:graphql@16.6";
import { typeDefs } from "./schema.ts";
import { resolvers } from "./resolvers.ts";

const server = new ApolloServer({
  typeDefs,
  resolvers,
});

const { url } = await startStandaloneServer(server, {
  listen: { port: 8000 },
});

console.log(`Server running on: ${url}`);
```

We pass our `typeDefs` and `resolvers` to `ApolloServer` to spool up a new
server. Finally, `startStandaloneServer` is a helper function to get the server
up and running quickly.

## Running the server

All that is left to do now is run the server:

```shell, ignore
deno run --allow-net --allow-read --allow-env main.ts
```

You should see `Server running on: 127.0.0.1:8000` in your terminal. If you go
to that address you will see the Apollo sandbox where we can enter our
`dinosaurs` query:

```graphql, ignore
query {
  dinosaurs {
    name
    description
  }
}
```

This will return our dataset:

```graphql
{
  "data": {
    "dinosaurs": [
      {
        "name": "Aardonyx",
        "description": "An early stage in the evolution of sauropods."
      },
      {
        "name": "Abelisaurus",
        "description": "\"Abel's lizard\" has been reconstructed from a single skull."
      }
    ]
  }
}
```

Or if we want just one `dinosaur`:

```graphql, ignore
query {
  dinosaur(name:"Aardonyx") {
    name
    description
  }
}
```

Which returns:

```graphql, ignore
{
  "data": {
    "dinosaur": {
      "name": "Aardonyx",
      "description": "An early stage in the evolution of sauropods."
    }
  }
}
```

Awesome!

[Learn more about using Apollo and GraphQL in their tutorials](https://www.apollographql.com/tutorials/).



/. 🚀 runtime/tutorials/how_to_with_npm/express.md
===================================================

# How to use Express with Deno

[Express](https://expressjs.com/) is a popular web framework known for being
simple and unopinionated with a large ecosystem of middleware.

This How To guide will show you how to create a simple API using Express and
Deno.

[View source here.](https://github.com/denoland/examples/tree/main/with-express)

## Create `main.ts`

Let's create `main.ts`:

```
touch main.ts
```

In `main.ts`, let's create a simple server:

```ts
// @deno-types="npm:@types/express@4.17.15"
import express from "npm:express@4.18.2";

const app = express();

app.get("/", (req, res) => {
  res.send("Welcome to the Dinosaur API!");
});

app.listen(8000);
```

Let's run this server:

```
deno run -A main.ts
```

And point our browser to `localhost:8000`. You should see:

```
Welcome to the Dinosaur API!
```

## Add data and routes

The next step here is to add some data. We'll use this Dinosaur data that we
found from [this article](https://www.thoughtco.com/dinosaurs-a-to-z-1093748).
Feel free to
[copy it from here](https://github.com/denoland/examples/blob/main/with-express/data.json).

Let's create `data.json`:

```
touch data.json
```

And paste in the dinosaur data.

Next, let's import that data into `main.ts`. Let's add this line at the top of
the file:

```ts
import data from "./data.json" assert { type: "json" };
```

Then, we can create the routes to access that data. To keep it simple, let's
just define `GET` handlers for `/api/` and `/api/:dinosaur`. Add the below after
the `const app = express();` line:

```ts
app.get("/", (req, res) => {
  res.send("Welcome to the Dinosaur API!");
});

app.get("/api", (req, res) => {
  res.send(data);
});

app.get("/api/:dinosaur", (req, res) => {
  if (req?.params?.dinosaur) {
    const found = data.find((item) =>
      item.name.toLowerCase() === req.params.dinosaur.toLowerCase()
    );
    if (found) {
      res.send(found);
    } else {
      res.send("No dinosaurs found.");
    }
  }
});

app.listen(8000);
```

Let's run the server with `deno run -A main.ts` and check out
`localhost:8000/api`. You should see a list of dinosaurs:

```json
[
  {
    "name": "Aardonyx",
    "description": "An early stage in the evolution of sauropods."
  },
  {
    "name": "Abelisaurus",
    "description": "\"Abel's lizard\" has been reconstructed from a single skull."
  },
  {
    "name": "Abrictosaurus",
    "description": "An early relative of Heterodontosaurus."
  },
...
```

And when we go to `localhost:8000/api/aardonyx`:

```json
{
  "name": "Aardonyx",
  "description": "An early stage in the evolution of sauropods."
}
```

Great!



/. 🚀 runtime/tutorials/how_to_with_npm/mongoose.md
===================================================

# How to use Mongoose with Deno

[Mongoose](https://mongoosejs.com/) is a popular, schema-based library that
models data for [MongoDB](https://www.mongodb.com/). It simplifies writing
MongoDB validation, casting, and other relevant business logic.

This tutorial will show you how to setup Mongoose and MongoDB with your Deno
project.

[View source](https://github.com/denoland/examples/tree/main/with-mongoose) or
[check out the video guide](https://youtu.be/dmZ9Ih0CR9g).

## Creating a Mongoose Model

Let's create a simple app that connects to MongoDB, creates a `Dinosaur` model,
and adds and updates a dinosaur to the database.

First, we'll create the necessary files and directories:

```
$ touch main.ts && mkdir model && touch model/Dinosaur.ts
```

In `/model/Dinosaur.ts`, we'll import `npm:mongoose`, define the [schema], and
export it:

```ts, ignore
import { model, Schema } from "npm:mongoose@^6.7";

// Define schema.
const dinosaurSchema = new Schema({
  name: { type: String, unique: true },
  description: String,
  createdAt: { type: Date, default: Date.now },
  updatedAt: { type: Date, default: Date.now },
});

// Validations
dinosaurSchema.path("name").required(true, "Dinosaur name cannot be blank.");
dinosaurSchema.path("description").required(
  true,
  "Dinosaur description cannot be blank.",
);

// Export model.
export default model("Dinosaur", dinosaurSchema);
```

## Connecting to MongoDB

Now, in our `main.ts` file, we'll import mongoose and the `Dinosaur` schema, and
connect to MongoDB:

```ts, ignore
import mongoose from "npm:mongoose@^6.7";
import Dinosaur from "./model/Dinosaur.ts";

await mongoose.connect("mongodb://localhost:27017");

// Check to see connection status.
console.log(mongoose.connection.readyState);
```

Because Deno supports top-level `await`, we're able to simply
`await mongoose.connect()`.

Running this, we should expect a log of `1`:

```shell, ignore
$ deno run --allow-read --allow-sys --allow-env --allow-net main.ts
1
```

It worked!

## Manipulating Data

Let's add an instance [method](https://mongoosejs.com/docs/guide.html#methods)
to our `Dinosaur` schema in `/model/Dinosaur.ts`:

```ts, ignore
// ./model/Dinosaur.ts

// Methods.
dinosaurSchema.methods = {
  // Update description.
  updateDescription: async function (description: string) {
    this.description = description;
    return await this.save();
  },
};

// ...
```

This instance method, `updateDescription`, will allow you to update a record's
description.

Back in `main.ts`, let's start adding and manipulating data in MongoDB.

```ts, ignore
// main.ts

// Create a new Dinosaur.
const deno = new Dinosaur({
  name: "Deno",
  description: "The fastest dinosaur ever lived.",
});

// // Insert deno.
await deno.save();

// Find Deno by name.
const denoFromMongoDb = await Dinosaur.findOne({ name: "Deno" });
console.log(
  `Finding Deno in MongoDB -- \n  ${denoFromMongoDb.name}: ${denoFromMongoDb.description}`,
);

// Update description for Deno and save it.
await denoFromMongoDb.updateDescription(
  "The fastest and most secure dinosaur ever lived.",
);

// Check MongoDB to see Deno's updated description.
const newDenoFromMongoDb = await Dinosaur.findOne({ name: "Deno" });
console.log(
  `Finding Deno (again) -- \n  ${newDenoFromMongoDb.name}: ${newDenoFromMongoDb.description}`,
);
```

Running the code, we get:

```
Finding Deno in MongoDB --
  Deno: The fastest dinosaur ever lived.
Finding Deno (again) --
  Deno: The fastest and most secure dinosaur ever lived.
```

Boom!

For more info on using Mongoose, please refer to
[their documentation](https://mongoosejs.com/docs/guide.html).



/. 🚀 runtime/tutorials/how_to_with_npm/mysql2.md
===================================================

# How to use MySQL2 with Deno

[MySQL](https://www.mysql.com/) is the most popular database in the
[2022 Stack Overflow Developer Survey](https://survey.stackoverflow.co/2022/#most-popular-technologies-database)
and counts Facebook, Twitter, YouTube, and Netflix among its users.

[View source here.](https://github.com/denoland/examples/tree/main/with-mysql2)

You can manipulate and query a MySQL database with Deno using the `mysql2` node
package and importing via `npm:mysql2`. This allows us to use its Promise
wrapper and take advantage of top-level await.

```tsx, ignore
import mysql from "npm:mysql2@^2.3.3/promise";
```

## Connecting to MySQL

We can connect to our MySQL server using the `createConnection()` method. You
need the host (`localhost` if you are testing, or more likely a cloud database
endpoint in production) and the user and password:

```tsx, ignore
const connection = await mysql.createConnection({
  host: "localhost",
  user: "root",
  password: "password",
});
```

You can also optionally specify a database during the connection creation. Here
we are going to use `mysql2` to create the database on the fly.

## Creating and populating the database

Now that you have the connection running, you can use `connection.query()` with
SQL commands to create databases and tables as well as insert the initial data.

First we want to generate and select the database to use:

```tsx, ignore
await connection.query("CREATE DATABASE denos");
await connection.query("use denos");
```

Then we want to create the table:

```tsx, ignore
await connection.query(
  "CREATE TABLE `dinosaurs` (   `id` int NOT NULL AUTO_INCREMENT PRIMARY KEY,   `name` varchar(255) NOT NULL,   `description` varchar(255) )",
);
```

After the table is created we can populate the data:

```tsx, ignore
await connection.query(
  "INSERT INTO `dinosaurs` (id, name, description) VALUES (1, 'Aardonyx', 'An early stage in the evolution of sauropods.'), (2, 'Abelisaurus', 'Abels lizard has been reconstructed from a single skull.'), (3, 'Deno', 'The fastest dinosaur that ever lived.')",
);
```

We now have all the data ready to start querying.

## Querying MySQL

We can use the same connection.query() method to write our queries. First we try
and get all the data in our `dinosaurs` table:

```tsx, ignore
const results = await connection.query("SELECT * FROM `dinosaurs`");
console.log(results);
```

The result from this query is all the data in our database:

```tsx, ignore
[
  [
    {
      id: 1,
      name: "Aardonyx",
      description: "An early stage in the evolution of sauropods."
    },
    {
      id: 2,
      name: "Abelisaurus",
      description: `Abel's lizard" has been reconstructed from a single skull.`
    },
    { id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." }
  ],
```

If we want to just get a single element from the database, we can change our
query:

```tsx, ignore
const [results, fields] = await connection.query(
  "SELECT * FROM `dinosaurs` WHERE `name` = 'Deno'",
);
console.log(results);
```

Which gives us a single row result:

```tsx, ignore
[{ id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." }];
```

Finally, we can close the connection:

```tsx, ignore
await connection.end();
```

For more on `mysql2`, check out their documentation
[here](https://github.com/sidorares/node-mysql2).



/. 🚀 runtime/tutorials/how_to_with_npm/planetscale.md
===================================================

# How to use Planetscale with Deno

Planetscale is a MySQL-compatible serverless database that is designed with a
developer workflow where developers can create, branch, and deploy databases
from the command line.

[View source here.](https://github.com/denoland/examples/tree/main/with-planetscale)

We'll use the Planetscale serverless driver, `@planetscale/database`, to work
with Deno. First we want to create `main.ts` and import the connect method from
this package:

```tsx, ignore
import { connect } from "npm:@planetscale/database@^1.4";
```

## Configuring our connection

The connection requires three credentials: host, username, and password. These
are database-specific, so we first need to create a database in Planetscale. You
can do that by following the initial instructions
[here](https://planetscale.com/docs/tutorials/planetscale-quick-start-guide).
Don't worry about adding the schema—we can do that through
`@planetscale/database`.

Once you have created the database, head to Overview, click "Connect", and
choose "Connect with `@planetscale/database`" to get the host and username. Then
click through to Passwords to create a new password for your database. Once you
have all three you can plug them in directly, or better, store them as
environment variables:

```bash
export HOST=<host>
export USERNAME=<username>
export PASSWORD=<password>
```

Then call them using `Deno.env`:

```tsx, ignore
const config = {
  host: Deno.env.get("HOST"),
  username: Deno.env.get("USERNAME"),
  password: Deno.env.get("PASSWORD"),
};

const conn = connect(config);
```

This will also work on Deno Deploy if you set the environment variables in the
dashboard. Run with:

```shell, ignore
deno run --allow-net --allow-env main.ts
```

The `conn` object is now an open connection to our Planetscale database.

## Creating and populating our database table

Now that you have the connection running, you can `conn.execute()` with SQL
commands to create tables and insert the initial data:

```tsx, ignore
await conn.execute(
  "CREATE TABLE dinosaurs (id int NOT NULL AUTO_INCREMENT PRIMARY KEY, name varchar(255) NOT NULL, description varchar(255) NOT NULL);",
);
await conn.execute(
  "INSERT INTO `dinosaurs` (id, name, description) VALUES (1, 'Aardonyx', 'An early stage in the evolution of sauropods.'), (2, 'Abelisaurus', 'Abels lizard has been reconstructed from a single skull.'), (3, 'Deno', 'The fastest dinosaur that ever lived.')",
);
```

## Querying Planetscale

We can use same `conn.execute()` to also write our queries. Let's get a list of
all our dinosaurs:

```tsx, ignore
const results = await conn.execute("SELECT * FROM `dinosaurs`");
console.log(results.rows);
```

The result:

```tsx, ignore
[
  {
    id: 1,
    name: "Aardonyx",
    description: "An early stage in the evolution of sauropods.",
  },
  {
    id: 2,
    name: "Abelisaurus",
    description: "Abels lizard has been reconstructed from a single skull.",
  },
  { id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." },
];
```

We can also get just a single row from the database by specifying a dinosaur
name:

```tsx, ignore
const result = await conn.execute(
  "SELECT * FROM `dinosaurs` WHERE `name` = 'Deno'",
);
console.log(result.rows);
```

Which gives us a single row result:

```tsx, ignore
[{ id: 3, name: "Deno", description: "The fastest dinosaur that ever lived." }];
```

You can find out more about working with Planetscale in their
[docs](https://planetscale.com/docs).



/. 🚀 runtime/tutorials/how_to_with_npm/prisma.md
===================================================

    curl -s -L https://docs.deno.com/runtime/tutorials/how_to_with_npm/prisma | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to create a RESTful API with Prisma and Oak

[Prisma](https://prisma.io) has been one of our top requested modules to work
with in Deno. The demand is understandable, given that Prisma's developer
experience is top notch and plays well with so many persistent data storage
technologies.

We're excited to show you how to use Prisma with Deno.

In this How To guide, we'll setup a simple RESTful API in Deno using Oak and
Prisma.

Let's get started.

[View source](https://github.com/denoland/examples/tree/main/with-prisma) or
[check out the video guide](https://youtu.be/P8VzA_XSF8w).

## Setup the application

Let's create the folder `rest-api-with-prisma-oak` and navigate there:

```shell, ignore
mkdir rest-api-with-prisma-oak
cd rest-api-with-prisma-oak
```

Then, let's run `prisma init` with Deno:

```shell, ignore
deno run --allow-read --allow-env --allow-write npm:prisma@latest init
```

This will generate
[`prisma/schema.prisma`](https://www.prisma.io/docs/concepts/components/prisma-schema).
Let's update it with the following:

```ts, ignore
generator client {
  provider = "prisma-client-js"
  previewFeatures = ["deno"]
  output = "../generated/client"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Dinosaur {
  id          Int     @id @default(autoincrement())
  name        String  @unique
  description String
}
```

Prisma also generates a `.env` file with a `DATABASE_URL` environment variable. Let's
assign `DATABASE_URL` to a PostgreSQL connection string. In this example, we'll
use a free [PostgreSQL database from Supabase](https://supabase.com/database).

Next, let's create the database schema:

```shell, ignore
deno run -A npm:prisma@latest db push
```

After that's complete, we'll need to generate a Prisma Client:

```shell, ignore
deno run -A --unstable npm:prisma@latest generate --no-engine
```

## Setup Accelerate in the Prisma Data Platform

To get started with the Prisma Data Platform:

1. Sign up for a free [Prisma Data Platform account](https://console.prisma.io).
2. Create a project.
3. Navigate to the project you created.
4. Enable Accelerate by providing your database's connection string.
5. Generate an Accelerate connection string and copy it to your clipboard.

Assign the Accelerate connection string, that begins with `prisma://`, to `DATABASE_URL` in your `.env` file replacing your existing connection string.

Next, let's create a seed script to seed the database.

## Seed your Database

Create `./prisma/seed.ts`:

```shell, ignore
touch prisma/seed.ts
```

And in `./prisma/seed.ts`:

```ts, ignore
import { Prisma, PrismaClient } from "../generated/client/deno/edge.ts";
import { load } from "https://deno.land/std@$STD_VERSION/dotenv/mod.ts";

const envVars = await load();

const prisma = new PrismaClient({
  datasourceUrl: envVars.DATABASE_URL,
});

const dinosaurData: Prisma.DinosaurCreateInput[] = [
  {
    name: "Aardonyx",
    description: "An early stage in the evolution of sauropods.",
  },
  {
    name: "Abelisaurus",
    description: "Abel's lizard has been reconstructed from a single skull.",
  },
  {
    name: "Acanthopholis",
    description: "No, it's not a city in Greece.",
  },
];

/**
 * Seed the database.
 */

for (const u of dinosaurData) {
  const dinosaur = await prisma.dinosaur.create({
    data: u,
  });
  console.log(`Created dinosaur with id: ${dinosaur.id}`);
}
console.log(`Seeding finished.`);

await prisma.$disconnect();
```

We can now run `seed.ts` with:

```shell, ignore
deno run -A prisma/seed.ts
```

After doing so, you should be able to see your data on Prisma Studio by running the following command:

```bash, ignore
deno run -A npm:prisma studio
```

You should see something similar to the following screenshot:

![New dinosaurs are in Prisma dashboard](https://docs.deno.com/assets/images/1-dinosaurs-in-prisma-825f3e2dafb04cb0c73f26cdf535e450.png)
<!-- ![New dinosaurs are in Prisma dashboard](../../manual/images/how-to/prisma/1-dinosaurs-in-prisma.png) -->

## Create your API routes

We'll use [`oak`](https://deno.land/x/oak) to create the API routes. Let's keep
them simple for now.

Let's create a `main.ts` file:

```shell, ignore
touch main.ts
```

Then, in your `main.ts` file:

```ts, ignore
import { PrismaClient } from "./generated/client/deno/edge.ts";
import { Application, Router } from "https://deno.land/x/oak@v11.1.0/mod.ts";
import { load } from "https://deno.land/std@$STD_VERSION/dotenv/mod.ts";

const envVars = await load();

/**
 * Initialize.
 */

const prisma = new PrismaClient({
  datasources: {
    db: {
      url: envVars.DATABASE_URL,
    },
  },
});
const app = new Application();
const router = new Router();

/**
 * Setup routes.
 */

router
  .get("/", (context) => {
    context.response.body = "Welcome to the Dinosaur API!";
  })
  .get("/dinosaur", async (context) => {
    // Get all dinosaurs.
    const dinosaurs = await prisma.dinosaur.findMany();
    context.response.body = dinosaurs;
  })
  .get("/dinosaur/:id", async (context) => {
    // Get one dinosaur by id.
    const { id } = context.params;
    const dinosaur = await prisma.dinosaur.findUnique({
      where: {
        id: Number(id),
      },
    });
    context.response.body = dinosaur;
  })
  .post("/dinosaur", async (context) => {
    // Create a new dinosaur.
    const { name, description } = await context.request.body("json").value;
    const result = await prisma.dinosaur.create({
      data: {
        name,
        description,
      },
    });
    context.response.body = result;
  })
  .delete("/dinosaur/:id", async (context) => {
    // Delete a dinosaur by id.
    const { id } = context.params;
    const dinosaur = await prisma.dinosaur.delete({
      where: {
        id: Number(id),
      },
    });
    context.response.body = dinosaur;
  });

/**
 * Setup middleware.
 */

app.use(router.routes());
app.use(router.allowedMethods());

/**
 * Start server.
 */

await app.listen({ port: 8000 });
```

Now, let's run it:

```shell, ignore
deno run -A main.ts
```

Let's visit `localhost:8000/dinosaurs`:

![List of all dinosaurs from REST API](https://docs.deno.com/assets/images/2-dinosaurs-from-api-0d0ab9ee1a88f4be4739dbeb4876afbf.png)
<!-- ![List of all dinosaurs from REST API](../../manual/images/how-to/prisma/2-dinosaurs-from-api.png) -->

Next, let's `POST` a new user with this `curl` command:

```shell, ignore
curl -X POST http://localhost:8000/dinosaur -H "Content-Type: application/json" -d '{"name": "Deno", "description":"The fastest, most secure, easiest to use Dinosaur ever to walk the Earth."}'
```

You should now see a new row on Prisma Studio:

![New dinosaur Deno in Prisma](https://docs.deno.com/assets/images/3-new-dinosaur-in-prisma-fa50b01627f33bac17bcc79b551da043.png)
<!-- ![New dinosaur Deno in Prisma](../../manual/images/how-to/prisma/3-new-dinosaur-in-prisma.png) -->

Nice!

## What's next?

Building your next app will be more productive and fun with Deno and Prisma,
since both technologies deliver an intuitive developer experience with data
modeling, type-safety, and robust IDE support.

If you're interested in connecting Prisma to Deno Deploy,
[check out this awesome guide](https://www.prisma.io/docs/guides/deployment/deployment-guides/deploying-to-deno-deploy).



/. 🚀 runtime/tutorials/how_to_with_npm/react.md
===================================================

    curl -s -L https://docs.deno.com/runtime/tutorials/how_to_with_npm/react | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to use React with Deno

[React](https://reactjs.org) is the most widely used JavaScript frontend
framework. It popularized a declarative approach towards designing user
interfaces, with a reactive data model. Due to its popularity, it's not
surprising that it's the most requested framework when it comes to building web
apps with Deno.

This is a tutorial that walks you through building a simple React app with Deno
in less than five minutes. The app will display a list of dinosaurs. When you
click on one, it'll take you to a dinosaur page with more details.

![demo of the app](https://docs.deno.com/assets/images/react-dinosaur-app-demo-57edc99edd80a5573d71fe81d9e4187c.gif)
<!-- ![demo of the app](../../manual/images/how-to/react/react-dinosaur-app-demo.gif) -->

[View source](https://github.com/denoland/examples/tree/main/with-react) or
[follow the video guide](https://www.youtube.com/watch?v=eStwt_2THd8).

## Create Vite Extra

This tutorial will use [Vite](https://vitejs.dev/) to quickly scaffold a Deno
and React app. Let's run:

```shell
deno run --allow-env --allow-read --allow-write npm:create-vite-extra
```

We'll name our project "dinosaur-react-app". Then, `cd` into the newly created
project folder.

## Add a backend

The next step is to add a backend API. We'll create a very simple API that
returns information about dinosaurs.

In the directory, let's create an `api` folder. In that folder, we'll create a
`main.ts` file, which will run the server, and a `data.json`, which is the hard
coded data.

```shell
mkdir api && touch api/data.json && touch api/main.ts
```

Copy and paste
[this json file](https://github.com/denoland/deno-vue-example/blob/main/api/data.json)
into your `api/data.json`.

Then, let's update `api/main.ts`:

```ts
import { Application, Router } from "https://deno.land/x/oak@v11.1.0/mod.ts";
import { oakCors } from "https://deno.land/x/cors@v1.2.2/mod.ts";
import data from "./data.json" assert { type: "json" };

const router = new Router();
router
  .get("/", (context) => {
    context.response.body = "Welcome to dinosaur API!";
  })
  .get("/api", (context) => {
    context.response.body = data;
  })
  .get("/api/:dinosaur", (context) => {
    if (context?.params?.dinosaur) {
      const found = data.find((item) =>
        item.name.toLowerCase() === context.params.dinosaur.toLowerCase()
      );
      if (found) {
        context.response.body = found;
      } else {
        context.response.body = "No dinosaurs found.";
      }
    }
  });

const app = new Application();
app.use(oakCors()); // Enable CORS for All Routes
app.use(router.routes());
app.use(router.allowedMethods());

await app.listen({ port: 8000 });
```

This is a very simple API server using [`oak`](https://deno.land/x/oak) that
will return dinosaur information based on the route. Let's start the API server:

```shell
deno run --allow-env --allow-net api/main.ts
```

If we go to `localhost:8000`, we see:

![json response of dinosaurs](https://docs.deno.com/assets/images/dinosaur-api-55fa3c52ba37583dba5b513aa6d3e6b8.png)
<!-- ![json response of dinosaurs](../../manual/images/how-to/react/dinosaur-api.png) -->

Lookin' good so far.

## Add a router

Our app will have two routes: `/` and `/:dinosaur`.

We'll use [`react-router-dom`](https://reactrouter.com/en/main) for our routing
logic. Let's add that to our dependencies in `vite.config.mjs`:

```js
import { defineConfig } from "npm:vite@^3.1.3";
import react from "npm:@vitejs/plugin-react@^2.1";

import "npm:react@^18.2";
import "npm:react-dom@^18.2/client";
import "npm:react-router-dom@^6.4"; // Add this line

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [react()],
});
```

Once we add the dependencies there, we can import them without `npm:` specifier
throughout our React app.

Next, let's go to `src/App.jsx` and add our routing logic:

```jsx
import React from "react";
import {
  BrowserRouter as Router,
  Navigate,
  Route,
  Routes,
} from "react-router-dom";
import Index from "./pages/Index.jsx";
import Dinosaur from "./pages/Dinosaur.jsx";

export default function App(props) {
  return (
    <Router>
      <Routes>
        <Route exact path="/" element={<Index />} />
        <Route exact path="/:dinosaur" element={<Dinosaur />} />
        <Route path="*" element={<Navigate to="/" />} />
      </Routes>
    </Router>
  );
}
```

Next, let's add the `<Index>` and `<Dinosaur>` pages.

## Add pages

There will be two pages in this app:

- `src/pages/Index.jsx`: our index page, which lists all of the dinosaurs
- `src/pages/Dinosaur.jsx`: our dinosaur page, which shows details of the
  dinosaur

We'll create a `src/pages` folder and create the `.jsx` files:

```shell
mkdir src/pages && touch src/pages/Index.jsx src/pages/Dinosaur.jsx
```

Let's start with `<Index>`. This page will `fetch` at `localhost:8000/api` and
render that through JSX.

```jsx
import React, { useEffect, useState } from "react";
import { Link, useParams } from "react-router-dom";

const Index = () => {
  const [dinos, setDinos] = useState([]);
  useEffect(() => {
    fetch(`http://localhost:8000/api/`)
      .then(async (res) => await res.json())
      .then((json) => setDinos(json));
  }, []);

  return (
    <div>
      <h1>Welcome to the Dinosaur app</h1>
      <p>
        Click on a dinosaur below to learn more.
      </p>
      <div>
        {dinos.map((dino) => {
          return (
            <div>
              <Link to={`/${dino.name.toLowerCase()}`}>{dino.name}</Link>
            </div>
          );
        })}
      </div>
    </div>
  );
};

export default Index;
```

Next, in `<Dinosaur>`, we'll do the same except for
`localhost:8000/api/${dinosaur}`:

```jsx
import React, { useEffect, useState } from "react";
import { Link, useParams } from "react-router-dom";

const Dinosaur = () => {
  const { dinosaur } = useParams();
  const [dino, setDino] = useState({});
  useEffect(() => {
    fetch(`http://localhost:8000/api/${dinosaur}`)
      .then(async (res) => await res.json())
      .then((json) => setDino(json));
  }, []);

  return (
    <div>
      <h1>{dino.name}</h1>
      <p>
        {dino.description}
      </p>
      <Link to="/">See all</Link>
    </div>
  );
};

export default Dinosaur;
```

Let's start the React app:

```
deno task start
```

And click through the app:

![demo of the app](https://docs.deno.com/assets/images/react-dinosaur-app-demo-57edc99edd80a5573d71fe81d9e4187c.gif)
<!-- ![demo of the app](../../manual/images/how-to/react/react-dinosaur-app-demo.gif) -->

Huzzah!



/. 🚀 runtime/tutorials/how_to_with_npm/redis.md
===================================================

    curl -s -L https://docs.deno.com/runtime/tutorials/how_to_with_npm/redis | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to Use Redis with Deno

[Redis](https://redis.io/) is an in-memory data store you can use for caching,
as a message broker, or for streaming data.

[View source here.](https://github.com/denoland/examples/tree/main/with-redis)

Here we're going to set up Redis to cache data from an API call to speed up any
subsequent requests for that data. We're going to:

- Set up a Redis client to save data from every API call in memory
- Set up a Deno server so we can easily request certain data
- Call the Github API within the server handler to get the data on first request
- Serve data from Redis on every subsequent request

We can do this within a single file, `main.ts`.

## Connecting to a Redis client

We need two modules. The first is the Deno server. We'll use this to get the
information from the user to query our API. The second is Redis. We can grab the
node package for Redis using the `npm:` modifier:

```tsx, ignore
import { Server } from "https://deno.land/std@$STD_VERSION/http/server.ts";
import { createClient } from "npm:redis@^4.5";
```

We create a Redis client using `createClient` and connect to our local Redis
server:

```tsx, ignore
// make a connection to the local instance of redis
const client = createClient({
  url: "redis://localhost:6379",
});

await client.connect();
```

You can also set host, user, password, and port individually in this
[configuration](https://github.com/redis/node-redis/blob/master/docs/client-configuration.md)
object.

## Setting up the server

Our server is going to act as a wrapper around the Github API. A client can call
our server with a Github username in the URL pathname, such as
`http://localhost:3000/{username}`.

Parsing out the pathname and calling the Github API will take place inside a
handler function in our server. We strip the leading slash so we are left with a
variable we can pass to the Github API as a username. We'll then pass the
response back to the user.

```tsx, ignore
const server = new Server({
  handler: async (req) => {
    const { pathname } = new URL(req.url);
    // strip the leading slash
    const username = pathname.substring(1);
    const resp = await fetch(`https://api.github.com/users/${username}`);
    const user = await resp.json();
    return new Response(JSON.stringify(user), {
        headers: {
          "content-type": "application/json",
        },
      });
    }
  },

  port: 3000,
});

server.listenAndServe();
```

We'll run this with:

```tsx, ignore
deno run --allow-net main.ts
```

If we then go to [http://localhost:3000/ry](http://localhost:3000/ry) in
Postman, we'll get the Github response:

![uncached-redis-body.png](https://docs.deno.com/assets/images/uncached-redis-body-2c0927c35c634d44b937de9626abf533.png)
<!-- ![uncached-redis-body.png](../../manual/images/how-to/redis/uncached-redis-body.png) -->

Let's cache this response using Redis.

## Checking the cache

Once we have our response from the Github API, we can cache this within Redis
using `client.set`, with our username as the key and the user object as the
value:

```tsx, ignore
await client.set(username, JSON.stringify(user));
```

Next time we request the same username, we can use `client.get` to get the
cached user:

```tsx, ignore
const cached_user = await client.get(username);
```

This returns null if the key doesn't exist. So we can use it in some flow
control. When we get the username, we'll initially check whether we already have
that user in the cache. If we do we'll serve the cached result. If not, we'll
call the Github API to get the user, cache it, the serve the API result. In both
cases, we'll add a custom header to show which version we're serving:

```tsx, ignore
const server = new Server({
  handler: async (req) => {
    const { pathname } = new URL(req.url);
    // strip the leading slash
    const username = pathname.substring(1);
    const cached_user = await client.get(username);
    if (cached_user) {
      return new Response(cached_user, {
        headers: {
          "content-type": "application/json",
          "is-cached": "true",
        },
      });
    } else {
      const resp = await fetch(`https://api.github.com/users/${username}`);
      const user = await resp.json();
      await client.set(username, JSON.stringify(user));
      return new Response(JSON.stringify(user), {
        headers: {
          "content-type": "application/json",
          "is-cached": "false",
        },
      });
    }
  },

  port: 3000,
});

server.listenAndServe();
```

Running this first time gives us the same response as above, and we'll see the
`is-cached` header set to `false`:

![uncached-redis-header.png](https://docs.deno.com/assets/images/uncached-redis-header-282d783adf41bd48a9ebb94aaeaf073b.png)
<!-- ![uncached-redis-header.png](../../manual/images/how-to/redis/uncached-redis-header.png) -->

But call with the same username again, and we get the cached result. The body is
identical:

![cached-redis-body.png](https://docs.deno.com/assets/images/cached-redis-body-28873d1de299497a3b2ebc7112458e8e.png)
<!-- ![cached-redis-body.png](../../manual/images/how-to/redis/cached-redis-body.png) -->

But the header shows we have the cache:

![cached-redis-header.png](https://docs.deno.com/assets/images/cached-redis-header-c1e1f82d4797dbed7b0df541107be40e.png)
<!-- ![cached-redis-header.png](../../manual/images/how-to/redis/cached-redis-header.png) -->

We can also see that the response was ~200ms quicker!

You can check out the Redis documentation [here](https://redis.io/docs/) and the
Redis node package [here](https://github.com/redis/node-redis).



/. 🚀 runtime/tutorials/how_to_with_npm/vue.md
===================================================

    curl -s -L https://docs.deno.com/runtime/tutorials/how_to_with_npm/vue | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# How to use Vue with Deno

[Vue](https://vuejs.org/) is a progressive front-end JavaScript framework, built
for performance and versatility.

This How To guide will show you how to create a simple app using Deno, Vite, and
Vue.

[View source](https://github.com/denoland/examples/tree/main/with-vue) or
[follow the video guide](https://www.youtube.com/watch?v=MDPauM8fZDE).

## Run `npm:create-vite-extra`

We'll use Vite to scaffold our Vue app. First, run:

```shell
deno run --allow-read --allow-write --allow-env npm:create-vite-extra@latest
```

Name your project, then select "deno-vue".

Then, `cd` into your new project and run:

```shell
deno task dev
```

You should now be able to view your default Deno and Vue app in your browser:

![default vue app](https://docs.deno.com/assets/images/default-vue-app-8a0ffbc131c2cba6f591435fee912689.png)
<!-- ![default vue app](../../manual/images/how-to/vue/default-vue-app.png) -->

## Add a backend

The next step is to add a backend API. We'll create a very simple API that
returns information about dinosaurs.

In the directory, let's create an `api` folder. In that folder, we'll create a
`main.ts` file, which will run the server, and a `data.json`, which is the hard
coded data.

```shell
mkdir api && touch api/data.json && touch api/main.ts
```

Copy and paste
[this json file](https://github.com/denoland/deno-vue-example/blob/main/api/data.json)
into your `api/data.json`.

Then, let's update `api/main.ts`:

```ts
import { Application, Router } from "https://deno.land/x/oak/mod.ts";
import { oakCors } from "https://deno.land/x/cors/mod.ts";
import data from "./data.json" assert { type: "json" };

const router = new Router();
router
  .get("/", (context) => {
    context.response.body = "Welcome to dinosaur API!";
  })
  .get("/api", (context) => {
    context.response.body = data;
  })
  .get("/api/:dinosaur", (context) => {
    if (context?.params?.dinosaur) {
      const found = data.find((item) =>
        item.name.toLowerCase() === context.params.dinosaur.toLowerCase()
      );
      if (found) {
        context.response.body = found;
      } else {
        context.response.body = "No dinosaurs found.";
      }
    }
  });

const app = new Application();
app.use(oakCors()); // Enable CORS for All Routes
app.use(router.routes());
app.use(router.allowedMethods());

await app.listen({ port: 8000 });
```

This is a very simple API server using [`oak`](https://deno.land/x/oak) that
will return dinosaur information based on the route. Let's start the API server:

```shell
deno run --allow-env --allow-net api/main.ts
```

If we go to `localhost:8000/api`, we see:

![json response of dinosaurs](https://docs.deno.com/assets/images/api-response-25c9245e09d56ade97ec4ee03def8d17.png)
<!-- ![json response of dinosaurs](../../manual/images/how-to/vue/api-response.png) -->

Lookin' good so far.

## Add Vue components

Let's update `src/components`. We'll add the files:

- `HomePage.vue`, the component for the home page
- `Dinosaurs.vue`, the component that lists all dinosaur names as anchor links,
  and
- `Dinosaur.vue`, the component that shows an individual dinosaur's name and
  description

```shell
touch src/components/HomePage.vue src/components/Dinosaurs.vue src/components/Dinosaur.vue
```

Before we create the components, let's add some state management.

## Maintain state with `store`

In order to maintain state across our `<Dinosaur>` and `<Dinosaurs>` components,
we'll use [Vue store](https://vuejs.org/guide/scaling-up/state-management.html).
Note for more complex state management, check out the Vue-endorsed
[Pinia](https://pinia.vuejs.org/) library.

Create a `src/store.js` file:

```shell
touch src/store.js
```

And in it, let's add:

```js
import { reactive } from "vue";

export const store = reactive({
  dinosaur: {},
  setDinosaur(name, description) {
    this.dinosaur.name = name;
    this.dinosaur.description = description;
  },
});
```

We'll import `store` into both `Dinosaurs.vue` and `Dinosaur.vue` to set and
retrieve dinosaur name and description.

## Update Vue components

In `Dinosaurs.vue`, we'll do three things:

- send a `GET` request to our API and return that as `dinosaurs`
- iterate through `dinosaurs` and render each `dinosaur` in `<router-link>` that
  points to the `<Dinosaur>` component
- add `store.setDinosaur()` to `@click` on each `dinosaur`, which will set the
  `store`

Here is the complete code below:

```tsx
<script>
import { ref } from 'vue'
import { store } from '../store.js'
export default ({
  async setup() {
    const res = await fetch("http://localhost:8000/api")
    const dinosaurs = await res.json();
    return {
      dinosaurs
    }
  },
  data() {
    return {
      store
    }
  }
})
</script>

<template>
  <div class="container">
    <div v-for="dinosaur in dinosaurs" class="dinosaur-wrapper">
      <span class="dinosaur">
        <router-link :to="{ name: 'Dinosaur', params: { dinosaur: `${dinosaur.name.toLowerCase()}` }}">
          <span @click="store.setDinosaur(dinosaur.name, dinosaur.description)">
            {{dinosaur.name}}
          </span>
        </router-link>
      </span>
    </div>
  </div>
</template>

<style scoped>
.dinosaur {
}
.dinosaur-wrapper {
  display: inline-block;
  margin: 0.15rem 1rem;
  padding: 0.15rem 1rem;
}
.container {
  text-align: left;
}
</style>
```

In `Dinosaur.vue`, we'll add:

- importing `store`
- rendering `store.dinosaur` in the HTML

```tsx
<script>
import { store } from '../store.js';
export default {
  data() {
    return {
      store
    }
  }
}
</script>

<template>
  Name: {{ store.dinosaur.name }}
  <br />
  Description: {{ store.dinosaur.description }}
</template>
```

Next, we'll update `HomePage.vue`. Since the `Dinosaurs` component needs to
fetch the data from the API, we'll use
[`<Suspense>`](https://vuejs.org/guide/built-ins/suspense.html), which manages
async dependencies in a component tree.

```tsx
<script>
import { ref } from 'vue'
import Dinosaurs from './Dinosaurs.vue'
export default {
  components: {
    Dinosaurs
  }
}
</script>

<template>
  <Suspense>
    <template #default>
      <Dinosaurs />
    </template>
    <template #fallback>
      <div>Loading...</div>
    </template>
  </Suspense>

  <p>
    Check out
    <a href="https://vuejs.org/guide/quick-start.html#local" target="_blank"
      >create-vue</a
    >, the official Vue + Vite starter
  </p>
  <p class="read-the-docs">Learn more about using Deno and Vite.</p>
</template>

<style scoped>
.read-the-docs {
  color: #888;
}
</style>
```

Tying it all together, let's update `src/App.vue`:

```tsx
<template>
  <router-view />
</template>;
```

## Add routing

You'll notice that we have used `<router-link>` and `<router-view>`. These
components are part of the [`vue-router` library](https://router.vuejs.org/),
which we'll have to setup and configure in another file.

First, let's import `vue-router` in our `vite.config.mjs` file:

```ts
import { defineConfig } from "npm:vite@^3.1.3";
import vue from "npm:@vitejs/plugin-vue@^3.2.39";

import "npm:vue@^3.2.39";
import "npm:vue-router@4";

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [vue()],
});
```

Next, let's create a folder named `router`. In it, let's create `index.ts`:

```
mkdir router && touch router/index.ts
```

In `router/index.ts`, we'll create `router`, which contains information about
each route and their component, and export it. For more information on using
`vue-router`, check out their [guide](https://router.vuejs.org/guide).

```ts
import { createRouter, createWebHistory } from "vue-router";
import HomePage from "../components/HomePage.vue";
import Dinosaur from "../components/Dinosaur.vue";

const routes = [
  {
    path: "/",
    name: "Home",
    component: HomePage,
  },
  {
    path: "/:dinosaur",
    name: "Dinosaur",
    component: Dinosaur,
    props: true,
  },
];

const router = createRouter({
  history: createWebHistory("/"),
  routes,
});

export default router;
```

Next, in our `src/main.ts` file, which contains all of the logic for the
frontend app, we'll have to import and use `router`:

```ts
import { createApp } from "vue";
import "./style.css";
import App from "./App.vue";
import router from "./router/index.ts";

const app = createApp(App);
app.use(router);
app.mount("#app");
```

Let's run it and see what we get so far:

![Clicking on a dinosaur to get to an individual dinosaur page](https://docs.deno.com/assets/images/vue-demo-f7efdc8c961fd0a77f2d1ebf36558380.gif)
<!-- ![Clicking on a dinosaur to get to an individual dinosaur page](../../manual/images/how-to/vue/vue-demo.gif) -->

Awesome!



/. 🚀 deploy/index.md
===================================================

---
sidebar_position: 1
sidebar_label: Quick Start
displayed_sidebar: deploy
---

* https://docs.deno.com/deploy/manual
* https://docs.deno.com/deploy/tutorials

# Quick Start

This guide will take you from setting up a Deno Deploy account to deploying your
first project.

## **Step 1:** Sign up for Deno Deploy

If you do not have a Deno Deploy account, [sign up](https://deno.com/deploy)
before continuing.

## **Step 2:** Deploy a project

Upon signing in to your account, you should land on a page that lists your
projects. (You won't have any since it's a new account).

Click on the **+New Project** button

There are three ways to deploy a new project in Deno Deploy:

- [Deploy with Github integration](./manual/ci_github)
- [Deploy with `deployctl`](./manual/deployctl)
- [Deploy with Deno Deploy Playground](./manual/playgrounds)

Select one of these methods, depending on the kind of project you have.

### Our recommendation

We generally recommend deploying with the Github integration because it is the
fastest. If you need to run a CI build process first (for example generating
static assets), we recommend deploying with the Github integration, and
selecting [Github Action](./manual/ci_github#github-action)

## **Step 3:** Adjust project settings if necessary

Once the project has been created, you can adjust a number of project settings
on the **Settings** tab. For more details, follow the links below.

- [Custom domain](./manual/custom-domains)
- [Environment variables](./manual/environment-variables)

## **Step 4:** Find project URL

The production URL is the URL that your production deployment can be reached at.

The project name will determine a project's production URL.

It has the form `$PROJECT_ID.deno.dev` (e.g. https://dead-clam-55.deno.dev).



/. 🚀 deploy/tutorials/index.md
===================================================

---
displayed_sidebar: deployTutorialsHome
sidebar_position: 1
sidebar_label: Overview
pagination_next: tutorials/tutorial-http-server
---

# Tutorials

Here, you'll find a collection of tutorials and example applications for Deno
Deploy. Check our ever expanding list of tutorials in the nav, and explore
[examples.deno.land](https://examples.deno.land) for even more.

## Code examples

- [Build a simple API server](./simple-api.md)
- [Serve static assets](./static-site.md)

## App building tutorials

- [Build a Fresh app](./fresh.md)
- [Build a Discord slash command](./discord-slash.md)
- [Build a site with Vite](./vite.md)



/. 🚀 deploy/tutorials/discord-slash.md
===================================================

    curl -s -L https://docs.deno.com/deploy/tutorials/discord-slash | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Discord Slash Command

Discord has a new feature called **Slash Commands**. They allow you to type `/`
followed by a command name to perform some action. For example, you can type
`/giphy cats` (a built-in command) to get some cat gifs.

Discord Slash Commands work by making a request to a URL whenever someone issues
a command. You don't need your app to be running all the time for Slash Commands
to work, which makes Deno Deploy a perfect solution to build such commands.

In this post, let's see how we can build a hello world Slash Command using Deno
Deploy.

## **Step 1:** Create an application on Discord Developer Portal

1. Go to
   [https://discord.com/developers/applications](https://discord.com/developers/applications)
   (login using your discord account if required).
2. Click on **New Application** button available at left side of your profile
   picture.
3. Name your application and click on **Create**.
4. Go to **Bot** section, click on **Add Bot**, and finally on **Yes, do it!**
   to confirm.

That's it. A new application is created which will hold our Slash Command. Don't
close the tab as we need information from this application page throughout our
development.

## **Step 2:** Register Slash command with Discord app

Before we can write some code, we need to curl a Discord endpoint to register a
Slash Command in our app.

Fill `BOT_TOKEN` with the token available in the **Bot** section and `CLIENT_ID`
with the ID available on the **General Information** section of the page and run
the command on your terminal.

```sh
BOT_TOKEN='replace_me_with_bot_token'
CLIENT_ID='replace_me_with_client_id'
curl -X POST \
-H 'Content-Type: application/json' \
-H "Authorization: Bot $BOT_TOKEN" \
-d '{"name":"hello","description":"Greet a person","options":[{"name":"name","description":"The name of the person","type":3,"required":true}]}' \
"https://discord.com/api/v8/applications/$CLIENT_ID/commands"
```

This will register a Slash Command named `hello` that accepts a parameter named
`name` of type string.

## **Step 3:** Create and deploy the hello world Slash Command on Deno Deploy

Next, we need to create a server to respond to Discord when it makes a POST
request with someone's slash command.

1. Navigate to https://dash.deno.com/new and click **Play** under the
   **Playground** card.
2. On the next page, in the editor, click the **Settings** icon on the top menu.
   In the modal that pops up, select **+ Add Variable**.
3. Input `DISCORD_PUBLIC_KEY` as KEY. The VALUE should be the public key
   available in **General Information** section in the Discord application page.
4. Copy and paste the following code into the editor:

   ```ts
   // Sift is a small routing library that abstracts away details like starting a
   // listener on a port, and provides a simple function (serve) that has an API
   // to invoke a function for a specific path.
   import {
     json,
     serve,
     validateRequest,
   } from "https://deno.land/x/sift@0.6.0/mod.ts";
   // TweetNaCl is a cryptography library that we use to verify requests
   // from Discord.
   import nacl from "https://cdn.skypack.dev/tweetnacl@v1.0.3?dts";

   // For all requests to "/" endpoint, we want to invoke home() handler.
   serve({
     "/": home,
   });

   // The main logic of the Discord Slash Command is defined in this function.
   async function home(request: Request) {
     // validateRequest() ensures that a request is of POST method and
     // has the following headers.
     const { error } = await validateRequest(request, {
       POST: {
         headers: ["X-Signature-Ed25519", "X-Signature-Timestamp"],
       },
     });
     if (error) {
       return json({ error: error.message }, { status: error.status });
     }

     // verifySignature() verifies if the request is coming from Discord.
     // When the request's signature is not valid, we return a 401 and this is
     // important as Discord sends invalid requests to test our verification.
     const { valid, body } = await verifySignature(request);
     if (!valid) {
       return json(
         { error: "Invalid request" },
         {
           status: 401,
         },
       );
     }

     const { type = 0, data = { options: [] } } = JSON.parse(body);
     // Discord performs Ping interactions to test our application.
     // Type 1 in a request implies a Ping interaction.
     if (type === 1) {
       return json({
         type: 1, // Type 1 in a response is a Pong interaction response type.
       });
     }

     // Type 2 in a request is an ApplicationCommand interaction.
     // It implies that a user has issued a command.
     if (type === 2) {
       const { value } = data.options.find((option) => option.name === "name");
       return json({
         // Type 4 responds with the below message retaining the user's
         // input at the top.
         type: 4,
         data: {
           content: `Hello, ${value}!`,
         },
       });
     }

     // We will return a bad request error as a valid Discord request
     // shouldn't reach here.
     return json({ error: "bad request" }, { status: 400 });
   }

   /** Verify whether the request is coming from Discord. */
   async function verifySignature(
     request: Request,
   ): Promise<{ valid: boolean; body: string }> {
     const PUBLIC_KEY = Deno.env.get("DISCORD_PUBLIC_KEY")!;
     // Discord sends these headers with every request.
     const signature = request.headers.get("X-Signature-Ed25519")!;
     const timestamp = request.headers.get("X-Signature-Timestamp")!;
     const body = await request.text();
     const valid = nacl.sign.detached.verify(
       new TextEncoder().encode(timestamp + body),
       hexToUint8Array(signature),
       hexToUint8Array(PUBLIC_KEY),
     );

     return { valid, body };
   }

   /** Converts a hexadecimal string to Uint8Array. */
   function hexToUint8Array(hex: string) {
     return new Uint8Array(
       hex.match(/.{1,2}/g)!.map((val) => parseInt(val, 16)),
     );
   }
   ```

5. Click **Save & Deploy** to deploy the server
6. Note the project URL once the file has been deployed. It will be on the upper
   right hand side of the editor, and end in `.deno.dev`.

## **Step 3:** Configure Discord application to use our URL as interactions endpoint URL

1. Go back to your application (Greeter) page on Discord Developer Portal
2. Fill **INTERACTIONS ENDPOINT URL** field with the Deno Deploy project URL
   from above and click on **Save Changes**.

The application is now ready. Let's proceed to the next section to install it.

## **Step 4:** Install the Slash Command on your Discord server

So to use the `hello` Slash Command, we need to install our Greeter application
on our Discord server. Here are the steps:

1. Go to **OAuth2** section of the Discord application page on Discord Developer
   Portal
2. Select `applications.commands` scope and click on the **Copy** button below.
3. Now paste and visit the URL on your browser. Select your server and click on
   **Authorize**.

Open Discord, type `/hello Deno Deploy` and press **Enter**. The output will
look something like below.

![Hello, Deno Deploy!](https://docs.deno.com/assets/images/discord-slash-command-15cff2f022936484704604d1c1f75965.png)
<!-- ![Hello, Deno Deploy!](../docs-images/discord-slash-command.png) -->

Congratulations for completing the tutorial! Go ahead and build some awesome
Discord Slash Commands! And do share them with us on **deploy** channel of
[the Deno Discord server](https://discord.gg/deno).



/. 🚀 deploy/tutorials/fresh.md
===================================================

# Basic Fresh site

This tutorial will cover how to deploy a Fresh application on Deno Deploy.

Fresh is a web framework built for Deno, akin to Express for Node.

## **Step 1:** Create Fresh application

```sh
deno run -A -r https://fresh.deno.dev fresh-site
```

To run this application locally:

```sh
deno task start
```

You can edit `routes/index.js` to modify the application.

## **Step 2:** Create a new Github repo and link your local Fresh application.

1. Create a new Github repo and record the git repo remote URL
2. From your local `fresh-site`, initialize git and push to the new remote repo:

   ```sh
   git init
   git add .
   git commit -m "First commit"
   git remote add <remote-url>
   git push origin main
   ```

## **Step 3:** Deploy to Deno Deploy

1. Navigate to https://dash.deno.com/new and click the **+New Project** button.
2. On the next page, choose the **Deploy from Github repository** card.
3. To fill in the values on the form, choose:
   - the new `fresh-site` Github repo that you just created
     - automatic (fastest)
   - `main` branch
   - `main.ts` as the entrypoint file



/. 🚀 deploy/tutorials/simple-api.md
===================================================

    curl -s -L https://docs.deno.com/deploy/tutorials/simple-api | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Simple API server

Deno is great for creating simple, light-weight API servers. Learn how to create
and deploy one using Deno Deploy in this tutorial.

## Create a local API server

In your terminal, create a file named `server.ts`. We'll implement a simple link
shortener service using a [Deno KV database](/kv/manual).

```ts title="server.ts"
const kv = await Deno.openKv();

Deno.serve(async (request: Request) => {
  // Create short links
  if (request.method == "POST") {
    const body = await request.text();
    const { slug, url } = JSON.parse(body);
    const result = await kv.set(["links", slug], url);
    return new Response(JSON.stringify(result));
  }

  // Redirect short links
  const slug = request.url.split("/").pop() || "";
  const url = (await kv.get(["links", slug])).value as string;
  if (url) {
    return Response.redirect(url, 301);
  } else {
    const m = !slug ? "Please provide a slug." : `Slug "${slug}" not found`;
    return new Response(m, { status: 404 });
  }
});
```

You can run this server on your machine with this command:

```shell
deno run -A --unstable server.ts
```

This server will respond to HTTP `GET` and `POST` requests. The `POST` handler
expects to receive a JSON document in request the body with `slug` and `url`
properties. The `slug` is the short URL component, and the `url` is the full URL
you want to redirect to.

Here's an example of using this API endpoint with cURL:

```shell
curl --header "Content-Type: application/json" \
  --request POST \
  --data '{"url":"https://docs.deno.com/runtime/manual","slug":"denodocs"}' \
  http://localhost:8000/
```

In response, the server should send you JSON with the KV data representing the
result of the `set` operation:

```json
{ "ok": true, "versionstamp": "00000000000000060000" }
```

A `GET` request to our server will take a URL slug as a path parameter, and
redirect to the provided URL. You can visit this URL in the browser, or make
another cURL request to see this in action!

```shell
curl -v http://localhost:8000/denodocs
```

Now that we have an API server, let's push it to a GitHub repository that we'll
later link to Deno Deploy.

## Create a GitHub repository for your app

Sign in to [GitHub](https://github.com) and
[create a new repository](https://docs.github.com/en/get-started/quickstart/create-a-repo).
You can skip adding a README or any other files for now - a blank repo will do
fine for our purposes.

In the folder where you created your API server, initialize a local git repo
with these commands in sequence. Be sure to swap out `your_username` and
`your_repo_name` with the appropriate values.

```sh
echo "# My Deno Link Shortener" >> README.md
git init
git add .
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/your_username/your_repo_name.git
git push -u origin main
```

You should now have a GitHub repository with your `server.ts` file in it, as in
[this example repository](https://github.com/kwhinnery/simple_api_server). Now
you're ready to import and run this application on Deno Deploy.

## Import and deploy your appliction project

Next, sign up for an account on [Deno Deploy](https://dash.deno.com) and
[create a new project](https://dash.deno.com/new). Choose to import an existing
GitHub repository - the one we created a moment ago. The configuration should
look something like this:

![Deno Deploy config](https://docs.deno.com/assets/images/simple_api_deploy-227f87b713b4ed18015a214f6ba345e1.png)
<!-- ![Deno Deploy config](./images/simple_api_deploy.png) -->

Click on the "Create and Deploy" button - in a few moments, your link shortener
service will be live on Deno Deploy!

![Deno Deploy dashboard](https://docs.deno.com/assets/images/simple_api_dashboard-e59f7c785d0969d62557d9caf6b9c682.png)
<!-- ![Deno Deploy dashboard](./images/simple_api_dashboard.png) -->

## Test out your new link shortener

Without any additional configuration (Deno KV just works on Deploy), your app
should run the same as it did on your local machine.

You can add new links using the `POST` handler as you did before. Just replace
the `localhost` URL with your live production URL on Deno Deploy:

```shell
curl --header "Content-Type: application/json" \
  --request POST \
  --data '{"url":"https://docs.deno.com/runtime/manual","slug":"denodocs"}' \
  https://expensive-rook-95.deno.dev/
```

Similarly, you can visit your shortened URLs in the browser, or view the
redirect coming back with a cURL command:

```shell
curl -v https://expensive-rook-95.deno.dev/denodocs
```

This was a very simple example - from here, we suggest you check out a
higher-level web framework like [Fresh](https://fresh.deno.dev), or learn more
about [Deno KV here](/kv/manual). Great work deploying your simple API server!



/. 🚀 deploy/tutorials/static-site.md
===================================================

# Deploy a static site

This tutorial will cover how to deploy a static site (no JavaScript) on Deno
Deploy.

## **Step 1:** Create the static site

```sh
mkdir static-site
cd static-site
touch index.html
```

Inside your `index.html`, paste the following html:

```html
<!DOCTYPE html>
<html>
  <head>
    <title>Hello</title>
  </head>
  <body>
    <h1>Hello</h1>
    <img src="image.png" alt="image" />
  </body>
</html>
```

Make sure that there a `image.png` inside `static-site`.

You have now a html page that says "Hello" and has a logo.

## **Step 2:** Create a new Deno project

1. Navigate to https://dash.deno.com/new and click the **+Empty Project** button
   under **Deploy from command line**.
2. On the next page, grab the project name, in this case `careful-goat-90`.

## **Step 3:** Deploy the static site using `deployctl`

To deploy this repo on Deno Deploy, from the `static-site` repository, run:

```
deployctl deploy --project=careful-goat-90 https://deno.land/std@$STD_VERSION/http/file_server.ts
```

To give a little more explanation of these commands: Because this is a static
site, there is no JavaScript to execute. Instead of giving Deno Deploy a
particular JavaScript or TypeScript file to run as the entrypoint file, you give
it this external `file_server.ts` program, which simply uploads all the static
files in the `static-site` repo, including the image and the html page, to Deno
Deploy. These static assets are then served up.

## **Step 4:** Voila!

If you go under the **Deployments** tab in the `careful-goat-90` project page,
you will see the link to this dev deployment. If you click on the url, you
should now see your html page with the "Hello" and the image.



/. 🚀 deploy/tutorials/tutorial-blog-fresh.md
===================================================

# Build a blog with Fresh

Tutorial [here](https://deno.com/blog/build-a-blog-with-fresh).



/. 🚀 deploy/tutorials/tutorial-dynamodb.md
===================================================

# API server with DynamoDB

In this tutorial let's take a look at how we can use it to build a small API
that has endpoints to insert and retrieve information, backed by DynamoDB.

The tutorial assumes that you have an AWS and Deno Deploy account.

- [Overview](#overview)
- [Setup DynamoDB](#setup-dynamodb)
- [Create a Project in Deno Deploy](#create-a-project-in-deno-deploy)
- [Write the Application](#write-the-application)
- [Deploy the Application](#deploy-the-application)

## Overview

We're going to build an API with a single endpoint that accepts GET/POST
requests and returns appropriate information

```sh
# A GET request to the endpoint should return the details of the song based on its title.
GET /songs?title=Song%20Title # '%20' == space
# response
{
  title: "Song Title"
  artist: "Someone"
  album: "Something",
  released: "1970",
  genres: "country rap",
}

# A POST request to the endpoint should insert the song details.
POST /songs
# post request body
{
  title: "A New Title"
  artist: "Someone New"
  album: "Something New",
  released: "2020",
  genres: "country rap",
}
```

## Setup DynamoDB

Our first step in the process is to generate AWS credentials to programmatically
access DynamoDB.

Generate Credentials:

1. Go to https://console.aws.amazon.com/iam/ and go to "Users" section.
2. Click on **Add user** button, fill the **User name** field (maybe use
   `denamo`) and select **Programmatic access** type.
3. Click on **Next: Permissions**, then on **Attach existing policies
   directly**, search for `AmazonDynamoDBFullAccess` and select it.
4. Click on **Next: Tags**, then on **Next: Review** and finally **Create
   user**.
5. Click on **Download .csv** button to download the credentials.

Create database table:

1. Go to https://console.aws.amazon.com/dynamodb and click on **Create table**
   button.
2. Fill the **Table name** field with `Songs` and **Primary key** with `title`.
3. Scroll down and click on **Create**. That's it.

## Create a Project in Deno Deploy

1. Go to [https://dash.deno.com/new](https://dash.deno.com/new) (Sign in with
   GitHub if you didn't already) and click on **Create**.
2. Now click on **Settings** button available on the project page.
3. Navigate to **Environment Variables** Section and add the following secrets.

- `AWS_ACCESS_KEY_ID` - Use the value that's available under **Access key ID**
  column in the downloaded CSV.
- `AWS_SECRET_ACCESS_KEY` - Use the value that's available under **Secret access
  key** column in the downloaded CSV.

Now click on the project name to go back to the project dashboard. Keep this tab
open as we will come back here later in the deploy step.

## Write the Application

```js
import {
  json,
  serve,
  validateRequest,
} from "https://deno.land/x/sift@0.6.0/mod.ts";
// AWS has an official SDK that works with browsers. As most Deno Deploy's
// APIs are similar to browser's, the same SDK works with Deno Deploy.
// So we import the SDK along with some classes required to insert and
// retrieve data.
import {
  DynamoDBClient,
  GetItemCommand,
  PutItemCommand,
} from "https://cdn.skypack.dev/@aws-sdk/client-dynamodb?dts";

// Create a client instance by providing your region information.
// The credentials are obtained from environment variables which
// we set during our project creation step on Deno Deploy.
const client = new DynamoDBClient({
  region: "ap-south-1",
  credentials: {
    accessKeyId: Deno.env.get("AWS_ACCESS_KEY_ID"),
    secretAccessKey: Deno.env.get("AWS_SECRET_ACCESS_KEY"),
  },
});

serve({
  "/songs": handleRequest,
});

async function handleRequest(request) {
  // The endpoint allows GET and POST request. A parameter named "title"
  // for a GET request to be processed. And body with the fields defined
  // below are required to process POST request.
  // validateRequest ensures that the provided terms are met by the request.
  const { error, body } = await validateRequest(request, {
    GET: {
      params: ["title"],
    },
    POST: {
      body: ["title", "artist", "album", "released", "genres"],
    },
  });
  if (error) {
    return json({ error: error.message }, { status: error.status });
  }

  // Handle POST request.
  if (request.method === "POST") {
    try {
      // When we want to interact with DynamoDB, we send a command using the client
      // instance. Here we are sending a PutItemCommand to insert the data from the
      // request.
      const {
        $metadata: { httpStatusCode },
      } = await client.send(
        new PutItemCommand({
          TableName: "Songs",
          Item: {
            // Here 'S' implies that the value is of type string
            // and 'N' implies a number.
            title: { S: body.title },
            artist: { S: body.artist },
            album: { S: body.album },
            released: { N: body.released },
            genres: { S: body.genres },
          },
        }),
      );

      // On a successful put item request, dynamo returns a 200 status code (weird).
      // So we test status code to verify if the data has been inserted and respond
      // with the data provided by the request as a confirmation.
      if (httpStatusCode === 200) {
        return json({ ...body }, { status: 201 });
      }
    } catch (error) {
      // If something goes wrong while making the request, we log
      // the error for our reference.
      console.log(error);
    }

    // If the execution reaches here it implies that the insertion wasn't successful.
    return json({ error: "couldn't insert data" }, { status: 500 });
  }

  // Handle GET request.
  try {
    // We grab the title form the request and send a GetItemCommand
    // to retrieve the information about the song.
    const { searchParams } = new URL(request.url);
    const { Item } = await client.send(
      new GetItemCommand({
        TableName: "Songs",
        Key: {
          title: { S: searchParams.get("title") },
        },
      }),
    );

    // The Item property contains all the data, so if it's not undefined,
    // we proceed to returning the information about the title
    if (Item) {
      return json({
        title: Item.title.S,
        artist: Item.artist.S,
        album: Item.album.S,
        released: Item.released.S,
        genres: Item.genres.S,
      });
    }
  } catch (error) {
    console.log(error);
  }

  // We might reach here if an error is thrown during the request to database
  // or if the Item is not found in the database.
  // We reflect both conditions with a general message.
  return json(
    {
      message: "couldn't find the title",
    },
    { status: 404 },
  );
}
```

## Deploy the Application

Now that we've everything in place, let's get to deploying the application.

The steps:

1. Go to https://gist.github.com/new and create a new gist with the above code
   (make sure the file ends with `.js`).
   > For convenience, the code is also hosted at
   > https://deno.com/examples/dynamo.js so you can skip creating a gist if you
   > just want to try out the above example without making changes to it.
2. Go to the project (that we previously created) dashboard in Deno Deploy.
3. Click on **Deploy URL** and paste the raw link of the gist.
4. Click on **Deploy** and copy the URL that's displayed under **Domains**
   section.

Let's test the API.

POST some data.

```sh
curl --request POST --data \
'{"title": "Old Town Road", "artist": "Lil Nas X", "album": "7", "released": "2019", "genres": "Country rap, Pop"}' \
--dump-header - https://<project_name>.deno.dev/songs
```

GET information about the title.

```sh
curl https://<project_name>.deno.dev/songs?title=Old%20Town%20Road
```

Congratulations on learning how to use DynamoDB with Deno Deploy!

---

[![Deploy this example](/deno-deploy-button.svg)](https://dash.deno.com/new?url=https://deno.com/examples/dynamo.js&env=AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY)



/. 🚀 deploy/tutorials/tutorial-faunadb.md
===================================================

# API server with FaunaDB

FaunaDB calls itself "The data API for modern applications". It's a database
with a GraphQL interface that enables you to use GraphQL to interact with it.
Since we communicate with it using HTTP requests, we don't need to manage
connections which suits very well for serverless applications.

The tutorial assumes that you've [FaunaDB](https://fauna.com) and Deno Deploy
accounts, Deno Deploy CLI installed, and some basic knowledge of GraphQL.

- [Overview](#overview)
- [Build the API Endpoints](#build-the-api-endpoints)
- [Use FaunaDB for Persistence](#use-faunadb-for-persistence)
- [Deploy the API](#deploy-the-api)

## Overview

In this tutorial, let's build a small quotes API with endpoints to insert and
retrieve quotes. And later use FaunaDB to persist the quotes.

Let's start by defining the API endpoints.

```sh
# A POST request to the endpoint should insert the quote to the list.
POST /quotes/
# Body of the request.
{
  "quote": "Don't judge each day by the harvest you reap but by the seeds that you plant.",
  "author": "Robert Louis Stevenson"
}

# A GET request to the endpoint should return all the quotes from the database.
GET /quotes/
# Response of the request.
{
  "quotes": [
    {
      "quote": "Don't judge each day by the harvest you reap but by the seeds that you plant.",
      "author": "Robert Louis Stevenson"
    }
  ]
}
```

Now that we understand how the endpoint should behave, let's proceed to build
it.

## Build the API Endpoints

First, create a file named `quotes.ts` and paste the following content.

Read through the comments in the code to understand what's happening.

```ts
import {
  json,
  serve,
  validateRequest,
} from "https://deno.land/x/sift@0.6.0/mod.ts";

serve({
  "/quotes": handleQuotes,
});

// To get started, let's just use a global array of quotes.
const quotes = [
  {
    quote: "Those who can imagine anything, can create the impossible.",
    author: "Alan Turing",
  },
  {
    quote: "Any sufficiently advanced technology is equivalent to magic.",
    author: "Arthur C. Clarke",
  },
];

async function handleQuotes(request: Request) {
  // Make sure the request is a GET request.
  const { error } = await validateRequest(request, {
    GET: {},
  });
  // validateRequest populates the error if the request doesn't meet
  // the schema we defined.
  if (error) {
    return json({ error: error.message }, { status: error.status });
  }

  // Return all the quotes.
  return json({ quotes });
}
```

Run the above program using [the Deno CLI](https://deno.land).

```sh
deno run --allow-net=:8000 ./path/to/quotes.ts
# Listening on http://0.0.0.0:8000/
```

And curl the endpoint to see some quotes.

```sh
curl http://127.0.0.1:8000/quotes
# {"quotes":[
# {"quote":"Those who can imagine anything, can create the impossible.", "author":"Alan Turing"},
# {"quote":"Any sufficiently advanced technology is equivalent to magic.","author":"Arthur C. Clarke"}
# ]}
```

Let's proceed to handle the POST request.

Update the `validateRequest` function to make sure a POST request follows the
provided body scheme.

```diff
-  const { error } = await validateRequest(request, {
+  const { error, body } = await validateRequest(request, {
    GET: {},
+   POST: {
+      body: ["quote", "author"]
+   }
  });
```

Handle the POST request by updating `handleQuotes` function with the following
code.

```diff
async function handleQuotes(request: Request) {
  const { error, body } = await validateRequest(request, {
    GET: {},
    POST: {
      body: ["quote", "author"],
    },
  });
  if (error) {
    return json({ error: error.message }, { status: error.status });
  }

+  // Handle POST requests.
+  if (request.method === "POST") {
+    const { quote, author } = body as { quote: string; author: string };
+    quotes.push({ quote, author });
+    return json({ quote, author }, { status: 201 });
+  }

  return json({ quotes });
}
```

Let's test it by inserting some data.

```sh
curl --dump-header - --request POST --data '{"quote": "A program that has not been tested does not work.", "author": "Bjarne Stroustrup"}' http://127.0.0.1:8000/quotes
```

The output might look like something below.

```
HTTP/1.1 201 Created
transfer-encoding: chunked
content-type: application/json; charset=utf-8

{"quote":"A program that has not been tested does not work.","author":"Bjarne Stroustrup"}
```

Awesome! We built our API endpoint, and it's working as expected. Since the data
is stored in memory, it will be lost after a restart. Let's use FaunaDB to
persist our quotes.

## Use FaunaDB for Persistence

Let's define our database schema using GraphQL Schema.

```gql
# We're creating a new type named `Quote` to represent a quote and its author.
type Quote {
  quote: String!
  author: String!
}

type Query {
  # A new field in the Query operation to retrieve all quotes.
  allQuotes: [Quote!]
}
```

Fauna has a graphql endpoint for its database, and it generates essential
mutations like create, update, delete for a data type defined in the schema. For
example, fauna will generate a mutation named `createQuote` to create a new
quote in the database for the data type `Quote`. And we're additionally defining
a query field named `allQuotes` that returns all the quotes in the database.

Let's get to writing the code to interact with fauna from Deno Deploy
applications.

To interact with fauna, we need to make a POST request to its graphql endpoint
with appropriate query and parameters to get the data in return. So let's
construct a generic function that will handle those things.

```typescript
async function queryFauna(
  query: string,
  variables: { [key: string]: unknown },
): Promise<{
  data?: any;
  error?: any;
}> {
  // Grab the secret from the environment.
  const token = Deno.env.get("FAUNA_SECRET");
  if (!token) {
    throw new Error("environment variable FAUNA_SECRET not set");
  }

  try {
    // Make a POST request to fauna's graphql endpoint with body being
    // the query and its variables.
    const res = await fetch("https://graphql.fauna.com/graphql", {
      method: "POST",
      headers: {
        authorization: `Bearer ${token}`,
        "content-type": "application/json",
      },
      body: JSON.stringify({
        query,
        variables,
      }),
    });

    const { data, errors } = await res.json();
    if (errors) {
      // Return the first error if there are any.
      return { data, error: errors[0] };
    }

    return { data };
  } catch (error) {
    return { error };
  }
}
```

Add this code to the `quotes.ts` file. Now let's proceed to update the endpoint
to use fauna.

```diff
async function handleQuotes(request: Request) {
  const { error, body } = await validateRequest(request, {
    GET: {},
    POST: {
      body: ["quote", "author"],
    },
  });
  if (error) {
    return json({ error: error.message }, { status: error.status });
  }

  if (request.method === "POST") {
+    const { quote, author, error } = await createQuote(
+      body as { quote: string; author: string }
+    );
+    if (error) {
+      return json({ error: "couldn't create the quote" }, { status: 500 });
+    }

    return json({ quote, author }, { status: 201 });
  }

  return json({ quotes });
}

+async function createQuote({
+  quote,
+  author,
+}: {
+  quote: string;
+  author: string;
+}): Promise<{ quote?: string; author?: string; error?: string }> {
+  const query = `
+    mutation($quote: String!, $author: String!) {
+      createQuote(data: { quote: $quote, author: $author }) {
+        quote
+        author
+      }
+    }
+  `;
+
+  const { data, error } = await queryFauna(query, { quote, author });
+  if (error) {
+    return { error };
+  }
+
+  return data;
+}
```

Now that we've updated the code to insert new quotes let's set up a fauna
database before proceeding to test the code.

Create a new database:

1. Go to https://dashboard.fauna.com (login if required) and click on **New
   Database**
2. Fill the **Database Name** field and click on **Save**.
3. Click on **GraphQL** section visible on the left sidebar.
4. Create a file ending with `.gql` extension with the content being the schema
   we defined above.

Generate a secret to access the database:

1. Click on **Security** section and click on **New Key**.
2. Select **Server** role and click on **Save**. Copy the secret.

Let's now run the application with the secret.

```sh
FAUNA_SECRET=<the_secret_you_just_obtained> deno run --allow-net=:8000 --watch quotes.ts
# Listening on http://0.0.0.0:8000
```

```sh
curl --dump-header - --request POST --data '{"quote": "A program that has not been tested does not work.", "author": "Bjarne Stroustrup"}' http://127.0.0.1:8000/quotes
```

Notice how the quote was added to your collection in FaunaDB.

Let's write a new function to get all the quotes.

```ts
async function getAllQuotes() {
  const query = `
    query {
      allQuotes {
        data {
          quote
          author
        }
      }
    }
  `;

  const {
    data: {
      allQuotes: { data: quotes },
    },
    error,
  } = await queryFauna(query, {});
  if (error) {
    return { error };
  }

  return { quotes };
}
```

And update the `handleQuotes` function with the following code.

```diff
-// To get started, let's just use a global array of quotes.
-const quotes = [
-  {
-    quote: "Those who can imagine anything, can create the impossible.",
-    author: "Alan Turing",
-  },
-  {
-    quote: "Any sufficiently advanced technology is equivalent to magic.",
-    author: "Arthur C. Clarke",
-  },
-];

async function handleQuotes(request: Request) {
  const { error, body } = await validateRequest(request, {
    GET: {},
    POST: {
      body: ["quote", "author"],
    },
  });
  if (error) {
    return json({ error: error.message }, { status: error.status });
  }

  if (request.method === "POST") {
    const { quote, author, error } = await createQuote(
      body as { quote: string; author: string },
    );
    if (error) {
      return json({ error: "couldn't create the quote" }, { status: 500 });
    }

    return json({ quote, author }, { status: 201 });
  }

+  // It's assumed that the request method is "GET".
+  {
+    const { quotes, error } = await getAllQuotes();
+    if (error) {
+      return json({ error: "couldn't fetch the quotes" }, { status: 500 });
+    }
+
+    return json({ quotes });
+  }
}
```

```sh
curl http://127.0.0.1:8000/quotes
```

You should see all the quotes we've inserted into the database. The final code
of the API is available at https://deno.com/examples/fauna.ts.

## Deploy the API

The process of deploying the API involves creating a new Deno Deploy project and
a secret to hold our FaunaDB secret.

Create a project and a secret:

1. Go to [https://dash.deno.com/new](https://dash.deno.com/new) (Sign in with
   GitHub if you didn't already) and click on **+ Empty Project** under **Deploy
   from the command line**.
2. Now click on **Settings** button available on the project page.
3. Navigate to **Environment Variables** Section and add the following secrets.

- `FAUNA_SECRET` - The value should be the secret we created in the previous
  step or a new one.

Don't close this tab yet.

Deploy the code:

1. Create a gist (make sure the extension of the file is `.ts`) at
   https://gist.github.com/new with your code and grab the raw link of it.
   > For convenience, the code is also hosted at
   > https://deno.com/examples/fauna.ts so you can skip creating a gist if you
   > just want to try out the above example without making changes to it.
2. Go back to Deno Deploy **Settings** screen where we created our secrets.
3. Click on your project name on the **Settings** page to go back to the
   dashboard of your project.
4. Click on **Deploy URL**, paste the raw link and click on **Deploy**.
5. Click on Visit to see your project live on Deno Deploy (remember to append
   `/quotes` to the deployment URL to see the content of your FaunaDB)

That's it.

Congrats on building and deploying the Quotes API!

---

[![Deploy this example](/deno-deploy-button.svg)](https://dash.deno.com/new?url=https://deno.com/examples/fauna.ts&env=FAUNA_SECRET)



/. 🚀 deploy/tutorials/tutorial-firebase.md
===================================================


# API server with Firestore (Firebase)

Firebase is a platform developed by Google for creating mobile and web
applications. You can persist data on the platform using Firestore. In this
tutorial let's take a look at how we can use it to build a small API that has
endpoints to insert and retrieve information.

- [Overview](#overview)
- [Concepts](#concepts)
- [Setup Firebase](#setup-firebase)
- [Write the application](#write-the-application)
- [Deploy the application](#deploy-the-application)

## Overview

We are going to build an API with a single endpoint that accepts `GET` and
`POST` requests and returns a JSON payload of information:

```sh
# A GET request to the endpoint without any sub-path should return the details
# of all songs in the store:
GET /songs
# response
[
  {
    title: "Song Title",
    artist: "Someone",
    album: "Something",
    released: "1970",
    genres: "country rap",
  }
]

# A GET request to the endpoint with a sub-path to the title should return the
# details of the song based on its title.
GET /songs/Song%20Title # '%20' == space
# response
{
  title: "Song Title"
  artist: "Someone"
  album: "Something",
  released: "1970",
  genres: "country rap",
}

# A POST request to the endpoint should insert the song details.
POST /songs
# post request body
{
  title: "A New Title"
  artist: "Someone New"
  album: "Something New",
  released: "2020",
  genres: "country rap",
}
```

In this tutorial, we will be:

- Creating and setting up a
  [Firebase Project](https://console.firebase.google.com/).
- Using a text editor to create our application.
- Creating a [gist](https://gist.github.com/) to "host" our application.
- Deploying our application on [Deno Deploy](https://dash.deno.com/).
- Testing our application using [cURL](https://curl.se/).

## Concepts

There are a few concepts that help in understanding why we take a particular
approach in the rest of the tutorial, and can help in extending the application.
You can skip ahead to [Setup Firebase](#setup-firebase) if you want.

### Deploy is browser-like

Even though Deploy runs in the cloud, in many aspects the APIs it provides are
based on web standards. So when using Firebase, the Firebase APIs are more
compatible with the web than those that are designed for server run times. That
means we will be using the Firebase web libraries in this tutorial.

### Firebase uses XHR

Firebase uses a wrapper around Closure's
[WebChannel](https://google.github.io/closure-library/api/goog.net.WebChannel.html)
and WebChannel was originally built around
[`XMLHttpRequest`](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest).
While WebChannel supports the more modern `fetch()` API, current versions of
Firebase for the web do not uniformly instantiate WebChannel with `fetch()`
support, and instead use `XMLHttpRequest`.

While Deploy is browser-like, it does not support `XMLHttpRequest`.
`XMLHttpRequest` is a "legacy" browser API that has several limitations and
features that would be difficult to implement in Deploy, which means it is
unlikely that Deploy will ever implement that API.

So, in this tutorial we will be using a limited _polyfill_ that provides enough
of the `XMLHttpRequest` feature set to allow Firebase/WebChannel to communicate
with the server.

### Firebase auth

Firebase offers quite [a few options](https://firebase.google.com/docs/auth)
around authentication. In this tutorial we are going to be using email and
password authentication.

When a user is logged in, Firebase can persist that authentication. Because we
are using the web libraries for Firebase, persisting the authentication allows a
user to navigate away from a page and not need to re-log in when returning.
Firebase allows authentication to be persisted in local storage, session storage
or none.

In a Deploy context, it is a little different. A Deploy deployment will remain
"active" meaning that in-memory state will be present from request to request on
some requests, but under various conditions a new deployment can be started up
or shutdown. Currently, Deploy doesn't offer any persistence outside of
in-memory allocation. In addition it doesn't currently offer the global
`localStorage` or `sessionStorage`, which is what is used by Firebase to store
the authentication information.

In order to reduce the need to re-authenticate but also ensure that we can
support multiple-users with a single deployment, we are going to use a polyfill
that will allow us to provide a `localStorage` interface to Firebase, but store
the information as a cookie in the client.

## Setup Firebase

[Firebase](https://firebase.google.com/) is a feature rich platform. All the
details of Firebase administration are beyond the scope of this tutorial. We
will cover what it needed for this tutorial.

1. Create a new project under the
   [Firebase console](https://console.firebase.google.com/).
2. Add a web application to your project. Make note of the `firebaseConfig`
   provided in the setup wizard. It should look something like the below. We
   will use this later:

   ```js
   var firebaseConfig = {
     apiKey: "APIKEY",
     authDomain: "example-12345.firebaseapp.com",
     projectId: "example-12345",
     storageBucket: "example-12345.appspot.com",
     messagingSenderId: "1234567890",
     appId: "APPID",
   };
   ```

3. Under `Authentication` in the administration console for, you will want to
   enable the `Email/Password` sign-in method.
4. You will want to add a user and password under `Authentication` and then
   `Users` section, making note of the values used for later.
5. Add `Firestore Database` to your project. The console will allow you to setup
   in _production mode_ or _test mode_. It is up to you how you configure this,
   but _production mode_ will require you to setup further security rules.
6. Add a collection to the database named `songs`. This will require you to add
   at least one document. Just set the document with an _Auto ID_.

_Note_ depending on the status of your Google account, there maybe other setup
and administration steps that need to occur.

## Write the application

We want to create our application as a JavaScript file in our favorite editor.

The first thing we will do is import the `XMLHttpRequest` polyfill that Firebase
needs to work under Deploy as well as a polyfill for `localStorage` to allow the
Firebase auth to persist logged in users:

```js
import "https://deno.land/x/xhr@0.1.1/mod.ts";
import { installGlobals } from "https://deno.land/x/virtualstorage@0.1.0/mod.ts";
installGlobals();
```

> ℹ️ we are using the current version of packages at the time of the writing of
> this tutorial. They may not be up-to-date and you may want to double check
> current versions.

Because Deploy has a lot of the web standard APIs, it is best to use the web
libraries for Firebase under deploy. Currently v9 is in still in beta for
Firebase, so we will use v8 in this tutorial:

```js
import firebase from "https://cdn.skypack.dev/firebase@8.7.0/app";
import "https://cdn.skypack.dev/firebase@8.7.0/auth";
import "https://cdn.skypack.dev/firebase@8.7.0/firestore";
```

We are also going to use [oak](https://deno.land/x/oak) as the middleware
framework for creating the APIs, including middleware that will take the
`localStorage` values and set them as client cookies:

```js
import {
  Application,
  Router,
  Status,
} from "https://deno.land/x/oak@v7.7.0/mod.ts";
import { virtualStorage } from "https://deno.land/x/virtualstorage@0.1.0/middleware.ts";
```

Now we need to setup our Firebase application. We will be getting the
configuration from environment variables we will setup later under the key
`FIREBASE_CONFIG` and get references to the parts of Firebase we are going to
use:

```js
const firebaseConfig = JSON.parse(Deno.env.get("FIREBASE_CONFIG"));
const firebaseApp = firebase.initializeApp(firebaseConfig, "example");
const auth = firebase.auth(firebaseApp);
const db = firebase.firestore(firebaseApp);
```

We are also going to setup the application to handle signed in users per
request. So we will create a map of users that we have previously signed in in
this deployment. While in this tutorial we will only ever have one signed in
user, the code can easily be adapted to allow clients to sign-in individually:

```js
const users = new Map();
```

Let's create our middleware router and create three different middleware
handlers to support `GET` and `POST` of `/songs` and a `GET` of a specific song
on `/songs/{title}`:

```js
const router = new Router();

// Returns any songs in the collection
router.get("/songs", async (ctx) => {
  const querySnapshot = await db.collection("songs").get();
  ctx.response.body = querySnapshot.docs.map((doc) => doc.data());
  ctx.response.type = "json";
});

// Returns the first document that matches the title
router.get("/songs/:title", async (ctx) => {
  const { title } = ctx.params;
  const querySnapshot = await db.collection("songs").where("title", "==", title)
    .get();
  const song = querySnapshot.docs.map((doc) => doc.data())[0];
  if (!song) {
    ctx.response.status = 404;
    ctx.response.body = `The song titled "${ctx.params.title}" was not found.`;
    ctx.response.type = "text";
  } else {
    ctx.response.body = querySnapshot.docs.map((doc) => doc.data())[0];
    ctx.response.type = "json";
  }
});

function isSong(value) {
  return typeof value === "object" && value !== null && "title" in value;
}

// Removes any songs with the same title and adds the new song
router.post("/songs", async (ctx) => {
  const body = ctx.request.body();
  if (body.type !== "json") {
    ctx.throw(Status.BadRequest, "Must be a JSON document");
  }
  const song = await body.value;
  if (!isSong(song)) {
    ctx.throw(Status.BadRequest, "Payload was not well formed");
  }
  const querySnapshot = await db
    .collection("songs")
    .where("title", "==", song.title)
    .get();
  await Promise.all(querySnapshot.docs.map((doc) => doc.ref.delete()));
  const songsRef = db.collection("songs");
  await songsRef.add(song);
  ctx.response.status = Status.NoContent;
});
```

Ok, we are almost done. We just need to create our middleware application, and
add the `localStorage` middleware we imported:

```js
const app = new Application();
app.use(virtualStorage());
```

And then we need to add middleware to authenticate the user. In this tutorial we
are simply grabbing the username and password from the environment variables we
will be setting up, but this could easily be adapted to redirect a user to a
sign-in page if they are not logged in:

```js
app.use(async (ctx, next) => {
  const signedInUid = ctx.cookies.get("LOGGED_IN_UID");
  const signedInUser = signedInUid != null ? users.get(signedInUid) : undefined;
  if (!signedInUid || !signedInUser || !auth.currentUser) {
    const creds = await auth.signInWithEmailAndPassword(
      Deno.env.get("FIREBASE_USERNAME"),
      Deno.env.get("FIREBASE_PASSWORD"),
    );
    const { user } = creds;
    if (user) {
      users.set(user.uid, user);
      ctx.cookies.set("LOGGED_IN_UID", user.uid);
    } else if (signedInUser && signedInUid.uid !== auth.currentUser?.uid) {
      await auth.updateCurrentUser(signedInUser);
    }
  }
  return next();
});
```

Now let's add our router to the middleware application and set the application
to listen on port 8000:

```js
app.use(router.routes());
app.use(router.allowedMethods());
await app.listen({ port: 8000 });
```

Now we have an application that should serve up our APIs.

## Create a Project in Deno Deploy

1. Go to [https://dash.deno.com/new](https://dash.deno.com/new) (Sign in with
   GitHub if you didn't already) and click on **+ Empty Project** under **Deploy
   from the command line**.
2. Now click on **Settings** button available on the project page.
3. Navigate to **Environment Variables** Section and add the following:

   <dl>
    <dt><code>FIREBASE_USERNAME</code></dt>
    <dd>The Firebase user (email address) that was added above.</dd>
    <dt><code>FIREBASE_PASSWORD</code></dt>
    <dd>The Firebase user password that was added above.</dd>
    <dt><code>FIREBASE_CONFIG</code></dt>
    <dd>The configuration of the Firebase application as a JSON string.</dd>
   </dl>

The configuration needs to be a valid JSON string to be readable by the
application. If the code snippet given when setting up looked like this:

```js
var firebaseConfig = {
  apiKey: "APIKEY",
  authDomain: "example-12345.firebaseapp.com",
  projectId: "example-12345",
  storageBucket: "example-12345.appspot.com",
  messagingSenderId: "1234567890",
  appId: "APPID",
};
```

You would need to set the value of the string to this (noting that spacing and
new lines are not required):

```json
{
  "apiKey": "APIKEY",
  "authDomain": "example-12345.firebaseapp.com",
  "projectId": "example-12345",
  "storageBucket": "example-12345.appspot.com",
  "messagingSenderId": "1234567890",
  "appId": "APPID"
}
```

## Deploy the application

Now let's deploy the application:

1. Go to https://gist.github.com/new and create a new gist, ensuring the
   filename of the gist ends with `.js`.

   > For convenience the whole application is hosted at
   > https://deno.com/examples/firebase.js. You can skip creating a gist if you
   > want to try the example without any modification, or click the link at the
   > bottom of the tutorial.

2. Copy the _Raw_ link of the saved gist.
3. In your project on `dash.deno.com`, click the **Deploy URL** button and enter
   the link to the raw gist in the URL field.
4. Click the **Deploy** button and copy one of the URLs displayed in the
   **Domains** section of the project panel.

Now let's take our API for a spin.

We can create a new song:

```sh
curl --request POST \
  --header "Content-Type: application/json" \
  --data '{"title": "Old Town Road", "artist": "Lil Nas X", "album": "7", "released": "2019", "genres": "Country rap, Pop"}' \
  --dump-header \
  - https://<project_name>.deno.dev/songs
```

And we can get all the songs in our collection:

```sh
curl https://<project_name>.deno.dev/songs
```

And we get specific information about a title we created:

```sh
curl https://<project_name>.deno.dev/songs/Old%20Town%20Road
```

---

[![Deploy this example](/deno-deploy-button.svg)](https://dash.deno.com/new?url=https://deno.com/examples/firebase.js&env=FIREBASE_USERNAME,FIREBASE_PASSWORD,FIREBASE_CONFIG)



/. 🚀 deploy/tutorials/tutorial-http-server.md
===================================================

# Simple HTTP server

In this tutorial, let's build a HTTP server that responds to all incoming HTTP
requests with `Hello World` and a `200 OK` HTTP status. We will be using the
Deno Deploy playground to deploy and edit this script.

## **Step 1:** Write the HTTP server script

Before we start writing the actual script, let's go over some basics: Deno
Deploy lets you listen for incoming HTTP requests using the same
[server side HTTP API][native-http] as the Deno CLI. This API is rather low
level though, so instead of using this API directly we'll use the high level
HTTP API exposed by [`std/http`][std-http].

This API revolves around the [`serve`](https://deno.land/std/http/server.ts)
function.

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

serve((_req) => {/* .. */});
```

> Note: the port number we listen on is not important, as Deno Deploy will
> automatically route requests from the outside world to whatever port we listen
> on.

The handler function is called with two arguments: a [`Request`][request]
object, and a [`ConnInfo`][conninfo] object. The `Request` object contains the
request data, and the `ConnInfo` object contains information about the
underlying connection, such as the origin IP address. You must return a
[`Response`][response] object from the handler function.

Let's use this information to finish our hello world script:

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

serve((_req) => {
  return new Response("Hello World!", {
    headers: { "content-type": "text/plain" },
  });
});
```

## **Step 2:** Deploy script to Deno Deploy

1. Create a new playground project by visiting https://dash.deno.com/new, and
   clicking the **Play** button under the **Playground** card.
2. On the next screen, copy the code above into the editor on the left side of
   the screen.
3. Press the **Save & Deploy** button on the right side of the top toolbar (or
   press <kbd>Ctrl</kbd>+<kbd>S</kbd>).

You can preview the result on the right side of the playground editor, in the
preview pane.

You will see that if you change the script (for example `Hello, World!` ->
`Hello, Galaxy!`) and then re-deploy, the preview will automatically update. The
URL shown at the top of the preview pane can be used to visit the deployed page
from anywhere.

Even in the playground editor, scripts are deployed worldwide across our entire
global network. This guarantees fast and reliable performance, no matter the
location of your users.

[native-http]: https://deno.land/manual@v1.15.1/runtime/http_server_apis
[std-http]: https://deno.land/std/http
[request]: ../api/runtime-request
[conninfo]: https://doc.deno.land/https/deno.land%2Fstd%2Fhttp%2Fserver.ts#ConnInfo
[response]: ../api/runtime-response



/. 🚀 deploy/tutorials/tutorial-hugo-blog.md
===================================================

# Build a blog with Hugo

Tutorial [here](https://deno.com/blog/hugo-blog-with-deno-deploy).



/. 🚀 deploy/tutorials/tutorial-postgres.md
===================================================

# API server with Postgres

Postgres is a popular database for web applications because of its flexibility
and ease of use. This guide will show you how to use Deno Deploy with Postgres.

- [Overview](#overview)
- [Setup Postgres](#setup-postgres)
- [Write and deploy the application](#write-and-deploy-the-application)

## Overview

We are going to build the API for a simple todo list application. It will have
two endpoints:

`GET /todos` will return a list of all todos, and `POST /todos` will create a
new todo.

```
GET /todos
# returns a list of all todos
[
  {
    "id": 1,
    "title": "Buy bread"
  },
  {
    "id": 2,
    "title": "Buy rice"
  },
  {
    "id": 3,
    "title": "Buy spices"
  }
]

POST /todos
# creates a new todo
"Buy milk"
# returns a 201 status code
```

In this tutorial, we will be:

- Creating and setting up a [Postgres](https://www.postgresql.org/) instance on
  [Supabase](https://supabase.com).
- Using a [Deno Deploy](/deploy) Playground to develop and deploy the
  application.
- Testing our application using [cURL](https://curl.se/).

## Setup Postgres

> This tutorial will focus entirely on connecting to Postgres unencrypted. If
> you would like to use encryption with a custom CA certificate, use the
> documentation [here](https://deno-postgres.com/#/?id=ssltls-connection).

To get started we need to create a new Postgres instance for us to connect to.
For this tutorial we will be using [Supabase](https://supabase.com) as they
provide free, managed Postgres instances. If you like to host your database
somewhere else, you can do that too.

1. Visit https://app.supabase.io/ and click "New project".
2. Select a name, password, and region for your database. Make sure to save the
   password, as you will need it later.
3. Click "Create new project". Creating the project can take a while, so be
   patient.
4. Once the project is created, navigate to the "Database" tab on the left.
5. Go to the "Connection Pooling" settings, and copy the connection string from
   the "Connection String" field. This is the connection string you will use to
   connect to your database. Insert the password you saved earlier into this
   string, and then save the string somewhere - you will need it later.

## Write and deploy the application

We can now start writing our application. To start, we will create a new Deno
Deploy playground in the control panel: press the "New Playground" button on
https://dash.deno.com/projects.

This will open up the playground editor. Before we can actually start writing
code, we'll need to put our Postgres connection string into the environment
variables. To do this, click on the project name in the top left corner of the
editor. This will open up the project settings.

From here, you can navigate to the "Settings" -> "Environment Variable" tab via
the left navigation menu. Enter "DATABASE_URL" into the "Key" field, and paste
your connection string into the "Value" field. Now, press "Add". Your
environment variables is now set.

Let's return back to the editor: to do this, go to the "Overview" tab via the
left navigation menu, and press "Open Playground". Let's start by the `std/http`
module so we can start serving HTTP requests:

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

serve(async (req) => {
  return new Response("Not Found", { status: 404 });
});
```

You can already save this code using <kbd>Ctrl</kbd>+<kbd>S</kbd> (or
<kbd>Cmd</kbd>+<kbd>S</kbd> on Mac). You should see the preview page on the
right refresh automatically: it now says "Not Found".

Next, let's import the Postgres module, read the connection string from the
environment variables, and create a connection pool.

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";
import * as postgres from "https://deno.land/x/postgres@v0.14.0/mod.ts";

// Get the connection string from the environment variable "DATABASE_URL"
const databaseUrl = Deno.env.get("DATABASE_URL")!;

// Create a database pool with three connections that are lazily established
const pool = new postgres.Pool(databaseUrl, 3, true);
```

Again, you can save this code now, but this time you should see no changes. We
are creating a connection pool, but we are not actually running any queries
against the database yet. Before we can do that, we need to set up our table
schema.

We want to store a list of todos. Let's create a table called `todos` with an
auto-increment `id` column and a `title` column:

```ts
const pool = new postgres.Pool(databaseUrl, 3, true);

// Connect to the database
const connection = await pool.connect();
try {
  // Create the table
  await connection.queryObject`
    CREATE TABLE IF NOT EXISTS todos (
      id SERIAL PRIMARY KEY,
      title TEXT NOT NULL
    )
  `;
} finally {
  // Release the connection back into the pool
  connection.release();
}
```

Now that we have a table, we can add the HTTP handlers for the GET and POST
endpoints.

```ts
serve(async (req) => {
  // Parse the URL and check that the requested endpoint is /todos. If it is
  // not, return a 404 response.
  const url = new URL(req.url);
  if (url.pathname !== "/todos") {
    return new Response("Not Found", { status: 404 });
  }

  // Grab a connection from the database pool
  const connection = await pool.connect();

  try {
    switch (req.method) {
      case "GET": { // This is a GET request. Return a list of all todos.
        // Run the query
        const result = await connection.queryObject`
          SELECT * FROM todos
        `;

        // Encode the result as JSON
        const body = JSON.stringify(result.rows, null, 2);

        // Return the result as JSON
        return new Response(body, {
          headers: { "content-type": "application/json" },
        });
      }
      case "POST": { // This is a POST request. Create a new todo.
        // Parse the request body as JSON. If the request body fails to parse,
        // is not a string, or is longer than 256 chars, return a 400 response.
        const title = await req.json().catch(() => null);
        if (typeof title !== "string" || title.length > 256) {
          return new Response("Bad Request", { status: 400 });
        }

        // Insert the new todo into the database
        await connection.queryObject`
          INSERT INTO todos (title) VALUES (${title})
        `;

        // Return a 201 Created response
        return new Response("", { status: 201 });
      }
      default: // If this is neither a POST, or a GET return a 405 response.
        return new Response("Method Not Allowed", { status: 405 });
    }
  } catch (err) {
    console.error(err);
    // If an error occurs, return a 500 response
    return new Response(`Internal Server Error\n\n${err.message}`, {
      status: 500,
    });
  } finally {
    // Release the connection back into the pool
    connection.release();
  }
});
```

And there we go - application done. Deploy this code by saving the editor. You
can now POST to the `/todos` endpoint to create a new todo, and you can get a
list of all todos by making a GET request to `/todos`:

```sh
$ curl -X GET https://tutorial-postgres.deno.dev/todos
[]⏎

$ curl -X POST -d '"Buy milk"' https://tutorial-postgres.deno.dev/todos

$ curl -X GET https://tutorial-postgres.deno.dev/todos
[
  {
    "id": 1,
    "title": "Buy milk"
  }
]⏎
```

It's all working 🎉

The full code for the tutorial:

<iframe width="100%" height="600" src="https://embed.deno.com/playground/tutorial-postgres?layout=code-only&corp"></iframe>

As an extra challenge, try add a `DELETE /todos/:id` endpoint to delete a todo.
The [URLPattern][urlpattern] API can help with this.

[urlpattern]: https://developer.mozilla.org/en-US/docs/Web/API/URL_Pattern_API



/. 🚀 deploy/tutorials/tutorial-wordpress-frontend.md
===================================================

# Use Wordpress as a headless CMS

Wordpress is the most popular CMS in the world, but is difficult to use in a
"headless" form, i.e. with a custom frontend.

In this tutorial, we show how to use Fresh, a modern web framework built on
Deno, to create a frontend for headless Wordpress.

## **Step 1:** Clone the Fresh Wordpress theme

Fresh offers two ready-to-go themes, one for a blog and one for shopfront.

**Blog**

```
git clone https://github.com/denoland/fresh-wordpress-themes.git
cd fresh-wordpress-themes/blog
deno task docker
```

**Shop**

```sh
git clone https://github.com/denoland/fresh-wordpress-themes.git
cd fresh-wordpress-themes/corporate
deno task docker
```

Note that Blog and Shop themes use different setups for WordPress server. Make
sure you run `deno task docker` command in the right directory.

## **Step 2:** Open another terminal in the same directory and run:

```sh
deno task start
```

## **Step 3:** Visit http://localhost:8000/

You can manage the contents of the site via the WordPress dashboard at
http://localhost/wp-admin (username: `user`, password: `password`).

## WordPress hosting options

There are a lot of options for hosting WordPress on the internet. Many cloud
providers
[have](https://aws.amazon.com/getting-sstarted/hands-on/launch-a-wordpress-website/)
[special](https://cloud.google.com/wordpress)
[guides](https://learn.microsoft.com/en-us/azure/app-service/quickstart-wordpress)
and
[templates](https://console.cloud.google.com/marketplace/product/click-to-deploy-images/wordpress)
dedicated to WordPress. There are also dedicated hosting services for WordPress,
such as [Bluehost](https://www.bluehost.com/),
[DreamHost](https://www.dreamhost.com/),
[SiteGround](https://www.siteground.com/), etc. You can choose which is the best
fit for your needs from these options.

There are also many resources on the internet about how to scale your WordPress
instances.



/. 🚀 deploy/tutorials/vite.md
===================================================

    curl -s -L https://docs.deno.com/deploy/tutorials/vite | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'


# Deploy a React app with Vite

This tutorial covers how to deploy a Vite Deno and React app on Deno Deploy.

## **Step 1:** Create Vite app

Let's use [Vite](https://vitejs.dev/) to quickly scaffold a Deno and React app:

```sh
deno run --allow-read --allow-write --allow-env npm:create-vite-extra@latest
```

We'll name our project `vite-project`. Be sure to select `deno-react` in the
project configuration.

Then, `cd` into the newly created project folder.

## **Step 2:** Build repo

```sh
deno task build
```

## **Step 3:** Create a new Deno project

Navigate to https://dash.deno.com/new and click the **+Empty Project** button
under **Deploy from command line**.

On the next page, grab the project name, in this case `late-goose-47`.

## **Step 4:** Deploy the static site to Deno Deploy

There are a couple of ways you can deploy the Vite site to Deno Deploy.

### Github integration

The first way is via the Github integration.

Recall that the Github integration has two modes:

- **Automatic**: Deno Deploy will automatically pull code and assets from your
  repository source every time you push and deploy it. This mode is very fast
  but does not allow for a build step.
- **GitHub Actions**: In this mode, you push your code and assets to Deno Deploy
  from a GitHub Actions workflow. This allows you to perform a build step before
  deploying.

Since there is a build step here, you will need to use the Github Actions mode.

1. Navigate to `<project-name>` project page and select `vite-project` under the
   **Git integration** card.

   ![vite-project](https://docs.deno.com/assets/images/vite-project-d80b8b3e14eab76faa2dc4cdca6be9cd.png)
   <!-- ![vite-project](../docs-images/vite-project.png) -->

2. Select your branch for the production branch, and in the popup that appears,
   select **Github Action**

   ![vite-branch](https://docs.deno.com/assets/images/vite-branch-ffca7d7203482c08caa0dce59e1a45cb.png)
   <!-- ![vite-branch](../docs-images/vite-branch.png) -->

3. Click **Ok**

   ![vite-ok](https://docs.deno.com/assets/images/vite-ok-14b1f5190ac0b874c6e5fabb91cc0214.png)
   <!-- ![vite-ok](../docs-images/vite-ok.png) -->

4. Click **Link**

   ![vite-link](https://docs.deno.com/assets/images/vite-link-21fecbb428609b562bbfbd02d3bdb66e.png)
   <!-- ![vite-link](../docs-images/vite-link.png) -->

5. This should take you to the next page, where you will see a preview of a
   `deploy.yml` file that you can download. Download the file and add it to your
   `vite-project` under `.github/workflows/deploy.yml`

   ![vite-deploy-yaml](https://docs.deno.com/assets/images/vite-deploy-yaml-dbf95bd1e5d32fa2d681e1b836891a8c.png)
   <!-- ![vite-deploy-yaml](../docs-images/vite-deploy-yaml.png) -->

6. Modify the `deploy.yml` file so that it looks like this:

   ```
   name: Deploy
   on: [push]

   jobs:
   deploy:
       name: Deploy
       runs-on: ubuntu-latest
       permissions:
       id-token: write # Needed for auth with Deno Deploy
       contents: read # Needed to clone the repository

       steps:
       - name: Clone repository
           uses: actions/checkout@v3

       - name: Install Deno
           uses: denoland/setup-deno@v1

       - name: Build
           run: deno task build

       - name: Deploy to Deno Deploy
           uses: denoland/deployctl@v1
           with:
           project: "<project-name>"
           entrypoint: https://deno.land/std@$STD_VERSION/http/file_server.ts
           root: dist
   ```

   For this example there are two build steps:

   - setting up Deno
   - running `deno task build`

   You will also have to set the entrypoint file to
   `https://deno.land/std@$STD_VERSION/http/file_server.ts`, and the root to
   `/dist`.

   Note that this is not a file that exists in the Vite repo itself. Instead, it
   is an external program. When run, this program uploads all the static asset
   files in your current repo (`vite-project/dist`) to Deno Deploy. Then when
   you navigate to the deployment URL, it serves up the local directory.

   Once the `deploy.yml` file has been pushed to your Github repo, every time
   code is pushed to the Github repo, it will also be pushed to Deno Deploy,
   with the build step run first.

### `deployctl`

Alternatively, you can use `deployctl` directly to deploy `vite-project` to Deno
Deploy.

```
cd /dist
deployctl deploy --project=<project-name> https://deno.land/std@$STD_VERSION/http/file_server.ts
```



/. 🚀 deploy/manual/index.mdx
===================================================

---
displayed_sidebar: deployGuideHome
---

    curl -s -L https://docs.deno.com/deploy/manual | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

* https://docs.deno.com/deploy/manual
* https://docs.deno.com/deploy/tutorials

# Deno Deploy Quick Start

Deno Deploy is a globally distributed platform for serverless JavaScript
applications. Your JavaScript, TypeScript, and WebAssembly code runs on managed
servers geographically close to your users, enabling low latency and faster
response times. Deploy applications run on fast, light-weight
[V8 isolates](https://deno.com/blog/anatomy-isolate-cloud) rather than virtual
machines, powered by the [Deno runtime](/runtime/manual).

Let's deploy your first application - it should only take a few minutes.

## Option 1: Start with a template

If you'd like to start out by deploying a pre-built template application, simply
[log in to the Deno Deploy dashboard](https://dash.deno.com) and click the "New
Project" button. You can choose to deploy a starter web application using
[Fresh](https://fresh.deno.dev) or any of our supported web frameworks.

## Option 2: Start with an existing app

If you already have a Deno project hosted on GitHub, you can immediately import
it in Deno Deploy. [From the Deno Deploy dashboard](https://dash.deno.com),
click the "New Project" button and choose the option to "Select a repository".
Follow the on-screen instructions to deploy your existing application.

## Option 3: Start with a playground

A [playground](./playgrounds.md) is a browser-based editor that enables you to
write and run JavaScript code right away. This is a great choice for just
kicking the tires on Deno and Deno Deploy!
[From the Deno Deploy dashboard](https://dash.deno.com), click the "New Project"
button and choose any of the options with a "Try with a playground" button.

## Option 4: Start from scratch

If you'd like to develop and deploy a simple application locally, follow these
instructions to get started. We'll use the [`deployctl`](./deployctl.md) command
line utility to deploy a local Deno script from your computer.

### Install Deno and `deployctl`

If you haven't already, you can 
[install the Deno runtime](/runtime/manual/getting_started/installation) 
using one of the commands below:

import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';

<Tabs groupId="operating-systems">
  <TabItem value="mac" label="macOS" default>

```sh
curl -fsSL https://deno.land/x/install/install.sh | sh
```

</TabItem>
  <TabItem  value="windows" label="Windows">

```powershell
irm https://deno.land/install.ps1 | iex
```

</TabItem>
  <TabItem value="linux" label="Linux">

```sh
curl -fsSL https://deno.land/x/install/install.sh | sh
```

</TabItem>
</Tabs>

After Deno is installed, install the [`deployctl`](./deployctl.md) utility:

```
deno install -A --no-check -r -f https://deno.land/x/deploy/deployctl.ts
```

You can confirm `deployctl` has been installed correctly by running:

```
deployctl --help
```

Now, you're ready to deploy a Deno script from the command line!

### Write and test a Deno program

Create a file called `server.ts` in your terminal, and include the following
"Hello World" web server:

```ts title="server.ts"
Deno.serve(() => new Response("Hello, world!"));
```

You can test that it works by running it with the command below:

```
deno run --allow-net server.ts
```

Your server should be viewable at [localhost:8000](http://localhost:8000). 
Now let's run this code on the edge with Deno Deploy!

### Sign up for Deno Deploy and create a blank project

If you haven't already, now is the time to 
[sign up for a Deno Deploy account](https://dash.deno.com). After signing up,
[click the "New Project" button here](https://dash.deno.com). Near the top of
the page, you'll see an option to "create a blank project" - choose that option
now, as we will need one of these projects to complete our deployment process.

![create a blank project](https://docs.deno.com/assets/images/blank_project-69d0c9382b131412f0aec4d0d88cbda2.png)
<!-- ![create a blank project](../docs-images/blank_project.png) -->

After creating the project, make a note of the name that's generated for you - 
you'll need this project name when deploying from the command line.

![project name](https://docs.deno.com/assets/images/project_name-052fe09eeaaa1ce857f525d5140d8648.png)
<!-- ![project name](../docs-images/project_name.png) -->

In this example, the project name is `deep-zebra-47` - we'll use this as an
example name in the commands below.

### Create and export a Deploy access token

In order to use `deployctl` to control your Deno Deploy account from the 
command line, you'll need an access token.

This token 
[can be found in the dashboard here](https://dash.deno.com/account#access-tokens).
Click "New Access Token", give the token a name, and copy your newly minted token
to a secure location on your computer.

In your terminal, you'll need to export this token as a system environment
variable that can be used by `deployctl`. 

<Tabs groupId="shells">
<TabItem value="bash" label="macOS / Linux" default>

```sh
export DENO_DEPLOY_TOKEN=your_access_token_here
```

</TabItem>

<TabItem  value="powershell" label=" Windows (PowerShell)">

```powershell
$env:DENO_DEPLOY_TOKEN = 'your_access_token_here'
```

</TabItem>
</Tabs>

### Deploy!

Now that you have a project created and an access token created, you're ready
to deploy your application. In the same directory as the `server.ts` file you
created before, run this command:

```sh
deployctl deploy --project=deep-zebra-47 --prod server.ts
```

In a few moments, your Hello World server will be deployed across ~30 data 
centers around the world, ready to handle large volumes of traffic.

## Next Steps

Now that you've created your first project, you can 
[check out the kinds of apps](./use-cases.md) you can run on Deploy. You could 
also skip right to [setting up your own custom domain](./custom-domains.md).
We're so excited to see what you'll ship with Deploy!



/. 🚀 deploy/manual/ci_github.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/ci_github | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# CI and GitHub Actions

Deno Deploy's Git integration enables deployment of code changes that are pushed
to a GitHub repository. Commits on the production branch will be deployed as a
production deployment. Commits on all other branches will be deployed as a
preview deployment.

There are two modes of operation for the Git integration:

1. Select your organization name, and repository. _If your repository or
   organization does not show up, make sure the [Deno Deploy GitHub App][ghapp]
   is installed on your repository._
2. Select a production branch. Code deployed from this branch will be deployed
   as a production deployment instead of a preview deployment.
3. Choose either **Automatic** or **GitHub Actions** deployment mode.
   - **Automatic**: Deno Deploy will automatically pull code and assets from
     your repository source every time you push, and deploy it. This mode is
     very fast, but does not allow for a build step. _This is the recommended
     mode for most users._
   - **GitHub Actions**: In this mode, you push your code and assets to Deno
     Deploy from a GitHub Actions workflow. This allows you to perform a build
     step before deploying. Below, we go into more detail about the different
     configurations for **Automatic** and **Github Actions** mode.

## Automatic

If you select **Automatic** mode above, you'll subsequently have to select a
file in your Github repo as the "entrypoint" file. The entry file is simply the
file that Deno will run.

## GitHub Action

**GitHub Action** mode enables you to add a build step to your deployment
process by leveraging the `deployctl` [Github action][deploy-action]:

1. Navigate to `<project-name>` project page and select your Github repo under
   the **Git integration** card.

   ![vite-project](https://docs.deno.com/assets/images/vite-project-d80b8b3e14eab76faa2dc4cdca6be9cd.png)
   <!-- ![vite-project](../docs-images/vite-project.png) -->

2. Select your branch for the production branch, and in the popup that appears,
   select **Github Action**

   ![vite-branch](https://docs.deno.com/assets/images/vite-branch-ffca7d7203482c08caa0dce59e1a45cb.png)
   <!-- ![vite-branch](../docs-images/vite-branch.png) -->

3. Click **Ok**

   ![vite-ok](https://docs.deno.com/assets/images/vite-ok-14b1f5190ac0b874c6e5fabb91cc0214.png)
   <!-- ![vite-ok](../docs-images/vite-ok.png) -->

4. Click **Link**

   ![vite-link](https://docs.deno.com/assets/images/vite-link-21fecbb428609b562bbfbd02d3bdb66e.png)
   <!-- ![vite-link](../docs-images/vite-link.png) -->

5. This should take you to a next page, where you see a preview of a
   `deploy.yml` file that you can download. Download the file and add it to your
   Github project under `.github/workflows/deploy.yml`

   ![vite-deploy-yaml](https://docs.deno.com/assets/images/vite-deploy-yaml-dbf95bd1e5d32fa2d681e1b836891a8c.png)
   <!-- ![vite-deploy-yaml](../docs-images/vite-deploy-yaml.png) -->

6. Modify the `deploy.yml` file as appropriate with your build step, Deno
   project name, and entrypoint file:

   ```yml
   job:
   permissions:
       id-token: write # This is required to allow the GitHub Action to authenticate with Deno Deploy.
       contents: read
   steps:
       - name: Deploy to Deno Deploy
       uses: denoland/deployctl@v1
       with:
           project: my-project # the name of the project on Deno Deploy
           entrypoint: main.ts # the entrypoint to deploy
   ```

   By default the entire contents of the repository will be deployed. This can
   be changed by specifying the `root` option.

   ```yml
   - name: Deploy to Deno Deploy
   uses: denoland/deployctl@v1
   with:
       project: my-project
       entrypoint: index.js
       root: dist
   ```

   The `entrypoint` can either be a relative path, file name, or an absolute
   URL. If it is a relative path, it will be resolved relative to the `root`.
   Both absolute `file:///` and `https://` URLs are supported.

   To deploy the `./dist` directory using the
   [std/http/file_server.ts][fileserver] module, you can use the following
   configuration:

   ```yml
   - name: Deploy to Deno Deploy
   uses: denoland/deployctl@v1
   with:
       project: my-project
       entrypoint: https://deno.land/std@$STD_VERSION/http/file_server.ts
       root: dist
   ```

   See
   [deployctl README](https://github.com/denoland/deployctl/blob/main/action/README.md)
   for more details.

[fileserver]: https://deno.land/std/http/file_server.ts
[ghapp]: https://github.com/apps/deno-deploy
[deploy-action]: https://github.com/denoland/deployctl/blob/main/action/README.md



/. 🚀 deploy/manual/custom-domains.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/custom-domains | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Custom domains

By default a project can be reached at its preview URL, which is
`$PROJECT_ID.deno.dev`, e.g. `dead-clam-55.deno.dev`. You can also add a custom
domain by following the instructions below.

## **Step 1:** Add your custom domain in the Deno Deploy dashboard

1. Click the "Settings" button on the project page, then select "Domains" from
   the sidebar.
2. Enter the domain name you wish to add to the project and press "Add." Note
   that you must own the domain that you want to add to a project. If you do not
   own a domain yet, you can register one at a domain registrar like Google
   Domains, Namecheap, or gandi.net.
   ![add_custom_domain](https://docs.deno.com/assets/images/add_custom_domain-b26c6ba7030a2a7775dadae408ca6fec.png)
   <!-- ![add_custom_domain](../docs-images/add_custom_domain.png) -->

3. The domain is added to the domains list and will have a "setup" badge.
4. Click on the "setup" badge to visit the domain setup page, which will display
   the list of DNS records that need to be created/updated for your domain.
   ![dns_records_modal](https://docs.deno.com/assets/images/dns_records_modal-02b7159983498b4a603cf1a6924ac293.png)
   <!-- ![dns_records_modal](../docs-images/dns_records_modal.png) -->

## **Step 2:** Update your custom domain's DNS records

Go to the DNS configuration panel of your domain registrar (or the service
you're using to manage DNS) and enter the records as described on the domain
setup page.

![change_dns_records](https://docs.deno.com/assets/images/change_dns_records-a9854a0c0cf358ee6e8921a95a5ac7ff.png)
<!-- ![change_dns_records](../docs-images/change_dns_records.png) -->

## **Step 3:** Validate that the DNS records have been updated

Go back to the Deno Deploy dashboard and click the **Validate** button on the
domain setup page. It will check if the DNS records are correctly set and if so,
update the status to "Validated, awaiting certificate provisioning."

![get_certificates](https://docs.deno.com/assets/images/get_certificates-8a46948663d5965a55861480c90c447d.png)
<!-- ![get_certificates](../docs-images/get_certificates.png) -->

## **Step 4:** Provision a certificate for your custom domain

At this point you have two options. 99% of the time, you should choose the first
option.

1. Let us automatically provision a certificate using Let's Encrypt.

   To do this, press the **Get automatic certificates** button. Provisioning a
   TLS certificate can take up to a minute. It is possible that the provisioning
   fails if your domain specifies a CAA record that prevents
   [Let's Encrypt](https://letsencrypt.org/) from provisioning certificates.
   Certificates will be automatically renewed around 30 days before the
   certificate expires. When you have been issued certificates successfully, you
   will see a green checkmark like this:

   ![green_check](https://docs.deno.com/assets/images/green_check-cdefc7272688c99ed83f62dcdf6f4bc8.png)
   <!-- ![green_check](../docs-images/green_check.png) -->

2. Manually upload a certificate and private key.

   To manually upload a certificate chain and private key, press the **Upload
   your own certificates** button. You will be prompted to upload a certificate
   chain and private key. The certificate chain needs to be complete and valid,
   and your leaf certificate needs to be at the top of the chain.



/. 🚀 deploy/manual/deployctl.md
===================================================

# Using deployctl on the command line

`deployctl` is a command line tool (CLI) that lets you work with the Deno Deploy
platform.

## Install `deployctl`

You can install the `deployctl` command with the below command:

    deno install --allow-all --no-check -r -f https://deno.land/x/deploy/deployctl.ts

You also need to set the `DENO_DEPLOY_TOKEN` environment variable to your
personal access token. You can generate your Personal Access Token in
https://dash.deno.com/account#access-tokens.

## Usage

To deploy a local script:

    deployctl deploy --project=helloworld main.ts

To deploy a remote script:

    deployctl deploy --project=helloworld https://deno.com/examples/hello.js

To deploy a remote script without static files:

    deployctl deploy --project=helloworld --no-static https://deno.com/examples/hello.js

To ignore the node_modules directory while deploying:

    deployctl deploy --project=helloworld --exclude=node_modules main.tsx

See the help message (`deployctl -h`) for more details.

## `deno` CLI and local development

For local development you can use the `deno` CLI. To install `deno`, follow the
instructions in the
[Deno manual](https://deno.land/manual/getting_started/installation).

After installation, you can run your scripts locally:

```shell
$ deno run --allow-net=:8000 https://deno.com/examples/hello.js
Listening on http://localhost:8000
```

To watch for file changes add the `--watch` flag:

```shell
$ deno run --allow-net=:8000 --watch ./main.js
Listening on http://localhost:8000
```

For more information about the Deno CLI, and how to configure your development
environment and IDE, visit the Deno Manual's [Getting Started][manual-gs]
section.

[manual-gs]: https://deno.land/manual/getting_started



/. 🚀 deploy/manual/deployments.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/deployments | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Deployments

A deployment is a snapshot of all code and environment variables required to run
an application. Deployments are immutable after they have been created. To
deploy a new version of the code for an application, a new deployment must be
created.

## Custom domains

There can also be other URLs that can point to a deployment, like
[custom domains](custom-domains).

## Branch domains

`<projectname--branchname>.deno.dev` is also supported.

## Production vs. preview deployments

All deployments have a preview URL that can be used to view this specific
deployment. Preview URLs have the format
`{project_name}-{deployment_id}.deno.dev`.

![image](https://docs.deno.com/assets/images/preview_deployment-ab5f4d8ed88cde4b79d19ea7ca58de31.png)
<!-- ![image](../docs-images/preview_deployment.png) -->

A deployment can either be a production or a preview deployment. These
deployments do not have any differences in runtime functionality. The only
distinguishing factor is that a project's production deployment will receive
traffic from the project URL (e.g. `myproject.deno.dev`), and from custom
domains in addition to traffic to the deployment's preview URL.

## Promoting preview deployments to production deployments via Deno Deploy UI

Preview deployments can be "promoted" to production via the Deno Deploy UI:

1. Navigate to the project page.
2. Click on the **Deployments** tab.
3. Click on the three dots next to the deployment you want to promote to
   production and select **Promote to Production**
   ![promote_to_production](https://docs.deno.com/assets/images/promote_to_production-580599cc71054eae72773289200de72b.png)
   <!-- ![promote_to_production](../docs-images/promote_to_production.png) -->

## Creating production deployments via `deployctl`

If you are deploying your Deno code with `deployctl`, you can deploy to
production with the `--prod` flag:

```sh
deployctl deploy --prod --project=helloworld main.ts
```



/. 🚀 deploy/manual/dynamodb.md
===================================================

# Connect to DynamoDB

Amazon DynamoDB is a fully managed NoSQL database. To persist data to DynamoDB,
follow the steps below:

The tutorial assumes that you have an AWS and Deno Deploy account.

You can find a more comprehensive tutorial that builds a sample application on
top of DynamoDB [here](../tutorials/tutorial-dynamodb).

## Gather credentials from DynamoDB

The first step in the process is to generate AWS credentials to programmatically
access DynamoDB.

Generate Credentials:

1. Go to https://console.aws.amazon.com/iam/ and go to the "Users" section.
2. Click on the **Add user** button, fill the **User name** field (maybe use
   `denamo`), and select **Programmatic access** type.
3. Click on **Next: Permissions**, then on **Attach existing policies
   directly**, search for `AmazonDynamoDBFullAccess` and select it.
4. Click on **Next: Tags**, then on **Next: Review** and finally **Create
   user**.
5. Click on **Download .csv** button to download the credentials.

## Create a project in Deno Deploy

Next, let's create a project in Deno Deploy and set it up with the requisite
environment variables:

1. Go to [https://dash.deno.com/new](https://dash.deno.com/new) (Sign in with
   GitHub if you didn't already) and click on **+ Empty Project** under **Deploy
   from the command line**.
2. Now click on the **Settings** button available on the project page.
3. Navigate to **Environment Variables** Section and add the following secrets.

- `AWS_ACCESS_KEY_ID` - Use the value that's available under **Access key ID**
  column in the downloaded CSV.
- `AWS_SECRET_ACCESS_KEY` - Use the value that's available under **Secret access
  key** column in the downloaded CSV.

## Write code that connects to DynamoDB

AWS has an
[official SDK](https://www.npmjs.com/package/@aws-sdk/client-dynamodb) that
works with browsers. As most Deno Deploy's APIs are similar to browsers', the
same SDK works with Deno Deploy. To use the SDK in Deno, import from a cdn like
below and create a client:

```js
import {
  DynamoDBClient,
  GetItemCommand,
  PutItemCommand,
} from "https://cdn.skypack.dev/@aws-sdk/client-dynamodb?dts";

// Create a client instance by providing your region information.
// The credentials are automatically obtained from environment variables which
// we set during our project creation step on Deno Deploy, so we don't have to
// pass them manually here.
const client = new ApiFactory().makeNew(DynamoDB);

serve({
  "/songs": handleRequest,
});

async function handleRequest(request) {
  // async/await.
  try {
    const data = await client.send(command);
    // process data.
  } catch (error) {
    // error handling.
  } finally {
    // finally.
  }
}
```

## Deploy application to Deno Deploy

Once you have finished writing your application, you can deploy it on Deno
Deploy.

To do this, go back to your project page at
`https://dash.deno.com/projects/<project-name>`.

You should see a couple of options to deploy:

- [Github integration](ci_github)
- [`deployctl`](deployctl)
  ```sh
  deployctl deploy --project=<project-name> <application-file-name>
  ```

Unless you want to add a build step, we recommend that you select the Github
integration.

For more details on the different ways to deploy on Deno Deploy and the
different configuration options, read [here](how-to-deploy).



/. 🚀 deploy/manual/environment-variables.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/environment-variables | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Environment variables

Environment variables are useful to store values like access tokens of web
services. You can create them in the project dashboard and access them in your
code via the `Deno.env` API. They are made available to both production and
preview deployments.

## Add an environment variable

To add an environment variable to your project, click on the **Settings** button
on the project page and then on **Environment Variables** from the sidebar. Fill
in the key/value fields and click on "Add" to add an environment variable to
your project. A new production deployment will be created automatically with the
new environment variables.

![environment_variable](https://docs.deno.com/assets/images/fauna2-59afc87c29e58f04371b123359ae5378.png)
<!-- ![environment_variable](../docs-images/fauna2.png) -->

Note that currently, this is the only way to add an environment variable. Even
if you deployed with `deployctl` or the Github integration, to add environment
variables, you must do so from the project page UI.

### Preset Variables

Every deployment has the following environment variables preset, which you can
access from your code.

1. `DENO_REGION`

   It holds the region code of the region in which the deployment is running.
   You can use this variable to serve region-specific content.

   You can refer to the region code from the [regions page](regions).

1. `DENO_DEPLOYMENT_ID`

   It holds the ID of the deployment.



/. 🚀 deploy/manual/fair-use-policy.md
===================================================

# Fair use policy

The public beta for the Deno Deploy service includes resources (CPU time,
request counts) that are subject to this Fair Use policy. This document can give
a rough estimate to what we consider as "Fair Use", and what we do not.

### Examples of Fair Use

- ✅ Server-side rendered websites
- ✅ Jamstack sites and apps
- ✅ Single page applications
- ✅ APIs that query a DB or external API
- ✅ A personal blog
- ✅ A company website
- ✅ An e-commerce site

### Not Fair Use

- ❌ Crypto mining
- ❌ Highly CPU-intensive load (e.g. machine learning)
- ❌ Media hosting for external sites
- ❌ Scrapers
- ❌ Proxy or VPN

## Guidelines

We expect most projects to fall well within the usage limits. We will notify you
if your projects usage significantly deviates from the norm. We will reach out
to you where possible before taking any action to address unreasonable burdens
on our infrastructure.



/. 🚀 deploy/manual/faunadb.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/faunadb | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Connect to FaunaDB

FaunaDB calls itself "the data API for modern applications." It's a database
with a GraphQL interface that enables you to use GraphQL to interact with it.
Since you communicate with it using HTTP requests, you don't need to manage
connections, which works well for serverless applications.

This tutorial covers how to connect to a Fauna database from an application
deployed on Deno Deploy.

You can find a more comprehensive tutorial that builds a sample application on
top of Fauna [here](../tutorials/tutorial-faunadb).

## Get credentials from Fauna

We assume that you've already created a Fauna instance at
https://dashboard.fauna.com.

To access your Fauna database programmatically, you'll need to generate a
credential:

1. Click on **Security** section inside your particular database and click on
   **New Key**. ![fauna1](https://docs.deno.com/assets/images/fauna1-dfbbafe0fc532faf83e6f68b2f11ae67.png)
   <!-- **New Key**. ![fauna1](../docs-images/fauna1.png) -->

2. Select **Server** role and click on **Save**. Copy the secret. You'll need it
   for the next step.

## Create a project in Deno Deploy

Next, let's create a project on Deno Deploy and set it up with the requisite
environment variables:

1. Go to [https://dash.deno.com/new](https://dash.deno.com/new) (Sign in with
   GitHub if you didn't already) and click on **+ Empty Project** under **Deploy
   from the command line**.
2. Now click on the **Settings** button available on the project page.
3. Navigate to the **Environment Variables** section and add the following
   secrets.

- `FAUNA_SECRET` - The value should be the secret we created in the previous
  step. ![fauna2](https://docs.deno.com/assets/images/fauna2-59afc87c29e58f04371b123359ae5378.png)
  <!-- step. ![fauna2](../docs-images/fauna2.png) -->

## Write code that connects to Fauna

While with Node there is a Fauna JavaScript driver, with Deno, you should use
the graphql endpoint.

Fauna has a graphql endpoint for its database, and it generates essential
mutations like `create`, `update`, `delete` for a data type defined in the
schema. For example, Fauna will generate a mutation named `createQuote` to
create a new quote in the database for the data type `Quote`.

To interact with Fauna, we need to make a POST request to its graphql endpoint
with appropriate query and parameters to get the data in return. So let's
construct a generic function that will handle those things.

```javascript
import query from "https://esm.sh/faunadb@4.7.1";
import Client from "https://esm.sh/faunadb@4.7.1";

// Grab the secret from the environment.
const token = Deno.env.get("FAUNA_SECRET");
if (!token) {
  throw new Error("environment variable FAUNA_SECRET not set");
}

var client = new Client.Client({
  secret: token,
  // Adjust the endpoint if you are using Region Groups
  endpoint: "https://db.fauna.com/",
});
// HEAD
client.query(query.ToDate("2018-06-06"));
//
client
  .query(query.ToDate("2018-06-06"))
  //1e2f378 (Add some more pages)
  .then(function (res) {
    console.log("Result:", res);
  })
  .catch(function (err) {
    console.log("Error:", err);
  });
```

## Deploy application to Deno Deploy

Once you have finished writing your application, you can deploy it on Deno
Deploy.

To do this, go back to your project page at
`https://dash.deno.com/projects/<project-name>`.

You should see a couple options to deploy:

- [Github integration](ci_github)
- [`deployctl`](deployctl)
  ```sh
  deployctl deploy --project=<project-name> <application-file-name>
  ```

Unless you want to add a build step, we recommend that you select the Github
integration.

For more details on the different ways to deploy on Deno Deploy and the
different configuration options, read [here](how-to-deploy).



/. 🚀 deploy/manual/firebase.md
===================================================

# Connect to Firebase

Firebase is a platform developed by Google for creating mobile and web
applications. Its features include authentication primitives for log in and a
NoSQL datasore, Firestore, that you can persist data to.

This tutorial covers how to connect to Firebase from an application deployed on
Deno Deploy.

You can find a more comprehensive tutorial that builds a sample application on
top of Firebase [here](../tutorials/tutorial-firebase).

## Get credentials from Firebase

> This tutorial assumes that you've already created a project in Firebase and
> added a web application to your project.

1. Navigate to your project in Firebase and click on **Project Settings**
2. Scroll down until you see a card with your app name, and a code sample that
   includes a `firebaseConfig`object. It should look something like the below.
   Keep this handy. We will use it later:

   ```js
   var firebaseConfig = {
     apiKey: "APIKEY",
     authDomain: "example-12345.firebaseapp.com",
     projectId: "example-12345",
     storageBucket: "example-12345.appspot.com",
     messagingSenderId: "1234567890",
     appId: "APPID",
   };
   ```

## Create a Project in Deno Deploy

1. Go to [https://dash.deno.com/new](https://dash.deno.com/new) (Sign in with
   GitHub if you didn't already) and click on **+ Empty Project** under **Deploy
   from the command line**.
2. Now click on the **Settings** button available on the project page.
3. Navigate to the **Environment Variables** section and add the following:

   <dl>
    <dt><code>FIREBASE_USERNAME</code></dt>
    <dd>The Firebase user (email address) that was added above.</dd>
    <dt><code>FIREBASE_PASSWORD</code></dt>
    <dd>The Firebase user password that was added above.</dd>
    <dt><code>FIREBASE_CONFIG</code></dt>
    <dd>The configuration of the Firebase application as a JSON string.</dd>
   </dl>

   The configuration needs to be a valid JSON string to be readable by the
   application. If the code snippet given when setting up looked like this:

   ```js
   var firebaseConfig = {
     apiKey: "APIKEY",
     authDomain: "example-12345.firebaseapp.com",
     projectId: "example-12345",
     storageBucket: "example-12345.appspot.com",
     messagingSenderId: "1234567890",
     appId: "APPID",
   };
   ```

   You would need to set the value of the string to this (noting that spacing
   and new lines are not required):

   ```json
   {
     "apiKey": "APIKEY",
     "authDomain": "example-12345.firebaseapp.com",
     "projectId": "example-12345",
     "storageBucket": "example-12345.appspot.com",
     "messagingSenderId": "1234567890",
     "appId": "APPID"
   }
   ```

## Write code that connects to Firebase

The first thing we will do is import the `XMLHttpRequest` polyfill that Firebase
needs to work under Deploy as well as a polyfill for `localStorage` to allow the
Firebase auth to persist logged in users:

```js
import "https://deno.land/x/xhr@0.1.1/mod.ts";
import { installGlobals } from "https://deno.land/x/virtualstorage@0.1.0/mod.ts";
installGlobals();
```

> ℹ️ we are using the current version of packages at the time of the writing of
> this tutorial. They may not be up-to-date and you may want to double check
> current versions.

Because Deploy has a lot of the web standard APIs, it is best to use the web
libraries for Firebase under deploy. Currently v9 is in still in beta for
Firebase, so we will use v8:

```js
import firebase from "https://esm.sh/firebase@9.17.0/app";
import "https://esm.sh/firebase@9.17.0/auth";
import "https://esm.sh/firebase@9.17.0/firestore";
```

Now we need to setup our Firebase application. We will be getting the
configuration from the environment variables we set up previously and get
references to the parts of Firebase we are going to use:

```js
const firebaseConfig = JSON.parse(Deno.env.get("FIREBASE_CONFIG"));
const firebaseApp = firebase.initializeApp(firebaseConfig, "example");
const auth = firebase.auth(firebaseApp);
const db = firebase.firestore(firebaseApp);
```

Ok, we are almost done. We just need to create our middleware application and
add the `localStorage` middleware we imported:

```js
const app = new Application();
app.use(virtualStorage());
```

And then we need to add middleware to authenticate the user. In this tutorial we
are simply grabbing the username and password from the environment variables we
will be setting up, but this could easily be adapted to redirect a user to a
sign-in page if they are not logged in:

```js
app.use(async (ctx, next) => {
  const signedInUid = ctx.cookies.get("LOGGED_IN_UID");
  const signedInUser = signedInUid != null ? users.get(signedInUid) : undefined;
  if (!signedInUid || !signedInUser || !auth.currentUser) {
    const creds = await auth.signInWithEmailAndPassword(
      Deno.env.get("FIREBASE_USERNAME"),
      Deno.env.get("FIREBASE_PASSWORD"),
    );
    const { user } = creds;
    if (user) {
      users.set(user.uid, user);
      ctx.cookies.set("LOGGED_IN_UID", user.uid);
    } else if (signedInUser && signedInUid.uid !== auth.currentUser?.uid) {
      await auth.updateCurrentUser(signedInUser);
    }
  }
  return next();
});
```

## Deploy the application to Deno Deploy

Once you have finished writing your application, you can deploy it on Deno
Deploy.

To do this, go back to your project page at
`https://dash.deno.com/projects/<project-name>`.

You should see a couple of options to deploy:

- [Github integration](ci_github)
- [`deployctl`](deployctl)
  ```sh
  deployctl deploy --project=<project-name> <application-file-name>
  ```

Unless you want to add a build step, we recommend that you select the Github
integration.

For more details on the different ways to deploy on Deno Deploy and the
different configuration options, read [here](how-to-deploy).



/. 🚀 deploy/manual/how-to-deploy.md
===================================================

# Deploy with GitHub integration

The simplest way to deploy more complex projects is via our Github integration.
This allows you to link a Deno Deploy project to a GitHub repository. Every time
you push to the repository, your changes will be automatically deployed.

Via the Github integration, you can add a Github Action that defines a build
step in your deployment process.

See [the Github integration page](ci_github) for more details.

### Deploy from command line with [`deployctl`](deployctl)

`deployctl` is a command line tool for deploying your code to Deno Deploy. You
can control more details of your deployment than the above automatic GitHub
integration by using `deployctl`.

See [the `deployctl` page](deployctl) for more details.

### Deploy with playground

The easiest way to deploy some code is via a Deno Deploy playground.

See the [playground page](playgrounds) for more details.



/. 🚀 deploy/manual/logs.md
===================================================

# Application logging

Applications can generate logs at runtime using the console API. These logs can
be viewed in real time by navigating to the `Logs` panel of a project or
deployment. Logs will be streamed directly from an application to the log panel.

Logs are retained for a period of 24 hours. To view persisted logs, switch from
`Live` to either `Recent` or `Custom` in the dropdown menu next to the search
box. Logs older than 24 hours are automatically deleted from the system.

Log messages have a maximum size of 2kb. Messages larger than this are trimmed
to 2kb.



/. 🚀 deploy/manual/middleware.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/middleware | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Reverse proxy middleware

This quickstart will cover how to deploy a small piece of middleware that
reverse proxies another server (in this case example.com). For additional
examples of common middleware functions, see the
[example gallery](https://www.deno.com/deploy/examples).

## **Step 1:** Create a new playground project on Deno Deploy

Navigate to https://dash.deno.com/new and click on the **Play** button in the
**Playground** card.

## **Step 2:** Deploy middleware code via playground

On the next page, copy and paste the code below into the editor. It is an HTTP
server that proxies all requests to https://example.com.

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/mod.ts";
async function reqHandler(req: Request) {
  const reqPath = new URL(req.url).pathname;
  return await fetch("https://example.com" + reqPath, { headers: req.headers });
}
serve(reqHandler, { port: 8000 });
```

Click **Save and Deploy**.

You should see something like this:

![image](https://docs.deno.com/assets/images/proxy_to_example-87d6aa1a577d2d2d8a7e2ca11060faa6.png)
<!-- ![image](../docs-images/proxy_to_example.png) -->



/. 🚀 deploy/manual/organizations.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/organizations | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Organizations

**Organizations** allow you to collaborate with other users. A project created
in an organization is accessible to all members of the organization. Users
should first signup for Deno Deploy before they can be added to an organization.

Currently, all organization members have full access to the organization. They
can add/remove members, and create/delete/modify all projects in the
organization.

### Create an organization

1. On your Deploy dashboard, click on the organization dropdown in the top left
   of the screen, in the navigation bar.
   ![organizations](https://docs.deno.com/assets/images/organizations-ee691dbf53042cbac7e8795e01b4d04f.png)
   <!-- ![organizations](../docs-images/organizations.png) -->
2. Select **Organization +**.
3. Enter a name for your organization and click on **Create**.

### Add members

1. Select the desired organization in the organization dropdown in the top left
   of the screen, in the navigation bar.
2. Click on the **Members** icon button.
3. Under the **Members** panel, click on **+ Invite member**.
   > **Note:** Users should first signup for Deno Deploy using
   > [this link](https://dash.deno.com/signin) before you invite them.
4. Enter the GitHub username of the user and click on **Invite**.

Deploy will send the user an invite email. They can then can either accept or
decline your invite. Once they accept the invite, they're added to your
organization and shown in the members panel.

Pending invites are displayed in the **Invites** panel. You can revoke pending
invites by clicking on the delete icon next to the pending invite.

### Remove members

1. Select the desired organization in the organization dropdown in the top left
   of the screen, in the navigation bar.
2. Click on the **Members** icon button.
3. In the **Members** panel, click on the delete button beside the user you want
   to remove.



/. 🚀 deploy/manual/playgrounds.md
===================================================

# Playgrounds

**Playgrounds** are an easy way to play around with Deno Deploy, and to create
small projects. Using playgrounds you can write code, run it, and see the output
fully inside the browser.

Playgrounds have the full power of Deno Deploy: they support all the same
features as a normal project, including environment variables, custom domains,
and logs.

Playgrounds are also just as performant as all other projects on Deno Deploy:
they make full use of our global network to run your code as close to users as
possible.

- [Creating a playground](#creating-a-playground)
- [Using the playground editor](#using-the-playground-editor)
- [Making a playground public](#making-a-playground-public)
- [Exporting a playground to GitHub](#exporting-a-playground-to-github)

## Creating a playground

To create a new playground press the **New Playground** button in the top right
corner of the [project overview page](https://dash.deno.com/projects).

This will create a new playground with a randomly generated name. You can change
this name in the project settings later.

## Using the playground editor

The playground editor is opened automatically when you create a new playground.
You can also open it by navigating to your project's overview page and clicking
the **Edit** button.

The editor consists of two main areas: the editor on the left, and the preview
panel on the right. The editor is where you write your code, and the preview
panel is where you can see the output of your code through a browser window.

There is also a logs panel underneath the editor panel on the left side. This
panel shows the console output of your code, and is useful for debugging your
code.

After editing your code, you need to save and deploy it so the preview on the
right updates. You can do this by clicking the **Save & Deploy** button in the
top right, by pressing <kbd>Ctrl</kbd> + <kbd>S</kbd>, or opening the command
palette with <kbd>F1</kbd> and selecting **Deploy: Save & Deploy**.

In the tool bar in the top right of the editor you can see the current
deployment status of your project while saving.

The preview panel on the right will refresh automatically every time you save
and deploy your code.

The language dropdown in the top right of the editor allows you to switch
between JavaScript, JSX, TypeScript, and TSX. The default selected language is
TSX which will work for most cases.

## Making a playground public

Playgrounds can be shared with other users by making them public. This means
that anyone can view the playground and its preview. Public playgrounds can not
be edited by anyone: they can still only be edited by you. Logs are also only
shown to you. Users have the option to fork a public playground to make a
private copy of it that they can edit.

To make a playground public, press the **Share** button in the top tool bar in
the editor. The URL to your playground will be copied to your clipboard
automatically.

You can also change the playground visibility from the playground settings page
in the Deno Deploy dashboard. This can be used to change the visibility of a
playground from public to private again.

## Exporting a playground to GitHub

Playgrounds can be exported to GitHub. This is useful if your project is
starting to outgrow the single file limit of the playground editor.

Doing this will create a new GitHub repository containing the playground code.
This project will be automatically turned into a git project that is linked to
this new GitHub repository. Environment variables and domains will be retained.

The new GitHub repository will be created in your personal account, and will be
set to private. You can change these settings later in the GitHub repository
settings.

After exporting a playground, you can no longer use the Deno Deploy playground
editor for this project. This is a one-way operation.

To export the playground visit the playground settings page in the Deno Deploy
dashboard or select **Deploy: Export to GitHub** from the command palette (press
<kbd>F1</kbd> in the editor).

Here you can enter a name for the new GitHub repository. This name will be used
to create the repository on GitHub. The repository must not already exist.

Press **Export** to export the playground to GitHub.



/. 🚀 deploy/manual/postgres.md
===================================================

    curl -s -L https://docs.deno.com/deploy/manual/postgres | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Connect to Postgres

This tutorial covers how to connect to a Postgres database from an application
deployed on Deno Deploy.

You can find a more comprehensive tutorial that builds a sample application on
top of Postgres [here](../tutorials/tutorial-postgres).

## Setup Postgres

> This tutorial will focus entirely on connecting to Postgres unencrypted. If
> you would like to use encryption with a custom CA certificate, use the
> documentation [here](https://deno-postgres.com/#/?id=ssltls-connection).

To get started, we need to create a new Postgres instance for us to connect to.
For this tutorial, we will be using [Supabase](https://supabase.com) as they
provide free, managed Postgres instances. If you like to host your database
somewhere else, you can do that too.

1. Visit https://app.supabase.io/ and click **New project**.
2. Select a name, password, and region for your database. Make sure to save the
   password, as you will need it later.
3. Click **Create new project**. Creating the project can take a while, so be
   patient.

## Gather credentials from Postgres

Once you've set up your Postgres database, gather your connection information
from your Postgres instance.

### Supabase

For the Supabase instance above, to get your connection information:

1. Navigate to the **Database** tab on the left.
2. Go to the **Project Settings** >> **Database** and copy the connection string
   from the **Connection String** >> **URI** field. This is the connection
   string you will use to connect to your database. Insert the password you
   saved earlier into this string, and then save the string somewhere - you will
   need it later.

### psql

If you are using psql, you should generally be able to find your connection
information by running:

```psql
test=# \conninfo
```

Your Postgres connection string will take the form:

```sh
postgres://user:password@127.0.0.1:5432/deploy?sslmode=disable
```

## Create a project in Deno Deploy

Next, let's create a project in Deno Deploy and set it up with the requisite
environment variables:

1. Go to [https://dash.deno.com/new](https://dash.deno.com/new) (Sign in with
   GitHub if you didn't already) and click on **+ Empty Project** under **Deploy
   from the command line**.
2. Now click on the **Settings** button available on the project page.
3. Navigate to **Environment Variables** Section and add the following secrets.

- `DATABASE_URL` - The value should be your connection string that you retrieved
  in the last step.

![postgres_env_variable](https://docs.deno.com/assets/images/postgres_env_variable-de2a82ddef8916007a7bb18f7774221d.png)
<!-- ![postgres_env_variable](../docs-images/postgres_env_variable.png) -->

## Write code that connects to Postgres

To read/write to Postgres, import the Postgres module, read the connection
string from the environment variables, and create a connection pool.

```ts
import { Pool } from "https://deno.land/x/postgres@v0.17.0/mod.ts";

// Get the connection string from the environment variable "DATABASE_URL"
const databaseUrl = Deno.env.get("DATABASE_URL")!;

// Create a database pool with three connections that are lazily established
const pool = new Pool(databaseUrl, 3, true);

// Connect to the database
const connection = await pool.connect();

try {
  // Create the table
  await connection.queryObject`
    CREATE TABLE IF NOT EXISTS todos (
      id SERIAL PRIMARY KEY,
      title TEXT NOT NULL
    )
  `;
} finally {
  // Release the connection back into the pool
  connection.release();
}
```

## Deploy application to Deno Deploy

Once you have finished writing your application, you can deploy it on Deno
Deploy.

To do this, go back to your project page at
`https://dash.deno.com/projects/<project-name>`.

You should see a couple of options to deploy:

- [Github integration](ci_github)
- [`deployctl`](deployctl)
  ```sh
  deployctl deploy --project=<project-name> <application-file-name>
  ```

Unless you want to add a build step, we recommend that you select the Github
integration.

For more details on the different ways to deploy on Deno Deploy and the
different configuration options, read [here](how-to-deploy).



/. 🚀 deploy/manual/pricing-and-limits.md
===================================================

# Pricing and limitations

Please see [our pricing page](https://www.deno.com/deploy/pricing) for the
overview of the available features in all plans. If you have a use case that
exceeds any of these limits, [please reach out](mailto:deploy@deno.com).

No uptime guarantees are provided during the initial public beta for Deno
Deploy. Access to the service will be controlled by
[our fair use policy](https://www.deno.com/deploy/fair-use-policy). Any user we
deem to be in violation of this policy, runs the risk of having their account
terminated.

## Maximum size for deployments

When uploading assets to a deployment, the total size of all files within the
deployment (source files and static files) __should not exceed 1 gigabyte__.

## TLS proxying

On the Free plan, TLS termination is required for outgoing connections to port
443 (the port used for HTTPS). Using
[Deno.connect](https://deno.land/api?s=Deno.connect) to connect to these ports
is prohibited. If you need to establish a TLS connection to port 443, please use
[Deno.connectTls](https://deno.land/api?s=Deno.connectTls) instead. `fetch` is
not impacted by this restriction.

This restriction is in place because connecting to port 443 without terminating
TLS is frequently used in TLS-over-TLS proxies, which are prohibited on the Deno
Deploy Free plan as per our Fair Use Policy.

This restriction impacts Free tier customers only. Pro tier customers are able
to connect to port 443 with both `Deno.connect` and `Deno.connectTls`.



/. 🚀 deploy/manual/privacy-policy.md
===================================================

# Deno Privacy Policy

Deno Land Inc is a corporation registered in Delaware, USA doing business as
"Deno". This privacy policy will explain how our organization uses the personal
data we collect from you when you use our website.

This privacy policy applies to all services provided at deno.com and deno.land.

Topics:

- What data do we collect?
- How do we collect your data?
- How will we use your data?
- How do we store your data?
- Marketing
- What are your data protection rights?
- What are cookies?
- How do we use cookies?
- What types of cookies do we use?
- How to manage your cookies
- Privacy policies of other websites
- Changes to our privacy policy
- How to contact us
- What data do we collect?

## What data do we collect?

For users of Deno Deploy, we collect your email address and GitHub login. We
also automatically collect from you your usage information, cookies, and device
information, subject, where necessary, to your consent.

## How do we collect your data?

- Your email address is collected during registration to Deno Deploy.
- Usage information, cookies, and device information are collected automatically
  when viewing our websites.

## How will we use your data?

Deno collects your data so that we can:

- Manage your account. Deno Deploy requires your email address for
  notifications, like when being invited an organization.
- Analyze usage patterns of our products and services.

Deno will not share your information with other parties.

## How do we store your data?

Deno takes measures reasonably necessary to protect User Personal Information
from unauthorized access, alteration, or destruction.

Deno will keep your email address indefinitely. Contact us at privacy@deno.com
to request your information be deleted.

## Marketing

Deno does not currently send out marketing information. However, Deno may in the
future send you information about products and services of ours that we think
you might like.

You have the right at any time to stop Deno from contacting you for marketing
purposes. Please contact us at privacy@deno.com

## What are your data protection rights?

Deno would like to make sure you are fully aware of all of your data protection
rights. Every user is entitled to the following:

- The right to access – You have the right to request Deno for copies of your
  personal data.

- The right to rectification – You have the right to request that Deno correct
  any information you believe is inaccurate. You also have the right to request
  Deno to complete the information you believe is incomplete.

- The right to erasure – You have the right to request that Deno erase your
  personal data, under certain conditions.

- The right to restrict processing – You have the right to request that Our
  Company restrict the processing of your personal data, under certain
  conditions.

- The right to object to processing – You have the right to object to Our
  Company’s processing of your personal data, under certain conditions.

- The right to data portability – You have the right to request that Deno
  transfer the data that we have collected to another organization, or directly
  to you, under certain conditions.

- If you make a request, we have one month to respond to you. If you would like
  to exercise any of these rights, please contact us at our email:
  privacy@deno.com

## Cookies

Cookies are text files placed on your computer to collect standard Internet log
information and visitor behavior information. When you visit our websites, we
may collect information from you automatically through cookies or similar
technology

For further information, visit allaboutcookies.org.

## How do we use cookies?

Deno uses cookies in a range of ways to improve your experience on our website,
including:

- Keeping you signed in
- Understanding how you use our website

## What types of cookies do we use?

There are a number of different types of cookies, however, our website uses:

- Functionality – Deno uses these cookies so that we recognize you on our
  website and remember your previously selected preferences. These could include
  what language you prefer and location you are in. A mix of first-party and
  third-party cookies are used.
- Understanding Usage – Deno uses these cookies to collect information about
  your visit to our website, the content you viewed, the links you followed and
  information about your browser, device, and your IP address.

## How to manage cookies

You can set your browser not to accept cookies, and the above website tells you
how to remove cookies from your browser. However, in a few cases, some of our
website features may not function as a result.

## Privacy policies of other websites

The Deno website contains links to other websites. Our privacy policy applies
only to deno.land and deno.com, so if you click on a link to another website,
you should read their privacy policy.

## Changes to our privacy policy

Deno keeps its privacy policy under regular review and places any updates on
this web page. This privacy policy was last updated on December 2 2021.

## How to contact us

If you have any questions about Deno’s privacy policy, the data we hold on you,
or you would like to exercise one of your data protection rights, please do not
hesitate to contact us at privacy@deno.com.



/. 🚀 deploy/manual/regions.md
===================================================

# Regions

Deno Deploy deploys your code throughout the world. Each new request is served
from the closest region to your user. Deploy is presently located in the
following regions:

<!-- Note to maintainers: Update NUM_REGIONS in utils/const.ts
 when you update the list of regions. -->

1. Taiwan (`asia-east1`)
1. Hong Kong (`asia-east2`)
1. Tokyo (`asia-northeast1`)
1. Osaka (`asia-northeast2`)
1. Seoul (`asia-northeast3`)
1. Mumbai (`asia-south1`)
1. Delhi (`asia-south2`)
1. Singapore (`asia-southeast1`)
1. Jakarta (`asia-southeast2`)
1. Sydney (`australia-southeast1`)
1. Melbourne (`australia-southeast2`)
1. Warsaw (`europe-central2`)
1. Finland (`europe-north1`)
1. Belgium (`europe-west1`)
1. London (`europe-west2`)
1. Frankfurt (`europe-west3`)
1. Netherlands (`europe-west4`)
1. Zurich (`europe-west6`)
1. Milan (`europe-west8`)
1. Paris (`europe-west9`)
1. Tel Aviv (`me-west1`)
1. Madrid (`europe-southwest1`)
1. Montréal (`northamerica-northeast1`)
1. Toronto (`northamerica-northeast2`)
1. São Paulo (`southamerica-east1`)
1. Chile (`southamerica-west1`)
1. Iowa (`us-central1`)
1. South Carolina (`us-east1`)
1. North Virginia (`us-east4`)
1. Ohio (`us-east5`)
1. Texas (`us-south1`)
1. Oregon (`us-west1`)
1. California (`us-west2`)
1. Utah (`us-west3`)
1. Nevada (`us-west4`)

We will update the list as we add more regions.



/. 🚀 deploy/manual/running-scripts-locally.md
===================================================

# Local development

For local development you can use the `deno` CLI. To install `deno`, follow the
instructions in the
[Deno manual](https://deno.land/manual/getting_started/installation).

After installation, you can run your scripts locally:

```shell
$ deno run --allow-net=:8000 https://deno.com/examples/hello.js
Listening on http://localhost:8000
```

To watch for file changes add the `--watch` flag:

```shell
$ deno run --allow-net=:8000 --watch ./main.js
Listening on http://localhost:8000
```

For more information about the Deno CLI, and how to configure your development
environment and IDE, visit the Deno Manual's [Getting Started][manual-gs]
section.

[manual-gs]: https://deno.land/manual/getting_started



/. 🚀 deploy/manual/security.md
===================================================

# Security and responsible disclosure

We consider the security of our systems, and all data controlled by those
systems a top priority. No matter how much effort we put into system security,
it is still possible that security vulnerabilities are present. We appreciate
investigative work into system security carried out by well-intentioned, ethical
security researchers. If you discover a vulnerability, however small, we would
like to know about it so we can address it with appropriate measures, as quickly
as possible. This page outlines the method we use to work with the security
research community to address our system security.

## Reporting a vulnerability

Please email you findings to security@deno.com. We strive to resolve all
problems as quickly as possible, and are more than happy to play an active role
in publication of writeups after the problem is resolved.

## Please do the following:

- Do not take advantage of the vulnerability or problem you have discovered. For
  example only download data that is necessary to demonstrate the
  vulnerability - do not download any more. Also do not delete, modify, or view
  other people's data.
- Do not publish or reveal the problem until it has been resolved.
- Do not use attacks on physical security, social engineering, distributed
  denial of service, spam or applications of third parties.
- Do provide sufficient information to reproduce the problem, so we will be able
  to resolve it as quickly as possible. Usually, the IP address or the URL of
  the affected system and a description of the vulnerability will be sufficient,
  but complex vulnerabilities may require further explanation.

## Our commitment

- If you act in accordance with this policy, we will not take legal action
  against you in regard to your report.
- We will handle your report with strict confidentiality, and not pass on your
  personal details to third parties without your permission.



/. 🚀 deploy/manual/subhosting/index.md
===================================================

# About Subhosting

A powerful use case for Deno Deploy is using our isolate cloud to run untrusted
code on behalf of your end users. There are a number of scenarios where you
might be interested in doing this:

- You are a SaaS provider that wants to empower your customers to extend your
  platform with custom code
- You are an infrastructure provider that would like to enable your customers to
  run Deno-powered edge functions
- You are building a browser-based editor for user code (possibly for
  education), and you'd like a place to execute that code in a controlled and
  secure way

In cases like these, you might consider using Deno Deploy's full-featured
[REST API](/deploy/api/rest) to implement
[**subhosting**](https://deno.com/subhosting). "Subhosting" is what we call the
scenario where you use Deno Deploy to run your users' untrusted code in a secure
and scalable environment designed for
[multitenancy](https://www.ibm.com/topics/multi-tenant).

## Quick start example

Looking for the smallest possible example that shows how to deploy code to
Deno's isolate cloud? We've got you covered below. Once you've skimmed over it,
you can read on for more details about subhosting.

```ts
// 1.) Get API access info ready
const accessToken = Deno.env.get("DEPLOY_ACCESS_TOKEN");
const orgId = Deno.env.get("DEPLOY_ORG_ID");
const API = "https://api.deno.com/v1";
const headers = {
  Authorization: `Bearer ${accessToken}`,
  "Content-Type": "application/json",
};

// 2.) Create a new project
const pr = await fetch(`${API}/organizations/${orgId}/projects`, {
  method: "POST",
  headers,
  body: JSON.stringify({
    name: null, // randomly generates project name
  }),
});
const project = await pr.json();

// 3.) Deploy a "hello world" server to the new project
const dr = await fetch(`${API}/projects/${project.id}/deployments`, {
  method: "POST",
  headers,
  body: JSON.stringify({
    entryPointUrl: "main.ts",
    assets: {
      "main.ts": {
        "kind": "file",
        "content": `Deno.serve(() => new Response("Hello, World!"));`,
        "encoding": "utf-8",
      },
    },
    envVars: {},
  }),
});
console.log(dr.status);
```

## How subhosting works

To build subhosting with Deno Deploy, it helps to understand some key resources
within the system. These resources are also represented in the
[REST API](/deploy/api/rest).

![overview of subhosting resources](./subhosting-org-structure.svg)

- [**Organizations**](/deploy/api/rest/organizations): Organizations are a
  container for all data related to a subhosting implementation. Other Deploy
  users can be invited to collaborate on an organization, and
  [access tokens](https://dash.deno.com/account#access-tokens) can give
  developers with organization access the ability to modify resources within the
  org via API. New organizations can be created in the
  [Deploy dashboard](https://dash.deno.com/orgs/new).
- [**Projects**](/deploy/api/rest/projects): a project is a container for
  **deployments**, and the analytics and usage information for all deployments
  within a project.
- [**Deployments**](/deploy/api/rest/deployments): a deployment is a set of
  configuration, runnable code, and supporting static files that can run on an
  isolate in Deno Deploy. Deployments have an entry file that can launch a
  server, can have a [Deno KV](/kv/manual) database associated with them, and
  can be set up to run on custom domains.
- [**Domains**](/deploy/api/rest/domains): custom domains that can be associated
  with deployments, giving them a unique URL.

The steps to implement subhosting are roughly as follows:

1. [Create an organization](./getting_started) and get an access token for the
   REST API
1. [Create a project](./projects_and_deployments), and then create your first
   deployment for that project
1. [Provision a domain](../../api/rest/domains.md) and associate that domain
   with a deployment

Using these techniques, you can package up user code as "deployments", and
execute that code on a Deno-provisioned URL or a custom URL you can configure
yourself.

## REST API reference and OpenAPI spec

For a complete reference for the REST API used to implement subhosting, you can
[check out the docs here](/deploy/api/rest). The Deno Deploy REST API also
provides an [OpenAPI specification](https://api.deno.com/v1/openapi.json) which
can be used with [a number of OpenAPI-compatible tools](https://openapi.tools/).



/. 🚀 deploy/manual/subhosting/domains.md
===================================================

# Working with custom domains

TODO - talk about provisioning domains and associating them with deployments.

For now, reference:
https://github.com/denoland/deploy-api/blob/main/samples.ipynb



/. 🚀 deploy/manual/subhosting/getting_started.md
===================================================

# Getting started with subhosting

To get started with subhosting, you will need to create an organization in the
[Deno Deploy dashboard](https://dash.deno.com/orgs/new). Follow the on-screen
instructions to create a new organization for subhosting.

Going through the onboarding flow, you will likely also generate an **access
token**, which you will use to access the [REST API](/deploy/api/rest). If you
didn't do this (or lost the token you generated), you can
[generate a new one here](https://dash.deno.com/account#access-tokens).

:::caution Save your token in a safe place

Once you generate an access token, **it will not be displayed again within the
Deploy dashboard UI**. Make sure you store this token in a safe place.

:::

## Set up a test environment

In the tutorial pages to follow, we will assume you are interacting with the
Deploy REST API through Deno scripts (TypeScript code), and will show examples
of interacting with the API in this way. However, the techniques shown here will
also work in any other environment capable of executing HTTP requests.

The example code shown here and in future chapters assume that you have
[Deno 1.38 or higher](/runtime/manual/getting_started/installation) installed.

When working with a REST API, it is useful to store authentication credentials
in the [system environment](/runtime/manual/basics/env_variables), to prevent
you from accidentally checking them in to source control.

For this tutorial, we'll use the new `--env` flag
[introduced in Deno 1.38](https://deno.com/blog/v1.38#deno-run---env) to manage
environment variables. On your local computer, create a new directory to store
our management scripts in, and create three files:

- `.env` - to hold our API access info
- `.gitignore` - to ignore our `.env` file so we don't put it in source control
  by mistake
- `create_project.ts` - a file we'll use in a moment to make our first request
  to the REST API

### Configure a `.env` file and `.gitignore` file

First, store your [access token](https://dash.deno.com/account#access-tokens)
and organization ID in the `.env` file you created earlier.

```bash title=".env"
DEPLOY_ACCESS_TOKEN=your_token_here
DEPLOY_ORG_ID=your_org_id_here
```

Replace the values in the file with the values from your own Deploy account.

Next, create a `.gitignore` file just to ensure we don't accidentally check our
`.env` file into source control:

```bash title=".gitignore"
# Ignore this file in git
.env

# Optional: ignore this junk file often generated on mac OS
.DS_Store
```

Now that we have our credentials set up, let's write some code to access the
REST API.

## Creating our first project

In order to do anything interesting with subhosting or the REST API, we'll need
to [create a project](/deploy/api/rest/projects). Copy the code below into a
file named `create_project.ts` in the same file as your `.env` and `.gitignore`
file.

```ts title="create_project.ts"
const accessToken = Deno.env.get("DEPLOY_ACCESS_TOKEN");
const orgId = Deno.env.get("DEPLOY_ORG_ID");
const API = "https://api.deno.com/v1";

// Create a new project
const res = await fetch(`${API}/organizations/${orgId}/projects`, {
  method: "POST",
  headers: {
    Authorization: `Bearer ${accessToken}`,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    name: null, // randomly generates project name
  }),
});

const project = await res.json();
console.log(project);
```

Execute this code with the following command in a terminal:

```bash
deno run -A --env create_project.ts
```

If everything goes according to plan, you should see output that looks something
like this:

```
{
  id: "f084712a-b23b-4aba-accc-3c2de0bfa26a",
  name: "strong-fox-44",
  createdAt: "2023-11-07T01:01:14.078730Z",
  updatedAt: "2023-11-07T01:01:14.078730Z"
}
```

Note the `id` of the project that was returned with this repsonse - this is the
project ID we'll use in the next step.

Now that we have REST API access configured and a project set up, we can move on
to [creating our first deployment](./projects_and_deployments).



/. 🚀 deploy/manual/subhosting/projects_and_deployments.md
===================================================

# Projects and deployments

In the [domain model for subhosting](./index.md), a **project** is a container
for **deployments**. You can track aggregate analytics for a project (like how
many requests are being processed, KV database usage, etc). But actual code that
runs and serves requests is contained in a **deployment**. Depending on the data
model for your application, you might choose to map projects and deployments in
different ways.

## Planning your implementation

For example - let's say that you were building a SaaS CRM platform like
Salesforce, and you wanted to empower your customers to write JavaScript code
that would be executed every time a new lead was captured.

If you were going to implement this feature using Deno Deploy, here's how you
might think about building it:

- Create a **project** and associate that project with a customer account in
  your database. This would allow you to track usage incurred by each customer,
  and potentially bill them for that usage, using analytics information about
  the project.
- Create a **deployment** that contains the code your end user provided, which
  should be run when a new lead is created.
- Using multiple deployments in the same project, you could implement "staging"
  or "production" versions of the event handling logic.
- Your CRM software would communicate with your end user's code by sending an
  HTTP request to a deployment and awaiting a response.
- In the future, if you wanted to support writing code for other events in your
  CRM (like creating a new contact, or to send automated reports every night),
  you could create a project for each of those events, and use a flow like the
  one described above for each.

Let's look at an example of the API endpoint required to make this happen.

## Creating a deployment for a project

In the [previous chapter](./getting_started.md), you created a new project and
noted its `id` property. In the example in the previous chapter, the ID was:

```
f084712a-b23b-4aba-accc-3c2de0bfa26a
```

You can use a project identifier to
[create a deployment](../../api/rest/deployments.md) for that project. Create a
new file called `create_deployment.ts` and include the following code to create
a new "hello world" deployment for your project.

```ts title="create_deployment.ts"
const accessToken = Deno.env.get("DEPLOY_ACCESS_TOKEN");
const API = "https://api.deno.com/v1";

// Replace with your desired project ID
const projectId = "f084712a-b23b-4aba-accc-3c2de0bfa26a";

// Create a new deployment
const res = await fetch(`${API}/projects/${projectId}/deployments`, {
  method: "POST",
  headers: {
    Authorization: `Bearer ${accessToken}`,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    entryPointUrl: "main.ts",
    assets: {
      "main.ts": {
        "kind": "file",
        "content": `Deno.serve(() => new Response("Hello, World!"));`,
        "encoding": "utf-8",
      },
    },
    envVars: {},
  }),
});

console.log(res.status);
```

If you run this script with the following command:

```bash
deno run -A --env create_deployment.ts
```

You should soon have a simple "Hello World!" server live on a public URL,
visible from your Deno Deploy dashboard.

## Parts of a deployment

The example above showed a very simple example of a deployment. A more complex
deployment might include some or all of these components, fully described
[here in the API docs](../../api/rest/deployments.md).

- **Assets:** TypeScript or JavaScript source files, images, JSON documents -
  code and static files that make your deployment run. These files can be
  encoded in the JSON you upload to the server using `utf-8` (for plain source
  files) or `base64` for images and other text files. In addition to actual
  files, you can also include symbolic links to other files.
- **Entry point URL:** A file path to an asset (a TypeScript or JavaScript file)
  from the collection above that should be executed to start a server in your
  deployment.
- **Environment variables:** You can specify values that should exist in the
  system environment, to be retrieved by `Deno.env.get`.
- **Database ID:** The identifier for a Deno KV database that should be made
  available to this deployment.
- **Compiler options:** A set of options that should be used to interpret
  TypeScript code.

## Custom domains

After a deployment is created, it is assigned a generated URL. That may be fine
for some scenarios, but often you'll want to associate a custom domain with your
deployments as well.
[Check out the API reference for domains](../../api/rest/domains.md).



/. 🚀 deploy/manual/use-cases.md
===================================================

# Deno Deploy Use Cases

Some popular use-cases for Deno currently are:

- [Middleware](#middleware)
- [API servers](#api-servers)
- [Full websites](#full-websites)

## Middleware

Middleware refers to bits of code that execute before and after the request gets
to the application server. You'll be writing middleware if you want to execute
some JavaScript or any other code very fast, early in the request. By deploying
your middleware code at the edge, Deno Deploy ensures the best performance for
your app.

Some examples include:

- setting a cookie
- serving different versions of a site depending on geolocation
- path rewriting
- redirecting requests
- dynamically changing the HTML on its way back from the server before it gets
  to the user.

Deno Deploy is a good alternative to other platforms you might be using to host
your middleware right now, for example:

- Cloudflare Workers
- AWS Lambda@Edge
- Traditional load balancers like nginx
- Custom rules

## API servers

Deno is also a great fit for API servers. By deploying these servers "at the
edge", closer to clients who are using them, Deno Deploy is able to offer lower
latency, improved performance, and reduced bandwidth costs compared to
traditional hosting platforms like Heroku or even modern centralized hosting
services like DigitalOcean.

## Full websites

We foresee a future where you can actually write your entire website on edge
functions. Some examples of sites that are already doing this include:

- [blog](https://github.com/ry/tinyclouds)
- [chat](https://github.com/denoland/showcase_chat)
- [calendly clone](https://github.com/denoland/meet-me)



/. 🚀 deploy/api/index.md
===================================================

---
displayed_sidebar: deployAPIHome
sidebar_position: 1
sidebar_label: Overview
pagination_next: api/runtime-broadcast-channel
---

# API Reference

This is a reference for runtime APIs available on Deno Deploy. This API is very
similar to the standard [runtime API](/runtime/manual/runtime), but some APIs
are not available in the same way, given that Deno Deploy is a serverless
environment.

Please use this section of the documentation to explore available APIs on Deno
Deploy.

### Web APIs

- [`console`](https://developer.mozilla.org/en-US/docs/Web/API/console)
- [`atob`](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/atob)
- [`btoa`](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/btoa)
- [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)
  - `fetch`
  - `Request`
  - `Response`
  - `URL`
  - `File`
  - `Blob`
- [TextEncoder](https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder)
- [TextDecoder](https://developer.mozilla.org/en-US/docs/Web/API/TextDecoder)
- [TextEncoderStream](https://developer.mozilla.org/en-US/docs/Web/API/TextEncoderStream)
- [TextDecoderStream](https://developer.mozilla.org/en-US/docs/Web/API/TextDecoderStream)
- [Performance](https://developer.mozilla.org/en-US/docs/Web/API/Performance)
- [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Crypto)
  - `randomUUID()`
  - `getRandomValues()`
  - [SubtleCrypto](https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto)
- [WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Timers](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/setTimeout)
  (`setTimeout`, `clearTimeout`, and `setInterval`)
- [Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API)
  - `ReadableStream`
  - `WritableStream`
  - `TransformStream`
- [URLPattern API](https://developer.mozilla.org/en-US/docs/Web/API/URLPattern)
- [Import Maps](https://deno.land/manual/linking_to_external_code/import_maps)
  - Note: `import maps` are currently only available via
    [deployctl](https://github.com/denoland/deployctl) or
    [deployctl GitHub Action](https://github.com/denoland/deployctl/blob/main/action/README.md)
    workflows.

### Deno APIs

> Note: only stable APIs of Deno are made available in Deploy.

- [`Deno.env`](https://doc.deno.land/deno/stable/~/Deno.env) - Interact with
  environment variables (secrets).
  - `get(key: string): string | undefined` - get the value of an environment
    variable.
  - `toObject(): { [key: string]: string }` - get all environment variables as
    an object.
- [`Deno.connect`](https://doc.deno.land/deno/stable/~/Deno.connect) - Connect
  to TCP sockets.
- [`Deno.connectTls`](https://doc.deno.land/deno/stable/~/Deno.connectTls) -
  Connect to TCP sockets using TLS.
- [`Deno.startTls`](https://doc.deno.land/deno/stable/~/Deno.startTls) - Start
  TLS handshake from an existing TCP connection.
- [`Deno.resolveDns`](https://doc.deno.land/deno/stable/~/Deno.resolveDns) -
  Make DNS queries
- File system API
  - [`Deno.cwd`](https://doc.deno.land/deno/stable/~/Deno.cwd) - Get the current
    working directory
  - [`Deno.readDir`](https://doc.deno.land/deno/stable/~/Deno.readDir) - Get
    directory listings
  - [`Deno.readFile`](https://doc.deno.land/deno/stable/~/Deno.readFile) - Read
    a file into memory
  - [`Deno.readTextFile`](https://doc.deno.land/deno/stable/~/Deno.readTextFile) -
    Read a text file into memory
  - [`Deno.open`](https://doc.deno.land/deno/stable/~/Deno.open) - Open a file
    for streaming reading
  - [`Deno.stat`](https://doc.deno.land/deno/stable/~/Deno.stat) - Get file
    system entry information
  - [`Deno.lstat`](https://doc.deno.land/deno/stable/~/Deno.lstat) - Get file
    system entry information without following symlinks
  - [`Deno.realPath`](https://doc.deno.land/deno/stable/~/Deno.realPath) - Get
    the real path of a file after resolving symlinks
  - [`Deno.readLink`](https://doc.deno.land/deno/stable/~/Deno.readLink) - Get
    the target path for the given symlink

## Future support

In the future, these APIs will also be added:

- [Cache API](https://developer.mozilla.org/en-US/docs/Web/API/Cache)
- UDP API:
  - `Deno.connectDatagram` for outbound UDP sockets
- Customizable `fetch` options using `Deno.createHttpClient`

## Limitations

Just like the Deno CLI, we do not implement the `__proto__` object field as
specified in ECMA Script Annex B.



/. 🚀 deploy/api/compression.md
===================================================

# Compressing response bodies

Compressing the response body to save bandwidth is a common practice. To take
some work off your shoulder, we built the capabilities directly into Deploy.

Deno Deploy supports brotli and gzip compression. Compression is applied when
the following conditions are met.

1. The request to your deployment has [`Accept-Encoding`][accept-encoding]
   header set to either `br` (brotli) or `gzip`.
2. The response from your deployment includes the [`Content-Type`][content-type]
   header.
3. The provided content type is compressible; we use
   [this database](https://github.com/jshttp/mime-db/blob/master/db.json) to
   determine if the content type is compressible.
4. The response body size is greater than 20 bytes.

When Deploy compresses the response body, it will set `Content-Encoding: gzip`
or `Content-Encoding: br` header to the response based on the compression
algorithm used.

### When is compression skipped?

Deno Deploy skips the compression if:

- The response has [`Content-Encoding`][content-encoding] header.
- The response has [`Content-Range`][content-range] header.
- The response's [`Cache-Control`][cache-control] header has
  [`no-transform`][no-transform] value (e.g.
  `cache-control: public, no-transform`).

### What happens to my `Etag` header?

When you set an Etag header with the response, we convert the header value to a
Weak Etag if we apply compression to your response body. If it is already a Weak
Etag, we don't touch the header.

[accept-encoding]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Encoding
[cache-control]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control
[content-encoding]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding
[content-type]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type
[no-transform]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control#other
[content-range]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Range



/. 🚀 deploy/api/rest/index.md
===================================================

    curl -s -L https://docs.deno.com/deploy/api/rest | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Deno Deploy REST API

Developers can provision projects, domains, KV databases, and other resources
using the Deno Deploy REST API. This API is most often used to implement
[Subhosting](/deploy/manual/subhosting), a use case of Deno Deploy where you can
run untrusted code on behalf of your users in the cloud.

[Refer to the manual](/deploy/manual/subhosting) to learn more about Subhosting.

## Endpoint and authentication

The base URL for the Deno Deploy REST API v1 is below.

```
https://api.deno.com/v1/
```

The v1 API uses
[HTTP bearer token](https://swagger.io/docs/specification/authentication/bearer-authentication/)
authentication. You can create an access token to use the API in the dashboard
[here](https://dash.deno.com/account#access-tokens). Most API requests will also
require your organization ID. You can retrieve yours from the Deno Deploy
dashboard for your organization.

![Find your org ID here](https://docs.deno.com/assets/images/org-id-d9d5b3239f2d8ff2f7f304bf76feaf5f.png)
<!-- ![Find your org ID here](./images/org-id.png) -->

Using both your organization ID and your access token, you can test your API
access by listing all the projects associated with your organization. Here is an
example Deno script you can use to access the API.

```typescript
// Replace these with your own!
const organizationId = "a75a9caa-b8ac-47b3-a423-3f2077c58731";
const token = "ddo_u7mo08lBNHm8GMGLhtrEVfcgBsCuSp36dumX";

const res = await fetch(
  `https://api.deno.com/v1/organizations/${organizationId}/projects`,
  {
    method: "GET",
    headers: {
      Authorization: `Bearer ${token}`,
    },
  },
);

const response = await res.json();
console.log(response);
```

## OpenAPI specification and tooling

The [OpenAPI specification](https://www.openapis.org/) for the Deploy API can be
found here:

```
https://api.deno.com/v1/openapi.json
```

This spec document can be used with a
[large number of OpenAPI-compatible tools](https://openapi.tools/). In addition
to the documentation for the REST API maintained here, you can find
auto-generated API documentation (including a browser-based testing tool)
[here](https://apidocs.deno.com/).



/. 🚀 deploy/api/rest/deployments.md
===================================================

import OpenApiEndpoint from "@site/src/components/OpenApiEndpoint";

# Deployments

A deployment is a container for assets, environment variables, compiler options,
and other data related to a deployed serverless application.

## Create a deployment

<!-- deno-fmt-ignore-start -->

<OpenApiEndpoint path="/projects/{projectId}/deployments" method="post"
  customDocs={{ 
    compilerOptions: "See **Compiler options** below.", 
    assets: "See **Deployment assets** below.", 
  }}
>
  <p>
    Initiate a build process for a new deployment. Note that this process is
    asynchronous - a successful request to this endpoint API doesn't mean the
    deployment is ready.
  </p>
  <p>
    For now, you can track the progress of a build by polling either the&nbsp;
    <a href="#get-deployment-build-logs">build logs for a deployment</a> or the&nbsp;
    <a href="#get-deployment-details">deployment details</a> API endpoints.
  </p>
</OpenApiEndpoint>

<!-- deno-fmt-ignore-end -->

### Compiler options

The `compilerOptions` key of the `POST` body sent with a deployment creation
request can override the options usually configured
[here in deno.json](/runtime/manual/getting_started/configuration_file#compileroptions).
Compiler options will determine how your application's TypeScript code will be
processed.

If `null` is provided, Deploy will attempt to discover a `deno.json` or
`deno.jsonc` within the assets of your deployment (see **Deployment assets**
below). If an empty object `{}` is provided, Deploy will use default TypeScript
configuration.

### Deployment assets

The assets associated with a deployment are the code and static files that drive
the behavior of the deployment and handle incoming requests. In JSON body sent
with a `POST` request to this endpoint, you will include an `assets` attribute
that contains keys that represent the file path to a particular asset.

So for example - a file that would live in a deployment directory under
`server/main.ts` would use that path as the key for the asset.

An asset has a `kind` attribute associated with it, which can be one of:

- `file` - an actual file associated with the deployment
- `symlink` - a [symbolic link](https://en.wikipedia.org/wiki/Symbolic_link) to
  another file in the deployment

File assets also have a `content` property, which as you might imagine, is the
actual contents of the file. These assets also have an `encoding` property,
which indicates whether the content is encoded as `utf-8` (plain text) or
`base64` for
[base64 encoded content](https://developer.mozilla.org/en-US/docs/Glossary/Base64).

To prevent the need to re-upload files that very seldom change, you can also
specify a `gitSha1` attribute, which is a `SHA-1` hash of the content that was
previously uploaded for the specified asset.

Below is an example of `assets` that could be used to set up a deployment.

```json
{
  "assets": {
    "main.ts": {
      "kind": "file",
      "content": "Deno.serve((req: Request) => new Response(\"Hello World\"));",
      "encoding": "utf-8"
    },
    "images/cat1.png": {
      "kind": "file",
      "content": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk",
      "encoding": "base64"
    },
    "images/cat2.png": {
      "kind": "file",
      "gitSha1": "5c4f8729e5c30a91a890e24d7285e89f418c637b"
    },
    "symlink.png": {
      "kind": "symlink",
      "target": "images/cat1.png"
    }
  }
}
```

## Get deployment details

<OpenApiEndpoint path="/deployments/{deploymentId}" method="get">
  Get details for a deployment with the given ID. This endpoint can be polled
  to track the results of a serverless app deployment.
</OpenApiEndpoint>

## Get deployment build logs

<OpenApiEndpoint path="/deployments/{deploymentId}/build_logs" method="get">
  Get build logs for the deployment specified by ID. You can use this
  information to check on the current status of a build, or to figure out
  what went wrong in the case of a failure.
  <br/><br/>
  The response format can be controlled by the <code>Accept</code> header. If&nbsp;
  <code>application/x-ndjson</code> is specified, the response will be a stream
  of newline-delimited JSON objects. Otherwise it will be a JSON array of
  objects.
</OpenApiEndpoint>

## Get deployment app logs

<OpenApiEndpoint path="/deployments/{deploymentId}/app_logs" method="get">
  Get execution logs of a deployment. This API can return either past logs or
  real-time logs depending on the presence of the <code>since</code> and&nbsp;
  <code>until</code> query parameters. If at least one of them is provided,
  past logs are returned. Otherwise real-time logs are returned.
  <br/><br/>
  Also, the response format can be controlled by the <code>Accept</code>&nbsp;
  header. If <code>application/x-ndjson</code> is specified, the response will
  be a stream of newline-delimited JSON objects. Otherwise, it will be a JSON
  array of objects.
</OpenApiEndpoint>



/. 🚀 deploy/api/rest/domains.md
===================================================

import OpenApiEndpoint from "@site/src/components/OpenApiEndpoint";

# Domains

Custom domains can be used to give your deployments a unique URL.

## List an organization's domains

<OpenApiEndpoint path="/organizations/{organizationId}/domains" method="get">
  Get a list of domains associated with an organization. Links to the first,
  last, next, and previous pages of results are found in the <code>Link</code>
  &nbsp;header of the response.
</OpenApiEndpoint>

## Add a domain to an organization

<OpenApiEndpoint path="/organizations/{organizationId}/domains" method="post">
  Add a new domain to the specified organization. Before use, added domain
  needs to be verified, and TLS certificates for the domain need to be
  provisioned.
</OpenApiEndpoint>

## Get a domain by ID

<OpenApiEndpoint path="/domains/{domainId}" method="get">
  Get metadata about a domain by the given ID.
</OpenApiEndpoint>

## Associate a domain with a deployment

<OpenApiEndpoint path="/domains/{domainId}" method="patch">
  With this API endpoint, you can associate or disassociate a domain with a
  deployment. Domain association is required in order to serve the deployment
  on the domain.
</OpenApiEndpoint>

## Delete a domain

<OpenApiEndpoint path="/domains/{domainId}" method="delete">
  Delete a domain by the given ID.
</OpenApiEndpoint>

## Verify a domain

<OpenApiEndpoint path="/domains/{domainId}/verify" method="post">
  This API endpoint triggers the ownership verification of a domain. It should
  be called after necessary DNS records are properly set up.
</OpenApiEndpoint>

## Upload TLS certificate for a domain

<OpenApiEndpoint path="/domains/{domainId}/certificates" method="post">
  Upload TLS certificates for your domain.
</OpenApiEndpoint>

## Provision TLS certificates for a domain

<OpenApiEndpoint path="/domains/{domainId}/certificates/provision" method="post">
  Provision TLS certificates for your domain.
</OpenApiEndpoint>



/. 🚀 deploy/api/rest/organizations.md
===================================================

import OpenApiEndpoint from "@site/src/components/OpenApiEndpoint";

# Organizations

Organizations are a container for projects, domains, and KV databases. New
organizations can be created in the
[Deno Deploy dashboard](https://dash.deno.com). The access tokens created for
your account may make changes to any of the organizations to which you have
access.

## Get organization details

<OpenApiEndpoint path="/organizations/{organizationId}" method="get">
  Get meta information about your organization, passing in your
  unique ID as a path parameter.
</OpenApiEndpoint>

## Get analytics for organization

<OpenApiEndpoint path="/organizations/{organizationId}/analytics" method="get">
  Get analytics information for an organization.
</OpenApiEndpoint>

## List projects for an organization

<OpenApiEndpoint path="/organizations/{organizationId}/projects" method="get">
  Get a paginated list of Projects for an organization. Links to the first,
  last, next, and previous pages of results are found in the <code>Link</code>
  &nbsp;header of the response.
</OpenApiEndpoint>

## Create a new project for an organization

<OpenApiEndpoint path="/organizations/{organizationId}/projects" method="post">
  Create a new project within the given organization. A project is a container
  for deployments, and can be associated with domains and KV databases.
</OpenApiEndpoint>

## List an organization's KV databases

<OpenApiEndpoint path="/organizations/{organizationId}/databases" method="get">
  Get a list of KV databases associated with an organization. Links to the first,
  last, next, and previous pages of results are found in the <code>Link</code>
  &nbsp;header of the response.
</OpenApiEndpoint>

## Create a KV database for an organization

<OpenApiEndpoint path="/organizations/{organizationId}/databases" method="post">
  Create a new KV database associated with an organization.
</OpenApiEndpoint>

## List an organization's domains

<OpenApiEndpoint path="/organizations/{organizationId}/domains" method="get">
  Get a list of domains associated with an organization. Links to the first,
  last, next, and previous pages of results are found in the <code>Link</code>
  &nbsp;header of the response.
</OpenApiEndpoint>

## Add a domain to an organization

<OpenApiEndpoint path="/organizations/{organizationId}/domains" method="post">
  Add a new domain to the specified organization. Before use, added domain
  needs to be verified, and TLS certificates for the domain need to be
  provisioned.
</OpenApiEndpoint>



/. 🚀 deploy/api/rest/projects.md
===================================================

import OpenApiEndpoint from "@site/src/components/OpenApiEndpoint";

# Projects

Projects are a container for deployments, and can be associated with domains and
KV databases in an organization.

## Get project details

<OpenApiEndpoint path="/projects/{projectId}" method="get">
  Get meta information about a project by unique ID.
</OpenApiEndpoint>

## Update project details

<OpenApiEndpoint path="/projects/{projectId}" method="patch">
  Update meta information about a project.
</OpenApiEndpoint>

## Delete a project

<OpenApiEndpoint path="/projects/{projectId}" method="delete">
  Delete a project by unique ID.
</OpenApiEndpoint>

## Get project analytics

<OpenApiEndpoint path="/projects/{projectId}/analytics" method="get">
  Get analytics data for the specified project. The analytics are returned as
  time series data in 15 minute intervals, with the <code>time</code> field
  representing the start of the interval.
</OpenApiEndpoint>

## Get project deployments

<OpenApiEndpoint path="/projects/{projectId}/deployments" method="get">
  Get a paginated list of deployments belonging to the specified project. The
  URLs for the next, previous, first, and last page are returned in the
  <code>Link</code> header of the response if needed.
</OpenApiEndpoint>



/. 🚀 deploy/api/runtime-broadcast-channel.md
===================================================

# BroadcastChannel

In Deno Deploy, code is run in different data centers around the world in order
to reduce latency by servicing requests at the data center nearest to the
client. In the browser, the BroadcastChannel API allows different tabs with the
same origin to exchange messages. In Deno Deploy, the BroadcastChannel API
provides a communication mechanism between the various instances; a simple
message bus that connects the various Deploy instances world wide.

- [Constructor](#constructor)
  - [Parameters](#parameters)
- [Properties](#properties)
- [Methods](#methods)
- [Example](#example)

## Constructor

The `BroadcastChannel()` constructor creates a new `BroadcastChannel` instance
and connects to (or creates) the provided channel.

```ts
let channel = new BroadcastChannel(channelName);
```

#### Parameters

| name        | type     | description                                               |
| ----------- | -------- | --------------------------------------------------------- |
| channelName | `string` | The name for the underlying broadcast channel connection. |

The return type of the constructor is a `BroadcastChannel` instance.

## Properties

| name             | type                   | description                                                                                                  |
| ---------------- | ---------------------- | ------------------------------------------------------------------------------------------------------------ |
| `name`           | `string`               | The name of the underlying broadcast channel.                                                                |
| `onmessage`      | `function` (or `null`) | The function that's executed when the channel receives a new message ([`MessageEvent`][messageevent]).       |
| `onmessageerror` | `function` (or `null`) | The function that's executed when the arrived message cannot be deserialized to a JavaScript data structure. |

## Methods

| name                   | description                                                                                                                        |
| ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| `close()`              | Close the connection to the underlying channel. After closing, you can no longer post messages to the channel.                     |
| `postMessage(message)` | Post a message to the underlying channel. The message can be a string, object literal, a number or any kind of [`Object`][object]. |

`BroadcastChannel` extends [`EventTarget`][eventtarget], which allows you to use
methods of `EventTarget` like `addEventListener` and `removeEventListener` on an
instance of `BroadcastChannel`.

## Example

A small example that has an endpoint to send a new message to all other actively
running instances in different regions and another to fetch all messages from an
instance.

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

const messages = [];
// Create a new broadcast channel named earth.
const channel = new BroadcastChannel("earth");
// Set onmessage event handler.
channel.onmessage = (event: MessageEvent) => {
  // Update the local state when other instances
  // send us a new message.
  messages.push(event.data);
};

function handler(req: Request): Response {
  const { pathname, searchParams } = new URL(req.url);

  // Handle /send?message=<message> endpoint.
  if (pathname.startsWith("/send")) {
    const message = searchParams.get("message");
    if (!message) {
      return new Response("?message not provided", { status: 400 });
    }

    // Update local state.
    messages.push(message);
    // Inform all other active instances of the deployment
    // about the new message.
    channel.postMessage(message);
    return new Response("message sent");
  }

  // Handle /messages request.
  if (pathname.startsWith("/messages")) {
    return new Response(JSON.stringify(messages), {
      "content-type": "application/json",
    });
  }

  return new Response("not found", { status: 404 });
}

serve(handler);
```

You can test this example by making an HTTP request to
`https://broadcast.deno.dev/send?message=Hello_from_<region>` and then making
another request to `https://broadcast.deno.dev/messages` from a different region
(by using a VPN or some other way) to check if the first request's message is
present in the second region.

We built [a small chat application](https://github.com/lucacasonato/deploy_chat)
that you can play with at https://denochat.deno.dev/

[eventtarget]: https://developer.mozilla.org/en-US/docs/Web/API/EventTarget
[messageevent]: https://developer.mozilla.org/en-US/docs/Web/API/MessageEvent
[object]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object



/. 🚀 deploy/api/runtime-fetch.md
===================================================

# HTTP requests (fetch)

The [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)
allows you to make outbound HTTP requests in Deno Deploy. It is a web standard
and has the following interfaces:

- `fetch()` - The method that allows you to make outbound HTTP requests
- [`Request`](./runtime-request) - represents a request resource of fetch()
- [`Response`](./runtime-response) - represents a response resource of fetch()
- [`Headers`](./runtime-headers) - represents HTTP Headers of requests and
  responses.

This page shows usage for the fetch() method. You can click above on the other
interfaces to learn more about them.

Fetch also supports fetching from file URLs to retrieve static files. For more
info on static files, see the [filesystem API documentation](./runtime-fs).

## `fetch()`

The `fetch()` method initiates a network request to the provided resource and
returns a promise that resolves after the response is available.

```ts
function fetch(
  resource: Request | string,
  init?: RequestInit,
): Promise<Response>;
```

#### Parameters

| name     | type                                                          | optional | description                                                        |
| -------- | ------------------------------------------------------------- | -------- | ------------------------------------------------------------------ |
| resource | [`Request`](./runtime-request) <br/> [`USVString`][usvstring] | `false`  | The resource can either be a request object or a URL string.       |
| init     | [`RequestInit`](./runtime-request#requestinit)                | `true`   | The init object lets you apply optional parameters to the request. |

The return type of `fetch()` is a promise that resolves to a
[`Response`](./runtime-response).

## Examples

The Deno Deploy script below makes a `fetch()` request to the GitHub API for
each incoming request, and then returns that response from the handler function.

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(req: Request): Promise<Response> {
  const resp = await fetch("https://api.github.com/users/denoland", {
    // The init object here has an headers object containing a
    // header that indicates what type of response we accept.
    // We're not specifying the method field since by default
    // fetch makes a GET request.
    headers: {
      accept: "application/json",
    },
  });
  return new Response(resp.body, {
    status: resp.status,
    headers: {
      "content-type": "application/json",
    },
  });
}

serve(handler);
```

[usvstring]: https://developer.mozilla.org/en-US/docs/Web/API/USVString



/. 🚀 deploy/api/runtime-fs.md
===================================================

# File system APIs

Deno Deploy supports a limited set of the file system APIs available in Deno.
These file system APIs can access static files from your deployments. Static
files are for example:

- The files in your GitHub repository, if you deploy via the GitHub integration.
- The entrypoint file in a playground deployment.

<!-- - The files in your local repository, if you deploy with a push deployment. -->

The APIs that are available are:

- [Deno.cwd](#denocwd)
- [Deno.readDir](#denoreaddir)
- [Deno.readFile](#denoreadfile)
- [Deno.readTextFile](#denoreadtextfile)
- [Deno.open](#denoopen)
- [Deno.stat](#denostat)
- [Deno.lstat](#denolstat)
- [Deno.realPath](#denorealpath)
- [Deno.readLink](#denoreadlink)

## `Deno.cwd`

`Deno.cwd()` returns the current working directory of your deployment. It is
located at the root of your deployment's root directory. For example, if you
deployed via the GitHub integration, the current working directory is the root
of your GitHub repository.

## `Deno.readDir`

`Deno.readDir()` allows you to list the contents of a directory.

The function is fully compatible with
[Deno](https://doc.deno.land/deno/stable/~/Deno.readDir).

```ts
function Deno.readDir(path: string | URL): AsyncIterable<DirEntry>
```

The path can be a relative or absolute. It can also be a `file:` URL.

### Example

This example lists the contents of a directory and returns this list as a JSON
object in the response body.

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  // List the posts in the `blog` directory located at the root
  // of the repository.
  const posts = [];
  for await (const post of Deno.readDir(`./blog`)) {
    posts.push(post);
  }

  // Return JSON.
  return new Response(JSON.stringify(posts, null, 2), {
    headers: {
      "content-type": "application/json",
    },
  });
}

serve(handler);
```

## `Deno.readFile`

`Deno.readFile()` allows you to read a file fully into memory.

The function definition is similar to
[Deno](https://doc.deno.land/deno/stable/~/Deno.readFile), but it doesn't
support
[`ReadFileOptions`](https://doc.deno.land/deno/stable/~/Deno.ReadFileOptions)
for the time being. Support will be added in the future.

```ts
function Deno.readFile(path: string | URL): Promise<Uint8Array>
```

The path can be a relative or absolute. It can also be a `file:` URL.

### Example

This example reads the contents of a file into memory as a byte array, then
returns it as the response body.

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  // Let's read the README.md file available at the root
  // of the repository to explore the available methods.

  // Relative paths are relative to the root of the repository
  const readmeRelative = await Deno.readFile("./README.md");
  // Absolute paths.
  // The content of the repository is available under at Deno.cwd().
  const readmeAbsolute = await Deno.readFile(`${Deno.cwd()}/README.md`);
  // File URLs are also supported.
  const readmeFileUrl = await Deno.readFile(
    new URL(`file://${Deno.cwd()}/README.md`),
  );

  // Decode the Uint8Array as string.
  const readme = new TextDecoder().decode(readmeRelative);
  return new Response(readme);
}

serve(handler);
```

> Note: to use this feature, you must link a GitHub repository to your project.

Deno Deploy supports the `Deno.readFile` API to read static assets from the file
system. This is useful for serving static assets such as images, stylesheets,
and JavaScript files. This guide demonstrates how to use this feature.

Imagine the following file structure on a GitHub repository:

```
├── mod.ts
└── style.css
```

The contents of `mod.ts`:

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handleRequest(request: Request): Promise<Response> {
  const { pathname } = new URL(request.url);

  // This is how the server works:
  // 1. A request comes in for a specific asset.
  // 2. We read the asset from the file system.
  // 3. We send the asset back to the client.

  // Check if the request is for style.css.
  if (pathname.startsWith("/style.css")) {
    // Read the style.css file from the file system.
    const file = await Deno.readFile("./style.css");
    // Respond to the request with the style.css file.
    return new Response(file, {
      headers: {
        "content-type": "text/css",
      },
    });
  }

  return new Response(
    `<html>
      <head>
        <link rel="stylesheet" href="style.css" />
      </head>
      <body>
        <h1>Example</h1>
      </body>
    </html>`,
    {
      headers: {
        "content-type": "text/html; charset=utf-8",
      },
    },
  );
}

serve(handleRequest);
```

The path provided to the
[`Deno.readFile`](https://deno.land/api@v1.31.1?s=Deno.readFile) API is relative
to the root of the repository. You can also specify absolute paths, if they are
inside `Deno.cwd`.

## `Deno.readTextFile`

This function is similar to [Deno.readFile](#Deno.readFile) except it decodes
the file contents as a UTF-8 string.

```ts
function Deno.readTextFile(path: string | URL): Promise<string>
```

### Example

This example reads a text file into memory and returns the contents as the
response body.

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  const readme = await Deno.readTextFile("./README.md");
  event.respondWith(new Response(readme));
}

serve(handler);
```

## `Deno.open`

`Deno.open()` allows you to open a file, returning a file handle. This file
handle can then be used to read the contents of the file. See
[`Deno.File`](#denofile) for information on the methods available on the file
handle.

The function definition is similar to
[Deno](https://doc.deno.land/deno/stable/~/Deno.open), but it doesn't support
[`OpenOptions`](https://doc.deno.land/deno/stable/~/Deno.OpenOptions) for the
time being. Support will be added in the future.

```ts
function Deno.open(path: string | URL): Promise<Deno.File>
```

The path can be a relative or absolute. It can also be a `file:` URL.

### Example

This example opens a file, and then streams the content as the response body.

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";
import { readableStreamFromReader } from "https://deno.land/std@$STD_VERSION/streams/conversion.ts";

async function handler(_req) {
  // Open the README.md file available at the root of the repository.
  const file = await Deno.open("./README.md");

  // Turn the `Deno.File` into a `ReadableStream`. This will automatically close
  // the file handle when the response is done sending.
  const body = readableStreamFromReader(file);

  return new Response(body);
}

serve(handler);
```

## `Deno.File`

`Deno.File` is a file handle returned from [`Deno.open()`](#denoopen). It can be
used to read chunks of the file using the `read()` method. The file handle can
be closed using the `close()` method.

The interface is similar to
[Deno](https://doc.deno.land/deno/stable/~/Deno.File), but it doesn't support
writing to the file, or seeking. Support for the latter will be added in the
future.

```ts
class File {
  readonly rid: number;

  close(): void;
  read(p: Uint8Array): Promise<number | null>;
}
```

The path can be a relative or absolute. It can also be a `file:` URL.

### `Deno.File#read()`

The read method is used to read a chunk of the file. It should be passed a
buffer to read the data into. It returns the number of bytes read or `null` if
the end of the file has been reached.

```ts
function read(p: Uint8Array): Promise<number | null>;
```

### `Deno.File#close()`

The close method is used to close the file handle. Closing the handle will
interrupt all ongoing reads.

```ts
function close(): void;
```

## `Deno.stat`

`Deno.stat()` reads a file system entry's metadata. It returns a
[`Deno.FileInfo`](#fileinfo) object. Symlinks are followed.

The function definition is the same as
[Deno](https://doc.deno.land/deno/stable/~/Deno.stat). It does not return
modification time, access time, or creation time values.

```ts
function Deno.stat(path: string | URL): Promise<Deno.FileInfo>
```

The path can be a relative or absolute. It can also be a `file:` URL.

### Example

This example gets the size of a file, and returns the result as the response
body.

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  // Get file info of the README.md at the root of the repository.
  const info = await Deno.stat("./README.md");

  // Get the size of the file in bytes.
  const size = info.size;

  return new Response(`README.md is ${size} bytes large`);
}

serve(handler);
```

## `Deno.lstat`

`Deno.lstat()` is similar to `Deno.stat()`, but it does not follow symlinks.

The function definition is the same as
[Deno](https://doc.deno.land/deno/stable/~/Deno.lstat). It does not return
modification time, access time, or creation time values.

```ts
function Deno.lstat(path: string | URL): Promise<Deno.FileInfo>
```

The path can be a relative or absolute. It can also be a `file:` URL.

## `Deno.FileInfo`

The `Deno.FileInfo` interface is used to represent a file system entry's
metadata. It is returned by the [`Deno.stat()`](#denostat) and
[`Deno.lstat()`](#denolstat) functions. It can represent either a file, a
directory, or a symlink.

In Deno Deploy, only the file type, and size properties are available. The size
property behaves the same way it does on Linux.

```ts
interface FileInfo {
  isDirectory: boolean;
  isFile: boolean;
  isSymlink: boolean;
  size: number;
}
```

## `Deno.realPath`

`Deno.realPath()` returns the resolved absolute path to a file after following
symlinks.

The function definition is the same as
[Deno](https://doc.deno.land/deno/stable/~/Deno.realPath).

```ts
function Deno.realPath(path: string | URL): Promise<string>
```

The path can be a relative or absolute. It can also be a `file:` URL.

### Example

This example calls `Deno.realPath()` to get the absolute path of a file in the
root of the repository. The result is returned as the response body.

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  const path = await Deno.realPath("./README.md");

  return new Response(`The fully resolved path for ./README.md is ${path}`);
}

serve(handler);
```

## `Deno.readLink`

`Deno.readLink()` returns the target path for a symlink.

The function definition is the same as
[Deno](https://doc.deno.land/deno/stable/~/Deno.readLink).

```ts
function Deno.readLink(path: string | URL): Promise<string>
```

The path can be a relative or absolute. It can also be a `file:` URL.

### Example

This example calls `Deno.readLink()` to get the absolute path of a file in the
root of the repository. The result is returned as the response body.

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  const path = await Deno.readLink("./my_symlink");

  return new Response(`The target path for ./my_symlink is ${path}`);
}

serve(handler);
```



/. 🚀 deploy/api/runtime-headers.md
===================================================

# HTTP Headers

The [Headers](https://developer.mozilla.org/en-US/docs/Web/API/Headers)
interface is part of the Fetch API. It allows you create and manipulate the HTTP
headers of request and response resources of fetch().

- [Constructor](#constructor)
  - [Parameters](#parameters)
- [Methods](#methods)
- [Example](#example)

## Constructor

The Header() constructor creates a new `Header` instance.

```ts
let headers = new Headers(init);
```

#### Parameters

| name | type                                    | optional | description                                                                                             |
| ---- | --------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------- |
| init | `Headers` / `{ [key: string]: string }` | `true`   | The init option lets you initialize the headers object with an existing `Headers` or an object literal. |

The return type of the constructor is a `Headers` instance.

## Methods

| name                                  | description                                                       |
| ------------------------------------- | ----------------------------------------------------------------- |
| `append(name: string, value: string)` | Appends a header (overwrites existing one) to the Headers object. |
| `delete(name: string)`                | Deletes a header from the Headers object.                         |
| `set(name: string, value: string)`    | Create a new header in the Headers object.                        |
| `get(name: string)`                   | Get the value of the header in the Headers object.                |
| `has(name: string)`                   | Check if the header exists in the Headers objects.                |
| `entries()`                           | Get the headers as key-value pair. The result is iterable.        |
| `keys()`                              | Get all the keys of the Headers object. The result is iterable.   |

## Example

```ts
// Create a new headers object from an object literal.
const myHeaders = new Headers({
  accept: "application/json",
});

// Append a header to the headers object.
myHeaders.append("user-agent", "Deno Deploy");

// Print the headers of the headers object.
for (const [key, value] of myHeaders.entries()) {
  console.log(key, value);
}

// You can pass the headers instance to Response or Request constructors.
const request = new Request("https://api.github.com/users/denoland", {
  method: "POST",
  headers: myHeaders,
});
```



/. 🚀 deploy/api/runtime-node.md
===================================================

# Node.js built-in APIs

Deno Deploy natively supports importing built-in Node.js modules like `fs`,
`path`, and `http` through `node:` specifiers. This allows running code
originally written for Node.js without changes in Deno Deploy.

Here is an example of a Node.js HTTP server running on Deno Deploy:

```js
import { createServer } from "node:http";
import process from "node:process";

const server = createServer((req, res) => {
  const message = `Hello from ${process.env.DENO_REGION} at ${new Date()}`;
  res.end(message);
});

server.listen(8080);
```

_You can see this example live here:
https://dash.deno.com/playground/node-specifiers_

When using `node:` specifiers, all other features of Deno Deploy are still
available. For example, you can use `Deno.env` to access environment variables
even when using Node.js modules. You can also import other ESM modules from
external URLs as usual.

The following Node.js modules are available:

- `assert`
- `assert/strict`
- `async_hooks`
- `buffer`
- `child_process`
- `cluster`
- `console`
- `constants`
- `crypto`
- `dgram`
- `diagnostics_channel`
- `dns`
- `dns/promises`
- `domain`
- `events`
- `fs`
- `fs/promises`
- `http`
- `http2`
- `https`
- `module`
- `net`
- `os`
- `path`
- `path/posix`
- `path/win32`
- `perf_hooks`
- `process`
- `punycode`
- `querystring`
- `readline`
- `stream`
- `stream/consumers`
- `stream/promises`
- `stream/web`
- `string_decoder`
- `sys`
- `timers`
- `timers/promises`
- `tls`
- `tty`
- `url`
- `util`
- `util/types`
- `v8`
- `vm`
- `worker_threads`
- `zlib`

The behavior of these modules should be identical to Node.js in most cases. Due
to the sandboxing behaviour of Deno Deploy, some features are not available:

- Executing binaries with `child_process`
- Spawning workers using `worker_threads`
- Creating contexts and evaluating code with `vm`

> Note: the emulation of Node.js modules is sufficient for most use cases, but
> it is not yet perfect. If you encounter any issues, please
> [open an issue](https://github.com/denoland/deno).



/. 🚀 deploy/api/runtime-request.md
===================================================

# HTTP Request

The [Request](https://developer.mozilla.org/en-US/docs/Web/API/Request)
interface is part of the Fetch API and represents the request of fetch().

- [Constructor](#constructor)
  - [Parameters](#parameters)
- [Properties](#properties)
- [Methods](#methods)
- [Example](#example)

## Constructor

The Request() constructor creates a new Request instance.

```ts
let request = new Request(input, init);
```

#### Parameters

| name     | type                          | optional | description                                                               |
| -------- | ----------------------------- | -------- | ------------------------------------------------------------------------- |
| resource | `Request` or `USVString`      | `false`  | The resource can either be a request object or a URL string.              |
| init     | [`RequestInit`](#requestinit) | `true`   | The init object lets you set optional parameters to apply to the request. |

The return type is a `Request` instance.

##### `RequestInit`

| name                         | type                                                                                    | default        | description                                                |
| ---------------------------- | --------------------------------------------------------------------------------------- | -------------- | ---------------------------------------------------------- |
| [`method`][method]           | `string`                                                                                | `GET`          | The method of the request.                                 |
| [`headers`][headers]         | `Headers` or `{ [key: string]: string }`                                                | none           | Th Headers for the request.                                |
| [`body`][body]               | `Blob`, `BufferSource`, `FormData`, `URLSearchParams`, `USVString`, or `ReadableStream` | none           | The body of the request.                                   |
| [`cache`][cache]             | `string`                                                                                | none           | The cache mode of the request.                             |
| [`credentials`][credentials] | `string`                                                                                | `same-origin`  | The credentials mode of the request.                       |
| [`integrity`][integrity]     | `string`                                                                                | none           | The crypotographic hash of the request's body.             |
| [`mode`][mode]               | `string`                                                                                | `cors`         | The request mode you want to use.                          |
| [`redirect`][redirect]       | `string`                                                                                | `follow`       | The mode of how redirects are handled.                     |
| [`referrer`][referrer]       | `string`                                                                                | `about:client` | A `USVString` specifying `no-referrer`, `client` or a URL. |

## Properties

| name                               | type                                       | description                                                                                                                  |
| ---------------------------------- | ------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------- |
| [`cache`][cache]                   | `string`                                   | The cache mode indicates how the (`default`, `no-cache`, etc) request should be cached by browser.                           |
| [`credentials`][credentials]       | `string`                                   | The credentials (`omit`, `same-origin`, etc) indicate whether user agent should send cookies in case of CORs of the request. |
| [`destination`][destination]       | [`RequestDestination`][requestdestination] | The string indicates the type of content being requested.                                                                    |
| [`body`][body]                     | [`ReadableStream`][readablestream]         | The getter exposes a `ReadableStream` of the body contents.                                                                  |
| [`bodyUsed`][bodyused]             | `boolean`                                  | Indicates whether the body content is read.                                                                                  |
| [`url`][url]                       | `USVString`                                | The URL of the request.                                                                                                      |
| [`headers`][headers]               | [`Headers`](runtime-headers)               | The headers associated with the request.                                                                                     |
| [`integrity`][integrity]           | `string`                                   | The crypotographic hash of the request's body.                                                                               |
| [`method`][method]                 | `string`                                   | The request's method (`POST`, `GET`, etc).                                                                                   |
| [`mode`][mode]                     | `string`                                   | Indicates the mode of the request (e.g. `cors` ).                                                                            |
| [`redirect`][redirect]             | `string`                                   | The mode of how redirects are handled.                                                                                       |
| [`referrer`][referrer]             | `string`                                   | The referrer of the request.                                                                                                 |
| [`referrerPolicy`][referrerpolicy] | `string`                                   | The referrer policy of the request                                                                                           |

All the above properties are read only.

## Methods

| name                           | description                                                                                 |
| ------------------------------ | ------------------------------------------------------------------------------------------- |
| [`arrayBuffer()`][arraybuffer] | Reads the body stream to its completion and returns an `ArrayBuffer` object.                |
| [`blob()`][blob]               | Reads the body stream to its completion and returns a `Blob` object.                        |
| [`formData()`][formdata]       | Reads the body stream to its completion and returns a `FormData` object.                    |
| [`json()`][json]               | Reads the body stream to its completion, parses it as JSON and returns a JavaScript object. |
| [`text()`][text]               | Reads the body stream to its completion and returns a USVString object (text).              |
| [`clone()`][clone]             | Clones the Request object.                                                                  |

## Example

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

function handler(_req) {
  // Create a post request
  const request = new Request("https://post.deno.dev", {
    method: "POST",
    body: JSON.stringify({
      message: "Hello world!",
    }),
    headers: {
      "content-type": "application/json",
    },
  });

  console.log(request.method); // POST
  console.log(request.headers.get("content-type")); // application/json

  return fetch(request);
}

serve(handler);
```

[cache]: https://developer.mozilla.org/en-US/docs/Web/API/Request/cache
[credentials]: https://developer.mozilla.org/en-US/docs/Web/API/Request/credentials
[destination]: https://developer.mozilla.org/en-us/docs/web/api/request/destination
[requestdestination]: https://developer.mozilla.org/en-US/docs/Web/API/RequestDestination
[body]: https://developer.mozilla.org/en-US/docs/Web/API/Body/body
[bodyused]: https://developer.mozilla.org/en-US/docs/Web/API/Body/bodyUsed
[url]: https://developer.mozilla.org/en-US/docs/Web/API/Request/url
[headers]: https://developer.mozilla.org/en-US/docs/Web/API/Request/headers
[method]: https://developer.mozilla.org/en-US/docs/Web/API/Request/method
[integrity]: https://developer.mozilla.org/en-US/docs/Web/API/Request/integrity
[mode]: https://developer.mozilla.org/en-US/docs/Web/API/Request/mode
[redirect]: https://developer.mozilla.org/en-US/docs/Web/API/Request/redirect
[referrer]: https://developer.mozilla.org/en-US/docs/Web/API/Request/referrer
[referrerpolicy]: https://developer.mozilla.org/en-US/docs/Web/API/Request/referrerpolicy
[readablestream]: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream
[arraybuffer]: https://developer.mozilla.org/en-US/docs/Web/API/Body/arrayBuffer
[blob]: https://developer.mozilla.org/en-US/docs/Web/API/Body/blob
[json]: https://developer.mozilla.org/en-US/docs/Web/API/Body/json
[text]: https://developer.mozilla.org/en-US/docs/Web/API/Body/text
[formdata]: https://developer.mozilla.org/en-US/docs/Web/API/Body/formdata
[clone]: https://developer.mozilla.org/en-US/docs/Web/API/Request/clone



/. 🚀 deploy/api/runtime-response.md
===================================================

# HTTP Response

The [Response](https://developer.mozilla.org/en-US/docs/Web/API/Response)
interface is part of the Fetch API and represents a response resource of
fetch().

- [Constructor](#constructor)
  - [Parameters](#parameters)
- [Properties](#properties)
- [Methods](#methods)
- [Example](#example)

## Constructor

The Response() constructor creates a new Response instance.

```ts
let response = new Response(body, init);
```

#### Parameters

| name | type                                                                                    | optional | description                                                                |
| ---- | --------------------------------------------------------------------------------------- | -------- | -------------------------------------------------------------------------- |
| body | `Blob`, `BufferSource`, `FormData`, `ReadableStream`, `URLSearchParams`, or `USVString` | `true`   | The body of the response. The default value is `null`.                     |
| init | `ResponseInit`                                                                          | `true`   | An optional object that allows setting status and headers of the response. |

The return type is a `Response` instance.

##### `ResponseInit`

| name         | type                                                  | optional | description                                           |
| ------------ | ----------------------------------------------------- | -------- | ----------------------------------------------------- |
| `status`     | `number`                                              | `true`   | The status code of the response.                      |
| `statusText` | `string`                                              | `true`   | The status message representative of the status code. |
| `headers`    | `Headers` or `string[][]` or `Record<string, string>` | `false`  | The HTTP headers of the response.                     |

## Properties

| name                       | type             | read only | description                                                 |
| -------------------------- | ---------------- | --------- | ----------------------------------------------------------- |
| [`body`][body]             | `ReadableStream` | `true`    | The getter exposes a `ReadableStream` of the body contents. |
| [`bodyUsed`][bodyused]     | `boolean`        | `true`    | Indicates whether the body content is read.                 |
| [`url`][url]               | `USVString`      | `true`    | The URL of the response.                                    |
| [`headers`][headers]       | `Headers`        | `true`    | The headers associated with the response.                   |
| [`ok`][ok]                 | `boolean`        | `true`    | Indicates if the response is successful (200-299 status).   |
| [`redirected`][redirected] | `boolean`        | `true`    | Indicates if the response is the result of a redirect.      |
| [`status`][status]         | `number`         | `true`    | The status code of the response                             |
| [`statusText`][statustext] | `string`         | `true`    | The status message of the response                          |
| [`type`][type]             | `string`         | `true`    | The type of the response.                                   |

## Methods

| name                                                 | description                                                                                 |
| ---------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| [`arrayBuffer()`][arraybuffer]                       | Reads the body stream to its completion and returns an `ArrayBuffer` object.                |
| [`blob()`][blob]                                     | Reads the body stream to its completion and returns a `Blob` object.                        |
| [`formData()`][formdata]                             | Reads the body stream to its completion and returns a `FormData` object.                    |
| [`json()`][json]                                     | Reads the body stream to its completion, parses it as JSON and returns a JavaScript object. |
| [`text()`][text]                                     | Reads the body stream to its completion and returns a USVString object (text).              |
| [`clone()`][clone]                                   | Clones the response object.                                                                 |
| [`error()`][error]                                   | Returns a new response object associated with a network error.                              |
| [`redirect(url: string, status?: number)`][redirect] | Creates a new response that redirects to the provided URL.                                  |

## Example

```ts
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

function handler(_req) {
  // Create a response with html as its body.
  const response = new Response("<html> Hello </html>", {
    status: 200,
    headers: {
      "content-type": "text/html",
    },
  });

  console.log(response.status); // 200
  console.log(response.headers.get("content-type")); // text/html

  return response;
}

serve(handler);
```

[clone]: https://developer.mozilla.org/en-US/docs/Web/API/Response/clone
[error]: https://developer.mozilla.org/en-US/docs/Web/API/Response/error
[redirect]: https://developer.mozilla.org/en-US/docs/Web/API/Response/redirect
[body]: https://developer.mozilla.org/en-US/docs/Web/API/Body/body
[bodyused]: https://developer.mozilla.org/en-US/docs/Web/API/Body/bodyUsed
[url]: https://developer.mozilla.org/en-US/docs/Web/API/Request/url
[headers]: https://developer.mozilla.org/en-US/docs/Web/API/Request/headers
[ok]: https://developer.mozilla.org/en-US/docs/Web/API/Response/ok
[redirected]: https://developer.mozilla.org/en-US/docs/Web/API/Response/redirected
[status]: https://developer.mozilla.org/en-US/docs/Web/API/Response/status
[statustext]: https://developer.mozilla.org/en-US/docs/Web/API/Response/statusText
[type]: https://developer.mozilla.org/en-US/docs/Web/API/Response/type
[method]: https://developer.mozilla.org/en-US/docs/Web/API/Request/method
[readablestream]: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream
[arraybuffer]: https://developer.mozilla.org/en-US/docs/Web/API/Body/arrayBuffer
[blob]: https://developer.mozilla.org/en-US/docs/Web/API/Body/blob
[json]: https://developer.mozilla.org/en-US/docs/Web/API/Body/json
[text]: https://developer.mozilla.org/en-US/docs/Web/API/Body/text
[formdata]: https://developer.mozilla.org/en-US/docs/Web/API/Body/formdata



/. 🚀 deploy/api/runtime-sockets.md
===================================================

# TCP sockets and TLS

Deno Deploy supports outbound TCP and TLS connections. These APIs allow you to
use databases like PostgreSQL, SQLite, MongoDB, etc., with Deploy.

## `Deno.connect`

Make outbound TCP connections.

The function definition is same as
[Deno](https://doc.deno.land/deno/stable/~/Deno.connect) with the limitation
that `transport` option can only be `tcp` and `hostname` cannot be localhost or
empty.

```ts
function Deno.connect(options: ConnectOptions): Promise<Conn>
```

### Example

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  // Make a TCP connection to example.com
  const connection = await Deno.connect({
    port: 80,
    hostname: "example.com",
  });

  // Send raw HTTP GET request.
  const request = new TextEncoder().encode(
    "GET / HTTP/1.1\nHost: example.com\r\n\r\n",
  );
  const _bytesWritten = await connection.write(request);

  // Read 15 bytes from the connection.
  const buffer = new Uint8Array(15);
  await connection.read(buffer);
  connection.close();

  // Return the bytes as plain text.
  return new Response(buffer, {
    headers: {
      "content-type": "text/plain;charset=utf-8",
    },
  });
}

serve(handler);
```

## `Deno.connectTls`

Make outbound TLS connections.

The function definition is the same as
[Deno](https://doc.deno.land/deno/stable/~/Deno.connectTls) with the limitation
that hostname cannot be localhost or empty.

```ts
function Deno.connectTls(options: ConnectTlsOptions): Promise<Conn>
```

### Example

```js
import { serve } from "https://deno.land/std@$STD_VERSION/http/server.ts";

async function handler(_req) {
  // Make a TLS connection to example.com
  const connection = await Deno.connectTls({
    port: 443,
    hostname: "example.com",
  });

  // Send raw HTTP GET request.
  const request = new TextEncoder().encode(
    "GET / HTTP/1.1\nHost: example.com\r\n\r\n",
  );
  const _bytesWritten = await connection.write(request);

  // Read 15 bytes from the connection.
  const buffer = new Uint8Array(15);
  await connection.read(buffer);
  connection.close();

  // Return the bytes as plain text.
  return new Response(buffer, {
    headers: {
      "content-type": "text/plain;charset=utf-8",
    },
  });
}

serve(handler);
```



/. 🚀 kv/index.md
===================================================

# Deno KV

_This URL redirected in production to [/kv/manual](/kv/manual)._

* https://docs.deno.com/kv/manual
* https://docs.deno.com/kv/tutorials


/. 🚀 kv/manual/_admonition.mdx
===================================================

:::caution Deno KV is currently in beta

Deno KV is currently **experimental** and **subject to change**. While we do our
best to ensure data durability, data loss is possible, especially around Deno
updates.

Executing Deno programs that use KV currently requires the `--unstable` flag, as
below:

```sh
deno run -A --unstable my_kv_code.ts
```

:::


/. 🚀 kv/manual/index.mdx
===================================================

* https://docs.deno.com/kv/tutorials
* https://docs.deno.com/kv/manual

import Admonition from "./_admonition.mdx";

# Deno KV Quick Start

**Deno KV** is a
[key-value database](https://en.wikipedia.org/wiki/Key%E2%80%93value_database)
built directly into the Deno runtime, available in the
[`Deno.Kv` namespace](https://deno.land/api?unstable&s=Deno.Kv). It can be used
for many kinds of data storage use cases, but excels at storing simple data
structures that benefit from very fast reads and writes. Deno KV is available in
the Deno CLI and on [Deno Deploy](./on_deploy.mdx).

<Admonition />

Let's walk through the key features of Deno KV.

## Opening a database

In your Deno program, you can get a reference to a KV database using
[`Deno.openKv()`](https://deno.land/api?unstable=&s=Deno.openKv). You may pass
in an optional file system path to where you'd like to store your database,
otherwise one will be created for you based on the current working directory of
your script.

```ts
const kv = await Deno.openKv();
```

## Creating, updating, and reading a key-value pair

Data in Deno KV is stored as key-value pairs, much like properties of a
JavaScript object literal or a
[Map](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map).
[Keys](./key_space.mdx) are represented as an array of JavaScript types, like
`string`, `number`, `bigint`, or `boolean`. Values can be arbitrary JavaScript
objects. In this example, we create a key-value pair representing a user's UI
preferences, and save it with
[`kv.set()`](https://deno.land/api?s=Deno.Kv&unstable=&p=prototype.set).

```ts
const kv = await Deno.openKv();

const prefs = {
  username: "ada",
  theme: "dark",
  language: "en-US",
};

const result = await kv.set(["preferences", "ada"], prefs);
```

Once a key-value pair is set, you can read it from the database with
[`kv.get()`](https://deno.land/api?s=Deno.Kv&unstable=&p=prototype.get):

```ts
const entry = await kv.get(["preferences", "ada"]);
console.log(entry.key);
console.log(entry.value);
console.log(entry.versionstamp);
```

Both `get` and `list` [operations](./operations.mdx) return a
[KvEntry](https://deno.land/api?s=Deno.KvEntry&unstable=) object with the
following properties:

- `key` - the array key you used to set the value
- `value` - the JavaScript object you set for this key
- `versionstamp` - a generated value used to determine if a key has been
  updated.

The `set` operation is also used to update objects that already exist for a
given key. When a key's value is updated, its `versionstamp` will change to a
new generated value.

## Listing several key-value pairs

To get values for a finite number of keys, you may use
[`kv.getMany()`](https://deno.land/api?s=Deno.Kv&unstable=&p=prototype.getMany).
Pass in several keys as arguments, and you'll receive an array of values for
each key. Note that **values and versionstamps can be `null`** if no value
exists for the given key(s).

```ts
const kv = await Deno.openKv();
const result = await kv.getMany([
  ["preferences", "ada"],
  ["preferences", "grace"],
]);
result[0].key; // ["preferences", "ada"]
result[0].value; // { ... }
result[0].versionstamp; // "00000000000000010000"
result[1].key; // ["preferences", "grace"]
result[1].value; // null
result[1].versionstamp; // null
```

Often, it is useful to retrieve a list of key-value pairs from all keys that
share a given prefix. This type of operation is possible using
[`kv.list()`](https://deno.land/api?s=Deno.Kv&unstable=&p=prototype.list). In
this example, we get a list of key-value pairs that share the `"preferences"`
prefix.

```ts
const kv = await Deno.openKv();
const entries = kv.list({ prefix: ["preferences"] });
for await (const entry of entries) {
  console.log(entry.key); // ["preferences", "ada"]
  console.log(entry.value); // { ... }
  console.log(entry.versionstamp); // "00000000000000010000"
}
```

Returned keys are ordered lexicographically based on the next component of the
key after the prefix. So KV pairs with these keys:

- `["preferences", "ada"]`
- `["preferences", "bob"]`
- `["preferences", "cassie"]`

Will be returned in that order by `kv.list()`.

Read operations can either be performed in
[**strong or eventual consistency mode**](./operations.mdx). Strong consistency
mode guarantees that the read operation will return the most recently written
value. Eventual consistency mode may return a stale value, but is faster. By
contrast, writes are always performed in strong consistency mode.

## Deleting key-value pairs

You can delete a key from the database using
[`kv.delete()`](https://deno.land/api?s=Deno.Kv&unstable=&p=prototype.delete).
No action is taken if no value is found for the given key.

```ts
const kv = await Deno.openKv();
await kv.delete(["preferences", "alan"]);
```

## Atomic transactions

Deno KV is capable of executing [atomic transactions](./transactions.mdx), which
enables you to conditionally execute one or many data manipulation operations at
once. In the following example, we create a new preferences object only if it
hasn't been created already.

```ts
const kv = await Deno.openKv();

const key = ["preferences", "alan"];
const value = {
  username: "alan",
  theme: "light",
  language: "en-GB",
};

const res = await kv.atomic()
  .check({ key, versionstamp: null }) // `null` versionstamps mean 'no value'
  .set(key, value)
  .commit();
if (res.ok) {
  console.log("Preferences did not yet exist. Inserted!");
} else {
  console.error("Preferences already exist.");
}
```

Learn more about transactions in Deno KV [here](./transactions.mdx).

## Improve querying with secondary indexes

[Secondary indexes](./secondary_indexes.mdx) store the same data by multiple
keys, allowing for simpler quries of the data you need. Let's say that we need
to be able to access user preferences by both username AND email. To enable
this, you could provide a function that wraps the logic to save the preferences
to create two indexes.

```ts
const kv = await Deno.openKv();

async function savePreferences(prefs) {
  const key = ["preferences", prefs.username];

  // Set the primary key
  const r = await kv.set(key, prefs);

  // Set the secondary key's value to be the primary key
  await kv.set(["preferencesByEmail", prefs.email], key);

  return r;
}

async function getByUsername(username) {
  // Use as before...
  const r = await kv.get(["preferences", username]);
  return r;
}

async function getByEmail(email) {
  // Look up the key by email, then second lookup for actual data
  const r1 = await kv.get(["preferencesByEmail", email]);
  const r2 = await kv.get(r1.value);
  return r2;
}
```

Learn more about [secondary indexes in the manual here](./secondary_indexes.mdx).

## Production usage

Deno KV is available for use in live applications on
[Deno Deploy](./on_deploy.mdx). In production, Deno KV is backed by
[FoundationDB](https://www.foundationdb.org/), the open source key-value store
created by Apple.

**No additional configuration is necessary** to run your Deno programs that use
KV on Deploy - a new Deploy database will be provisioned for you when required
by your code. Learn more about Deno KV on Deno Deploy [here](./on_deploy.mdx).

## Next steps

At this point, you're just beginning to scratch the surface with Deno KV. Be
sure to check out our guide on the [Deno KV key space](./key_space.mdx), and a
collection of [tutorials and example applications](../tutorials/index.md) here.



/. 🚀 kv/tutorials/index.md
===================================================

* https://docs.deno.com/kv/tutorials
* https://docs.deno.com/kv/manual

# Deno KV Tutorials & Examples

Check out these examples showing real-world usage of Deno KV.

## Use queues to process incoming webhooks

Follow [this tutorial](./webhook_processor.md) to learn how to use queues to
offload tasks to a background process, so your web app can remain responsive.
This example shows how to enqueue tasks that handle incoming webhook requests
from [GitHub](https://www.github.com).

## Use queues to schedule a future notification

Follow [this tutorial](./schedule_notification.md) to learn how to schedule code
to execute at some time in the future using queues. This example shows how to
schedule a notification with [Courier](https://www.courier.com/).

## CRUD in Deno KV - TODO List

- Zod schema validation
- Built using Fresh
- Real-time collaboration using BroadcastChannel
- [Source code](https://github.com/denoland/showcase_todo)
- [Live preview](https://showcase-todo.deno.dev/)

## Deno SaaSKit

- Modern SaaS template built on Fresh.
- [Product Hunt](https://www.producthunt.com/)-like template entirely built on
  KV.
- Uses Deno KV OAuth for GitHub OAuth 2.0 authentication
- Use to launch your next app project faster
- [Source code](https://github.com/denoland/saaskit)
- [Live preview](https://hunt.deno.land/)

## Multi-player Tic-Tac-Toe

- GitHub authentication
- Saved user state
- Real-time sync using BroadcastChannel
- [Source code](https://github.com/denoland/tic-tac-toe)
- [Live preview](https://tic-tac-toe-game.deno.dev/)

## Multi-user pixel art drawing

- Persistent canvas state
- Multi-user collaboration
- Real-time sync using BroadcastChannel
- [Source code](https://github.com/denoland/pixelpage)
- [Live preview](https://pixelpage.deno.dev/)

## GitHub authentication and KV

- Stores drawings in KV
- GitHub authentication
- [Source code](https://github.com/hashrock/kv-sketchbook)
- [Live preview](https://hashrock-kv-sketchbook.deno.dev/)

## Deno KV oAuth 2

- High-level OAuth 2.0 powered by Deno KV
- [Source code](https://github.com/denoland/deno_kv_oauth)
- [Live preview](https://kv-oauth.deno.dev/)



/. 🚀 kv/tutorials/schedule_notification.md
===================================================

# Schedule a notification for a future date

A common use case for [queues](../manual/queue_overview.md) is scheduling work
to be completed at some point in the future. To help demonstrate how this works,
we've provided a sample application (described below) that schedules
notification messages sent through the [Courier API](https://www.courier.com/).
The application runs on [Deno Deploy](https://www.deno.com/deploy), using the
built-in KV and queue API implementations available there with zero
configuration.

## Download and configure the sample

⬇️
[**Download or clone the complete sample app here**](https://github.com/kwhinnery/deno_courier_example).

You can run and deploy this sample application yourself using the instructions
in the GitHub repo's
[`README` file](https://github.com/kwhinnery/deno_courier_example).

To run the example app above, you'll also need to
[sign up for Courier](https://app.courier.com/signup). Of course the techniques
you'll see in the application would just as easily apply to any notification
service, from [Amazon SNS](https://aws.amazon.com/sns/) to
[Twilio](https://www.twilio.com), but Courier provides an easy-to-use
notification API that you can use with a personal GMail account for testing (in
addition to all the other neat things it can do).

## Key functionality

After setting up and running the project, we'd like to direct your attention to
a few key parts of the code that implement the scheduling mechanics.

### Connecting to KV and adding a listener on app start

Most of the example app's functionality lives in
[server.tsx](https://github.com/kwhinnery/deno_courier_example/blob/main/server.tsx)
in the top-level directory. When the Deno app process starts, it creates a
connection to a Deno KV instance and attaches an event handler which will
process messages as they are received from the queue.

```ts title="server.tsx"
// Create a Deno KV database reference
const kv = await Deno.openKv();

// Create a queue listener that will process enqueued messages
kv.listenQueue(async (message) => {
  /* ... implementation of listener here ... */
});
```

### Creating and scheduling a notification

After a new order is submitted through the form in this demo application, the
`enqueue` function is called with a delay of five seconds before a notification
email is sent out.

```ts title="server.tsx"
app.post("/order", async (c) => {
  const { email, order } = await c.req.parseBody();
  const n: Notification = {
    email: email as string,
    body: `Order received for: "${order as string}"`,
  };

  // Select a time in the future - for now, just wait 5 seconds
  const delay = 1000 * 5;

  // Enqueue the message for processing!
  kv.enqueue(n, { delay });

  // Redirect back home with a success message!
  setCookie(c, "flash_message", "Order created!");
  return c.redirect("/");
});
```

### Defining the notification data type in TypeScript

Often, it is desirable to work with strongly typed objects when pushing data
into or out of the queue. While queue messages are an
[`unknown`](https://www.typescriptlang.org/docs/handbook/2/functions.html#unknown)
TypeScript type initially, we can use
[type guards](https://www.typescriptlang.org/docs/handbook/2/narrowing.html) to
tell the compiler the shape of the data we expect.

Here's the source code for the
[notification module](https://github.com/kwhinnery/deno_courier_example/blob/main/notification.ts),
which we use to describe the properties of a notification in our system.

```ts title="notification.ts"
// Shape of a notification object
export default interface Notification {
  email: string;
  body: string;
}

// Type guard for a notification object
export function isNotification(o: unknown): o is Notification {
  return (
    ((o as Notification)?.email !== undefined &&
      typeof (o as Notification).email === "string") &&
    ((o as Notification)?.body !== undefined &&
      typeof (o as Notification).body === "string")
  );
}
```

In `server.tsx`, we use the exported type guard to ensure we are responding to
the right message types.

```ts title="server.tsx"
kv.listenQueue(async (message) => {
  // Use type guard to short circuit early if the message is of the wrong type
  if (!isNotification(message)) return;

  // Grab the relevant data from the message, which TypeScript now knows
  // is a Notification interface
  const { email, body } = message;

  // Create an email notification with Courier
  // ...
});
```

### Sending a Courier API request

To send an email as scheduled, we use the Courier REST API. More information
about the Courier REST API can be found in
[their reference docs](https://www.courier.com/docs/reference/send/message/).

```ts title="server.tsx"
const response = await fetch("https://api.courier.com/send", {
  method: "POST",
  headers: {
    Authorization: `Bearer ${COURIER_API_TOKEN}`,
  },
  body: JSON.stringify({
    message: {
      to: { email },
      content: {
        title: "New order placed by Deno!",
        body: "notification body goes here",
      },
    },
  }),
});
```



/. 🚀 kv/tutorials/webhook_processor.md
===================================================

    curl -s -L https://docs.deno.com/kv/tutorials/webhook_processor | sed -n 's/<img/\n/gp' | sed -n 's|.*src="\([^"]\+\)".*|https://docs.deno.com\1|; s/image/\0/p'

# Offload webhook processing to a queue

In a web application, it is often desirable to offload processing of async tasks
for which a client doesn't need an immediate response to a queue. Doing so can
keep your web app fast and responsive, instead of taking up valuable resources
waiting for long-running processes to complete.

One instance where you might want to deploy this technique is when
[handling webhooks](https://en.wikipedia.org/wiki/Webhook). Immediately upon
receiving the webhook request from a non-human client that doesn't need a
response, you can offload that work to a queue where it can be handled more
efficiently.

In this tutorial, we'll show you how to execute this technique when
[handling webhook requests for a GitHub repo](https://docs.github.com/en/webhooks/about-webhooks-for-repositories).

## Try in a playground

✏️
[**Check out the this playground, which implements a GitHub repo webhook handler**](https://dash.deno.com/playground/github-webhook-example).

Using Deno Deploy [playgrounds](/deploy/manual/playgrounds), you can instantly
deploy your own GitHub webhook handler that uses both queues and Deno KV. We'll
walk through what this code does in a moment.

## Configuring GitHub webhooks for a repository

To try out the webhook you just launched in a playground, set up a new webhook
configuration for a GitHub repository you control. You can find webhook
configuration under "Settings" for your repository.

![configure a github webhook](https://docs.deno.com/assets/images/github_webhook-1cb9bf1ac45df20570c527d70a841bb3.png)
<!-- ![configure a github webhook](./images/github_webhook.png) -->

## Code walkthrough

Our webhook handler function is relatively simple - without comments, it's only
23 lines of code total. It connects to a Deno KV database, sets up a queue
listener to process incoming messages, and sets up a simple server with
[`Deno.serve`](https://deno.land/api?s=Deno.serve) which responds to incoming
webhook requests.

Read along with the comments below to see what's happening at each step.

```ts title="server.ts"
// Get a handle for a Deno KV database instance. KV is built in to the Deno
// runtime, and is available with zero config both locally and on Deno Deploy
const kv = await Deno.openKv();

// Set up a listener that will handle work that is offloaded from our server.
// In this case, it's just going to add incoming webhook payloads to a KV
// database, with a timestamp.
kv.listenQueue(async (message) => {
  await kv.set(["github", Date.now()], message);
});

// This is a simple HTTP server that will handle incoming POST requests from
// GitHub webhooks.
Deno.serve(async (req: Request) => {
  if (req.method === "POST") {
    // GitHub sends webhook requests as POST requests to your server. You can
    // configure GitHub to send JSON in the POST body, which you can then parse
    // from the request object.
    const payload = await req.json();
    await kv.enqueue(payload);
    return new Response("", { status: 200 });
  } else {
    // If the server is handling a GET request, this will just list out all the
    // webhook events that have been recorded in our KV database.
    const iter = kv.list<string>({ prefix: ["github"] });
    const github = [];
    for await (const res of iter) {
      github.push({
        timestamp: res.key[1],
        payload: res.value,
      });
    }
    return new Response(JSON.stringify(github, null, 2));
  }
});
```



/. 🚀 kv/manual/key_space.mdx
===================================================

import Admonition from "./_admonition.mdx";

# Key Space

<Admonition />

Deno KV is a key value store. The key space is a flat namespace of
key+value+versionstamp pairs. Keys are sequences of key parts, which allow
modeling of hierarchical data. Values are arbitrary JavaScript objects.
Versionstamps represent when a value was inserted / modified.

## Keys

Keys in Deno KV are sequences of key parts, which can be `string`s, `number`s,
`boolean`s, `Uint8Array`s, or `bigint`s.

Using a sequence of parts, rather than a single string eliminates the
possibility of delimiter injection attacks, because there is no visible
delimiter.

> A key injection attack occurs when an attacker manipulates the structure of a
> key-value store by injecting delimiters used in the key encoding scheme into a
> user controlled variable, leading to unintended behavior or unauthorized
> access. For example, consider a key-value store using a slash (/) as a
> delimiter, with keys like "user/alice/settings" and "user/bob/settings". An
> attacker could create a new user with the name "alice/settings/hacked" to form
> the key "user/alice/settings/hacked/settings", injecting the delimiter and
> manipulating the key structure. In Deno KV, the injection would result in the
> key `["user", "alice/settings/hacked", "settings"]`, which is not harmful.

Between key parts, invisible delimiters are used to separate the parts. These
delimiters are never visible, but ensure that one part can not be confused with
another part. For example, the key parts `["abc", "def"]`, `["ab", "cdef"]`,
`["abc", "", "def"]` are all different keys.

Keys are case sensitive and are ordered lexicographically by their parts. The
first part is the most significant, and the last part is the least significant.
The order of the parts is determined by both the type and the value of the part.

### Key Part Ordering

Key parts are ordered lexicographically by their type, and within a given type,
they are ordered by their value. The ordering of types is as follows:

1. `Uint8Array`
1. `string`
1. `number`
1. `bigint`
1. `boolean`

Within a given type, the ordering is:

- `Uint8Array`: byte ordering of the array
- `string`: byte ordering of the UTF-8 encoding of the string
- `number`: -Infinity < -1.0 < -0.5 < -0.0 < 0.0 < 0.5 < 1.0 < Infinity <
  NaN
- `bigint`: mathematical ordering, largest negative number first, largest
  positive number last
- `boolean`: false < true

This means that the part `1.0` (a number) is ordered before the part `2.0` (also
a number), but is greater than the part `0n` (a bigint), because `1.0` is a
number and `0n` is a bigint, and type ordering has precedence over the ordering
of values within a type.

### Key Examples

```js
["users", 42, "profile"]; // User with ID 42's profile
["posts", "2023-04-23", "comments"]; // Comments for all posts on 2023-04-23
["products", "electronics", "smartphones", "apple"]; // Apple smartphones in the electronics category
["orders", 1001, "shipping", "tracking"]; // Tracking information for order ID 1001
["files", new Uint8Array([1, 2, 3]), "metadata"]; // Metadata for a file with Uint8Array identifier
["projects", "openai", "tasks", 5]; // Task with ID 5 in the OpenAI project
["events", "2023-03-31", "location", "san_francisco"]; // Events in San Francisco on 2023-03-31
["invoices", 2023, "Q1", "summary"]; // Summary of Q1 invoices for 2023
["teams", "engineering", "members", 1n]; // Member with ID 1n in the engineering team
```

### Universally Unique Lexicographically Sortable Identifiers (ULIDs)

Key part ordering allows keys consisting of timestamps and ID parts to be listed
chronologically. Typically, you can generate a key using the following:
[`Date.now()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/now)
and
[`crypto.randomUUID()`](https://developer.mozilla.org/en-US/docs/Web/API/Crypto/randomUUID):

```js
async function setUser(user) {
  await kv.set(["users", Date.now(), crypto.randomUUID()], user);
}
```

Run multiple times sequentially, this produces the following keys:

```js
["users", 1691377037923, "8c72fa25-40ad-42ce-80b0-44f79bc7a09e"]; // First user
["users", 1691377037924, "8063f20c-8c2e-425e-a5ab-d61e7a717765"]; // Second user
["users", 1691377037925, "35310cea-58ba-4101-b09a-86232bf230b2"]; // Third user
```

However, having the timestamp and ID represented within a single key part may be
more straightforward in some cases. You can use a
[Universally Unique Lexicographically Sortable Identifier (ULID)](https://github.com/ulid/spec)
to do this. This type of identifier encodes a UTC timestamp, is
lexicographically sortable and is cryptographically random by default:

```js
import { ulid } from "https://deno.land/x/ulid/mod.ts";

const kv = await Deno.openKv();

async function setUser(user) {
  await kv.set(["users", ulid()], user);
}
```

```js
["users", "01H76YTWK3YBV020S6MP69TBEQ"]; // First user
["users", "01H76YTWK4V82VFET9YTYDQ0NY"]; // Second user
["users", "01H76YTWK5DM1G9TFR0Y5SCZQV"]; // Third user
```

Furthermore, you can generate ULIDs monotonically increasingly using a factory
function:

```js
import { monotonicFactory } from "https://deno.land/x/ulid/mod.ts";

const ulid = monotonicFactory();

async function setUser(user) {
  await kv.set(["users", ulid()], user);
}
```

```js
// Strict ordering for the same timestamp by incrementing the least-significant random bit by 1
["users", "01H76YTWK3YBV020S6MP69TBEQ"]; // First user
["users", "01H76YTWK3YBV020S6MP69TBER"]; // Second user
["users", "01H76YTWK3YBV020S6MP69TBES"]; // Third user
```

## Values

Values in Deno KV can be arbitrary JavaScript values that are compatible with
the [structured clone algorithm][structured clone algorithm]. This includes:

- `undefined`
- `null`
- `boolean`
- `number`
- `string`
- `bigint`
- `Uint8Array`
- `Array`
- `Object`
- `Map`
- `Set`
- `Date`
- `RegExp`

Objects and arrays can contain any of the above types, including other objects
and arrays. `Map`s and `Set`s can contain any of the above types, including
other `Map`s and `Set`s.

Circular references within values are supported.

Objects with a non-primitive prototype are not supported (such as class
instances or Web API objects). Functions and symbols can also not be serialized.

### `Deno.KvU64` type

In addition to structured serializable values, the special value `Deno.KvU64` is
also supported as a value. This object represents a 64-bit unsigned integer,
represented as a bigint. It can be used with the `sum`, `min`, and `max` KV
operations. It can not be stored within an object or array. It must be stored as
a top-level value.

It can be created with the `Deno.KvU64` constructor:

```js
const u64 = new Deno.KvU64(42n);
```

### Value Examples

```js,ignore
undefined;
null;
true;
false;
42;
-42.5;
42n;
"hello";
new Uint8Array([1, 2, 3]);
[1, 2, 3];
{ a: 1, b: 2, c: 3 };
new Map([["a", 1], ["b", 2], ["c", 3]]);
new Set([1, 2, 3]);
new Date("2023-04-23");
/abc/;

// Circular references are supported
const a = {};
const b = { a };
a.b = b;

// Deno.KvU64 is supported
new Deno.KvU64(42n);
```

## Versionstamp

All data in the Deno KV key-space is versioned. Every time a value is inserted
or modified, a versionstamp is assigned to it. Versionstamps are monotonically
increasing, non-sequential, 12 byte values that represent the time that the
value was modified. Versionstamps do not represent real time, but rather the
order in which the values were modified.

Because versionstamps are monotonically increasing, they can be used to
determine whether a given value is newer or older than another value. This can
be done by comparing the versionstamps of the two values. If versionstamp A is
greater than versionstamp B, then value A was modified more recently than value
B.

```js
versionstampA > versionstampB;
"000002fa526aaccb0000" > "000002fa526aacc90000"; // true
```

All data modified by a single transaction are assigned the same versionstamp.
This means that if two `set` operations are performed in the same atomic
operation, then the versionstamp of the new values will be the same.

Versionstamps are used to implement optimistic concurrency control. Atomic
operations can contain checks that ensure that the versionstamp of the data they
are operating on matches a versionstamp passed to the operation. If the
versionstamp of the data is not the same as the versionstamp passed to the
operation, then the transaction will fail and the operation will not be applied.

[structured clone algorithm]: https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm



/. 🚀 kv/manual/key_expiration.mdx
===================================================

import Admonition from "./_admonition.mdx";

# Key Expiration

<Admonition />

Since version 1.36.2, Deno KV supports key expiration. This allows an expiration
timestamp to be associated with a key, after which the key will be automatically
deleted from the database:

```ts
const kv = await Deno.openKv();

// `expireIn` is the number of milliseconds after which the key will expire.
function addSession(session: Session, expireIn: number) {
  await kv.set(["sessions", session.id], session, { expireIn });
}
```

Key expiration is supported on both Deno CLI and Deno Deploy.

## Atomic expiration of multiple keys

If multiple keys are set in the same atomic operation and have the same
`expireIn` value, the expiration of those keys will be atomic. For example:

```ts
const kv = await Deno.openKv();

function addUnverifiedUser(
  user: User,
  verificationToken: string,
  expireIn: number,
) {
  await kv.atomic()
    .set(["users", user.id], user, { expireIn })
    .set(["verificationTokens", verificationToken], user.id, { expireIn })
    .commit();
}
```

## Caveats

The expire timestamp specifies the _earliest_ time after which the key can be
deleted from the database. An implementation is allowed to expire a key at any
time after the specified timestamp, but not before. If you need to strictly
enforce an expiration time (e.g. for security purposes), please also add it as a
field of your value and do a check after retrieving the value from the database.



/. 🚀 kv/manual/backup.mdx
===================================================

import Admonition from "./_admonition.mdx";
import backupAddBucketToDash from "./images/backup-add-bucket-to-dash.png";
import backupGcsBucketCreate from "./images/backup-gcs-bucket-create.png";

# Backups

<Admonition />

KV databases hosted on Deno Deploy can be continuously backed up to your own S3-compatible storage buckets. This is in
addition to the replication and backups that we internally perform for all data stored in hosted Deno KV databases to ensure
high availability and data durability.

This backup happens continuously with very little lag, enabling _[point-in-time-recovery](https://en.wikipedia.org/wiki/Point-in-time_recovery)_
and live replication. Enabling backup for KV databases unlocks various interesting use-cases:

- Retrieving a consistent snapshot of your data at any point in time in the past
- Running a read-only data replica independent of Deno Deploy
- Pushing data into your favorite data pipeline by piping mutations into streaming platforms and analytical databases like Kafka, BigQuery and ClickHouse

## Configuring backup to Amazon S3

First you must create a bucket on AWS:

import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';

<Tabs groupId="aws-tool">
<TabItem value="console" label="AWS Console" default>

1. Go to the [AWS S3 console](https://s3.console.aws.amazon.com/s3/home)
2. Click "Create bucket"
3. Enter a bucket name and choose a AWS region, then scroll down and click "Next"


</TabItem>
<TabItem value="cli" label="AWS CLI">

1. Install the [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
2. Run `aws s3api create-bucket --bucket <bucket-name> --region <region> --create-bucket-configuration LocationConstraint=<region>` (replace `<bucket-name>` and `<region>` with your own values)


</TabItem>
</Tabs>

Then, create an IAM policy with `PutObject` access to the bucket, attach it to
an IAM user, and create access keys for that user:

<Tabs groupId="aws-tool">
<TabItem value="console" label="AWS Console" default>

1. Go to the [AWS IAM console](https://console.aws.amazon.com/iam/home)
2. Click "Policies" in the left sidebar
3. Click on "Create policy"
4. Select the "JSON" the policy editor and paste the following policy:
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Sid": "KVBackup",
         "Effect": "Allow",
         "Action": "s3:PutObject",
         "Resource": "arn:aws:s3:::<bucket-name>/*"
       }
     ]
   }
   ```
   Replace `<bucket-name>` with the name of the bucket you created earlier.
5. Click "Review policy"
6. Enter a name for the policy and click "Create policy"
7. Click "Users" in the left sidebar
8. Click "Add user"
9. Enter a name for the user and click "Next"
10. Click "Attach policies directly"
11. Search for the policy you created earlier and click the checkbox next to it
12. Click "Next"
13. Click "Create user"
14. Click on the user you just created
15. Click "Security credentials" and then "Create access key"
16. Select "Other", then click "Next"
17. Enter a description for the access key and click "Create access key"
18. Copy the access key ID and secret access key and save them somewhere safe.
    You will need them later, and you will not be able to retrieve them again.

</TabItem>
<TabItem value="cli" label="AWS CLI">

1. Copy the following command to your terminal, and replace `<bucket-name>` with
   the name of the bucket you created earlier, then run it:
   ```
   aws iam create-policy --policy-name <policy-name> --policy-document '{"Version":"2012-10-17","Statement":[{"Sid":"KVBackup","Effect":"Allow","Action":"s3:PutObject","Resource":"arn:aws:s3:::<bucket-name>/*"}]}'
   ```
2. Copy the following command to your terminal, and replace `<user-name>` with
   a name for the user you are creating, then run it:
   ```
   aws iam create-user --user-name <user-name>
   ```
3. Copy the following command to your terminal, and replace `<policy-arn>` with
   the ARN of the policy you created in step 1, and `<user-name>` with
   the name of the user you created in the previous step, then run it:
   ```
   aws iam attach-user-policy --policy-arn <policy-arn> --user-name <user-name>
   ```
4. Copy the following command to your terminal, and replace `<user-name>` with
   the name of the user you created in step 2, then run it:
   ```
   aws iam create-access-key --user-name <user-name>
   ```
5. Copy the access key ID and secret access key and save them somewhere safe.
   You will need them later, and you will not be able to retrieve them again.
   

</TabItem>
</Tabs>

Now visit the [Deno Deploy dashboard](https://dash.deno.com), and click on the
"KV" tab in your project. Scroll to the "Backup" section, and click on "AWS S3".
Enter the bucket name, access key ID, and secret access key you created earlier,
and the region the bucket is in. Then click "Save".

<img
  src={backupAddBucketToDash}
  alt="add backup to dashboard"
  style={{
    height: "500px",
  }}
/>

The backup will start immediately. Once the data has been backed up, and
continous backup is active, you will see the status change to "Active".

## Configuring backup to Google Cloud Storage

Google Cloud Storage (GCS) is compatible with the S3 protocol, and can also be
used as a backup target.

First you must create a bucket on GCP:

<Tabs groupId="gcp-tool">
<TabItem value="console" label="GCP Console" default>

1. Go to the [GCP Cloud Storage console](https://console.cloud.google.com/storage/browser)
2. Click on "Create" in the top bar
3. Enter a bucket name, choose a location, and click "Create"

</TabItem>
<TabItem value="cli" label="gcloud CLI">

1. Install the [gcloud CLI](https://cloud.google.com/sdk/docs/install)
2. Run `gcloud storage buckets create <bucket-name> --location <location>` (replace `<bucket-name>` and `<location>` with your own values)

</TabItem>
</Tabs>

Then, create a service account with `Storage Object Admin` access to the bucket,
and create an HMAC access key for the service account:

<Tabs groupId="gcp-tool">
<TabItem value="console" label="GCP Console" default>

1. Go to the [GCP IAM console](https://console.cloud.google.com/iam-admin/iam)
2. Click on "Service accounts" in the left sidebar
3. Click on "Create service account"
4. Enter a name for the service account and click "Done"
5. Copy the email for the service account you just created. You will need it
   later.
6. Go to the [GCP Cloud Storage console](https://console.cloud.google.com/storage/browser)
7. Click on the bucket you created earlier
8. Click on "Permissions" in the toolbar
9. Click "Grant access"
10. Paste the email for the service account you copied earlier into the "New
    principals" field
11. Select "Storage Object Admin" from the "Select a role" dropdown
12. Click "Save"
13. Click on "Settings" in the left sidebar (still in the Cloud Storage console)
14. Click on the "Interoperability" tab
15. Click on "Create a key for a service account"
16. Select the service account you created earlier
17. Click "Create key"
18. Copy the access key and secret access key and save them somewhere safe.
    You will need them later, and you will not be able to retrieve them again.


</TabItem>
<TabItem value="cli" label="gcloud CLI">

1. Run the following command, replacing `<service-account-name>` with a name for
   the service account you are creating:
   ```
   gcloud iam service-accounts create <service-account-name>
   ```
2. Run the following command, replacing `<bucket-name>` with the name of the
   bucket you created earlier, and `<service-account-email>` with the email of
   the service account you created in the previous step:
   ```
   gsutil iam ch serviceAccount:<service-account-email>:objectAdmin gs://<bucket-name>
   ```
3. Run the following command, replacing `<service-account-email>` with the email
   of the service account you created in the previous step:
   ```
   gcloud storage hmac create <service-account-email>
   ```
4. Copy the `accessId` and `secret` and save them somewhere safe. You will need
   them later, and you will not be able to retrieve them again.


</TabItem>
</Tabs>

Now visit the [Deno Deploy dashboard](https://dash.deno.com), and click on the
"KV" tab in your project. Scroll to the "Backup" section, and click on "Google
Cloud Storage". Enter the bucket name, access key ID, and secret access key you
created earlier, and the region the bucket is in. Then click "Save".

The backup will start immediately. Once the data has been backed up, and
continous backup is active, you will see the status change to "Active".

## Using backups

S3 backups can be used with the `denokv` tool. Please refer to the
[documentation](https://github.com/denoland/denokv) for more details.



/. 🚀 kv/manual/data_modeling_typescript.mdx
===================================================

import Admonition from "./_admonition.mdx";

# Data Modeling in TypeScript

<Admonition />

In TypeScript applications, it is usually desirable to create strongly-typed,
well-documented objects to contain the data that your application operates on.
Using [interfaces](https://www.typescriptlang.org/docs/handbook/2/objects.html)
or [classes](https://www.typescriptlang.org/docs/handbook/2/classes.html), you
can describe both the shape and behavior of objects in your programs.

If you are using Deno KV, however, there is a bit of extra work required to
persist and retrieve objects that are strongly typed. In this guide, we'll cover
strategies for working with strongly typed objects going into and back out from
Deno KV.

## Using interfaces and type assertions

When storing and retrieving application data in Deno KV, you might want to begin
by describing the shape of your data using TypeScript interfaces. Below is an
object model which describes some key components of a blogging system:

```ts title="model.ts"
export interface Author {
  username: string;
  fullName: string;
}

export interface Post {
  slug: string;
  title: string;
  body: string;
  author: Author;
  createdAt: Date;
  updatedAt: Date;
}
```

This object model describes a blog post and an associated author.

With Deno KV, you can use these TypeScript interfaces like
[data transfer objects (DTOs)](https://martinfowler.com/bliki/LocalDTO.html) - a
strongly typed wrapper around the otherwise untyped objects you might send to or
receive from Deno KV.

Without any additional work, you can happily store the contents of one of these
DTOs in Deno KV.

```ts
import { Author } from "./model.ts";

const kv = await Deno.openKv();

const a: Author = {
  username: "acdoyle",
  fullName: "Arthur Conan Doyle",
};

await kv.set(["authors", a.username], a);
```

When retreiving this same object from Deno KV, however, it won't by default have
type information associated with it. If you know the shape of the object that
was stored for the key, however, you can use
[type assertion](https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#type-assertions)
to inform the TypeScript compiler about the shape of an object.

```ts
import { Author } from "./model.ts";

const kv = await Deno.openKv();

const r = await kv.get(["authors", "acdoyle"]);
const ac = r.value as Author;

console.log(ac.fullName);
```

You can also specify an optional
[type parameter](https://deno.land/api?s=Deno.Kv&p=prototype.get&unstable) for
`get`:

```ts
import { Author } from "./model.ts";

const kv = await Deno.openKv();

const r = await kv.get<Author>(["authors", "acdoyle"]);

console.log(r.value.fullName);
```

For simpler data structures, this technique may be sufficient. But often, you
will want or need to apply some business logic when creating or accessing your
domain objects. When this need arises, you can develop a set of pure functions
that can operate on your DTOs.

## Encapsulating business logic with a service layer

When your application's persistence needs become more complex - such as when you
need to create [secondary indexes](./secondary_indexes.mdx) to query your data by
different keys, or maintain relationships between objects - you will want to
create a set of functions to sit on top of your DTOs to ensure that the data
being passed around is valid (and not merely typed correctly).

From our business objects above, the `Post` object is complex enough where it is
likely to need a small layer of code to save and retrieve an instance of the
object. Below is an example of two functions that wrap the underlying Deno KV
APIs, and return strongly typed object instances for the `Post` interface.

Notably, we need to store an identifier for an `Author` object, so we can
retrieve author information from KV later.

```ts
import { Author, Post } from "./model.ts";

const kv = await Deno.openKv();

interface RawPost extends Post {
  authorUsername: string;
}

export async function savePost(p: Post): Promise<Post> {
  const postData: RawPost = Object.assign({}, p, {
    authorUsername: p.author.username,
  });

  await kv.set(["posts", p.slug], postData);
  return p;
}

export async function getPost(slug: string): Promise<Post> {
  const postResponse = await kv.get(["posts", slug]);
  const rawPost = postResponse.value as RawPost;
  const authorResponse = await kv.get(["authors", rawPost.authorUsername]);

  const author = authorResponse.value as Author;
  const post = Object.assign({}, postResponse.value, {
    author,
  }) as Post;

  return post;
}
```

This thin layer uses a `RawPost` interface, which extends the actual `Post`
interface, to include some additional data that is used to reference data at
another index (the associated `Author` object).

The `savePost` and `getPost` functions take the place of a direct Deno KV `get`
or `set` operation, so that they can properly serialize and "hydrate" model
objects for us with appropriate types and associations.



/. 🚀 kv/manual/on_deploy.mdx
===================================================

import Admonition from "./_admonition.mdx";

# KV on Deno Deploy

<Admonition />

Deno Deploy now offers a built-in serverless key-value database called Deno KV.

Additionally, Deno KV is available within Deno itself, utilizing SQLite as its
backend. This feature has been accessible since Deno v1.32 with the `--unstable`
flag. Learn more about [Deno KV](/kv/manual).

## Consistency

Deno KV, by default, is a strongly-consistent database. It provides the
strictest form of strong consistency called _external consistency_, which
implies:

- **Serializability**: This is the highest level of isolation for transactions.
  It ensures that the concurrent execution of multiple transactions results in a
  system state that would be the same as if the transactions were executed
  sequentially, one after another. In other words, the end result of
  serializable transactions is equivalent to some sequential order of these
  transactions.
- **Linearizability**: This consistency model guarantees that operations, such
  as read and write, appear to be instantaneous and occur in real-time. Once a
  write operation completes, all subsequent read operations will immediately
  return the updated value. Linearizability ensures a strong real-time ordering
  of operations, making the system more predictable and easier to reason about.

Meanwhile, you can choose to relax consistency constraints by setting the
`consistency: "eventual"` option on individual read operations. This option
allows the system to serve the read from global replicas and caches for minimal
latency.

Below are the latency figures observed in our top regions:

| Region                     | Latency (Eventual Consistency) | Latency (Strong Consistency) |
| -------------------------- | ------------------------------ | ---------------------------- |
| North Virginia (us-east4)  | 7ms                            | 7ms                          |
| Frankfurt (europe-west3)   | 7ms                            | 94ms                         |
| Netherlands (europe-west4) | 13ms                           | 95ms                         |
| California (us-west2)      | 72ms                           | 72ms                         |
| Hong Kong (asia-east2)     | 42ms                           | 194ms                        |

## Distributed queues

Serverless distributed queues are available on Deno Deploy. See
[Queues on Deno Deploy](/kv/manual/queue_overview#queues-on-deno-deploy) for
more details.

## Connect to managed databases from outside of Deno Deploy

You can connect to your Deno Deploy KV database from your Deno application
outside of Deno Deploy. To open a managed database, set the
`DENO_KV_ACCESS_TOKEN` environment variable to a Deno Deploy personal access
token and provide the URL of the database to `Deno.openKv`:

```ts
const kv = await Deno.openKv(
  "https://api.deno.com/databases/<database-id>/connect",
);
```

Please check the
[docs](https://github.com/denoland/deno/tree/main/ext/kv#kv-connect) for the
specification of the protocol for connecting to a remote KV database

## Data distribution

Deno KV databases are replicated across at least 6 data centers, spanning 3
regions (US, Europe, and Asia). Once a write operation is committed, its
mutations are persistently stored in a minimum of two data centers within the
primary region. Asynchronous replication typically transfers these mutations to
the other two regions in under 10 seconds.

The system is designed to tolerate most data center-level failures without
experiencing downtime or data loss. Recovery Point Objectives (RPO) and Recovery
Time Objectives (RTO) help quantify the system's resilience under various
failure modes. RPO represents the maximum acceptable amount of data loss
measured in time, whereas RTO signifies the maximum acceptable time required to
restore the system to normal operations after a failure.

- Loss of one data center in the primary region: RPO=0 (no data loss), RTO<5s
  (system restoration in under 5 seconds)
- Loss of any number of data centers in a replica region: RPO=0, RTO<5s
- Loss of two or more data centers in the primary region: RPO<60s (under 60
  seconds of data loss)



/. 🚀 kv/manual/operations.mdx
===================================================

import Admonition from "./_admonition.mdx";

# Operations

<Admonition />

The Deno KV API provides a set of operations that can be performed on the key
space.

There are two operations that read data from the store, and five operations that
write data to the store.

Read operations can either be performed in strong or eventual consistency mode.
Strong consistency mode guarantees that the read operation will return the most
recently written value. Eventual consistency mode may return a stale value, but
is faster.

Write operations are always performed in strong consistency mode.

## `get`

The `get` operation returns the value and versionstamp associated with a given
key. If a value does not exist, get returns a `null` value and versionstamp.

There are two APIs that can be used to perform a `get` operation. The
[`Deno.Kv.prototype.get(key, options?)`][get] API, which can be used to read a
single key, and the [`Deno.Kv.prototype.getMany(keys, options?)`][getMany] API,
which can be used to read multiple keys at once.

Get operations are performed as a "snapshot read" in all consistency modes. This
means that when retrieving multiple keys at once, the values returned will be
consistent with each other.

```ts
const res = await kv.get<string>(["config"]);
console.log(res); // { key: ["config"], value: "value", versionstamp: "000002fa526aaccb0000" }

const res = await kv.get<string>(["config"], { consistency: "eventual" });
console.log(res); // { key: ["config"], value: "value", versionstamp: "000002fa526aaccb0000" }

const [res1, res2, res3] = await kv.getMany<[string, string, string]>([
  ["users", "sam"],
  ["users", "taylor"],
  ["users", "alex"],
]);
console.log(res1); // { key: ["users", "sam"], value: "sam", versionstamp: "00e0a2a0f0178b270000" }
console.log(res2); // { key: ["users", "taylor"], value: "taylor", versionstamp: "0059e9035e5e7c5e0000" }
console.log(res3); // { key: ["users", "alex"], value: "alex", versionstamp: "00a44a3c3e53b9750000" }
```

## `list`

The `list` operation returns a list of keys that match a given selector. The
associated values and versionstamps for these keys are also returned. There are
2 different selectors that can be used to filter the keys matched.

The `prefix` selector matches all keys that start with the given prefix key
parts, but not inclusive of an exact match of the key. The prefix selector may
optionally be given a `start` OR `end` key to limit the range of keys returned.
The `start` key is inclusive, and the `end` key is exclusive.

The `range` selector matches all keys that are lexographically between the given
`start` and `end` keys. The `start` key is inclusive, and the `end` key is
exclusive.

> Note: In the case of the prefix selector, the `prefix` key must consist only
> of full (not partial) key parts. For example, if the key `["foo", "bar"]`
> exists in the store, then the prefix selector `["foo"]` will match it, but the
> prefix selector `["f"]` will not.

The list operation may optionally be given a `limit` to limit the number of keys
returned.

List operations can be performed using the
[`Deno.Kv.prototype.list<string>(selector, options?)`][list] method. This method
returns a `Deno.KvListIterator` that can be used to iterate over the keys
returned. This is an async iterator, and can be used with `for await` loops.

```ts
// Return all users
const iter = kv.list<string>({ prefix: ["users"] });
const users = [];
for await (const res of iter) users.push(res);
console.log(users[0]); // { key: ["users", "alex"], value: "alex", versionstamp: "00a44a3c3e53b9750000" }
console.log(users[1]); // { key: ["users", "sam"], value: "sam", versionstamp: "00e0a2a0f0178b270000" }
console.log(users[2]); // { key: ["users", "taylor"], value: "taylor", versionstamp: "0059e9035e5e7c5e0000" }

// Return the first 2 users
const iter = kv.list<string>({ prefix: ["users"] }, { limit: 2 });
const users = [];
for await (const res of iter) users.push(res);
console.log(users[0]); // { key: ["users", "alex"], value: "alex", versionstamp: "00a44a3c3e53b9750000" }
console.log(users[1]); // { key: ["users", "sam"], value: "sam", versionstamp: "00e0a2a0f0178b270000" }

// Return all users lexicographically after "taylor"
const iter = kv.list<string>({ prefix: ["users"], start: ["users", "taylor"] });
const users = [];
for await (const res of iter) users.push(res);
console.log(users[0]); // { key: ["users", "taylor"], value: "taylor", versionstamp: "0059e9035e5e7c5e0000" }

// Return all users lexicographically before "taylor"
const iter = kv.list<string>({ prefix: ["users"], end: ["users", "taylor"] });
const users = [];
for await (const res of iter) users.push(res);
console.log(users[0]); // { key: ["users", "alex"], value: "alex", versionstamp: "00a44a3c3e53b9750000" }
console.log(users[1]); // { key: ["users", "sam"], value: "sam", versionstamp: "00e0a2a0f0178b270000" }

// Return all users starting with characters between "a" and "n"
const iter = kv.list<string>({ start: ["users", "a"], end: ["users", "n"] });
const users = [];
for await (const res of iter) users.push(res);
console.log(users[0]); // { key: ["users", "alex"], value: "alex", versionstamp: "00a44a3c3e53b9750000" }
```

The list operation reads data from the store in batches. The size of each batch
can be controlled using the `batchSize` option. The default batch size is 500
keys. Data within a batch is read in a single snapshot read, so the values are
consistent with each other. Consistency modes apply to each batch of data read.
Across batches, data is not consistent. The borders between batches is not
visible from the API as the iterator returns individual keys.

The list operation can be performed in reverse order by setting the `reverse`
option to `true`. This will return the keys in lexicographically descending
order. The `start` and `end` keys are still inclusive and exclusive
respectively, and are still interpreted as lexicographically ascending.

```ts
// Return all users in reverse order, ending with "sam"
const iter = kv.list<string>({ prefix: ["users"], start: ["users", "sam"] }, {
  reverse: true,
});
const users = [];
for await (const res of iter) users.push(res);
console.log(users[0]); // { key: ["users", "taylor"], value: "taylor", versionstamp: "0059e9035e5e7c5e0000" }
console.log(users[1]); // { key: ["users", "sam"], value: "sam", versionstamp: "00e0a2a0f0178b270000" }
```

> Note: in the above example we set the `start` key to `["users", "sam"]`, even
> though the first key returned is `["users", "taylor"]`. This is because the
> `start` and `end` keys are always evaluated in lexicographically ascending
> order, even when the list operation is performed in reverse order (which
> returns the keys in lexicographically descending order).

## `set`

The `set` operation sets the value of a key in the store. If the key does not
exist, it is created. If the key already exists, its value is overwritten.

The `set` operation can be performed using the
[`Deno.Kv.prototype.set(key, value)`][set] method. This method returns a
`Promise` that resolves to a `Deno.KvCommitResult` object, which contains the
`versionstamp` of the commit.

Set operations are always performed in strong consistency mode.

```ts
const res = await kv.set(["users", "alex"], "alex");
console.log(res.versionstamp); // "00a44a3c3e53b9750000"
```

## `delete`

The `delete` operation deletes a key from the store. If the key does not exist,
the operation is a no-op.

The `delete` operation can be performed using the
[`Deno.Kv.prototype.delete(key)`][delete] method.

Delete operations are always performed in strong consistency mode.

```ts
await kv.delete(["users", "alex"]);
```

## `sum`

The `sum` operation atomically adds a value to a key in the store. If the key
does not exist, it is created with the value of the sum. If the key already
exists, its value is added to the sum.

The `sum` operation can only be performed as part of an atomic operation. The
[`Deno.AtomicOperation.prototype.mutate({ type: "sum", value })`][mutate] method
can be used to add a sum mutation to an atomic operation.

The sum operation can only be performed on values of type `Deno.KvU64`. Both the
operand and the value in the store must be of type `Deno.KvU64`.

If the new value of the key is greater than `2^64 - 1` or less than `0`, the sum
operation wraps around. For example, if the value in the store is `2^64 - 1` and
the operand is `1`, the new value will be `0`.

Sum operations are always performed in strong consistency mode.

```ts
await kv.atomic()
  .mutate({
    type: "sum",
    key: ["accounts", "alex"],
    value: new Deno.KvU64(100n),
  })
  .commit();
```

## `min`

The `min` operation atomically sets a key to the minimum of its current value
and a given value. If the key does not exist, it is created with the given
value. If the key already exists, its value is set to the minimum of its current
value and the given value.

The `min` operation can only be performed as part of an atomic operation. The
[`Deno.AtomicOperation.prototype.mutate({ type: "min", value })`][mutate] method
can be used to add a min mutation to an atomic operation.

The min operation can only be performed on values of type `Deno.KvU64`. Both the
operand and the value in the store must be of type `Deno.KvU64`.

Min operations are always performed in strong consistency mode.

```ts
await kv.atomic()
  .mutate({
    type: "min",
    key: ["accounts", "alex"],
    value: new Deno.KvU64(100n),
  })
  .commit();
```

## `max`

The `max` operation atomically sets a key to the maximum of its current value
and a given value. If the key does not exist, it is created with the given
value. If the key already exists, its value is set to the maximum of its current
value and the given value.

The `max` operation can only be performed as part of an atomic operation. The
[`Deno.AtomicOperation.prototype.mutate({ type: "max", value })`][mutate] method
can be used to add a max mutation to an atomic operation.

The max operation can only be performed on values of type `Deno.KvU64`. Both the
operand and the value in the store must be of type `Deno.KvU64`.

Max operations are always performed in strong consistency mode.

```ts
await kv.atomic()
  .mutate({
    type: "max",
    key: ["accounts", "alex"],
    value: new Deno.KvU64(100n),
  })
  .commit();
```

[get]: https://deno.land/api?s=Deno.Kv&p=prototype.get&unstable
[getMany]: https://deno.land/api?s=Deno.Kv&p=prototype.getMany&unstable
[list]: https://deno.land/api?s=Deno.Kv&p=prototype.list&unstable
[set]: https://deno.land/api?s=Deno.Kv&p=prototype.set&unstable
[delete]: https://deno.land/api?s=Deno.Kv&p=prototype.delete&unstable
[mutate]: https://deno.land/api?s=Deno.AtomicOperation&p=prototype.mutate&unstable



/. 🚀 kv/manual/queue_overview.md
===================================================

import Admonition from "./_admonition.mdx";

# Using Queues

<Admonition />

The Deno runtime includes a queueing API that supports offloading larger
workloads for async processing, with guaranteed at-least-once delivery of queued
messages. Queues can be used to offload tasks in a web application, or to
schedule units of work for a time in the future.

The primary APIs you'll use with queues are in the `Deno.Kv` namespace as
[`enqueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.enqueue)
and
[`listenQueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.listenQueue).

## Enqueue a message

To enqueue a message for processing, use the `enqueue` method on an instance of
[`Deno.Kv`](https://deno.land/api?unstable=true&s=Deno.Kv). In the example
below, we show what it might look like to enqueue a notification for delivery.

```ts title="queue_example.ts"
// Describe the shape of your message object (optional)
interface Notification {
  forUser: string;
  body: string;
}

// Get a reference to a KV instance
const kv = await Deno.openKv();

// Create a notification object
const message: Notification = {
  forUser: "alovelace",
  body: "You've got mail!",
};

// Enqueue the message for immediate delivery
await kv.enqueue(message);
```

You can enqueue a message for later delivery by specifying a `delay` option in
milliseconds.

```ts
// Enqueue the message for delivery in 3 days
const delay = 1000 * 60 * 60 * 24 * 3;
await kv.enqueue(message, { delay });
```

You can also specify a key in Deno KV where your message value will be stored if
your message isn't delivered for any reason.

```ts
// Configure a key where a failed message would be sent
const backupKey = ["failed_notifications", "alovelace", Date.now()];
await kv.enqueue(message, { keysIfUndelivered: [backupKey] });

// ... disaster strikes ...

// Get the unsent message
const r = await kv.get<Notification>(backupKey);
// This is the message that didn't get sent:
console.log("Found failed notification for:", r.value?.forUser);
```

## Listening for messages

You can configure a JavaScript function that will process items added to your
queue with the `listenQueue` method on an instance of
[`Deno.Kv`](https://deno.land/api?unstable=true&s=Deno.Kv).

```ts title="listen_example.ts"
// Define the shape of the object we expect as a message in the queue
interface Notification {
  forUser: string;
  body: string;
}

// Create a type guard to check the type of the incoming message
function isNotification(o: unknown): o is Notification {
  return (
    ((o as Notification)?.forUser !== undefined &&
      typeof (o as Notification).forUser === "string") &&
    ((o as Notification)?.body !== undefined &&
      typeof (o as Notification).body === "string")
  );
}

// Get a reference to a KV database
const kv = await Deno.openKv();

// Register a handler function to listen for values - this example shows
// how you might send a notification
kv.listenQueue((msg: unknown) => {
  // Use type guard - then TypeScript compiler knows msg is a Notification
  if (isNotification(msg)) {
    console.log("Sending notification to user:", msg.forUser);
    // ... do something to actually send the notification!
  } else {
    // If the message is of an unknown type, it might be an error
    console.error("Unknown message received:", msg);
  }
});
```

## Queue API with KV atomic transactions

You can combine the queue API with [KV atomic transactions](./transactions.mdx)
to atomically enqueue messages and modify keys in the same transaction.

```ts title="kv_transaction_example.ts"
const kv = await Deno.openKv();

kv.listenQueue(async (msg: unknown) => {
  const nonce = await kv.get(["nonces", msg.nonce]);
  if (nonce.value === null) {
    // This messaged was already processed
    return;
  }

  const change = msg.change;
  const bob = await kv.get(["balance", "bob"]);
  const liz = await kv.get(["balance", "liz"]);

  const success = await kv.atomic()
    // Ensure this message was not yet processed
    .check({ key: nonce.key, versionstamp: nonce.versionstamp })
    .delete(nonce.key)
    .sum(["processed_count"], 1n)
    .check(bob, liz) // balances did not change
    .set(["balance", "bob"], bob.value - change)
    .set(["balance", "liz"], liz.value + change)
    .commit();
});

// Modify keys and enqueue messages in the same KV transaction!
const nonce = crypto.randomUUID();
await kv
  .atomic()
  .check({ key: ["nonces", nonce], versionstamp: null })
  .enqueue({ nonce: nonce, change: 10 })
  .set(["nonces", nonce], true)
  .sum(["enqueued_count"], 1n)
  .commit();
```

## Queue behavior

### Message delivery guarantees

The runtime guarantees at-least-once delivery. This means that for majority of
enqueued messages, the
[`listenQueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.listenQueue)
handler will be invoked once for each message. In some failure scenarios, the
handler may be invoked multiple times for the same message to ensure delivery.
It's important to design your applications such that duplicate messages are
handled correctly.

You may use queues in combination with
[KV atomic transactions](https://docs.deno.com/kv/manual/transactions)
primitives to ensure that your queue handler KV updates are performed exactly
once per message. See
[Queue API with KV atomic transactions](#queue-api-with-kv-atomic-transactions).

### Automatic retries

[`listenQueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.listenQueue)
handler is invoked to process your queued messages when they're ready for
delivery. If your handler throws an exception the runtime will automatically
retry to call the handler again until it succeeds or until maximum retry
attempts are reached. The message is considered to be succesfully processed once
the
[`listenQueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.listenQueue)
handler invocation completes succesfully. The message will be dropped if the
handler consistently fails on retries.

### Message delivery order

The runtime makes best effort to deliver messages in the order they were
enqueued. However, there is not strict order guarantee. Occasionally, messages
may be delivered out of order to ensure maximum throughput.

## Queues on Deno Deploy

Deno Deploy offers global, serverless, distributed implementation of the
queueing API, designed for high availability and throughput. You can use it to
build applications that scale to handle large workloads.

### Just-in-time isolate spin-up

When using queues with Deno Deploy, isolates are automatically spun up on demand
to invoke your
[`listenQueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.listenQueue)
handler when a message becomes available for processing. Defining
[`listenQueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.listenQueue)
handler is the only requirement to enable queue processing in your Deno Deploy
application, no additional configuration is needed.

### Queue size limit

The maximum number of undelivered queue messages is limited to 100,000.
[`enqueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.enqueue)
method will fail with an error if the queue is full.

### Pricing details and limits

- [`enqueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.enqueue)
  is treated just like other
  [`Deno.Kv`](https://deno.land/api?unstable=true&s=Deno.Kv) write operations.
  Enqueued messages consume KV storage and write units.
- Messages delivered through
  [`listenQueue`](https://deno.land/api?unstable=true&s=Deno.Kv&p=prototype.listenQueue)
  consume requests and KV write units.
- See [Pricing details](https://deno.com/deploy/docs/pricing) for more
  information.

## Use cases

Queues can be useful in many different scenarios, but there are a few use cases
you might see a lot when building web applications.

### Offloading async processes

Sometimes a task that's initiated by a client (like sending a notification or
API request), may take long enough where you don't want to make clients wait for
that task to be completed before returning a response. Other times, clients
don't actually need a response at all, such as when a client is sending your
application a [webhook request](https://en.wikipedia.org/wiki/Webhook), so
there's no need to wait for the underlying task to be completed before returning
a response.

In these cases, you can offload work to a queue to keep your web application
responsive and send immediate feedback to clients. To see an example of this use
case in action, check out our
[webhook processing example](../tutorials/webhook_processor.md).

### Scheduling work for the future

Another helpful application of queues (and queue APIs like this one), is to
schedule work to happen at an appropriate time in the future. Maybe you'd like
to send a notification to a new customer a day after they have placed an order
to send them a satisfaction survey. You can schedule a queue message to be
delivered 24 hours into the future, and set up a listener to send out the
notification at that time.

To see an example of scheduling a notification to go out in the future, check
out our [notification example](../tutorials/schedule_notification.md).



/. 🚀 kv/manual/secondary_indexes.mdx
===================================================

import Admonition from "./_admonition.mdx";

# Secondary Indexes

<Admonition />

Key-value stores like Deno KV organize data as collections of key-value pairs,
where each unique key is associated with a single value. This structure enables
easy retrieval of values based on their keys but does not allow for querying
based on the values themselves. To overcome this constraint, you can create
secondary indexes, which store the same value under additional keys that include
(part of) that value.

Maintaining consistency between primary and secondary keys is crucial when using
secondary indexes. If a value is updated at the primary key without updating the
secondary key, the data returned from a query targeting the secondary key will
be incorrect. To ensure that primary and secondary keys always represent the
same data, use atomic operations when inserting, updating, or deleting data.
This approach ensures that the group of mutation actions are executed as a
single unit, and either all succeed or all fail, preventing inconsistencies.

## Unique indexes (one-to-one)

Unique indexes have each key in the index associated with exactly one primary
key. For example, when storing user data and looking up users by both their
unique IDs and email addresses, store user data under two separate keys: one for
the primary key (user ID) and another for the secondary index (email). This
setup allows querying users based on either their ID or their email. The
secondary index can also enforce uniqueness constraints on values in the store.
In the case of user data, use the index to ensure that each email address is
associated with only one user - in other words that emails are unique.

To implement a unique secondary index for this example, follow these steps:

1. Create a `User` interface representing the data:

   ```tsx
   interface User {
     id: string;
     name: string;
     email: string;
   }
   ```

2. Define an `insertUser` function that stores user data at both the primary and
   secondary keys:

   ```tsx
   async function insertUser(user: User) {
     const primaryKey = ["users", user.id];
     const byEmailKey = ["users_by_email", user.email];
     const res = await kv.atomic()
       .check({ key: primaryKey, versionstamp: null })
       .check({ key: byEmailKey, versionstamp: null })
       .set(primaryKey, user)
       .set(byEmailKey, user)
       .commit();
     if (!res.ok) {
       throw new TypeError("User with ID or email already exists");
     }
   }
   ```

   > This function performs the insert using an atomic operation that checks
   > that no user with the same ID or email already exists. If either of these
   > constraints is violated, the insert fails and no data is modified.

3. Define a `getUser` function to retrieve a user by their ID:

   ```tsx
   async function getUser(id: string): Promise<User | null> {
     const res = await kv.get<User>(["users", id]);
     return res.value;
   }
   ```

4. Define a `getUserByEmail` function to retrieve a user by their email address:

   ```tsx
   async function getUserByEmail(email: string): Promise<User | null> {
     const res = await kv.get<User>(["users_by_email", email]);
     return res.value;
   }
   ```

   This function queries the store using the secondary key
   (`["users_by_email", email]`).

5. Define a deleteUser function to delete users by their ID:

   ```tsx
   async function deleteUser(id: string) {
     let res = { ok: false };
     while (!res.ok) {
       const getRes = await kv.get<User>(["users", id]);
       if (getRes.value === null) return;
       res = await kv.atomic()
         .check(getRes)
         .delete(["users", id])
         .delete(["users_by_email", getRes.value.email])
         .commit();
     }
   }
   ```

   <!-- deno-fmt-ignore -->
   > This function first retrieves the user by their ID to get the users email
   > address. This is needed to retrieve the email that is needed to construct
   > the key for the secondary index for this user address. It then performs an
   > atomic operation that checks that the user in the database has not changed,
   > and then deletes both the primary and secondary key pointing to the user
   > value. If this fails (the user has been modified between query and delete),
   > the atomic operation aborts. The entire procedure is retried until the
   > delete succeeds.
   > 
   > The check is required to prevent race conditions where
   > value may have been modified between the retrieve and delete. This race can
   > occur if an update changes the user's email, because the secondary index
   > moves in this case. The delete of the secondary index then fails, because
   > the delete is targeting the old secondary index key.

## Non-Unique Indexes (One-to-Many)

Non-unique indexes are secondary indexes where a single key can be associated
with multiple primary keys, allowing you to query for multiple items based on a
shared attribute. For example, when querying users by their favorite color,
implement this using a non-unique secondary index. The favorite color is a
non-unique attribute since multiple users can have the same favorite color.

To implement a non-unique secondary index for this example, follow these steps:

1. Define the `User` interface:

   ```ts
   interface User {
     id: string;
     name: string;
     favoriteColor: string;
   }
   ```

2. Define the `insertUser` function:

   <!-- deno-fmt-ignore -->
   ```ts
   async function insertUser(user: User) {
     const primaryKey = ["users", user.id];
     const byColorKey = ["users_by_favorite_color", user.favoriteColor, user.id];
     await kv.atomic()
       .check({ key: primaryKey, versionstamp: null })
       .set(primaryKey, user)
       .set(byColorKey, user)
       .commit();
   }
   ```

3. Define a function to retrieve users by their favorite color:

   ```ts
   async function getUsersByFavoriteColor(color: string): Promise<User[]> {
     const iter = kv.list<User>({ prefix: ["users_by_favorite_color", color] });
     const users = [];
     for await (const { value } of iter) {
       users.push(value);
     }
     return users;
   }
   ```

This example demonstrates the use of a non-unique secondary index,
`users_by_favorite_color`, which allows querying users based on their favorite
color. The primary key remains the user `id`.

The primary difference between the implementation of unique and non-unique
indexes lies in the structure and organization of the secondary keys. In unique
indexes, each secondary key is associated with exactly one primary key, ensuring
that the indexed attribute is unique across all records. In the case of
non-unique indexes, a single secondary key can be associated with multiple
primary keys, as the indexed attribute may be shared among multiple records. To
achieve this, non-unique secondary keys are typically structured with an
additional unique identifier (e.g., primary key) as part of the key, allowing
multiple records with the same attribute to coexist without conflicts.



/. 🚀 kv/manual/transactions.mdx
===================================================

import Admonition from "./_admonition.mdx";

# Transactions

<Admonition />

The Deno KV store utilizes _optimistic concurrency control transactions_ rather
than _interactive transactions_ like many SQL systems like PostgreSQL or MySQL.
This approach employs versionstamps, which represent the current version of a
value for a given key, to manage concurrent access to shared resources without
using locks. When a read operation occurs, the system returns a versionstamp for
the associated key in addition to the value.

To execute a transaction, one performs an atomic operations that can consist of
multiple mutation actions (like set or delete). Along with these actions,
key+versionstamp pairs are provided as a condition for the transaction's
success. The optimistic concurrency control transaction will only commit if the
specified versionstamps match the current version for the values in the database
for the corresponding keys. This transaction model ensures data consistency and
integrity while allowing concurrent interactions within the Deno KV store.

Because OCC transactions are optimistic, they can fail on commit because the
version constraints specified in the atomic operation were violated. This occurs
when an agent updates a key used within the transaction between read and commit.
When this happens, the agent performing the transaction must retry the
transaction.

To illustrate how to use OCC transactions with Deno KV, this example shows how
to implement a `transferFunds(from: string, to: string, amount: number)`
function for an account ledger. The account ledger stores the balance for each
account in the key-value store. The keys are prefixed by `"account"`, followed
by the account identifier: `["account", "alice"]`. The value stored for each key
is a number that represents the account balance.

Here's a step-by-step example of implementing this `transferFunds` function:

<!-- deno-fmt-ignore -->
```ts
async function transferFunds(sender: string, receiver: string, amount: number) {
  if (amount <= 0) throw new Error("Amount must be positive");

  // Construct the KV keys for the sender and receiver accounts.
  const senderKey = ["account", sender];
  const receiverKey = ["account", receiver];

  // Retry the transaction until it succeeds.
  let res = { ok: false };
  while (!res.ok) {
    // Read the current balance of both accounts.
    const [senderRes, receiverRes] = await kv.getMany([senderKey, receiverKey]);
    if (senderRes.value === null) throw new Error(`Account ${sender} not found`);
    if (receiverRes.value === null) throw new Error(`Account ${receiver} not found`);

    const senderBalance = senderRes.value;
    const receiverBalance = receiverRes.value;

    // Ensure the sender has a sufficient balance to complete the transfer.
    if (senderBalance < amount) {
      throw new Error(
        `Insufficient funds to transfer ${amount} from ${sender}`,
      );
    }

    // Perform the transfer.
    const newSenderBalance = senderBalance - amount;
    const newReceiverBalance = receiverBalance + amount;

    // Attempt to commit the transaction. `res` returns an object with
    // `ok: false` if the transaction fails to commit due to a check failure
    // (i.e. the versionstamp for a key has changed)
    res = await kv.atomic()
      .check(senderRes) // Ensure the sender's balance hasn't changed.
      .check(receiverRes) // Ensure the receiver's balance hasn't changed.
      .set(senderKey, newSenderBalance) // Update the sender's balance.
      .set(receiverKey, newReceiverBalance) // Update the receiver's balance.
      .commit();
  }
}
```

In this example, the `transferFunds` function reads the balances and
versionstamps of both accounts, calculates the new balances after the transfer,
and checks if there are sufficient funds in account A. It then performs an
atomic operation, setting the new balances with the versionstamp constraints. If
the transaction is successful, the loop exits. If the version constraints are
violated, the transaction fails, and the loop retries the transaction until it
succeeds.
