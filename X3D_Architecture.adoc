:icons: font
:stem: latexmath
:source-highlighter: highlight.js
:standards: https://www.web3d.org/standards
:model: https://sourceforge.net/p/x3d/code/HEAD/tree/www.web3d.org/specifications/X3dUnifiedObjectModel-4.0.json

image:https://x3dgraphics.com/examples/X3dForWebAuthors/Chapter01-TechnicalOverview/X3dSpecificationsHoneycombDiagram.png[X3D Technical Overview]

Extensible 3D (X3D) Specifications:

• <<A19775_1, Part 1: Architecture and base components (19775-1)>>
• <<A19775_2, Part 2: Scene access interface (SAI) (19775-2)>>
• <<B19776_1, XML Binding (19776-1)>>
• <<B19776_2, Classic VRML Binding (19776-2)>>
• <<B19776_3, Compressed Binary Binding (19776-3)>>
• <<C19777_1, ECMAScript Binding (19777-1)>>
• <<C19777_2, Java Binding (19777-2)>>

[[A19775_1]]
== Part 1: Architecture and base components

ISO/IEC IS 19775-1:2023		© Web3D Consortium — All rights reserved

[link=https://www.web3d.org/documents/specifications/19775-1/V4.0/index.html]
image::https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/x3d.png[X3D logo]

Extensible 3D (X3D)  +
Part 1: Architecture and base components +
ISO/IEC 19775-1:2023


This document is Edition 4 of ISO/IEC 19775-1, Extensible 3D (X3D). The
full title of this document is: _Computer graphics, image processing,
and environmental data representation — Extensible 3D (X3D) — 
Part 1: Architecture and base components_.

// [opts=autowidth,frame=ends,grid=rows]
// |===
// |Background     2+|Clauses       |Annexes

• <<foreword_html, Foreword>>
• <<introduction_html, Introduction>>
• 1 <<scope_html, Scope>>
• 2 <<references_html, Normative references>>
• 3 <<glossary_html, Definitions, acronyms, and abbreviated terms>>
• 4 <<concepts_html, Concepts>>
• 5 <<fieldTypes_html, Field type reference>>
• 6 <<conformance_html, Conformance>>
• 7 <<core_html, Core component>>
• 8 <<time_html, Time component>>
• 9 <<networking_html, Networking component>>
• 10 <<grouping_html, Grouping component>>
• 11 <<rendering_html, Rendering component>>
• 12 <<shape_html, Shape component>>
• 13 <<geometry3D_html, Geometry3D component>>
• 14 <<geometry2D_html, Geometry2D component>>
• 15 <<text_html, Text component>>
• 16 <<sound_html, Sound component>>
• 17 <<lighting_html, Lighting component>>
• 18 <<texturing_html, Texturing component>>
• 19 <<interpolators_html, Interpolation component>>
• 20 <<pointingDeviceSensor_html, Pointing device sensor component>>
• 21 <<keyDeviceSensor_html, Key device sensor component>>
• 22 <<environmentalSensor_html, Environmental sensor component>>
• 23 <<navigation_html, Navigation component>>
• 24 <<environmentalEffects_html, Environmental effects component>>
• 25 <<geospatial_html, Geospatial component>>
• 26 <<hanim_html, Humanoid Animation (HAnim) component>>
• 27 <<nurbs_html, NURBS component>>
• 28 <<dis_html, Distributed interactive simulation (DIS) component>>
• 29 <<scripting_html, Scripting component>>
• 30 <<eventUtilities_html, Event utilities component>>
• 31 <<shaders_html, Programmable shaders component>>
• 32 <<CADGeometry_html, CAD geometry component>>
• 33 <<texture3D_html, Texturing3D component>>
• 34 <<environmentalTexturing_html, Cube map environmental texturing component>>
• 35 <<layering_html, Layering component>>
• 36 <<layout_html, Layout component>>
• 37 <<rigidBodyPhysics_html, Rigid body physics component>>
• 38 <<picking_html, Picking component>>
• 39 <<followers_html, Followers component>>
• 40 <<particleSystems_html, Particle systems component>>
• 41 <<volume_html, Volume rendering component>>
• 42 <<textureProjection_html, Texture projection component>>
• A <<coreprofile_html, Core profile>>
• B <<interchange_html, Interchange profile>>
• C <<interactive_html, Interactive profile>>
• D <<MPEG4interactive_html, MPEG-4 interactive profile>>
• E <<immersive_html, Immersive profile>>
• F <<fullProfile_html, Full profile>>
• G <<behaviours_html, Recommended navigation behaviours>>
• H <<CADInterchange_html, CADInterchange profile>>
• I <<shaders_glsl_html, OpenGL shading language (GLSL) binding>>
• J <<shaders_hlsl_html, Microsoft high level shading language (HLSL) binding>>
• K <<shaders_cg_html, nVidia Cg shading language binding>>
• L <<htmlGuidelines_html, HTML authoring guidelines>>
• M <<MedicalInterchange_html, MedicalInterchange profile>>
• Z <<versionContent_html, Version content>>
• <<bibliography_html, Bibliography>>
• <<componentIndex_html, Component index>>
• <<profileIndex_html, Profile index>>
• <<nodeIndex_html, Node, abstract node type, and abstract interface index>>


The *Foreword* provides background on the standards process for X3D. The
*Introduction* describes the purpose, design criteria, and functional
characteristics of X3D. The following clauses define Part 1 of ISO/IEC
19775:


• *Scope* defines the problem area that X3D addresses.

• *Normative references* lists the normative standards referenced in
this document.

• *Definitions, acronyms, andabbreviated terms* contains the glossary of
terminology used in this document.

• *Concepts* describes the workings of the X3D runtime system.

• *Field type reference* describes the fundamental data types in X3D.

• *Conformance* describes the conformance requirements for X3D
implementations.

• *Core component* provides a detailed specification of the Core
component of X3D.

• *Time component* provides a detailed specification of the Time
component of X3D.

• *Networking component* provides a detailed specification of the
Networking component of X3D, including network-security precautions.

• *Grouping component* provides a detailed specification of the Grouping
component of X3D.

• *Rendering component* provides a detailed specification of the
Rendering component of X3D.

• *Shape component* provides a detailed specification of the Shape
component of X3D including advanced appearance and material
capabilities.

• *Geometry3D component* provides a detailed specification of the
Geometry3D component of X3D.

• *Geometry2D component* provides a detailed specification of the
Geometry2D component of X3D.

• *Text* provides a detailed specification of the Text component of X3D.

• *Sound component* provides a detailed specification of audio
generation and destinations, audio processing, spatialized sound, and
acoustic rendering.

• *Lighting component* defines lighting and shadow requirements for
visually rendering X3D models.

• *Texturing component* provides a detailed specification of the
Texturing component of X3D including advanced material characteristics.

• *Interpolation component* provides a detailed specification of the
Interpolation component of X3D.

• *Pointing device sensor component* provides a detailed specification
of the Pointing device sensor component of X3D.

• *Key device sensor component* provides a detailed specification of the
Key device sensor component of X3D.

• *Environmental sensor component* provides a detailed specification of
the Environmental sensor component of X3D.

• *Navigation component* provides a detailed specification of the
Navigation component of X3D.

• *Environmental effects component* provides a detailed specification of
the Environmental effects component of X3D.

• *Geospatial component* provides a detailed specification of the
Geospatial component of X3D.

• *Humanoid animation (HAnim) component* provides a detailed
specification of Humanoid structure and motion animation.

• *NURBS component* provides a detailed specification of the NURBS
component of X3D.

• *Distributed interactive simulation (DIS) component* provides a
detailed specification of the DIS component of X3D.

• *Scripting component* provides a detailed specification of the
Scripting component of X3D.

• *Event utilities component* provides a detailed specification of the
Event utilities component of X3D.

• *Shader component* provides a detailed specification of the Shader
component of X3D.

• *CAD geometry component* provides a detailed specification of the CAD
geometry component of X3D.

• *Texturing3D component* provides a detailed specification of the 3D
texturing component of X3D.

• *Cube mapenvironmental texturing component* provides a detailed
specification of the environmental texturing component of X3D.

• *Layering component* provides a detailed specification for organizing
the content of worlds into independent, overlapping layers.

• *Layout component* provides a detailed specification for arranging
content to appear in specific regions of the display surface.

• *Rigid body physics component* provides a detailed specification for
applying rigid body physics properties to content.

• *Picking sensor component* provides a detailed specification for
selecting items in the content by user interaction.

• *Followers component* provides a detailed specification for using
follower transitions.

• *Particle systems component* provides a detailed specification for
specifying and using particle systems in X3D worlds.

• *Volume rendering component* provides a detailed specification for the
rendering of volumetric data sets as part of X3D worlds.

• *Texture projection component* provides a detailed specification for
projecting textures as light onto geometry.

There are several annexes included in the specification:

[upperalpha]

• *Core profile* defines a minimal subset of X3D functionality that
constitutes the Core profile.

• *Interchange profile* defines the proper subset of X3D functionality
that constitutes the Interchange profile.

• *Interactive profile* defines the proper subset of X3D functionality
that constitutes the Interactive profile.

• *MPEG-4 interactive profile* defines the proper subset of X3D
functionality that constitutes the MPEG-4 interactive profile.

• *Immersive profile* defines the proper subset of X3D functionality
that corresponds to the base profile defined in ISO/IEC 14772-1.

• *Full profile* defines the proper subset of X3D functionality that
constitutes the Full profile.

• *Recommended navigation behaviours* specifies some recommended
behaviours that may be adopted by X3D browser implementers.

• *CADInterchange profile* defines the proper subset of X3D
functionality that constitutes the CADInterchange profile.

• *OpenGL shading language (GLSL) binding* provides a mapping of
Programmable shader component functionality to the GLSL shading
language.

• *Microsoft DirectX shading language (HLSL) binding* provides a mapping
of Programmable shader component functionality to the HLSL shading
language.

• *nVidia CG shading language binding* provides a mapping of
Programmable shader component functionality to the Cg shading language.

• *HTML authoring guidelines* describes suggested techniques for
integrating HTML Web pages with X3D content.

• *MedicalInterchange profile* defines the proper subset of X3D
functionality that constitutes the MedicalInterchange profile.

• *Version content* specifies which X3D functionality is in which
version.

*Bibliography* lists the informative, non-standard topics referenced in
this document.

*Component index* lists the available components defined in this
document in alphabetical order with hyperlinks to their respective
definitions.

*Profile index* lists the profiles defined in this document in
alphabetical order with hyperlinks to their respective definitions.

*Node, abstract node type, and abstract interface index* lists the nodes
defined in this document in alphabetical order with hyperlinks to their
respective definitions.

[[foreword_html]]
== Foreword

ISO (the International Organization for Standardization) and IEC (the
International Electrotechnical Commission) form the specialized system
for worldwide standardization. National bodies that are members of ISO
or IEC participate in the development of International Standards through
technical committees established by the respective organization to deal
with particular fields of technical activity. ISO and IEC technical
committees collaborate in fields of mutual interest. Other international
organizations, governmental and non-governmental, in liaison with ISO
and IEC, also take part in the work.

The procedures used to develop this document and those intended for its
further maintenance are described in the ISO/IEC Directives, Part 1. In
particular, the different approval criteria needed for the different
types of document should be noted. This document was drafted in
accordance with editorial rules of the ISO/IEC Directives, Part 2 (see
https://www.iso.org/directives[www.iso.org/directives] or
https://www.iec.ch/news-resources/reference-material[www.iec.ch]).

Attention is drawn to the possibility that some of the elements of this
document may be the subject of patent rights. ISO and IEC shall not be
held responsible for identifying any or all such patent rights. Details
of any patent rights identified during the development of the document
will be in the Introduction and/or on the ISO list of patent
declarations received (see https://www.iso.org/patents[www.iso.org]) or 
the IEC list of patent declarations received (see
https://patents.iec.ch[patents.iec.ch]).

Any trade name used in this document is information given for the
convenience of users and does not constitute an endorsement.

For an explanation of the voluntary nature of standards, the meaning of
ISO specific terms and expressions related to conformity assessment, as
well as information about ISO's adherence to the World Trade
Organization (WTO) principles in the Technical Barriers to Trade (TBT)
see https://www.iso.org/iso/foreword.html[www.iso.org/iso/foreword.html].
In the IEC see https://www.iec.ch/understanding-standards[www.iec.ch].

This document was prepared by Joint Technical Committee ISO/IEC JTC 1,
Information technology, Subcommittee 24, Computer graphics, image
processing and environmental data representation, in collaboration with
Web3D Consortium, Inc. (https://www.web3d.org[www.web3d.org]).

This fourth edition cancels and replaces the third edition (ISO
19775-1:2013), which has been technically revised. Major changes include

* Integration with HTML5 <<W3C-HTML5>> and Cascading
Style Sheets (CSS) <<W3C-CSS-Style>> in Web pages,
* Support for advanced lighting and rendering to match <<GLTF, 2.GLTF>>,
* Advanced audio rendering in accordance with Web Audio API
<<W3C-WebAudio>>, and
* Addition of <<textureProjection_html, Texture Projection component>>.

A list of all parts in the ISO 19775 series can be found on the ISO and
IEC websites.

Any feedback or questions on this document should be directed to the
user’s national standards body. A complete listing of these bodies can
be found at https://www.iso.org/members.html[www.iso.org/members.html] and
https://www.iec.ch/national-committees[www.iec.ch/national-committees].


[[Introduction_html]]
== Introduction

[[h-0.1]]
=== General

_Extensible 3D_ (X3D) is a software standard for defining interactive
web- and broadcast-based 3D content integrated with multimedia. X3D is
intended for use on a variety of hardware devices and in a broad range
of application areas such as engineering and scientific visualization,
multimedia presentations, entertainment and educational titles, web
pages, and shared virtual worlds. X3D is also intended to be a universal
interchange format for integrated 3D graphics and multimedia. X3D is the
successor to the Virtual Reality Modeling Language (VRML), the original
ISO standard for web-based 3D graphics (<<I14772_1, ISO/IEC 14772>>).
X3D improves upon VRML with new features, advanced application
programmer interfaces, additional data encoding formats, stricter
conformance, and a componentized architecture that allows for a modular
approach to supporting the standard.

This section describes the design objectives behind the development of
X3D and provides an overview of the features of X3D.

[[h-0.2]]
=== Design objectives

X3D has been developed to meet a specific set of market and technical
requirements. To meet these requirements, X3D has adopted the following
design objectives:

* Separate the runtime architecture from the data encoding,
* Support a variety of encoding formats, including the Extensible Markup
Language (XML),
* Add new graphical, behavioural and interactive objects,
* Provide alternative application programmer interfaces (APIs) into the
3D scene,
* Define subsets of the specification ("Profiles") that meet different
market needs,
* Allow for the specification to be implemented at varying levels of
service, and
* Eliminate, where possible, unspecified or underspecified behaviours.

[[h-0.3]]
=== X3D features

X3D has a rich set of features to support applications such as
engineering and scientific visualization, multimedia presentations,
entertainment and educational titles, web pages, and shared virtual
worlds. The X3D feature set includes:

* *3D graphics* - Polygonal geometry, parametric geometry, hierarchical
transformations, advanced materials and lighting for Physically Based
Rendering (PBR), multi-pass/multi-stage texture mapping,
* *2D graphics* - Text, 2D vector and planar shapes displayed within the
3D transformation hierarchy,
* *Animation* - Timers and interpolator to drive continuous animations;
humanoid animation and morphing,
* *Humanoid Animation* - full-fidelity representations of human skeleton
with motion animation,
* *Metadata* - comprehensive inclusion of typed metadata sets,
* *Spatialized audio and video* - Sound generation and rendering,
audiovisual sources mapped onto geometry in the scene, support for Web
Audio API <<W3C-WebAudio>> and <<MIDI-2, MIDI 2.0>>,
* *User interaction* - Mouse-based picking and dragging; keyboard input,
* *Navigation* - Cameras; user movement within the 3D scene; collision,
proximity and visibility detection,
* *User-defined objects* - Ability to extend built-in X3D browser
functionality by creating user-defined data types,
* *Scripting* - Ability to dynamically change the scene via programming
and scripting languages,
* *Networking* - Ability to compose a single X3D scene out of assets
located on a network; hyperlinking of objects to other scenes or assets
located on the World Wide Web; improved control of loading, refresh
rates and security,
* *Physical simulation* - Humanoid animation; geospatial datasets;
integration with Distributed Interactive Simulation (DIS) protocols,
* *Geospatial positioning* - Ability to accurately position X3D scene
objects geospatially.,
* *CAD geometry* – ability to represent CAD models mapped from CAD
systems.,
* *Layering* – Ability to organize X3D scenes into rendering groups so
that objects in each layer can overlay objects in underlying layers.,
* *Support for programmable shaders* – Ability to replace the X3D
lighting model with custom shader programs.,
* *Particle systems* – Ability to generate systems of particles that can
represent fire, smoke, and other such effects, and
* *Volume rendering* – Ability to specify and render volumetric data
sets, as used within medical imaging, for example.

For a complete list of X3D features, consult the component descriptions
in clauses 7 through 42 of this document.

[[scope_html]]
== 1 Scope

ISO/IEC 19775 Extensible 3D (X3D) defines a software system that
integrates network-enabled 3D graphics and multimedia. Conceptually,
each X3D application is a 3D time-based space that contains graphic and
aural objects that can be dynamically modified through a variety of
mechanisms. This document defines the architecture and base components
of X3D.

The semantics of X3D describe an abstract functional behaviour of
time-based, interactive 3D, multimedia information. This document does
not define physical devices or any other implementation-dependent
concepts ( _e.g._, screen resolution and input devices). This document
is intended for a wide variety of devices and applications, and provides
wide latitude in interpretation and implementation of the functionality.
For example, this document does not assume the existence of a mouse or
2D display device.

Each X3D application:

[loweralpha]
. implicitly establishes a world coordinate space for all objects
defined, as well as all objects included by the application,
. explicitly defines and composes a set of 3D and multimedia objects,
. can specify hyperlinks to other files and applications,
. can define programmatic or data-driven object behaviours,
. can connect to external modules or applications via programming and
scripting languages,
. explicitly declares its functional requirements by specifying a
profile, and
. can declare additional functional requirements by specifying
components.

[[references_html]]
== 2 Normative references

The following documents are referred to in the text in such a way that
some or all of their content constitutes requirements of this document.
For dated references, only the edition cited applies. For undated
references, the latest edition of the referenced document (including any
amendments) applies.

The <<bibliography_html, Bibliography>> contains a list of informative
documents and technology.

[options="header,autowidth",frame=ends,grid=rows]
|===
|Identifier |Reference

|[[I639]] *I639* a|
https://www.iso.org[ISO] 639, _Codes for the representation of names of
languages_:

ISO 639-1:2002, _Part 1: Alpha-2 code_ +
ISO 639-2:1998, _Part 2: Alpha-3 code_.

|[[I3166]] *I3166* a|
https://www.iso.org[ISO] 3166, _Codes for the representation of names of
countries and their subdivisions_:

ISO 3166-1, _Part 1: Country codes_ +
ISO 3166-2, _Part 2: Country subdivision code_ +
ISO 3166-3, _Part 3: Code for formerly used names of countries_.

|[[I8632]] *I8632* a|
https://www.iso.org[ISO/IEC] 8632, _Information technology — Computer
graphics — Metafile for the storage and transfer of picture description
information_:

ISO/IEC 8632-1:1999, _Part 1: Functional specification_

ISO/IEC 8632-3:1999, _Part 3: Binary encoding_

ISO/IEC 8632-4:1999, _Part 4: Clear text encoding_.

|[[I8859_1]] *I8859-1* |https://www.iso.org[ISO/IEC] 8859-1:1998,
_Information technology — 8-bit single-byte coded graphic character sets
— Part 1: Latin alphabet No. 1_.

|[[I9899]] *I9899* |https://www.iso.org[ISO/IEC] 9899:1999,
_Programming languages — C_.

|[[I9973]] *I9973* |https://www.iso.org[ISO/IEC] 9973:2006,
_Information technology — Computer graphics, image processing and
environmental representation — Procedures for registration of items_.

|[[I10641]] *I10641* |https://www.iso.org[ISO/IEC] 10641:1993,
_Information technology — Computer graphics and image processing —
Conformance testing of implementations of graphics standards_.

|[[I10646]] *I10646* |https://www.iso.org[ISO/IEC] 10646:2003,
_Information technology — Universal Multiple-Octet Coded Character Set
(UCS)_.

|[[I11172_1]] *I11172-1* |https://www.iso.org[ISO/IEC] 11172-1:1993,
_Information technology — Coding of moving pictures and associated audio
for digital storage media at up to about 1,5 Mbit/s — Part 1: Systems_.

|[[I14496_1]] *I14496-1* |https://www.iso.org[ISO/IEC] 14496-1:2010,
_Information technology —Coding of audio-visual objects — Part 1:
Systems_.

|[[I14496_14]] *I14496-14* |https://www.iso.org[ISO/IEC] 14496-14:2020,
_Information technology — Coding of audio-visual objects —   Part 14:
MP4 file format_

|[[I14772_1]] *I14772-1* |https://www.iso.org[ISO/IEC] 14772-1:1997,
_Information technology — Computer graphics and image processing — The
Virtual reality modeling language (VRML) — Part 1: Functional
specification and UTF-8 encoding_.

|[[I15948]] *I15948* |https://www.iso.org[ISO/IEC] 15948:2004,
_Information technology — Computer graphics — PNG (Portable Network
Graphics): Functional specification_.

|[[I16262]] *I16262* |https://www.iso.org[ISO/IEC] 16262:2011,
_Information technology — ECMAScript language specification_.

|[[I18026]] *I18026* |https://www.iso.org[ISO/IEC] 18026:2006,
_Information technology — Spatial Reference Model (SRM)_.

|[[I19774]] *I19774* |https://www.iso.org[ISO/IEC] 19774:2019,
_Information technology — Computer graphics and image processing —
Humanoid Animation (HAnim) Parts 1 and 2_.

|[[I19775_2]] *I19775-2* |https://www.iso.org[ISO/IEC] 19775-2,
_Information technology — Computer graphics, image processing and
environmental data representation — Extensible 3D (X3D) Part 2: Scene
access interface (SAI)_.

|[[I19776]] *I19776* |https://www.iso.org[ISO/IEC] 19776, _Information
technology — Computer graphics, image processing and environmental data
representation — Extensible 3D (X3D) file encodings_. +
  ISO/IEC 19776-1, _Part 1: Extensible Markup Language (XML) encoding_ +
  ISO/IEC 19776-2, _Part 2: Classic VRML encoding_ +
  ISO/IEC 19776-3, _Part 3: Compressed binary encoding_

|[[I19777]] *I19777* |https://www.iso.org[ISO/IEC] 19777, _Information
technology — Computer graphics, image processing and environmental data
representation — Extensible 3D (X3D) language bindings_. +
  ISO/IEC 19777-1, _Part 1: ECMAScript_ +
  ISO/IEC 19777-2, _Part 2: Java_

|[[I80000]] *I80000* |https://www.iso.org[ISO] 80000, _Quantities and
Units_ +
  ISO 80000-1:2009, _Part 1: General_ +
  ISO 80000-2:2009, _Part 2: Mathematical signs and symbols to be used
in the natural sciences and technology_ +
  ISO 80000-3:2006, _Part 3: Space and time_ +
  ISO 80000-4:2006, _Part 4: Mechanics_ +
  ISO 80000-5:2007, _Part 5: Thermodynamics_ +
  ISO 80000-6:2008, _Part 6: Electromagnetism_ +
  ISO 80000-7:2008, _Part 7: Light_ +
  ISO 80000-8:2007, _Part 8: Acoustics_ +
  ISO 80000-9:2009, _Part 9: Physical chemistry and molecular physics_ +
  ISO 80000-10:2009, _Part 10: Atomic and nuclear physics_ +
  ISO 80000-11:2008, _Part 11: Characteristic numbers_ +
  ISO 80000-12:2009, _Part 12: Solid state physics_ +
  ISO 80000-13:2008, _Part 13: Information science and technology_ +
  ISO 80000-14:2008, _Part 14: Telebiometrics related to human
physiology_

|[[DICOM]] *DICOM* |_The DICOM Standard_, Digital Imaging and
Communications in Medicine, Rosslyn, VA, 2003. +
https://www.dicomstandard.org

|[[glTF]] *GLTF* |_GL Transmission Format (glTF) Specification_, The
Khronos Group, Version 2.0, 2021. +
https://github.com/KhronosGroup/glTF/tree/master/specification/2.0

|[[IEEE1278]] *IEEE1278* |https://standards.ieee.org[IEEE] Standard
1278.1-2012, _Standard for Distributed Interactive Simulation(DIS)—
Application Protocols, 2012_. +
https://standards.ieee.org[IEEE] Standard 1278.2-2015, _Standard for
Distributed Interactive Simulation(DIS)— Communication Services and
Profiles, 2015_. +
https://standards.ieee.org[IEEE] Standard 1278.3-1996, _Recommended
Practice for Distributed Interactive Simulation(DIS)— Exercise
Management and Feedback, 1997_. +
https://standards.ieee.org[IEEE] Standard 1278.4-1997, _Recommended
Practice for Distributed Interactive Simulation(DIS)— Verification,
Validation, and Accreditation, 1997_.

|[[JAVA]] *JAVA* |https://docs.oracle.com/en/java/javase[Java Language
and Virtual Machine Specifications], Java Platform Standard Edition
Documentation, Oracle Corporation, 2023.

|[[JPEG]] *JPEG* |_JPEG File Interchange Format, JFIF_, Version 1.02,
1992. +
https://www.w3.org/Graphics/JPEG/jfif.txt +
https://www.iso.org[ISO/IEC] 10918-1:1994, _Information technology —
Digital compression and coding of continuous-tone still images:
Requirements and guidelines_.

|[[MIDI-1]] *MIDI1.0* |_Complete MIDI 1.0 Detailed Specification v96.1
(second edition)_, MIDI Association, 2001. +
https://www.midi.org/specifications-old/item/the-midi-1-0-specification

|[[MIDI-2]] *MIDI 2.0* |_Details about MIDI 2.0™, MIDI-CI, Profiles and
Property Exchange_, MIDI Association, 2020. +
https://www.midi.org/specifications

|*[[REG]] REG* |_ISO International Register of Graphical Items_,
ISO/IEC JTC 1/SC 24, ISO/IEC 9973 Items Register. +
https://www.iso.org/jtc1/sc24/register

|[[RFC768]] *RFC768* |https://www.ietf.org/rfc/rfc768.txt[IETF RFC 768]
STD 64, _User Datagram Protocol (UDP)_, INTERNET STANDARD.

|[[RFC2077]] *RFC2077* |http://www.rfc-editor.org/info/rfc2077[IETF RFC
2077], _The Model Primary Content Type for Multipurpose Internet Mail
Extensions_.

|[[RFC2397]] *RFC2397* |https://www.rfc-editor.org/info/rfc2397[IETF
RFC 2397], _The "data" URL scheme_, PROPOSED STANDARD.

|[[RFC3541]] *RFC3541* |https://www.rfc-editor.org/info/rfc3541[IETF
RFC 3541], _A Uniform Resource Name (URN) Namespace for the Web3D
Consortium (Web3D)_.

|[[RFC3550]] *RFC3550* 
|https://www.rfc-editor.org/info/rfc3550[IETF RFC 3550 STD 64], _RTP: A
Transport Protocol for Real-Time Applications_, INTERNET STANDARD.

|[[RFC5646]] *RFC5646* |https://www.rfc-editor.org/info/rfc5646[IETF
RFC 5646 BCP 47], _Tags for Identifying Languages_.

|[[RFC7231]] *RFC7231* |https://www.rfc-editor.org/info/rfc7231[IETF
RFC 7231], _Hypertext Transfer Protocol (HTTP/1.1): Semantics and
Content_.

|[[RFC8089]] *RFC8089* 
|https://www.rfc-editor.org/info/rfc8089[IETF RFC 8089], _The "file" URI
Scheme_, PROPOSED STANDARD.

|[[RFC8141]] *RFC8141* 
|https://www.rfc-editor.org/info/rfc8141[IETF RFC 8141], _Uniform
Resource Names (URNs)_, PROPOSED STANDARD.

|[[SISO]] *SISO* |https://SISOstds.org[Simulation Interoperability
Standards Organization (SISO)] SISO-REF-010-2023, _Reference for
Enumerations for Simulation Interoperability,2023_.

|[[URI_]] *URI* 
|https://www.rfc-editor.org/info/rfc3986[IETF RFC 3986 STD 66],
_Universal Resource Identifiers (URI)_, INTERNET STANDARD.

|[[W3C-WebAudio]] *W3C-WebAudio* |https://www.w3.org/TR/webaudio[Web
Audio API], _World Wide Web Consortium (W3C)Recommendation, 17 June
2021_.

|[[W3C-Media]] *W3C-Media*
|https://www.w3.org/TR/mediacapture-streams[Media Capture and Streams],
_World Wide Web Consortium (W3C) Candidate Recommendation Draft,3
February 2023_.

|[[W3C-WebMIDI]] *W3C-WebMIDI*
|https://webaudio.github.io/web-midi-api[Web MIDI API], _World Wide Web
Consortium (W3C) Editor's Draft,14 September 2022_.
|===

[[glossary_html]]
== 3 Definitions, acronyms, and abbreviations

[[Definitions]]
=== 3.1 Definitions

For the purposes of this document , the following definitions apply.

ISO and IEC maintain terminology databases for use in standardization at
the following addresses:

* ISO Online browsing platform: available at
https://www.iso.org/obp[www.iso.org/obp]
* IEC Electropedia: available at
https://www.electropedia.org[www.electropedia.org]

[[Activate]]
==== 3.1.1 activate

cause a _<<SensorNode, sensor node>>_ to generate an _isActive_
_<<Event, event>>_

[[Ancestor]]
==== 3.1.2 ancestor

_<<Node, node>>_ which is an antecedent of another node in the
_<<TransformationHierarchy, transformation hierarchy>>_

[[AudioGraph]]
==== 3.1.3 audio graph

structured collection of nodes that process audio inputs and outputs

[[Author]]
==== 3.1.4 author

person or agent that creates _<<X3DFile, X3D files>>_

[[AuthoringTool]]
==== 3.1.5 authoring tool

See _<<Generator, generator>>_.

[[Avatar]]
==== 3.1.6 avatar

abstract representation of the _<<User, user>>_ in an X3D
_<<World, world>>_

[[Bearing]]
==== 3.1.7 bearing

straight line passing through the _<<Pixel, pointer>>_ location in the
direction of the pointer

[[BindingNode]]
==== 3.1.8 bindable node

_<<Node, node>>_ that may have many _<<Instance, instances>>_ in a
_<<SceneGraph, scene graph>>_ but only one instance may be active at
any instant of _<<Time, time>>_

[[Browser]]
==== 3.1.9 browser

computer program that interprets _<<X3DFile, X3D files>>_, presents
their content to a _<<User, user>>_ on a _<<DisplayDevice, display device>>_, 
and allows the user to interact with _<<World, worlds>>_
defined by X3D files by means of a user interface

[[BrowserExtension]]
==== 3.1.10 browser extension

<<Node, _nodes_>> defined using the prototyping mechanism that are
understood only by certain _<<Browser, browsers>>_

[[Built-InNode]]
==== 3.1.11 built-in node

_<<Node, node>>_ of a _<<NodeType, type>>_ explicitly defined in
this document

[[Callback]]
==== 3.1.12 callback

function defined in a _<<ScriptingLanguage, scripting language>>_ to
which _<<Event, events>>_ are passed

[[Child]]
==== 3.1.13 child

instance of a _<<ChildrenNode, children node>>_

[[ChildrenNode]]
==== 3.1.14 children node

one of a set of __<<NodeType, node type>>__s, instances of which can
be collected in a group to share specific properties dependent on the
type of the _<<GroupingNode, grouping node>>_

[[ClientSystem]]
==== 3.1.15 client system

computer system, attached to a _<<Network, network>>_, that relies on
another computer (the server) for essential processing functions

[[CollisionProxy]]
==== 3.1.16 collision proxy

_<<Node, node>>_ used as a substitute for all of a Collision node's
children during collision detection

[[ColourModel]]
==== 3.1.17 colour model

characterization of a colour space in terms of explicit parameters

[[Culling]]
==== 3.1.18 culling

process of identifying _<<Object, objects>>_ or parts of objects which
do not need to be processed further by the _<<Browser, browser>>_ in
order to produce the desired view of a _<<World, world>>_

[[Descendent]]
==== 3.1.19 descendant

_<<Node, node>>_ which descends from another node in the
_<<TransformationHierarchy, transformation hierarchy>>_ (a
_<<ChildrenNode, children node>>_)

[[DisplayDevice]]
==== 3.1.20 display device

graphics device on which X3D _<<World, worlds>>_ may be rendered

[[DragSensor]]
==== 3.1.21 drag sensor

_<<PointingDeviceSensor, pointing device sensor>>_ that causes
_<<Event, events>>_ to be generated in response to sensor-dependent
pointer motions

[[EnvironmentalSensor]]
==== 3.1.22 environmental sensor

sensor _<<Node, node>>_ that generates _<<Event, events>>_ based on
the location of the viewpoint in the _<<World, world>>_ or in relation
to _<<Object, objects>>_ in the world

[[Event]]
==== 3.1.23 event

message sent from one _<<Node, node>>_ to another as defined by a
<<ROUTE>>

[[EventCascade]]
==== 3.1.24 event cascade

sequence of _<<Event, events>>_ initiated by a script or sensor event
and propagated from _<<Node, node>>_ to node along one or more
<<ROUTE, _routes_>> all of which are considered to have occurred
simultaneously

(see Concepts, <<ExecutionModel, 4.4.8.3 Execution model>>)

[[ExecutionModel]]
==== 3.1.25 execution model

rules governing how _<<Event, events>>_ are processed by
_<<Browser, browsers>>_ and scripts

[[ExternalPrototype]]
==== 3.1.26 external prototype

_<<Prototype, prototype>>_ defined in an external file and referenced
by a _<<URL>>_

[[Field]]
==== 3.1.27 field

property or attribute of a _<<Node, node>>_

[[FieldName]]
==== 3.1.28 field name

identifier of a _<<Field, field>>_

[[Frame]]
==== 3.1.29 frame

single rendering of a _<<World, world>>_ on a
_<<DisplayDevice, display device>>_ or a single time-step in a
simulation

[[Generator]]
==== 3.1.30 generator

computer program which creates _<<X3DFile, X3D files>>_

[[GeometricPropertyNode]]
==== 3.1.31 geometric property node

_<<Node, node>>_ defining the properties of a specific geometry node

[[GeometryNode]]
==== 3.1.32 geometry node

_<<Node, node>>_ containing mathematical descriptions of points,
lines, surfaces, text strings and solids

[[Grab]]
==== 3.1.33 grab

receive _<<Event, events>>_ from activated
<<PointingDevice, pointing devices>>

[[GroupingNode]]
==== 3.1.34 grouping node

one of a set of _<<NodeType, node types>>_ which include a list of
nodes, referred to as its _<<ChildrenNode, children nodes>>_

[[HostApplication]]
==== 3.1.35 host application

client application with which the _<<Browser, browser>>_ communicates
using the SAI

[[Image]]
==== 3.1.36 image

two-dimensional (2D) rectangular array of pixel values

[[Immersive]]
==== 3.1.37 immersive

creating the illusion of being inside a computer-generated scene

[[In-lining]]
==== 3.1.38 in-lining

mechanism by which one _<<X3DFile, X3D file>>_ is hierarchically
included in another

[[Instance]]
==== 3.1.39 instance

the <<Node, _node_>> created by an instantiation

[[Instantiation]]
==== 3.1.40 instantiation

the creation of a <<Node, _node_>> based on its _<<NodeType, node type>>_

[[InterpolatorNode]]
==== 3.1.41 interpolator node

_<<Node, node>>_ that defines a piece-wise or smoothly continuous
interpolation

[[Intranet]]
==== 3.1.42 intranet

private _<<Network, network>>_ that uses the same protocols and
standards as the Internet

[[LevelOfDetail]]
==== 3.1.43 level of detail

amount of detail or complexity which is displayed at any particular
_<<Time, time>>_ for any particular _<<Object, object>>_

[[LineTerminator]]
==== 3.1.44 line terminator

linefeed character (0x0A) and/or carriage return character (0x0D)

[[Loop]]
==== 3.1.45 loop

sequence of _<<Event, events>>_ which would result in a specific event
generator sending more than one event with the same
_<<Timestamp, timestamp>>_

[[Multimedia]]
==== 3.1.46 multimedia

integrated presentation, typically on a computer, of content of various
types, such as computer graphics, audio, and video

[[Network]]
==== 3.1.47 network

set of interconnected computers

[[Node]]
==== 3.1.48 node

fundamental component of a _<<SceneGraph, scene graph>>_ that defines
model information, such as graph structure, geometry, animation,
interaction, object metadata, rendering, or display

[[NodeType]]
==== 3.1.49 node type

characteristic of each _<<Node, node>>_ that describes, in general,
its particular semantics

[[Object]]
==== 3.1.50 object

collection of data and procedures, packaged according to the rules and
syntax defined in this document

NOTE:  This term is usually synonymous with _<<Node, node>>_.

[[OrderOfPreference]]
==== 3.1.51 order of preference

order (specified by the user) in which a list of _<<Field, field>>_
values is processed by the _<<Browser, browser>>_

[[Panorama]]
==== 3.1.52 panorama

background texture that is placed behind all geometry in the scene and
in front of the ground and sky

[[Parent]]
==== 3.1.53 parent

_<<Node, node>>_ which is an instance of a
_<<GroupingNode, grouping node>>_

[[Pixel]]
==== 3.1.54 pixel

one element of an <<Image, image>> specified as a matrix of colour
elements

[[Pointer]]
==== 3.1.55 pointer

location and direction in the _<<VirtualWorld, virtual world>>_
defined by the _<<PointingDevice, pointing device>>_ with which the
_<<User, user>>_ is currently interacting with the virtual world

[[PointingDevice]]
==== 3.1.56 pointing device

hardware device connected to the _<<User, user's>>_ computer by which
the user directly controls the location and direction of the
_<<Pixel, pointer>>_

[[PointingDeviceSensor]]
==== 3.1.57 pointing device sensor

sensor _<<Node, node>>_ that generates _<<Event, events>>_ based on
_<<User, user>>_ actions, such as _<<PointingDevice, pointing device>>_ 
motions or button activations

[[Polyline]]
==== 3.1.58 polyline

piecewise linear curve

[[Profile]]
==== 3.1.59 profile

named collection of criteria for functionality and conformance that
defines an implementable subset of a standard

[[Prototype]]
==== 3.1.60 prototype

definition of a new _<<NodeType, node type>>_ in terms of the
_<<Node, nodes>>_ defined in this document

[[Prototyping]]
==== 3.1.61 prototyping

mechanism for extending the set of _<<NodeType, node types>>_ from
within a _<<X3DFile, X3D file>>_

[[Route]]
==== 3.1.62 ROUTE

connection between a _<<Node, node>>_ generating an
_<<Event, event>>_ and a node receiving the event

[[SceneGraph]]
==== 3.1.63 scene graph

ordered set of _<<Node, nodes>>_ and _<<Statement, statements>>_

[[S3_Script]]
==== 3.1.64 script

set of procedural functions normally executed as part of an
_<<EventCascade, event cascade>>_

[[Scripting]]
==== 3.1.65 scripting

process of creating or referring to a script

[[ScriptingLanguage]]
==== 3.1.66 scripting language

system of syntactical and semantic constructs used to define and
automate procedures and processes on a computer

[[SensorNode]]
==== 3.1.67 sensor node

_<<Node, node>>_ that enables the _<<User, user>>_ to interact with
the _<<World, world>>_ in the scene graph hierarchy

[[SeparatorCharacter]]
==== 3.1.68 separator character

_<<UTF-8>>_ character used to separate syntactical entities in
an _<<X3DFile, X3D file>>_

[[Sibling]]
==== 3.1.69 sibling

_<<Node, node>>_ which shares a _<<Parent, parent>>_ with other
nodes

[[SimulationTick]]
==== 3.1.70 simulation tick

smallest time unit capable of being identified in a digital simulation
of analog time

[[slerp]]
==== 3.1.71 slerp

_<<slerp, spherical linear interpolation>>_ for animating 3D rotation
values

[[SpecialGroupNode]]
==== 3.1.72 special group node

_<<GroupingNode, grouping node>>_ that exhibits special behaviour (
_e.g._, Switch or LOD)

[[Statement]]
==== 3.1.73 statement

A statement specifies fundamental scene-related information

[[Texel]]
==== 3.1.74 texel

<<Pixel, pixel>> in an <<Image, image>> used as a
<<Texture, texture>>

[[Texture]]
==== 3.1.75 texture

_<<Immersive, image>>_ used to create visual appearance effects when
applied to _<<GeometryNode, geometry nodes>>_

[[S3_TextureCoordinates]]
==== 3.1.76 texture coordinates

set of coordinates used to map a texture to geometry

[[Time]]
==== 3.1.77 time

monotonically increasing value generated by a _<<Node, node>>_

[[Timestamp]]
==== 3.1.78 timestamp

that part of an _<<Event, event>>_ that describes the time the
_<<Event, event>>_ occurred and that caused the message to be sent

[[S3_TransformationHierarchy]]
==== 3.1.79 transformation hierarchy

subset of the _<<SceneGraph, scene graph>>_ consisting of
_<<Node, nodes>>_ that have well-defined coordinate systems

==== 3.1.80 transparency chunk

section of a PNG file containing transparency information (derived from
<<I15948, ISO/IEC 15948>>)

[[Traverse]]
==== 3.1.81 traverse

process the _<<Node, nodes>>_ in a _<<SceneGraph, scene graph>>_ in
the correct order

[[User]]
==== 3.1.82 user

person or agent who uses and interacts with _<<X3DFile, X3D files>>_
by means of a _<<Browser, browser>>_

[[Viewer]]
==== 3.1.83 viewer

location, direction, and viewing angle in a _<<VirtualWorld, virtual world>>_ 
that determines the portion of the virtual world presented by
the _<<Browser, browser>>_ to the _<<User, user>>_

[[VirtualWorld]]
==== 3.1.84 virtual world

See _<<World, world>>_.

[[WhiteSpace]]
==== 3.1.85 white space

one or more consecutive occurrences of a
_<<SeparatorCharacter, separator character>>_

[[World]]
==== 3.1.86 world

collection of one or more _<<X3DFile, X3D files>>_ (potentially
including other multimedia content) that is interpreted by an
_<<X3DBrowser, X3D browser>>_ to present an interactive experience to
the _<<User, user>>_ that is consistent with the intent of the
_<<Author, author>>_

[[WorldCoordinateSpace]]
==== 3.1.87 world coordinate space

coordinate system in which each X3D _<<World, world>>_ is defined

[[X3DBrowser]]
==== 3.1.88 X3D browser

See _<<Browser, browser>>_.

[[X3DDocumentServer]]
==== 3.1.89 X3D document server

computer program that locates and transmits __<<X3DFile, X3D file>>__s
and supporting files in response to requests from
_<<Browser, browsers>>_

[[X3DFile]]
==== 3.1.90 X3D file

set of X3D _<<Node, nodes>>_ and _<<Statement, statements>>_ as
defined in this document

[[XYPlane]]
==== 3.1.91 XY plane

plane perpendicular to the Z-axis that passes through the point Z = 0.0

[[YZPlane]]
==== 3.1.92 YZ plane

plane perpendicular to the X-axis that passes through the point X = 0.0

[[ZXPlane]]
==== 3.1.93 ZX plane

plane perpendicular to the Y-axis that passes through the point Y = 0.0

[[AcronymsAndAbbreviations]]
=== 3.2 Acronyms and abbreviated terms

For the purposes of this document, the following expansion of acronyms
and abbreviated terms apply:

[[CAD]]
==== 3.2.1 CAD

Computer-Assisted Design

[[HSV]]
==== 3.2.2 HSV

Hue, Saturation, and Value colour model

<<FOLEY>>

[[JPEG_]]
==== 3.2.3 JPEG

Joint Photographic Experts Group

<<JPEG, ISO/IEC 10918-1>>

[[MIDI]]
==== 3.2.4 MIDI

Musical Instrument Digital Interface. A standard for digital music
representation

<<MIDI>>

[[MIME]]
==== 3.2.5 MIME

Multipurpose Internet Mail Extension

<<RFC2077, IETF RFC2077>>

[[MF]]
==== 3.2.6 MF

Multiple-valued field

(see Field type reference, <<X3DArrayField, 5.2.2 X3DArrayField>>)

[[MPEG]]
==== 3.2.7 MPEG

Moving Picture Experts Group

<<I11172_1, ISO/IEC 11172-1>>

[[PNG]]
==== 3.2.8 PNG

Portable Network Graphics. A specification for representing
two-dimensional images in files

<<I15948, ISO/IEC 15948>>

[[RGB]]
==== 3.2.9 RGB

Red, Green, and Blue colour model

<<FOLEY>>

[[RURL]]
==== 3.2.10 RURL

Relative Uniform Resource Locator

<<URI>>

[[SAI]]
==== 3.2.11 SAI

Scene Access Interface

[[SF]]
==== 3.2.12 SF

Single-valued field

(see Field type reference, <<X3DField, 5.2.3 X3DField>>)

[[UCS]]
==== 3.2.13 UCS

Universal multiple-octet coded Character Set

<<I10646, ISO/IEC 10646>>

[[URI]]
==== 3.2.14 URI

Universal Resource Identifier

<<URI_>>

[[URL]]
==== 3.2.15 URL

Uniform Resource Locator

<<URI_>> <<RFC1738, RFC8089>>

[[URN]]
==== 3.2.16 URN

Universal Resource Name

<<RFC8141>>

[[UTF-8]]
==== 3.2.17 UTF-8

variable-length 8-bit Universal multiple-octet coded character set
Transformation Format

<<I10646, ISO/IEC 10646>>


[[S4_Concepts]]
== 4 Concepts

[[S4_General]]
=== 4.1 General

[[S4_Topics]]
==== 4.1.1 Topics in this clause

This clause describes the X3D core concepts, including how X3D scenes
are authored and played back, the run-time semantics of the X3D scene,
modularization through components and profiles, conformance via support
levels, data encoding semantics, programmatic access, and networking
considerations.

<<t4_1, Table 4.1>> provides links to the major topics in this
clause.

[[t4_1]]
Table 4.1 — Topics

* <<S4_General, 4.1 General>>
** <<S4_Topics, 4.1.1 Topics in this clause>>
** <<TopicsOverview, 4.1.2 Overview>>
** <<Conventions, 4.1.3 Conventions used>>
* <<Authoring, 4.2 Authoring and playback>>
** <<X3Dbrowsers, 4.2.1 X3D browsers>>
** <<X3Dgenerators, 4.2.2 X3D generators>>
** <<X3DLoaders, 4.2.3 X3D loaders>>
* <<scenegraph, 4.3 The scene graph>>
** <<TheSceneGraphOverview, 4.3.1 Overview>>
** <<Rootnodes, 4.3.2 Root nodes>>
** <<Scenegraphhierarchy, 4.3.3 Scene graph hierarchy>>
** <<Descendantandancestornodes, 4.3.4 Descendant and ancestor nodes>>
** <<S4_TransformationHierarchy, 4.3.5 Transformation hierarchy>>
** <<Standardunitscoordinates, 4.3.6 Standard units and coordinate system>>
** <<Behaviourgraph, 4.3.7 Behaviour graph>>
* <<Runtimeenvironment, 4.4 Run-time environment>>
** <<RuntimeOverview, 4.4.1 Overview>>
** <<Objectmodel, 4.4.2 Object model>>
*** <<ObjectmodelOverview, 4.4.2.1 Overview>>
*** <<FieldSemantics, 4.4.2.2 Field semantics>>
*** <<InterfaceHierarchy, 4.4.2.3 Interface hierarchy>>
*** <<Modifyingobjects, 4.4.2.4 Modifying objects>>
**** <<ModifyingObjectsRoutes, 4.4.2.4.1 Routes>>
**** <<ModifyingObjectsViaProgrammaticAccess, 4.4.2.4.2 Modifying objects via programmatic access>>
*** <<Objectlifecycle, 4.4.2.5 Object life cycle>>
** <<DEF_USE_Semantics, 4.4.3 DEF/USE semantics>>
** <<PrototypeSemantics, 4.4.4 Prototype semantics>>
*** <<PrototypeSemanticsIntro, 4.4.4.1 Introduction>>
*** <<PROTOinterfacedeclsemantics, 4.4.4.2 PROTO interface declaration semantics>>
*** <<PROTOdefinitionsemantics, 4.4.4.3 PROTO definition semantics>>
*** <<Prototypescopingrules, 4.4.4.4 Prototype scoping rules>>
** <<Externalprototypesemantics, 4.4.5 External prototype semantics>>
*** <<ExternalprototypeIntro, 4.4.5.1 Introduction>>
*** <<EXTERNPROTOInterfaceSemantics, 4.4.5.2 EXTERNPROTO interface semantics>>
*** <<EXTERNPROTOURLSemantics, 4.4.5.3 EXTERNPROTO URL semantics>>
** <<ImportExportsemantics, 4.4.6 Import/Export semantics>>
** <<Runtimenamescope, 4.4.7 Run-time name scope>>
** <<S4_Eventmodel, 4.4.8 Event model>>
*** <<Events, 4.4.8.1 Events>>
*** <<Routes, 4.4.8.2 Routes>>
*** <<ExecutionModel, 4.4.8.3 Execution model>>
*** <<Loops, 4.4.8.4 Loops>>
*** <<Fan-inFan-out, 4.4.8.5 Fan-in and fan-out>>
* <<Components, 4.5 Components>>
** <<ComponentsOverview, 4.5.1 Overview>>
** <<DefiningComponents, 4.5.2 Defining components>>
** <<Basecomponents, 4.5.3 Base components>>
* <<Profiles, 4.6 Profiles>>
** <<ProfilesOverview, 4.6.1 Overview>>
** <<Definingprofiles, 4.6.2 Defining profiles>>
** <<RelationshipBetweenProfilesAndComponents, 4.6.3 Relationship between profiles and components>>
* <<S4_SupportLevels, 4.7 Support levels>>
* <<Dataencodings, 4.8 Data encodings>>
* <<SceneAccessInterface, 4.9 Scene access interface (SAI)>>
* <<Componentprofilereg, 4.10 Component and profile registration>>
* <<f-X3DArchitecture, Figure 4.1 — X3D Architecture>>
* <<f-Objecthierarchy, Figure 4.2 — Interface hierarchy>>
* <<f-ConceptualExecutionModel, Figure 4.3 — Conceptual execution model>>
* <<t4_1, Table 4.1 — Topics>>
* <<t4_2, Table 4.2 — Standard units>>
* <<t4_3, Table 4.3 — Derived units>>
* <<t4_4, Table 4.4 — Rules for mapping PROTOTYPE declarations to node instances>>
* <<t4_5, Table 4.5 — Example support level table>>



[[TopicsOverview]]
==== 4.1.2 Overview

Conceptually, each X3D application is a 3D time-based space that
contains graphic and aural objects that can be loaded over a network and
dynamically modified through a variety of mechanisms. The semantics of
X3D describe an abstract functional behaviour of time-based, interactive
3D, multimedia information. X3D does not define physical devices or any
other implementation-dependent concepts ( _e.g._, screen resolution and
input devices). X3D is intended for a wide variety of devices and
applications, and provides wide latitude in interpretation and
implementation of the functionality. For example, X3D does not assume
the existence of a mouse or 2D display device.

Each X3D application:

[loweralpha]
. implicitly establishes a world coordinate space for all objects
defined, as well as all objects included by the application;
. explicitly defines and composes a set of 2D, 3D and multimedia
objects;
. can specify hyperlinks to other files and applications;
. can define object behaviours;
. can connect to external modules or applications via programming and
scripting languages.

The X3D system architecture is shown in <<f-X3DArchitecture, Figure 4.1>>.

[[f-X3DArchitecture]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/X3DArchitecture.png[X3D Architecture]

Figure 4.1 — X3D architecture

The abstract structure of the sequence of nodes and statements that
together form an X3D world is specified in
<<AbstractX3DStructure, 7.2.5 Abstract X3D structure>>.

X3D browsers can also exist within an HTML page rendered by an HTML
browser, handling events in either an integrated or independent manner.
See <<htmlGuidelines_html, Annex L HTML authoring guidelines>> for
details.

[[Conventions]]
==== 4.1.3 Conventions used

The following conventions are used throughout this document:

_Italics_ are used for field names, and are also used when new terms are
introduced and equation variables are referenced.

A `fixed-space` font is used for URL addresses and source code
examples.

Node type names are appropriately capitalized ( _e.g._, "The Billboard
node is a grouping node..."). However, the concept of the node is often
referred to in lower case in order to refer to the semantics of the
node, not the node itself ( _e.g._, "To rotate the billboard...").

The form "0xhh" expresses a byte as a hexadecimal number representing
the bit configuration for that byte.

Throughout this document, references to International Standards cite the
number of the standard and hyperlinks to the reference in
<<references_html, 2 Normative references>>. References to portions of
this document consist of the clause or subclause number followed by the
title of the clause or subclause. The text consisting of the number and
title is hyperlinked to the referenced material. References to external
documents that are not International Standards are denoted using the
"x.[ABCD]" notation, where "x" denotes in which clause the reference is
described and "[ABCD]" is an abbreviation of the reference title. For
the Bibliography, the "x." is omitted.

In addition, the first reference to a node or node type in a subclause
will be hyperlinked to the definition of that node or node type.

EXAMPLE  "[ABCD]" refers to a reference described in
<<references_html, 2 Normative references>> and [ABCD] refers to a
reference described in the <<bibliography_html, Bibliography>>.

[[Authoring]]
=== 4.2 Authoring and playback

[[X3Dbrowsers]]
==== 4.2.1 X3D browsers

The interpretation, execution, and presentation of X3D files occurs
using a mechanism known as a _browser_, which displays the shapes and
sounds in the scene graph. This presentation is known as a _virtual
world_ and is navigated in the X3D browser by a human or mechanical
entity, known as a _user_. The world is displayed as if experienced from
a particular location; that position and orientation in the world is
known as the _viewer_. The X3D browser may provide navigation paradigms
(such as walking or flying) that enable the user to move the viewer
through the virtual world.

In addition to navigation, the X3D browser provides a limited mechanism
allowing the user to interact with the world through sensor nodes in the
scene graph hierarchy. Sensors respond to user interaction with
geometric objects in the world, the movement of the user through the
world, or the passage of time. Additionally, the X3D Scene Access
Interface (SAI) defined in <<I19775_2, Part 2 ofthis document>>
provides mechanisms for getting user input, and for getting and setting
the current viewpoint. To provide navigation capabilities, a viewer may
use the SAI to provide the user with the ability to navigate.
Additionally, authors may use scripting or programming languages with
bindings to the SAI to implement their own navigation algorithms. Other
profiles may specify navigation capabilities as a requirement of the
viewer; implementations of such viewers will typically do so by making
use of the SAI.

The visual presentation of geometric objects in an X3D world follows a
conceptual model designed to resemble the physical characteristics of
light. The X3D lighting model describes how appearance properties and
lights in the world are combined to produce displayed colours (see
<<lighting_html, 17 Lighting component>> for details).

[[X3Dgenerators]]
==== 4.2.2 X3D generators

A _generator_ is a human or computerized creator of X3D files. It is the
responsibility of the generator to ensure the correctness of the X3D
file and the availability of supporting assets ( _e.g._, images, audio
clips, other X3D files) referenced therein. It is also the
responsibility of the generator to insure that the functionality
represented in the X3D file is correctly stated in the profile,
component and level information in the header statement of the file.

[[X3DLoaders]]
==== 4.2.3 X3D loaders

A _loader_ is a program responsible for loading X3D content but does not
apply any run-time execution to the content. Geometry is presented as
though time has not run, although the loader is free to load textures
and other remotely defined content. A time zero loader is typically
found in modelling tools that intend to construct or modify existing X3D
content without evaluating the run-time aspects of the specification.

A second form of loader may load files and allow run-time execution of
content, but it does so as part of a larger user interface and 3D
graphics rendering engine. Such loaders might be used to load individual
models such as trees in a game environment, but the run-time evaluation
of the X3D content is dependent on the external application, and is not
self contained in the same fashion as an X3D browser.

[[scenegraph]]
=== 4.3 The scene graph

[[TheSceneGraphOverview]]
==== 4.3.1 Overview

The basic unit of the X3D run-time environment is the _scene graph_.
This structure contains all the objects in the system and their
relationships. Relationships are contained along several axes of the
scene graph. The _transformation hierarchy_ describes the spatial
relationship of rendering objects. The _behavior graph_ describes the
connections between fields and the flow of events through the system.

[[Rootnodes]]
==== 4.3.2 Root nodes

An X3D file contains zero or more root nodes. The root nodes for an X3D
file are those nodes defined by the node statements or USE statements
that are not contained in other node or PROTO statements.

The following nodes are allowed as root nodes.

* Nodes that implement the X3DChildNode interface,
* Nodes that implement the X3DMetadataObject interface,
* <<GeoOrigin>> node
* <<LayerSet>> node

[[Scenegraphhierarchy]]
==== 4.3.3 Scene graph hierarchy

An X3D scene graph is a directed acyclic graph. Nodes can contain
specific fields with one or more children nodes which participate in the
hierarchy. These may, in turn, contain nodes (or instances of nodes).
This hierarchy of nodes is called the _scene graph_. Each arc in the
graph from A to B means that node A has a field whose value directly
contains node B. See <<FOLEY>> for details on hierarchical
scene graphs.

[[Descendantandancestornodes]]
==== 4.3.4 Descendant and ancestor nodes

The _descendants_ of a node are all of the nodes in its fields, as well
as all of those nodes' descendants. The _ancestors_ of a node are all of
the nodes that have the node as a descendant.

[[S4_TransformationHierarchy]]
==== 4.3.5 Transformation hierarchy

The transformation hierarchy includes all of the root nodes and root
node descendants that are considered to have one or more particular
locations in the virtual world. X3D includes the notion of _local
coordinate systems_, defined in terms of transformations from ancestor
coordinate systems. The coordinate system in which the root nodes are
displayed is called the _world coordinate system_.

An X3D browser's task is to present an X3D file to the user; it does
this by presenting the transformation hierarchy to the user. The
transformation hierarchy describes the directly perceptible parts of the
virtual world.

Some nodes, such as sensors and environmental nodes, are in the scene
graph but not affected by the transformation hierarchy. These include
<<CoordinateInterpolator>>, <<Script>>, <<TimeSensor>>, and
<<WorldInfo>>.

Some nodes, such as <<Switch>> or <<LOD>>, contain a
list of children, of which at most one is traversed during rendering.
However, for the purposes of computing scene position, all children of
these nodes are considered to be part of the transformation hierarchy,
whether they are traversed during rendering or not. For instance, a
<<Viewpoint>> node which is a child of a Switch whose
whichChoice field is set to -1 (indicating that none of its children
should be traversed during rendering) still uses the local coordinate
space of the Switch to determine its position in the scene.

The transformation hierarchy shall be a directed acyclic graph; a node
in the transformation hierarchy that is its own ancestor is considered
invalid and shall be ignored. The following is an example of a node in
the scene graph that is its own ancestor:

[source,listing]
----
DEF T Transform {
    children [
       Shape { ... }
       USE T
    ]
}     
----

[[Standardunitscoordinates]]
==== 4.3.6 Standard units and coordinate system

ISO/IEC 19775 defines the initial base unit of measure of the world
coordinate system to be metres. However, the world coordinate units may
be modified by specifying a different length unit using the UNIT
statement. All other coordinate systems are then built from
transformations based upon the specified world coordinate system. Other
measurements used in this International Standard have their own initial
base units.

<<t4_2, Table 4.2>> lists the initial base units for
ISO/IEC 19775, including the reference for each unit in <<I80000, ISO 80000>>.

[[t4_2]]
Table 4.2 — Standard units

[options="header,autowidth",frame=ends,grid=rows]
|===
|Category |Initial base unit |Reference
|angle    |radian            |ISO 80000-3:2006 item 3-5.a
|force    |newton            |ISO 80000-4:2006 item 4-9.a and item 4-9.1
|length   |metre             |ISO 80000-3:2006 item 3-1.a
|mass     |kilogram          |ISO 80000-4:2006 item 4-1.a
|===

The initial base units for the entire hierarchy of an X3D world may be
changed to another default base unit by using one or more UNIT
statements as specified in <<core_html, 7 Core component>>. In this
document, the initial base units of measure are assumed. Any ranges
specified in initial base units apply to their equivalent limits in the
specified default base unit. The X3D browser shall convert the default
base unit to initial base units as necessary for correct processing.

The base unit of time is seconds and cannot be changed.

Additional units, called _derived units_ are used in this International
Standard. A derived unit depends on the current base units. The value
for a derived unit can be calculated using the appropriate formula from
Table 4.3:

[[t4_3]]
Table 4.3 — Derived units

[options="header,autowidth",frame=ends,grid=rows]
|===
|Category         |Initial base unit |Reference
|acceleration     |length/second^2^  |ISO 80000-3:2006 item 3-9.a
|angular_velocity |angle/second      |ISO 80000-3:2006 item 3-10.a
|area             |length^2^         |ISO 80000-3:2006 item 3-3.a
|speed            |length/second     |ISO 80000-3:2006 item 3-8.a and item 3-8.1
|volume           |length^3^         |ISO 80000-3:2006 item 3-4.a
|===

The standard colour space used by this document is RGB where each colour
component has the range [0.,1.].

ISO/IEC 19775 uses a Cartesian, right-handed, three-dimensional
coordinate system. By default, the viewer is on the Z-axis looking down
the -Z-axis toward the origin with +X to the right and +Y straight up. A
modelling transformation (see the <<Transform>> node definition in 
<<grouping_html, 10 Grouping component>> and the <<Billboard>> node 
definition in <<navigation_html, 23 Navigation component>>) or viewing 
transformation (see the <<X3DViewpointNode>> node type definition in
<<navigation_html, 23 Navigation component>> can be used to alter this
default projection.

[[Behaviourgraph]]
==== 4.3.7 Behaviour graph

The event model of X3D allows the declaration of unidirectional ROUTE
connections between fields and a model for the propagation of events
along those connections. Script nodes can also send and receive events
via declared fields, either through ROUTE connections or direct
modification. The behavior graph is the collection of these field
connections. It can be changed dynamically by rerouting, adding or
breaking connections. Events are injected into the system and propagate
through the behavior graph in a well defined order.

Fields can only be routed to other fields with the same data type,
unless a component supports an extension to this rule.

[[Runtimeenvironment]]
=== 4.4 Run-time environment

[[RuntimeOverview]]
==== 4.4.1 Overview

The X3D run-time environment maintains the current state of the scene
graph, renders the scene as needed, receives input from a variety of
sources ( _Sensors_) and performs changes to the scene graph in response
to instructions from the behavioral system. The X3D run-time environment
manages the life cycle of objects, including built-in and user-defined
objects and programmatic scripts. The run-time environment coordinates
the processing of _Events_, the primary means of generating behaviors in
X3D. The run-time environment also manages interoperation between the
X3D browser and host application for file delivery, hyperlinking, page
integration and external programmatic access.

The run-time environment manages objects. X3D supports several types of
_built-in objects_ that contain generally useful functionality in the
run-time environment. There are built-in objects to represent data
structures such as an _SFVec3f_ 3D vector value, nodes such as geometry
( _e.g._, <<Cylinder>>), and ROUTEs between nodes. Each node
contains zero or more _fields_ that define storage for data values,
and/or zero or more _events_ for sending messages to/from the object.
Nodes are instantiated by declaring them in a file or by using
procedural code at run-time. The author may create new node types using
the prototyping mechanism (see <<PrototypeSemantics>>). 
These nodes become part of the run-time environment and
behave exactly like built-in nodes. New nodes can be created
declaratively by including a prototype declaration in a file, by
including an external prototype referencing a prototype declaration in a
separate location, or by using a native prototype declaration provided
by the run-time environment itself. PROTOs may only be used to create
other nodes, not fields or routes.

_Events_ are the primary means of generating behaviors in the X3D
run-time environment. Events are used throughout X3D: driving time-based
animations; handling object picking; detecting user movement and
collision; changing the scene graph hierarchy. The run-time environment
manages the propagation of events through the system and order of
evaluation according to a well-defined set of rules.

An author of X3D content can control the creation and management of
scenes, rendering and behavior, and loading of media assets. The loading
and incorporation of authored extensions, which can be written in X3D or
an external language, can also be controlled. The ability to make
content-defined extensions is provided in profiles that support the
Prototyping mechanism.

[[Objectmodel]]
==== 4.4.2 Object model

[[ObjectmodelOverview]]
===== 4.4.2.1 Overview

The X3D system is made up of abstract individual entities called
_objects_. This document defines a functional specification for each
object type but does not dictate implementation. A compliant
implementation of an object shall behave according to its functional
specification as provided in <<fieldTypes_html, 5 Field type reference>>,
clauses 7 through 40 describing components,
<<I19775_2, Part 2 of ISO/IEC 19775>> or additional parts of this
standard that define object, field or node types. An X3D author arranges
objects in the scene graph using one of the declarative X3D encodings
described in <<I19776, ISO/IEC 19776>> or other future encoding
formats, or at run time using built-in scripting (if the supported
profile provides it) or some other form of programmatic access to the
scene graph (see <<I19775_2, Part 2 of ISO/IEC 19775>>).

Objects representing lightweight concepts such as data storage and
operations on data of that type are called _fields_ and are derived from
the _<<X3DField>>_ object. Objects representing more
complete spatial or temporal processing concepts are called _nodes_ and
are derived from the _<<X3DNode>>_ object. Nodes contain one
or more fields that hold data values or send or receive events for that
node.

Some nodes implement additional functionality by inheritance of
_interfaces_ that represent common properties or functionality, such as
bounding boxes for visual objects and grouping nodes or a specification
that a particular object represents metadata. In addition, X3D defines
object types for accessing scene graph information not stored in fields
or nodes, such as ROUTEs, PROTO declarations, Component/Profile
information and world metadata.

A field may contain either a single value of the given type or an array
of such types. Throughout this document, a field type containing a
single value is said to be of the given type and is prefixed by the
characters _SF_ ( _e.g._, field _a_ is of type _SFVec3f_), while a field
containing an array has its type prefixed by the characters _MF_ (
_e.g._, field _b_ is of type _MFVec3f_). A field may contain a reference
to one or more nodes by using the _SFNode_ and _MFNode_ field types.

Each object has the following common characteristics:

[loweralpha]
. *A type name*. Examples include SFVec3f, MFColor, SFFloat,
<<Group>>, <<Background>>, or <<SpotLight>>.
. *An implementation*. The implementation of each object defines how it
reacts to changes in its property values, what other property values it
alters as a result of these changes, and how it effects the state of the
run-time environment. This document defines the functional semantics of
built-in nodes ( _i.e._, nodes with implementations that are provided by
the X3D browser).

An object derived from _X3DNode_ has the following additional
characteristics:

[loweralpha, start=4]
. *Zero or more field values*. Field values are stored in the X3D file
along with the nodes or fields, and encode the state of the virtual
world.
. *Zero or more events that it can receive and send*. Each node may
receive events to its fields which will result in some change to the
node's state. Each node may also generate events from its fields to
report changes in the node's state. Events generated from one node can
be connected to fields of other nodes to propagate these changes. This
is done using the ROUTE statement in the file or through an SAI service
reference.
. *A name*. Nodes can be named using either the DEF statement in the
file or at run-time through an SAI service call. This is used by other
statements to reference a specific instantiation of a node. It is also
be used to locate a specific named node within the scene hierarchy.

Node implementations can come from two sources, built-in nodes and
prototypes. Built-in nodes are nodes that are available to the author as
specified by the applicable profile and/or component declarations.
Different components define different sets of built-in nodes.

Additionally, X3D supports content extensions using prototypes.
Prototypes are objects that the author creates using PROTO or
EXTERNPROTO statements. These objects are written in the same
declarative notation used to describe nodes in the scene graph. They add
new object types to the system which are only available for the lifetime
of the session into which they are loaded. Some profiles may not include
support of these extension capabilities. The semantics of prototypes are
discussed in <<PrototypeSemantics, 4.4.4, Prototype semantics>>,
and <<Externalprototypesemantics, 4.4.5, External prototype semantics>>.

Both prototypes and built-in nodes are available for instantiation using
similar mechanisms. An object can be instantiated declaratively or at
run-time using the SAI services specified in <<I19775_2, Part 2 of ISO/IEC 19775>>.
All prototypes inherit from the base node type
_<<X3DPrototypeInstance>>_.

[[FieldSemantics]]
===== 4.4.2.2 Field semantics

Fields define the persistent state of nodes, and values which nodes may
send or receive in the form of events. X3D supports four types of access
to a node's fields:

[loweralpha]
. _initializeOnly_ access, which allows content to supply an initial
value for the field but does not allow subsequent changes to its value;
. _inputOnly_ access, which means that the node may receive an event to
change the value of its field, but does not allow the field's value to
be read;
. _outputOnly_ access, which means that the node may send an event when
its value changes, but does not allow the field's value to be written;
and
. _inputOutput_ access, which allows full access to the field: content
may supply an initial value for the field, the node may receive an event
to change the value of its field, and the node may send an event when
its value changes.

An _inputOutput_ field can receive events like an _inputOnly_ field, can
generate events like an _outputOnly_ field, and can be stored in X3D
files like an initializeOnly field. An _inputOutput_ field named _zzz_
can be referred to as ' _set_zzz_' and treated as an inputOnly, and can
be referred to as ' _zzz_changed_' and treated as an outputOnly field.
Within ISO/IEC 19775, fields with _inputOutput_ access or inputOnly
access are collectively referred to as _input_ fields, fields with
_inputOutput_ access or _outputOnly_ access are collectively referred to
as _output_ fields, and the events these fields receive and send are
called _input events_ and _output events_, respectively.

The initial value of an _initializeOnly_ or _inputOutput_ field is its
specified value in the X3D file. If a value is not specified, the value
of the field for the node in which it is contained is the default value.
When an _inputOutput_ field receives an event it shall generate an event
with the same value and timestamp. The following sources, in precedence
order, shall be used to determine the initial value of the _inputOutput_
field:

[loweralpha, start=5]
. the user-defined value in the instantiation (if one is specified);
. the default value for that field as specified in the node or prototype
definition.

The recommendations for naming _initializeOnly_ fields, _inputOutput_
fields, _inputOnly_ fields, and _outputOnly_ fields for built-in nodes
are as follows:

[loweralpha, start=7]
. All names containing multiple words start with a lower case letter,
and the first letter of all subsequent words is capitalized ( _e.g._, 
_addChildren_), with the exception of _set__ and __changed_, as
described below.
. It is recommended that all _inputOnly_ fields have the prefix "
_set__" (with the exception of the _addChildren_ and _removeChildren_
fields).
. Certain _inputOnly_ fields and _outputOnly_ fields of type SFTime do
not use the " _set__" prefix or " __changed_" suffix.
. It is recommended that all other _outputOnly_ fields have the suffix "
__changed_" appended (with the exception of _outputOnly_ fields of type
SFBool).

[[InterfaceHierarchy]]
===== 4.4.2.3 Interface hierarchy

Most object types derive some of their interfaces and functionality from
other object types in the system. These are known as its _supertypes_,
and an object is said to be _derived_ from these supertypes. Likewise,
these supertypes may derive their capabilities from other object types,
forming a chain all the way to a small number of base types from which
all the others are ultimately derived. The graph describing the
relationship between all object types in the system is called the
_interface hierarchy_. In this part of ISO/IEC 19775, the object
hierarchy specifies conceptual relationships between objects but does
not necessarily dictate actual implementation.

<<f-Objecthierarchy, Figure 4.2>> depicts the object hierarchy for
object types defined in this document for all versions. A specification
of which object types are available for which versions may be found in
<<versionContent_html, Annex Z Version content>>.

NOTE  Not all object types are supported in certain component levels,
profiles or versions; refer to the individual component and profile
specifications in this document for details.

[source,diagram]
....
      X3DField -+------------- X3DArrayField -+
                +- SFBool                     +- MFBool
                +- SFColor                    +- MFColor
                +- SFColorRGBA                +- MFColorRGBA
                +- SFDouble                   +- MFDouble
                +- SFFloat                    +- MFFloat
                +- SFImage                    +- MFImage
                +- SFInt32                    +- MFInt32
                +- SFMatrix3d                 +- MFMatrix3d 
                +- SFMatrix3f                 +- MFMatrix3f 
                +- SFMatrix4d                 +- MFMatrix4d 
                +- SFMatrix4f                 +- MFMatrix4f 
                +- SFNode                     +- MFNode
                +- SFRotation                 +- MFRotation
                +- SFString                   +- MFString
                +- SFTime                     +- MFTime
                +- SFVec2d                    +- MFVec2d
                +- SFVec2f                    +- MFVec2f
                +- SFVec3d                    +- MFVec3d
                +- SFVec3f                    +- MFVec3f
                +- SFVec4d                    +- MFVec4d
                +- SFVec4f                    +- MFVec4f

      X3DBoundedObject

      X3DFogObject

      X3DPickableObject

      X3DProgrammableShaderObject

      X3DMetadataObject 

      X3DUrlObject 

      X3DNode
        | 
        +- Contact
        +- Contour2D
        
        +- GeoOrigin 
        +- LayerSet
        +- MetadataBoolean (X3DMetadataObject)* 
        +- MetadataDouble (X3DMetadataObject)*
        +- MetadataFloat (X3DMetadataObject)*
        +- MetadataInteger (X3DMetadataObject)*
        +- MetadataSet (X3DMetadataObject)*
        +- MetadataString (X3DMetadataObject)*
        +- NurbsTextureCoordinate
        +-  
        +- ShaderPart (X3DUrlObject)*
        +- ShaderProgram (X3DUrlObject, X3DProgrammableShaderObject)*
        +- TextureProperties
        |
        +- X3DAppearanceNode -+- Appearance
        |
        +- X3DAppearanceChildNode -+- AcousticProperties
        |                          +- FillProperties
        |                          +- LineProperties
        |                          +- PointProperties
        |                          |
        |                          +- X3DMaterialNode -+- X3DOneSidedMaterialNode -+- Material
        |                          |                   |                           +- PhysicalMaterial
        |                          |                   |                           +- UnlitMaterial
        |                          |                   +- TwoSidedMaterial (deprecated)
        |                          |
        |                          |
        |                          +- X3DShaderNode -+- ComposedShader (X3DProgrammableShaderObject)*
        |                          |                 +- PackagedShader (X3DUrlObject, X3DProgrammableShaderObject)*
        |                          |                 +- ProgramShader
        |                          |
        |                          +- X3DTextureNode -+- MultiTexture
        |                          |                  |
        |                          |                  + X3DSingleTextureNode -+- X3DEnvironmentTextureNode -+- ComposedCubeMapTexture
        |                          |                                          |                             +- GeneratedCubeMapTexture
        |                          |                                          |                             +- ImageCubeMapTexture (X3DUrlObject)*
        |                          |                                          | 
        |                          |                                          +- X3DTexture2DNode -+- ImageTexture (X3DUrlObject)*
        |                          |                                          |                    +- MovieTexture (X3DSoundSourceNode, X3DUrlObject)*
        |                          |                                          |                    +- PixelTexture
        |                          |                                          |
        |                          |                                          +- X3DTexture3DNode -+- ComposedTexture3D
        |                          |                                                               +- ImageTexture3D (X3DUrlObject)*
        |                          |                                                               +- PixelTexture3D
        |                          |
        |                          |
        |                          +- X3DTextureTransformNode  +- MultiTextureTransform
        |                                                      +- X3DSingleTextureTransformNode -+- TextureTransform
        |                                                                                        +- TextureTransformMatrix3D
        |                                                                                        +- TextureTransform3D
        |
        |
        +- X3DFontStyleNode -+- FontStyle
        |                    +- ScreenFontStyle                              
        |
        +- X3DGeometryNode -+- Arc2D
        |                   +- ArcClose2D
        |                   +- Box
        |                   +- Circle2D
        |                   +- Cone
        |                   +- Cylinder
        |                   +- Disk2D
        |                   +- ElevationGrid
        |                   +- Extrusion
        |                   +- GeoElevationGrid
        |                   +- IndexedLineSet
        |                   +- LineSet
        |                   +- PointSet
        |                   +- Polyline2D
        |                   +- Polypoint2D
        |                   +- Rectangle2D
        |                   +- Sphere
        |                   +- Text
        |                   +- TriangleSet2D 
        |                   |
        |                   +- X3DComposedGeometryNode -+- IndexedFaceSet
        |                   |                           +- IndexedTriangleFanSet
        |                   |                           +- IndexedTriangleSet
        |                   |                           +- IndexedTriangleStripSet
        |                   |                           +- IndexedQuadSet
        |                   |                           +- QuadSet
        |                   |                           +- TriangleFanSet
        |                   |                           +- TriangleSet
        |                   |                           +- TriangleStripSet
        |                   |
        |                   +- X3DParametricGeometryNode -+- NurbsCurve
        |                                                 +- NurbsSweptSurface
        |                                                 +- NurbsSwungSurface
        |                                                 |
        |                                                 +- X3DNurbsSurfaceGeometryNode -+- NurbsPatchSurface
        |                                                                                 +- NurbsTrimmedSurface
        |
        +- X3DGeometricPropertyNode -+- FogCoordinate
        |                            +- HAnimDisplacer
        |                            |
        |                            |+- X3DColorNode -+- Color
        |                            |                 +- ColorRGBA
        |                            |
        |                            +- X3DCoordinateNode -+- Coordinate
        |                            |                     +- CoordinateDouble
        |                            |                     +- GeoCoordinate
        |                            |
        |                            +- X3DNormalNode -+- Normal
        |                            |
        |                            +- X3DTextureCoordinateNode -+- MultiTextureCoordinate
        |                            |                            +- X3DSingleTextureCoordinateNode -+- TextureCoordinate
        |                            |                                                               +- TextureCoordinate3D
        |                            |                                                               +- TextureCoordinate4D
        |                            |                                                               +- TextureCoordinateGenerator
        |                            |
        |                            |
        |                            +- X3DVertexAttributeNode -+- FloatVertexAttribute
        |                                                       +- Matrix3VertexAttribute
        |                                                       +- Matrix4VertexAttribute
        |
        +- X3DLayerNode -+- Layer
        |                +- LayoutLayer
        |
        +- X3DNBodyCollisionSpaceNode (X3DBoundedObject)* -+- CollisionSpace
        |
        +- X3DNurbsControlCurveNode -+- ContourPolyline2D
        |                            +- NurbsCurve2D
        |
        +- X3DParticleEmitterNode -+- ConeEmitter
        |                          +- ExplosionEmitter
        |                          +- PointEmitter
        |                          +- PolylineEmitter
        |                          +- SurfaceEmitter
        |                          +- VolumeEmitter
        |
        +- X3DParticlePhysicsModelNode  -+- BoundedPhysicsModel
        |                                +- ForcePhysicsModel
        |                                +- WindPhysicsModel
        |
        +- X3DProtoInstance
        |
        +- X3DRigidJointNode -+- BallJoint
        |                     +- DoubleAxisHingeJoint
        |                     +- MotorJoint
        |                     +- SingleAxisHingeJoint
        |                     +- SliderJoint
        |                     +- UniversalJoint
        |
        +- X3DVolumeRenderStyleNode -+- ProjectionVolumeStyle
        |                            |
        |                            +- X3DComposableVolumeRenderStyleNode -+- BlendedVolumeStyle
        |                                                                   +- BoundaryEnhancementVolumeStyle
        |                                                                   +- CartoonVolumeStyle
        |                                                                   +- ComposedVolumeStyle
        |                                                                   +- EdgeEnhancementVolumeStyle
        |                                                                   +- OpacityMapVolumeStyle
        |                                                                   
        |                                                                   +- ShadedVolumeStyle
        |                                                                   +- SilhouetteEnhancementVolumeStyle
        |                                                                   +- ToneMappedVolumeStyle
        |
        +- X3DChildNode -+- BooleanFilter
                         +- BooleanToggle
                         +- ClipPlane
                         +- CollisionCollection
                         +- DISEntityManager
                         +- EaseInEaseOut
                         +- GeoLOD (X3DBoundedObject)*
                         +- HAnimHumanoid (X3DBoundedObject)*
                         +- HAnimMotion
                         +- Inline (X3DUrlObject, X3DBoundedObject)*
                         +- LocalFog (X3DFogObject)*
                         +- NurbsOrientationInterpolator
                         +- NurbsPositionInterpolator
                         +- NurbsSet (X3DBoundedObject)*
                         +- NurbsSurfaceInterpolator
                         +- RigidBody
                         +- RigidBodyCollection 
                         +- StaticGroup (X3DBoundedObject)*
                         +- ViewpointGroup
                         |
                         +- X3DBindableNode -+- Fog (X3DFogObject)*
                         |                   +- 
                         |                   +- NavigationInfo
                         |                   +- ListenerPoint
                         |                   |
                         |                   +- X3DBackgroundNode -+- Background 
                         |                   |                     +- TextureBackground
                         |                   |
                         |                   +- X3DViewpointNode -+- GeoViewpoint
                         |                                        +- OrthoViewpoint
                         |                                        +- Viewpoint
                         |                                        
                         |
                         +- X3DFollowerNode -+- X3DChaserNode -+- ColorChaser
                         |                   |                 +- CoordinateChaser
                         |                   |                 +- OrientationChaser
                         |                   |                 +- PositionChaser
                         |                   |                 +- PositionChaser2D
                         |                   |                 +- ScalerChaser
                         |                   |                 +- TexCoordChaser2D
                         |                   |
                         |                   +- X3DDamperNode -+- ColorDamper
                         |                                     +- CoordinateDamper
                         |                                     +- OrientationDamper
                         |                                     +- PositionDamper
                         |                                     +- PositionDamper2D
                         |                                     +- ScalarDamper
                         |                                     +- TexCoordDamper
                         |
                         +- X3DGroupingNode (X3DBoundedObject)* -+- Anchor
                         |                                       +- Billboard
                         |                                       +- CADAssembly (X3DProductStructureChildNode)*
                         |                                       +- CADLayer
                         |                                       +- CADPart (X3DProductStructureChildNode)*
                         |                                       +- Collision (X3DSensorNode)*
                         |                                       +- EspduTransform (X3DSensorNode)*
                         |                                       +- GeoLocation
                         |                                       +- GeoTransform
                         |                                       +- Group
                         |                                       +- HAnimJoint
                         |                                       +- HAnimSegment
                         |                                       +- HAnimSite
                         |                                       +- LayoutGroup
                         |                                       +- LOD
                         |                                       +- PickableGroup (X3DPickableObject)*
                         |                                       +- ScreenGroup
                         |                                       +- Switch
                         |                                       +- Transform
                         |                                       |
                         |                                       +- X3DViewportNode -+- Viewport
                         |
                         +- X3DInfoNode --+- DISEntityTypeMapping (X3DUrlObject)*
                         |                +- GeoMetadata (X3DUrlObject)*
                         |                +- WorldInfo
                         |
                         +- X3DInterpolatorNode -+- ColorInterpolator
                         |                       +- CoordinateInterpolator
                         |                       +- CoordinateInterpolator2D
                         |                       +- GeoPositionInterpolator
                         |                       +- NormalInterpolator
                         |                       +- OrientationInterpolator
                         |                       +- PositionInterpolator
                         |                       +- PositionInterpolator2D
                         |                       +- ScalarInterpolator
                         |                       +- SplinePositionInterpolator
                         |                       +- SplinePositionInterpolator2D
                         |                       +- SplineScalarInterpolator
                         |                       +- SquadOrientationInterpolator
                         |
                         +- X3DLayoutNode -+- Layout
                         |                   
                         +- X3DLightNode -+- DirectionalLight
                         |                +- PointLight
                         |                +- SpotLight 
                         |
                         +- X3DNBodyCollidableNode (X3DBoundedObject)* -+- CollidableOffset
                         |                                              +- CollidableShape
                         |
                         +- X3DProductStructureChildNode -+- CADAssembly (X3DGroupingNode)*
                         |                                +- CADFace (X3DBoundedObject)*
                         |                                +- CADPart (X3DGroupingNode)*
                         |
                         +- X3DTextureProjectorNode -+- TextureProjectorPerspective
                         |                           +- TextureProjectorParallel
                         |
                         +- X3DScriptNode (X3DUrlObject)* -+- Script
                         |
                         +- X3DSensorNode -+- Collision (X3DGroupingNode)* 
                         |                 +- CollisionSensor

                         |                 +- TimeSensor (X3DTimeDependentNode)*
                         |                 |
                         |                 +- X3DEnvironmentalSensorNode -+- GeoProximitySensor
                         |                 |                              +- ProximitySensor
                         |                 |                              +- TransformSensor
                         |                 |                              +- VisibilitySensor
                         |                 |
                         |                 +- X3DKeyDeviceSensorNode -+- KeySensor
                         |                 |                          +- StringSensor
                         |                 +- TimeSensor (X3DTimeDependentNode)*
                         |                 |
                         |                 +- X3DNetworkSensorNode +- EspduTransform
                         |                                         +- LoadSensor (X3DGroupingNode)*
                         |                                         +- ReceiverPdu (X3DBoundedObject)*
                         |                                         +- SignalPdu (X3DBoundedObject)*
                         |                                         +- TransmitterPdu (X3DBoundedObject)*
                         |                 |
                         |                 +- X3DPickSensorNode -+- LinePickSensor
                         |                 |                     +- PointPickSensor
                         |                 |                     +- PrimitivePickSensor
                         |                 |                     +- VolumePickSensor
                         |                 | 
                         |                 +- X3DPointingDeviceSensorNode -+- X3DDragSensorNode -+- CylinderSensor
                         |                                                 |                     +- PlaneSensor
                         |                                                 |                     +- SphereSensor
                         |                                                 |
                         |                                                 +- X3DTouchSensorNode -+- GeoTouchSensor
                         |                                                                        +- TouchSensor
                         |
                         +- X3DSequencerNode -+- BooleanSequencer
                         |                    +- IntegerSequencer
                         |
                         +- X3DShapeNode (X3DBoundedObject)* -+- ParticleSystem
                         |                                    +- Shape
                         |
                         +- X3DSoundNode -+- PeriodicWave
                         |                +- Sound
                         |                +- SpatialSound
                         |                |
                         |                +- X3DSoundChannelNode -+- ChannelMerger
                         |                |                       +- ChannelSelector
                         |                |                       +- ChannelSplitter
                         |                |
                         |                +- X3DSoundDestinationNode -+- AudioDestination
                         |                !                           +- StreamAudioDestination
                         |                |
                         |                +- X3DSoundProcessingNode (X3DTimeDependentNode)* -+- Analyser
                         |                |                                                  +- BiquadFilter
                         |                |                                                  +- Convolver
                         |                |                                                  +- Delay
                         |                |                                                  +- DynamicsCompressor
                         |                |                                                  +- Gain
                         |                |                                                  +- WaveShaper
                         |                |
                         |                +- X3DSoundSourceNode (X3DTimeDependentNode)* -+- AudioClip (X3DUrlObject)*
                         |                                                               +- BufferAudioSource
                         |                                                               +- ListenerPointSource
                         |                                                               +- MicrophoneSource
                         |                                                               +- MovieTexture (X3DTexture2DNode, X3DUrlObject)*
                         |                                                               +- OscillatorSource
                         |                                                               +- StreamAudioSource
                         |


                         |
                         +- X3DTriggerNode -+- BooleanTrigger
                         |                  +- IntegerTrigger
                         |                  +- TimeTrigger
                         |
                         +- X3DVolumeDataNode (X3DBoundedObject)* -+- IsoSurfaceVolumeData
                                                                   +- SegmentedVolumeData
                                                                   +- VolumeData

* = Derived from multiple interfaces
....

Figure 4.2 — Interface hierarchy

The object hierarchy defines both _abstract_ interfaces and _concrete_
node types. Abstract interfaces define functionality that is inherited
by other interfaces and/or nodes, but are never instantiated in the
scene graph as objects. Concrete node types derive from one or more
abstract interfaces and may be instantiated in the scene graph. Thus,
the live scene graph consists only of instances of concrete node types. 
Components defined in this document are required to implement the
functionality of abstract interfaces only insofar as that functionality
is made available via one of the derived concrete node types.
<<I19775_2, Part 2 of ISO/IEC 19775>> defines the means by which
applications may access the functionality provided in both abstract
interfaces and concrete nodes via programmatic means.

The two main types of object from which most others are derived are
_<<X3DNode>>_ and _<<X3DField>>_. Nodes are the
objects used in the declarative language to form the scene graph, while
fields are contained within nodes and hold the data items for nodes.
Some field objects contain simple data values like integers or arrays of
strings. Other field objects contain references to nodes. It is this
ability of _X3DNode_ to contain _X3DField_, and _X3DField_ to contain
references to _X3DNode_, that makes it possible for X3D to form scene
graph hierarchies.

EXAMPLE

[source,listing]
----
Transform { translation 1 2 3
  children [
    Shape {
      geometry Box { }
    }
    Group {
      children [ ... ]
    }
  ]
}
----

In the above example, the Transform contains a simple field,
_translation_, which contains a vector of 3 numbers. It also contains a
_children_ field which may contain an array of other nodes. In this case
it has two, a Shape and a Group. The Shape and the Group both contain
fields which may have other objects as well.

Derivation makes it possible to strongly type all objects. In the above
example, the children field is constrained to contain a list of objects
derived from an object type called _<<X3DChildNode>>_.
Both <<Shape>> and <<Group>> are derived (indirectly)
from this object and can therefore be placed in the children field. The
geometry field of Shape, on the other hand, can only contain a single
node derived from _<<X3DGeometryNode>>_.
<<Box>> is derived from this object and can therefore be placed
in the geometry field. But Box is not derived from _X3DChildNode_, so it
cannot be placed in the children field. Likewise, Group is not derived
from _X3DGeometryNode_ and can therefore not be placed in the geometry
field.

The above example exhibits another quality of derivation.
<<Transform>> is derived from _<<X3DGroupingNode>>_ and therefore inherits 
its children field. This makes the specification of Transform simpler
because it does not need to describe the functionality of the children
field. Because it is derived from _X3DGroupingNode_, the author knows it
contains a children field which behaves like the one in Group which is
also derived from _X3DGroupingNode_.

[[Modifyingobjects]]
===== 4.4.2.4 Modifying objects

[[ModifyingObjectsRoutes]]
===== 4.4.2.4.1 Routes

There are several ways to modify the fields of an object. Using one of
the X3D file formats, an author can declare a set of nodes, the initial
state of their fields, and interconnections between the fields called
_Routes_. X3D uses an event propagation, or _dataflow_ model to change
the values of fields at run-time. As part of its abstract specification,
the behavior of a node in response to events sent to its fields, and the
conditions under which its fields send events out, is described.

EXAMPLE  It is possible to create a scene with run-time behavior using
only this event propagation model:

[source,listing]
----
DEF TS TimeSensor {
  loop TRUE
  cycleInterval 5
}
DEF I PositionInterpolator {
  key [ 0 0.5 1 ]
  keyValue [ 0 -1 0, 0 1 0, 0 -1 0 ]
}
DEF T Transform {
  children [
    Shape {
      geometry Box { }
    }
  ]
}
ROUTE ts.fraction_changed TO I.set_fraction
ROUTE I.value_changed TO T.set_translation
----

This example bounces a box up and down repeatedly over a five-second
interval. The TimeSensor object is defined to send an event continuously
out of its _fraction_ field. This event sends a floating point value
which varies from 0 to 1 over a 5 second interval, as specified by the
_cycleInterval_. Its _loop_ field tells it to do so repeatedly. This
fraction value is sent to the _fraction_ field of a
PositionInterpolator. This object is defined to send an event out of its
_value_ field whenever it receives an event on its fraction field. The
value is determined by the _key_ and _keyValue_ fields. In this case it
sends a vector whose y value varies between -1 and +1 and back again
over the interval. This value is sent to the _translation_ field of the
Transform node. This node is defined to set the position of its children
according to the value of _translation_. <<Routes, 4.4.8.2 Routes>>
contains more information on routing.

[[ModifyingObjectsViaProgrammaticAccess]]
===== 4.4.2.4.2 Modifying objects via programmatic access

The routing mechanism is simple, but is limited to changing field values
of nodes, and only changes that are designed into a given node set. For
greater flexibility, some profiles provide programmatic access to
objects in the system. This allows field values to be set and read, and
functions to be called. Mechanisms are also provided to allow PROTO
objects to be found, which in turn allows objects of that type to be
instantiated.

There are two types of programmatic access in X3D: External access
(EXAMPLE  access from a containing HTML page or embedding
native application) and Internal scripts using any of the supported
scripting languages.

Programmatic access to objects is provided via _interfaces_ to those
objects. The interface of an object (its set of data and function
properties) is specified, and is also referred to as the _object type_.
An object type that represents a node is also referred to as a _node
type_. Object types may be either abstract or concrete. Abstract object
types are not instantiable. Instead, they are used to derive other
object types or to indicate that a field may contain a node of any of
the derivative node types. Concrete node types are those derived from
abstract node types and are instantiable. A compliant implementation of
an object's interface shall support the interface specifications as
defined in <<I19775_2, Part 2 of ISO/IEC 197775>>.

See <<SceneAccessInterface, 4.9, Application programmer interfaces>> 
for additional information.

[[Objectlifecycle]]
===== 4.4.2.5 Object life cycle

Nodes have a life cycle: they are created, used and eventually
destroyed. A node is considered live if one or more of the following is
true:

[loweralpha]
. The node is a root node in the scene.
. The node is referenced by a field of a live node.
. There is a reference from a live script to the node.
. There is an external programmatic reference to the node.

Rules b and c are applied recursively to cover the entire live scene
graph.

Nodes instanced from a file are created implicitly by the X3D browser
upon encountering a node instance or upon instancing a prototype's scene
graph. Nodes may also be instanced programmatically; in this case there
are additional discrete steps in the node's life cycle. Refer to
<<I19775_2, Part 2 of ISO/IEC 197775>> for more details.

[[DEF_USE_Semantics]]
==== 4.4.3 DEF/USE semantics

Node DEF names are limited in scope to a single X3D file, prototype
definition, or string submitted to either CreateX3DFromString,
CreateX3DFromStream, or CreateX3DFromURL X3D browser service (as
specified in <<I19775_2, ISO/IEC 19775-2>>).

The USE statement does not create a copy of the node identified by a DEF
name. Instead, the same node is inserted into the scene graph a second
time, resulting in the node having multiple parents (see
<<S4_TransformationHierarchy, 4.3.5 Transformation hierarchy>>, for
restrictions on self-referential nodes).

Node names shall be unique in the context within which the associated
DEF name occurs.

[[PrototypeSemantics]]
==== 4.4.4 Prototype semantics


[[S4_Introduction]]
===== 4.4.4.1 Introduction

The PROTO statement defines a new node type in terms of already defined
(built-in or prototyped) node types. Once defined, prototyped node types
may be instantiated in the scene graph exactly like the built-in node
types.

Node type names shall be unique in each X3D file. The results are
undefined if a prototype is given the same name as a built-in node type
or a previously defined prototype in the same scope.

[[PROTOinterfacedeclsemantics]]
===== 4.4.4.2 PROTO interface declaration semantics

The prototype interface defines the fields and field access types for
the new node type. The interface declaration includes the types, names
and default values (for _initializeOnly_ and _inputOutput_ fields) for
the prototype's fields.

The interface declaration may contain _inputOutput_ field declarations,
which are a convenient way of defining an _initializeOnly_ field,
_inputOnly_ field, and _outputOnly_ field at the same time. If an
_inputOutput_ field named _zzz_ is declared, it is equivalent to
separately declaring an _initializeOnly_ field named _zzz_, an
_inputOnly_ field named _set_zzz_, and an _outputOnly_ field named
_zzz_changed_.

Each prototype instance can be considered to be a complete copy of the
prototype, with its own field values and copy of the prototype
definition. A prototyped node type is instantiated using appropriate
node syntax. For example, the following prototype instance (which has an
empty interface declaration):

[source,listing]
----
PROTO Cube [ ] { Box { } }
----

may be instantiated within the scene graph as follows:

[source,listing]
----
Shape { geometry Cube { } }
----

It is recommended that user-defined field names defined in PROTO
interface declarations statements follow the naming conventions
described in <<FieldSemantics, 4.4.2.2 Field semantics>>. Field names
shall be an identifier that is unique for this prototype. Prototype
declarations shall not define a new _metadata_ field since that is
already specified as part of
<<X3DPrototypeInstance>>.

If an _outputOnly_ field in the prototype declaration is associated with
an _inputOutput_ field in the prototype definition, the initial value of
the associated _outputOnly_ field shall be the initial value of the
_inputOutput_ field. If the _outputOnly_ field is associated with
multiple _inputOutput_ fields, the results are undefined.

Prototype and field declarations may optionally include _appinfo_
functional descriptions (_i.e._, tooltip summary) and a _documentation_
url providing a link to further related information.

[[PROTOdefinitionsemantics]]
===== 4.4.4.3 PROTO definition semantics

A prototype definition consists of a prototype interface, followed by a
prototype body containing one or more nodes, nested PROTO statements,
and ROUTE statements. The first node type determines how instantiations
of the prototype can be used in an X3D file. Only the first node in the
body of a prototype is rendered, while peer nodes (which follow) are not
displayed but remain active. An instantiation is created by filling in
the parameters of the prototype declaration and inserting copies of the
first node (and its scene graph) wherever the prototype instantiation
occurs.

EXAMPLE  If the first node in the prototype definition is a Material
node, instantiations of the prototype can be used wherever a Material
node can be used. Any other nodes (that are specified after the Material
node) are not part of the rendered transformation hierarchy, but remain
active and may be referenced by ROUTE statements or Script nodes in the
prototype definition.

Nodes in the prototype definition may have their fields associated with
the fields of the prototype interface declaration by using IS statements
in the body of the node. When prototype instances are read from an X3D
file, field values for the fields of the prototype interface may be
given. If given, the field values are used for all nodes in the
prototype definition that have IS statements for those fields.
Similarly, when an input field of a prototype instance is sent an event,
the event is delivered to all nodes that have IS statements for that
field. When a node in a prototype instance generates an output event
that has an IS statement, the event is sent to any input fields
connected (via ROUTE) to the prototype instance's output field.

IS statements may appear inside the prototype definition wherever fields
may appear. IS statements shall refer to fields defined in the prototype
declaration. Results are undefined if an IS statement refers to a
non-existent declaration. Results are undefined if the type of the field
being associated by the IS statement does not match the type declared in
the prototype's interface declaration. For example, it is illegal to
associate an SFColor with an SFVec3f. It is also illegal to associate an
SFColor with an MFColor or _vice versa_.

Results are undefined if an IS statement:

* inputOnly field is associated with a _initializeOnly_ field or an
_outputOnly_ field;
* outputOnly field is associated with a _initializeOnly_ field or
_inputOnly_ field;
* initializeOnly field is associated with an _inputOnly_ field or
_outputOnly_ field.

An _inputOutput_ field in the prototype interface may be associated only
with an inputOutput field in the prototype definition, but an
_inputOutput_ field in the prototype definition may be associated with
either an _inputOutput_ field, _inputOnly_ field, or _outputOnly_ field
in the prototype interface. When associating an _inputOutput_ field in a
prototype definition with an _inputOnly_ field or _outputOnly_ field in
the prototype declaration, it is valid to use either the shorthand
_inputOutput_ field name ( _e.g._, _translation_) or the explicit field
name ( _e.g._, _set_translation_ or _translation_changed_).
<<t4_4, Table 4.4>> defines the rules for
mapping between the access types of fields in a prototype declarations
and the access types for fields in its primary scene graph's nodes (
_yes_ denotes a legal mapping, _no_ denotes an error).

[[t4_4]]
Table 4.4 — Rules for mapping PROTOTYPE
declarations to node instances

[,cols="50%,^50%",options="header,autowidth",frame=ends,grid=rows]
|===
| |*Prototype declaration*

|*Prototype definition* a|
!===
! !*inputOutput* !*initializeOnly* !*inputOnly* !*outputOnly*

!*inputOutput*    !yes !yes !yes !yes
!*initializeOnly* !no  !yes !no  !no
!*inputOnly*      !no  !no  !yes !no
!*outputOnly*     !no  !no  !no  !yes
!===

|===

Results are undefined if a field of a node in the prototype definition
is associated with more than one field in the prototype's interface (
_i.e._, multiple IS statements for a field in a node in the prototype
definition), but multiple IS statements for the fields in the prototype
interface declaration is valid. Results are undefined if a field of a
node in a prototype definition is both defined with initial values (
_i.e._, field statement) and associated by an IS statement with a field
in the prototype's interface.

If a prototype interface has an _outputOnly_ field _E_ associated with
multiple _outputOnly_ fields in the prototype definition _ED_ ~_i_~, the
value of _E_ is the value of the field that generated the event with the
greatest timestamp. If two or more of the _outputOnly_ fields generated
events with identical timestamps, results are undefined.

Security precaution: it is an error for a prototype to reference an
instance or repeated declaration of itself, directly or indirectly, in
order to avoid nonterminating recursion loops. This error might occur
with either local or external (PROTO or EXTERNPROTO) declarations. X3D
browsers shall not honor self-referential loading of prototype
declaration loops in order to avoid security vulnerabilities.

[[Prototypescopingrules]]
===== 4.4.4.4 Prototype scoping rules

A prototype may be instantiated in a file anywhere after the completion
of the prototype definition. Prototype definitions appearing inside a
prototype definition ( _i.e._, nested) have scope local to the enclosing
prototype. IS statements inside a nested prototype's implementation may
refer to the prototype declarations of the innermost prototype.

A PROTO statement establishes a DEF/USE name scope separate from the
rest of the scene and separate from any nested PROTO statements. Nodes
given a name by a DEF construct inside the prototype may not be
referenced in a USE construct outside of the prototype's scope. Nodes
given a name by a DEF construct outside the prototype scope may not be
referenced in a USE construct inside the prototype scope.

[[Externalprototypesemantics]]
==== 4.4.5 External prototype semantics


[[S4_Introduction]]
===== 4.4.5.1 Introduction

The EXTERNPROTO statement defines a new node type. It is equivalent to
the PROTO statement, with two exceptions. First, the implementation of
the node type is stored externally, either in an X3D file containing an
appropriate PROTO statement or using some other implementation-dependent
mechanism. Second, default values for fields are not given since the
implementation will define appropriate defaults.

[[EXTERNPROTOInterfaceSemantics]]
===== 4.4.5.2 EXTERNPROTO interface semantics

The semantics of the EXTERNPROTO are exactly the same as for a PROTO
statement, except that default field values are not specified locally.
In addition, events sent to an instance of an externally prototyped node
may be ignored until the implementation of the node is found.

Until the definition has been loaded, the X3D browser shall determine
the initial value of _inputOutput_ fields using the following rules (in
order of precedence):

[loweralpha]
. the user-defined value in the instantiation (if one is specified);
. the default value for that field type.

For _outputOnly_ fields, the initial value on startup will be the
default value for that field type. During the loading of an EXTERNPROTO,
if an initial value of an _outputOnly_ field is found, that value is
applied to the field and no event is generated.

The names and types of the fields of the interface declaration shall be
a subset of those defined in the implementation. Declaring a field with
a non-matching name is an error, as is declaring a field with a matching
name but a different type.

It is recommended that user-defined field names defined in EXTERNPROTO
interface statements follow the naming conventions described in
<<FieldSemantics, 4.4.2.2 Field semantics>>.

[[EXTERNPROTOURLSemantics]]
===== 4.4.5.3 EXTERNPROTO URL semantics

The string or strings specified after the interface declaration give the
location of the prototype's implementation. If multiple strings are
specified, the X3D browser searches in the order of preference. For more
information on URLs, see <<networking_html, 9 Networking component>>.

If a URL in an EXTERNPROTO statement refers to an X3D file, the first
PROTO statement found in the X3D file (excluding EXTERNPROTOs) is used
to define the external prototype's definition. The name of that
prototype does not need to match the name given in the EXTERNPROTO
statement. Results are undefined if a URL in an EXTERNPROTO statement
refers to a non-X3D file

To enable the creation of libraries of reusable PROTO definitions, X3D
browsers shall recognize EXTERNPROTO URLs that end with "# _name_" to
mean the PROTO statement for "name" in the given X3D file. For example,
a library of standard materials might be stored in an X3D file called
"materials.x3dv" that looks like:

[source,listing]
----
#X3D V3.0 utf8
PROTO Gold   [] { Material { ... } }
PROTO Silver [] { Material { ... } }
     ...etc.
----

A material from this library might be used as follows:

[source,listing]
----
#X3D V3.0 utf8
EXTERNPROTO GoldFromLibrary [] "https://.../materials.x3dv#Gold"
   ...
 Shape {
   appearance Appearance { material GoldFromLibrary {} }
   geometry   ...
 }
 ...
----

[[ImportExportsemantics]]
==== 4.4.6 Import/Export semantics

The IMPORT feature allows authors to incorporate content defined within
Inline nodes or created programmatically into the namespace of the
containing file for the purposes of event routing. In contrast with
external prototyping 
(see <<Externalprototypesemantics, 4.4.5 External prototype semantics>>), 
which allows access to individual fields
of nodes defined as prototypes in external files, IMPORT provides access
to all the fields of an externally defined node with a single statement
(see <<IMPORTStatement, 9.2.5 IMPORT statement>>).

Importing nodes from an Inlined file is accomplished with two
statements: IMPORT and EXPORT. The IMPORT statement is used in the
containing file to define which nodes of an Inline are to be
incorporated into the containing file's namespace. The EXPORT statement
is used in the file being Inlined, to control access over which nodes
within a file are visible to other files (see
<<EXPORTStatement, 9.2.6 EXPORT statement>>). EXPORT statements are
not allowed in prototype declarations.

[[Runtimenamescope]]
==== 4.4.7 Run-time name scope

Each X3D browser defines a run-time name scope that contains all of the
root nodes currently contained by the scene graph and all of the
descendant nodes of the root nodes, with the exception of nodes hidden
inside another name scope. Prototypes establish a name scope and
therefore nodes inside prototype instances are hidden from the parent
name scope.

Each Inline node or prototype instance also defines a run-time name
scope, consisting of all of the root nodes of the file referred to by
the Inline node or all of the root nodes of the prototype definition,
restricted as above. Other nodes or extension mechanism may be
introduced which specify their own name scope.

The IMPORT feature allows nodes defined within files referenced from
<<Inline>>nodes to be incorporated into the run-time name
scope of the containing scene graph. Once an IMPORT statement has been
encountered, the new name may be used exactly like any other node name
for the purposes of routing or programmatic access ( _i.e._, may be used
in ROUTE statements and accessed as a field from the Scene Access
Interface). Names imported from an Inline shall be explicitly declared
as exportable within the content of the inlined file, using the EXPORT
statement; only names exported using the EXPORT statement are available
to be imported into other run-time name scopes. The optional AS keyword
allows a unique name to be assigned to the imported node in order to
avoid name conflicts in the containing scene graph's run-time name
scope.

Nodes created dynamically (using the X3D Scene Access Interface) are not
part of any name scope, until they are added to the scene graph, at
which point they become part of the same name scope of their parent
node(s). A node may be part of more than one run-time name scope. A node
shall be removed from a name scope when it is removed from the scene
graph.

[[S4_Eventmodel]]
==== 4.4.8 Event model

[[Events]]
===== 4.4.8.1 Events

_Events_ are the primary means of generating behaviors in the X3D
run-time environment. Events are used throughout X3D: driving time-based
animations; handling object picking; detecting user movement and
collision; changing the scene graph hierarchy. The run-time environment
manages the propagation of events through the system according to a
well-defined set of rules.

Nodes define input fields ( _i.e._, fields with _inputOutput_ or
_inputOnly_ access) that trigger behavior. When a given event occurs,
the node receives notification and can potentially change internal state
and the value of one or more of its fields. Nodes also define output
fields ( _i.e._, fields with _inputOutput_ or _outputOnly_ access) that
are sent upon signal state changes or other occurrences within the node.
Events sent to input fields and events sent by output fields are
referred to collectively in ISO/IEC 19775 as _Events_.

[[Routes]]
===== 4.4.8.2 Routes

_Routes_ allows an author to declaratively connect the output events of
a node to input events of other nodes, providing a way to implement
complex behaviors without imperative programming. When a routed output
event is fired, the corresponding destination input event receives
notification and can process a response to that change. This processing
can change the state of the node, generate additional events, or change
the structure of the scene graph. Routes may be created declaratively in
an X3D file or programmatically via an SAI call.

Routes are not nodes. The ROUTE statement is a construct for
establishing event paths between specified fields of nodes. ROUTE
statements may either appear at the top level of an X3D file or inside a
node wherever fields may appear. A ROUTE statement shall only appear
after the definition of the source and destination nodes. Placing a
ROUTE statement within a node does not associate it with that node in
any way. A ROUTE statement does follow the name scoping rules as
described in <<Runtimenamescope, 4.4.7 Run-time name scope>>.

The type of the destination field shall be the same as the source type,
unless a component or support level permits an extension to this rule.

Redundant routing is ignored. If an X3D file repeats a routing path, the
second and subsequent identical routes are ignored. This also applies
for routes created dynamically using the X3D SAI.

Nodes created through the X3D prototyping mechanism give authors an
opportunity to create custom processing of incoming events. Events
coming into a prototyped node through an interface field can be routed
to internal nodes for processing, or routed to other interface fields
for propagation outside the node. An author can also add programmatic
processing logic to an interface field using the internal scripting
support of the Script node.

[[ExecutionModel]]
===== 4.4.8.3 Execution model

Once a sensor or Script has generated an _initial event_, the event is
propagated from the field producing the event along any ROUTEs to other
nodes. These other nodes may respond by generating additional events,
continuing until all routes have been honoured. This process is called
an <<EventCascade, event cascade>>. All events generated during a
given event cascade are assigned the same timestamp as the initial
event, since all are considered to happen instantaneously.

Some sensors generate multiple events simultaneously. Similarly, it is
possible that asynchronously generated events might arrive at the
identical time as one or more sensor-generated event. In these cases,
all events generated are part of the same initial event cascade and each
event has the same timestamp. The order in which the events are applied
is not considered significant. Conforming X3D worlds shall be able to
accommodate simultaneous events in arbitrary order.

After all events of the initial event cascade are honored, post-event
processing performs actions stimulated by the event cascade. The X3D
browser shall perform the following sequence of actions during a single
timestamp:

[loweralpha]
. Update camera based on currently bound Viewpoint's position and
orientation.
. Evaluate input from sensors.
. Evaluate routes.
. If any events were generated from steps b and c, go to step b and
continue.
. If particle system evaluation is to take place, evaluate the particle
systems here.
. If physics model evaluation is to take place, evaluate the physics
model.

For profiles that support <<Script>> nodes and the Scene
Access Interface, the above order may have several intermediate steps.
Details are described in <<scripting_html, 29 Scripting>>and
<<I19775_2, I.19775-2>>.

<<f-ConceptualExecutionModel, Figure 4.3>> provides a conceptual
illustration of the execution model.

[[f-ConceptualExecutionModel]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ConceptualExecutionModel.png[]

Figure 4.3 — Conceptual execution model

Nodes that contain output events shall produce at most one event per
field per timestamp. If a field is connected to another field via a
ROUTE, an implementation shall send only one event per ROUTE per
timestamp. This also applies to scripts where the rules for determining
the appropriate action for sending output events are defined in
<<scripting_html, 29 Scripting component>>.

[[Loops]]
===== 4.4.8.4 Loops

Event cascades may contain _loops_ where an event _E_ is routed to a
node that generates an event that eventually results in _E_ being
generated again. See <<ExecutionModel, 4.4.8.3 Execution model>>, for
the loop breaking rule that limits each event to one event per
timestamp. This rule shall also be used to break loops created by cyclic
dependencies between different sensor nodes.

[[Fan-inFan-out]]
===== 4.4.8.5 Fan-in and fan-out

_Fan-in_ occurs when two or more routes have the same destination field.
All events are considered to have been received simultaneously;
therefore, the order in which they are processed is not considered
relevant.

_Fan-out_ occurs when one field is the source for more than one route.
This results in sending any event generated by the field along all
routes. All events are considered to have been sent simultaneously;
therefore, the order in which they are processed is not considered
relevant.

[[Components]]
=== 4.5 Components

[[ComponentsOverview]]
==== 4.5.1 Overview

An X3D component is a set of related functionality consisting of various
X3D objects and services as described below.

Components are specified in this standard or may be defined elsewhere.
This standard specifies a set of requirements which shall be satisfied
for a component to be considered an X3D component. Components may be
organized into support levels as provided by the component
specification. The support levels are assigned an integer identifier
starting with level 1 as the simplest support level. Higher numbered
support levels (if specified) should incorporate all of the
functionality of lower numbered support levels. Thus, the support levels
support a hierarchy of functionality.

New components may be defined either through creation of a new part to
this document or through registration. Functionality may be added to an
already defined component by amending the appropriate part of this
document or through registration. Such new functionality shall be in the
form of one or more new levels that augment the functionality already
provided. Levels already defined shall not be subdivided. Each such
addition shall satisfy the requirements for component definition stated
above.

[[DefiningComponents]]
==== 4.5.2 Defining components

The following are the requirements for defining components:

[loweralpha]
. All node objects within a component shall be derived, either directly
or indirectly, from the _<<X3DNode>>_ class.
. All field objects within a component shall be derived from the
_<<X3DField>>_ or _<<X3DArrayField>>_
classes.
. The names for nodes and fields shall follow the naming semantics set
forth in this standard including those for scoping.

Several components are defined in this standard as shown in the
<<componentIndex_html, Component index>>. These components are defined
in their respective parts of this document.. In all cases, the X3D
extension mechanism may be used to add new levels to the components or
may be used to define separate new components.

Each component definition is comprised of:

[loweralpha, start=4]
. a name for the component suitable for use in the COMPONENT statement;
. one or more levels starting with Level 1;
. a list of prerequisites for the component (each prerequisite
consisting of a statement of which level in which other component is
required for support of the component being defined);
. a conceptual description of the functionality being provided;
. a definition of nodes being provided with an indication of in which
level each node is; and
. a statement of conformance for the component.

[[Basecomponents]]
==== 4.5.3 Base components

Components are specified in this standard or may be defined elsewhere.
See the <<componentIndex_html, Component index>> for a list of the
components of X3D which have been formally accepted by the governing
body.

Each component is presented by describing the functionality to be
supported. This is followed by the specification of the abstract nodes
of the component, if any. Following the abstract node specifications,
the concrete nodes of the component are specified. Finally, the support
levels are specified.

The support levels are specified in a table in which the first column
presents the number of each support level. The second column specifies
the prerequisite components that are required by the particular support
level for the component being specified. Each new level is presented
with its prerequisites in a separate row of the table. Subsequent rows
until the next new level are used to specify node support for that
level. The third column specifies the nodes and other features of the
component that are to be supported, in whole or in part, by the
indicated support level. The fourth column specifies any constraints on
the particular feature or node for the indicated support level. For each
support level i+1, all features of the previous support level shall also
be supported.

In the second column, each prerequisite for a support level is listed by
a component name and a support level within that component. These table
entries indicate that, for the X3D browser to claim support for that
level of the component, the X3D browser implementation shall also
support the component and support level(s) listed as a prerequisite. If
there are no prerequisites, the word "None" is specified.

In the third column, abstract nodes introduced at that support level are
listed first followed by the concrete nodes introduced at that support
level.

In the fourth column, a listing of "n/a" means "not applicable". When it
is indicated that a field is "optionally supported", an X3D browser is
not required to support that field. If all fields of a node are to be
entirely supported, the phrase "Full support" is used.

<<t4_5, Table 4.5>> is an example of the format
for a support level table:

[[t4_5]]
Table 4.5 — Example support level table

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1*   |Core 1 Networking 2 | |
|      |              |_X3DTimeDependentNode_ (abstract) |n/a
|      |              |Node1Name     |fieldi optionally supported.
|      |              |Node2Name     |All fields fully supported.
|*2*   |              |              |
|      |              |Level 1 nodes |All fields as supported by Level 1.
|      |              |NodeName      |All fields fully supported.
|===

Any new components defined by amendment or in new parts of this
International Standard shall specify their functionality using the same
format.

[[Profiles]]
=== 4.6 Profiles

[[ProfilesOverview]]
==== 4.6.1 Overview

ISO/IEC 19775 supports the concept of profiles. A profile is a named
collection of functionality and requirements that shall be supported in
order for an implementation to conform to that profile. Profiles are
defined as a set of components and levels of each component as well as
the minimum support criteria for all of the objects contained within
that set.

This document defines seven profiles satisfying varying sets of
requirements:

[loweralpha]
. Core profile (see <<coreprofile_html, Annex A>>)
. Interchange profile (see <<interchange_html, Annex B>>)
. Interactive profile (see <<interactive_html, Annex C>>)
. MPEG-4 interactive profile (see <<MPEG4interactive_html, Annex D>>)
. Immersive profile (see <<immersive_html, Annex E>>)
. Full profile (see <<fullProfile_html, Annex F>>)
. CADInterchange profile (see <<CADInterchange_html, Annex H>>)
. MedicalInterchange profile (see <<MedicalInterchange_html, Annex M>>)

Each set of requirements is directed at supporting the needs of a
particular constituency. Not all constituencies may be satisfied by the
functionality represented by these profiles. Therefore, this document
allows for defining additional profiles either through amendment to this
document or by registration.

A system that conforms to a given profile supports the full set of
objects and capabilities defined for that profile.

[[Definingprofiles]]
==== 4.6.2 Defining profiles

A profile definition consists of the following:

[loweralpha]
. a name for the profile suitable for use in the PROFILE statement;
. an introduction defining the purpose for the profile;
. a list of the components, and levels within those components, which
comprise the profile;
. a statement of conformance criteria for the profile;
. a table containing the node type set supported by the profile stating
the X3D File Limit and Minimum X3D browser Support for each node type;
. a table of other limitations for the profile; and
. any other information specific to the profile.

[[RelationshipBetweenProfilesAndComponents]]
==== 4.6.3 Relationship between profiles and components

A profile consists of a collection of components at given support
levels. A user may also supplement the predefined set of components for
a given profile by specifying extra component statements (see
<<COMPONENTStatement, 7.2.5.4 COMPONENT statement>>). If the user
supplies additional component declarations in addition to the components
and levels defined as part of the profile, the resultant components
supported shall be the union of all components and levels requested.
That is, a user cannot force a lower level of component conformance onto
a profile by explicitly declaring the component with a lower level of
support than that defined by the profile.

A profile definition shall be internally consistent. If a profile
contains components that list prerequisites that are not covered by the
component levels declared for that profile, the prerequisites shall not
be automatically made available. Authors wishing to use these missing
prerequisites shall explicitly declare the component and level required
through the use of the COMPONENT statement.

[[S4.7_SupportLevels]]
=== 4.7 Support levels

The X3D specification may be supported at varying _Levels_, or qualities
of service. Any X3D component may designate a level of service by using
a numbering scheme in which higher-numbered levels denote increasing
qualities of service. A higher level of service may indicate any of the
following:

[loweralpha]
. The presence (or absence) of features;
. Improved support for a particular feature;
. More rigorously defined semantics; or
. More stringent conformance requirements.

Note that service levels between different features do not necessarily
correspond. For example, a profile may contain one component supported
at level 2 and another at level 1. Any profile may combine components
defined at different service levels, provided that the features
interoperate properly, the behavior is deterministic (within practical
limits) and the conformance requirements for that profile and components
are well-defined.

[[Dataencodings]]
=== 4.8 Data encodings

The X3D run-time architecture is independent of the data encoding
format. X3D content and applications can be authored in a variety of
encodings, including textual (XML and Classic VRML encodings) and
binary, either compressed or uncompressed. ISO/IEC 19775 contains an
abstract encoding specification that defines the structure of the X3D
scene: hierarchical relationships among objects, initial values for
objects, and dataflow connections between objects. All concrete data
encodings for X3D shall conform to this abstract specification.

Browsers and generators may support any or all of the standard encoding
formats, depending on their application needs and the conformance
requirements of a specific component or profile.

X3D encodings are fully specified in the parts of <<I19776, ISO/IEC 19776>>.

[[SceneAccessInterface]]
=== 4.9 Scene access interface (SAI)

X3D provides a set of application programmer interfaces (APIs), called
the Scene Access Interface (SAI), that defines run-time access to the
scene. Using the SAI a developer may create and destroy nodes, send
events to nodes, create connections between nodes ( _routes_), read or
set field values in nodes, traverse the scene graph, and control the
operations of the X3D browser. Programmatic access may be _internal_ (
_i.e._, used to create customized elements within the scene graph) or
_external_ ( _i.e._, connecting to program elements outside the scene
such as in a host application such as a web X3D browser). Internal
access is supported via a special node called a <<Script>>
node. Script nodes allow developers to connect programming language
functions and object classes to the scene graph. Fields of a script are
automatically mapped to properties and methods of the object associated
with that script. Script node code may generate events which are
propagated back to the scene graph by the run-time environment. External
access is supported through integration between the X3D run-time system
and a variety of programming language run-time libraries.

The X3D SAI is specified as a set of language-independent services and
bindings to several programming and scripting languages. A complete
specification of the X3D SAI services and the component model interfaces
may be found in <<I19775_2, ISO/IEC 19775-2>>. The language bindings
for the services defined in ISO/IEC 19775-2 are specified in
<<I19777>>. Internal programmatic access is enabled through
the Script node, described in <<scripting_html, 29 Scripting component>>.

[[Componentprofilereg]]
=== 4.10 Component and profile registration

This document allows new concepts to be defined by registration of
components, new levels within components, and profiles. Registration
shall not be used to modify any existing component, level of a
component, or profile. New functionality is registered using the
established procedures of the https://www.iso.org/jtc1/sc24/register[ISO
International Register of Items]^<<Footnote1, 1)>>^. These procedures
require the proposer to supply all information for a new registered item
except for the level number. The level number (if applicable) is
assigned and managed by the ISO International Registration Authority for
the ISO Registry of Items. Registration shall be according to the
procedures in <<I9973, ISO/IEC 9973>>.

^[[Footnote1]]1)^Contact information for the ISO-designated
Registration Authority for Items registered under the ISO/IEC 9973
procedures is available at the ISO Maintenance Agencies and Registration
Authorities web site:
https://www.iso.org/iso/standards_development/maintenance_agencies.htm.

[[fieldTypes_html]]
== 5 Field type reference

[[S5_General]]
=== 5.1 General

This clause describes the syntax and general semantics of _fields_, the
elemental data types used by X3D to define the properties of nodes.
Nodes are composed of fields whose types are defined in this clause. For
more information on nodes, see <<ObjectModel, 4.4.2 Object model>>.

<<t5_1, Table 5.1>> provides links to the major topics in this
clause.

[[t5_1]]
Table 5.1 — Topics

* <<S5_General, 5.1 General>>
* <<AbstractFieldTypes, 5.2 Abstract field types>>
** <<S5_Overview, 5.2.1 Overview>>
** <<X3DArrayField, 5.2.2 _X3DArrayField_>>
** <<X3DField, 5.2.3 _X3DField_>>
* <<FieldTypes, 5.3 Field types>>
** <<SFBoolAndMFBool, 5.3.1 SFBool and MFBool>>
** <<SFColorAndMFColor, 5.3.2 SFColor and MFColor>>
** <<SFColorRGBAAndMFColorRGBA, 5.3.3 SFColorRGBA and MFColorRGBA>>
** <<SFDoubleAndMFDouble, 5.3.4 SFDouble and MFDouble>>
** <<SFFloatAndMFFloat, 5.3.5 SFFloat and MFFloat>>
** <<SFImageAndMFImage, 5.3.6 SFImage and MFImage>>
** <<SFInt32AndMFInt32, 5.3.7 SFInt32 and MFInt32>>
** <<SFMatrix3dAndMFMatrix3d, 5.3.8 SFMatrix3d and MFMatrix3d>>
** <<SFMatrix3fAndMFMatrix3f, 5.3.9 SFMatrix3f and MFMatrix3f>>
** <<SFMatrix4dAndMFMatrix4d, 5.3.10 SFMatrix4d and MFMatrix4d>>
** <<SFMatrix4fAndMFMatrix4f, 5.3.11 SFMatrix4f and MFMatrix4f>>
** <<SFNodeAndMFNode, 5.3.12 SFNode and MFNode>>
** <<SFRotationAndMFRotation, 5.3.13 SFRotation and MFRotation>>
** <<SFStringAndMFString, 5.3.14 SFString and MFString>>
** <<SFTimeAndMFTime, 5.3.15 SFTime and MFTime>>
** <<SFVec2dAndMFVec2d, 5.3.16 SFVec2d and MFVec2d>>
** <<SFVec2fAndMFVec2f, 5.3.17 SFVec2f and MFVec2f>>
** <<SFVec3dAndMFVec3d, 5.3.18 SFVec3d and MFVec3d>>
** <<SFVec3fAndMFVec3f, 5.3.19 SFVec3f and MFVec3f>>
** <<SFVec4dAndMFVec4d, 5.3.20 SFVec4d and MFVec4d>>
** <<SFVec4fAndMFVec4f, 5.3.21 SFVec4f and MFVec4f>>

[[AbstractFieldTypes]]
=== 5.2 Abstract field types

[[S5_Overview]]
==== 5.2.1 Overview

There are two general classes of field types: field types that contain a
single value (where a value may be a single number, a vector, or even an
image), and field types that contain an ordered list of multiple values.
Single-valued field types have names that begin with *`SF`*.
Multiple-valued field types have names that begin with *`MF`*.
Multiple-valued fields are written as an ordered list of values. If the
field has zero values, the value is empty but still represented.

[[X3DArrayField]]
==== 5.2.2 _X3DArrayField_

_X3DArrayField_ is the abstract field type from which all field types
that can contain multiple values are derived. All fields derived from
_X3DArrayField_ have names beginning with *MF* (multiple-valued field).
MF fields may zero or more values, each of which shall be of the type
indicated by the corresponding SF field type. It is illegal for any MF
field to mix values of different SF field types.

EXAMPLE  MFString is a field type that can contain zero or
more character strings.

[[X3DField]]
==== 5.2.3 _X3DField_

_X3DField_ is the abstract field type from which all single values field
types are derived. All fields directly derived from _X3DField_ have
names beginning with *SF* (single-valued field). SF fields may only
contain a single value of the type indicated by the name of the field
type.

EXAMPLE  SFBool is a field type that can contain a single Boolean value.

[[FieldTypes]]
=== 5.3 Field types

[[SFBoolAndMFBool]]
==== 5.3.1 SFBool and MFBool

The SFBool field specifies a single Boolean value. The MFBool field
specifies multiple Boolean values. Each Boolean value represents either
`TRUE` or `FALSE`. How these values are represented is
encoding dependent.

The default value of an uninitialized SFBool field is `FALSE`.
The default value of an uninitialized MFBool field is the empty list.

[[SFColorAndMFColor]]
==== 5.3.2 SFColor and MFColor

The SFColor field specifies one RGB (red-green-blue) colour triple.
MFColor specifies zero or more RGB triples. Each colour is written to
the X3D file as an RGB triple of floating point numbers in the range 0.0
to 1.0.

The default value of an uninitialized SFColor field is (0 0 0). The
default value of an uninitialized MFColor field is the empty list.

[[SFColorRGBAAndMFColorRGBA]]
==== 5.3.3 SFColorRGBA and MFColorRGBA

The SFColorRGBA field specifies one RGBA (red-green-blue-alpha) colour
quadruple that includes alpha (opacity) information. MFColorRGBA
specifies zero or more RGBA quadruples. Each colour is written to the
X3D file as an RGBA quadruple of floating point numbers in the range 0.0
to 1.0. Alpha values range from 0.0 (fully transparent) to 1.0 (fully
opaque).

The default value of an uninitialized SFColorRGBA field is (0 0 0 0).
The default value of an uninitialized MFColorRGBA field is the empty
list.

[[SFDoubleAndMFDouble]]
==== 5.3.4 SFDouble and MFDouble

The SFDouble field specifies one double-precision floating point number.
MFDouble specifies zero or more double-precision floating point numbers.
SFDouble and MFDouble are represented in the X3D file as specified in
the respective encoding.

Implementation of these fields is targeted at the double precision
floating point capabilities of processors. However, it is allowable to
implement this field using fixed point numbering provided at least 14
decimal digits of precision are maintained and that exponents have range
of at least [-12, 12] for both positive and negative numbers.

The default value of an uninitialized SFDouble field is 0.0. The default
value of an MFDouble field is the empty list.

[[SFFloatAndMFFloat]]
==== 5.3.5 SFFloat and MFFloat

The SFFloat field specifies one single-precision floating point number.
MFFloat specifies zero or more single-precision floating point numbers.
SFFloats and MFFloats are represented in the X3D file as specified in
the respective encoding.

Implementation of these fields is targeted at the single precision
floating point capabilities of processors. However, it is allowable to
implement this field using fixed point numbering provided at least six
decimal digits of precision are maintained and that exponents have range
of at least [-12, 12] for both positive and negative numbers.

The default value of an uninitialized SFFloat field is 0.0. The default
value of an MFFloat field is the empty list.

[[SFImageAndMFImage]]
==== 5.3.6 SFImage and MFImage

The SFImage field specifies a single uncompressed 2-dimensional pixel
image. SFImage fields contain three integers representing the width,
height and number of components in the image, followed by width×height
hexadecimal or integer values representing the pixels in the image.
MFImage fields contain zero or more SFImage fields. Each image in an
MFImage field may contain different values for the width, height, and
number of components in the image and hence may have a different number
of hexadecimal or integer values.

Pixel values are limited to 256 levels of intensity ( _i.e._, 0-255
decimal or 0x00-0xFF hexadecimal). A one-component image specifies
one-byte hexadecimal or integer values representing the intensity of the
image. For example, `0xFF` is full intensity in hexadecimal (255
in decimal), `0x00` is no intensity (0 in decimal). A
two-component image specifies the intensity in the first (high) byte and
the alpha opacity in the second (low) byte. Pixels in a three-component
image specify the red component in the first (high) byte, followed by
the green and blue components ( _e.g._, `0xFF0000` is red,
`0x00FF00` is green, `0x0000FF` is blue). Four-component
images specify the alpha opacity byte after red/green/blue (
_e.g._, `0x0000FF80` is semi-transparent blue). A value of
`0x00` is completely transparent, 0xFF is completely opaque. Note
that alpha equals (1.0 -transparency), if alpha and transparency each
range from 0.0 to 1.0.

Each pixel is read as a single unsigned number. For example, a
3-component pixel with value `0x0000FF` may also be written as
`0xFF` (hexadecimal) or `255` (decimal). Pixels are
specified from left to right, bottom to top. The first hexadecimal value
is the lower left pixel and the last value is the upper right pixel.

The default value of an uninitialized SFImage field is (0 0 0). The
default value of an MFImage field is the empty list.

[[SFInt32AndMFInt32]]
==== 5.3.7 SFInt32 and MFInt32

The SFInt32 field specifies one 32-bit integer. The MFInt32 field
specifies zero or more 32-bit integers. SFInt32 and MFInt32 fields are
signed integers.

The default value of an uninitialized SFInt32 field is 0. The default
value of an MFInt32 field is the empty list.

[[SFMatrix3dAndMFMatrix3d]]
==== 5.3.8 SFMatrix3d and MFMatrix3d

The SFMatrix3d field specifies a 3×3 matrix of double-precision floating
point numbers. MFMatrix3d specifies zero or more 3×3 matrices of
double-precision floating point numbers. Each floating point number is
represented in the X3D file as specified in the respective encoding.

SFMatrix3d matrices are organized in row-major fashion. The first row of
the matrix stores information for the _x_ dimension, and the second for
the _y_ dimension. Since these data types are commonly used for 2D
transformation matrices, translation values are stored in the third row.

The default value of an uninitialized SFMatrix3d field is the identity
matrix [1 0 0 0 1 0 0 0 1]. The default value of an uninitialized
MFMatrix3d field is the empty list.

[[SFMatrix3fAndMFMatrix3f]]
==== 5.3.9 SFMatrix3f and MFMatrix3f

The SFMatrix3f field specifies a 3×3 matrix of single-precision floating
point numbers. MFMatrix3f specifies zero or more 3×3 matrices of
single-precision floating point numbers. Each floating point number is
represented in the X3D file as specified in the respective encoding.

SFMatrix3f matrices are organized in row-major fashion. The first row of
the matrix stores information for the _x_ dimension, and the second for
the _y_ dimension. Since these data types are commonly used for 2D
transformation matrices, translation values are stored in the third row.

The default value of an uninitialized SFMatrix3f field is the identity
matrix [1 0 0 0 1 0 0 0 1]. The default value of an uninitialized
MFMatrix3f field is the empty list.

[[SFMatrix4dAndMFMatrix4d]]
==== 5.3.10 SFMatrix4d and MFMatrix4d

The SFMatrix4d field specifies a 4×4 matrix of double-precision floating
point numbers. MFMatrix4d specifies zero or more 4×4 matrices of
double-precision floating point numbers. Each floating point number is
represented in the X3D file as specified in the respective encoding.

SFMatrix4d matrices are organized in row-major fashion. The first row of
the matrix stores information for the _x_ dimension, the second for the
_y_ dimension, and the third for the _z_ dimension. Since these data
types are commonly used for 3D transformation matrices, translation
values are stored in the fourth row.

The default value of an uninitialized SFMatrix4d field is the identity
matrix [1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]. The default value of an
uninitialized MFMatrix4d field is the empty list.

[[SFMatrix4fAndMFMatrix4f]]
==== 5.3.11 SFMatrix4f and MFMatrix4f

The SFMatrix4f field specifies a 4x4 matrix of single-precision floating
point numbers. MFMatrix4f specifies zero or more 4x4 matrices of
single-precision floating point numbers. Each floating point number is
represented in the X3D file as specified in the respective encoding.

SFMatrix4f matrices are organized in row-major fashion. The first row of
the matrix stores information for the _x_ dimension, the second for the
_y_ dimension, and the third for the _z_ dimension. Since these data
types are commonly used for 3D transformation matrices, translation
values are stored in the fourth row.

The default value of an uninitialized SFMatrix4f field is the identity
matrix [1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]. The default value of an
uninitialized MFMatrix4f field is the empty list.

[[SFNodeAndMFNode]]
==== 5.3.12 SFNode and MFNode

The SFNode field specifies an X3D node. The MFNode field specifies zero
or more nodes.

The default value of an uninitialized SFNode field is `NULL`. The
default value of an MFNode field is the empty list.

[[SFRotationAndMFRotation]]
==== 5.3.13 SFRotation and MFRotation

The SFRotation field specifies one arbitrary rotation. The MFRotation
field specifies zero or more arbitrary rotations. An SFRotation is
written to the X3D file as four floating point values. The allowable
form for a floating point number is defined in the specific encoding.
The first three values specify a normalized rotation axis vector about
which the rotation takes place. The fourth value specifies the amount of
right-handed rotation about that axis in angle base units.

The 3x3 matrix representation of a rotation (x y z a) is

[stem]
++++
\begin{pmatrix}
  tx^2 + c & txy+sz  & txz-sy \\
  txy-sz   & ty^2+c  & tyz+sx \\
  txz+sy   & tyz-sx  & tz^2 +c
\end{pmatrix}
++++

where `c = cos(a)`, `s = sin(a)`, and `t = 1-c`.

The default value of an uninitialized SFRotation field is (0 0 1 0). The
default value of an MFRotation field is the empty list.

[[SFStringAndMFString]]
==== 5.3.14 SFString and MFString

The SFString and MFString fields contain strings encoded with the UTF-8
universal character set (see <<I10646, ISO/IEC 10646>>). SFString
specifies a single string. The MFString specifies zero or more strings.
Strings are specified as a sequence of UTF-8 octets.

Any characters (including linefeeds and '#') may appear within the
string.

The default value of an uninitialized SFString outputOnly field is the
empty string. The default value of an MFString field is the empty list.

Characters in <<I10646, ISO/IEC 10646>> are encoded in multiple
octets. Code space is divided into four units, as follows:

[source,listing]
----
+-------------+-------------+-----------+------------+
| Group-octet | Plane-octet | Row-octet | Cell-octet |
+-------------+-------------+-----------+------------+
----

<<I10646, ISO/IEC 10646>> allows two basic forms for characters:

[loweralpha]
. UCS-2 (Universal Coded Character Set-2). This form is also known as
the Basic Multilingual Plane (BMP). Characters are encoded in the lower
two octets (row and cell).
. UCS-4 (Universal Coded Character Set-4). Characters are encoded in the
full four octets.

In addition, two transformation formats (UCS Transformation Format or
UTF) are accepted: UTF-8 and UTF-16. Each represents the nature of the
transformation: 8-bit or 16-bit. UTF-8 and UTF-16 are referenced in
<<I10646, ISO/IEC 10646>>.

UTF-8 maintains transparency for all ASCII code values (0...127). It
allows ASCII text (0x0..0x7F) to appear without any changes and encodes
all characters from 0x80.. 0x7FFFFFFF into a series of six or fewer
bytes.

If the most significant bit of the first character is 0, the remaining
seven bits are interpreted as an ASCII character. Otherwise, the number
of leading 1 bits indicates the number of bytes following. There is
always a zero bit between the count bits and any data.

The first byte is one of the following. The X indicates bits available
to encode the character:

[source,listing]
----
 0XXXXXXX only one byte   0..0x7F (ASCII)
 110XXXXX two bytes       Maximum character value is 0x7FF
 1110XXXX three bytes     Maximum character value is 0xFFFF
 11110XXX four bytes      Maximum character value is 0x1FFFFF
 111110XX five bytes      Maximum character value is 0x3FFFFFF
 1111110X six bytes       Maximum character value is 0x7FFFFFFF
----

All following bytes have the format 10XXXXXX.

As a two byte example, the symbol for a registered trade mark ®, encoded
as 0x00AE in UCS-2 of ISO 10646, has the following two byte encoding in
UTF-8: 0xC2, 0xAE.

[[SFTimeAndMFTime]]
==== 5.3.15 SFTime and MFTime

The SFTime field specifies a single time value. The MFTime field
specifies zero or more time values. Time values are specified as a
double-precision floating point number. The allowable form for a double
precision floating point number is defined in the specific encoding.
Time values are specified as the number of seconds from a specific time
origin. Typically, SFTime fields represent the number of seconds since
Jan 1, 1970, 00:00:00 GMT.

When an SFTime value represents a time-interval duration, negative
values are not allowed. See <<TimeOrigin, 8.2.2 Time origin>> for
further details.

The default value of an uninitialized SFTime field is -1. The default
value of an MFTime field is the empty list.

[[SFVec2dAndMFVec2d]]
==== 5.3.16 SFVec2d and MFVec2d

The SFVec2d field specifies a two-dimensional (2D) vector. An MFVec2d
field specifies zero or more 2D vectors. SFVec2d's and MFVec2d's are
represented as a pair of double-precision floating point values (see
<<SFDoubleAndMFDouble, 5.3.4 SFDouble and MFDouble>>). The allowable
form for a double-precision floating point number is defined in the
specific encoding.

The default value of an uninitialized SFVec2d field is (0 0). The
default value of an MFVec2d field is the empty list.

[[SFVec2fAndMFVec2f]]
==== 5.3.17 SFVec2f and MFVec2f

The SFVec2f field specifies a two-dimensional (2D) vector. An MFVec2f
field specifies zero or more 2D vectors. SFVec2f's and MFVec2f's are
represented as a pair of single-precision floating point values (see
<<SFFloatAndMFFloat, 5.3.5 SFFloat and MFFloat>>). The allowable form
for a single-precision floating point number is defined in the specific
encoding.

The default value of an uninitialized SFVec2f field is (0 0). The
default value of an MFVec2f field is the empty list.

[[SFVec3dAndMFVec3d]]
==== 5.3.18 SFVec3d and MFVec3d

The SFVec3d field or event specifies a three-dimensional (3D) vector. An
MFVec3d field or event specifies zero or more 3D vectors. SFVec3d's and
MFVec3d's are represented as a 3-tuple of double-precision floating
point values (see <<SFDoubleAndMFDouble, 5.3.4 SFDouble and MFDouble>>). The allowable form for a double-precision floating point
number is defined in the specific encoding.

The default value of an uninitialized SFVec3d field is (0 0 0). The
default value of an MFVec3d field is the empty list.

[[SFVec3fAndMFVec3f]]
==== 5.3.19 SFVec3f and MFVec3f

The SFVec3f field or event specifies a three-dimensional (3D) vector. An
MFVec3f field or event specifies zero or more 3D vectors. SFVec3f's and
MFVec3f's are represented as a 3-tuple of single-precision floating
point values (see <<SFFloatAndMFFloat, 5.3.5 SFFloat and MFFloat>>).
The allowable form for a single-precision floating point number is
defined in the specific encoding.

The default value of an uninitialized SFVec3f field is (0 0 0). The
default value of an MFVec3f field is the empty list.

[[SFVec4dAndMFVec4d]]
==== 5.3.20 SFVec4d and MFVec4d

The SFVec4d field or event specifies a three-dimensional (3D)
homogeneous vector. An MFVec4d field or event specifies zero or more 3D
homogeneous vectors. SFVec4d's and MFVec4d's are represented as a
4-tuple of double-precision floating point values (see
<<SFDoubleAndMFDouble, 5.3.4 SFDouble and MFDouble>>). The allowable
form for a double-precision floating point number is defined in the
specific encoding.

The default value of an uninitialized SFVec4d field is (0 0 0 1). The
default value of an MFVec4d field is the empty list.

[[SFVec4fAndMFVec4f]]
==== 5.3.21 SFVec4f and MFVec4f

The SFVec4f field or event specifies a three-dimensional (3D)
homogeneous vector. An MFVec4f field or event specifies zero or more 3D
homogeneous vectors. SFVec4f's and MFVec4f's are represented as a
4-tuple of single-precision floating point values (see
<<SFFloatAndMFFloat, 5.3.5 SFFloat and MFFloat>>). The allowable form
for a single-precision floating point number is defined in the specific
encoding.

The default value of an uninitialized SFVec4f field is (0 0 0 1). The
default value of an MFVec4f field is the empty list.

[[conformance_html]]
== 6 Conformance

[[S6_General]]
=== 6.1 General

[[S6_Topics]]
==== 6.1.1 Topics

This clause addresses conformance of X3D files, X3D generators and X3D
browsers.

The topics covered in this clause are shown in <<t6_1, Table 6.1>>.

[[t6_1]]
Table 6.1 — Topics

[width="100%",cols="100%",]
|===
a|
* <<S6_General, 6.1 General>>
** <<S6_Topics, 6.1.1 Topics>>
** <<Objectives, 6.1.2 Objectives>>
** <<Scope, 6.1.3 Scope>>
* <<S6_Conformance, 6.2 Conformance>>
** <<ConformanceX3Dfiles, 6.2.1 Conformance of X3D files>>
** <<ConformanceX3Dgens, 6.2.2 Conformance of X3D generators>>
** <<ConformanceX3Dbrowsers, 6.2.3 Conformance of X3D browsers>>
* <<Minimumsupport, 6.3 Minimum support requirements>>
** <<Minsupportforgen, 6.3.1 Minimum support requirements for generators>>
** <<Minsupportforbrowser, 6.3.2 Minimum support requirements forX3Dbrowsers>>
|===


[[Objectives]]
==== 6.1.2 Objectives

The primary objectives of the specifications in this clause are:

[loweralpha]
. to promote interoperability by eliminating arbitrary subsets of, or
extensions to, ISO/IEC 19775;
. to promote uniformity in the development of conformance tests;
. to promote consistent results across X3D browsers;
. to facilitate automated test generation.

[[Scope]]
==== 6.1.3 Scope

Conformance is defined for X3D files and for X3D browsers. For X3D
generators, conformance guidelines are presented for enhancing the
likelihood of successful interoperability.

A concept of _base profile conformance_ is defined to ensure
interoperability of X3D generators and X3D browsers. Base profile
conformance is based on a set of limits and minimal requirements. Base
profile conformance is intended to provide a functional level of
reasonable utility for X3D generators while limiting the complexity and
resource requirements of X3D browsers. Base profile conformance may not
be adequate for all uses of X3D.

This clause addresses the X3D data stream and implementation
requirements. Implementation requirements include the latitude allowed
for X3D generators and X3D browsers. This clause does not directly
address the environmental, performance, or resource requirements of the
generator or X3D browser.

This clause does not define the application requirements or dictate
application functional content within a X3D file.

The scope of this clause is limited to rules for the open interchange of
X3D content.

[[S6_Conformance]]
=== 6.2 Conformance

[[ConformanceX3Dfiles]]
==== 6.2.1 Conformance of X3D files

An X3D file is _syntactically correct_ according to this document if the
following conditions are met:

[loweralpha]
. The X3D file contains as its first element an X3D header statement
(see <<HeaderStatement, 7.2.5.2 Header>> statement) specifying the
version to which this file conforms. Versions and associated content are
specified in <<versionContent_html, AnnexZVersion content>>.
. All entities contained therein match the functional specification of
entities of this document that correspond to the version specified in
the header statement. The X3D file shall obey the relationships defined
in the formal grammar and all other syntactic requirements.
. The sequence of entities in the X3D file obeys the relationships
specified in this document for the version specified in the header
statement producing the structure specified in the part of ISO/IEC 19775
for the version specified in the header statement.
. All field values in the X3D file obey the relationships specified in
this document for the version specified in the header statement
producing the structure specified in this document for the version
specified in the header statement.
. No nodes appear in the X3D file other than those specified for the
applicable profile as specified in this document unless specified in a
COMPONENT statement, are required for the encoding technique, or are
those defined by the PROTO or EXTERNPROTO entities should such be
available in the profile.
. No nodes or fields appear in the X3D file other than those defined as
part of the version specified in the header statement.
. The X3D file is encoded according to the rules of <<I19776, ISO/IEC 19776>>.
. It does not contain behaviour described as undefined in this document.

[[ConformanceX3Dgens]]
==== 6.2.2 Conformance of X3D generators

A X3D generator is conforming to ISO/IEC 19775 if all X3D files that are
generated are syntactically correct and meet the requirements state in
<<ConformanceX3Dfiles, 6.2.1 Conformance of X3D files>>.

A X3D generator conforms to a profile if it can be configured such that
all X3D files generated conform to that profile.

[[ConformanceX3Dbrowsers]]
==== 6.2.3 Conformance of X3D browsers

An X3D browser is conforming if:

[loweralpha]
. It is able to read any X3D file that conforms to the profiles and
components supported by that X3D browser for the version(s) and
encoding(s) supported by that browser.
. It implements the functionality specified for all abstract interfaces,
insofar as they are made available in concrete nodes derived from those
interfaces, within the latitude defined for the specified profile,
components, and version and as allowed in this clause.
. It presents the graphical and audio characteristics of the X3D nodes
in any X3D file that conforms to the applicable profile, components, and
version, within the latitude defined for the specified profile,
components, and version and as allowed in this clause.
. It correctly handles user interaction and generation of events as
specified for the applicable profile, components, and version, within
the latitude defined for the specified profile, components, and version
and as allowed in this clause.
. It satisfies the minimum support requirements for X3D browsers for the
applicable profile as enumerated in the table of minimum support
requirements for that profile.

[[Minimumsupport]]
=== 6.3 Minimum support requirements

[[Minsupportforgen]]
==== 6.3.1 Minimum support requirements for generators

There is no minimum complexity which is required of (or appropriate for)
X3D generators. Any compliant set of nodes of arbitrary complexity may
be generated, as appropriate to represent application content, and which
produce only the nodes allowed by the applicable profile, components,
and version.

[[Minsupportforbrowser]]
==== 6.3.2 Minimum support requirements for X3D browsers

Each profile defines the minimum complexity which shall be supported by
an X3D browser in support of that profile. X3D browser implementations
may choose to support greater limits but may not reduce the limits
described for the applicable profile. When the X3D file contains nodes
which exceed the limits implemented by the X3D browser, the results are
undefined. The words "optionally supported" in the minimum browser
support column refers only to the display of the item; in particular,
_set__ events to ignored inputOutput fields shall still generate
corresponding __changed_ events. Where latitude is specified in a table
of minimum support requirements for a particular node, full support is
required for other aspects of that node.

[[core_html]]
== 7 Core component

[[S7_Introduction]]
=== 7.1 Introduction

[[S7_Name]]
==== 7.1.1 Name

The name of this component is "Core". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S7_Overview]]
==== 7.1.2 Overview

This clause describes the Core component of this document . The Core
component supplies the base functionality for the X3D run-time system,
including the abstract base node type, field types, the event model, and
routing. <<t7_1, Table 7.1>> lists the major topics in this
clause.

[[t7_1]]
Table 7.1 — Topics

* <<S7Introduction, 7.1 Introduction>>
** <<S7_Name, 7.1.1 Name>>
** <<S7_Overview, 7.1.2 Overview>>
* <<S7_Concepts, 7.2 Concepts>>
** <<Overviewofthecore, 7.2.1 Overview of the core>>
** <<BindableChildrenNodes, 7.2.2 Bindable children nodes>>
** <<Sensors, 7.2.3 Sensors>>
** <<Metadata, 7.2.4 Metadata>>
*** <<MetadataOverview, 7.2.4.1 Overview>>
*** <<DataTypesForMetadata, 7.2.4.2 Data types for metadata>>
*** <<AssigningMetadataToEntireX3DWorld, 7.2.4.3 Integration with X3D worlds>>
*** <<AssigningMetadataToEntireX3DWorld, 7.2.4.4 Assigning metadata to an entire X3D world>>
** <<AbstractX3DStructure, 7.2.5 Abstract X3D structure>>
*** <<Organization, 7.2.5.1 Organization>>
*** <<HeaderStatement, 7.2.5.2 Header statement>>
*** <<PROFILEStatement, 7.2.5.3 PROFILE statement>>
*** <<COMPONENTStatement, 7.2.5.4 COMPONENT statement>>
*** <<UNITStatement, 7.2.5.5 UNIT statement>>
*** <<METAStatement, 7.2.5.6 META statement>>
*** <<ROUTEStatement, 7.2.5.7 ROUTE statement>>
*** <<PROTOStatement, 7.2.5.8 PROTO statement>>
*** <<EXTERNPROTOStatement, 7.2.5.9 EXTERNPROTO statement>>
* <<S7_AbstractTypes, 7.3 Abstract types>>
** <<X3DBindableNode, 7.3.1 _X3DBindableNode_>>
** <<X3DChildNode, 7.3.2 _X3DChildNode_>>
** <<X3DInfoNode, 7.3.3 _X3DInfoNode_>>
** <<X3DMetadataObject, 7.3.4 _X3DMetadataObject_>>
** <<X3DNode, 7.3.5 _X3DNode_>>
** <<X3DPrototypeInstance, 7.3.6 _X3DPrototypeInstance_>>
** <<X3DSensorNode, 7.3.7 _X3DSensorNode_>>
* <<S7_NodeReference, 7.4 Node reference>>
** <<MetadataBoolean, 7.4.1 MetadataBoolean>>
** <<MetadataDouble, 7.4.2 MetadataDouble>>
** <<MetadataFloat, 7.4.3 MetadataFloat>>
** <<MetadataInteger, 7.4.4 MetadataInteger>>
** <<MetadataSet, 7.4.5 MetadataSet>>
** <<MetadataString, 7.4.6 MetadataString>>
** <<WorldInfo, 7.4.7 WorldInfo>>
* <<S7_SupportLevels, 7.5 Support levels>>

* <<t7_1, Table 7.1 — Topics>>
* <<t7_2, Table 7.2 — Core component support levels>>



[[S7_Concepts]]
=== 7.2 Concepts

[[Overviewofthecore]]
==== 7.2.1 Overview of the core

The Core component provides the minimum functionality required by all
X3D-compliant implementations. The Core component supplies the following
abstract constructs:

[loweralpha]
. X3D field types descended from the abstract type _<<X3DField>>_;
. the base abstract node types _<<X3DNode>>_ and _<<X3DPrototypeInstance>>_;
. all statements;
. commonly used interfaces such as _<<X3DBindableNode>>_;
. the X3D event model and routing;
. abstract file structure; and
. prototyping.

The Core component is a prerequisite component for all other X3D
components.

The Core component may be supported at a variety of
<<SupportLevels, levels>>, allowing for a range of implementations
that are conformant to the X3D architecture, object model and event
model. For more information on these topics, see <<concepts_html, 4. Concepts>>.

[[BindableChildrenNodes]]
==== 7.2.2 Bindable children nodes

Several X3D nodes, such as <<Background>>, <<TextureBackground>>, <<Fog>>,
<<NavigationInfo>>, and all nodes derived from <<X3DViewpointNode>> are 
bindable children nodes, inheriting from the abstract node type
<<X3DBindableNode>>. These nodes have the unique
behaviour that only one of each type can be bound per layer ( _i.e._,
affect the user's experience) at any instant in time. The X3D browser
shall maintain an independent, separate stack for each type of bindable
node in each layer. If there is no <<LayerSet>> node
defined, there shall be only one set of binding stacks that apply to all
nodes in the scene graph. Each of these nodes includes a _set_bind_
inputOnly field and an _isBound_ outputOnly field. The _set_bind_
inputOnly field is used to move a given node to and from its respective
top of stack. A `TRUE` value sent to the _set_bind_ inputOnly
field moves the node to the top of the stack; sending a `FALSE`
value removes it from the stack. The _isBound_ event is output when a
given node is:

[loweralpha]
. moved to the top of the stack;
. removed from the top of the stack;
. pushed down from the top of the stack by another node being placed on top.

That is, _isBound_ events are sent when a given node becomes, or ceases
to be, the active node. The node at the top of the stack (the most
recently bound node) is the active node for its type and is used by the
X3D browser to set the world state. If the stack is empty (
_i.e._, either the X3D file has no bindable nodes for a given type or
the stack has been popped until empty), the default field values for
that node type are used to set world state. The results are undefined if
a multiply instanced (DEF/USE) bindable node is bound.

Bindable nodes only affect the binding stacks of the layer in which they
are defined.

The following rules describe the behaviour of the binding stack for a
node of type _<bindable node>_ (Background, TextureBackground, Fog,
NavigationInfo, or Viewpoint):

[loweralpha, start=4]
. During read, the first encountered _<bindable node>_ in each layer is
bound by pushing it to the top of the _<bindable node>_ stack for that
layer. Nodes contained within files referenced by <<Inline>>
nodes, within the strings passed to the Browser.createX3DFromString()
method, or within X3D files passed to the Browser.createX3DFromURL()
method (see <<I19775_2, Part 2 of ISO/IEC 19775>>) are not candidates
for the first encountered _<bindable node>_. The first node within a
locally defined prototype instance is a valid candidate for the first
encountered _<bindable node>_. The first encountered _<bindable node>_
sends an _isBound_ `TRUE` event.
. When a _set_bind_ `TRUE` event is received by a _<bindable node>_,
[arabic]
.. If it is not on the top of the stack: the current top of stack node
sends an _isBound_ `FALSE` event. The new node is moved to the
top of the stack and becomes the currently bound _<bindable node>_. The
new _<bindable node>_ (top of stack) sends an _isBound_ `TRUE`
event.
.. If the node is already at the top of the stack, this event has no
effect.
. When a _set_bind_ `FALSE` event is received by a _<bindable
node>_ in the stack, it is removed from the stack. If it was on the top
of the stack,
[arabic]
.. it sends an _isBound_ `FALSE` event;
.. the next node in the stack becomes the currently bound _<bindable
node>_ ( _i.e._, pop) and issues an _isBound_ `TRUE` event.
. If a _set_bind_ `FALSE` event is received by a node not in the
stack, the event is ignored and _isBound_ events are not sent.
. When a node replaces another node at the top of the stack, the
_isBound_ `TRUE` and `FALSE` output events from the two
nodes are sent simultaneously ( _i.e._, with identical timestamps).
. If a bound node is deleted, it behaves as if it received a _set_bind_
`FALSE` event (see f above).

A Script node with a field containing a USE reference to a bindable node
has the ability to bind a node directly by changing the value of the
bind field. Setting the bind value is equivalent to receiving a
_set_bind_ event.

The results are undefined if a bindable node is bound and is the child
of an <<LOD>>, <<Switch>>, or any node or prototype
that disables its children. If a bindable node is bound that results in
collision with geometry, the X3D browser shall perform its self-defined
navigation adjustments as if the user navigated to this point (see
<<Collision, 23.3.2 Collision>>).

[[Sensors]]
==== 7.2.3 Sensors

Sensors are nodes that generate events based on external inputs to the
scene graph, such as user input, changes to the viewing environment,
messages from the network or ticks of the system clock. X3D defines the
following types of sensors:

[loweralpha]
. Pointing device sensors (see <<pointingDeviceSensor_html>>),
. Environmental sensors (see <<environmentalSensor_html>>),
. Key device sensors (see <<keyDeviceSensor_html>>),
. Load sensors (see <<networking_html, 9 Networking component>>),
. Time sensors (see <<time_html, 8 Time component>>), and
. Picking sensors (see <<picking_html, 38 Picking component>>).

Sensors are children nodes in the hierarchy and therefore may be
parented by grouping nodes as described in
<<Groupingandchildrennodes, 10.2.1 Grouping and children node types>>.

Each type of sensor defines when an event is generated. The state of the
scene graph after several sensors have generated events shall be as if
each event is processed separately, in order. If sensors generate events
at the same time, the state of the scene graph will be undefined if the
results depend on the ordering of the events.

It is possible to create dependencies between various types of sensors.

EXAMPLE  A TouchSensor may result in a change to a VisibilitySensor
node's transformation, which in turn may cause the VisibilitySensor
node's visibility status to change.

For a detailed description of how dependencies among sensors are handled
during execution, see <<Executionmodel, 4.4.8.3 Execution model>>.

[[Metadata]]
==== 7.2.4 Metadata

[[MetadataOverview]]
===== 7.2.4.1 Overview

Metadata is information that is associated with the objects of the X3D
world but is not a direct part of the world representation. This
document defines an abstract interface
_<<X3DMetadataObject>>_ that identifies a node as
containing metadata and metadata nodes that specify metadata values in
various data types.

[[DataTypesForMetadata]]
===== 7.2.4.2 Data types for metadata

This document specifies four basic representation types:  strings,
single-precision and double-precision floating point values, booleans,
and integers. Each piece of metadata has two additional strings that
describe:

[loweralpha]
. the metadata standard (if any) from which the metadata specification
emanates, and
. the identification for the particular piece of metadata being
provided.

The <<MetadataSet>> node is provided to support cases
when a specific set of metadata requires more than a single data type.

NOTE  Since a metadata node is derived from _<<X3DNode>>_,
the metadata node may itself have metadata.

[[IntegrationWithX3DWorlds]]
===== 7.2.4.3 Integration with X3D worlds

The _<<X3DNode>>_ abstract node type specifies an SFNode
field _metadata_ that may only be populated with nodes derived from
_<<X3DMetadataObject>>_. If the _metadata_ field is
empty, no metadata is associated with the node. Since all nodes in X3D
are derived from _X3DNode_, metadata may be placed anywhere in an X3D
world.

Metadata is not included as part of the depiction of an X3D world.
However, metadata nodes may have a DEF name and the values of the fields
of a metadata node may be accessed by SAI services and can be accessed
using routing.

The content of the value field of a metadata node is not interpreted by
the X3D browser.

Metadata may also be attached to other X3D nodes by setting the metadata
field of that node to a node derived from the X3DMetadataNode abstract
node type.

[[AssigningMetadataToEntireX3DWorld]]
===== 7.2.4.4 Assigning metadata to an entire X3D world

The META statement (see <<METAStatement, 7.2.5.5 META statement>>) may
be used to assign metadata to the entire world. The content of the META
statement is accessible using the SAI. If it is desired that metadata
information that applies to the entire world be provided for access
through routing, a <<WorldInfo>> node containing the
metadata in its metadata field may be inserted as a root node.

[[AbstractX3DStructure]]
==== 7.2.5 Abstract X3D structure

[[Organization]]
===== 7.2.5.1 Organization

An X3D world is conceptually defined as a sequence of nodes and
statements organized as a file. The first item in the file is the Header
statement. The second item in the file is the PROFILE statement. The
PROFILE statement may be optionally followed by one or more COMPONENT,
UNIT and/or META statements in that order. There may be multiple of each
of the COMPONENT, UNIT, and/or META statements. The remainder of the
file consists of the other elements (nodes and statements) defined in
this document .

X3D statements include the following:

* Header,
* PROFILE,
* COMPONENT,
* META,
* UNIT,
* ROUTE,
* PROTO declare,
* EXTERNPROTO declare,
* PROTO interface,
* PROTO body,
* IS,
* connect,
* IMPORT, and
* EXPORT

Syntax and explicit/implicit definition for these statements can vary
among various X3D encodings and language bindings.

ROUTE statements are used to specify the pathways for allowed
transmission of events. These statements link a field in one node to a
field of the same field type in another node.

PROTO statements are used to specify new node types. Such statements
assign a name to the new node type along with a declaration of the
interface for the new node type. This is followed by a definition for
the node type functionality.

EXTERNPROTO statements are used to specify an interface to PROTO or
EXTERNPROTO statements located externally to the local file.

Prototype instances are nodes.

Any additional X3D content loaded into the scene via
<<Inline>> nodes or scenes loaded using createX3DFromStream,
createX3DFromString, or createX3DFromUrl, shall be declared as having a
profile that has an equal or smaller set of required functionality;
_i.e._, there can be no components explicitly declared, or implied by
the profile in that content, that requires functionality not declared in
the original profile and component declarations for the containing
scene. Any UNIT statements within the additional contained external X3D
content are ignored and the units specified in the root file are used.

Although an X3D world is described as being contained in a file, the
file may be conceptual and created dynamically during run-time as
described in <<I19775_2, Part 2 of ISO/IEC 19775>>.

Comments may appear at various places throughout an X3D model, with
syntax varying according to file encoding. Comments have no effect on
scene functionality. Comments are not X3D nodes and not X3D statements.
Comments may be interspersed between other X3D nodes and statements as
long as they do not interfere with the functionality of the model.

[[HeaderStatement]]
===== 7.2.5.2 Header statement

The Header statement is an encoding-dependent statement containing the
following elements:

[loweralpha]
. identification of the standard being supported (for this standard,
this is "X3D");
. version of the standard being supported (for this version of this
document , the version number is "4.0");
. identification of the character encoding being supported (for this
standard, this shall be "UTF-8"), and
. optional comments that may apply to the file.

While the exact representation of this information is dependent on the
encoding, this information shall always be stored as human-readable
text.

[[PROFILEStatement]]
===== 7.2.5.3 PROFILE statement

Every X3D application shall declare a profile at the beginning of
execution. This declaration tells the X3D browser the exact set of
components and their support levels that are required for the
application to run, allowing for a X3D browser to dynamically load the
appropriate components if it so desires, and providing a mechanism for
strict conformance should the X3D browser choose to enforce it. If a
browser supports the combination of declared profiles, components, and
component support levels (see <<COMPONENTStatement, 7.2.5.4 COMPONENT statement>>), it may proceed with presenting the world; otherwise, it
shall fail.

Each PROFILE is equivalent to a precise combination of COMPONENT
statements including names and levels. The Full profile defined to be
the superset of all components and component support levels. The Core
profile is defined to be the minimum set of all components and component
support levels.

The profile is declared via a PROFILE statement immediately following
the Header statement at the top of the file. The form of the PROFILE
statement is:

____
`PROFILE <name>`
____

where name is a string that does not contain whitespace.

The following profiles are defined in this standard:

[loweralpha]
. Core (see <<coreprofile_html, A Core profile>>),
. Interchange (see <<interchange_html, B Interchange profile>>),
. Interactive (see <<interactive_html, C Interactive profile>>),
. MPEG-4 interactive (see <<MPEG4interactive_html, D MPEG-4 interactive profile>>),
. Immersive (see <<immersive_html, E Immersive profile>>),
. Full (see <<fullProfile_html, F Full profile>>),
. CADInterchange (see <<CADInterchange_html, H CAD interchange profile>>) and
. MedicalInterchange (see <<MedicalInterchange_html, M MedicalInterchange profile>>).

The profile name is implicitly qualified by the version number of the
standard (see <<HeaderStatement, 7.2.5.2 Header statement>>). X3D
browsers shall use both the profile name and the version number to
determine the specific characteristics of the profile.

For an X3D model that includes references to Inline nodes, the topmost
model defines the maximum capabilities of the combined models. The
combination of defined PROFILE and COMPONENT statements in the parent
model shall be equivalent to (or a superset of) the union of components
and component support levels identified by the PROFILE and COMPONENT
statements specified in each contained Inline scene.

[[COMPONENTStatement]]
===== 7.2.5.4 COMPONENT statement

X3D applications may explicitly declare additional components required
for the application to run. This is useful for combining features that
do not appear together in a predefined profile, such as adding humanoid
animation support to the Immersive profile. If an X3D browser supports
the combination of declared profile and components, it may proceed with
presenting the world; otherwise, it shall fail.

Declaring a component in a file shall only add support for nodes and
functionality defined in that component at the requested support level.
Nodes that are defined as part of the prerequisite components (see
<<Basecomponents, 4.5.3 Base Components>>) shall not be automatically
included. A user shall declare all components and levels for the nodes
and/or functionality being used either explicitly through the use of the
COMPONENT statement or implicitly through the PROFILE statement.

Components are declared by COMPONENT statements at the top of the file,
immediately following the PROFILE statement but preceding any other
content. The form of the component statement is:

____
`COMPONENT <name> <level>`
____

where <name> is a string that does not contain whitespace, and <level>
is a positive integer.

If support for a component at the desired level is implied by the
application's declared profile, the declaration for that component is
unnecessary but may be included.

[[UNITStatement]]
===== 7.2.5.5 UNIT statement

X3D applications may explicitly alter the initial base units within an
X3D world by inserting UNIT statements defining the characteristics of
the new default base units. At most one UNIT statement shall be provided
for each base unit type. Only the UNIT statements in the root file apply
to an X3D world. If no UNIT statements are provided, the initial base
units as specified in <<Standardunitscoordinates, 4.3.6 Standard units and coordinate system>> shall apply.

UNIT statements contained in X3D files referenced by Inline nodes or
contained in X3D files consisting of EXTERNPROTO bodies shall be used to
align affected units to the base units of the root file before the
referenced X3D file content is incorporated in the X3D world.

UNIT statements may only be contained in X3D worlds created for X3D
version 3.3 or later (as specified in the Header statement). If a
version of 3.2 or earlier is specified in conjunction with UNIT
statements, the X3D browser shall fail.

A change in a base unit is specified by UNIT statements at the top of
the file preceding any element content but in the statement order
specified in <<Organization, 7.2.5.1 Organization>>. The form of the
UNIT statement is:

____
`UNIT <category> <name> <conversionFactor>`
____

where <category> is a string specifying one of the categories in
<<t4_2, Table 4.2>>, <name> is a string that does not
contain whitespace that provides a name for the new default base unit,
and <conversionFactor> is a positive double-precision value that
converts the new default base unit to the initial base unit specified in
<<t4_2, Table 4.2>>.

____
`initialBaseUnit = newDefaultBaseUnit x <conversionFactor>`
____

Direct modification of conversion factors for derived units is not
allowed.

[[METAStatement]]
===== 7.2.5.6 META statement

X3D applications may explicitly declare metadata about the world being
defined. This is done by adding one or more META statements that contain
such information. Such statements do not affect the scene graph but
simply provide additional information in the world.

Metadata that applies to the entire file may be specified by META
statements at the top of the file preceding any element content but in
the statement order specified in <<Organization, 7.2.5.1 Organization>>. 
The form of the META statement is:

____
`META <key> <data>`
____

where <key> is a string that identifies the metadata and <data> is a
string that defines the value for the metadata identified by <key>.

[[ROUTEStatement]]
===== 7.2.5.7 ROUTE statement

X3D applications specify connections between fields of one node to
fields of other nodes using the ROUTE statement. See
<<Routes, 4.4.8.2 Routes>> for a general discussion of routes.

ROUTE statements may appear anywhere in the file and have the following
form:

____
`ROUTE <fromNodeName> <fromFieldName> <toNodeName> <toFieldName>`
____

where <fromNodeName> identifies the node that will generate an event,
<fromFieldName> is the name of the field in the generating node from
which the event will emanate, <toNodeName> identifies the node that will
receive an event, and <toFieldName> identifies the field in the
destination node that will receive the event.

[[PROTOStatement]]
===== 7.2.5.8 PROTO statement

New node types may be defined by X3D applications through use of the
PROTO statement as specified in <<PROTOdefinitionsemantics, 4.4.4 Prototype semantics>>.

PROTO statements may appear anywhere in the file and have the following
form:

____
`PROTO <protoName> <protoInterfaceDeclaration> <protoDefinition>`
____

The <protoName> specifies the name for the new node type.

The <protoInterfaceDeclaration> specifies a list of field definitions.
Each field definition specifies the data type, access type, and name for
the field. For initializeOnly and inputOutput fields, the default value
is also specified. See <<PROTOinterfacedeclsemantics, 4.4.4.2 PROTO interface declaration semantics>> for details.

The <protoDefinition> consists of a list of nodes the first of which is
used to specify the node type for the prototype. This list may
instantiate other prototypes provided that the definitions of the
referenced prototypes precede this PROTO statement. See
<<PROTOdefinitionsemantics, 4.4.4.3 PROTO definition semantics>> for
details.

[[EXTERNPROTOStatement]]
===== 7.2.5.9 EXTERNPROTO statement

Externally defined new node types may be used by X3D applications by
referencing their definition using the EXTERNPROTO statement as
specified in <<Externalprototypesemantics, 4.4.5 External prototype semantics>>.

EXTERNPROTO statements may appear anywhere in the file and have the
following form:

____
EXTERNPROTO <externprotoName> <externprotoInterfaceDeclaration> <externprotoURL>
____

The <externprotoName> specifies the name for the new node type.

The <externprotoInterfaceDeclaration> specifies a list of field
definitions. Each field definition specifies the data type, access type,
and name for the field. The default value for initializeOnly and
inputOutput field is derived as specified in
<<EXTERNPROTOInterfaceSemantics, 4.4.5.2 EXTERNPROTO interface semantics>>.

The <externprotoURL> specifies the location of the definition for the
externally defined prototype. See <<EXTERNPROTOURLSemantics, 4.4.5.3 EXTERNPROTO URL semantics>> for details.


=== 7.3 Abstract types

[[X3DBindableNode]]
==== 7.3.1 _X3DBindableNode_

[source,node]
----
X3DBindableNode : X3DChildNode {
  SFBool [in]     set_bind
  SFNode [in,out] metadata NULL [X3DMetadataObject]
  SFTime [out]    bindTime
  SFBool [out]    isBound
}
----

X3DBindableNode is the abstract node type for all bindable children
nodes, including <<Background>>, <<TextureBackground>>, <<Fog>>,
<<NavigationInfo>> and <<Viewpoint>>. For
complete discussion of bindable behaviors, see
<<BindableChildrenNodes, 7.2.2 Bindable children nodes>>.

[[X3DChildNode]]
==== 7.3.2 _X3DChildNode_

[source,node]
----
X3DChildNode : X3DNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type indicates that the concrete nodes that are
instantiated based on it may be used in _children, addChildren, and
removeChildren_ fields.

More details on related _children_, _addChildren_, and _removeChildren_
fields for parent nodes can be found in
<<Groupingandchildrennodes, 10.2.1 Grouping and children node types>>.

[[X3DInfoNode]]
==== 7.3.3 _X3DInfoNode_

[source,node]
----
X3DInfoNode : X3DChildNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for selected nodes that only contain
information and have no associated rendering.

[[X3DMetadataObject]]
==== 7.3.4 _X3DMetadataObject_

[source,node]
----
X3DMetadataObject { 
  SFString [in,out] name      ""  (Required)
  SFString [in,out] reference "" 
}
----

This abstract interface is the basis for all metadata nodes. The
interface is inherited by all metadata nodes.

The specification of a non-empty value for the _name_ field is required.

The specification of the _reference_ field is optional. If provided, it
identifies the metadata standard or other specification that defines the
_name_ field. If the _reference_ field is not provided or is empty, the
meaning of the _name_ field is considered implicit to the characters in
the string.

[[X3DNode]]
==== 7.3.5 _X3DNode_

[source,node]
----
X3DNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all nodes and node types in
the X3D system.

The _metadata_ field provides information about the current node
contents, as described in <<Metadata, 7.2.4 Metadata>>.

[[X3DPrototypeInstance]]
==== 7.3.6 _X3DPrototypeInstance_

[source,node]
----
X3DPrototypeInstance : X3DNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all prototype instances in
the X3D system. Any user-defined nodes declared with PROTO or
EXTERNPROTO are instantiated using this base type. An
_X3DPrototypeInstance_ may be placed anywhere in the scene graph where
it is legal to place the first node declared within the prototype
instance.

For example, if the base type of first node is _X3DAppearanceNode_, that
prototype may be instantiated anywhere in the scene graph that allows
for an Appearance node (EXAMPLE  Shape). See
<<PROTOdefinitionsemantics, 4.4.4.3 PROTO definition semantics>> for a
further example.

[[X3DSensorNode]]
==== 7.3.7 _X3DSensorNode_

[source,node]
----
X3DSensorNode  : X3DChildNode {
  SFString [in,out] description   ""
  SFBool   [in,out] enabled  TRUE
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
  SFBool   [out]    isActive
}
----

This abstract node type is the base type for all sensors with general
behavior described in <<Sensors, 7.2.3 Sensors>>.

The _description_ field is useful for authors to communicate functional
intent of the interaction with users. Mechanisms for displaying such
description hints are intentionally not specified and may vary among X3D
browsers.

The _enabled_ field either enables or disables sensing by the node.

The _isActive_ field provides a TRUE event when node sensing becomes
active, and a FALSE event when node sensing is stopped.

NOTE It is considered good security practice for X3D browsers to notify
a user when sensing is active.


=== 7.4 Node reference

[[MetadataBoolean]]
==== 7.4.1 MetadataBoolean

[source,node]
----
MetadataBoolean : X3DNode, X3DMetadataObject {
  SFNode   [in,out] metadata  NULL [X3DMetadataObject]
  SFString [in,out] name      ""
  SFString [in,out] reference ""
  MFBool   [in,out] value     []
}
----

The _value_ field provides a list of Boolean metadata whose meaning is
specified by the _name_ field.

[[MetadataDouble]]
==== 7.4.2 MetadataDouble

[source,node]
----
MetadataDouble : X3DNode, X3DMetadataObject {
  SFNode   [in,out] metadata  NULL [X3DMetadataObject]
  SFString [in,out] name      ""
  SFString [in,out] reference ""
  MFDouble [in,out] value     []
}
----

The _value_ field provides a list of double-precision floating-point
metadata whose meaning is specified by the _name_ field.

[[MetadataFloat]]
==== 7.4.3 MetadataFloat

[source,node]
----
MetadataFloat : X3DNode, X3DMetadataObject { 
  SFNode   [in,out] metadata  NULL [X3DMetadataObject]
  SFString [in,out] name      ""
  SFString [in,out] reference ""
  MFFloat  [in,out] value     []
}
----

The _value_ field provides a list of single-precision floating-point
metadata whose meaning is specified by the _name_ field.

[[MetadataInteger]]
==== 7.4.4 MetadataInteger

[source,node]
----
MetadataInteger : X3DNode, X3DMetadataObject { 
  SFNode   [in,out] metadata  NULL [X3DMetadataObject]
  SFString [in,out] name      ""
  SFString [in,out] reference ""
  MFInt32  [in,out] value     []
}
----

The _value_ field provides a list of integer metadata whose meaning is
specified by the _name_ field.

[[MetadataSet]]
==== 7.4.5 MetadataSet

[source,node]
----
MetadataSet : X3DNode, X3DMetadataObject { 
  SFNode   [in,out] metadata  NULL [X3DMetadataObject]
  SFString [in,out] name      ""
  SFString [in,out] reference ""
  MFNode   [in,out] value     [] [X3DMetadataObject]
}
----

The _value_ field provides a list of _X3DMetadataObject_ nodes whose
meaning is specified by the _name_ field.

[[MetadataString]]
==== 7.4.6 MetadataString

[source,node]
----
MetadataString : X3DNode, X3DMetadataObject { 
  SFNode   [in,out] metadata  NULL [X3DMetadataObject]
  SFString [in,out] name      ""
  SFString [in,out] reference ""
  MFString [in,out] value     []
}
----

The _value_ field provides a list of string metadata whose meaning is
specified by the _name_ field.

[[WorldInfo]]
==== 7.4.7 WorldInfo

[source,node]
----
WorldInfo : X3DInfoNode { 
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
  MFString [in,out] info     []
  SFString [in,out] title    ""
}
----

The WorldInfo node contains information about the world. This node is
strictly for documentation purposes and has no effect on the visual
appearance or behaviour of the world.

The _title_ field is intended to store the name or title of the world so
that X3D browsers can present this to the user (perhaps in the window
border). The first WorldInfo _title_ encountered in a parent scene is
used for display. WorldInfo nodes in a parent scene take precedence over
WorldInfo nodes contained in child scenes that are loaded via the Inline
node.

Any other information about the world can be stored in the _info_ field,
such as author information, copyright, and usage instructions.

[[S7.5_SupportLevels]]
=== 7.5 Support levels

The Core component provides two levels of support as specified in
<<t7_2, Table 7.2>>. Level 1 provides the minimum basis
for all profiles and components. Level 2 adds support for prototypes.

[[t7_2]]
Table 7.2 — Core component support levels

[cols="^25%,25%,25%,25%",options="header",]
|===
|*Level* |Prerequisites |*Nodes/Features* |Support
|*1* |None | |
|    |     |_X3DBindableNode_ (abstract) |n/a
|    |     |_X3DChildNode_ (abstract) |n/a
|    |     |_X3DField_ (abstract) |n/a
|    |     |_X3DInfoNode_ (abstract) |n/a
|    |     |_X3DMetadataObject_ (abstract) |n/a
|    |     |_X3DNode_ (abstract) |n/a
|    |     |_X3DPrototypeInstance_ (abstract) |n/a
|    |     |_X3DSensorNode_ (abstract) |n/a
|    |     |MetadataBoolean |All fields are fully supported.
|    |     |MetadataDouble |All fields are fully supported.
|    |     |MetadataFloat |All fields are fully supported.
|    |     |MetadataInteger |All fields are fully supported.
|    |     |MetadataSet |All fields are fully supported.
|    |     |MetadataString |All fields are fully supported.
|    |     |WorldInfo |All fields are fully supported.
|    |     |Statements: +
  Header +
  PROFILE +
  COMPONENT +
  UNIT +
  META |Full support.
|    |     |Field types |All field types. +
|    |     |Event model |As specified in <<EventModel, 4.4.8 Event Model>>.
|    |     |Routing |Full support.
|    |     |Prototyping |Optionally supported.
|    |     |Comments |Full support.
|*2* |None | | 
|    |     |All Level 1 Core objects |As supported in Level 1.
|    |     |Prototyping |Full support.
|===

[[time_html]]
== 8 Time component

[[S8_Introduction]]
=== 8.1 Introduction

[[S8_Name]]
==== 8.1.1 Name

The name of this component is "Time". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S8_Overview]]
==== 8.1.2 Overview

This clause describes the Time component of this document. This includes
a definition of the TimeSensor node, the fundamental means for
connecting the X3D world to the time base of the X3D browser.
<<t8_1, Table 8.1>> links to the major topics in this clause.

[[t8_1]]
Table 8.1 — Topics

* <<S8Introduction, 8.1 Introduction>>
** <<S8_Name, 8.1.1 Name>>
** <<S8_Overview, 8.1.2 Overview>>
* <<S8_Concepts, 8.2 Concepts>>
** <<Timemodel, 8.2.1 Time model>>
** <<TimeOrigin, 8.2.2 Time origin>>
** <<Discreteandcontinuous, 8.2.3 Discrete and continuous changes>>
** <<Time-dependent, 8.2.4 Time-dependent nodes>>
*** <<TimeDependentNodesOverview, 8.2.4.1 Overview>>
*** <<Timecycles, 8.2.4.2 Time cycles>>
*** <<Timeactivation, 8.2.4.3 Time activation>>
*** <<PausingTime, 8.2.4.4 Pausingand resumingtime>>
* <<S8_AbstractTypes, 8.3 Abstract types>>
** <<X3DTimeDependentNode, 8.3.1 _X3DTimeDependentNode_>>
* <<S8_NodeReference, 8.4 Node reference>>
** <<TimeSensor, 8.4.1 TimeSensor>>
* <<S8_SupportLevels, 8.5 Support levels>>

* <<f-Examples, Figure 8.1 — Examples of time-dependent node execution>>

* <<t8_1, Table 8.1 — Topics>>
* <<t8_2, Table 8.2 — Time component support levels>>


[[S8_Concepts]]
=== 8.2 Concepts

[[Timemodel]]
==== 8.2.1 Time model

The X3D browser controls the passage of time in a world by causing
<<TimeSensor>> nodes to generate events as time passes.
Specialized X3D browsers or authoring applications may cause time to
pass more quickly or slowly than in the real world, but typically the
times generated by TimeSensor nodes will approximate "real" time. A
world's creator should make no assumptions about how frequently a
TimeSensor will generate events but can safely assume that each time
event generated will have a timestamp greater than any previous time
event.

[[TimeOrigin]]
==== 8.2.2 Time origin

Time (0.0) is equivalent to 00:00:00 GMT January 1, 1970. Absolute times
are specified in SFTime or MFTime fields as double-precision floating
point numbers representing seconds. Negative absolute times are
interpreted as happening before 1970.

When an SFTime value represents a time-interval duration, negative
values are not allowed.

Processing an event with timestamp _t_ may only result in generating
events with timestamps greater than or equal to _t_.

[[Discreteandcontinuous]]
==== 8.2.3 Discrete and continuous changes

This document does not distinguish between discrete events (such as
those generated by a <<TouchSensor>>) and events that are
the result of sampling a conceptually continuous set of changes (such as
the fraction events generated by a <<TimeSensor>>). An
ideal X3D implementation would generate an infinite number of samples
for continuous changes, each of which would be processed infinitely
quickly.

Before processing a discrete event, all continuous changes that are
occurring at the discrete event's timestamp shall behave as if they
generate events at that same timestamp.

Beyond the requirements that continuous changes be up-to-date during the
processing of discrete changes, the sampling frequency of continuous
changes is implementation dependent. Typically, a TimeSensor affecting a
visible (or otherwise perceptible) portion of the world will generate
events once per _frame_, where a frame is a single rendering of the
world or one time-step in a simulation.

[[Time-dependent]]
==== 8.2.4 Time-dependent nodes

[[TimeDependentNodesOverview]]
===== 8.2.4.1 Overview

<<AudioClip>>, <<MovieTexture>>, and <<TimeSensor>> are examples of nodes 
of <<X3DTimeDependentNode, _X3DTimeDependentNode_>> type that can
activate, pause, resume, and deactivate instantiations of themselves at
specified times. Each of these node types contains the inputOutput
fields: _startTime_, _pauseTime_, _resumeTime_, _stopTime_, _loop_,
_elapsedTime_, _isActive_ and _isPaused_. The values of the inputOutput
fields are used to determine when an instantiated node becomes active or
inactive and enters or exits a paused state. Also, under certain
conditions, these instantiated nodes ignore events to some of their
inputOutput fields. A node ignores an input event by not accepting the
new value and not generating an xxx __changed_ event. An abstract
time-dependent node type can be realized as any one of AudioClip,
MovieTexture, or TimeSensor.

[[Timecycles]]
===== 8.2.4.2 Time cycles

Time-dependent nodes execute in cycles. A cycle is defined by field data
within the node. If, at the end of a cycle, the value of _loop_ is
`FALSE`, execution is terminated (see below for events at
termination). Conversely, if _loop_ is `TRUE` at the end of a
cycle, a time-dependent node continues execution into the next cycle.
Thus, a time-dependent node with _loop_ `TRUE` at the end of
every cycle continues cycling forever if _startTime ≥ stopTime_, or
until _stopTime_ if _startTime < stopTime_, or until the conditions to
pause are set.

The _elapsedTime_ outputOnly field delivers the current elapsed time
since the TimeSensor was activated and running, cumulative in seconds
and not counting any time while in a paused state.

[[Timeactivation]]
===== 8.2.4.3 Time activation

The default values for each of the time-dependent nodes are specified
such that any node with default values is already inactive and resumed
(and, therefore, will generate no events upon loading). A time-dependent
node can be defined such that it will be active upon reading by
specifying _loop_ `TRUE`. This use of a non-terminating
time-dependent node should be used with caution since it incurs
continuous overhead on the simulation.

A time-dependent node generates an _isActive_ `TRUE` event when
it becomes active and generates an _isActive_ `FALSE` event when
it becomes inactive. These are the only times at which an _isActive_
event is generated. In particular, _isActive_ events are not sent at
each tick of a simulation.

A time-dependent node is inactive until its _startTime_ is reached. When
time _now_ becomes greater than or equal to _startTime_, an _isActive_
`TRUE` event is generated and the time-dependent node becomes
active ( _now_ refers to the time at which the browser is simulating and
displaying the virtual world). When a time-dependent node is read from a
X3D file and the ROUTEs specified within the X3D file have been
established, the node should determine if it is active and, if so,
generate an _isActive_ `TRUE` event and begin generating any
other necessary events. However, if a node would have become inactive at
any time before the reading of the X3D file, no events are generated
upon the completion of the read.

An active time-dependent node will become inactive when _stopTime_ is
reached if _stopTime > startTime_. The value of _stopTime_ is ignored if
_stopTime ≤ startTime_. Also, an active time-dependent node will become
inactive at the end of the current cycle if _loop_ is `FALSE`. If
an active time-dependent node receives a _set_loop_ `FALSE`
event, execution continues until the end of the current cycle or until
_stopTime_ (if _stopTime > startTime_), whichever occurs first. The
termination at the end of cycle can be overridden by a subsequent
_set_loop_ `TRUE` event.

Any _set_startTime_ events to an active time-dependent node are ignored.
Any _set_stopTime_ event where _stopTime_ ≤ _startTime_ sent to an
active time-dependent node is also ignored. A _set_stopTime_ event where
_startTime < stopTime ≤ now_ sent to an active time-dependent node
results in events being generated as if _stopTime_ has just been
reached. That is, final events, including an _isActive_ `FALSE`,
are generated and the node becomes inactive. The _stopTime_changed_
event will have the _set_stopTime_ value. Other final events are
node-dependent (see <<TimeSensor, 8.4.1 TimeSensor>>).

A time-dependent node may be restarted while it is active by sending a
_set_stopTime_ event equal to the current time (which will cause the
node to become inactive) and a _set_startTime_ event, setting it to the
current time or any time in the future. These events will have the same
time stamp and should be processed as _set_stopTime_, then
_set_startTime_ to produce the correct behaviour.

<<f-Examples, Figure 8.1>> illustrates the behavior of several common
cases of time-dependent nodes. In each case, the initial conditions of
_startTime_, _stopTime_, _loop_, and the time-dependent node's cycle
interval are labelled, the red region denotes the time period during
which the time-dependent node is active, the arrows represent input
events received by (and output events sent by) the time-dependent node,
and the horizontal axis represents time. Slanted lines indicate the time
interval associated with each cycle.

[[f-Examples]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/timeDep.gif[Time dependent examples,width=336,height=668]

Figure 8.1 — Examples of time-dependent node execution

[[PausingTime]]
===== 8.2.4.4 Pausing and resuming time

While an active time-dependent node is paused, it generates
`TRUE` _isPaused_ and _pauseTime_changed_ events and ceases to
generate all other output events, while maintaining (or "freezing") its
state (holding the last output values and the clock's internal time when
the pausing conditions are met).

An active time-dependent node may be paused when its SFTime fields are
such that _now ≥ pauseTime_ > _resumeTime_. When a time-dependent node
is paused, the time-dependent node shall send out a `TRUE` event
on _isPaused_ and a _pauseTime_changed_ event reporting the simulation
time when the node was paused.

An active but paused time-dependent node shall resume at the first
simulation tick when _now_ ≥ _resumeTime_ > _pauseTime_. The
time-dependent node then resumes generating its output events from the
paused state at the simulation tick. At the time when the node resumes,
the `+fraction_changed+` event continues from its value when paused. A
_resumeTime_changed_ event is also generated reporting the simulation
time when the node was resumed.


=== 8.3 Abstract types

[[X3DTimeDependentNode]]
==== 8.3.1 _X3DTimeDependentNode_

[source,node]
----
X3DTimeDependentNode : X3DChildNode {
  SFString [in,out] description  ""
  SFBool   [in,out] enabled      FALSE
  SFBool   [in,out] loop         FALSE
  SFNode   [in,out] metadata     NULL  [X3DMetadataObject]
  SFTime   [in,out] pauseTime    0     (-∞,∞)
  SFTime   [in,out] resumeTime   0     (-∞,∞)
  SFTime   [in,out] startTime    0     (-∞,∞)
  SFTime   [in,out] stopTime     0     (-∞,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

This abstract node type is the base node type from which all
time-dependent nodes are derived.

The _description_ field specifies a textual description for intended
purpose of the node. This information is beneficial for authoring, and
may be used by optional X3D browser-specific user interfaces that
present users with more detailed information about active time-dependent
behavior.

The _enabled_ field enables and disables operation in a manner
appropriate for the associated node.

See <<S8_Concepts, 8.2 Concepts>> for a detailed discussion of fields and
corresponding behavior responses in time-dependent nodes.


=== 8.4 Node reference

[[TimeSensor]]
==== 8.4.1 TimeSensor

[source,node]
----
TimeSensor : X3DTimeDependentNode, X3DSensorNode {
  SFTime   [in,out] cycleInterval    1     (0,∞)
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFBool   [in,out] loop             FALSE
  SFNode   [in,out] metadata         NULL  [X3DMetadataObject]
  SFTime   [in,out] pauseTime        0     (-∞,∞)
  SFTime   [in,out] resumeTime       0
  SFTime   [in,out] startTime        0     (-∞,∞)
  SFTime   [in,out] stopTime         0     (-∞,∞)
  SFTime   [out]    cycleTime
  SFTime   [out]    elapsedTime
  SFFloat  [out]    fraction_changed
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
  SFTime   [out]    time
}
----

TimeSensor nodes generate events as time passes. TimeSensor nodes can be
used for many purposes including:

[loweralpha]
. driving continuous simulations and animations;
. controlling periodic activities ( _e.g._, one per minute);
. initiating single occurrence events such as an alarm clock.

The TimeSensor node contains two discrete outputOnly fields: _isActive_
and _cycleTime_. The _isActive_ outputOnly field sends `TRUE`
when the TimeSensor node begins running, and `FALSE` when it
stops running. The _cycleTime_ outputOnly field sends a time event at
_startTime_ and at the beginning of each new cycle (useful for
synchronization with other time-based objects). The remaining outputOnly
fields generate continuous events. The _fraction_changed_ outputOnly
field, an SFFloat in the closed interval [0,1], sends the completed
fraction of the current cycle. The _time_ outputOnly field sends the
absolute time for a given _simulation tick_.

If the _enabled_ field is `TRUE`, the TimeSensor node is enabled
and may be running. If a _set_enabled_ `FALSE` event is received
while the TimeSensor node is running, the sensor performs the following
actions:

[loweralpha, start=4]
. evaluates and sends all relevant outputs;
. sends a `FALSE` value for _isActive_;
. disables itself.

Input events on the fields of the TimeSensor node ( _e.g._,
_set_startTime)_ are processed and their corresponding outputOnly fields
( _e.g._, _startTime_changed)_ are sent regardless of the state of the
_enabled_ field. The remaining discussion assumes _enabled_ is
`TRUE`.

The _loop, startTime, stopTime_ and _isActive_ fields and their effects
on the TimeSensor node are discussed in detail in <<S8_Concepts, 8.2 Concepts>>.

The computation of `+elapsedTime+` is defined in
<<Timecycles, 8.2.4.2 Time cycles>>.

The effects of the `+isPaused+`, `+pauseTime+`, and `+resumeTime+`
fields are defined in <<PausingTime, 8.2.4.4 Pausing and resuming time>>.

The cycle of a TimeSensor node lasts for _cycleInterval_ seconds. The
value of _cycleInterval_ shall be greater than zero. If the value of
_cycleInterval_ changes during an active loop, `+fraction_changed+`
events continue to increase smoothly at a correspondingly faster or
slower rate. If the new value of _cycleInterval_ is less than the
currently elapsed cycle duration, then the current loop is complete.

A _cycleTime_ outputOnly field can be used for synchronization purposes
such as sound with animation. The value of a _cycleTime_ event will be
equal to the time at the beginning of the current cycle. A _cycleTime_
event is generated at the beginning of every cycle, including the cycle
starting at _startTime_. The first _cycleTime_ event for a TimeSensor
node can be used as an alarm (single pulse at a specified time).

When a TimeSensor node becomes active, it generates an _isActive_ =
`TRUE` event and begins generating _time_, _fraction_changed_,
and _cycleTime_ events which may be routed to other nodes to drive
animation or simulated behaviours. The behaviour at read time is
described below. The _time_ event sends the absolute time for a given
tick of the TimeSensor node (<<SFTime, SFTime/MFTime>> fields and
events represent the number of seconds since midnight GMT January 1,
1970).

_fraction_changed_ events output a floating point value in the closed
interval [0, 1]. At _startTime_ the value of _fraction_changed_ is 0.
After _startTime_, the value of _fraction_changed_ in any cycle will
progress through the range (0.0, 1.0]. At __startTime__ + N ×
_cycleInterval_, for N = 1, 2, ..., ( _i.e._, at the end of every
cycle), the value of _fraction_changed_ is 1.

Let _now_ represent the time at the current simulation tick. Then the
_time_ and _fraction_changed_ output-only fields can then be computed
as:

[source,listing]
----
   time =    now

temp = ( now - startTime) / cycleInterval
   f = fractionalPart(temp)

 if (f == 0.0 &&    now > startTime)    fraction_changed = 1.0
 else    fraction_changed = f
----

where `+fractionalPart(x)+` is a function that returns the fractional
part, (that is, the digits to the right of the decimal point), of a
nonnegative floating point number.

A TimeSensor node can be set up to be active at read time by specifying
_loop_ `TRUE` (not the default) and __stopTime __less than or
equal to _ startTime_ (satisfied by the default values). The _time_
events output absolute times for each tick of the TimeSensor node
simulation. The _time_ events shall start at the first simulation tick
greater than or equal to _startTime_. _time_ events end at _stopTime_,
or at __startTime __+  _N_ × _cycleInterval_ for some positive integer
value of _N_, or loop forever depending on the values of the other
fields. An active TimeSensor node shall stop at the first simulation
tick when _now_ ≥  _stopTime_ >  _startTime_.

No guarantees are made with respect to how frequently a TimeSensor node
generates time events, but a TimeSensor node shall generate events at
least at every simulation tick. TimeSensor nodes are guaranteed to
generate final _time_ and _fraction_changed_ events. If loop is
`FALSE` at the end of the __N__th cycleInterval and was
`TRUE` at _startTime + M cycleInterval_ for all _0 < M < N_, the
final _time_ event will be generated with a value of ( _startTime + N_ ×
_cycleInterval_) or __stopTime (__if __stopTime __>  _startTime)_,
whichever value is less. If _loop_ is `TRUE` at the completion of
every cycle, the final event is generated as evaluated at _stopTime_ (if
__stopTime __>  _startTime)_ or _never_.

Operation of an active TimeSensor node effectively ignores
_set_startTime_ events. Operation of an active TimeSensor node also
effectively ignores _set_stopTime_ events for  values  less than or
equal to _ startTime_. For example, if a _set_startTime_ event is
received while a TimeSensor node is active, that _set_startTime_ event
is ignored (the _startTime_ field is not changed, and a
_startTime_changed_ event is not generated). If an active TimeSensor
node receives a _set_stopTime_ event that is less than the current time,
and greater than _startTime_, it behaves as if the _stopTime_ requested
is the current time and sends the final events based on the current time
(note that _stopTime_ is set as specified in the field).

A TimeSensor read from an X3D file being loaded during run time shall
generate _isActive_ `TRUE`, _time_ and _fraction_changed_ events
if the sensor is enabled and all conditions for a TimeSensor to be
active are met.

Multiple TimeSensors getting loaded in the same initial scene are all
effectively initiated at the same clock time. Similarly, if the original
model loads Inline nodes with active TimeSensor nodes, each loaded
TimeSensor is consistently synchronized in order to achieve
deterministic behavior results independent of network-loading delays.

[[S8.5_SupportLevels]]
=== 8.5 Support levels

The Time component provides four levels of support as specified in
<<t8_2, Table 8.2>>. Level 1 provides basic support for
TimeSensor. Level 2 adds support for all of the fields of the TimeSensor
node.

[[t8_2]]
Table 8.2 — Time component support levels

[cols="^,,,",options="header",]
|===
|Level |Prerequisites |*Nodes/Features* |Support
|*1* |Core 1 | |

|  | |_X3DTimeDependentNode_ (abstract) |n/a
|  | |TimeSensor |_pauseTime_ optionally supported. _isPaused_
optionally supported. _resumeTime_ optionally supported.

|*2* |Core 1 | |

| | |Level 1 supported node |All fields as supported by Level 1.
| | |TimeSensor |All fields fully supported.
|===

[[networking_html]]
== 9 Networking component

[[S9_Introduction]]
=== 9.1 Introduction

[[S9_Name]]
==== 9.1.1 Name

The name of this component is "Networking". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S9_Overview]]
==== 9.1.2 Overview

This clause describes the Networking component of this document. This
component defines the node types and other features used to access
file-based and streaming resources on the World Wide Web.
<<t9_1, Table 9.1>> lists the major topics in this clause.

[[t9_1]]
Table 9.1 — Topics

* <<S9Introduction, 9.1 Introduction>>
** <<S9_Name, 9.1.1 Name>>
** <<S9_Overview, 9.1.2 Overview>>
* <<S9_Concepts, 9.2 Concepts>>
** <<URLs, 9.2.1 URLs, URNs and URIs>>
** <<RelativeURLs, 9.2.2 Relative URLs>>
** <<ScriptingLanguageProtocols, 9.2.3 Scripting language protocols>>
** <<BrowserProperties, 9.2.4X3Dbrowser options>>
** <<IMPORTStatement, 9.2.5 IMPORT statement>>
** <<EXPORTStatement, 9.2.6 EXPORT statement>>
* <<S9_AbstractTypes, 9.3 Abstract types>>
** <<X3DNetworkSensorNode, 9.3.1 _X3DNetworkSensorNode_>>
** <<X3DUrlObject, 9.3.2 _X3DUrlObject_>>
* <<S9_NodeReference, 9.4 Node reference>>
** <<Anchor, 9.4.1 Anchor>>
** <<Inline, 9.4.2 Inline>>
** <<S9_LoadSensor, 9.4.3 LoadSensor>>
* <<S9_SupportLevels, 9.5 Support levels>>

* <<t9_1, Table 9.1 — Topics>>
* <<t9_2, Table 9.2 —X3Dbrowser options>>
* <<t9_3, Table 9.3 — Networking component support levels>>




[[S9_Concepts]]
=== 9.2 Concepts

[[URLs]]
==== 9.2.1 URLs, URNs and URIs

A URL (Uniform Resource Locator) is a form of Universal Resource
Identifier (URI) described in <<URI>> <<RFC8089>>
that specifies a file located on a particular server and accessed
through a specified protocol (such as `file:`, `http:` or
`https:`). In this document, the upper-case term URL refers to a
Uniform Resource Locator, while the italicized lower-case version _url_
refers to a field which may contain URLs or in-line encoded data.

Higher levels of this component extend the URL support of a X3D browser
to additional forms of URI, such as supporting Uniform Resource Name
(URN) definition, which are another form of URI. A URN allows an
abstract resolution mechanism to be invoked to locate a resource (see
<<RFC8141>>). This allows a resource to be located on the
local machine or a platform dependent resource to be located using the
URN along with platform-specific identifiers.

For levels that support URNs, the _url_ field shall also support the
Web3D Consortium URN Namespace (see <<RFC3541>>) and also
support the Universal Media Library that may be accessed using that
namespace. A URN allows an abstract resolution mechanism to be invoked
to locate a resource (see <<RFC8141>>). This approach
allows a resource to located on the local machine or a platform
dependent resource to be located using the URN along with platform
specific identifiers. A component extension can extend the URL support
of a X3D browser by supporting other URN naming schemes. More
information on the _url_ field may be found in <<X3DUrlObject, 9.3.2 X3DUrlObject>>. More general information on URLs is described in
<<URL, RFC1738>>.

[[RelativeURLs]]
==== 9.2.2 Relative URLs

Relative URLs are handled as described in <<URI>>. All name
scopes (see <<Runtimenamescope, 4.4.7 Run-time name scope>>) maintain
a base URI which is used for all relative URLs within that name scope.
Whenever a node with a relative URL is defined, that node may only
reference assets available within its name scope. It has no advance
knowledge of how it may or may not be included by an Inline node or
referenced by an external prototype instantiation. The base document for
EXTERNPROTO statements or nodes that contain a URL field is:

[loweralpha]
. The X3D file in which an EXTERNPROTO is declared, namely the value of
the _externprotoURL_ field specified in
<<EXTERNPROTOStatement, 7.2.5.9 EXTERNPROTO statement>>.
. The X3D file in which the parent PROTO is declared, if the statement
is inside the body of a prototype declaration, namely the value of the
protoDefinition field specified in <<PROTOStatement, 7.2.5.8 PROTO statement>>.
. The X3D file in which a Script is defined.
. Otherwise, the X3D file from which the statement is read.

[[ScriptingLanguageProtocols]]
==== 9.2.3 Scripting language protocols

Components can add scripting support to an X3D browser. An example of
this is the Scripting component which introduces a <<Script>>
node. The Script node's _url_ field may support custom protocols for the
various scripting languages. For example, a script _url_ prefixed with
_ecmascript:_ (or the deprecated _javascript:_) shall contain ECMAScript
source, with line terminators allowed in the string. The details of each
language protocol are defined in the parts of <<I19777, ISO/IEC 19777>>, which define the bindings for each language. X3D browsers that
conform to a profile that supports scripting are not required to support
both the Java and ECMAScript scripting languages. X3D browsers shall
adhere to the protocol defined in the corresponding part of
<<I19777, ISO/IEC 19777>> for any scripting language that is
supported.

EXAMPLE  The following illustrates the use of mixing custom protocols
and standard protocols in a single _url_ field (order of precedence
determines priority):

[source,listing]
----
#X3D V3.0 utf8
Script {
 url [ "ecmascript: ...", # custom in-line ECMAScript code
 "https://bar.com/foo.js", # ECMAScript file reference
 "https://bar.com/foo.class" ] # Java platform bytecode file reference
}
----

The "..." represents in-line ECMAScript source code.

[[BrowserProperties]]
==== 9.2.4 X3D browser options

X3D supports configuring the X3D browser via a set of options. These
options are values passed to the X3D browser at start-up time that
control its run-time operation. Browser options may be set as HTML PARAM
values within an EMBED or OBJECT tag if the X3D browser is running as an
embedded control within a World Wide Web browser, or through an
application-specific mechanism such as a configuration file or system
registry entry if the X3D browser is running within some other
containing application.

Support for X3D browser options is not required but is strongly
recommended. Some X3D browsers may not support all available options,
due to limitations in the underlying rendering system.

<<t9_2, Table 9.2>> lists the available X3D browser
options.

[[t9_2]]
Table 9.2 — X3D browser options

[cols=",,,",options="header",]
|===
|Name |Description |Type/valid range |Default
|Antialiased |Render using hardware antialiasing if available |Boolean
|False

|Dashboard |Display X3D browser navigation user interface |Boolean
|Specified by bound NavigationInfo in content

|EnableInlineViewpoints |Viewpoints from Inline nodes are included in
list of viewpoints if made available by the Inline node. |Boolean |True

|MotionBlur |Render animations with motion blur |Boolean |False

|PrimitiveQuality |Render quality (tesselation level) for Box, Cone,
Cylinder, Sphere |Low, Medium, High |Medium

|QualityWhenMoving |Render quality while camera is moving |Low, Medium,
High, Same (as while stationary) |Same

|Shading |Specify shading mode for all objects |Wireframe, Flat,
Gouraud, Phong |Phong

|SplashScreen |Display X3D browser splash screen on startup |Boolean
|Implementation-dependent

|TextureQuality |Quality of texture map display |Low, Medium, High
|Medium
|===

[[IMPORTStatement]]
==== 9.2.5 IMPORT statement

The IMPORT statement is used within an X3D file to specify nodes, which
are defined within Inline files or programmatically created content,
that are to be brought into the namespace of the containing file for the
purposes of event routing. Once a node is imported, events may be sent
to its fields via ROUTEs, or routed from any fields of the node which
have output events.

IMPORT statements may appear anywhere in the file and have the following
form:

____
`IMPORT <InlineNodeName>.<ExportedNameFromInlinedFile> [ AS<NewLocalNodeName> ]`
____

The IMPORT statement has the following components:

[loweralpha]
. The name of the Inline node that contains the node to be imported
. The name of the node to import
. An optional name that is used as an alias for the imported node within
the run-time name scope, to help prevent name clashes within the parent
scene containing the IMPORT statement.

The IMPORT statement has the following semantics:

[loweralpha, start=4]
. Once imported, events may be routed to or from the imported node in
exactly the same manner as any node defined with DEF.
. Nodes imported into an X3D scene using the IMPORT statement may not be
instanced via the USE statement.
. Only nodes that are exported from within the Inline via an EXPORT
statement may be imported using a corresponding IMPORT statement.
. The IMPORT statement can appear wherever a ROUTE statement is allowed,
and shall follow the Inline node to which it refers.

The following example illustrates the use of the IMPORT statement
(Classic VRML encoding syntax):

[source,listing]
----
DEF I1 Inline {
  url "someurl.x3d"
}
      . . .

IMPORT I1.rootTransform AS I1Root
DEF PI PositionInterpolator { ... }
ROUTE PI.value_changed TO I1Root.set_translation
----

In the above example, `rootTransform` is defined as a Transform
node in the file someurl.x3d and exported via an EXPORT statement (see
<<EXPORTSemantics, 4.4.6.3 EXPORT semantics>>). The optional AS
keyword defines an alias for `rootTransform` so that within the
containing scene the node is referenced using the DEF name
`I1Root`. All defined alias AS names shall also meet appropriate
uniqueness requirements in the local DEF namespace of the parent scene.

[[EXPORTStatement]]
==== 9.2.6 EXPORT statement

The EXPORT statement is used within an X3D file to specify nodes that
may be imported into other scenes when Inlining that file. Only named
nodes exported with an EXPORT statement are eligible to be imported into
another file.

EXPORT statements may appear anywhere in the file and have the following
form:

____
`EXPORT <NodeName> [ AS <ExportedNodeName> ] `
____

The EXPORT statement has the following components:

[loweralpha]
. The DEF name of the node to be exported
. An optional name that is used as an alias for the exported node when
importing it into other files

The EXPORT statement has the following semantics:

[loweralpha, start=3]
. Once imported into a containing scene, events may be routed to or from
an exported node in exactly the same manner as any node defined with
DEF.
. Exported nodes imported into a containing scene may not be instanced
via the USE statement.
. Exportation may not be propagated across multiple files; that is, a
node imported into one scene using the IMPORT statement may not then be
further exported into another scene using the EXPORT statement.
. Nodes shall not be exported from the body of a PROTO declaration.
. The EXPORT statement can appear wherever a ROUTE statement is allowed,
and shall be contained within the Inline node to which it refers.

The following example illustrates the use of the EXPORT statement
(Classic VRML encoding):

[source,listing]
----
DEF T1 Transform {
   ...
}
     . . .

EXPORT T1 AS rootTransform 
----

In the above example, node `T1` is exported for use by other X3D
scenes. The optional AS keyword defines the exported name of *`T1`* as  `*rootTransform*` ( _i.e._, other scenes may import the
node only using the name  `rootTransform`). All defined alias AS
names shall also meet appropriate uniqueness requirements in the local
DEF namespace of the parent scene.


=== 9.3 Abstract types

[[X3DNetworkSensorNode]]
==== 9.3.1 _X3DNetworkSensorNode_

[source,node]
----
X3DNetworkSensorNode : X3DSensorNode {
  SFString [in,out] description ""
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
  SFBool   [out]    isActive
}
----

This abstract node type is the basis for all sensors that generate
events based on network activity.

[[X3DUrlObject]]
==== 9.3.2 _X3DUrlObject_

[source,node]
----
X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0    [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0 [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  MFString [in,out] url                  []     [URI]
}
----

This abstract interface is inherited by all nodes that contain data
located on the World Wide Web, such as <<AudioClip>>,
<<ImageTexture>> and <<Inline>>.

The _autoRefresh_ field defines the interval in seconds that are
necessary before an automatic reload of the current _url_ asset is
performed. If the preceding file loading fails or the _load_ field is
FALSE, no automatic refresh is performed. If performed, a refresh
attempts to reload the currently loaded entry of the url list. If an
automatic refresh fails to reload the currently loaded _url_ entry, the
X3D browser retries the other entries in the _url_ list.

NOTE  Automatic refresh is different than query and response timeouts
performed by a networking library while sequentially attempting to
retrieve addressed content from a _url_ list.

The _autoRefreshTimeLimit_ field defines the maximum duration that
automatic refresh activity can occur.

WARNING  Automatically reloading content can have security implications
and needs to be considered carefully.

The _description_ field specifies a textual description for the url
asset. This information may be used by X3D browser-specific user
interfaces that wish to present users with more detailed information
about the linked content.

The _load_ field allows deferring when the referenced content is read
and displayed, in profiles that support that field. In profiles that do
not support the _load_ field, _url_ content is loaded immediately.

All _url_ fields can hold multiple string values. The strings in these
fields indicate multiple locations to search for data in the order
listed. If the X3D browser cannot locate or interpret the data specified
by the first location, it shall try the second and subsequent locations
in order until a location containing interpretable data is encountered.
X3D browsers only have to interpret a single string. If no interpretable
locations are found, the node type defines the resultant default
behaviour.

If loading an X3D model, each specified URL shall refer to a valid X3D
file that contains a list of children nodes, prototypes and routes at
the top level as described in <<Groupingandchildrennodes, 10.2.1 Grouping and children node types>>. The results are undefined if the URL
refers to a file that is not a supported file type, or if the file
contains invalid content.

It shall be an error to specify an X3D file in the URL field that has a
set of component definitions that is not a subset of the components of
the containing world. In addition, the components shall not be of a
higher support level than those used by the containing world, either
implicitly or through the PROFILE declaration or additional COMPONENT
statements. When the world indicated by the _url_ field requests
capabilities greater than its parent, the following actions shall occur:

* an error shall be generated,
* the URL shall be treated as not interpretable as specified in
<<X3DUrlObject, 9.3.2 _X3DUrlObject_>>, and
* the next URL shall be loaded and checked in accordance with
<<S9_Concepts, 9.2 Concepts>>.

For more information on URLs, see <<URLs, 9.2.1 URLs, URNs and URIs>>.


=== 9.4 Node reference

[[Anchor]]
==== 9.4.1 Anchor

[source,node]
----
Anchor : X3DGroupingNode,X3DUrlObject { 
  MFNode   [in]     addChildren
  MFNode   [in]     removeChildren
  SFTime   [in,out] autoRefresh          0.0      [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0   [0,∞)
  SFBool   [in,out] bboxDisplay          FALSE
  MFNode   [in,out] children             []       [X3DChildNode]
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL     [X3DMetadataObject]
  MFString [in,out] parameter            []
  MFString [in,out] url                  []       [URI]
  SFBool   [in,out] visible              TRUE
  SFVec3f  []       bboxCenter           0 0 0    (-∞,∞)
  SFVec3f  []       bboxSize             -1 -1 -1 [0,∞) or −1 −1 −1 
}
----

The Anchor grouping node retrieves the content of a URL when the user
activates (such as, clicks) some geometry contained within the Anchor
node's children. If the URL points to a valid X3D file, that world
replaces the world of which the Anchor node is a part (except when the
_parameter_ field, described below, alters this behaviour). If non-X3D
data is retrieved, the X3D browser shall determine how to handle that
data; typically, it will be passed to an appropriate non-X3D browser.

Exactly how a user activates geometry contained by the Anchor node
depends on the pointing device and is determined by the X3D browser.
Typically, clicking with the pointing device will result in the new
scene replacing the current scene. An Anchor node with an empty _url_
does nothing when its children are chosen. A description of how multiple
Anchors and pointing-device sensors are resolved on activation is
contained in <<S20_Concepts, 20.2 Concepts>>.

More details on the _children_, _addChildren_, and _removeChildren_
fields can be found in <<S10_Concepts, 10.2 Concepts>>.

The _description_ field in the Anchor node specifies a textual
description of the Anchor node. This information may be used by X3D
browser-specific user interfaces that wish to present users with more
detailed information about the Anchor.

The _autoRefresh_ and _load_ fields have no effect.

The _parameter_  field may be used to supply any additional information
to be interpreted by the X3D browser. Each string shall consist of
"keyword=value" pairs. For example, some X3D browsers allow the
specification of a "target" for a link to display a link in another part
of an HTML document. The _parameter_ field is then:

[source,listing]
----
Anchor { 
 parameter [ "target=name_of_frame" ];
  ...
}
----

An Anchor node may be used to bind the initial Viewpoint node in a world
by specifying a URL ending with "#ViewpointName" where "ViewpointName"
is the DEF name of a viewpoint defined in the X3D file.

EXAMPLE

[source,listing]
----
Anchor { 
  url "https://www.school.edu/X3D/someScene.wrl#OverView";
    children  Shape { geometry Box {} };
}
----

specifies an anchor that loads the X3D file "someScene.wrl" and binds
the initial user view to the Viewpoint node named "OverView" when the
Anchor node's geometry (Box) is activated. If the named Viewpoint node
is not found in the X3D file, the X3D file is loaded using the default
Viewpoint node binding stack rules (see <<Viewpoint, 23.3.5 Viewpoint>>).

If the _url_ field is specified in the form "#ViewpointName" (
_i.e._, no file name), the Viewpoint node with the given name
("ViewpointName") in the Anchor's run-time name scope(s) shall be bound
( _set_bind_ ``TRUE##). The results are undefined if
there are multiple nodes derived from _X3DViewpointNode_ with the same
name in the Anchor's run-time name scope(s). The results are undefined
if the Anchor node is not part of any run-time name scope or is part of
more than one run-time name scope. See <<Runtimenamescope, 4.4.7 Run-time name scope>> for a description of run-time name scopes. See
<<Viewpoint, 23.3.5 Viewpoint>>, for the _X3DViewpointNode_ transition
rules that specify how X3D browsers shall interpret the transition from
the old node derived from _X3DViewpointNode_ to the new one. For
example:

[source,listing]
----
Anchor { 
  url "#Doorway";
  children Shape { geometry Sphere {} };
}
----

binds the viewer to the viewpoint defined by the "Doorway" viewpoint in
the current world when the sphere is activated. In this case, if the
node derived from _X3DViewpointNode_ is not found, no action occurs on
activation.

More details on the _url_ field are contained in <<URLs, 9.2.1 URLs, URNs and URIs>>.

NOTE  Viewpoint functionality is in addition to the X3DUrlObject
interface characteristics.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the Anchor's children. This is a hint that may be used for
optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the children at
any time. The default _bboxSize_ value, (-1, -1, -1), implies that the
bounding box is not specified and if needed shall be calculated by the
X3D browser. More details on the _bboxCenter_ and _bboxSize_ fields can
be found in <<Boundingboxes, 10.2.2 Bounding boxes>>.

[[Inline]]
==== 9.4.2 Inline

[source,node]
----
Inline : X3DChildNode, X3DBoundedObject, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0      [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0   [0,∞)
  SFBool   [in,out] bboxDisplay          FALSE
  SFString [in,out] description          ""
  SFBool   [in,out] global               FALSE
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL     [X3DMetadataObject]
  MFString [in,out] url                  []       [URI]
  SFBool   [in,out] visible              TRUE
  SFVec3f  []       bboxCenter           0 0 0    (-∞,∞)
  SFVec3f  []       bboxSize             -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The Inline node embeds an X3D scene stored at a location on the World
Wide Web into the current scene.

The _load_ field controls when the Inline scene is read and displayed,
in profiles that support that field. In profiles that do not support the
_load_ field, exactly when the scene is read and displayed is not
defined (such as, reading the scene may be delayed until the Inline
node's bounding box is available to the viewer).

The run-time system can support any number of 3D model resource types as
long as those follow the abstract model definition (see
<<RFC2077, 2.[RFC2077>>]), provide a registered content type ( _e.g._,
`model/x3d-xml`, `model/gltf-bin`, `model/stl`,
etc.), and can be determined with some form of content negotiation (see
<<RFC2616, 2.[RFC2616>>]). The run-time system shall support at least
one X3D type ( _e.g._, `model/x3d-xml`) but can also support and
negotiate any number of X3D encodings and (optionally) non-X3D
representation formats. Support for loading glTF assets (see
<<GLTF, 2.[GLTF>>]) also requires support for Shape component level 2
and Lighting component level 4.

Once the Inline scene is loaded, its children are added to the current
scene and are treated as children of the Inline for rendering and
interaction; however the children are not exposed to the current scene
for routing and DEF name access unless their names have been explicitly
imported into the scene using the IMPORT statement (see
<<IMPORTSemantics, 4.4.6.2 IMPORT semantics>>).

NOTE  When Inline is used to load a child scene, processing of the
Inline content is as specified in the respective PROFILE, COMPONENT,
UNIT, IMPORT, and EXPORT statements.

The _visible_ field specifies whether or not the content within a node
is visually displayed. The value of this field has no effect on
animation behaviors, collision behaviors, event passing, or other
non-visual characteristics.

The _global_ field controls whether lights contained in the Inline scene
are allowed to have external lighting effects or not, according to
<<ScopingOfLights, 17.2.1.2 Scoping of lights>>.

If the _load_ field is set to ``TRUE## (the default field
value), the X3D file specified by the _url_ field is loaded immediately.
If the _load_ field is set to `FALSE`, no action is taken. It is
possible to explicitly load the URL at a later time by sending a
`TRUE` event to the _load_ field (such as, the result of a
ProximitySensor or other sensor firing an event). If a `FALSE`
event is sent to the _load_ field of a previously loaded Inline, the
contents of the Inline will be unloaded from the scene graph.

An event sent to _url_ can be used to change the scene that is inlined
by the Inline node. If this value is set after the Inline is already
loaded, its contents will be unloaded and the scene to which the new URL
points will be loaded.

The user is able to specify a bounding box for the Inline node using the
_bboxCenter_ and _bboxSize_ fields. This is a hint to the X3D browser
and may be used for optimization purposes such as culling.

Note that Shape nodes defined as part of models loaded from prior
versions of X3D have the _castShadow_ field set to `TRUE` when
loaded in the current scene.

Security precaution: it is an error for a model to Inline itself,
directly or indirectly, in order to avoid nonterminating recursion
loops. X3D browsers shall not honor self-referential loading of Inline
model loops in order to avoid security vulnerabilities.

[[S9_LoadSensor]]
==== 9.4.3 LoadSensor

[source,node]
----
LoadSensor : X3DNetworkSensorNode {
  MFNode   [in,out] children    []   [X3DUrlObject]
  SFString [in,out] description ""
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
  SFTime   [in,out] timeOut     0
  SFBool   [out]    isActive
  SFBool   [out]    isLoaded
  SFTime   [out]    loadTime
  SFFloat  [out]    progress
}
----

The LoadSensor monitors the progress and success of downloading URL
elements over a network. Only nodes that contain a valid URL field (
_i.e._, descendants of _X3DUrlObject)_, may be specified in the
_children_ field. Multiple nodes may be watched with a single
LoadSensor.

The _timeOut_ field specifies the maximum time for which the LoadSensor
will monitor loading, starting from when the sensor becomes active. A
value of 0 for the _timeOut_ field indicates an indefinite time out
period; _i.e._, the LoadSensor will wait until loading has completed
either with success or failure.

The _children_ field contains one or more URL objects to monitor. Only
nodes that contain a valid URL field ( _i.e._, descendants of
_X3DUrlObject)_, may be specified as elements of _children_. If multiple
values are specified for this field, output events are generated only
when all of the children have loaded or at least one has failed. If
individual load status information is desired for different nodes,
multiple LoadSensor nodes may be used, each with a single _children_
element.

NOTE:  the original name for the LoadSensor _children_ field in
X3D version 3 is _watchList_. 

If an Anchor node is part of a _children_ field value, _isLoaded_
reports success for this node as follows. There are three cases that
Anchor node can handle:

. binding to a Viewpoint node in the current scene,
. loading a replacement world or file asset, and
. launching a separate window for a file asset.

When binding to a viewpoint (item a above), the asset is loaded when the
Viewpoint is bound. When loading a replacement world or asset (item b
above), no action is taken because the current world is lost. When
launching a separate window or asset (item c above), the load is
considered complete when the operating system or web X3D browser
acknowledges the load request.

The _isActive_ field generates events when loading of the LoadSensor's
_children_ elements begins and ends. An _isActive_ `TRUE` event
is generated when the first element begins loading. An _isActive_
`FALSE` event is generated when loading has completed, either
with a successful load of all objects or a failed load of one of the
objects, or when the timeout period is reached as specified in the
_timeout_ field.

The _isLoaded_ field generates events when loading of the LoadSensor's
_children_ has completed. An _isLoaded_ `TRUE` event is generated
when all of the elements have been loaded. An _isLoaded_ `FALSE`
event is generated when one or more of the elements has failed to load,
or when the timeout period is reached as specified in the _timeout_
field. If all elements in the _children_ are already loaded by the time
the LoadSensor is processed, the LoadSensor shall generate an _isLoaded_
event with value `TRUE` and a _progress_ event with value 1 at
the next event cascade.

The _loadTime_ event is generated when loading of the LoadSensor's
_children_ has successfully completed. If loading fails or the timeout
period is reached, a _loadTime_ event is not generated.

The _progress_ field generates events as loading progresses. The value
of _progress_ is a floating-point number between 0 and 1 inclusive. A
value of 1 indicates complete loading of all _children_ elements. The
exact meaning of all other values ( _i.e._, whether these indicate a
percentage of total bytes, a percentage of total number of files, or
some other measurement) and the frequency with which _progress_ events
are generated are X3D browser-dependent. Regardless, the X3D browser
shall in all cases guarantee that a _progress_ value of 1 is generated
upon successful load of all URL objects.

The following example defines a LoadSensor that monitors the progress of
loading two different ImageTexture nodes:

[source,listing]
----
Shape {
   appearance Appearance {
      material Material {
         texture DEF TEX1 ImageTexture { url "Amypic.png" }
      }
   }
   geometry Sphere {}
}
Shape {
   appearance Appearance {
      material Material {
         texture DEF TEX2 ImageTexture { url "Bmypic.png" }
      }
   }
   geometry Sphere {}
}
DEF LS LoadSensor {
   watchList [ USE TEX1, USE TEX2 ]
}
ROUTE LS.loadTime TO MYSCRIPT.loadTime
----

The events this would generate are:

* Success of all children:
** isLoaded = true
** loadTime = now
** progress = 1
** isActive = false
* Timeout of any children, failure of any children, or no network
present:
** isLoaded = false
** isActive = false

For _children_ elements that allow dynamic reloading of their contents,
any reload of that element (EXAMPLE  changing the _url_
field of an ImageTexture or setting the _load_ field of an Inline),
resets the LoadSensor so that it monitors those elements based on the
new values and resets its _timeout_ period if one was specified.

For streamed media types, the first frame of data available means
successful load of the URL object ( _i.e._, the X3D browser can render
one frame of a movie or start playing an audio file).

[[S9.5_SupportLevels]]
=== 9.5 Support levels

The Networking component provides four levels of support as specified in
<<t9_3, Table 9.3>>.

[[t9_3]]
Table 9.3 — Networking component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |*Nodes/Features* |Support
|*1* |Core 1 |  | 

|  |  |_X3DUrlObject_ (Abstract) |n/a

| | |_X3DNetworkSensorNode_ (Abstract) |n/a

|  |  |Protocols |file: protocol only.

|  |  |Name resolution |Fully-specified URLs.

|*2* |Core 1 +
Grouping 1 |  | 

|  |  |Level 1 supported nodes |Support as specified for Level 1.

| | |Anchor |All fields fully supported.

| | |Inline |All fields except _load_ which is optionally supported.

| | |Protocols |file:, http:, and https: protocols are required.

| | |Name resolution |Relative URLs and URNs.

|*3* |Core 1 +
Grouping 1 | |

|  |  |Level 2 supported nodes |Support as specified for Level 2.

| | |Inline |All fields fully supported.

| | |LoadSensor |All fields fully supported.

|  |  |Statements: +
  IMPORT +
  EXPORT |Full support.

| | |Browser options |Implementation-dependent.

|*4* |Core 1 +
Grouping 1 |  | 

|  |  |Level 3 supported nodes |Support as specified for Level 3.

|  |  |Model support a|
Support for glTF models in _Inline_ nodes, in .gltf
(`model/gltf+json`) and .glb (`model/gltf-binary`)
formats.

Requires support for Shape component level 2 and Lighting component
level 3.

Minimum required glTF support:

* transformation hierarchy,
* meshes,
* physical materials,
* loading of external binary data referenced from .gltf files ( _e.g._,
for vertex coordinates).

|===

[[grouping_html]]
== 10 Grouping component

[[S10_Introduction]]
=== 10.1 Introduction

[[S10_Name]]
==== 10.1.1 Name

The name of this component is "Grouping". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S10_Overview]]
==== 10.1.2 Overview

This clause describes the Grouping component of this document. This
includes how nodes are organized into groups to establish a
transformation hierarchy for the X3D scene graph. <<t10_1, Table 10.1>> provides links to the major topics in this clause.

[[t10_1]]
Table 10.1 — Topics

* <<S10Introduction, 10.1 Introduction>>
** <<S10_Name, 10.1.1 Name>>
** <<S10_Overview, 10.1.2 Overview>>
* <<S10_Concepts, 10.2 Concepts>>
** <<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>
** <<BoundingBoxes, 10.2.2 Bounding boxes>>
* <<S10_AbstractTypes, 10.3 Abstract types>>
** <<X3DBoundedObject, 10.3.1 _X3DBoundedObject_>>
** <<X3DGroupingNode, 10.3.2 _X3DGroupingNode_>>
* <<S10_NodeReference, 10.4 Node reference>>
** <<Group, 10.4.1 Group>>
** <<StaticGroup, 10.4.2 StaticGroup>>
** <<Switch, 10.4.3 Switch>>
** <<Transform, 10.4.4 Transform>>
* <<S10_SupportLevels, 10.5 Support levels>>

* <<t10_1, Table 10.1 — Topics>>
* <<t10_2, Table 10.2 — Grouping component support levels>>




[[S10_Concepts]]
=== 10.2 Concepts

[[GroupingAndChildrenNodes]]
==== 10.2.1 Grouping and children node types

Grouping nodes have a field that contains a list of children nodes. Each
grouping node defines a coordinate space for its children. This
coordinate space is relative to the coordinate space of the node of
which the group node is a child. Such a node is called a _parent_ node.
This means that transformations accumulate down the scene graph
hierarchy.

This document defines several grouping nodes, including the following:

* <<Anchor>>
* <<Billboard>>
* <<Collision>>
* <<Group>>
* <<LOD>>
* <<Switch>>
* <<Transform>>

Components may add the following:

* new grouping node types,
* new node types that may be used as children, and
* node types that may not be used as children.

All grouping nodes have _addChildren_ and _removeChildren_ inputOnly
fields. The _addChildren_ event appends nodes to the _children_ field of
a grouping node. Any nodes passed to the _addChildren_ inputOnly field
that are already in the children list of the grouping node are ignored.
For example, if the _children_ field contains the nodes Q, L and S (in
order) and the group receives an _addChildren_ event containing (in
order) nodes A, L, and Z, the result is a _children_ field containing
(in order) nodes Q, L, S, A, and Z.

The _removeChildren_ event removes nodes from the _children_ field of
the grouping node. Any nodes in the _removeChildren_ event that are not
in the _children_ list of the grouping node are ignored. For example, if
the _children_ field contains the nodes Q, L, S, A and Z and it receives
a _removeChildren_ event containing nodes A, L, and Z, the result is Q,
S.

Note that a variety of node types reference other node types through
fields. Some of these are parent-child relationships, while others are
not (there are node-specific semantics).

All grouping nodes shall have a _children_ field of type MFNode. Adding
a node to this field will add that node to the grouping node's set of
children. A _children_ field is not allowed to directly contain multiple
instances of the same node. A _children_ field is not allowed to contain
nodes that are ancestors of the grouping node.

A variety of node types reference other node types through fields. Some
of these are parent-child relationships ( _e.g._, the children field of
the Transform node) while others are not ( _e.g._, the appearance field
of the Shape node). The field type specifies which type of node may be
placed in them. For instance, the node type of the children field of the
Transform node is MFNode where all nodes shall be derived from
_X3DChildNode_. Therefore, only node types derived from _X3DChildNode_
may be placed there. Shape is legal in the children field because it is
derived from _X3DChildNode_, while Appearance is not. See
<<f-Objecthierarchy, Figure 4.2>> for a complete derivation hierarchy.

New node types may be defined using extension mechanisms, typically
PROTO/EXTERNPROTO declarations and instances. These new node types can
be placed in a node field as long as the field type in the containing
node is part of the derivation hierarchy of the new node type.

[[BoundingBoxes]]
==== 10.2.2 Bounding boxes

Several node types include a bounding box specification comprised of two
fields, _bboxSize_ and _bboxCenter_. A bounding box is a rectangular
parallelepiped of dimension _bboxSize_ centred on the location
_bboxCenter_ in the local coordinate system. This is typically used by
grouping nodes to provide a hint to the X3D browser on the group's
approximate size for culling optimizations. The default size for
bounding boxes (−1, −1, −1) indicates that the user did not specify the
bounding box and the effect shall be as if the bounding box were
infinitely large. A _bboxSize_ value of (0, 0, 0) is valid and
represents a point in space ( _i.e._, an infinitely small box).
Specified _bboxSize_ field values shall be ≥ 0.0 or equal to
(−1, −1, −1). The _bboxCenter_ fields specify a position offset from the
local coordinate system.

The _bboxCenter_ and _bboxSize_ fields may be used to specify a maximum
possible bounding box for the objects inside a grouping node
(EXAMPLE  Transform). These are used as hints to optimize
certain operations such as determining whether or not the group needs to
be drawn. The bounding box shall be large enough at all times to enclose
the union of the group's children's bounding boxes; it shall not include
any transformations performed by the group itself ( _i.e._, the bounding
box is defined in the local coordinate system of the children). Results
are undefined if the specified bounding box is smaller than the true
bounding box of the group.


=== 10.3 Abstract types

[[X3DBoundedObject]]
==== 10.3.1 _X3DBoundedObject_

[source,node]
----
X3DBoundedObject { 
  SFBool  [in,out] bboxDisplay FALSE
  SFBool  [in,out] visible     TRUE
  SFVec3f []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f []       bboxSize    -1 -1 -1 [0,∞) or −1 −1 −1
}
----

This abstract interface is the basis for all node types that have bounds
specified as part of the definition.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the grouping node's children. This is a hint that may be used
for optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the children at
any time. A default _bboxSize_ value, (-1, -1, -1), implies that the
bounding box is not specified and, if needed, is calculated by the X3D
browser. A description of the _bboxCenter_ and _bboxSize_ fields is
contained in <<BoundingBoxes, 10.2.2 Bounding boxes>>.

When _bboxDisplay_ is true, the bounding box is displayed for the
associated geometry so that both are aligned with world coordinates. The
bounding box is displayed regardless of whether contained content is
visible.

The _visible_ field specifies whether or not the content within a node
is visually displayed. The value of this field has no effect on
animation behaviors, collision behaviors, event passing, or other
non-visual characteristics.

[[X3DGroupingNode]]
==== 10.3.2 _X3DGroupingNode_

[source,node]
----
X3DGroupingNode : X3DChildNode, X3DBoundedObject { 
  MFNode  [in]     addChildren             [X3DChildNode]
  MFNode  [in]     removeChildren          [X3DChildNode]
  MFNode  [in,out] children       []       [X3DChildNode]
  SFBool  [in,out] bboxDisplay    FALSE
  SFNode  [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool  [in,out] visible        TRUE
  SFVec3f []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f []       bboxSize       -1 -1 -1 [0,∞) or −1 −1 −1
}
----

This abstract node type indicates that concrete node types derived from
it contain children nodes and is the basis for all aggregation.

More details on the _children_, _addChildren_, and _removeChildren_
fields can be found i <<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>.


=== 10.4 Node reference

[[Group]]
==== 10.4.1 Group

[source,node]
----
Group : X3DGroupingNode {
  MFNode  [in]     addChildren             [X3DChildNode]
  MFNode  [in]     removeChildren          [X3DChildNode]
  MFNode  [in,out] children       []       [X3DChildNode]
  SFBool  [in,out] bboxDisplay    FALSE
  SFNode  [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool  [in,out] visible        TRUE
  SFVec3f []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f []       bboxSize       -1 -1 -1 [0,∞) or −1 −1 −1
}
----

A Group node contains children nodes without introducing a new
transformation. It is equivalent to a <<Transform>> node
containing an identity transform.

More details on the _children_, _addChildren_, and _removeChildren_
fields can be found in <<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the Group node's children. This is a hint that may be used for
optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the children at
any time. A default _bboxSize_ value, (-1, -1, -1), implies that the
bounding box is not specified and, if needed, is calculated by the X3D
browser. A description of the _bboxCenter_ and _bboxSize_ fields is
contained in <<BoundingBoxes, 10.2.2 Bounding boxes>>.

[[StaticGroup]]
==== 10.4.2 StaticGroup

[source,node]
----
StaticGroup : X3DChildNode, X3DBoundedObject {
  SFBool  [in,out] bboxDisplay FALSE
  SFNode  [in,out] metadata    NULL      [X3DMetadataObject]
  SFBool  [in,out] visible     TRUE
  MFNode  []       children    []        [X3DChildNode]
  SFVec3f []       bboxCenter  0 0 0     (-∞,∞)
  SFVec3f []       bboxSize    -1 -1 -1  [0,∞) or −1 −1 −1
}
----

The StaticGroup node contains children nodes which cannot be modified.
StaticGroup children are guaranteed to not change, send events, receive
events or contain any USE references outside the StaticGroup. This
allows the X3D browser to optimize this content for faster rendering and
less memory usage.

A X3D browser shall prevent all illegal attempts to modify the
StaticGroup and its children. Children of the StaticGroup are guaranteed
not to generate events.

Implementations are free to rearrange or remove nodes inside a
StaticGroup as long as the final rendering is the same. These
optimizations might include flattening a series of transformations into
one transform, performing appearance bundling or heavy analysis of the
scene graph for maximal rendering speed. A StaticGroup does not need to
maintain its children's X3D representations (such as field data), as
they cannot be accessed after creation time.

The _visible_ field specifies whether or not the content within a node
is visually displayed. The value of this field has no effect on
animation behaviors, collision behaviors, event passing, or other
non-visual characteristics.

[[Switch]]
==== 10.4.3 Switch

[source,node]
----
Switch : X3DGroupingNode {
  MFNode  [in]     addChildren             [X3DChildNode]
  MFNode  [in]     removeChildren          [X3DChildNode]
  MFNode  [in,out] children       []       [X3DChildNode]
  SFBool  [in,out] bboxDisplay    FALSE
  SFNode  [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool  [in,out] visible        TRUE
  SFInt32 [in,out] whichChoice    -1       [-1,∞)
  SFVec3f []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f []       bboxSize       -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The Switch grouping node traverses zero or one of the nodes specified in
the _children_ field.

<<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>,
describes details on the types of nodes that are legal values for
_children_.

The _whichChoice_ field specifies the index of the child to traverse,
with the first child having index 0. If _whichChoice_ is less than zero
or greater than the number of nodes in the _children_ field, nothing is
chosen.

All nodes under a Switch continue to receive and send events regardless
of the value of _whichChoice_. For example, if an active TimeSensor is
contained within an inactive choice of an Switch, the TimeSensor sends
events regardless of the Switch's state.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the Switch node's children. This is a hint that may be used for
optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the child with
the largest bounding box at any time. A default _bboxSize_ value, (-1,
-1, -1), implies that the bounding box is not specified and, if needed,
is calculated by the X3D browser. A description of the _bboxCenter_ and
_bboxSize_ fields is contained in <<BoundingBoxes, 10.2.2 Bounding boxes>>.

[[Transform]]
==== 10.4.4 Transform

[source,node]
----
Transform : X3DGroupingNode {
  MFNode     [in]     addChildren               [X3DChildNode]
  MFNode     [in]     removeChildren            [X3DChildNode]
  SFVec3f    [in,out] center           0 0 0    (-∞,∞)
  MFNode     [in,out] children         []       [X3DChildNode]
  SFBool     [in,out] bboxDisplay      FALSE
  SFNode     [in,out] metadata         NULL     [X3DMetadataObject]
  SFRotation [in,out] rotation         0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] scale            1 1 1    (-∞, ∞)
  SFRotation [in,out] scaleOrientation 0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] translation      0 0 0    (-∞,∞)
  SFBool     [in,out] visible          TRUE
  SFVec3f    []       bboxCenter       0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize         -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The Transform node is a grouping node that defines a coordinate system
for its children that is relative to the coordinate systems of its
<<S4_TransformationHierarchy, 4.3.5 Transformation hierarchy>> and 
coordinate system] for a description of coordinate systems and
transformations.

<<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>,
provides a description of the _children_, _addChildren_, and
_removeChildren_ fields.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the children of the Transform node. This is a hint that may be
used for optimization purposes. The results are undefined if the
specified bounding box is smaller than the actual bounding box of the
children at any time. A default _bboxSize_ value, (-1, -1, -1), implies
that the bounding box is not specified and, if needed, shall be
calculated by the X3D browser. The bounding box shall be large enough at
all times to enclose the union of the group's children's bounding boxes;
it shall not include any transformations performed by the group itself (
_i.e._, the bounding box is defined in the local coordinate system of
the children). A description of the _bboxCenter_ and _bboxSize_ fields
is provided in <<BoundingBoxes, 10.2.2 Bounding boxes>>.

The _translation_, _rotation_, _scale_, _scaleOrientation_ and _center_
fields define a geometric 3D transformation consisting of (in order):

[loweralpha]
. a (possibly) non-uniform scale about an arbitrary point;
. a rotation about an arbitrary point and axis;
. a translation.

The _center_ field specifies a translation offset from the origin of the
local coordinate system (0,0,0). The _rotation_ field specifies a
rotation of the coordinate system. The _scale_ field specifies a
non-uniform scale of the coordinate system. Scale values may have any
value: positive, negative (indicating a reflection), or zero. A value of
zero indicates that any child geometry shall not be displayed. The
_scaleOrientation_ specifies a rotation of the coordinate system before
the scale (to specify scales in arbitrary orientations). The
_scaleOrientation_ applies only to the scale operation. The
_translation_ field specifies a translation to the coordinate system.

Given a 3-dimensional point *P* and Transform node, *P* is transformed
into point *P'* in its parent's coordinate system by a series of
intermediate transformations. In matrix transformation notation, where C
( _center_), SR ( _scaleOrientation_), T ( _translation_), R (
_rotation_), and S ( _scale_) are the equivalent transformation
matrices,

[source,listing]
----
  P' = T * C * R * SR * S * -SR * -C * P
----

The following Transform node:

[source,listing]
----
Transform {
  center           C
  rotation         R
  scale            S
  scaleOrientation SR
  translation      T
  children         [
    # Point P (or children holding other geometry)
  ]
}
----

is equivalent to the nested sequence of:

[source,listing]
----
Transform {
  translation T 
  children Transform {
    translation C
    children Transform {
      rotation R
      children Transform {
        rotation SR 
        children Transform {
          scale S 
          children Transform {
            rotation -SR 
            children Transform {
              translation -C
              children [
                # Point P (or children holding other geometry)
              ]
}}}}}}}
----

[[S10.5_SupportLevels]]
=== 10.5 Support levels

The Grouping component provides four levels of support as specified in
<<t10_2, Table 10.2>>.

[[t10_2]]
Table 10.2 — Grouping component support levels

[cols="^,,,",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 | |
| | |_X3DBoundedObject_ (abstract) |n/a
| | |_X3DGroupingNode_ (abstract) |n/a
| | |Group |_addChildren_ optionally supported. _removeChildren_
optionally supported. Otherwise as for all groups.
| | |Transform |_addChildren_ optionally supported. _removeChildren_
optionally supported. Otherwise as for all groups.

|*2* |Core 1 | |
| | |All Level 1 Grouping nodes |All fields fully supported.
| | |Switch |All fields fully supported.

|*3* |Core 1 | |
| | |All Level 2 Grouping nodes |All fields fully supported.
| | |StaticGroup |All fields fully supported.
|===

[[rendering_html]]
== 11 Rendering component

[[S11_Introduction]]
=== 11.1 Introduction

[[S11_Name]]
==== 11.1.1 Name

The name of this component is "Rendering". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S11_Overview]]
==== 11.1.2 Overview

This clause describes the Rendering component of this document. This
includes fundamental rendering primitives such as
<<TriangleSet>> and <<PointSet>> nodes, and
geometric properties nodes that define how coordinate indices, colors,
normals and texture coordinates are specified. <<t11_1, Table 11.1>> provides links to the major topics in this clause.

[[t11_1]]
Table 11.1 — Topics

* <<S11Introduction, 11.1 Introduction>>
** <<S11_Name, 11.1.1 Name>>
** <<S11_Overview, 11.1.2 Overview>>
* <<S11_Concepts, 11.2 Concepts>>
** <<Renderingprimitives, 11.2.1 Rendering primitives>>
** <<Geometricproperties, 11.2.2 Geometric properties>>
*** <<GeometricPropertiesOverview, 11.2.2.1 Overview>>
*** <<ColorModel, 11.2.2.2 Colourmodel>>
*** <<Coordinates, 11.2.2.3 Coordinates>>
*** <<Normals, 11.2.2.4 Normals>>
*** <<PointsLinesRendering, 11.2.2.5 Points and lines rendering>>
** <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>
** <<ClipPlanes, 11.2.4 Clip planes>>
*** <<ClipPlanesOverview, 11.2.4.1 Overview>>
*** <<ClipPlaneSemantics, 11.2.4.2 Clip plane semantics>>
*** <<S11_TransformationHierarchy, 11.2.4.3 Transformation hierarchy>>
*** <<ScopingOfClipPlanes, 11.2.4.4 Scoping of clip planes>>
*** <<ClipPlaneLimitations, 11.2.4.5 Clip plane limitations>>
* <<S11_AbstractTypes, 11.3 Abstract types>>
** <<X3DColorNode, 11.3.1 _X3DColorNode_>>
** <<X3DComposedGeometryNode, 11.3.2 _X3DComposedGeometryNode_>>
** <<X3DCoordinateNode, 11.3.3 _X3DCoordinateNode_>>
** <<X3DGeometricPropertyNode, 11.3.4 _X3DGeometricPropertyNode_>>
** <<X3DGeometryNode, 11.3.5 _X3DGeometryNode_>>
** <<X3DNormalNode, 11.3.6 _X3DNormalNode_>>
* <<S11_NodeReference, 11.4 Node reference>>
** <<ClipPlane, 11.4.1 ClipPlane>>
** <<Color, 11.4.2 Color>>
** <<ColorRGBA, 11.4.3 ColorRGBA>>
** <<Coordinate, 11.4.4 Coordinate>>
** <<CoordinateDouble, 11.4.5 CoordinateDouble>>
** <<IndexedLineSet, 11.4.6 IndexedLineSet>>
** <<IndexedTriangleFanSet, 11.4.7 IndexedTriangleFanSet>>
** <<IndexedTriangleSet, 11.4.8 IndexedTriangleSet>>
** <<IndexedTriangleStripSet, 11.4.9 IndexedTriangleStripSet>>
** <<LineSet, 11.4.10 LineSet>>
** <<Normal, 11.4.11 Normal>>
** <<PointSet, 11.4.12 PointSet>>
** <<TriangleFanSet, 11.4.13 TriangleFanSet>>
** <<TriangleSet, 11.4.14 TriangleSet>>
** <<TriangleStripSet, 11.4.15 TriangleStripSet>>
* <<S11_SupportLevels, 11.5 Support levels>>

* <<f-EffectsOfLocalClipPlanesOnGeometry, Figure 11.1 — Effects of clip planes on geometry>>
* <<f-TriangleFanSet, Figure 11.2 — TriangleFanSet node>>
* <<f-TriangleSet, Figure 11.3 — TriangleSet node>>
* <<f-TriangleStripSet, Figure 11.4 — TriangleStripSet node>>

* <<t11_1, Table 11.1 — Topics>>
* <<t11_2, Table 11.2 — Rendering component support levels>>




[[S11_Concepts]]
=== 11.2 Concepts

[[Renderingprimitives]]
==== 11.2.1 Rendering primitives

The following nodes represent the fundamental visual objects common to
polygonal rendering systems:

[loweralpha]
. <<IndexedLineSet>>,
. <<IndexedTriangleFanSet>>,
. <<IndexedTriangleSet>>,
. <<IndexedTriangleStripSet>>,
. <<PointSet>>,
. <<TriangleFanSet>>,
. <<TriangleSet>>, and
. <<TriangleStripSet>>.

Most complex geometries, such as those found in the
<<geometry3D_html, 13 Geometry3D component>> and
<<geometry2D_html, 14 Geometry2D component>>, can be implemented as a
combination of these nodes. The Rendering component provides these nodes
as basic services for building arbitrary geometry types.

All of the rendering primitive nodes are descendants of the
_<<X3DGeometryNode>>_ type.

[[Geometricproperties]]
==== 11.2.2 Geometric properties

[[GeometricPropertiesOverview]]
===== 11.2.2.1 Overview

Several geometry nodes contain <<Coordinate>>,
<<Color>> or <<ColorRGBA>>, <<Normal>>,
and <<TextureCoordinate>> as geometric property
node types. The geometric property node types are defined as individual
node types so that instancing and sharing is possible between different
geometry nodes. The <<TextureCoordinate>> node type
is defined in <<texturing_html, 18 Texturing component>>.

[[ColorModel]]
===== 11.2.2.2 Colour model

Colour in X3D is specified using the RGB colour model in which the three
components of colour specifications are red, green, and blue ranging in
value from 0 to 1. This colour model results in a colour specification
of (0,0,0) representing black and (1,1,1) representing white. Colour may
also be specified using the RGBA colour model in which a fourth alpha
component specifies a value ranging from 0 (fully transparent) to 1
(fully opaque). See <<FOLEY>> for more information on the RGB
colour model.

[[Coordinates]]
===== 11.2.2.3 Coordinates

Coordinates in X3D are specified as an (x, y, z) triplet in a
right-handed, rectangular coordinate system.

[[Normals]]
===== 11.2.2.4 Normals

Normals define perpendicular directions from a piece of geometry and are
used to perform lighting calculations. They may either be specified as
part of the content or computed directly from the geometry by the X3D
browser. When specified as part of the content, each normal vector shall
have unit length.

[[PointsLinesRendering]]
===== 11.2.2.5 Points and lines rendering

It is not possible to automatically calculate normal vectors for line
and point geometry nodes (<<IndexedLineSet>>,
<<PointSet, LineSet>>, <<PointSet>>). Therefore, the
following rules apply when rendering these nodes:

* Emissive colors are the primary means of rendering these nodes. The
_emissiveColor_ and _emissiveTexture_ fields typically control glowing
effects.
* If the <<Material>> node is used together with unlit
points and lines, geometry shall be rendered as unlit and only the
_emissiveColor_ is used.
+
_Note_: The _emissiveTexture_ of <<Material>> node is
ignored in this case. Using the _Material.emissiveColor_ is a special
rule, only to provide compatibility with X3D 3, which is why it is
deliberately limited, and does not provide any way to use
_Material.emissiveTexture_ or any _PhysicalMaterial_ feature on unlit
point and lines.
* If the _normal_ field contains a <<Normal>> node, points and
lines shall be rendered using the same lighting equations as the other
geometry and can be lit.
* If the _normal_ information is not provided (the _normal_ field
remains `NULL`), points and lines shall be rendered using the
"unlit" lighting equations, following <<LightingUnlit, 17.2.2.4 Unlit lighting model>>. Authors are advised to use
<<UnlitMaterial>> to customize the look of unlit points
and lines.
* If any other material node is used together with unlit points and
lines, the geometry shall be rendered as white unlit.

In the absence of the _normal_ field, rendering of the points and lines
can be customized using textures, _Color_, _ColorRGBA_ and
_UnlitMaterial_ nodes.

[[S11_CommonGeometryFields]]
==== 11.2.3 Common geometry fields

Certain geometry nodes have several fields that provide information
about the rendering of the geometry. These fields specify the vertex
ordering, if the shape is solid, if the shape contains convex faces, and
at what angle a crease appears between faces, and are named _ccw_,
_solid_, _convex_ and _creaseAngle_, respectively.

The _ccw_ field defines the ordering of the vertex coordinates of the
geometry with respect to user-given or automatically generated normal
vectors used in the lighting model equations. If _ccw_ is `TRUE`,
the normals shall follow the right hand rule; the orientation of each
normal with respect to the vertices (taken in order) shall be such that
the vertices appear to be oriented in a counterclockwise order when the
vertices are viewed (in the local coordinate system of the
<<Shape>>) from the opposite direction as the normal. If _ccw_
is `FALSE`, the normals shall be oriented in the opposite
direction. If normals are not generated but are supplied using a
<<Normal>> node, and the orientation of the normals does not
match the setting of the _ccw_ field, results are undefined.

The _solid_ field determines whether one or both sides of each polygon
shall be displayed. If _solid_ is `FALSE`, each polygon shall be
visible regardless of the viewing direction ( _i.e._, no backface
culling shall be done, and two sided lighting shall be performed to
illuminate both sides of lit surfaces). If _solid_ is `TRUE`, the
visibility of each polygon shall be determined as follows: Let *_V_* be
the position of the viewer in the local coordinate system of the
geometry. Let *_N_* be the geometric normal vector of the polygon, and
let *_P_* be any point (besides the local origin) in the plane defined
by the polygon's vertices. Then if ( *_V_* dot *_N_*) - ( *_N_* dot
*_P_*) is greater than zero, the polygon shall be visible; if it is less
than or equal to zero, the polygon shall be invisible (back face
culled).

The _convex_ field indicates whether all polygons in the shape are
convex (`TRUE`). A polygon is convex if it is planar, does not
intersect itself, and all of the interior angles at its vertices are
less than 180 degrees. Non planar and self intersecting polygons may
produce undefined results even if the _convex_ field is `FALSE`.

The _creaseAngle_ field affects how default normals are generated. If
the angle between the geometric normals of two adjacent faces is less
than the crease angle, normals shall be calculated so that the faces are
shaded smoothly across the edge; otherwise, normals shall be calculated
so that a lighting discontinuity across the edge is produced. Crease
angles shall be greater than or equal to 0.0 angle base units.

EXAMPLE  A crease angle of 0.5 angle base units means that an edge
between two adjacent polygonal faces will be smooth shaded if the
geometric normals of the two faces form an angle that is less than 0.5
angle base units. Otherwise, the faces will appear faceted.

[[ClipPlanes]]
==== 11.2.4 Clip planes

[[ClipPlanesOverview]]
===== 11.2.4.1 Overview

The 3D graphics rendering pipeline uses an implicit step of trimming
objects that are partially in the view frustum called clipping. In
addition to these implied bounds, it is also possible to provide an
additional clipping of the geometry through the provision of additional
clip plane definitions.

[[ClipPlaneSemantics]]
===== 11.2.4.2 Clip plane semantics

A clip plane is defined as a plane that generates two half-spaces. The
affected geometry in the half-space that is defined as being outside the
plane is removed from the rendered image as a result of a clipping
operation.

[[S11_TransformationHierarchy]]
===== 11.2.4.3 Transformation hierarchy

Clip planes may be defined at any level of the transformation hierarchy.
The clip plane definitions are accumulated from the root of the scene
graph down to the individual leaf nodes that are rendered. Clipping
occurs against the intersection of the half-spaces resulting from the
current list of transformed clip plane definitions. Since the clip
planes are collected during the traversal of the scene graph, specifying
both local and globally scoped planes is possible.

<<f-EffectsOfLocalClipPlanesOnGeometry, Figure 11.1>> illustrates four
objects affected by a horizontal clip plane and a vertical clip plane.

[[f-EffectsOfLocalClipPlanesOnGeometry]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/clipplane.png[ClipPlane example,width=513,height=196]

Figure 11.1 — Effects of clip planes on geometry

[[ScopingOfClipPlanes]]
===== 11.2.4.4 Scoping of clip planes

A <<ClipPlane>> node affects only objects that are in the
same transformation hierarchy as the node. Each plane is transformed
according to the parent transformation hierarchy but is not further
transformed by the children it affects.

Clip planes shall affect nodes derived from
_<<X3DBackgroundNode>>_.

[[ClipPlaneLimitations]]
===== 11.2.4.5 Clip plane limitations

Many renderers only support a limited number of clip plane definitions
(typically, six). If, while traversing from the root of the scene to a
particular leaf, more than the number of supported clip planes are
specified, the clip plane definitions closest to the leaf are discarded
first ( _i.e._, the clip planes that are closer to the root of the scene
graph are considered most important).


=== 11.3 Abstract types

[[X3DColorNode]]
==== 11.3.1 _X3DColorNode_

[source,node]
----
X3DColorNode : X3DGeometricPropertyNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for color specifications in X3D.

[[X3DComposedGeometryNode]]
==== 11.3.2 _X3DComposedGeometryNode_

[source,node]
----
X3DComposedGeometryNode : X3DGeometryNode { 
  MFNode [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode [in,out] color           NULL [X3DColorNode]
  SFNode [in,out] coord           NULL [X3DCoordinateNode]
  SFNode [in,out] fogCoord        NULL [FogCoordinate]
  SFNode [in,out] metadata        NULL [X3DMetadataObject]
  SFNode [in,out] normal          NULL [X3DNormalNode]
  SFNode [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool []       ccw             TRUE
  SFBool []       colorPerVertex  TRUE
  SFBool []       normalPerVertex TRUE
  SFBool []       solid           TRUE
}
----

This is the base node type for all composed 3D geometry in X3D.

A composed geometry node type defines an abstract type that composes
geometry from a set of nodes that define individual components. Composed
geometry may have color, coordinates, normal and texture coordinates
supplied. The rendered output of the combination of these is dependent
on the concrete node definition. However, in general, the following
rules shall be applied for all nodes:

* If the color field is not `NULL`, it shall contain an
_<<X3DColorNode>>_ node whose colours are applied to the
vertices or faces of the _X3DComposedGeometryNode_ as follows:
* If _colorPerVertex_ is `FALSE`, colours are applied to each
face. If _colorPerVertex_ is true, colours are applied to each vertex.
* If the _color_ field is `NULL`, the geometry shall be rendered
normally using the material and texture defined in the
<<Appearance>> node (see <<Appearancenode, 12.2.2 Appearance node>> for details).
* If _normalPerVertex_ is `FALSE`, normals are applied to each
face. If _normalPerVertex_ is true, normals are applied to each vertex.
* If the _normal_ field is not `NULL`, it shall contain a
<<Normal>> node whose normals are applied to the vertices or
faces of the _X3DComposedGeometryNode_ in a manner exactly equivalent to
that described above for applying colours to vertices/faces (where
_normalPerVertex_ corresponds to _colorPerVertex_ and _normalIndex_
corresponds to _colorIndex_).
* If the _normal_ field is `NULL`, the X3D browser shall
automatically generate normals in accordance with the node's definition.
If the node does not define a behaviour, the default is to generate an
averaged normal for all faces that share that vertex.
* If the _texCoord_ field is not `NULL`, it shall contain a
<<X3DTextureCoordinateNode>> node.

If the _attrib_ field is not empty it shall contain a list of per-vertex
attribute information for programmable shaders as specified in
<<Pervertexattributes, 32.2.2.4 Per-vertex attributes>>.

If the _fogCoord_ field is not empty, it shall contain a list of
per-vertex depth values for calculating fog depth as specified in
<<FogColourCalculation, 24.2.2.5 Fog colour calculation>>.

Further information about _texCoord_ field handling is described in
<<IndexedFaceSet>>.

[[X3DCoordinateNode]]
==== 11.3.3 _X3DCoordinateNode_

[source,node]
----
X3DCoordinateNode : X3DGeometricPropertyNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for all coordinate node types in X3D. All
coordinates are specified in nodes derived from this abstract node type.

[[X3DGeometricPropertyNode]]
==== 11.3.4 _X3DGeometricPropertyNode_

[source,node]
----
X3DGeometricPropertyNode : X3DNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for all geometric property node types defined
in X3D

[[X3DGeometryNode]]
==== 11.3.5 _X3DGeometryNode_

[source,node]
----
X3DGeometryNode : X3DNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for all geometry in X3D. +

[[X3DNormalNode]]
==== 11.3.6 _X3DNormalNode_

[source,node]
----
X3DNormalNode : X3DGeometricPropertyNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for all normal node types in X3D. All normals
are specified in nodes derived from this abstract node type.


=== 11.4 Node reference

[[ClipPlane]]
==== 11.4.1 ClipPlane

[source,node]
----
ClipPlane : X3DChildNode { 
  SFBool  [in,out] enabled  TRUE
  SFNode  [in,out] metadata NULL    [X3DMetadataObject]
  SFVec4f [in,out] plane    0 1 0 0 [-1,1] 
}
----

The ClipPlane node specifies a single plane equation used to clip the
geometry. The _plane_ field specifies a four-component plane equation
that describes the inside and outside half space, `+a*x+b*y+c*z+d = 0+`.
The first three components are a normalized vector describing the
direction of the plane's normal direction. The fourth component is
distance from local origin. The inside half-space is clipped, _i.e._,
not rendered.

[[Color]]
==== 11.4.2 Color

[source,node]
----
Color : X3DColorNode { 
  MFColor [in,out] color    [NULL] [0,1]
  SFNode  [in,out] metadata NULL   [X3DMetadataObject]
}
----

This node defines a set of RGB colours to be used in the fields of
another node.

Color nodes are only used to specify multiple colours for a single
geometric shape, such as colours for the faces or vertices of an
<<IndexedFaceSet>>. A material node is used to specify
the overall material parameters of lit geometry. If both a material node
and a _Color_ node are specified for a geometric shape, the colours
shall replace the _main color_ component of the material.

The _main color_ is defined as:

* Material _diffuseColor_, if Phong Material is used.
* PhysicalMaterial _baseColor_, if PhysicalMaterial is used.
* UnlitMaterial _emissiveColor_, if UnlitMaterial is used.

This definition of _main color_ here is consistent with the definition
of _main texture_ used in case of _Gouraud shading_. See
<<GouraudShading, 17.2.2.8 Gouraud shading>>.

RGB or RGBA textures are mixed with colors. Details on lighting
equations can be found in <<LightingModel, 17.2.2 Lighting model>>.

[[ColorRGBA]]
==== 11.4.3 ColorRGBA

[source,node]
----
ColorRGBA : X3DColorNode { 
  MFColorRGBA [in,out] color    [NULL] [0,1]
  SFNode      [in,out] metadata NULL   [X3DMetadataObject]
}
----

This node defines a set of RGBA colours to be used in the fields of
another node.

RGBA color nodes are only used to specify multiple colours with alpha
for a single geometric shape, such as colours for the faces or vertices
of an <<IndexedFaceSet>>. A material node is used to
specify the overall material parameters of lit geometry. If both a
material node and a _ColorRGBA_ node are specified for a geometric
shape, the colours shall replace the _main color_ and _transparency_
components of the material.

The _main color_ is defined as:

* _Material.diffuseColor_, if Phong _Material_ is used.
* _PhysicalMaterial.baseColor_, if _PhysicalMaterial_ is used.
* _UnlitMaterial.emissiveColor_, if _UnlitMaterial_ is used.

This definition of _main color_ here is consistent with the definition
of _main texture_ used in case of _Gouraud shading_ is used. See
<<GouraudShading, 17.2.2.8 Gouraud shading>>.

RGB or RGBA textures are mixed with colors. Details on lighting
equations can be found in <<LightingModel, 17.2.2 Lighting model>>.

[[Coordinate]]
==== 11.4.4 Coordinate

[source,node]
----
Coordinate : X3DCoordinateNode { 
  SFNode  [in,out] metadata NULL   [X3DMetadataObject]
  MFVec3f [in,out] point    []     (-∞,∞)
}
----

This node defines a set of 3D coordinates to be used in the _coord_
field of vertex-based geometry nodes including:

[loweralpha]
. <<IndexedFaceSet>>,
. <<IndexedLineSet>>,
. <<IndexedTriangleFanSet>>,
. <<IndexedTriangleSet>>,
. <<IndexedTriangleStripSet>>,
. <<PointSet>>,
. <<TriangleFanSet>>,
. <<TriangleSet>>, and
. <<TriangleStripSet>>.

[[CoordinateDouble]]
==== 11.4.5 CoordinateDouble

[source,node]
----
CoordinateDouble : X3DCoordinateNode { 
  SFNode  [in,out] metadata NULL [X3DMetadataObject]
  MFVec3d [in,out] point    []   (-∞,∞)
}
----

CoordinateDouble is a node type derived from
_<<X3DCoordinateNode>>_ that allows the definition
of 3D coordinates in double precision floating point values.

[[IndexedLineSet]]
==== 11.4.6 IndexedLineSet

[source,node]
----
IndexedLineSet : X3DGeometryNode {
  MFInt32 [in]     set_colorIndex
  MFInt32 [in]     set_coordIndex
  MFNode  [in,out] attrib         []   [X3DVertexAttributeNode]
  SFNode  [in,out] color          NULL [X3DColorNode]
  SFNode  [in,out] coord          NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord       NULL [FogCoordinate]
  SFNode  [in,out] metadata       NULL [X3DMetadataObject]
  SFNode  [in,out] normal         NULL [X3DNormalNode]
  MFInt32 []       colorIndex     []   [0,∞) or -1
  SFBool  []       colorPerVertex TRUE
  MFInt32 []       coordIndex     []   [0,∞) or -1
}
----

The IndexedLineSet node represents a 3D geometry formed by constructing
polylines from 3D vertices specified in the _coord_ field.
IndexedLineSet uses the indices in its _coordIndex_ field to specify the
polylines by connecting vertices from the _coord_ field. An index of
"-1" indicates that the current polyline has ended and the next one
begins. The last polyline may be (but does not have to be) followed by a
"-1". IndexedLineSet is specified in the local coordinate system and is
affected by the transformations of its ancestors.

The _coord_ field specifies the 3D vertices of the line set and contains
a <<X3DCoordinateNode, _X3DCoordinateNode_>> node.

Lines do not participate in collision detection. The width and style of
lines are determined by the line properties specified in an associated
<<Appearance>> node. If no line properties are specified,
the default values for fields of the
<<LineProperties>> node shall be used (see
<<LineProperties, 12.4.3 LineProperties>>).

If the _color_ field is not `NULL`, it shall contain a node
derived from _<<X3DColorNode>>_. The colours are applied
to the line(s) as follows:

[loweralpha]
. If _colorPerVertex_ is `FALSE`:
[arabic]
.. If the _colorIndex_ field is not empty, one colour is used for each
polyline of the IndexedLineSet. There shall be at least as many indices
in the _colorIndex_ field as there are polylines in the IndexedLineSet.
If the greatest index in the _colorIndex_ field is N, there shall be N+1
colours in the Color node. The _colorIndex_ field shall not contain any
negative entries.
.. If the _colorIndex_ field is empty, the colours from the Color node
are applied to each polyline of the IndexedLineSet in order. There shall
be at least as many colours in the X3DColorNode node as there are
polylines.
. If _colorPerVertex_ is `TRUE`:
[arabic]
.. If the _colorIndex_ field is not empty, colours are applied to each
vertex of the IndexedLineSet in exactly the same manner that the
_coordIndex_ field is used to supply coordinates for each vertex from
the <<X3DCoordinateNode, _X3DCoordinateNode_>>. The _colorIndex_ field
shall contain at least as many indices as the _coordIndex_ field and
shall contain end-of-polyline markers (−1) in exactly the same places as
the _coordIndex_ field. If the greatest index in the _colorIndex_ field
is N, there shall be N+1 colours in the Color node.
.. If the _colorIndex_ field is empty, the _coordIndex_ field is used to
choose colours from the Color node. If the greatest index in the
_coordIndex_ field is N, there shall be N+1 colours in the Color node.

Lines can be lit (if the normal vectors are provided), textured and
affected by per-vertex colors. See <<PointsLinesRendering, 11.2.2.5 Points and lines rendering>> section.

[[IndexedTriangleFanSet]]
==== 11.4.7 IndexedTriangleFanSet

[source,node]
----
IndexedTriangleFanSet : X3DComposedGeometryNode {
  MFInt32 [in]     set_index       []   [0,∞) or -1
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
  MFInt32 []       index           []   [0,∞) or -1
}
----

An IndexedTriangleFanSet represents a 3D shape composed of triangles
that form a fan shape around the first vertex declared in each fan as
depicted in <<f-TriangleFanSet, Figure11.2>>. IndexedTriangleFanSet
uses the indices in its _index_ field to specify the triangle fans by
connecting vertices from the _coord_ field. An index of "-1" indicates
that the current fan has ended and the next one begins. The last fan may
be (but does not have to be) followed by a "-1".Each fan shall have at
least three non-coincident vertices.

The IndexedTriangleFanSet node is specified in the local coordinate
system and is affected by the transformations of its ancestors.
Descriptions of the _color_, _coord_, _normal_, and _texCoord_ fields
are provided in the <<Color>>, <<ColorRGBA>>,
<<Coordinate>>, <<Normal>>, and
<<TextureCoordinate>> nodes, respectively. If
values are provided for the _color_, _normal_ and _texCoord_ fields, the
values are applied in the same manner as the values from the _coord_
field and there shall be at least as many values as are present in the
_coord_ field. The value of the _colorPerVertex_ field is ignored and
always treated as `TRUE`. If the _normal_ field is not provided,
normals shall be generated as follows:

* If _normalPerVertex_ is `TRUE`, the normal for each vertex
shall be the average of the normals for all triangles sharing that
vertex.
* If _normalPerVertex_ is `FALSE`, the normal shall be generated
for the current triangle based on the _ccw_ field.

The _solid_ field determines whether the IndexedTriangleFanSet is
visible when viewed from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_
field.

[[IndexedTriangleSet]]
==== 11.4.8 IndexedTriangleSet

[source,node]
----
IndexedTriangleSet : X3DComposedGeometryNode {
  MFInt32 [in]     set_index       []   [0,∞)
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
  MFInt32 []       index           []   [0,∞)
}
----

The IndexedTriangleSet node represents a 3D shape composed of a
collection of individual triangles as depicted in
<<f-TriangleSet, Figure11.3>>. IndexedTriangleSet uses the indices in
its _index_ field to specify the vertices of each triangle from the
_coord_ field. Each triangle is formed from a set of three vertices of
the <<X3DCoordinateNode, _X3DCoordinateNode_>> identified by three
consecutive indices from the index field. If the _index_ field does not
contain a multiple of three coordinate values, the remaining vertices
shall be ignored.

The IndexedTriangleSet node is specified in the local coordinate system
and is affected by the transformations of its ancestors. Descriptions of
the _color_, _coord_, _normal_, and _texCoord_ fields are provided in
the <<Color>>, <<ColorRGBA>>, Coordinate,
<<TextureCoordinate>> nodes, respectively. If
values are provided for the _color_, _normal_ and _texCoord_ fields, the
values are applied in the same manner as the values from the _coord_
field and there shall be at least as many values as are present in the
_coord_ field. The value of the _colorPerVertex_ field is ignored and
always treated as `TRUE`. If the _normal_ field is not supplied,
normals shall be generated as follows:

* If _normalPerVertex_ is `TRUE`, the normal at each vertex shall
be the average of the normals for all triangles that share that vertex.
* If _normalPerVertex_ is `FALSE`, the normal at each vertex
shall be perpendicular to the face for that triangle.

The _solid_ field determines whether the IndexedTriangleSet is visible
when viewed from the backside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

[[IndexedTriangleStripSet]]
==== 11.4.9 IndexedTriangleStripSet

[source,node]
----
IndexedTriangleStripSet : X3DComposedGeometryNode {
  MFInt32 [in]     set_index       []   [0,∞) or −1
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
  MFInt32 []       index           []   [0,∞) or −1
}
----

An IndexedTriangleStripSet represents a 3D shape composed of strips of
triangles as depicted in <<f-TriangleStripSet, Figure 11.3>>.
IndexedTriangleStripSet uses the indices in its _index_ field to specify
the triangle strips by connecting vertices from the _coord_ field. An
index of "−1" indicates that the current strip has ended and the next
one begins. The last strip may be (but does not have to be) followed by
a "−1". Each strip shall have at least three non-coincident vertices.

The IndexedTriangleStripSet node is specified in the local coordinate
system and is affected by the transformations of its ancestors.
Descriptions of the _color_, _coord_, _normal_, and _texCoord_ fields
are provided in the <<Color>>, <<ColorRGBA>>,
<<Coordinate>>, <<Normal>>, and
<<TextureCoordinate>> nodes, respectively. If
values are provided for the _color_, _normal_ and _texCoord_ fields, the
values are applied in the same manner as the values from the _coord_
field and there shall be at least as many values as are present in the
_coord_ field. The value of the _colorPerVertex_ field is ignored and
always treated as `TRUE`. If the _normal_ field is not supplied,
normals shall be generated as follows:

* If _normalPerVertex_ is `TRUE`, the normal shall be the average
of all triangles sharing that vertex.
* If _normalPerVertex_ is `FALSE`, the normal shall be generated
for the triangle based on the _ccw_ field.

The _ccw_ field describes the ordering of the vertex coordinates in the
initial triangle, and alternates for subsequent triangles.

The _solid_ field determines whether the IndexedTriangleStripSet is
visible when viewed from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_
field.

[[LineSet]]
==== 11.4.10 LineSet

[source,node]
----
LineSet : X3DGeometryNode {
  MFNode  [in,out] attrib         []   [X3DVertexAttributeNode]
  SFNode  [in,out] color          NULL [X3DColorNode]
  SFNode  [in,out] coord          NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord       NULL [FogCoordinate]
  SFNode  [in,out] metadata       NULL [X3DMetadataObject]
  SFNode  [in,out] normal         NULL [X3DNormalNode]
  MFInt32 [in,out] vertexCount    []   [2,∞)
}
----

The LineSet node represents a 3D geometry formed by constructing
polylines from 3D vertices specified in the _coord_ field.

The _color_ field specifies the colour of the line set at each vertex
and contains a node derived from _<<X3DColorNode>>_. A
description of the _color_ field is provided in the color node. If the
_color_ field is `NULL` and there is a material defined for the
<<Appearance>> affecting this LineSet, the _emissiveColor_
of the material shall be used to draw the lines. Details on lighting
equations as they affect LineSet nodes are described in
<<lighting_html, 17 Lighting component>>

The _coord_ field specifies the 3D vertices of the line set and contains
an <<X3DCoordinateNode, _X3DCoordinateNode_>>.

The _vertexCount_ field describes how many vertices are to be used in
each polyline from the coordinate field. Coordinates are assigned to
each line by taking _vertexCount_[n] vertices from the coordinate field.
Each value of the _vertexCount_ array shall be greater than or equal to
two. It shall be an error to have a value less than two.

Lines do not participate in collision detection. The width and style of
lines are determined by the line properties specified in an associated
Appearance node. If no line properties are specified, the default values
for the fields of the <<LineProperties>> node shall be
used (see <<LineProperties, 12.4.3 LineProperties>>).

Lines can be lit (if the normal vectors are provided), textured and
affected by per-vertex colors. See <<PointsLinesRendering, 11.2.2.5 Points and lines rendering>> section.

[[Normal]]
==== 11.4.11 Normal

[source,node]
----
Normal : X3DNormalNode { 
  SFNode  [in,out] metadata NULL [X3DMetadataObject]
  MFVec3f [in,out] vector   []   [-1,1]
}
----

This node defines a set of 3D direction vectors to be used for the
_normal_ field of some geometry nodes (EXAMPLE
 <<IndexedFaceSet>>,
<<IndexedLineSet>>, <<LineSet>>,
<<PointSet>>, and <<ElevationGrid>>). The
term 'normal' is common usage to indicate direction vectors, even though
the direction vectors might not necessarily indicate perpendicularity.
This node contains one multiple-valued field that contains the normal
vectors. Normals shall be of unit length.

[[PointSet]]
==== 11.4.12 PointSet

[source,node]
----
PointSet : X3DGeometryNode { 
  MFNode [in,out] attrib   []   [X3DVertexAttributeNode]
  SFNode [in,out] color    NULL [X3DColorNode]
  SFNode [in,out] coord    NULL [X3DCoordinateNode]
  SFNode [in,out] fogCoord NULL [FogCoordinate]
  SFNode [in,out] metadata NULL [X3DMetadataObject]
  SFNode [in,out] normal   NULL [X3DNormalNode]
}
----

The PointSet node specifies a set of 3D points, in the local coordinate
system, with associated colours at each point. The _coord_ field
specifies an <<X3DCoordinateNode, _X3DCoordinateNode_>>. The results
are undefined if the _coord_ field specifies any other type of node.
PointSet uses the coordinates in order. If the _coord_ field is
`NULL`, the point set is considered empty.

PointSet nodes are not lit, not texture-mapped, nor do they participate
in collision detection. The size of each point is
implementation-dependent.

If the _color_ field is not `NULL`, it shall specify a node
derived from _<<X3DColorNode>>_ that contains at least
the number of points contained in the _coord_ node. The results are
undefined if the _color_ field specifies any other type of node. Colours
shall be applied to each point in order. The results are undefined if
the number of values in the _X3DColorNode_ node is less than the number
of values specified in the <<X3DCoordinateNode, _X3DCoordinateNode_>>
node.

Points can be lit (if the normal vectors are provided), textured and
affected by per-vertex colors. See <<PointsLinesRendering, 11.2.2.5 Points and lines rendering>> section.

[[TriangleFanSet]]
==== 11.4.13 TriangleFanSet

[source,node]
----
TriangleFanSet : X3DComposedGeometryNode {
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  MFInt32 [in,out] fanCount        []   [3,∞)
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
}
----

A TriangleFanSet represents a 3D shape composed of triangles that form a
fan shape around the first vertex declared in each fan.

The _fanCount_ field describes how many vertices are to be used in each
fan from the coordinate field. Coordinates are assigned to each strip by
taking _fanCount_[n] vertices from the coordinate field. Each value of
the _fanCount_ array shall be greater than or equal to three. It shall
be an error to have a value less than three.

<<f-TriangleFanSet, Figure 11.2>> displays a TriangleFanSet containing
a single fan showing the ordering of the vertices for that fan.

[[f-TriangleFanSet]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/TriangleFanSet.jpg[TriangleFanSet node]

Figure 11.2 — TriangleFanSet node

The TriangleFanSet node is specified in the local coordinate system and
is affected by the transformations of its ancestors. Descriptions of the
_color, coord_, _normal_, and _texCoord_ fields are provided in the
<<Color>>/<<ColorRGBA>>,
<<Coordinate>>, <<Normal>>, and
<<TextureCoordinate>> nodes, respectively. If
values are provided for the _color_, _normal_, and _texCoord_ fields,
there shall be at least as many values as are present in the _coord_
field. The value of the _colorPerVertex_ field is ignored and always
treated as `TRUE`. If the normal field is not provided, for each
fan, the normal shall be generated as follows: if normalPerVertex is
`TRUE`, the normal shall be the average of all triangles within
that fan sharing that vertex. For the vertex of the fan, the normal
shall be the average of the contributions of all of the individual face
normals. If _normalPerVertex_ is `FALSE`, the normal shall be
generated for the current triangle based on the _ccw_ field.

The _solid_ field determines whether the TriangleFanSet is visible when
viewed from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

[[TriangleSet]]
==== 11.4.14 TriangleSet

[source,node]
----
TriangleSet : X3DComposedGeometryNode {
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
}
----

The TriangleSet node represents a 3D shape that represents a collection
of individual triangles.

The _coord_ field contains an
<<X3DCoordinateNode, _X3DCoordinateNode_>> that defines the 3D
vertices that define the triangle. Each triangle is formed from a
consecutive set of three vertices of the
<<X3DCoordinateNode, _X3DCoordinateNode_>> node. If the
<<X3DCoordinateNode, _X3DCoordinateNode_>> node does not contain a
multiple of three coordinate values, the remaining vertices shall be
ignored.

<<f-TriangleSet, Figure 11.3>> depicts a TriangleSet node with several
triangles. The ordering of the vertices is also shown.

[[f-TriangleSet]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/TriangleSet.png[TriangleSet
node,width=438,height=360]

Figure 11.3 — TriangleSet node

The TriangleSet node is specified in the local coordinate system and is
affected by the transformations of its ancestors. Descriptions of the
_color, coord_, _normal_, and _texCoord_ fields are provided in the
<<Color>>/<<ColorRGBA>>,
<<Coordinate>>, <<Normal>>, and
<<TextureCoordinate>> nodes, respectively. If
values are provided for the _color_, _normal_, and _texCoord_ fields,
there shall be at least as many values as are present in the _coord_
field. The value of the _colorPerVertex_ field is ignored and always
treated as `TRUE`. If the _normal_ field is not supplied, the
normal shall be generated as perpendicular to the face for either
version of _normalPerVertex_.

The _solid_ field determines whether the TriangleSet is visible when
viewed from the backside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

[[TriangleStripSet]]
==== 11.4.15 TriangleStripSet

[source,node]
----
TriangleStripSet : X3DComposedGeometryNode {
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  MFInt32 [in,out] stripCount      []   [3,∞)
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
}
----

A TriangleStripSet represents a 3D shape composed of strips of
triangles.

The _ccw_ field describes the ordering of the vertex coordinates in the
initial triangle, and alternates for subsequent triangles.

The _stripCount_ field describes how many vertices are to be used in
each strip from the coordinate field. Coordinates are assigned to each
strip by taking _stripCount_[i] vertices from the coordinate field,
where i is a sequential index of _stripCount_. Each value of the
_stripCount_ array shall be greater than or equal to three. It shall be
an error to have a value less than three.
<<f-TriangleStripSet, Figure 11.4>> depicts a TriangleStripSet with a
single triangle strip. +

[[f-TriangleStripSet]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/TriangleStripSet.png[TriangleStripSet node,width=375,height=191]

Figure 11.4 — TriangleStripSet node

The TriangleStripSet node is specified in the local coordinate system
and is affected by the transformations of its ancestors. Descriptions of
the _color, coord_, _normal_, and _texCoord_ fields are provided in the
<<Color>>/<<ColorRGBA>>,
<<Coordinate>>, <<Normal>>, and
<<TextureCoordinate>> nodes, respectively. If
values are provided for the _color_, _normal_, and _texCoord_ fields,
there shall be at least as many values as are present in the _coord_
field. The value of the _colorPerVertex_ field is ignored and always
treated as  `TRUE`. If the normal field is not provided, for each
strip, the normal shall be generated as follows: if normalPerVertex is
`TRUE`, the normal shall be the average of all triangles within
that strip sharing that vertex. If _normalPerVertex_ is `FALSE`,
the normal shall be generated for the triangle based on the _ccw_ field.

The _solid_ field determines whether the TriangleStripSet is visible
when viewed from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

[[S11.5_SupportLevels]]
=== 11.5 Support levels

The Rendering component provides three levels of support as specified in
<<t11_2, Table 11.2>>.

[[t11_2]]
Table 11.2 — Rendering component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 | |

| | |_X3DComposedGeometryNode_ (abstract) |n/a

| | |_X3DGeometricPropertyNode_ (abstract) |n/a

| | |_X3DGeometryNode_ (abstract) |n/a

| | |_X3DColorNode_ (abstract) |n/a

| | |_X3DCoordinateNode_ (abstract) |n/a

| | |Color |All fields fully supported.

| | |ColorRGBA |Alpha value optionally supported.

| | |Coordinate |All fields fully supported.

| | |CoordinateDouble |All fields fully supported.

| | |IndexedLineSet |_set_colorIndex_ optionally supported.
_set_coordIndex_ optionally supported. _normal_ optionally supported.

|  |  |LineSet |_normal_ optionally supported.

| | |PointSet |_normal_ optionally supported.

|*2* |Core 1 +
Grouping 1 | |

| | |All Level 1 Rendering nodes |All fields as supported in Level 1.

| | |_X3DNormalNode_ (abstract) |n/a

| | |Normal |All fields fully supported.

|*3* |Core 1 +
Grouping 1 | |

| | |All Level 2 Rendering nodes |All fields fully supported except for
ColorRGBA supported as in Level 2.

| | |IndexedTriangleFanSet |All fields fully supported.

| | |IndexedTriangleSet |All fields fully supported.

| | |IndexedTriangleStripSet |All fields fully supported.

| | |TriangleFanSet |All fields fully supported.

| | |TriangleSet |All fields fully supported.

| | |TriangleStripSet |All fields fully supported.

|*4* |Core 1 +
Grouping 1 |  | 

|  |  |All Level 3 Rendering nodes |All fields as supported in Level 3.

|  |  |ColorRGBA |Alpha value fully supported.

|*5* |Core 1 +
Grouping 1 |  | 

|  |  |All Level 4 Rendering nodes |All fields as supported in Level 4.

|  |  |ClipPlane |All fields fully supported.
|===

[[shape_html]]
== 12 Shape component

[[S12_Introduction]]
=== 12.1 Introduction

[[S12_Name]]
==== 12.1.1 Name

The name of this component is "Shape". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S12_Overview]]
==== 12.1.2 Overview

This clause describes the Shape component of this document. The Shape
component defines nodes for associating geometry with their visible
properties and the scene environment. <<t12_1, Table 12.1>>
provides links to the major topics in this clause.

[[t12_1]]
Table 12.1 — Topics

* <<S12Introduction, 12.1 Introduction>>
** <<S12_Name, 12.1.1 Name>>
** <<S12_Overview, 12.1.2 Overview>>
* <<S12_Concepts, 12.2 Concepts>>
** <<ShapeCharacteristics, 12.2.1 Shape characteristics>>
** <<AppearanceCharacteristics, 12.2.2 Appearance characteristics>>
** <<TwoSidedMaterials, 12.2.3 Two-sided materials>>
** <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>>
*** <<TextureMappingCoordinate, 12.2.4.1 Texture coordinates>>
*** <<TextureMappingTransform, 12.2.4.2 Texture coordinates transformation>>
** <<CoexistenceMaterialTexturesWithAppearanceTexture>>
* <<S12_AbstractTypes, 12.3 Abstract types>>
** <<X3DAppearanceChildNode, 12.3.1 _X3DAppearanceChildNode_>>
** <<X3DAppearanceNode, 12.3.2 _X3DAppearanceNode_>>
** <<X3DMaterialNode, 12.3.3 _X3DMaterialNode_>>
** <<X3DOneSidedMaterialNode, 12.3.4 _X3DOneSidedMaterialNode_>>
** <<X3DShapeNode, 12.3.5 _X3DShapeNode_>>
* <<S12_NodeReference, 12.4 Node reference>>
** <<AcousticProperties, 12.4.1 AcousticProperties>>
** <<Appearance, 12.4.2 Appearance>>
** <<FillProperties, 12.4.3 FillProperties>>
** <<LineProperties, 12.4.4 LineProperties>>
** <<Material, 12.4.5 Material>>
** <<PhysicalMaterial, 12.4.6 PhysicalMaterial>>
** <<PointProperties, 12.4.7 PointProperties>>
** <<Shape, 12.4.8 Shape>>
** <<TwoSidedMaterial, 12.4.9 TwoSidedMaterial>> (deprecated)
** <<UnlitMaterial, 12.4.10 UnlitMaterial>>
* <<S12_SupportLevels, 12.5 Support levels>>

* <<f-EffectsOfTwoSidedMaterials, Figure 12.1 — Effects of two-sided materials on geometry>>

* <<t12_1, Table 12.1 — Topics>>
* <<t12_2, Table 12.2 — International register of items hatchstyles>>
* <<t12_3, Table 12.3 — International register of items linetypes>>
* <<t12_4, Table 12.4 — Shape component support levels>>




[[S12_Concepts]]
=== 12.2 Concepts

[[ShapeCharacteristics]]
==== 12.2.1 Shape characteristics

The <<Shape>> node associates a geometry node with nodes that
define that geometry's appearance. Shape nodes shall be part of the
transformation hierarchy to have any visible result, and the
transformation hierarchy shall contain Shape nodes for any geometry to
be visible (the only nodes that render visible results are Shape nodes
and the background nodes described in <<environmentalEffects_html>>). 
A Shape node contains exactly one geometry node
in its _geometry_ field, which is of type _X3DGeometryNode_. The Shape
node descends from the abstract base type _X3DShapeNode_.

[[AppearanceCharacteristics]]
==== 12.2.2 Appearance characteristics

Shape nodes may specify an <<Appearance>> node that
describes the appearance properties (material, texture and texture
transformation) to be applied to the geometry of the Shape. All valid
children of the Appearance node descend from the abstract base type
_<<X3DAppearanceChildNode>>_.

Nodes of the following types may be specified in the _material_ field of
the Appearance node:

* <<Material>>
* <<PhysicalMaterial>>
* <<TwoSidedMaterial>> (deprecated)
* <<UnlitMaterial>>

This set of nodes may be extended by creating new nodes derived from the
<<X3DMaterialNode, _X3DMaterialNode_>> abstract base type.

Nodes of the following types may be specified in the _backMaterial_
field of the Appearance node:

* <<Material>>
* <<PhysicalMaterial>>
* <<UnlitMaterial>>

This set may be extended by creating new nodes derived from the
_<<X3DOneSidedMaterialNode>>_ abstract base
type.

The Appearance node specifies texture mapping in its _texture_ field.
Valid values of the texture field are descendants of
_<<X3DTextureNode>>_, including:

* <<ImageTexture>>
* <<PixelTexture>>
* <<MovieTexture>>
* <<MultiTexture>>

This set may be extended by creating new nodes derived from the abstract
_X3DTextureNode_ base class as defined in <<X3DTextureNode, 18.3.2 X3DTextureNode>>.

Nodes of the type
_<<X3DTextureTransformNode>>_ may be
specified in the _textureTransform_ field of the Appearance node (see
<<X3DTextureTransformNode, 18.3.4 X3DTextureTransformNode>>),
including:

* <<TextureTransform>>

Interaction between the appearance properties and properties specific to
geometry nodes are described in <<geometry3D_html, 13 Geometry3D component>>
and <<geometry2D_html, 14 Geometry2D component>>.

An Appearance node may specify additional information about the
appearance of the corresponding geometry. Special properties may also be
defined for geometric areas. These properties are defined in the
_acousticProperties_, _fillProperties_, _lineProperties_, and
_pointProperties_ fields by the following nodes, respectively:

* <<AcousticProperties>>
* <<FillProperties>>
* <<LineProperties>>
* <<PointProperties>>

[[TwoSidedMaterials]]
==== 12.2.3 Two-sided materials

A polygon defines a front face based on the direction of the normal
vector. That normal is either explicitly provided by the end user or
implicitly calculated by the X3D browser based on the winding rules for
the node (for example, see the _ccw_ field on many of the polygonal
geometry nodes such as <<IndexedFaceSet>>).

The _solid_ field, described in the <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>, controls whether the geometry is visible from
the back side.

* When _solid_ is `TRUE`, the back faces are not visible at all.
* When _solid_ is `FALSE`, the back faces of the geometry are
lit, using an inverted normal vector applied to the corresponding front
faces.

Using the <<Appearance>> field _backMaterial_ allows
rendering the front and back sides of the polygon with different
material properties. It is meaningful only when _solid_ is
`FALSE`, since otherwise the back faces are never rendered. When
the _solid_ is `TRUE`, the value of _backMaterial_ has no effect
on rendering.

<<TwoSidedMaterial>> (deprecated) provides similar
functionality for back faces but is limited to the Phong lighting model.

<<f-EffectsOfTwoSidedMaterials, Figure 12.1>> depicts example effects
of the <<Appearance>> field _backMaterial_ node.

[[f-EffectsOfTwoSidedMaterials]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/two_sided_material.png[Two-sided material demonstration]

Figure 12.1 — Effects of different material properties on front and back
sides of the geometry

Several constraints pertain to the _backMaterial_ field value:

* The _backMaterial_ field can have a value different than `NULL`
only when the _material_ field also has a value different than
`NULL`.
* It is not allowed to provide a _backMaterial_ when the _material_
specifies a <<TwoSidedMaterial>> (deprecated).
* When both the _material_ and _backMaterial_ are provided (not
`NULL`), it is required that they:
. Specify the same node class. In other words, both of them should be
<<Material>>, or both should be
<<PhysicalMaterial>>, or both should be
<<UnlitMaterial>>.
. The _material_ and _backMaterial_ nodes need to apply the same
textures with the same mapping. In other words, the values of the fields
documented in <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>> shall be equal for both front and back materials.
Utilizing the DEF / USE mechanism can ensure matching references to
texture nodes and mappings.

In effect, the _material_ and _backMaterial_ nodes may differ only in
their numeric fields. For example, front side may have a different
_diffuseColor_ than the back side.

To summarize, the following combinations are allowed:

* Both _material_ and _backMaterial_ are `NULL`. In this case
results are equivalent to a default Material node, when viewed from
either the front and back side.
+
This case is exactly equivalent to using an
<<UnlitMaterial>> with default _emissiveColor_ white
for both _material_ and _backMaterial_.
* _material_ is a _TwoSidedMaterial_ node, _backMaterial_ is
`NULL`.
+
This case is only provided for compatibility. The _TwoSidedMaterial_ is
deprecated since X3D 4.0. Whether the rendering parameters are the same,
or different, for front and back sides is determined by the
_separateBackColor_ field of the relevant _TwoSidedMaterial_ node.
* _material_ contains a <<Material>>,
<<PhysicalMaterial>> or
<<UnlitMaterial>> node, and _backMaterial_ is
`NULL`.
+
In this case, both front and back sides will be rendered with the same
parameters. This case is _exactly equivalent_ to reusing the same
material node (through DEF / USE mechanism) for both _material_ and
_backMaterial_ fields.
* _material_ contains a <<Material>>,
<<PhysicalMaterial>> or
<<UnlitMaterial>> node, and _backMaterial_ also
contains a node of the same type.
+
In this case, some front and back material parameters may differ.

[[TextureMapping]]
==== 12.2.4 Texture mapping specified in material nodes

The <<X3DOneSidedMaterialNode>> and
descendants (<<Material>>,
<<PhysicalMaterial>>,
<<UnlitMaterial>>) introduce a number of fields to
modify material parameters using textures. They are consistently defined
by a pair of fields like this:

[source]
....
  SFNode   [in,out] xxxTexture        NULL
  SFString [in,out] xxxTextureMapping ""
....

The field _xxxTexture_ indicates a texture node.

The _xxxTextureMapping_ determines the _texture coordinates_ and
_texture coordinates transformation_ for given texture _xxxTexture_.

The corresponding texture coordinate and texture coordinate
transformation nodes have a field _mapping_ that will match the value of
the _xxxTextureMapping_ field. See the
<<X3DSingleTextureCoordinateNode>> and
<<X3DSingleTextureTransformNode>>
definitions.

Multiple textures may use the same texture coordinates and their
transformations. For example, it is common that both
`normalTextureMapping` and `diffuseTextureMapping` are
equal, if the graphic artist prepared both `normalTexture` and
`diffuseTexture` simultaneously, assuming the same mapping.

[[TextureMappingCoordinate]]
===== 12.2.4.1 Texture coordinates

Let's define a _list of texture coordinates_ for each geometry node like
this:

* If the geometry field does not have a _texCoord_ field then this list
is empty.
+
Most geometric objects with a predefined geometry ( _e.g._, _Sphere_)
don't have _texCoord_ field. Most geometric objects with geometry
defined by the author ( _e.g._, all the nodes derived from
<<X3DComposedGeometryNode>>) have _texCoord_
field.
* Otherwise, if the value of the _texCoord_ field is `NULL`, then
this list is again empty.
* Otherwise, if the value of the _texCoord_ field is a single node
derived from
<<X3DSingleTextureCoordinateNode>>,
then place this one node on the list.
+
<<X3DSingleTextureCoordinateNode>>
includes all texture coordinate nodes (like
<<TextureCoordinate>> or
<<TextureCoordinateGenerator>>) except
<<MultiTextureCoordinate>>.
* Otherwise, the value of this field shall be
<<MultiTextureCoordinate>> node. Then use the
_MultiTextureCoordinate.texCoord_ contents list as our _list of texture
coordinates_.

NOTE   The above definition means that using a
<<MultiTextureCoordinate>> with exactly one
child is equivalent to using this child directly. This is a general rule
in X3D 4.0, see also the
<<MultiTextureCoordinate>> specification for
details and an example.

All the
<<X3DSingleTextureCoordinateNode>>
nodes on the _list of texture coordinates_ defined above shall have a
different _mapping_ value. An exception is the empty _mapping_ value,
which may occur many times.

If the _xxxTextureMapping_ field is not empty, it should refer to a
corresponding _X3DSingleTextureCoordinateNode_ node on a _list of
texture coordinates_. The corresponding _X3DSingleTextureCoordinateNode_
node shall have equal _mapping_ value. If no corresponding
_X3DSingleTextureCoordinateNode_ is found on this list, the X3D browser
should determine texture coordinates as if _xxxTextureMapping_ would be
empty (see below). If multiple _X3DSingleTextureCoordinateNode_ nodes
with the same _mapping_ field values are present then the one that is
first found on the _list of texture coordinates_ is used.

If the _xxxTextureMapping_ field is empty, then the *first* item on a
_list of texture coordinates_ is used (regardless of the _mapping_
value). Only if no such texture coordinate exists (the list is empty),
then then _default texture coordinates_ for the specific geometry node
are used.

The algorithm to perform the _default texture coordinate calculation_ is
described at each geometry node. For example
<<IndexedFaceSet>> determines the coordinates based on
the local bounding box sizes, <<Box>> has the texture applied 6
times on 6 faces etc.

____
Hint for implementations: This section makes an important guarantee.
Generating _default texture coordinates_ only needs to be done when the
_texCoord_ field of the geometry is empty, or contains an empty
_MultiTextureCoordinate_ node. In all other cases, you know that
_default texture coordinates_ are not necessary, because all textures
will use one of the coordinates in the _texCoord_ list.

This is an important property, because X3D browsers may want to avoid
generating _default texture coordinates_ as it is a time-consuming
process ( _e.g._, requires to iterate over vertexes at least twice in
case of _IndexedFaceSet_) and often not necessary (models exported by 3D
authoring software typically have all texture coordinates provided in
the file).
____

[[TextureMappingTransform]]
===== 12.2.4.2 Texture coordinates transformation

Let's define a _list of texture transformations_ for each geometry node
like this:

* If the shape uses no <<Appearance>> node then this list
is empty.
* Otherwise, if the value of _Appearance.textureTransform_ is NULL, then
this list is again empty.
* Otherwise, if the value of _Appearance.textureTransform_ is a single
node <<X3DSingleTextureTransformNode>>,
then place this one node in the list.
+
Most texture transformation nodes are derived from
<<X3DSingleTextureTransformNode>>, like
<<TextureTransform>> and
<<TextureTransform3D>>. But not
<<MultiTextureTransform>>.
* Otherwise, the value of _Appearance.textureTransform_ shall be
<<MultiTextureTransform>>. Then use the
_MultiTextureTransform.textureTransform_ contents as our _list of
texture transformations_.

A <<MultiTextureTransform>> with a single child
node is always treated the same as using the child directly.

If the _xxxTextureMapping_ field is not empty, it should refer to a
corresponding _X3DSingleTextureTransformNode_ node within the _list of
texture transformations_. The corresponding
_X3DSingleTextureTransformNode_ node shall have equal _mapping_ value.
If no such corresponding _X3DSingleTextureTransformNode_ is found, the
X3D browser should determine texture transformation as if
_xxxTextureMapping_ would be empty (see below). If multiple
X3DSingleTextureTransformNode nodes with the same _mapping_ field values
are present, the one that is first found on the _list of texture
transformations_ is used.

If the _xxxTextureMapping_ is an empty string, then the *first* item on
a _list of texture transformations_ is used (regardless of the _mapping_
value). If the list is empty, no texture transformation is used.

NOTE   Throughout this section, an empty string is treated as as a
special case for _xxxTextureMapping_ and _mapping_ fields. Such mapping
names are allowed (they are even the default) but they do not constitute
a "match". It would be error-prone if two empty mapping values would
match, as it's easy to use them accidentally, since they are the default
field values. Instead, empty _xxxTextureMapping_ just indicates "use the
first coordinates / transformations" — this is simplest and most
natural.

[[CoexistenceMaterialTexturesWithAppearanceTexture]]
==== 12.2.5 Coexistence of textures specified in material nodes with the "Appearance.texture" field

In X3D 4.0, models can specify textures using the _xxxTexture_ fields
inside the various
<<X3DOneSidedMaterialNode>> descendants. This
allows to control every material parameter by a different texture.

Alternatively, models can also use the mechanism known from X3D 3.x, and
provide a texture inside the _Appearance.texture_ field.

The exact behavior of _MultiTexture_ node and _Appearance.texture_ is
the following:

. If the _Appearance.material_ is <<Material>>, and the
_Material.diffuseTexture_ is `NULL`, then _Appearance.texture_
affects the _diffuseParameter_ for the lighting equation.
+
In a way, _Appearance.texture_ performs then the role of
_Material.diffuseTexture_. It can even use _MultiTexture_ to calculate
the diffuse parameter by a composition ( _e.g._, addition or
multiplication) of other textures.
+
The _Material.diffuseTextureMapping_ value is ignored.
. If the _Appearance.material_ is
<<PhysicalMaterial>>, and the
_PhysicalMaterial.baseTexture_ is `NULL`, then
_Appearance.texture_ affects the _baseParameter_ for the lighting
equation.
+
The _PhysicalMaterial.baseTextureMapping_ value is ignored.
. If the _Appearance.material_ is <<UnlitMaterial>>,
and the _UnlitMaterial.emissiveTexture_ is `NULL`, then
_Appearance.texture_ affects the _emissiveParameter_ for the lighting
equation.
+
The _UnlitMaterial.emissiveTextureMapping_ value is ignored.
. Otherwise, if the _Appearance.material_ is `NULL`, results are
equivalent to a default <<UnlitMaterial>> node. The
_Appearance.texture_ affects the _emissiveParameter_ for the lighting
equation, and is used with the unlit lighting model.

The _Appearance.texture_ can contain any texture type derived from
<<X3DTextureNode>>, which includes all textures
derived from <<X3DSingleTextureNode>> and also
the <<MultiTexture>> node. When
<<MultiTexture>> node is used, the
<<MultiTextureCoordinate>> and
<<MultiTextureTransform>> nodes can be used to
provide texture coordinates and transfomations in the same order as
textures in the _MultiTexture.texture_ list. See the
<<MultiTextureCoordinate>> and
<<MultiTextureTransform>> nodes for details.

The <<lighting_html, 17 Lighting component>> describes the exact
equations to calculate the lighting parameters, consistent with the
above description.


=== 12.3 Abstract types

[[X3DAppearanceChildNode]]
==== 12.3.1 _X3DAppearanceChildNode_

[source,node]
----
X3DAppearanceChildNode : X3DNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for the child nodes of the
_X3DAppearanceNode_ type.

[[X3DAppearanceNode]]
==== 12.3.2 _X3DAppearanceNode_

[source,node]
----
X3DAppearanceNode : X3DNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for all Appearance nodes.

[[X3DMaterialNode]]
==== 12.3.3 _X3DMaterialNode_

[source,node]
----
X3DMaterialNode : X3DAppearanceChildNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for all material nodes.

There are two direct descendants of this node type:

. Abstract <<X3DOneSidedMaterialNode>>.
+
In turn, the _X3DOneSidedMaterialNode_ is a descendant for all
non-abstract and non-deprecated material nodes that you shall use in X3D
models:
* <<Material>> (Phong lighting model)
* <<PhysicalMaterial>> (physically-based lighting
model)
* <<UnlitMaterial>> (trivial lighting model that
ignores light sources, for non-realistic rendering and special effects)
. <<TwoSidedMaterial>> (deprecated)

[[X3DOneSidedMaterialNode]]
==== 12.3.4 _X3DOneSidedMaterialNode_

[source,node]
----
X3DOneSidedMaterialNode : X3DMaterialNode {
  
  SFNode   [in,out] emissiveTexture         NULL   [X3DSingleTextureNode]
  SFString [in,out] emissiveTextureMapping  ""
  SFNode   [in,out] metadata                NULL   [X3DMetadataObject]
  SFFloat  [in,out] normalScale             1      [0, ∞)
  SFNode   [in,out] normalTexture           NULL   [X3DSingleTextureNode]
  SFString [in,out] normalTextureMapping    ""
}
----

This is the base node type for material nodes that describe how the
shape looks like from one side.

This node defines common properties for a lighting calculation, but
independent of the lighting model (Phong, physically-based, unlit).

This node can be used within _Appearance.material_ or
_Appearance.backMaterial_.

The _normalTexture_ field affects normal vectors information (surface
curvature) in the following way:

* Each normal encoded in a texture is a 3D vector (normalized
direction).
+
3D direction of each normal shall be calculated from texture RGB color,
using this equation:
+
_normal.xyz = normalize((textureSample(normalTexture).rgb * vec3(2,2,2)
- vec3(1,1,1)) * vec3(normalScale, normalScale, 1))_
+
That is, assuming _normalScale_ equal 1 (default), the red color
component is linearly mapped from [0..1] to [-1..1] range and represents
the X axis of the normal vector. Analogously the green component is
mapped to Y, and the blue component is mapped to Z.
* The normals are provided in tangent space, where tangent space is
defined to be the space that is local to the surface of a polygon, with
the +X direction pointing along the texture coordinate U of the normal
texture, the +Y direction pointing along the texture coordinate V of the
normal texture, and the +Z direction pointing outward from the polygon.
+
Each normal vector in the _normalTexture_ field has the property in
tangent space that the (0,0,1) vector is pointing perfectly outward from
a polygon. More precisely, the "outward" direction (mapped to (0,0,1) in
tangent space) is the direction of the "normal vector" derived from
other X3D mechanisms: from the per-vertex or per-face normal vectors (if
provided in the _Normal_ node), or calculating the normals automatically
( _e.g._, using _IndexedFaceSet.creaseAngle_). Additionally, the vectors
(1,0,0) and (0,1,0) in the tangent space indicate the direction where
the texture coordinate U and V remains orthogonal to (0,0,1) and each
other.
* A correct normal-map texture is typically blueish, since most of the
normals on a more-or-less smooth surface revolve around (0,0,1), thus
the texture colors revolve around (0.5,0.5,1).
* The alpha channel of the _normalTexture_ is ignored by the
calculations. X3D browsers _can_ use the alpha channel of the
_normalTexture_ to specify heights (from which the normal vectors have
been derived). In the current X3D standard version, these heights are
not used for anything, although X3D browsers may already use them for
X3D browser-specific rendering effects (for example to perform _parallax
bump mapping_ or _displacement_, activated by X3D browser-specific
extensions).

The _emissiveColor_ field is defined in implementing nodes (albeit with
differing default values). The _emissiveColor_ and _emissiveTexture_
fields enable an author to model glowing objects. This can be useful for
displaying unlit (pre-lit) models (where the light energy of the room is
computed explicitly), or for displaying scientific data. Application of
emissive color values has an essential role when rendering lines
(LineSet and IndexedLineSet), points (PointSet), and geometry rendered
with unlit materials. To display an unlit object (whose visible color
should not be modified by any light in the scene), an author can use an
<<UnlitMaterial>> node.

The _emissiveTexture_ RGB channel is multiplied with the _emissiveColor_
to yield the _emissiveParameter_ in the <<LightingModel, lighting equations>>. Further information is provided in
<<PointsLinesRendering, 11.2.2.5 Points and lines rendering>>.

The meaning of the alpha channel of the _emissiveTexture_ depends on the
_X3DOneSidedMaterialNode_ descendant. It is ignored by
<<Material>> and <<PhysicalMaterial>>.
It is used, as the transparency factor, by the
<<UnlitMaterial>>. Across the specification, the
treatment of _Material.diffuseTexture_, _PhysicalMaterial.baseTexture_
and _UnlitMaterial.emissiveTexture_ is consistent: these "main" textures
provide the transparency information for given material. For details,
refer to the documentation of each _X3DOneSidedMaterialNode_ descendant.

See the section <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>> for a description how the texture coordinates and
texture coordinate transformations are determined based on the
_xxxTextureMapping_ fields of this node.

[[X3DShapeNode]]
==== 12.3.5 _X3DShapeNode_

[source,node]
----
X3DShapeNode : X3DChildNode, X3DBoundedObject {
  SFNode  [in,out] appearance  NULL     [X3DAppearanceNode]
  SFBool  [in,out] bboxDisplay FALSE
  SFBool  [in,out] castShadow  TRUE
  SFNode  [in,out] geometry    NULL     [X3DGeometryNode]
  SFNode  [in,out] metadata    NULL     [X3DMetadataObject]
  SFBool  [in,out] visible     TRUE
  SFVec3f []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f []       bboxSize    -1 -1 -1 [0,∞) or −1 −1 −1
}
----

This is the base node type for all Shape nodes.

The _visible_ field determines whether Shape geometry is rendered.

The _castShadow_ field defines whether this Shape casts shadows as
produced by lighting nodes. If the _visible_ field is FALSE, then the
Shape does not cast any shadows, regardless of the _castShadow_ value.


=== 12.4 Node reference

[[AcousticProperties]]
==== 12.4.1 AcousticProperties

[source,node]
----
AcousticProperties : X3DAppearanceChildNode  {
  SFFloat  [in,out] absorption  0    [0,1]
  SFString [in,out] description ""
  SFFloat  [in,out] diffuse     0    [0,1]
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
  SFFloat  [in,out] refraction  0    [0,1]
  SFFloat  [in,out] specular    0    [0,1]
}
----

The AcousticProperties node specifies the interaction of sound waves
with the characteristics of objects in the scene. Properties influencing
sound propagation include surface-related physical phenomena such as the
_specular_ reflection, _diffuse_ reflection, _absorption_, and
_refraction_ coefficients of materials. These coefficient values are
expected to fully account for physical and structural characteristics of
the associated geometry such as width, height, thickness, shape,
softness and/or hardness, and density variations.

The _absorption_ field specifies the sound absorption coefficient of a
surface which is the ratio of the sound intensity absorbed or otherwise
not reflected by a specific surface that of the initial sound intensity.
This characteristic depends on the nature and thickness of the material.
Sound energy is partially absorbed when it encounters fibrous or porous
materials, panels that have some flexibility, volumes of air that
resonate, and openings in room boundaries ( _e.g._, doorways). Moreover,
the absorption of sound by a particular shape depends on the angle of
incidence and frequency of the sound wave.

The _description_ field specifies a textual description node
characteristics. This information is beneficial for authoring, and may
be used by optional X3D browser-specific user interfaces that present
users with more detailed information about active time-dependent
behavior.

The _enabled_ field enables and disables acoustic effects.

The _diffuse_ field describes the diffuse coefficient of sound
reflection. This is one of the physical phenomena of sound that occurs
when a sound wave strikes a plane surface, and part of the sound energy
is reflected back into space in multiple directions.

The _refraction_ field describes the sound refraction coefficient of a
medium, which determines the change in propagation direction of a sound
wave when it obliquely crosses the boundary between two mediums where
its speed is different. These relationships are described by Snell's
Law.

The _specular_ field describes the specular coefficient of sound
reflection, which is one of the physical phenomena of sound that occurs
when a sound wave strikes a plane surface. Part of the sound energy is
directly reflected back into space, where the angle of reflection is
equal to the angle of incidence.

[[Appearance]]
==== 12.4.2 Appearance

[source,node]
----
Appearance : X3DAppearanceNode {
  SFNode   [in,out] acousticProperties NULL   [AcousticProperties]
  SFFloat  [in,out] alphaCutoff        0.5    [0,1]
  SFString [in,out] alphaMode          "AUTO" ["AUTO", "OPAQUE", "MASK", "BLEND"]
  SFNode   [in,out] backMaterial       NULL   [X3DOneSidedMaterialNode]
  SFNode   [in,out] fillProperties     NULL   [FillProperties]
  SFNode   [in,out] lineProperties     NULL   [LineProperties]
  SFNode   [in,out] material           NULL   [X3DMaterialNode]
  SFNode   [in,out] metadata           NULL   [X3DMetadataObject]
  SFNode   [in,out] pointProperties    NULL   [PointProperties]
  MFNode   [in,out] shaders            []     [X3DShaderNode]
  SFNode   [in,out] texture            NULL   [X3DTextureNode]
  SFNode   [in,out] textureTransform   NULL   [X3DTextureTransformNode]
}
----

The Appearance node specifies the visual properties of geometry. The
value for each of the fields in this node may be `NULL`. However,
if the field is non-`NULL`, it shall contain one node of the
appropriate type.

The _acousticProperties_ field, if specified, shall contain an
<<AcousticProperties>> node describing
coefficients related to the physical propagation of sound for various
materials.

The _alphaCutoff_ field provides a threshold value for pixel rendering
as either transparent or opaque, used either when _alphaMode_ has value
`MASK` or else when _alphaMode_ has value `AUTO` and the
X3D browser determines that `MASK` mode is most appropriate for
use.

The _alphaMode_ field determines how the final transparency value is
computed for each pixel. The final alpha value is determined by various
properties of the material and textures (following the lighting model
equations given in the <<lighting_html, 17 Lighting component>>) or by
custom shaders, when these are used (see 
<<shaders_html, 31 Programmable shaders component>>). 
The following values of _alphaMode_ are allowed:

* `AUTO` — the X3D browser automatically determines the alpha
treatment based on the material _transparency_, optionally taking into
account the alpha channel of the textures that affect the final alpha
value. In effect, this mode means that X3D browser auto-detects which of
the algorithms described below: `OPAQUE`, `MASK` or
`BLEND`. This mode corresponds to rendering according to the X3D
version 3 specification.
* `OPAQUE` — the shape is rendered as opaque, and the final alpha
value is ignored.
* `MASK` — the shape is rendered using alpha testing. When the
final alpha value is less than _alphaCutoff_, the relevant pixel is
discarded ( _i.e._, treated as fully transparent). When the final alpha
value is greater than or equal to _alphaCutoff_, the relevant pixel is
rendered as if it was fully opaque. Note that the _alphaCutoff_ value
matters only when _alphaMode_ is `MASK`, or when when _alphaMode_
is `AUTO` and X3D browser auto-detected that the `MASK`
mode is the most appropriate. Note that if custom shader nodes are
applied (see <<shaders_html, 31 Programmable shaders component>>) then
implementation of this technique may require appropriate code in the
user-provided shader content.
* `BLEND` — the shape is rendered using blending techniques.
Ideally, the shape is rendered in front of other shapes and the
background behind it, mixing the shape color proportionally to the final
alpha value. The final alpha value value 0.0 results in a fully
transparent pixel, value 1.0 results in a fully opaque pixel, and
in-between values results in a partially transparent pixel.

The _backMaterial_ field, if specified, shall contain a
<<Material>>, <<PhysicalMaterial>> or
<<UnlitMaterial>> node. It is only allowed to define a
_backMaterial_ if the _material_ is also defined (not `NULL`).
The node type provided to _backMaterial_ (if any) shall match the node
type provided to _material_. This field allows to render back faces with
a different material parameters than the front faces. The meaning and
all constraints of this field are explained in the section
<<TwoSidedMaterials, Two-sided materials>>.

The _fillProperties_ field, if specified, shall contain a
<<FillProperties>> node. If _fillProperties_ is
`NULL` or unspecified, the _fillProperties_ field has no effect.

The _lineProperties_ field, if specified, shall contain a
<<LineProperties>> node. If _lineProperties_ is
`NULL` or unspecified, the _lineProperties_ field has no effect.

The _material_ field, if specified, shall contain a
<<Material>>, <<PhysicalMaterial>>,
<<TwoSidedMaterial, TwoSidedMaterial (deprecated)>> or
<<UnlitMaterial>> node. If the _material_ field is
`NULL` or unspecified, lighting is off (all lights are ignored
during rendering of the object that references this Appearance) and the
unlit object colour is (1, 1, 1). Details of the X3D lighting model are
in <<PART8, 17 Lighting component>>.

The _pointProperties_ field, if specified, shall contain a
<<PointProperties>> node. If _pointProperties_ is
`NULL` or unspecified, the _pointProperties_ field has no effect.

The _shaders_ field contains a listing, in order of preference, of nodes
that describe programmable shaders that replace the fixed rendering
requirements of this document with user-provided functionality. If the
field is not empty, one shader node is selected and the fixed rendering
requirements defined by this document are ignored. The field shall
contain one of the various types of shader nodes as specified in
<<shaders_html, 31 Programmable shaders component>>.

The _texture_ field, if specified, shall contain one of the various
types of texture nodes (see <<texturing_html, 18 Texturing component>>).
The texture node, if it is provided and not `NULL`,
specifies the texture that plays the role of _main texture_ (diffuse,
base, or emissive texture — depending on the material type) as described
in <<CoexistenceMaterialTexturesWithAppearanceTexture>>.

The _textureTransform_ field, if specified, shall contain a
<<TextureTransform>> node as defined in
<<TextureTransform, 18.4.8 TextureTransform>>. If the
_textureTransform_ is `#NULL `#or unspecified, the
_textureTransform_ field has no effect.

[[FillProperties]]
==== 12.4.3 FillProperties

[source,node]
----
FillProperties : X3DAppearanceChildNode { 
  SFBool  [in,out] filled     TRUE
  SFColor [in,out] hatchColor 1 1 1 [0,1]
  SFBool  [in,out] hatched    TRUE
  SFInt32 [in,out] hatchStyle 1     [0,∞)
  SFNode  [in,out] metadata   NULL  [X3DMetadataObject]
}
----

The FillProperties node specifies additional properties to be applied to
all polygonal areas on top of whatever appearance is specified by the
other fields of the respective <<Appearance>> node. Thus,
hatches are applied on top of the already rendered appearance of the
node. Thus, if _filled_ is `TRUE`, the polygonal area is filled
according to the other fields of the Appearance node. If _hatched_ is
`TRUE`, the polygonal area is hatched as specified by the
_hatchStyle_ field. Hatches shall be applied after fills are applied.

The _hatchStyle_ field selects a hatch pattern as defined in the
International Register of Graphical Items (see <<REG>>). The
hatches are rendered using the colour specified by the _hatchColor_
field. X3D browsers shall support hatchstyles 1-6 with hatchstyle 1
being the default. X3D browsers may support any other of the registered
hatchstyles. If a hatchstyle that is not supported is requested,
hatchstyle 1 shall be used. <<t12_2, Table 12.2>> specifies
the first nineteen hatch styles as defined in the
https://isotc.iso.org/livelink/livelink/fetch/-8916524/8916549/8916590/6208440/class_pages/hatchstyle.html[Hatchstyle
Section of the International Register of Items]. Examples of each hatch
style are available at the International Register of Items.

[[t12_2]]
Table 12.2 — International register of items hatchstyles

[cols="^,",]
|===
|1  |Horizontal equally spaced parallel lines
|2  |Vertical equally spaced parallel lines
|3  |Positive slope equally spaced parallel lines
|4  |Negative slope equally spaced parallel lines
|5  |Horizontal/vertical crosshatch
|6  |Positive slope/negative slope crosshatch
|7  |(cast iron or malleable iron and general use for all materials)
|8  |(steel)
|9  |(bronze, brass, copper, and compositions)
|10 |(white metal, zinc, lead, babbit, and alloys)
|11 |(magnesium, aluminum, and aluminum alloys)
|12 |(rubber, plastic, and electrical insulation)
|13 |(cork,felt, fabric, leather, and fibre)
|14 |(thermal insulation)
|15 |(titanium and refractory material)
|16 |(marble, slate, porcelain, glass, etc.)
|17 |(earth)
|18 |(sand)
|19 |(repeating dot)
|===

The associated geometry shall be filled and/or hatched only when the
respective values of the _filled_ and/or _hatched_ fields have value
`TRUE`.

[[LineProperties]]
==== 12.4.4 LineProperties

[source,node]
----
LineProperties : X3DAppearanceChildNode { 
  SFBool  [in,out] applied              TRUE
  SFInt32 [in,out] linetype             1    [1,∞)
  SFFloat [in,out] linewidthScaleFactor 0    (-∞,∞)
  SFNode  [in,out] metadata             NULL [X3DMetadataObject]
}
----

The LineProperties node specifies additional properties to be applied to
all line geometry. The _linetype_ and _linewidthScaleFactor_ fields
shall only be applied when the _applied_ field has value `TRUE`.
When the value of the _applied_ field is `FALSE`, a solid line of
nominal width shall be produced. The colour of the line is specified by
the associated <<X3DColorNode>> color values.

The _linetype_ field selects a line pattern as defined in the
International Register of Graphical Items (see <<REG>>). X3D
browsers shall support _linetype_ values 1 through 5, with 1 being the
default value. X3D browsers may support any other of the registered
_linetype_ values. If a _linetype_ that is not supported is requested,
value 1 shall be used. <<t12_2, Table 12.2>> specifies the first
sixteen _linetype_ values as defined in the
https://www.iso.org/jtc1/sc24/register[Linetype Section] of the
International Register of Items.

[[t12_3]]
Table 12.3 — International register of items linetypes

[cols="^,",]
|===
|1  |Solid
|2  |Dashed
|3  |Dotted
|4  |Dashed-dotted
|5  |Dash-dot-dot
|6  |(single arrow)
|7  |(single dot)
|8  |(double arrow)
|10 |(chain line)
|11 |(center line)
|12 |(hidden line)
|13 |(phantom line)
|14 |(break line 1)
|15 |(break line 2)
|16 |User-specified dash pattern
|===

The arrowhead is drawn as short lines forming barbs at any convenient
angle between 15 and 90 degrees. The arrowhead is closed and filled in.
For linetype "single arrow", the arrowhead is rendered so that the arrow
tip occurs at the last point of the each individual list of points
passed to a polyline and is in the direction of the last vector. For
linetype "double arrow", the first arrowhead is rendered so that the
arrow tip occurs at the first point of the list of points passed to a
polyline and is in the reverse direction of the first vector. The second
arrowhead is rendered as for "single arrow" at the opposite end of the
polyline.

The _linewidthScaleFactor_ field is a multiplicative value that scales a
X3D browser-dependent nominal line width by the given value. This
resulting value shall then be mapped to the nearest available line
width. A value less than or equal to zero refers to the minimum
available line width.

[[Material]]
==== 12.4.5 Material

[source,node]
----
Material : X3DOneSidedMaterialNode {
  SFFloat  [in,out] ambientIntensity          0.2          [0,1]
  SFNode   [in,out] ambientTexture            NULL         [X3DSingleTextureNode]
  SFString [in,out] ambientTextureMapping     ""
  SFColor  [in,out] diffuseColor              0.8 0.8 0.8  [0,1]
  SFNode   [in,out] diffuseTexture            NULL         [X3DSingleTextureNode]
  SFString [in,out] diffuseTextureMapping     ""
  SFColor  [in,out] emissiveColor             0 0 0        [0,1]
  SFNode   [in,out] emissiveTexture           NULL         [X3DSingleTextureNode]
  SFString [in,out] emissiveTextureMapping    ""
  SFNode   [in,out] metadata                  NULL         [X3DMetadataObject]
  SFFloat  [in,out] normalScale               1            [0, ∞)
  SFNode   [in,out] normalTexture             NULL         [X3DSingleTextureNode]
  SFString [in,out] normalTextureMapping      ""
  SFFloat  [in,out] occlusionStrength         1            [0,1]
  SFNode   [in,out] occlusionTexture          NULL         [X3DSingleTextureNode]
  SFString [in,out] occlusionTextureMapping   ""
  SFFloat  [in,out] shininess                 0.2          [0,1]
  SFNode   [in,out] shininessTexture          NULL         [X3DSingleTextureNode]
  SFString [in,out] shininessTextureMapping   ""
  SFColor  [in,out] specularColor             0 0 0        [0,1]
  SFNode   [in,out] specularTexture           NULL         [X3DSingleTextureNode]
  SFString [in,out] specularTextureMapping    ""
  SFFloat  [in,out] transparency              0            [0,1]
}
----

The <<Material>> node specifies surface material properties
for associated geometry nodes. It indicates that a surface is using
_Phong lighting model_. <<lighting_html, 17 Lighting component>>
contains a detailed description of the X3D lighting model equations.

The material parameters are specified as scalars or RGB colors in the
X3D file. All of the `SFFloat` and `SFColor` fields in the
Material node range from 0.0 to 1.0.

Moreover every material parameter can be adjusted using a texture. This
allows to vary this parameter across the surface. The information
sampled from the texture is always multiplied by the simple scalar/color
fields.

Examples of texture usage:

* Texture assigned to the _diffuseTexture_ controls the most intuitive
"visible color of the object". This is the most often used texture.
* Texture assigned to the _specularTexture_ allows the surface to be
partially shiny (white values in the texture) and partially matte (black
values in the texture).

The fields in the Material node determine how light reflects off an
object to create color:

[loweralpha]
. The _ambientIntensity_ and _ambientTexture_ fields specify how much
ambient light from light sources this surface shall reflect. Ambient
light is omnidirectional and depends only on the number of light
sources, not their positions with respect to the surface.
+
Ambient parameter is calculated as
_ambientIntensity × diffuseColor × textureSample(ambientTexture).rgb_.
. The _diffuseColor_ and _diffuseTexture_ fields reflect all X3D light
sources depending on the angle of the surface with respect to the light
source. The more directly the surface faces the light, the more diffuse
light reflects.
. The _emissiveColor_ and _emissiveTexture_ fields model glowing or
unlit objects. See
<<X3DOneSidedMaterialNode>> for the
description of these fields.
. The _specularColor_, _specularTexture_, _shininess_ and
_shininessTexture_ fields determine the specular highlights (
_e.g._, the shiny spots on an apple).
+
When the angle from the light to the surface is close to the angle from
the surface to the viewer, the _specularColor_ × 
_textureSample(specularTexture).rgb_ is added to the diffuse and ambient
color calculations.
+
Lower shininess values produce soft glows, while higher values result in
sharper, smaller highlights. Shininess is calculated as _shininess_ × 
_textureSample(shininessTexture).a_.
. The _transparency_ field (together with alpha channel of the
_diffuseTexture_) specifies how "clear" an object is, with 1.0 being
completely transparent, and 0.0 completely opaque.
+
The transparency determines the _opacity_ as `opacity = 1.0 -transparency`. This is then multiplied by the alpha channel of
_diffuseTexture_ to determine the final alpha of the rendered pixel.

The RGB channels of _diffuseTexture_, _specularTexture_ and
_emissiveTexture_ are multiplied by the corresponding _diffuseColor_,
_specularColor_, _emissiveColor_ before being used in the current
lighting calculation. The alpha channel of a _diffuseTexture_ is
multiplied by the material _opacity_ (which equals just `1.0 -transparency`). The alpha channels contents of _specularTexture_ and
_emissiveTexture_ are ignored.

The _shininessTexture_ alpha channel contains values multiplied with the
_shininess_ factor of the <<Material>> node. The RGB
channels contents of the _shininessTexture_ are ignored.

It is expected, and advised, that authors reuse the same texture node
for _specularTexture_ and _shininessTexture_. The specular data is
deliberately contained in different channels (RGB) than the shininess
data (Alpha).

The optional _occlusionTexture_ can be used to indicate areas of
indirect lighting, typically called _ambient occlusion_. Only the _Red_
channel of the texture is used for the computation, the other channels
are ignored. Higher values indicate areas that should receive full
indirect lighting and lower values indicate no indirect lighting. The
_occlusionStrength_ determines how much does the occlusion texture
affect the final result.

See the section <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>> for a description how the texture coordinates and
texture coordinate transformations are determined based on the
_xxxTextureMapping_ fields of this node.

[[PhysicalMaterial]]
==== 12.4.6 PhysicalMaterial

[source,node]
----
PhysicalMaterial : X3DOneSidedMaterialNode {
  SFColor  [in,out] baseColor                       1 1 1  [0,1]
  SFNode   [in,out] baseTexture                     NULL   [X3DSingleTextureNode]
  SFString [in,out] baseTextureMapping              ""
  SFColor  [in,out] emissiveColor                   0 0 0  [0,1]
  SFNode   [in,out] emissiveTexture                 NULL   [X3DSingleTextureNode]
  SFString [in,out] emissiveTextureMapping          "" 
  SFNode   [in,out] metadata                        NULL   [X3DMetadataObject]
  SFFloat  [in,out] metallic                        1      [0,1]
  SFNode   [in,out] metallicRoughnessTexture        NULL   [X3DSingleTextureNode]
  SFString [in,out] metallicRoughnessTextureMapping ""
  SFFloat  [in,out] normalScale                     1      [0, ∞)
  SFNode   [in,out] normalTexture                   NULL   [X3DSingleTextureNode]
  SFString [in,out] normalTextureMapping            ""
  SFFloat  [in,out] occlusionStrength               1      [0,1]
  SFNode   [in,out] occlusionTexture                NULL   [X3DSingleTextureNode]
  SFString [in,out] occlusionTextureMapping         ""
  SFFloat  [in,out] roughness                       1      [0,1]
  SFFloat  [in,out] transparency                    0      [0,1]
}
----

The <<PhysicalMaterial>> node specifies surface
material properties for associated geometry nodes. It indicates that a
physical lighting model should be used for the computation.
<<lighting_html, 17 Lighting component>> contains a detailed
description of the X3D lighting model equations.

Physical interpretation of the material parameters follows. These
parameter descriptions closely follow the glTF specification (see
<<glTF>>).

NOTE   The physical material properties of X3D are also deliberately
consistent with the glTF 2.0 material definition. Effectively,
converting (in either direction) between X3D PhysicalMaterial and glTF
2.0 material definitions is equivalent.

The physical lighting equation, as an input, relies on the following
parameters:

* _baseParameter_ (RGB color) is, in simple cases, a multiplication of
_baseTexture_ RGB channel (if such texture was specified) with the
_baseColor_.
+
In other words, it is calculated at every pixel as _baseColor_ × 
_textureSample(baseTexture).rgb_.
+
NOTE   This interpretation is true in most cases, but in general it is a
simplification of what actually happens. The texture may also come from
_Appearance.texture_, and it can even be _MultiTexture_ in which case it
is not necessarily multiplied. See the <<LightingPhysical, 17.2.2.6 Physical lighting model>> for the exact specification how the
_baseParameter_ is calculated in every possible case.
* _metallicParameter_ is a multiplication of _metallic_ with the _Blue_
texture channel of _metallicRoughnessTexture_ (if such texture was
specified).
+
In other words, it is calculated at every pixel as _metallic_ × 
_textureSample(metallicRoughnessTexture).b_.
* _roughnessParameter_ is a multiplication of _roughness_ with the
_Green_ texture channel of _metallicRoughnessTexture_ (if such texture
was specified).
+
In other words, it is calculated at every pixel as _roughness_ × 
_textureSample(metallicRoughnessTexture).g_.

When calculating _metallicParameter_ and _roughnessParameter_ terms, the
_Red_ and _Alpha_ channels of the _metallicRoughnessTexture_ are
ignored. It is possible to use the same texture for
_metallicRoughnessTexture_ and _occlusionTexture_, as they deliberately
look at different channels, so all the information can be contained in
one RGB texture.

The final alpha, used for blending or alpha-testing, is calculated as
_baseTexture_ alpha channel multiplied with the opacity (`1.0 -transparency`). This is consistent with the behavior of _diffuseColor_,
_diffuseTexture_ and _transparency_ on the Phong
<<Material>>. If the _baseTexture_ was not specified, it is
also possible to use the _Application.texture_. See the
<<LightingPhysical, 17.2.2.6 Physical lighting model>> for the exact
specification, and the <<CoexistenceMaterialTexturesWithAppearanceTexture>> 
for a description how _Appearance.texture_ is used.

Moreover the <<PhysicalMaterial>> defines the
_emissiveColor_ and optional _emissiveTexture_. The resulting
_emissiveParameter_ term is simply added to the pixel color, this
behavior is consistent for all X3D materials.

The optional _occlusionTexture_ can be used to indicate areas of
indirect lighting, typically called _ambient occlusion_. Only the _Red_
channel of the texture is used for the computation, the other channels
are ignored. Higher values indicate areas that should receive full
indirect lighting and lower values indicate no indirect lighting. The
_occlusionStrength_ determines how much does the occlusion texture
affect the final result.

The _baseParameter_ color has two different interpretations depending on
the value of _metallicParameter_. When the material is a metal, the
_baseParameter_ color is the specific measured reflectance value at
normal incidence (F~0~). For a non-metal the _baseParameter_ color
represents the reflected diffuse color of the material. In this model it
is not possible to specify a F~0~ value for non-metals, and a linear
value of 4% (0.04) is used.

The following algorithm shows how to calculate bidirectional reflectance
distribution function (BRDF) inputs ( _c~diff~_, _F~0~_, _α_) from the
metallic-roughness material properties.

[source,listing]
----
  const dielectricSpecular = rgb(0.04, 0.04, 0.04)
  const black = rgb(0, 0, 0)
  cdiff = lerp(baseParameter * (1 - dielectricSpecular.r), black, metallicParameter)
  F0 = lerp(dieletricSpecular, baseParameter, metallicParameter)
  α = roughnessParameter ^ 2
----

See the section <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>> for a description how the texture coordinates and
texture coordinate transformations are determined based on the
_xxxTextureMapping_ fields of this node.

[[PointProperties]]
==== 12.4.7 PointProperties

[source,node]
----
PointProperties : X3DAppearanceChildNode {
  SFVec3f  [in,out] attenuation           1 0 0 [0,∞)
  
  SFNode   [in,out] metadata              NULL  [X3DMetadataObject]
  SFFloat  [in,out] pointSizeMaxValue     1     [0,∞)
  SFFloat  [in,out] pointSizeMinValue     1     [0,∞)
  SFFloat  [in,out] pointSizeScaleFactor  1     [1,∞)
}
----

The PointProperties node specifies additional properties to be applied
to all point geometry. The colour of the line is specified by the
associated <<X3DColorNode>> color values.

The _attenuation_ field defines a depth perception effect in a point
cloud rendering by making points close to the viewer appear larger. The
modification of point size depending on distance from the view occurs in
two steps, starting with the nominal point size as determined by the
_pointSizeScaleFactor_ field. The _attenuation_ field defines three
parameters `a`, `b`, and `c` from the components of
a single SFVec3f value:

`a = attenuation[0]` +
`b = attenuation[1]` +
`c = attenuation[2]`

Together these parameters define an attenuation factor `1/(a +b×r + c×r^2^)` where `r` is the distance from the observer
position (current viewpoint) to each point. The nominal point size is
multiplied by the attenuation factor and then clipped to a minimum value
of _pointSizeMinValue_ × the minimum renderable point size, then clipped
to a maximum size of _pointSizeMaxValue_ × minimum renderable point
size.

_pointSizeScaleFactor_ is a value determining the nominal point size
before modification by the sizing modifications, as determined by the
_pointSizeMinValue_, _pointSizeMaxValue_, and _attenuation_ values
discussed below. The nominal rendered point size is a X3D
browser-dependent minimum renderable point size.

_pointSizeMinValue_ is minimum allowed scaling factor on nominal X3D
browser point scaling. _pointSizeMaxValue_ is maximum allowed scaling
factor on nominal X3D browser point scaling. The provided value for
_pointSizeMinValue_ shall be less than or equal to value for
_pointSizeMaxValue_.

When a X3DTextureNode is defined in the same Appearance instance as
PointProperties node, the points of a PointSet shall be displayed as
point sprites using the given texture(s).

[[Shape]]
==== 12.4.8 Shape

[source,node]
----
Shape : X3DShapeNode {
  SFNode  [in,out] appearance  NULL     [X3DAppearanceNode]
  SFBool  [in,out] bboxDisplay FALSE
  SFBool  [in,out] castShadow  TRUE
  SFNode  [in,out] geometry    NULL     [X3DGeometryNode]
  SFNode  [in,out] metadata    NULL     [X3DMetadataObject]
  SFBool  [in,out] visible     TRUE
  SFVec3f []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f []       bboxSize    -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The Shape node has two fields, _appearance_ and _geometry_, that are
used to create rendered objects in the world. The _appearance_ field
contains an Appearance node that specifies the visual attributes (
_e.g._, material and texture) to be applied to the geometry. The
_geometry_ field contains a geometry node. The specified geometry node
is rendered with the specified appearance nodes applied. See
<<S12_Concepts, 12.2 Concepts>> for more information.

<<lighting_html, 17 Lighting component>> contains details of the X3D
lighting model and the interaction between Appearance nodes and geometry
nodes.

If the _geometry_ field is `NULL`, the object is not drawn.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the Shape node's geometry. This is a hint that may be used for
optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the geometry at
any time. A default _bboxSize_ value, (-1 -1 -1), implies that the
bounding box is not specified and, if needed, is calculated by the X3D
browser. A description of the _bboxCenter_ and _bboxSize_ fields is
contained in <<Boundingboxes, 10.2.2 Bounding boxes>>.

[[TwoSidedMaterial]]
==== 12.4.9 TwoSidedMaterial (deprecated)

[source,node]
----
TwoSidedMaterial : X3DMaterialNode {
  SFFloat [in,out] ambientIntensity     0.2         [0,1]
  SFFloat [in,out] backAmbientIntensity 0.2         [0,1]
  SFColor [in,out] backDiffuseColor     0.8 0.8 0.8 [0,1]
  SFColor [in,out] backEmissiveColor    0 0 0       [0,1]
  SFFloat [in,out] backShininess        0.2         [0,1]
  SFColor [in,out] backSpecularColor    0 0 0       [0,1]
  SFFloat [in,out] backTransparency     0           [0,1]
  SFColor [in,out] diffuseColor         0.8 0.8 0.8 [0,1]
  SFColor [in,out] emissiveColor        0 0 0       [0,1]
  SFNode  [in,out] metadata             NULL        [X3DMetadataObject]
  SFFloat [in,out] shininess            0.2         [0,1]
  SFBool  [in,out] separateBackColor    FALSE
  SFColor [in,out] specularColor        0 0 0       [0,1]
  SFFloat [in,out] transparency         0           [0,1]
}
----

This node defines material properties that can effect both the front and
back side of a polygon individually. These materials are used for both
the front and back side of the geometry whenever the X3D lighting model
is active.

If the _separateBackColor_ field is set to `TRUE`, the rendering
shall render the front and back faces of the geometry with different
values. If the value is `FALSE`, the front colours are used for
both the front and back side of the polygon, as per the existing X3D
lighting rules.

When calculating the terms in the lighting equations, the front geometry
shall use the fields _ambientIntensity_, _diffuseColor_,
_emissiveColor_, _shininess_, _specularColor_, and _transparency_. The
faces that are determined to be the back side are rendered using
_backAmbientIntensity_, _backDiffuseColor_, _backEmissiveColor_,
_backShininess_, and _backTransparency_ as the appropriate components in
the lighting equations.

[[UnlitMaterial]]
==== 12.4.10 UnlitMaterial

[source,node]
----
UnlitMaterial : X3DOneSidedMaterialNode {
  SFColor  [in,out] emissiveColor                   1 1 1  [0,1]
  SFNode   [in,out] emissiveTexture                 NULL   [X3DSingleTextureNode]
  SFString [in,out] emissiveTextureMapping          ""
  SFNode   [in,out] metadata                        NULL   [X3DMetadataObject]
  SFFloat  [in,out] normalScale                     1      [0, ∞)
  SFNode   [in,out] normalTexture                   NULL   [X3DSingleTextureNode]
  SFString [in,out] normalTextureMapping            ""
  SFFloat  [in,out] transparency                    0      [0,1]
}
----

Material that is unaffected by light sources. Suitable to create various
non-realistic effects, when the colors are defined explicitly and are
not affected by the placement of the shape relative to the lights or
camera.

The output color and opacity, called _emissiveParameter_ by the
<<LightingModel, lighting equations>>, are determined like this:

. Use the _emissiveColor_ field value as the _emissiveParameter.rgb_.
Use the _1.0 - transparency_ as the _emissiveParameter.a_.
. If shape is using <<Color>> node then the information from
<<Color>> node overrides the _emissiveParameter.rgb_. If shape
is using <<ColorRGBA>> node then the information from
<<ColorRGBA>> overrides both the _emissiveParameter.rgb_
and the _emissiveParameter.a_.
+
NOTE   This is consistent with how <<Color>> or
<<ColorRGBA>> override _diffuseColor_ and _transparency_ in
case of <<Material>>.
. If the _emissiveTexture_ is not NULL, then it multiplies
(component-wise) the _emissiveParameter.rgb_ (multiplied by the texture
RGB channels) and _emissiveParameter.a_ (multiplied by the texture alpha
channel).
+
If the _emissiveTexture_ is NULL, but _Appearance.texture_ field is not
NULL, then the same logic is applied to the _Appearance.texture_
texture: it multiplies _emissiveParameter.rgb_ and _emissiveParameter.a_. 
See <<CoexistenceMaterialTexturesWithAppearanceTexture>> for a description 
how is the _Appearance.texture_ field used.

_Note about default values_: This node inherits the _emissiveColor_
field from the <<X3DOneSidedMaterialNode>>
ancestor, but the default value of this field changes: only for
<<UnlitMaterial>>, the default _emissiveColor_ is
`1 1 1` (white), instead of `0 0 0` (black, default of
_X3DOneSidedMaterialNode.emissiveColor_).

_Implementation hint_: Normal vectors information is not useful for the
calculation of unlit material. Implementations can ignore the normal
vectors provided in the geometry node (per-face or per-vertex) and in
the _normalTexture_ field. Implementations are encouraged to optimize
this case, and not send unneeded normals data to GPU, and not calculate
implicit normal vectors (normally derived from creaseAngle and ccw
fields). _However, there is an exception to this optimization_: if the
shape is using <<TextureCoordinateGenerator>> with some
modes (`CAMERASPACENORMAL`, `CAMERASPACEREFLECTIONVECTOR`)
then the shader code may need access to normals anyway.

See the section <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>>
for a description how the texture coordinates and
texture coordinate transformations are determined based on the
_xxxTextureMapping_ fields of this node.

[[S12.5_SupportLevels]]
=== 12.5 Support levels

The Shape component provides three levels of support as specified in
<<t12_4, Table 12.4>>.

[[t12_4]]
Table 12.4 — Shape component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Rendering 1 +
Texturing 1 | |

| | |_X3DAppearanceChildNode_(abstract) |n/a
| | |_X3DAppearanceNode_ (abstract) |n/a
| | |_X3DMaterialNode_ (abstract) |n/a
| | |_X3DOneSidedMaterialNode_ (abstract) |n/a
| | |_X3DShapeNode_ (abstract) |n/a
| | |Appearance |Optional support for _textureTransform_,
_lineProperties_, _fillProperties_, _shaders_, _backMaterial_.

| | |Material |Support for _diffuseTexture_ required. Optional support
for _ambientIntensity_, _shininess_, _specularColor_, _ambientTexture_,
_emissiveTexture_, _normalTexture_, _occlusionTexture_,
_shininessTexture_, _specularTexture_).

| | |UnlitMaterial |All fields fully supported.

| | |Shape |All fields fully supported.

|*2* |Core 1 +
Lighting 4 +
Rendering 1 +
Texturing 1 | |

| | |All Level 1 nodes except Appearance |All fields fully supported.
| | |Appearance |Optional support for the same properties as on level 1.
| | |LineProperties |All fields fully supported.
| | |PhysicalMaterial |All fields fully supported.

|*3* |Core 1 +
Lighting 4 +
Rendering 1 +
Texturing 1 | | 

|  |  |All Level 2 nodes except Appearance |All fields fully supported.
|  |  |Appearance |Optional support for _backMaterial_.
|  |  |FillProperties |All fields fully supported.
|  |  |PointProperties |All fields fully supported.
|  |  |TwoSidedMaterial (deprecated) |Support optional.

|*4* |Core 1 +
Lighting 4 +
Grouping 1 +
Rendering 1 | |

|  |  |All Level 3 nodes |All fields fully supported.
|  |  |AcousticProperties |All fields fully supported.
|===

[[geometry3D_html]]
== 13 Geometry3D component

[[S13_Introduction]]
=== 13.1 Introduction

[[S13_Name]]
==== 13.1.1 Name

The name of this component is "Geometry3D". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S13_Overview]]
==== 13.1.2 Overview

This clause describes the Geometry3D component of this document. This
includes how 3D geometry is specified and what shapes are available.
<<t13_1, Table 13.1>> provides links to the major topics in this
clause.

[[t13_1]]
Table 13.1 — Topics

* <<S13Introduction, 13.1 Introduction>>
** <<S13_Name, 13.1.1 Name>>
** <<S13_Overview, 13.1.2 Overview>>
* <<S13_Concepts, 13.2 Concepts>>
** <<S13_OverviewOfGeometry, 13.2.1 Overview of geometry>>
** <<Shapeandgeometry, 13.2.2 Shape and geometry nodes>>
** <<Geometricproperty, 13.2.3 Geometric property nodes>>
** <<Appearancenodes, 13.2.4 Appearance nodes>>
** <<S13_CommonGeometryFields, 13.2.5 Common geometry fields>>
* <<S13_NodeReference, 13.3 Node reference>>
** <<Box, 13.3.1 Box>>
** <<Cone, 13.3.2 Cone>>
** <<Cylinder, 13.3.3 Cylinder>>
** <<ElevationGrid, 13.3.4 ElevationGrid>>
** <<Extrusion, 13.3.5 Extrusion>>
*** <<Syntax, 13.3.5.1 Syntax>>
*** <<ExtrusionOverview, 13.3.5.2 Overview>>
*** <<AlgorithmicDescription, 13.3.5.3 Algorithmic description>>
*** <<Specialcases, 13.3.5.4 Special cases>>
**** <<SpecialcasesOverview, 13.3.5.4.1 Overview>>
**** <<NumberofScaleOrientationValues, 13.3.5.4.2 Number of scale or orientation values>>
**** <<CollinearSpinePoints, 13.3.5.4.3 Collinear spine points>>
**** <<CoincidentSpinePoints, 13.3.5.4.4 Coincident spine points>>
**** <<NumberOfDistinctSpinePoints, 13.3.5.4.5 Number of distinct spine points>>
*** <<Commoncases, 13.3.5.5 Common cases>>
*** <<S13_OtherFields, 13.3.5.6 Other fields>>
** <<IndexedFaceSet, 13.3.6 IndexedFaceSet>>
** <<Sphere, 13.3.7 Sphere>>
* <<S13_SupportLevels, 13.4 Support levels>>

* <<f-Boxnode, Figure 13.1 — Box node>>
* <<f-Conenode, Figure 13.2 — Cone node>>
* <<f-Cylindernode, Figure 13.3 — Cylinder node>>
* <<f-ElevationGridnode, Figure 13.4 — ElevationGrid node>>
* <<f-Spine-alignedcross-section, Figure 13.5 — Spine-aligned cross-section plane at a spine point>>
* <<f-IndexedFaceSettextureDefaultMapping, Figure 13.6 — IndexedFaceSet texture default mapping>>
* <<f-ImageTextureforIndexedFaceSet, Figure 13.7 — ImageTexture for IndexedFaceSet in Figure 13.6>>
* <<f-Spherenode, Figure 13.8 — Sphere node>>

* <<t13_1, Table 13.1 — Topics>>
* <<t13_2, Table 13.2 — Geometry3D component support levels>>




[[S13_Concepts]]
=== 13.2 Concepts

[[S13_OverviewOfGeometry]]
==== 13.2.1 Overview of geometry

The geometry component consists of four types of nodes:  shape,
geometry, geometry property, and appearance. Together, these node types
are used to describe the visual elements of a X3D world.

[[Shapeandgeometry]]
==== 13.2.2 Shape and geometry nodes

The <<Shape>> node associates a geometry node with nodes that
define that geometry's appearance. Shape nodes shall be part of the
transformation hierarchy to have any visible result, and the
transformation hierarchy shall contain Shape nodes for any geometry to
be visible (the only nodes that render visible results are Shape nodes
and the background nodes in 
<<environmentalEffects_html, 24 Environmental effects>>). 
A Shape node contains exactly one geometry node
in its _geometry_ field, which is of type
_<<X3DGeometryNode>>_. For more on the Shape node,
see <<shape_html, 12 Shape component>>.

Other components may define additional geometry node types.

NOTE  Non-planar, degenerate, and self-intersecting polygons are ill
specified and rendering results are undefined.

[[Geometricproperty]]
==== 13.2.3 Geometric property nodes

Several geometry nodes contain geometric property nodes such as
<<Coordinate>>, <<Color>>,
<<ColorRGBA>>, and/or <<Normal>>. These nodes are
specified in <<rendering_html, 11 Rendering component>>. The
_<<X3DTextureCoordinateNode, X3DTextureCoordinate>>_ nodes specified
in <<texturing_html, 18 Texturing component>> are also geometry
property nodes.

[[Appearancenodes]]
==== 13.2.4 Appearance nodes

<<Shape>> nodes may specify an <<Appearance>>
node that describes the appearance properties (material and texture) to
be applied to the Shape's geometry. Appearance is described in
<<shape_html, 12 Shape component>>.

[[S13_CommonGeometryFields]]
==== 13.2.5 Common geometry fields

Several 3D geometry nodes share common fields to describe attributes.
These fields specify the vertex ordering, if the shape is solid, if the
shape contains convex faces, and at what angle a crease appears between
faces, and are named _ccw_, _solid_, _convex_ and _creaseAngle_,
respectively. Common 3D geometry fields are described in
<<rendering_html, 11 Rendering component>>.


=== 13.3 Node reference

[[Box]]
==== 13.3.1 Box

[source,node]
----
Box : X3DGeometryNode { 
  SFNode  [in,out] metadata NULL  [X3DMetadataObject]
  SFVec3f []       size     2 2 2 (0,∞)
  SFBool  []       solid    TRUE
}
----

The Box node specifies a rectangular parallelepiped box centred at
(0, 0, 0) in the local coordinate system and aligned with the local
coordinate axes. By default, the box measures 2 units in each dimension,
from -1 to +1. The _size_ field specifies the extents of the box along
the X-, Y-, and Z-axes respectively and each component value shall be
greater than zero. <<f-Boxnode, Figure 13.1>> illustrates the Box
node.

[[f-Boxnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/box.gif[Box node,width=353,height=326]

Figure 13.1 — Box node

Textures are applied individually to each face of the box. On the front
(+Z), back (-Z), right (+X), and left (-X) faces of the box, when viewed
from the outside with the +Y-axis up, the texture is mapped onto each
face with the same orientation as if the image were displayed normally
in 2D. On the top face of the box (+Y), when viewed from above and
looking down the Y-axis toward the origin with the -Z-axis as the view
up direction, the texture is mapped onto the face with the same
orientation as if the image were displayed normally in 2D. On the bottom
face of the box (-Y), when viewed from below looking up the Y-axis
toward the origin with the +Z-axis as the view up direction, the texture
is mapped onto the face with the same orientation as if the image were
displayed normally in 2D. <<TextureTransform>>
affects the texture coordinates of the Box (see
<<TextureTransform, 18.4.8 TextureTransform>>).

The _solid_ field determines whether the box is visible when viewed from
the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>
provides a complete description of the _solid_ field.

[[Cone]]
==== 13.3.2 Cone

[source,node]
----
Cone : X3DGeometryNode { 
  SFNode  [in,out] metadata     NULL [X3DMetadataObject]
  SFBool  [in,out] bottom       TRUE
  SFFloat []       bottomRadius 1    (0,∞)
  SFFloat []       height       2    (0,∞)
  SFBool  [in,out] side         TRUE
  SFBool  []       solid        TRUE
}
----

The Cone node specifies a cone which is centred in the local coordinate
system and whose central axis is aligned with the local Y-axis. The
_bottomRadius_ field specifies the radius of the cone's base, and the
_height_ field specifies the height of the cone from the centre of the
base to the apex. By default, the cone has a radius of 1.0 at the bottom
and a height of 2.0, with its apex at y = _height_/2 and its bottom at y
= - _height_/2. Both _bottomRadius_ and _height_ shall be greater than
zero. <<f-Conenode, Figure 13.2>> illustrates the Cone node.

[[f-Conenode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/cone.gif[Cone
node,width=356,height=386]

Figure 13.2 — Cone node

The _side_ field specifies whether sides of the cone are created and the
_bottom_ field specifies whether the bottom cap of the cone is created.
A value of `TRUE` specifies that this part of the cone exists,
while a value of `FALSE` specifies that this part does not exist
(not rendered or eligible for collision or sensor intersection tests).

When a texture is applied to the sides of the cone, the texture wraps
counterclockwise (from above) starting at the back of the cone. The
texture has a vertical seam at the back in the X=0 plane, from the apex
(0,  _height_/2, 0) to the point (0, - _height_/2, - _bottomRadius_).
For the bottom cap, a circle is cut out of the texture square centred at
(0, - _height_/2, 0) with dimensions (2 ×  _bottomRadius)_ by (2 × 
_bottomRadius)_. The bottom cap texture appears right side up when the
top of the cone is rotated towards the -Z-axis.
<<TextureTransform>> affects the texture coordinates
of the Cone (see <<TextureTransform, 18.4.8 TextureTransform>>).

The _solid_ field determines whether the cone is visible when viewed
from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

This geometry node is fundamentally a mathematical representation.
Displayed geometry shall have sufficient rendering quality that surface
and silhouette edges appear smooth, including when textures are applied.

[[Cylinder]]
==== 13.3.3 Cylinder

[source,node]
----
Cylinder : X3DGeometryNode { 
  SFNode  [in,out] metadata NULL [X3DMetadataObject]
  SFBool  [in,out] bottom   TRUE
  SFFloat []       height   2    (0,∞)
  SFFloat []       radius   1    (0,∞)
  SFBool  [in,out] side     TRUE
  SFBool  []       solid    TRUE
  SFBool  [in,out] top      TRUE
}
----

The Cylinder node specifies a capped cylinder centred at (0,0,0) in the
local coordinate system and with a central axis oriented along the local
Y-axis. By default, the cylinder is sized at "-1" to "+1" in all three
dimensions. The _radius_ field specifies the radius of the cylinder and
the _height_ field specifies the height of the cylinder along the
central axis. Both _radius_ and _height_ shall be greater than zero.
<<f-Cylindernode, Figure 13.3>> illustrates the Cylinder node.

The cylinder has three _parts_: the _side_, the _top_ (Y = +height/2)
and the _bottom_ (Y = −height/2). Each part has an associated SFBool
field that indicates whether the part exists (`TRUE`) or does not
exist (`FALSE`). Parts which do not exist are not rendered and
not eligible for intersection tests (EXAMPLE  collision
detection or sensor activation).

[[f-Cylindernode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/cylinder.gif[Cylinder node,width=452,height=392]

Figure 13.3 — Cylinder node

When a texture is applied to a cylinder, it is applied differently to
the sides, top, and bottom. On the sides, the texture wraps
counterclockwise (from above) starting at the back of the cylinder. The
texture has a vertical seam at the back, intersecting the X=0 plane. For
the top and bottom caps, a circle is cut out of the unit texture squares
centred at (0, ±height/2, 0) with dimensions 2 ×  _radius_ by 2 × 
_radius_. The top texture appears right side up when the top of the
cylinder is tilted toward the +Z-axis, and the bottom texture appears
right side up when the top of the cylinder is tilted toward the −Z-axis.
<<TextureTransform>> affects the texture coordinates
of the Cylinder node (see <<TextureTransform, 18.4.8 TextureTransform>>).

The _solid_ field determines whether the cylinder is visible when viewed
from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

This geometry node is fundamentally a mathematical representation.
Displayed geometry shall have sufficient rendering quality that surface
and silhouette edges appear smooth, including when textures are applied.

[[ElevationGrid]]
==== 13.3.4 ElevationGrid

[source,node]
----
ElevationGrid : X3DGeometryNode {
  MFFloat [in]     set_height
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE  
  SFBool  []       colorPerVertex  TRUE
  SFFloat []       creaseAngle     0    [0,∞)
  MFFloat []       height          []   (-∞,∞)
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
  SFInt32 []       xDimension      0    [0,∞)
  SFFloat []       xSpacing        1.0  (0,∞)
  SFInt32 []       zDimension      0    [0,∞)
  SFFloat []       zSpacing        1.0  (0,∞)
}
----

The ElevationGrid node specifies a uniform rectangular grid of varying
height in the Y=0 plane of the local coordinate system. The geometry is
described by a scalar array of height values that specify the height of
a surface above each point of the grid.

The _xDimension_ and _zDimension_ fields indicate the number of elements
of the grid _height_ array in the X and Z directions. Both _xDimension_
and _zDimension_ shall be greater than or equal to zero. If either the
_xDimension_ or the _zDimension_ is less than two, the ElevationGrid
contains no quadrilaterals. The vertex locations for the rectangles are
defined by the _height_ field and the _xSpacing_ and _zSpacing_ fields:

* The _height_ field is an _xDimension_ by _zDimension_ array of scalar
values representing the height above the grid for each vertex. The
height array values are given in row-major order from left to right
along the X axis, then back to front along the Z axis.
* The _xSpacing_ and _zSpacing_ fields indicate the distance between
vertices in the X and Z directions respectively, and shall be greater
than zero.

Thus, the vertex corresponding to the point P[i, j] on the grid is
placed at:

[source,node]
----
  P[i,j].x = xSpacing × i

  P[i,j].y = height[ i + j × xDimension]

  P[i,j].z = zSpacing × j

    where 0 ≤ i < xDimension and 0 ≤ j < zDimension,
    and P[0,0] is height[0] units above/below the origin of the local
    coordinate system
----

If the rendering algorithm being used requires tessellation, the
quadrilaterals are split into triangles along the seam starting at the
initial vertex of the quadrilateral and proceeding to the opposite
vertex. The positive direction for the normal of each triangle shall be
on the same side of the quadrilateral. The triangles are defined either
counterclockwise or clockwise depending on the value of the _ccw_ field.

EXAMPLE  In <<f-ElevationGridnode, Figure 13.4>> with the _ccw_ field
set to `TRUE`, the first polygon is split into triangles with
vertices [0, 5, 6] and vertices [0, 6, 1].

The _set_height_ inputOnly field allows the height MFFloat field to be
changed to support animated ElevationGrid nodes.

The _color_ field specifies per-vertex or per-quadrilateral colours for
the ElevationGrid node depending on the value of _colorPerVertex_. If
the _color_ field is `NULL`, the ElevationGrid node is rendered
with the overall attributes of the <<Shape>> node enclosing the
ElevationGrid node (see <<shape_html, 12 Shape component>>).

The _colorPerVertex_ field determines whether colours specified in the
_color_ field are applied to each vertex or each quadrilateral of the
ElevationGrid node. If _colorPerVertex_ is `FALSE` and the
_color_ field is not `NULL`, the _color_ field shall specify a
node derived from _<<X3DColorNode>>_ containing at least
( __xDimension-1)__×( _zDimension-1)_ colours; one for each
quadrilateral, ordered as follows:

[source]
....
    QuadColor[i,j] = Color[ i + j × (xDimension-1)]

    where 0 ≤ i < xDimension-1 and 0 ≤ j < zDimension-1,
    and QuadColor[i,j] is the colour for the quadrilateral defined
    by height[i+j × xDimension], height[(i+1)+j × xDimension],
    height[(i+1)+(j+1) × xDimension] and height[i+(j+1) × xDimension]
....

If _colorPerVertex_ is `TRUE` and the _color_ field is not
`NULL`, the _color_ field shall specify a node derived from
_X3DColorNode_ containing at least __xDimension __×  _zDimension_
colours, one for each vertex, ordered as follows:

[source]
....
    VertexColor[i,j] = Color[ i + j × xDimension ]

    where 0 ≤ i < xDimension and 0 ≤ j < zDimension,
    and VertexColor[i,j] is the colour for the vertex defined by
    height[ i+j × xDimension ]
....

The _normal_ field specifies per-vertex or per-quadrilateral normals for
the ElevationGrid node. If the _normal_ field is `NULL`, the X3D
browser shall automatically generate normals, using the _creaseAngle_
field to determine if and how normals are smoothed across the surface
(see <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>).

The _normalPerVertex_ field determines whether normals are applied to
each vertex or each quadrilateral of the ElevationGrid node depending on
the value of _normalPerVertex_. If _normalPerVertex_ is `FALSE`
and the _normal_ node is not `NULL`, the _normal_ field shall
specify a node derived from _<<Normal, X3DNormalNode>>_ containing at
least ( __xDimension−1)__×( _zDimension−1)_ normals; one for each
quadrilateral, ordered as follows:

[source]
....
    QuadNormal[i,j] = Normal[ i + j × (xDimension-1)]

    where 0 ≤ i < xDimension-1 and 0 ≤ j < zDimension-1,
    and QuadNormal[i,j] is the normal for the quadrilateral defined
    by height[i+j × xDimension], height[(i+1)+j × xDimension],
    height[(i+1)+(j+1) × xDimension] and height[i+(j+1) × xDimension]
....

If _normalPerVertex_ is `TRUE` and the _normal_ field is not
`NULL`, the _normal_ field shall specify a node derived from
_X3DNormalNode_ containing at least __xDimension __×  _zDimension_
normals; one for each vertex, ordered as follows:

[source]
....
    VertexNormal[i,j] = Normal[ i + j × xDimension]

    where 0 ≤ i < xDimension and 0 ≤ j < zDimension,
    and VertexNormal[i,j] is the normal for the vertex defined
    by height[i+j × xDimension]
....

The _texCoord_ field specifies per-vertex texture coordinates for the
ElevationGrid node. If _texCoord_ is `NULL`, default texture
coordinates are applied to the geometry. The default texture coordinates
range from (0,0) at the first vertex to (1,1) at the last vertex. The S
texture coordinate is aligned with the positive X-axis, and the T
texture coordinate with positive Z-axis. If _texCoord_ is not
`NULL`, it shall specify a node derived from
_<<X3DTextureCoordinateNode>>_ containing at
least ( __xDimension)__×( _zDimension)_ texture coordinates; one for
each vertex, ordered as follows:

[source]
....
    VertexTexCoord[i,j] = TextureCoordinate[ i + j × xDimension]

    where 0 ≤ i < xDimension and 0 ≤ j < zDimension,
    and VertexTexCoord[i,j] is the texture coordinate for the vertex
    defined by height[i+j × xDimension]
....

The _ccw_, _solid_, and _creaseAngle_ fields are described in
<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>.

By default, the quadrilaterals are defined with a counterclockwise
ordering. Hence, the Y-component of the normal is positive. Setting the
_ccw_ field to `FALSE` reverses the normal direction. Backface
culling is enabled when the _solid_ field is `TRUE`.

See <<f-ElevationGridnode, Figure 13.4>> for a depiction of the
ElevationGrid node.

[[f-ElevationGridnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ElevationGrid.gif[ElevationGrid node,width=527,height=335]

Figure 13.4 — ElevationGrid node

[[Extrusion]]
==== 13.3.5 Extrusion

[[Syntax]]
===== 13.3.5.1 Syntax

[source,node]
----
Extrusion : X3DGeometryNode {
  MFVec2f    [in]     set_crossSection
  MFRotation [in]     set_orientation
  MFVec2f    [in]     set_scale
  MFVec3f    [in]     set_spine
  SFNode     [in,out] metadata         NULL                      [X3DMetadataObject]
  SFBool     []       beginCap         TRUE
  SFBool     []       ccw              TRUE
  SFBool     []       convex           TRUE
  SFFloat    []       creaseAngle      0                         [0,∞)
  MFVec2f    []       crossSection     [1 1 1 -1 -1 -1 -1 1 1 1] (-∞,∞)
  SFBool     []       endCap           TRUE
  MFRotation []       orientation      0 0 1 0                   [-1,1] or (-∞,∞)
  MFVec2f    []       scale            1 1                       (0,∞)
  SFBool     []       solid            TRUE
  MFVec3f    []       spine            [0 0 0 0 1 0]             (-∞,∞)
}   
----

[[ExtrusionOverview]]
===== 13.3.5.2 Overview

The Extrusion node specifies geometric shapes based on a two dimensional
cross-section extruded along a three dimensional spine in the local
coordinate system. The cross-section can be scaled and rotated at each
spine point to produce a wide variety of shapes.

An Extrusion node is defined by:

[loweralpha]
. a 2D _crossSection_ piecewise linear curve (described as a series of
connected vertices);
. a 3D _spine_ piecewise linear curve (also described as a series of
connected vertices);
. a list of 2D _scale_ parameters;
. a list of 3D _orientation_ parameters.

[[AlgorithmicDescription]]
===== 13.3.5.3 Algorithmic description

Shapes are constructed as follows. The cross-section curve, which starts
as a curve in the Y=0 plane, is first scaled about the origin by the
first _scale_ parameter (first value scales in X, second value scales in
Z). It is then translated by the first spine point and oriented using
the first _orientation_ parameter (as explained later). The same
procedure is followed to place a cross-section at the second spine
point, using the second scale and orientation values. Corresponding
vertices of the first and second cross-sections are then connected,
forming a quadrilateral polygon between each pair of vertices. This same
procedure is then repeated for the rest of the spine points, resulting
in a surface extrusion along the spine.

The final orientation of each cross-section is computed by first
orienting it relative to the spine segments on either side of point at
which the cross-section is placed. This is known as the _spine-aligned
cross-section plane_ (SCP), and is designed to provide a smooth
transition from one spine segment to the next (see
<<f-Spine-alignedcross-section, Figure 13.5>>).

[[f-Spine-alignedcross-section]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Extrusion.gif[Spine-aligned cross-section plane at a spine point,width=538,height=455]

Figure 13.5 — Spine-aligned cross-section plane (SCP) at a spine point.

The SCP for each point is determined by first computing its Y-axis and
Z-axis, then taking the cross product of these to determine the X-axis.
These three axes are then used to determine the rotation value needed to
rotate the Y=0 plane to the SCP. This results in a normal to the plane
that is the approximate tangent of the spine at the point, as shown in
<<f-Spine-alignedcross-section, Figure 13.5>>. First the Y-axis is
determined, as follows:

Let n be the number of spines and let i be the index variable satisfying +
0 ≤ i < n:

[loweralpha]
. _For all points other than the first or last_: The Y-axis for
_spine_[i] is found by normalizing the vector defined by +
( _spine_[i+1] − _spine_[i−1]).
. _If the spine curve is closed_: The SCP for the first and last points
is the same and is found using ( _spine_[1] − _spine_[n−2]) to compute
the Y-axis.
. _If the spine curve is not closed_: The Y-axis used for the first
point is the vector from _spine_[0] to _spine_[1], and for the last it
is the vector from _spine_[ _n−2_] to _spine_[ _n−1_].

The Z-axis is determined as follows:

[loweralpha, start=4]
. _For all points other than the first or last_: Take the following
cross-product: +
+
....
   Z = (spine[i+1] − spine[i]) × (spine[i-1] − spine[i])
....
. _If the spine curve is closed_: The SCP for the first and last points
is the same and is found by taking the following cross-product:
+
....
   Z = (spine[1] − spine[0]) × (spine[n-2] − spine[0])
....
. _If the spine curve is not closed_: The Z-axis used for the first
spine point is the same as the Z-axis for _spine_[ _1_]. The Z-axis used
for the last spine point is the same as the Z-axis for _spine_[ _n−2_].
. After determining the Z-axis, its dot product with the Z-axis of the
previous spine point is computed. If this value is negative, the Z-axis
is flipped (multiplied by −1). In most cases, this prevents small
changes in the spine segment angles from flipping the cross-section 180
degrees.

Once the Y- and Z-axes have been computed, the X-axis can be calculated
as their cross-product.

[#bugnotes1]#Each SCP is then rotated by the corresponding orientation
value. This rotation is performed relative to the SCP itself. For
example, to impart twist in the cross-section, a rotation about the
local Y-axis (0 1 0) would be used. Other orientation values are valid
and may rotate the cross-section out of the plane of the original SCP#.

[[Specialcases]]
===== 13.3.5.4 Special cases

[[SpecialcasesOverview]]
===== 13.3.5.4.1 Overview

There are a number of special cases require specific handling. These
concern the numbers of values or points, and collinear or coincident
spine points.

[[NumberofScaleOrientationValues]]
===== 13.3.5.4.2 Number of scale or orientation values

If the number of _scale_ or _orientation_ values is greater than the
number of spine points, the excess values are ignored. If they contain
one value, it is applied at all spine points. The results are undefined
if the number of scale or orientation values is greater than one but
less than the number of spine points.

[[CollinearSpinePoints]]
===== 13.3.5.4.3 Collinear spine points

If the three points used in computing the Z-axis are collinear, the
cross-product is zero so the value from the previous point is used
instead.

If the Z-axis of the first point is undefined (because the spine is not
closed and the first two spine segments are collinear) then the Z-axis
for the first spine point with a defined Z-axis is used.

If the entire spine is collinear, the SCP for all the spine points is
computed by finding the rotation of a vector along the positive Y-axis
(`+v1+`) to the vector (`+v2+`) defined by (spine[n] - spine [0]), where
spine[n] is the first spine point not coincident with spine [0]. If v2
is parallel to and in the direction of the negative-Y axis, the rotation
will be a 180 degree rotation about the Z-axis. The Y=0 plane is then
rotated by this value.

[[CoincidentSpinePoints]]
===== 13.3.5.4.4 Coincident spine points

If two or more sequential points in a spine array are coincident, they
are each treated as a single point when computing the corresponding SCP,
and each will have an identical SCP.

NOTE:  This case is useful when animating the spine array without
needing to simultaneously modify the corresponding orientation and scale
arrays.

If each coincident point has a different orientation value, the surface
is constructed by connecting edges of the cross-sections as normal. This
is useful in creating revolved surfaces.

NOTE:  Combining coincident and non-coincident spine segments, as
well as other combinations, can lead to interpenetrating surfaces which
the extrusion algorithm makes no attempt to avoid.

[[NumberOfDistinctSpinePoints]]
===== 13.3.5.4.5 Number of distinct spine points

If only 2 distinct, non-coincident, spine points are provided, the
corresponding SCP planes for each are perpendicular to the vector
defined by these two points.

If fewer than 2 non-coincident spine points are provided, the extrusion
is not well defined and no results are rendered.

[[Commoncases]]
===== 13.3.5.5 Common cases

The following common cases are among the effects which are supported by
the Extrusion node:

_Surfaces of revolution_:::
  If the cross-section is an approximation of a circle and the spine is
  straight, the Extrusion is equivalent to a surface of revolution,
  where the _scale_ parameters define the size of the cross-section
  along the spine.
_Uniform extrusions_:::
  If the _scale_ is (1, 1) and the spine is straight, the cross-section
  is extruded uniformly without twisting or scaling along the spine. The
  result forms a parallelepiped with a uniform cross section.
_Bend/twist/taper objects_:::
  These shapes are the result of using all fields. The spine curve bends
  the extruded shape defined by the cross-section, the orientation
  parameters (given as rotations about the Y-axis) twist it around the
  spine, and the scale parameters taper it (by scaling about the spine).

[[S13_OtherFields]]
===== 13.3.5.6 Other fields

Extrusion has three _parts_: the sides, the _beginCap_ (the surface at
the initial end of the spine) and the _endCap_ (the surface at the final
end of the spine). The caps have an associated SFBool field that
indicates whether each exists (`TRUE`) or does not exist
(`FALSE`).

When the _beginCap_ or _endCap_ fields are specified as `TRUE`,
planar cap surfaces will be generated regardless of whether the
_crossSection_ is a closed curve. If _crossSection_ is not a closed
curve, the caps are generated by adding a final point to _crossSection_
that is equal to the initial point. An open surface can still have a
cap, resulting (for a simple case) in a shape analogous to a soda can
sliced in half vertically. These surfaces are generated even if _spine_
is also a closed curve. If a field value is `FALSE`, the
corresponding cap is not generated.

Texture coordinates are automatically generated by Extrusion nodes.
Textures are mapped so that the coordinates range in the U direction
from 0 to 1 along the _crossSection_ curve (with 0 corresponding to the
first point in _crossSection_ and 1 to the last) and in the V direction
from 0 to 1 along the _spine_ curve (with 0 corresponding to the first
listed _spine_ point and 1 to the last). If either the _endCap_ or
_beginCap_ exists, the _crossSection_ curve is uniformly scaled and
translated so that the larger dimension of the cross-section (X or Z)
produces texture coordinates that range from 0.0 to 1.0. The _beginCap_
and _endCap_ textures' S and T directions correspond to the X and Z
directions in which the _crossSection_ coordinates are defined.

The X3D browser shall automatically generate normals for the Extrusion
node, using the _creaseAngle_ field to determine if and how normals are
smoothed across the surface. Normals for the caps are generated along
the Y-axis of the SCP, with the ordering determined by viewing the
cross-section from above (looking along the negative Y-axis of the SCP).
By default, a _beginCap_ with a counterclockwise ordering shall have a
normal along the negative Y-axis. An _endCap_ with a counterclockwise
ordering shall have a normal along the positive Y-axis.

Each quadrilateral making up the sides of the extrusion are ordered from
the bottom cross-section (the one at the earlier spine point) to the
top. So, one quadrilateral has the points:

[source]
....
    spine[0](crossSection[0], crossSection[1])
    spine[1](crossSection[1], crossSection[0])
....

in that order. By default, normals for the sides are generated as
described in <<Shapeandgeometry, 13.2.2 Shape and geometry nodes>>.

For instance, a circular crossSection with counter-clockwise ordering
and the default spine form a cylinder. With _solid_ `TRUE` and
_ccw_ `TRUE`, the cylinder is visible from the outside. Changing
_ccw_ to `FALSE` makes it visible from the inside.

The _ccw_, _solid_, _convex_, and _creaseAngle_ fields are described in
<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>.

[[IndexedFaceSet]]
==== 13.3.6 IndexedFaceSet

[source,node]
----
IndexedFaceSet : X3DComposedGeometryNode {
  MFInt32 [in]     set_colorIndex
  MFInt32 [in]     set_coordIndex
  MFInt32 [in]     set_normalIndex
  MFInt32 [in]     set_texCoordIndex
  MFNode  [in,out] attrib            []   [X3DVertexAttributeNode]
  SFNode  [in,out] color             NULL [X3DColorNode]
  SFNode  [in,out] coord             NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord          NULL [FogCoordinate]
  SFNode  [in,out] metadata          NULL [X3DMetadataObject]
  SFNode  [in,out] normal            NULL [X3DNormalNode]
  SFNode  [in,out] texCoord          NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw               TRUE
  MFInt32 []       colorIndex        []   [0,∞) or -1
  SFBool  []       colorPerVertex    TRUE
  SFBool  []       convex            TRUE
  MFInt32 []       coordIndex        []   [0,∞) or -1
  SFFloat []       creaseAngle       0    [0,∞)
  MFInt32 []       normalIndex       []   [0,∞) or -1
  SFBool  []       normalPerVertex   TRUE
  SFBool  []       solid             TRUE
  MFInt32 []       texCoordIndex     []   [-1,∞)
}
----

The IndexedFaceSet node represents a 3D shape formed by constructing
faces (polygons) from vertices listed in the _coord_ field. The _coord_
field contains a <<X3DCoordinateNode, _X3DCoordinateNode_>> node that
defines the 3D vertices referenced by the _coordIndex_ field.
IndexedFaceSet uses the indices in its _coordIndex_ field to specify the
polygonal faces by indexing into the coordinates in the
<<X3DCoordinateNode, _X3DCoordinateNode_>> node. An index of "−1"
indicates that the current face has ended and the next one begins. The
last face may be (but does not have to be) followed by a "−1" index. If
the greatest index in the _coordIndex_ field is N, the
<<X3DCoordinateNode, _X3DCoordinateNode_>> node shall contain N+1
coordinates (indexed as 0 to N). Each face of the IndexedFaceSet shall
have:

[loweralpha]
. at least three non-coincident vertices;
. vertices that define a planar polygon;
. vertices that define a non-self-intersecting polygon.

Otherwise, the results are undefined.

The IndexedFaceSet node is specified in the local coordinate system and
is affected by the transformations of its ancestors.

Descriptions of the _coord_, _normal_, and _texCoord_ fields are
provided in Coordinate, _<<X3DNormalNode>>_, and
<<X3DTextureCoordinateNode>>, respectively.

Details on lighting equations and the interaction between _color_ field,
_normal_ field, textures, materials, and geometries are provided in
<<rendering_html, 11 Rendering component>> and <<shape_html, 12 Shape component>>.

If the _color_ field is not `NULL`, it shall contain a node
derived from _<<X3DColorNode>>_ whose colours are
applied to the vertices or faces of the IndexedFaceSet as follows:

[loweralpha, start=4]
. If _colorPerVertex_ is `FALSE`, colours are applied to each
face, as follows:
[arabic]
.. If the _colorIndex_ field is not empty, one colour is used for each
face of the IndexedFaceSet. There shall be at least as many indices in
the _colorIndex_ field as there are faces in the IndexedFaceSet. If the
greatest index in the _colorIndex_ field is N, there shall be N+1
colours in the _X3DColorNode_. The _colorIndex_ field shall not contain
any negative entries.
.. If the _colorIndex_ field is empty, the colours in the _X3DColorNode_
node are applied to each face of the IndexedFaceSet in order. There
shall be at least as many colours in the _X3DColorNode_ node as there
are faces.
. If _colorPerVertex_ is `TRUE`, colours are applied to each
vertex, as follows:
[arabic]
.. If the _colorIndex_ field is not empty, colours are applied to each
vertex of the IndexedFaceSet in exactly the same manner that the
_coordIndex_ field is used to choose coordinates for each vertex from
the <<X3DCoordinateNode, _X3DCoordinateNode_>> node. The _colorIndex_
field shall contain at least as many indices as the _coordIndex_ field,
and shall contain end-of-face markers (−1) in exactly the same places as
the _coordIndex_ field. If the greatest index in the _colorIndex_ field
is N, then there shall be N+1 colours in the _X3DColorNode_ node.
.. If the _colorIndex_ field is empty, the _coordIndex_ field is used to
choose colours from the _X3DColorNode_ node. If the greatest index in
the _coordIndex_ field is N, then there shall be N+1 colours in the
_X3DColorNode_ node.

If the _color_ field is `NULL`, the geometry shall be rendered
normally using the Material and texture defined in the Appearance node
(see <<shape_html, 12 Shape component>> for details).

If the _normal_ field is not `NULL`, it shall contain a node
derived from _X3DNormalNode_ whose normals are applied to the vertices
or faces of the IndexedFaceSet in a manner exactly equivalent to that
described above for applying colours to vertices/faces (where
_normalPerVertex_ corresponds to _colorPerVertex_ and _normalIndex_
corresponds to _colorIndex_). If the _normal_ field is `NULL`,
the X3D browser shall automatically generate normals, using
_creaseAngle_ to determine if and how normals are smoothed across shared
vertices (see <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>).

If the _texCoord_ field is not `NULL`, it shall contain a node
derived from _X3DTextureCoordinateNode_. The texture coordinates in that
node are applied to the vertices of the IndexedFaceSet as follows:

[loweralpha, start=6]
. If the _texCoordIndex_ field is not empty, then it is used to choose
texture coordinates for each vertex of the IndexedFaceSet in exactly the
same manner that the _coordIndex_ field is used to choose coordinates
for each vertex from the <<X3DCoordinateNode, _X3DCoordinateNode_>>
node. The _texCoordIndex_ field shall contain at least as many indices
as the _coordIndex_ field, and shall contain end-of-face markers (−1) in
exactly the same places as the _coordIndex_ field. If the greatest index
in the _texCoordIndex_ field is N, then there shall be N+1 texture
coordinates in the _X3DTextureCoordinateNode_.
. If the _texCoordIndex_ field is empty, then the _coordIndex_ array is
used to choose texture coordinates from the _X3DTextureCoordinateNode_
node. If the greatest index in the _coordIndex_ field is N, then there
shall be N+1 texture coordinates in the _X3DTextureCoordinateNode_ node.

If the _texCoord_ field is `NULL`, a default texture coordinate
mapping is calculated using the local coordinate system bounding box of
the shape. The longest dimension of the bounding box defines the S
coordinates, and the next longest defines the T coordinates. If two or
all three dimensions of the bounding box are equal, ties shall be broken
by choosing the X, Y, or Z dimension in that order of preference. The
value of the S coordinate ranges from 0 to 1, from one end of the
bounding box to the other. The T coordinate ranges between 0 and the
ratio of the second greatest dimension of the bounding box to the
greatest dimension. <<f-IndexedFaceSettextureDefaultMapping, Figure 13.6>> illustrates the default texture coordinates for a simple box
shaped IndexedFaceSet with an X dimension twice as large as the Z
dimension and four times as large as the Y dimension.
<<f-ImageTextureforIndexedFaceSet, Figure 13.7>> illustrates the
original texture image used on the IndexedFaceSet used in
<<f-IndexedFaceSettextureDefaultMapping, Figure 13.6>>.

[[f-IndexedFaceSettextureDefaultMapping]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/IFStexture.gif[IndexedFaceSet node texture mapping,width=488,height=352]

Figure 13.6 — IndexedFaceSet texture default mapping

[[f-ImageTextureforIndexedFaceSet]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/IFStexture2.gif[ImageTexture for IndexedFaceSet in Figure 6.10,width=362,height=171]

Figure 13.7 — ImageTexture for IndexedFaceSet in Figure 13.6

<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>, provides a
description of the ccw, solid, convex, and creaseAngle fields.

[[Sphere]]
==== 13.3.7 Sphere

[source,node]
----
Sphere : X3DGeometryNode { 
  SFNode  [in,out] metadata NULL [X3DMetadataObject]
  SFFloat []       radius   1    (0,∞)
  SFBool  []       solid    TRUE
}
----

The Sphere node specifies a sphere centred at (0, 0, 0) in the local
coordinate system. The _radius_ field specifies the radius of the sphere
and shall be greater than zero. <<f-Spherenode, Figure 13.8>> depicts
the fields of the Sphere node.

[[f-Spherenode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/sphere.gif[Sphere node,width=342,height=334]

Figure 13.8 — Sphere node

When a texture is applied to a sphere, the texture covers the entire
surface, wrapping counterclockwise from the back of the sphere ( _i.e._,
longitudinal arc intersecting the -Z-axis) when viewed from the top of
the sphere. The texture has a seam at the back where the X=0 plane
intersects the sphere and Z values are negative.
<<TextureTransform>> affects the texture coordinates
of the Sphere (see <<TextureTransform, 18.4.8 TextureTransform>>).

The _solid_ field determines whether the sphere is visible when viewed
from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

This geometry node is fundamentally a mathematical representation.
Displayed geometry shall have sufficient rendering quality that surface
and silhouette edges appear smooth, including when textures are applied.

[[S13.4_SupportLevels]]
=== 13.4 Geometry3D component support levels.

The Geometry3D component provides three levels of support as specified
in <<t13_2, Table 13.2>>. Level 1 provides the basic indexed
geometry types with limited support for some fields, as well as the
geometric primitives and the <<Shape>> node. Level 2 adds
support for the <<IndexedFaceSet>> node. Level 3 adds
support for the <<ElevationGrid>> node to enable
lightweight terrain and data visualization and supports all fields in
all nodes supported at Level 3. Level 4 adds support for the
<<Extrusion>> node.

[[t13_2]]
Table 13.2 — Geometry3D component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Rendering 1 +
Shape 1 | |

| | |Box      |All fields fully supported.
| | |Cone     |All fields fully supported.
| | |Cylinder |All fields fully supported.
| | |Sphere   |All fields fully supported.

|*2* |Core 1 +
Grouping 1 +
Rendering 1 +
Shape 1 | |

| | |All Level 1 geometry nodes |All fields as supported in Level 1.

| | |IndexedFaceSet a|
_ccw_ optionally supported. _set_colorIndex_ optionally supported.
_set_normalIndex_ optionally supported. _normal_ optionally supported.
Only convex indexed face sets supported. Hence, _convex_ optionally
supported. For _creaseAngle_, only 0 and π radians supported
(or the equivalent if a different angle base unit has been specified).
_normalIndex_ optionally supported.

Face list shall be well-defined as follows:

. Each face is terminated with -1, including the last face in the array.
. Each face contains at least three non-coincident vertices.
. A given _coordIndex_ is not repeated in a face.
. The vertices of a face shall define a planar polygon.
. The vertices of a face shall not define a self-intersecting polygon.

|*3* |Core 1 +
Grouping 1 +
Rendering 1 +
Shape 1 |  | 

|  |  |All Level 2 geometry nodes |All fields as supported in Level 2.

| | |ElevationGrid |_ccw_ optionally supported.

|*4* |Core 1 +
Grouping 1 +
Rendering 1 +
Shape 1 |  | 

|  |  |All Level 3 geometry nodes |All fields fully supported.

| | |Extrusion |All fields fully supported.
|===

[[geometry2D_html]]
== 14 Geometry2D component

[[S14_Introduction]]
=== 14.1 Introduction

[[S14_Name]]
==== 14.1.1 Name

The name of this component is "Geometry2D". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S14_Overview]]
==== 14.1.2 Overview

This clause describes the Geometry2D component of this document. This
includes how two-dimensional geometry is specified and what shapes are
available. <<t14_1, Table 14.1>> provides links to the major topics
in this clause.

[[t14_1]]
Table 14.1 — Topics

* <<S14Introduction, 14.1 Introduction>>
** <<S14_Name, 14.1.1 Name>>
** <<S14_Overview, 14.1.2 Overview>>
* <<S14_Concepts, 14.2 Concepts>>
** <<S14_OverviewOfGeometry, 14.2.1 Overview of geometry>>
** <<ShapeAndGeometryNodes, 14.2.2 Shape and geometry nodes>>
** <<GeometryPropertyNodes, 14.2.3 Geometric property nodes>>
** <<AppearanceNodes, 14.2.4 Appearance nodes>>
* <<S14_NodeReference, 14.3 Node Reference>>
** <<Arc2D, 14.3.1 Arc2D>>
** <<ArcClose2D, 14.3.2 ArcClose2D>>
** <<Circle2D, 14.3.3 Circle2D>>
** <<Disk2D, 14.3.4 Disk2D>>
** <<Polyline2D, 14.3.5 Polyline2D>>
** <<Polypoint2D, 14.3.6 Polypoint2D>>
** <<Rectangle2D, 14.3.7 Rectangle2D>>
** <<TriangleSet2D, 14.3.8 TriangleSet2D>>
* <<S14_SupportLevels, 14.4 Support levels>>

* <<f-Arc2Dnode, Figure 14.1 — Arc2D node>>
* <<f-ArcClose2DNodePIE, Figure 14.2 — ArcClose2D node ("PIE" closure)>>
* <<f-ArcClose2DnodeCHORD, Figure 14.2 — ArcClose2D node ("CHORD" closure)>>
* <<f-Circle2Dnode, Figure 13.4 — Circle2D node>>
* <<f-Disk2Dnode, Figure 14.5 — Disk2D node>>
* <<f-Polyline2Dnode, Figure 14.6 — Polyline2D node>>
* <<f-Polypoint2Dnode, Figure 14.7 — Polypoint2D node>>
* <<f-Rectangle2Dnode, Figure 14.8 — Rectangle2D node>>
* <<f-TriangleSet2Dnode, Figure 14.9 — TriangleSet2D node>>

* <<t14_1, Table 14.1 — Topics>>
* <<t14_2, Table 14.2 — Geometry2D component support levels>>




[[S14_Concepts]]
=== 14.2 Concepts

[[ShapeAndGeometryNodes]]
==== 14.2.1 Overview of geometry

The geometry2D component consists of only geometry nodes since it uses
the shape, geometry property, and appearance nodes defined in the Shape
component. The geometry2D nodes may be considered to be planar objects.

The two-dimensional coordinate system in which all 2D nodes are
specified is defined to be the z=0 plane of the current 3D coordinate
system with x- and y-axes coincident with those of the current 3D
coordinate system. The origin of the 2D coordinate system is defined to
be the origin of the 3D coordinate system.  The unspecified z-component
of a 2D coordinate is defined to always have value zero. The position
and orientation of 2D nodes are affected by all transformations whether
2D or 3D.

Each face in a 2D node is coplanar with the z=0 plane of the coordinate
system in which it is defined. Faces have both a front and a back face.
The front face is defined to be that on the positive side of the z=0
plane. Faces are subject to culling as defined elsewhere in this
standard for 3D geometry.

When 2D nodes are viewed edge-on, they disappear as they have no depth.

[[ShapeAndGeometryNodes]]
==== 14.2.2 Shape and geometry nodes

The <<Shape>> node is defined in <<shape_html, 12 Shape component>>.

[[GeometryPropertyNodes]]
==== 14.2.3 Geometric property nodes

Several geometry nodes contain geometric property nodes such as
<<Coordinate>>, <<Color>>,
<<ColorRGBA>>, and/or <<Normal>>. These nodes are
specified in <<rendering_html, 11 Rendering component>>. The
_<<X3DTextureCoordinateNode, X3DTextureCoordinate>>_ nodes specified
in <<texturing_html, 18 Texturing component>> are also geometry
property nodes.

[[AppearanceNodes]]
==== 14.2.4 Appearance nodes

<<Shape>> nodes may specify an <<Appearance>>
node that describes the appearance properties (material and texture) to
be applied to the Shape's geometry. Appearance is described in
<<shape_html, 12 Shape component>>

The interaction between the appearance properties and properties
specific to geometry nodes  is described in <<shape_html, 12 Shape component>>.


=== 14.3 Node reference

[[Arc2D]]
==== 14.3.1 Arc2D

[source,node]
----
Arc2D : X3DGeometryNode { 
  SFNode  [in,out] metadata   NULL  [X3DMetadataObject]
  SFFloat []       endAngle   π/2   [-2π,2π]
  SFFloat []       radius     1     (0,∞)
  SFFloat []       startAngle 0     [-2π,2π]
}
----

The Arc node specifies a linear circular arc whose center is at (0,0)
and whose angles are measured starting at the positive x-axis and
sweeping towards the positive y-axis.

The _radius_ field specifies the radius of the circle of which the arc
is a portion.

The arc extends from the _startAngle_ counterclockwise to the
_endAngle_. The values of _startAngle_ and _endAngle_ shall be in the
range [-2π, 2π] radians (or the equivalent if a
different angle base unit has been specified). If _startAngle_
`and` _endAngle_ have the same value, a circle is specified.

See <<LineSet, 11.4.10 LineSet>> for additional considerations
regarding line rendering and collision detection.

See <<f-Arc2Dnode, Figure 14.1>> for a depiction of the Arc node.

[[f-Arc2Dnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Arc2DNode.gif[Arc2D node,width=104,height=98]

Figure 14.1 — Arc2D node

[[ArcClose2D]]
==== 14.3.2 ArcClose2D

[source,node]
----
ArcClose2D : X3DGeometryNode { 
  SFNode   [in,out] metadata    NULL  [X3DMetadataObject]
  SFString []       closureType "PIE" ["PIE"|"CHORD"]
  SFFloat  []       endAngle    π/2   [-2π,2π]
  SFFloat  []       radius      1     (0,∞)
  SFBool   []       solid       FALSE
  SFFloat  []       startAngle  0     [-2π,2π]
}
----

The ArcClose2D node specifies surface geometry describing a portion of a
circle, whose center is at (0,0) and whose angles are measured starting
at the positive x-axis and sweeping towards the positive y-axis.

The end points of the arc specified are connected as defined by the
_closureType_ field.

The _radius_ field specifies the radius of the circle of which the arc
is a portion.

The arc extends from the _startAngle_ counterclockwise to the
_endAngle_. The value of _radius_ shall be greater than zero. The values
of _startAngle_ and _endAngle_ shall be in the range [-2π, 2π] radians 
(or the equivalent if a different default angle
base unit has been specified). If _startAngle_ and _endAngle_ have the
same value, a circle is specified and _closureType_ is ignored.  If the
absolute difference between _startAngle_ and _endAngle_ is greater than
or equal to 2π, a complete circle is produced with no chord
or radial line(s) drawn from the center.

A _closureType_ of `"PIE"` connects the end point to the start
point by defining two straight line segments first from the end point to
the center and then the center to the start point. This forms a pie
wedge surface as shown in <<f-ArcClose2DNodePIE, Figure 14.2>>.

[[f-ArcClose2DNodePIE]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ArcClose2DPie.gif[ArcClose2D node pie closure,width=152,height=146]

Figure 14.2 — ArcClose2D node ("PIE" closure)

A _closureType_ of `"CHORD"` connects the end point to the start
point by defining a straight line segment from the end point to the
start point. This forms a surface as shown in
<<f-ArcClose2DnodeCHORD, Figure 14.3>>.

[[f-ArcClose2DnodeCHORD]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ArcClose2DChord.gif[ArcClose2D node CHORD closure) ,width=104,height=98]

Figure 14.3 — ArcClose2D node ("CHORD" closure)

Textures are applied individually to each face of the ArcClose2D. On the
front (+Z) and back (-Z) faces of the ArcClose2D, when viewed from the
+Z-axis, the texture is mapped onto each face with the same orientation
as if the image were displayed normally in 2D. TextureTransform affects
the texture coordinates of the ArcClose2D (see
<<TextureTransform, 18.4.9 TextureTransform>>).

<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a
complete description of the _solid_ field.

[[Circle2D]]
==== 14.3.3 Circle2D

[source,node]
----
Circle2D : X3DGeometryNode { 
  SFNode  [in,out] metadata NULL  [X3DMetadataObject]
  SFFloat []       radius   1     (0,∞)
}
----

The Circle2D node specifies a circle centred at (0,0) in the local 2D
coordinate system.

The _radius_ field specifies the radius of the Circle2D. The value of
_radius_ shall be greater than zero.

<<f-Circle2Dnode, Figure 14.4>> illustrates the Circle2D node with a
dashed linetype applied.

[[f-Circle2Dnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Circle2D.gif[circle2D node,width=112,height=112]

Figure 14.4 — Circle2D node

[[Disk2D]]
==== 14.3.4 Disk2D

[source,node]
----
Disk2D : X3DGeometryNode { 
 SFNode  [in,out] metadata    NULL  [X3DMetadataObject]
 SFFloat []       innerRadius 0     [0,∞)
 SFFloat []       outerRadius 1     (0,∞)
 SFBool  []       solid       FALSE
}
----

The Disk2D node specifies a circular disk which is centred at (0, 0) in
the local coordinate system.

The _outerRadius_ field specifies the radius of the outer dimension of
the Disk2D. The _innerRadius_ field specifies the inner dimension of the
Disk2D. The value of _outerRadius_ shall be greater than zero. The value
of _innerRadius_ shall be greater than or equal to zero and less than or
equal to _outerRadius_. If _innerRadius_ is zero, the Disk2D is
completely filled. Otherwise, the area within the _innerRadius_ forms a
hole in the Disk2D. If _innerRadius_ is equal to _outerRadius_, a solid
circular line shall be drawn using the current line properties.

<<f-Disk2Dnode, Figure 14.5>> illustrates the Disk2D node containing a
non-zero _innerRadius_.

[[f-Disk2Dnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Disk2D.gif[Disk2D node,width=108,height=108]

Figure 14.5 — Disk2D node

Textures are applied individually to each face of the Disk2D. On the
front (+Z) and back (-Z) faces of the Disk2D, when viewed from the
+Z-axis, the texture is mapped onto each face with the same orientation
as if the image were displayed normally in 2D.
<<TextureTransform>> affects the texture coordinates
of Disk2D nodes (see <<TextureTransform, 18.4.9 TextureTransform>>).

<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a
complete description of the _solid_ field.

[[Polyline2D]]
==== 14.3.5 Polyline2D

[source,node]
----
Polyline2D : X3DGeometryNode { 
  SFNode  [in,out] metadata     NULL  [X3DMetadataObject]
  MFVec2f []       lineSegments []    (-∞,∞)
}
----

The Polyline2D node specifies a series of contiguous line segments in
the local 2D coordinate system connecting the specified vertices.

The _lineSegments_ field specifies the vertices to be connected.

See <<LineSet, 11.4.10 LineSet>> for additional considerations
regarding line rendering and collision detection.

<<f-Polyline2Dnode, Figure 14.6>> illustrates the Polyline2D node.

[[f-Polyline2Dnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Polyline2D.gif[Polyline2D,width=316,height=136]

Figure 14.6 — Polyline2D node

[[Polypoint2D]]
==== 14.3.6 Polypoint2D

[source,node]
----
Polypoint2D : X3DGeometryNode { 
  SFNode  [in,out] metadata NULL [X3DMetadataObject]
  MFVec2f [in,out] point    []    (-∞,∞)
}
----

The Polyline2D node specifies a set of vertices in the local 2D
coordinate system at each of which is displayed a point.

The _points_ field specifies the vertices to be displayed.

<<f-Polypoint2Dnode, Figure 14.7>> illustrates the Polypoint2D node by
depicting the line in <<f-Polyline2Dnode, Figure 14.6>> (with points
augmented for illustrative purposes).

[[f-Polypoint2Dnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Polypoint2D.gif[Polypoint2D node,width=333,height=147]

Figure 14.7 — Polypoint2D node

[[Rectangle2D]]
==== 14.3.7 Rectangle2D

[source,node]
----
Rectangle2D : X3DGeometryNode { 
  SFNode  [in,out] metadata NULL  [X3DMetadataObject]
  SFVec2f []       size     2 2   (0,∞)
  SFBool  []       solid    FALSE
}
----

The Rectangle2D node specifies a rectangle centred at (0, 0) in the
current local 2D coordinate system and aligned with the local coordinate
axes. By default, the box measures 2 units in each dimension, from -1 to
+1.

The _size_ field specifies the extents of the box along the X- axis and
Y-axis respectively, and each component value shall be greater than
zero. <<f-Rectangle2Dnode, Figure 14.8>> illustrates the Rectangle2D
node with a <<FillProperties>> node defining a hatch
style.

[[f-Rectangle2Dnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Rectangle2D.gif[Rectangle2D node,width=221,height=201]

Figure 14.8 — Rectangle2D node

Textures are applied individually to each face of the Rectangle2D. On
the front (+Z) and back (-Z) faces of the Rectangle2D, when viewed from
the +Z-axis, the texture is mapped onto each face with the same
orientation as if the image were displayed normally in 2D.
<<TextureTransform>> affects the texture coordinates
of the Rectangle2D (see <<TextureTransform, 18.4.9 TextureTransform>>).

<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a
complete description of the _solid_ field.

[[TriangleSet2D]]
==== 14.3.8 TriangleSet2D

[source,node]
----
TriangleSet2D : X3DGeometryNode { 
  SFNode  [in,out] metadata NULL  [X3DMetadataObject]
  MFVec2f [in,out] vertices []    (-∞,∞)
  SFBool  []       solid    FALSE
}
----

The TriangleSet2D node specifies a set of triangles in the local 2D
coordinate system.

The _vertices_ field specifies the triangles to be displayed. The number
of vertices provided shall be evenly divisible by three.  Excess
vertices shall be ignored.

<<f-TriangleSet2Dnode, Figure 14.9>> illustrates the TriangleSet2D
node.

[[f-TriangleSet2Dnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/TriangleSet2D.gif[TriangleSet2D node,width=211,height=292]

Figure 14.9 — TriangleSet2D node

<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a
complete description of the _solid_ field.

Textures are applied individually to each face of the TriangleSet2D. On
the front (+Z) and back (-Z) faces of the TriangleSet2D, when viewed
from the +Z-axis, the texture is mapped onto each face with the same
orientation as if the image were displayed normally in 2D.
<<TextureTransform>> affects the texture coordinates
of the TriangleSet2D (see <<TextureTransform, 18.4.9 TextureTransform>>).

[[S14.4_SupportLevels]]
=== 14.4 Support levels

The Geometry2D component provides two levels of support as specified in
<<t14_2, Table 14.2>>. Level 1 provides the basic support
for two-dimensional geometry with straight sides. Level 2 adds support
for two-dimensional geometry with non-straight sides.

[[t14_2]]
Table 14.2 — Geometry2D component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | |
| | |Polyline2D |All fields fully supported.
| | |Polypoint2D |All fields fully supported.
| | |Rectangle2D |All fields fully supported.
| | |TriangleSet2D |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | |
| | |All Level 1 Geometry2D nodes |All fields fully supported.
| | |Arc2D |All fields fully supported.
| | |ArcClose2D |All fields fully supported.
| | |Circle2D |All fields fully supported.
| | |Disk2D |All fields fully supported.
|===

[[text_html]]
== 15 Text component

[[S15_Introduction]]
=== 15.1 Introduction

[[S15_Name]]
==== 15.1.1 Name

The name of this component is "Text". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S15_Overview]]
==== 15.1.2 Overview

This clause describes the Text component of this document. The Text
component specifies how text strings are rendered in an X3D scene.
<<t15_1, Table 15.1>> provides links to the major topics in this
clause.

[[t15_1]]
Table 15.1 — Topics

* <<S15Introduction, 15.1 Introduction>>
** <<S15_Name, 15.1.1 Name>>
** <<S15_Overview, 15.1.2 Overview>>
* <<S15_Concepts, 15.2 Concepts>>
** <<Textsemantics, 15.2.1 Text semantics>>
*** <<TextSemanticsOverview, 15.2.1.1 Overview>>
*** <<Appearance, 15.2.1.2 Appearance>>
** <<TextFormatting, 15.2.2 Text formatting>>
*** <<FormattingIntroduction, 15.2.2.1 Introduction>>
*** <<Fontfamilyandstyle, 15.2.2.2 Font family and style>>
*** <<Directionandjustification, 15.2.2.3 Direction and justification>>
*** <<Language, 15.2.2.4 Language>>
* <<S15_AbstractTypes, 15.3 Abstract types>>
** <<X3DFontStyleNode, 15.3.1 _X3DFontStyleNode_>>
* <<S15_NodeReference, 15.4 Node reference>>
** <<FontStyle, 15.4.1 FontStyle>>
** <<Text, 15.4.2 Text>>
* <<SupportlLevels, 15.5 Support levels>>

* <<f-KeyforTables, Figure 15.1 — Key for Tables 15.5 and 15.6>>
* <<f-Textsizeandspacingfields, Figure 15.2 — Text __size__and __spacing__fields>>
* <<f-LineBoundsAndTextBoundsMeasurements, Figure 15.3 — __lineBounds__and __textBounds__measurements>>

* <<t15_1, Table 15.1 — Topics>>
* <<t15_2, Table 15.2 — Major Alignment, horizontal = TRUE>>
* <<t15_3, Table 15.3 — Major Alignment, horizontal = FALSE>>
* <<t15_4, Table 15.4 — Minor Alignment, horizontal = TRUE>>
* <<t15_5, Table 15.5 — Minor Alignment, horizontal = FALSE>>
* <<t15_6, Table 15.6 — horizontal = TRUE>>
* <<t15_7, Table 15.7 — horizontal = FALSE>>
* <<t15_8, Table 15.8 — Text component support levels>>




[[S15_Concepts]]
=== 15.2 Concepts

[[Textsemantics]]
==== 15.2.1 Text semantics

[[TextSemanticsOverview]]
===== 15.2.1.1 Overview

Text is processed as geometry in X3D. There are special considerations
when specifying text as well as when displaying text. This subclause
describes the manner in which text values are specified in X3D using the
<<Text>> node. <<TextFormatting, 15.2.2 Text formatting>>
describes text formatting.

[[Appearance]]
===== 15.2.1.2 Appearance

Textures are applied to text as follows. The texture origin is at the
origin of the first string, as determined by the justification. The
texture is scaled equally in both S and T dimensions, with the font
height representing 1 unit. S increases to the right, and T increases
up.

<<shape_html, 12 Shape component>> specifies how
<<Appearance>>, material and textures interact with
lighting. <<lighting_html, 17 Lighting component>> specifies the X3D
lighting equations.

[[TextFormatting]]
==== 15.2.2 Text formatting


===== 15.2.2.1 Introduction

There is a long history of text layout and formatting. This standard
specifies techniques to be used in X3D that provide support for a
variety of languages and layout schemes. Additional layout functionality
is specified in <<layout_html, 36 Layout component>>.

[[Fontfamilyandstyle]]
===== 15.2.2.2 Font family and style

Font attributes are defined with the _family_ and _style_ fields. The
X3D browser shall map the specified font attributes to an appropriate
available font as described below.

The _family_ field contains a case-sensitive MFString value that
specifies a sequence of font family names in preference order. The X3D
browser shall search the MFString value for the first font family name
matching a supported font family. If none of the string values matches a
supported font family, the default font family "`SERIF`" shall be
used. All X3D browsers shall support at least "`SERIF`" (the
default) for a serif font such as Times Roman; "`SANS`" for a
sans-serif font such as Helvetica; and "`TYPEWRITER`" for a
fixed-pitch font such as Courier. An empty _family_ value is identical
to ["`SERIF`"]. Any font family may be specified as shown in the
following example of the specification of a font family:

[source]
....
    ["Lucida Sans Typewriter", "Lucida Sans", "Helvetica", "SANS"]
....

In this example, the X3D browser would first look for the font family
"Lucida Sans Typewriter" on the system on which the X3D browser is
operating. If that is not available, the X3D browser looks for "Lucida
Sans". If that is not available, the browser looks for "Helvetica". If
that is not available, the X3D browser looks for any sans-serif font. If
there are not sans-serif fonts installed, the X3D browser will use any
serif font (the default). It is the responsibility of the author that a
suitable list of font families be  specified so that the desired
appearance is achieved in most operating environments. However, the
author should always be willing to accept that the requested font
families may not be available resulting in the use of a X3D
browser-selected "`SERIF`" font being used.

The _style_ field specifies a case-sensitive SFString value that may be
"`PLAIN`" (the default) for default plain type; "`BOLD`"
for boldface type; "`ITALIC`" for italic type; or
"`BOLDITALIC`" for bold and italic type. An empty _style_ value
("") is identical to "`PLAIN`". In the case where the requested
style is not available, the available style that is closest to the
requested style shall be used. For example, some font families specify a
Demibold style rather than Bold. In this case, specifying
"`BOLD`" will result in the X3D browser using Demibold as the
nearest substitute.

[[Directionandjustification]]
===== 15.2.2.3 Direction and justification

The _horizontal_, _leftToRight_, and _topToBottom_ fields indicate the
direction of the text. The _horizontal_ field indicates whether the text
advances horizontally in its major direction ( _horizontal_ =
`TRUE`, the default) or vertically in its major direction (
_horizontal_ = `FALSE`). The _leftToRight_ and _topToBottom_
fields indicate direction of text advance in the major (characters
within a single string) and minor (successive strings) axes of layout.
Which field is used for the major direction and which is used for the
minor direction is determined by the _horizontal_ field. Note that the
direction specification overrides any modes inherent in a particular
language.

For horizontal text ( _horizontal_ = `TRUE`), characters on each
line of text advance in the positive X direction if _leftToRight_ is
`TRUE` or in the negative X direction if _leftToRight_ is
`FALSE`. Characters are advanced according to their natural
advance width. Each line of characters is advanced in the negative Y
direction if _topToBottom_ is `TRUE` or in the positive Y
direction if _topToBottom_ is `FALSE`. Lines are advanced by the
amount of __size __×  _spacing_.

For vertical text ( _horizontal_ = `FALSE`), characters on each
line of text advance in the negative Y direction if _topToBottom_ is
`TRUE` or in the positive Y direction if _topToBottom_ is
`FALSE`. Characters are advanced according to their natural
advance height. Each line of characters is advanced in the positive X
direction if _leftToRight_ is `TRUE` or in the negative X
direction if _leftToRight_ is `FALSE`. Lines are advanced by the
amount of __size __×  _spacing_.

The _justify_ field determines alignment of the above text layout
relative to the origin of the object coordinate system. The _justify_
field is an MFString which can contain 2 values. The first value
specifies alignment along the major axis and the second value specifies
alignment along the minor axis, as determined by the _horizontal_ field.
An empty _justify_ value ("") is equivalent to the default value. If the
second string, minor alignment, is not specified, minor alignment
defaults to the value "`FIRST`". Thus, _justify_ values of "",
"`BEGIN`", and ["`BEGIN`" "`FIRST`"] are
equivalent.

The major alignment is along the X-axis when _horizontal_ is
`TRUE` and along the Y-axis when _horizontal is_ `FALSE`.
The minor alignment is along the Y-axis when _horizontal_ is
`TRUE` and along the X-axis when _horizontal is_ `FALSE`.
The possible values for each enumerant of the _justify_ field are
"`FIRST`", "`BEGIN`", "`MIDDLE`", and
"`END`". For major alignment, each line of text is positioned
individually according to the major alignment enumerant. For minor
alignment, the block of text representing all lines together is
positioned according to the minor alignment enumerant.
<<t15_2, Tables 15.2-15.5>> describe the behaviour in
terms of which portion of the text is at the origin.

[[t15_2]]
Table 15.2 — Major Alignment, _horizontal_ =
`TRUE`

[cols=",,",]
|===
|*__justify__Enumerant* |*__leftToRight__=* `TRUE`
|*__leftToRight__=* `FALSE`

| `FIRST` | Left edge of each line | Right edge of each line

| `BEGIN` | Left edge of each line | Right edge of each line

| `MIDDLE` | Centred about X-axis | Centred about X-axis

| `END` | Right edge of each line | Left edge of each line
|===

[[t15_3]]
Table 15.3 — Major Alignment, _horizontal_ =
`FALSE`

[cols=",,",]
|===
|*__justify__Enumerant* |*__topToBottom__=* `TRUE`
|*__topToBottom__=* `FALSE`

| `FIRST` | Top edge of each line | Bottom edge of each line

| `BEGIN` | Top edge of each line | Bottom edge of each line

| `MIDDLE` | Centred about Y-axis | Centre about Y-axis

| `END` | Bottom edge of each line | Top edge of each line
|===

[[t15_4]]
Table 15.4 — Minor Alignment, _horizontal_ =
`TRUE`

[cols=",,",]
|===
|*__justify__Enumerant* |*__topToBottom__=* `TRUE`
|*__topToBottom__=* `FALSE`

|`FIRST` |Baseline of first line |Baseline of first line

|`BEGIN` |Top edge of first line |Bottom edge of first line

|`MIDDLE` |Centred about Y-axis |Centred about Y-axis

|`END` |Bottom edge of last line |Top edge of last line
|===

[[t15_5]]
Table 15.5 — Minor Alignment, _horizontal_ =
`FALSE`

[cols=",,",]
|===
|*__justify__Enumerant* |*__leftToRight__=* `TRUE`
|*__leftToRight__=* `FALSE`

|`FIRST` |Left edge of first line |Right edge of first line

|`BEGIN` |Left edge of first line |Right edge of first line

|`MIDDLE` |Centred about X-axis |Centred about X-axis

|`END` |Right edge of last line |Left edge of last line
|===

The default minor alignment is *"*`FIRST` *"*. This is a special
case of minor alignment when _horizontal_ is `TRUE`. Text starts
at the baseline at the Y-axis. In all other cases, *"*`FIRST` *"*
is identical to *"*`BEGIN` *"*. In <<t15_6, Tables 15.6 and 15.7>>, each colour-coded cross-hair indicates where the X-axis
and Y-axis shall be in relation to the text. <<f-KeyforTables, Figure 15.1>> describes the symbols used in <<t15_6, Tables 15.6>>
and <<t15_7, Table 15.7>>.

[[f-KeyforTables]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/key.gif[Key for Tables 14.6 and 14.7,width=349,height=93]

Figure 15.1 — Key for Tables 15.6 and 15.7

[[t15_6]]
Table 15.6 — _horizontal_ = [.code]]
TRUE#

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/horizontal.gif[horizontal = TRUE,width=633,height=278]

[[t15_7]]
Table 15.7 — _horizontal =_ [.code]]
FALSE#

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/vertical.gif[horizontal = FALSE,width=630,height=483]

[[Language]]
===== 15.2.2.4 Language

The _language_ field specifies the context of the language for the text
string in the form of a language and a country in which that language is
used. Both the language and the country are specified using the language
tags defined in <<RFC3066>> which may specify only a
country (using the three-character codes defined in <<I3166, ISO 3166>>) or both a language (using the two-character codes specified in
<<I639, ISO 639>>) and a country (using the three-character codes
specified in <<I3166, ISO 3166>>) utilizing a sub-tag structure as
specified in <<RFC3066>>). The language tags contain
between one and eight characters. Note that the characters used in the
language tag are in the Basic Latin alphabet that maps to single-byte
characters in the UTF-8 encoding.

See <<references_html, 2 Normative references>>, for more information
on RFC 3066 (<<RFC3066>>), <<I10646, ISO/IEC 10646>>,
<<I639, ISO/IEC 639>>, and <<I3166, ISO 3166>>.


=== 15.3 Abstract types

[[X3DFontStyleNode]]
==== 15.3.1 _X3DFontStyleNode_

[source,node]
----
X3DFontStyleNode : X3DNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base node type for all font style nodes.


=== 15.4 Node reference

[[FontStyle]]
==== 15.4.1 FontStyle

[source,node]
----
FontStyle : X3DFontStyleNode {
  SFNode   [in,out] metadata    NULL    [X3DMetadataObject]
  MFString [in,out] family      "SERIF"
  SFBool   [in,out] horizontal  TRUE
  MFString [in,out] justify     "BEGIN" ["BEGIN"|"END"|"FIRST"|"MIDDLE"|""],["BEGIN"|"END"|"FIRST"|"MIDDLE"|""] 
  SFString [in,out] language    ""
  SFBool   [in,out] leftToRight TRUE
  SFFloat  [in,out] size        1.0     (0,∞)
  SFFloat  [in,out] spacing     1.0     [0,∞)
  SFString [in,out] style       "PLAIN" ["PLAIN"|"BOLD"|"ITALIC"|"BOLDITALIC"|""]
  SFBool   [in,out] topToBottom TRUE
}
----

The FontStyle node defines the _size_, _family_, and _style_ used for
<<Text>> nodes (see <<TextFormatting, 15.2.2 Text formatting>>), as well as the direction of the text strings and any
language-specific rendering techniques used for non-English text. See
<<Text>> for a description of the Text node.

The _size_ field specifies the nominal height, in the local coordinate
system of the Text node, of glyphs rendered and determines the spacing
of adjacent lines of text. Values of the _size_ field shall be greater
than zero.

The _spacing_ field determines the line spacing between adjacent lines
of text. The distance between the baseline of each line of text is (
__spacing __×  _size)_ in the appropriate direction (depending on other
fields described below). The effects of the _size_ and _spacing_ field
are depicted in <<f-Textsizeandspacingfields, Figure 15.2>> (
__spacing __greater than 1.0). Values of the _spacing_ field shall be
non-negative.

[[f-Textsizeandspacingfields]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/FontStylespacing.gif[Text size and spacing fields,width=431,height=103]

Figure 15.2 — Text _size_ and _spacing_ fields

[[Text]]
==== 15.4.2 Text

[source,node]
----
Text : X3DGeometryNode {
  SFNode   [in,out] fontStyle  NULL  [X3DFontStyleNode]
  MFFloat  [in,out] length     []    [0,∞)
  SFFloat  [in,out] maxExtent  0.0   [0,∞)
  SFNode   [in,out] metadata   NULL  [X3DMetadataObject]
  MFString [in,out] string     []
  MFVec2f  [out]    lineBounds
  SFVec3f  [out]    origin
  SFVec2f  [out]    textBounds
  SFBool   []       solid      FALSE
}
----

The Text node specifies a two-sided (by default), flat text string
object positioned in the Z=0 plane of the local coordinate system based
on values defined in the _fontStyle_ field (see <<FontStyle, 15.4.1 FontStyle>>). Text nodes may contain multiple text strings specified
using the UTF-8 encoding as specified by <<I10646, ISO 10646>>. The
text strings are stored in the order in which the text mode characters
are to be produced as defined by the parameters in the
<<FontStyle>> node.

The text strings are contained in the _string_ field. The _fontStyle_
field contains one FontStyle node that specifies the font size, font
family and style, direction of the text strings, and any specific
language rendering techniques used for the text. If no FontStyle node is
specified by the _fontStyle_ field, the default values of the FontStyle
node are used.

The _maxExtent_ field limits and compresses all of the text strings if
the length of the maximum string is longer than the maximum extent, as
measured in the local coordinate system. If the text string with the
maximum length is shorter than the _maxExtent_, then there is no
compressing. The maximum extent is measured horizontally for horizontal
text (FontStyle node: __horizontal__=TRUE) and vertically for vertical
text (FontStyle node: __horizontal__=FALSE). The _maxExtent_ field shall
be greater than or equal to zero.

The _length_ field contains an MFFloat value that specifies the length
of each text string in the local coordinate system. The length of each
line of type is measured horizontally for horizontal text (FontStyle
node: __horizontal__=`#TRUE`#) and vertically for vertical text
(FontStyle node: __horizontal__=`#FALSE`#). The _length_ and
_maxExtent_ fields thus refer to local coordinate units along the
dimension of type flow (major axis). If the string is too short, it is
stretched (either by scaling the text or by adding space between the
characters). If the string is too long, it is compressed (either by
scaling the text or by subtracting space between the characters). If a
length value is missing (for example, if there are four strings but only
three length values), the missing values are considered to be 0. The
_length_ field shall be greater than or equal to zero.

Specifying a value of 0 for both the _maxExtent_ and _length_ fields
indicates that the string may be any length.

When the default values of _length_ and _maxExtent_ are used, the Text
node shall generate events called _origin_, _lineBounds_ and
_textBounds_ to provide applications with spatial data regarding the
size and position of the rendered string(s) with the font being used.
These events are also generated when the default values of _length_ and
_maxExtent_ are used and the text is redrawn ( _e.g._, the string field
is changed programmatically or the FontStyle node is replaced).

The field _origin_ is a single 3D position that specifies the origin of
the text local coordinate system in units of the coordinate system in
which the Text node is embedded. The value of the _origin_ field
represents the upper left corner of the _textBounds_. The field
_lineBounds_ is a set of 2D vectors where each vector contains the size
of the 2D bounding box for each line of rendered text in local text x
and y units. The _textBounds_ event is a single 2D vector that contains
the size in x and y dimensions of the Text node’s 2D bounding box (all
strings) as rendered. An example for each value of the _topToBottom_ of
the FontStyle node is depicted in
<<f-LineBoundsAndTextBoundsMeasurements, Figure 15.3>>. Through the
_origin_ event, authors can locate relative measures of _lineBounds_ and
_textBounds_ regardless of the FontStyle's major or minor axis.

NOTE  In horizontal font styles, the x dimension of the _lineBounds_ and
_textBounds_ fields is equivalent to a specified _length_ or _maxExtent_
(the major axis). However, in vertical font styles, the x dimension of
the lineBounds and textBounds fields is along the minor axis.

[[f-LineBoundsAndTextBoundsMeasurements]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/textBounds.jpg[Text Bounds]

Figure 15.3 — lineBounds and textBounds measurements

<<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a
complete description of the _solid_ field.

[[SupportlLevels]]
=== 15.5 Support levels

The Text component provides 1 level of support as specified in
<<t15_8, Table 15.8>>.

[[t15_8]]
Table 15.8 — Text component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | |
| | |_X3DFontStyleNode_(abstract) |n/a
| | |FontStyle |All fields fully supported.
| | |Text |All fields fully supported.
|===

[[sound_html]]
== 16 Sound component

[[S16_Introduction]]
=== 16.1 Introduction

[[S16_Name]]
==== 16.1.1 Name

The name of this component is "Sound". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S16_Overview]]
==== 16.1.2 Overview

This clause describes the Sound component of this document. This
includes how sound is delivered to an X3D world as well as how sounds
are accessed. <<t16_1, Table 16.1>> provides links to the major
topics in this clause.

[[t16_1]]
Table 16.1 — Topics

* <<S16Introduction, 16.1 Introduction>>
** <<S16_Name, 16.1.1 Name>>
** <<S16_Overview, 16.1.2 Overview>>
* <<S16_Concepts, 16.2 Concepts>>
** <<Architecture, 16.2.1 Audio and sound spatial architecture>>
** <<Soundpriority, 16.2.2 Sound priority>>
** <<Soundattenandspatial, 16.2.3 Sound attenuation and spatialization>>
** <<SoundPropagation, 16.2.4 Sound propagation>>
** <<SoundEffectsProcessing, 16.2.5 Sound effects processing>>
** <<AudioEncodingFormats, 16.2.6 Audio encoding formats>>
* <<S16_AbstractTypes, 16.3 Abstract types>>
** <<X3DSoundChannelNode, 16.3.1 _X3DSoundChannelNode_>>
** <<X3DSoundDestinationNode, 16.3.2 _X3DSoundDestinationNode_>>
** <<X3DSoundNode, 16.3.3 _X3DSoundNode_>>
** <<X3DSoundProcessingNode, 16.3.4 _X3DSoundProcessingNode_>>
** <<X3DSoundSourceNode, 16.3.5 _X3DSoundSourceNode_>>
* <<S16_NodeReference, 16.4 Node reference>>
** <<Analyser, 16.4.1 Analyser>>
** <<AudioClip, 16.4.2 AudioClip>>
** <<AudioDestination, 16.4.3 AudioDestination>>
** <<BiquadFilter, 16.4.4 BiquadFilter>>
** <<BufferAudioSource, 16.4.5 BufferAudioSource>>
** <<ChannelMerger, 16.4.6 ChannelMerger>>
** <<ChannelSelector, 16.4.7 ChannelSelector>>
** <<ChannelSplitter, 16.4.8 ChannelSplitter>>
** <<Convolver, 16.4.9 Convolver>>
** <<Delay, 16.4.10 Delay>>
** <<DynamicsCompressor, 16.4.11 DynamicsCompressor>>
** <<Gain, 16.4.12 Gain>>
** <<ListenerPointSource, 16.4.13 ListenerPointSource>>
** <<MicrophoneSource, 16.4.14 MicrophoneSource>>
** <<OscillatorSource, 16.4.15 OscillatorSource>>
** <<PeriodicWave, 16.4.16 PeriodicWave>>
** <<Sound, 16.4.17 Sound>>
** <<SpatialSound, 16.4.18 SpatialSound>>
** <<StreamAudioDestination, 16.4.19 StreamAudioDestination>>
** <<StreamAudioSource, 16.4.20 StreamAudioSource>>
** <<WaveShaper, 16.4.21 WaveShaper>>
* <<S16_SupportLevels, 16.5 Support levels>>

* <<f-Stereopanning, Figure 16.1 — Stereo panning>>
* <<f-SoundPropagationPhenomena, Figure 16.2 — Sound propagation phenomena>>
* <<f-Soundnodegeometry, Figure 16.3 — Sound node geometry>>
* <<f-SpatialSoundPanningGainRelationships, Figure 16.4 — SpatialSound Panning Gain Relationships for viewer (or ListenerPointSource)>>

* <<t16_1, Table 16.1 — Topics>>
* <<t16_2, Table 16.2 — BiquadFilter type enumerations>>
* <<t16_3, Table 16.3— Sound component support levels>>




[[S16_Concepts]]
=== 16.2 Concepts

[[Architecture]]
==== 16.2.1 Audio and sound spatial architecture

The Sound component provides a rich set of spatialized audio
capabilities in a comprehensive architecture suitable for 3D models and
virtual environments.

[loweralpha]
. _Signal sources for sound_. In addition to playing inputs from
prerecorded sound files, capabilities are provided for computational
audio generation, microphones, and virtual listening points.
. _Virtual locations for sound generation_. The Sound and SpatialSound
nodes define location, direction, and characteristics of expected sound
production in virtual 3D space.
. _Propagation_. Attenuation characteristics may be further modified by
<<AcousticProperties>> in the Shape component
describing reflection, refraction and absorption that affect
sound-propagation interactions with surrounding geometry.
. _Reception points_. Avatar-centered listening points and recordable
listening points, each with arbitrary location and direction, can
receive acoustic results modified by corresponding with left-right pan
and spatialization.

[[Soundpriority]]
==== 16.2.2 Sound priority

If the X3D browser does not have the resources to play all of the
currently active sounds, it is recommended that the X3D browser sort the
active sounds into an ordered list using the following sort keys in the
order specified:

[loweralpha]
. decreasing _priority_;
. for sounds with _priority_ > 0.5, increasing (now- _startTime_);
. decreasing _intensity_ at viewer location ( __intensity__× "intensity
attenuation");

where __priority__is the _priority_ field of the Sound node, now
represents the current time, _startTime_ is the _startTime_ field of the
audio source node specified in the _source_ field, and "intensity
attenuation" refers to the intensity multiplier derived from the linear
decibel attenuation ramp between inner and outer ellipsoids.

It is important that sort key 2 be used for the high priority (event and
cue) sounds so that new cues are heard even when the X3D browser is
"full" of currently active high priority sounds. Sort key 2 should not
be used for normal priority sounds, so selection among them is based on
sort key 3 (intensity at the location of the viewer).

The X3D browser shall play as many sounds from the beginning of this
sorted list as it can given available resources and allowable latency
between rendering. On most systems, the resources available for MIDI
streams are different from those for playing sampled sounds, thus it may
be beneficial to maintain a separate list to handle MIDI data.

[[Soundattenandspatial]]
==== 16.2.3 Sound attenuation and spatialization

In order to create a linear decrease in loudness as the viewer moves
from the inner to the outer ellipsoid of the sound, the attenuation
shall be based on a linear decibel ramp. To make the falloff consistent
across X3D browsers, the decibel ramp is to vary from 0 dB at the
minimum ellipsoid to -20 dB at the outer ellipsoid. Sound nodes with an
outer ellipsoid that is ten times larger than the minimum will display
the inverse square intensity drop-off that approximates sound
attenuation in an anechoic environment.

Browsers may support spatial localization of sounds whose _spatialize_
field is `TRUE` as well as their underlying sound libraries will
allow. X3D browsers shall at least support stereo panning of non-MIDI
sounds based on the angle between the viewer and the source. This angle
is obtained by projecting the <<Sound>> _location_ (in global
space) onto the XZ plane of the viewer. Determine the angle between the
Z-axis and the vector from the viewer to the transformed _location_, and
assign a pan value in the range [0.0, 1.0] as depicted in
<<f-Stereopanning, Figure 16.1>>. Given this pan value, left and right
channel levels can be obtained using the following equations:

      leftPanFactor = 1 - pan^2^ +
    rightPanFactor = 1 - (1 - pan)^2^ +

[[f-Stereopanning]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Sound2.gif[Stereo
Panning,width=394,height=288]

Figure 16.1 — Stereo panning

Using this technique, the loudness of the sound is modified by the
_intensity_ field value, then distance attenuation to obtain the
unspatialized audio output. The values in the unspatialized audio output
are then scaled by leftPanFactor and rightPanFactor to determine the
final left and right output signals. The use of more sophisticated
localization techniques is encouraged, but not required.

These planar gain-reduction relationships pertain to the location and
relative direction of current avatar as well as any
<<ListenerPointSource>> nodes.

[[SoundPropagation]]
==== 16.2.4 Sound propagation

Sound-propagation techniques can be used to simulate sound waves as they
travel from each source to scene listening points by taking into account
the expected interactions with various objects in the scene. In other
words, spatial sound rendering includes the estimation of physical
effects involved in sound propagation such as surface reflection
(specular, diffusion) and wave phenomena (refraction, diffraction)
within a 3D scene. <<f-SoundPropagationPhenomena, Figure 16.2>>
provides an overview of the physical models of sound propagation that
are considered.

[[f-SoundPropagationPhenomena]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/SoundPropagationPhenomena.png[Sound propagation phenomena,scaledwidth=90.0%]

Figure 16.2 — Sound propagation phenomena

* _Specular and diffuse reflection_: during the propagation of a sound
wave in an enclosed space, the wave hits objects or room boundaries and
its free propagation is disturbed. Moreover, during this process, at
least a portion of the incident wave is thrown back, a phenomenon known
as reflection. If the wavelength of the sound wave is small enough with
respect to the dimensions of the reflecting object and large compared
with possible irregularities of the reflecting surface, a specular
reflection occurs. This phenomenon is illustrated in
<<f-SoundPropagationPhenomena, Figure 16.2>> (inset a), in which the
angle of reflection is equal to the angle of incidence. In contrast, if
the sound wavelength is comparable to the corrugation dimensions of an
irregular reflection surface, the incident sound wave is scattered in
many directions. In this case, the phenomenon is called diffuse
reflection and is illustrated in
<<f-SoundPropagationPhenomena, Figure 16.2>> (inset b).
* _Refraction_: it is the change in the propagation direction of waves
when they obliquely cross the boundary between two mediums where their
speed changes, as shown in <<f-SoundPropagationPhenomena, Figure 16.2>> (inset c). For transmission of a plane sound wave from air into
another medium, the refraction index in following equation (Snell’s Law)
is used, for calculating the geometric conditions. +
    `n = c'/c = sinθ'/sinθ` where c’ and c the sound speed in the
two media, θ the angle of incidence and θ’ the angle of refraction.
* _Diffraction_: the fact that a listener can hear sounds around corners
and around barriers involves a diffraction model of sound. It is the
spread of waves around corners, behind obstacles or around the edges of
an opening as illustrated in <<f-SoundPropagationPhenomena, Figure 16.2>> (inset d). The amount of diffraction increases with wavelength,
meaning that sound waves with lower frequencies, and thus with greater
wavelengths than obstacles or openings dimensions, is spread over larger
regions behind the openings or around the obstacles.

Diffraction sources are not explicitly represented in this component,
and often can be handled by computational engines. Complex geometric
openings may also be modeled by an audio chain including
<<ListenerPointSource>> and
<<SpatialSound>> to emulate sophisticated diffraction
propagation paths.

If a simplified geometry alternative from <<Collision>>
_proxy_ field is available, it is used preferentially by
collision-detection algorithms for sound propagation, rather than
descendant children of the <<Collision>> node. Such
geometric simplifications can often reduce computational costs
significantly without reduction in perceived audio fidelity of 3D scene
acoustics.

[[SoundEffectsProcessing]]
==== 16.2.5 Sound effects processing#

Sound streams can be manipulated by a variety of sound effects. Audio
graphs are a powerful mechanism for modeling the diversity of real-world
and electronic modifications to sound that can occur. Close integration
of sound rendering and effects with 3D models and aggregate scenes
provides powerful capabilities for increased realism.

Historically a wide variety of computational libraries for sound
generation and propagation have been available, often with significant
differences and limitations. Sound propagation and effects processing in
this component are based on design patterns found in W3C Web Audio API
<<W3C-WebAudio>>. Design goals of that specification
include supporting "the capabilities found in modern game audio engines
as well as some of the mixing, processing, and filtering tasks that are
found in modern desktop audio production applications." These
capabilities are broad, implemented in a variety of libraries, and
deployed in multiple Web X3D browsers. The primary interfaces of W3C Web
Audio API <<W3C-WebAudio>> necessary for creating
audio graphs have corresponding X3D node support in this component.

Descriptions follow for a number of fields that are common to multiple
nodes related to sound processing.

The _channelCount_ field is the number of channels used when up-mixing
and down-mixing connections to any inputs of a node. The default value
is typically 2 except for specific nodes where its value is specially
determined. This attribute has no effect for nodes with no inputs.

The _channelCountMode_ field is used to determine the
_computedNumberOfChannels_ that controls how inputs to a node are to be
mixed.

* `"MAX":` use _computedNumberOfChannels_ (value for
_channelCount_ is ignored)
* `"CLAMPED_MAX":` use _computedNumberOfChannels_ clamped to
maximum value given by _channelCount_
* `"EXPLICIT":` Up-mix by filling channels until they run out
then zero out remaining channels. Down-mix by filling as many channels
as possible, then dropping remaining channels.

The _channelInterpretation_ field determines how individual channels are
treated when up-mixing and down-mixing connections to any inputs to the
node. The default value is "speakers". This attribute has no effect for
nodes with no inputs. Allowed values include the following:

* `"SPEAKERS":` use up-mix equations or down-mix equations. In
cases where the number of channels do not match any of these basic
speaker layouts, revert to `"discrete"`.
* `"DISCRETE":` _computedNumberOfChannels_ is the exact value as
specified by the _channelCount_.

The _gain_ field is a factor that represents the amount of linear
amplification to apply to the output of the node. Decibel values shall
not be used. Negative gain factors negate the input signal.

[[AudioEncodingFormats]]
==== 16.2.6 Audio encoding formats

X3D browsers shall support at least the _wavefile_ format in
uncompressed PCM format (see <<WAV>>).

It is recommended that X3D browsers support the MIDI file type 1 sound
format (see <<MIDI-1, MIDI 1.0>>). MIDI files are presumed to use
the General MIDI patch set. +
X3D browser support is also recommended for MIDI 2.0 (see
<<MIDI-2, MIDI 2.0>> and Web MIDI API (see
<<W3C-WebMIDI>>).

It is also recommended that X3D browsers support the following formats:

* Format=MP3, container=MP3, compressed (see
<<I11172_1, I11172-1>>).
* Format=AAC, container=MP4 (see <<I14496_14, 14496-14>>).


=== 16.3 Abstract types

[[X3DSoundChannelNode]]
==== 16.3.1 _X3DSoundChannelNode_

[source,node]
----
X3DSoundChannelNode : X3DSoundNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFInt32  [out]    channelCount                     [0,∞)
}
----

This is the base node type for nodes that handle of channels in an audio
stream, allowing them to be split or merged.

The _children_ field is a set of input nodes, with the current node
continuing creation of the audio graph.

The _gain_ field is a factor that represents the amount of linear
amplification to apply. Decibel values shall not be used. Negative gain
factors negate the input signal.

The _description, enabled, pauseTime, resumeTime, startTime_, and
_stopTime_ inputOutput fields and the _elapsedTime, isActive_, and
_isPaused_ outputOnly fields, and their effects on nodes implementing
this abstract node type, are discussed in detail in
<<X3DTimeDependentNode>> and
<<Time-dependent, 8.2.4 Time-dependent nodes>>.

If _enabled_ field is FALSE, the audio signal passes through unmodified
and is not blocked.

[[X3DSoundDestinationNode]]
==== 16.3.2 _X3DSoundDestinationNode_

[source,node]
----
X3DSoundDestinationNode : X3DSoundNode {
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFString [in,out] mediaDeviceID         ""
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFBool   [out]    isActive
  SFInt32  [out]    channelCount                     [0,∞)
}
----

This is the base node type for all sound destination nodes, which
represent the final destination of an audio signal and are what the user
can ultimately hear. Such nodes are often considered as audio output
devices which are connected to speakers. All rendered audio that is
intended to be heard gets routed to these terminal nodes.

The _children_ field is a set of input nodes, with the current node
continuing creation of the audio graph.

The _gain_ field is a factor that represents the amount of linear
amplification to apply. Decibel values shall not be used. Negative gain
factors negate the input signal.

The _mediaDeviceID_ field corresponds to the ID parameter functionality
defined in W3C Web Audio API <<W3C-WebAudio>>.

The _description_, _enabled_, _pauseTime_, _resumeTime_, _startTime_,
and _stopTime_ inputOutput fields and the _elapsedTime_, _isActive_, and
_isPaused_ outputOnly fields, and their effects on nodes implementing
this abstract node type, are discussed in detail in
<<X3DTimeDependentNode>> and
<<Time-dependent, 8.2.4 Time-dependent nodes>>.

If _enabled_ field is FALSE, the audio signal is blocked and does not
pass through.

[[X3DSoundNode]]
==== 16.3.3 _X3DSoundNode_#

[source,node]
----
X3DSoundNode : X3DChildNode {
  SFString [in,out] description   ""
  SFBool   [in,out] enabled       TRUE
  SFNode   [in,out] metadata      NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all sound nodes.

The _description_ field specifies a textual description for the node.

The _enabled_ field determines whether or not node functionality occurs.

[[X3DSoundProcessingNode]]
==== 16.3.4 _X3DSoundProcessingNode_#

[source,node]
----
X3DSoundProcessingNode : X3DTimeDependentNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          "" (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFTime   [in,out] tailTime              0          [0,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

This is the base node type for all sound processing nodes, which are
used to enhance audio with filtering, delaying, changing gain, etc.

The _children_ field is a set of input nodes, with the current node
continuing creation of the audio graph.

The _gain_ field is a factor that represents the amount of linear
amplification to apply. Decibel values shall not be used. Negative gain
factors negate the input signal.

The _description_, _enabled_, _pauseTime_, _resumeTime_, _startTime_,
and _stopTime_ inputOutput fields and the _elapsedTime_, _isActive_, and
_isPaused_ outputOnly fields, and their effects on nodes implementing
this abstract node type, are discussed in detail in
<<X3DTimeDependentNode>> and
<<Time-dependent, 8.2.4 Time-dependent nodes>>.

The _tailTime_ field is duration of time that a node continues to
provide output signal after the input signal becomes silent.

If _enabled_ field is FALSE, the audio signal passes through unmodified
and is not blocked.

[[X3DSoundSourceNode]]
==== 16.3.5 _X3DSoundSourceNode_#

[source,node]
----
X3DSoundSourceNode : X3DTimeDependentNode {
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFFloat  [in,out] gain             1    (-∞,∞)
  SFNode   [in,out] metadata         NULL [X3DMetadataObject]
  SFTime   [in,out] pauseTime        0    (-∞,∞)
  SFTime   [in,out] resumeTime       0    (-∞,∞)
  SFTime   [in,out] startTime        0    (-∞,∞)
  SFTime   [in,out] stopTime         0    (-∞,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

This abstract node type is used to derive node types that can emit audio
data.

The _gain_ field is a factor that represents the amount of linear
amplification to apply. Decibel values shall not be used. Negative gain
factors negate the input signal.

The _description_, _pauseTime_, _resumeTime_, _startTime_, and
_stopTime_ inputOutput fields and the _elapsedTime_, _isActive_, and
_isPaused_ outputOnly fields, and their effects on nodes implementing
this abstract node type, are discussed in detail in
<<X3DTimeDependentNode>> and
<<Time-dependent, 8.2.4 Time-dependent nodes>>.

The _isActive_ field may be used by other nodes to determine if the node
is currently active.


=== 16.4 Node reference

[[Analyser]]
==== 16.4.1 Analyser

[source,node]
----
Analyser :  X3DSoundProcessingNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFInt32  [in,out] fftSize               2048       [0,∞)
  SFInt32  [in,out] frequencyBinCount     1024       [0,∞)
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFFloat  [in,out] minDecibels           -100       (-∞,∞)
  SFFloat  [in,out] maxDecibels           -30        (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFFloat  [in,out] smoothingTimeConstant 0.8        [0,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFTime   [in,out] tailTime              0          [0,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

The Analyser node provides real-time frequency and time-domain analysis
information, without any change to the input other than _gain_
amplification.

The _fftSize_ field is an unsigned long value representing the size of
the FFT (https://en.wikipedia.org/wiki/Fast_Fourier_transform[Fast
Fourier Transform]) to be used to determine the frequency domain.

The _frequencyBinCount_ field is an unsigned long value half that of the
FFT size. This generally equates to the number of data values you will
have to play with for the visualization.

The _minDecibels_ field is a value representing the minimum power value
in the scaling range for the FFT analysis data, for conversion to
unsigned byte values.

The _maxDecibels_ field is a value representing the maximum power value
in the scaling range for the FFT analysis data, for conversion to
unsigned byte values.

The _smoothingTimeConstant_ field is a value representing the averaging
constant with the last analysis frame.

The _tailTime_ field always has a value of zero.

Fields derived from X3DSoundProcessingNode ( _gain_, _pauseTime_,
_resumeTime_, _startTime_, _stopTime_, _elapsedTime_, _isActive_ and
_isPaused_) only affect the analysis capabilities of the node, and do
not modify transfer of input signals to output.

[[AudioClip]]
==== 16.4.2 AudioClip

[source,node]
----
AudioClip : X3DSoundSourceNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0   [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0   [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] enabled              TRUE
  SFFloat  [in,out] gain                 1     (-∞,∞)
  SFBool   [in,out] load                 TRUE
  SFBool   [in,out] loop                 FALSE
  SFNode   [in,out] metadata             NULL  [X3DMetadataObject]
  SFTime   [in,out] pauseTime            0     (-∞,∞)
  SFFloat  [in,out] pitch                1.0   (0,∞)
  SFTime   [in,out] resumeTime           0     (-∞,∞)
  SFTime   [in,out] startTime            0     (-∞,∞)
  SFTime   [in,out] stopTime             0     (-∞,∞)
  MFString [in,out] url                  []    [URI]
  SFTime   [out]    duration_changed
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

An AudioClip node specifies audio data that can be referenced by
<<Sound>> nodes.

The _description_ field specifies a textual description of the audio
source. A X3D browser is not required to display the _description_ field
but may choose to do so in addition to playing the sound.

The "cycle" of an AudioClip is the length of time in seconds for one
playing of the audio file at the specified _pitch_.

The _pitch_ field specifies a multiplier for the rate at which sampled
sound is played. Values for the _pitch_ field shall be greater than
zero. Changing the _pitch_ field affects both the pitch and playback
speed of a sound. A _set_pitch_ event to an active AudioClip is ignored
and no _pitch_changed_ field is generated. If _pitch_ is set to 2.0, the
sound shall be played one octave higher than normal and played twice as
fast. For a sampled sound, the _pitch_ field alters the sampling rate at
which the sound is played. The proper implementation of pitch control
for MIDI (or other note sequence sound clips) is to multiply the tempo
of the playback by the _pitch_ value and adjust the MIDI Coarse Tune and
Fine Tune controls to achieve the proper pitch change.

A _duration_changed_ event is sent whenever there is a new value for the
"normal" duration of the clip. Typically, this will only occur when the
current _url_ in use changes and the sound data has been loaded,
indicating that the clip is playing a different sound source. The
duration is the length of time in seconds for one cycle of the audio for
a _pitch_ set to 1.0. Changing the _pitch_ field will not trigger a
_duration_changed_ event. A duration value of "−1" implies that the
sound data has not yet loaded or the value is unavailable for some
reason. A _duration_changed_ event shall be generated if the AudioClip
node is loaded when the X3D file is read or the AudioClip node is added
to the scene graph.

The " _cycle"_ of an AudioClip is the length of time in seconds for one
playing of the audio at the specified _pitch_.

The _isActive_ field may be used by other nodes to determine if the clip
is currently active. If an AudioClip is active, it shall be playing the
sound corresponding to the sound time ( _i.e._, in the sound's local
time system with sample 0 at time 0):

[source,listing]
----
    t = (now − startTime) modulo (duration / pitch)
----

The _url_ field specifies the URL from which the sound file is loaded.
<<AudioEncodingFormats, 16.2.6 Audio encoding formats>> describes
required and recommended file format support. <<URLs, 9.2.1 URLs, URNs and URIs>> contains details on the _url_ field.

[[AudioDestination]]
==== 16.4.3 AudioDestination

[source,node]
----
AudioDestination : X3DSoundDestinationNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFInt32  [in,out] maxChannelCount       2          [0,∞)
  SFString [in,out] mediaDeviceID         ""
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFBool   [out]    isActive
  SFInt32  [out]    channelCount                     [0,∞)
}
----

AudioDestination represents the final audio destination and is what user
ultimately hears, typically from the speakers of user device. An
AudioDestinationNode representing the audio hardware end-point (the
normal case) can potentially output more than 2 channels of audio if the
audio hardware is multi-channel.

The _maxChannelCount_ field is the maximum number of channels that the
destination is capable of supporting.

[[BiquadFilter]]
==== 16.4.4 BiquadFilter

[source,node]
----
BiquadFilter : X3DSoundProcessingNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFFloat  [in,out] detune                0          [0,∞)
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] frequency             350        [0,∞)
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFFloat  [in,out] qualityFactor         1          [0,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFTime   [in,out] tailTime              0          [0,∞)
  SFString [in,out] type                  "LOWPASS"  ["LOWPASS",   "HIGHPASS", "BANDPASS", "LOWSHELF", 
                                                      "HIGHSHELF", "PEAKING",  "NOTCH",    "ALLPASS"]  
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

BiquadFilter represents different kinds of filters, tone control
devices, and graphic equalizers. Low-order filters are the building
blocks of basic tone controls (bass, mid, treble), graphic equalizers,
and more advanced filters. Multiple BiquadFilterNode filters can be
combined to form more complex filters. The filter parameters such as
frequency can be changed over time for filter sweeps, etc.

The _detune_ field is a detune value, in cents, for the frequency.

The _frequency_ field is the frequency at which the BiquadFilterNode
will operate, in Hz.

The _gain_ field is the amplitude gain of the filter. Its value is in dB
units. The _gain_ value is only used for lowshelf, highshelf, and
peaking filters.

The _qualityFactor_ field is Quality Factor (Q) of the filter.

The _type_ field is the type of this BiquadFilterNode. Note that the
meaning of the different properties ( _frequency_, _detune_ and
_qualityFactor_) differs depending on the type of the filter used.
Descriptions for supported _type_ values are specified in
<<t16_2, Table 16.2>>.

[[t16_2]]
Table 16.2 — BiquadFilter type
enumerations

[width="100%",cols="50%,50%",options="header",]
|===
|Enumeration |Description
|`"LOWPASS" ` a|
A https://en.wikipedia.org/wiki/Low-pass_filter[lowpass filter] allows
frequencies below the cutoff frequency to pass through and attenuates
frequencies above the cutoff. It implements a standard second-order
resonant lowpass filter with 12dB/octave rolloff.

frequency::
  The cutoff frequency
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Controls how peaked the response will be at the cutoff frequency. A
  large value makes the response more peaked.
gain::
  Not used in this filter type

|`"HIGHPASS" ` a|
A https://en.wikipedia.org/wiki/High-pass_filter[highpass filter] is the
opposite of a lowpass filter. Frequencies above the cutoff frequency are
passed through, but frequencies below the cutoff are attenuated. It
implements a standard second-order resonant highpass filter with
12dB/octave rolloff.

frequency::
  The cutoff frequency below which the frequencies are attenuated
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Controls how peaked the response will be at the cutoff frequency. A
  large value makes the response more peaked.
gain::
  Not used in this filter type

|`"BANDPASS" ` a|
A https://en.wikipedia.org/wiki/Band-pass_filter[bandpass filter] allows
a range of frequencies to pass through and attenuates the frequencies
below and above this frequency range. It implements a second-order
bandpass filter.

frequency::
  The center of the frequency band
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Controls the width of the band. The width becomes narrower as the Q
  value increases.
gain::
  Not used in this filter type

|`"LOWSHELF" ` a|
The lowshelf filter allows all frequencies through, but adds a boost (or
attenuation) to the lower frequencies. It implements a second-order
lowshelf filter.

frequency::
  The upper limit of the frequences where the boost (or attenuation) is
  applied.
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Not used in this filter type.
gain::
  The boost, in dB, to be applied. If the value is negative, the
  frequencies are attenuated.

|`"HIGHSHELF" ` a|
The highshelf filter is the opposite of the lowshelf filter and allows
all frequencies through, but adds a boost to the higher frequencies. It
implements a second-order highshelf filter

frequency::
  The lower limit of the frequences where the boost (or attenuation) is
  applied.
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Not used in this filter type.
gain::
  The boost, in dB, to be applied. If the value is negative, the
  frequencies are attenuated.

|`"PEAKING" ` a|
The peaking filter allows all frequencies through, but adds a boost (or
attenuation) to a range of frequencies.

frequency::
  The center frequency of where the boost is applied.
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Controls the width of the band of frequencies that are boosted. A
  large value implies a narrow width.
gain::
  The boost, in dB, to be applied. If the value is negative, the
  frequencies are attenuated.

|`"NOTCH" ` a|
The notch filter (also known as a
https://en.wikipedia.org/wiki/Band-stop_filter[band-stop or
band-rejection filter]) is the opposite of a bandpass filter. It allows
all frequencies through, except for a set of frequencies.

frequency::
  The center frequency of where the notch is applied.
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Controls the width of the band of frequencies that are attenuated. A
  large value implies a narrow width.
gain::
  Not used in this filter type.

|`"ALLPASS" ` a|
An
https://en.wikipedia.org/wiki/All-pass_filter#Digital_Implementation[allpass
filter] allows all frequencies through, but changes the phase
relationship between the various frequencies. It implements a
second-order allpass filter

frequency::
  The frequency where the center of the phase transition occurs. Viewed
  another way, this is the frequency with maximal
  https://en.wikipedia.org/wiki/Group_delay[group delay].
qualityFactor https://en.wikipedia.org/wiki/Q_factor[Q]::
  Controls how sharp the phase transition is at the center frequency. A
  larger value implies a sharper transition and a larger group delay.
gain::
  Not used in this filter type.

|===

[[BufferAudioSource]]
==== 16.4.5 BufferAudioSource

[source,node]
----
BufferAudioSource : X3DSoundSourceNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh           0.0        [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit  3600.0     [0,∞)
  MFFloat  [in,out] buffer                []         [−1,1]
  SFTime   [in,out] bufferDuration        0          [0,∞)
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  SFString [in,out] description           ""  
  SFFloat  [in,out] detune                0          [0,∞)
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFBool   [in,out] load                  TRUE  
  SFBool   [in,out] loop                  FALSE  
  SFTime   [in,out] loopEnd               0          [0,∞)
  SFTime   [in,out] loopStart             0          [0,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFInt32  [in,out] numberOfChannels      0          [0,∞)
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFFloat  [in,out] playbackRate          1          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFFloat  [in,out] sampleRate            0          [0,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  MFString [in,out] url                   []         [URI]
  SFInt32  [out]    bufferLength          0          [0,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

The BufferAudioSource node represents a memory-resident audio asset that
can contain one or more channels. Typically the length of the Pulse-Code
Modulation (PCM) data is expected to be fairly short (usually somewhat
less than a minute). For longer sounds, such as music soundtracks,
streaming such as <<StreamAudioSource>> should be
used.

The _buffer_ field is a data block holding the audio sample data. The
_buffer_ data format is non-interleaved 32-bit floating-point linear PCM
values with a normal range of [−1,1], but values are not limited to this
range.

The _bufferDuration_ field is duration in seconds of the PCM audio
_buffer_ data, computed from the _bufferLength_ field divided by
_sampleRate_ field.

The _bufferLength_ field is the length of the PCM audio data in sample
frames.

The _detune_ field forms a compound field together with _playbackRate_
that together determine a computedPlaybackRate value.

[source]
....
    computedPlaybackRate(t) =  playbackRate(t) * pow(2, detune(t) / 1200)
....

The _loop_ field determines whether processing is repeated when _buffer_
playback is complete.

The _loopStart_ field is optional playhead position where looping begins
if _loop_ attribute is `TRUE`. If _loopStart_ is greater than the
duration of the buffer, looping will begin at the end of the buffer.

The _loopEnd_ field is optional playhead position where looping ends if
_loop_ attribute is `TRUE`. If _loopEnd_ value is zero, or if
_loopEnd_ is greater than the duration of the buffer, looping will end
at the end of the buffer.

The _numberOfChannels_ field is the discrete number of audio channels
for this buffer.

The _playbackRate_ field is the speed at which to render the audio
stream, and is a compound parameter with _detune_.

The _sampleRate_ field is the sample-rate used for the PCM audio data in
samples per second.

The _url_ field specifies the URL from which the sound file is loaded.
<<AudioEncodingFormats, 16.2.6 Audio encoding formats>> describes
required and recommended file format support. <<URLs, 9.2.1 URLs, URNs and URIs>> contains details on the _url_ field.

[[ChannelMerger]]
==== 16.4.6 ChannelMerger

[source,node]
----
ChannelMerger : X3DSoundChannelNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFInt32  [out]    channelCount                     [0,∞)
}
----

ChannelMerger unites different input channels into a single output
channel.

[[ChannelSelector]]
==== 16.4.7 ChannelSelector

[source,node]
----
ChannelSelector : X3DSoundChannelNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  SFInt32  [in,out] channelSelection      0          [0,∞)
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFInt32  [out]    channelCount                     [0,∞)
}
----

ChannelSelector selects a single channel output from all input channels.
If the selected channel is not monophonic, further splitting remains
feasible.

The _channelSelection_ field indicates which channel to select, with
index values beginning at 0.

[[ChannelSplitter]]
==== 16.4.8 ChannelSplitter

[source,node]
----
ChannelSplitter : X3DSoundChannelNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  SFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  MFNode   [in,out] outputs               NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFInt32  [out]    channelCount                     [0,∞)
}
----

ChannelSplitter separates the different channels of a single audio
source into a set of monophonic output channels.

The _outputs_ field is a set of output nodes receiving the split
channels, and making up a section of the audio graph.

[[Convolver]]
==== 16.4.9 Convolver

[source,node]
----
Convolver : X3DSoundProcessingNode {
  MFFloat  [in,out] buffer                []         [−1,1]
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFBool   [in,out] normalize             FALSE
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFTime   [in,out] tailTime              0          [0,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

Convolver performs a linear convolution on a given AudioBuffer, often
used to achieve a reverberation effect. Potential modifications include
chorus effects, reverberation, and telephone-like speech. The idea for
producing room effects is to play back a reference sound in a room,
record it, and then (metaphorically) take the difference between the
original sound and the recorded one. The result of this is an impulse
response that captures the effect that the room has on a sound.

The _buffer_ field represents a memory-resident audio asset (for
one-shot sounds and other short audio clips). Its format is
non-interleaved 32-bit linear floating-point PCM values with a normal
range of [−1,1], but values are not limited to this range. It can
contain one or more channels. Typically, it would be expected that the
length of the PCM data would be fairly short (usually somewhat less than
a minute). For longer sounds, such as music soundtracks, streaming
should be used with the `<audio>` HTML element and AudioClip.

The _normalize_ field is a boolean that controls whether or not the
impulse response from the buffer is scaled by an equal-power
normalization when the buffer field is set.

[[Delay]]
==== 16.4.10 Delay

[source,node]
----
Delay : X3DSoundProcessingNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFTime   [in,out] delayTime             0          [0,∞)
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFTime   [in,out] maxDelayTime          1          [0,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

Delay causes a time delay between the arrival of input data and
subsequent propagation to the output.

The _delayTime_ field represents the amount of delay (in seconds) to
apply.

The _maxDelayTime_ field represents the maximum amount of delay (in
seconds) that can be applied.

NOTE. Extremely long time delays may pose security considerations.

[[DynamicsCompressor]]
==== 16.4.11 DynamicsCompressor

[source,node]
----
DynamicsCompressor : X3DSoundProcessingNode {
  SFTime   [in,out] attack         0.003      [0,∞)
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFFloat  [in,out] knee                  30         [0,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFFloat  [in,out] ratio                 12         [0,∞)
  SFTime   [in,out] release               0.25       [0,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFTime   [in,out] tailTime              0          [0,∞)
  SFFloat  [in,out] threshold             -24        [0,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
  SFFloat  [out]    reduction                        [0,∞)
}
----

DynamicsCompressor implements a dynamics compression effect, lowering
the volume of the loudest parts of the signal and raising the volume of
the softest parts.

The _attack_ field is the amount of time (in seconds) to reduce the gain
by 10dB.

The _knee_ field contains a decibel value representing the range above
the threshold where the curve smoothly transitions to the compressed
portion.

The _ratio_ field represents the amount of change, in dB, needed in the
input for a 1 dB change in the output.

The _reduction_ field represents the amount of gain reduction in dB
currently applied by the compressor to the output signal. If fed no
signal, then the output value is 0 (no gain reduction).

The _release_ field represents the amount of time (in seconds) to
increase the gain by 10dB.

The _threshold_ field represents the decibel value above which the
compression starts taking effect.

[[Gain]]
==== 16.4.12 Gain

[source,node]
----
Gain : X3DSoundProcessingNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFTime   [in,out] tailTime              0          [0,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

The Gain node amplifies or deamplifies the input signal.

The _gain_ field is a factor that represents the amount of linear
amplification to apply. Decibel values shall not be used. Negative gain
factors negate the input signal.

The _tailTime_ field always has a value of zero.

NOTE. A Gain node is similar to a Delay node with no time delay.

[[ListenerPointSource]]
==== 16.4.13 ListenerPointSource

[source,node]
----
ListenerPointSource : X3DSoundSourceNode {
  SFString   [in,out] description        ""
  SFBool     [in,out] dopplerEnabled     FALSE
  SFBool     [in,out] enabled            TRUE
  SFInt32    [in,out] gain               1       (-∞,∞)
  SFFloat    [in,out] interauralDistance 0       [0, infinity)
  SFNode     [in,out] metadata           NULL    [X3DMetadataObject]
  SFRotation [in,out] orientation        0 0 1 0 [-1,1],(-∞,∞)
  SFVec3f    [in,out] position           0 0 0   (-∞,∞)
  SFTime     [in,out] pauseTime          0       (-∞,∞)
  SFTime     [in,out] resumeTime         0       (-∞,∞)
  SFTime     [in,out] startTime          0       (-∞,∞)
  SFTime     [in,out] stopTime           0       (-∞,∞)
  SFBool     [in,out] trackCurrentView   FALSE
  SFTime     [out]    elapsedTime
  SFBool     [out]    isActive
  SFBool     [out]    isPaused
}
----

ListenerPointSource represents the position and orientation of a person
listening to virtual sound in the audio scene, and provides single or
multiple sound channels as output. Multiple ListenerPointSource nodes
can be active for sound processing.

If the _dopplerEnabled_ field is TRUE then sound sources which are
moving spatially in the transformation hierarchy, relative to the
location of the ListenerPointSource node, shall be modified by applying
velocity-induced frequency shifts corresponding to Doppler effect.

The _interauralDistance_ field can be used to support binaural recording
or precision sound-reproduction headgear.

If the _trackCurrentView_ field is `TRUE` then _position_ and
_orientation_ matches the user's current view.

Security consideration: an Inline scene or external prototype might
include a ListenerPointSource with _trackCurrentView_ `TRUE` that
can eavesdrop on the virtual sound heard by the user, capturing the
audio stream and then saving or streaming it surreptitiously.

[[MicrophoneSource]]
==== 16.4.14 MicrophoneSource

[source,node]
----
MicrophoneSource : X3DSoundSourceNode {
  SFString [in,out] description    ""
  SFBool   [in,out] enabled        TRUE
  SFFloat  [in,out] gain           1    (-∞,∞)
  SFString [in,out] mediaDeviceID  ""
  SFNode   [in,out] metadata       NULL [X3DMetadataObject]
  SFTime   [in,out] pauseTime      0    (-∞,∞)
  SFTime   [in,out] resumeTime     0    (-∞,∞)
  SFTime   [in,out] startTime      0    (-∞,∞)
  SFTime   [in,out] stopTime       0    (-∞,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

MicrophoneSource captures input from a physical microphone in the real
world.

The _mediaDeviceID_ field is a unique identifier for the active device.

Security consideration: enabling a MicrophoneSource node has privacy and
permission prerequisites.

[[OscillatorSource]]
==== 16.4.15 OscillatorSource

[source,node]
----
Oscillator : X3DSoundSourceNode {
  SFString [in,out] description      ""
  SFFloat  [in,out] detune           0      [0,∞)
  SFBool   [in,out] enabled          TRUE
  SFFloat  [in,out] frequency        440.0  [0,∞)
  SFFloat  [in,out] gain             1      (-∞,∞)
  SFNode   [in,out] metadata         NULL   [X3DMetadataObject]
  SFTime   [in,out] pauseTime        0      (-∞,∞)
  SFNode   [in,out] periodicWave     NULL   [PeriodicWave]
  SFTime   [in,out] resumeTime       0      (-∞,∞)
  SFTime   [in,out] startTime        0      (-∞,∞)
  SFTime   [in,out] stopTime         0      (-∞,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

The OscillatorSource node represents a virtual audio source generating a
periodic waveform, providing a constant tone.

The _detune_ field is an a-rate AudioParam representing detuning of
oscillation in cents (though the AudioParam returned is read-only, the
value it represents is not).

The _frequency_ field represents oscillation in hertz. The default value
440 Hz is a standard middle-A note.

The _periodicWave_ field can hold an optional PeriodicWave node
providing a regular or arbitrary periodic waveform.

[[PeriodicWave]]
==== 16.4.16 PeriodicWave

[source,node]
----
PeriodicWave : X3DSoundNode {
  SFString [in,out] description ""
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL     [X3DMetadataObject]
  MFFloat  [in,out] optionsReal []
  MFFloat  [in,out] optionsImag []
  SFString [in,out] type        "SQUARE" ["SINE", "SQUARE", "SAWTOOTH", "TRIANGLE", "CUSTOM"] 
}
----

PeriodicWave defines a periodic waveform that can be used to shape the
output of an Oscillator.

The _optionsReal_ and _optionsImag_ fields define waveform coefficients
and correspond to functionality defined in W3C Web Audio API
<<W3C-WebAudio>>.

The _type_ field is a string which specifies the shape of waveform to
play; this can be one of a number of standard values, or custom to use a
PeriodicWave to describe a custom waveform. Different types of waves
produce different sounds. Standard values are "SQUARE" "SINE", "SQUARE",
"SAWTOOTH", "TRIANGLE", "CUSTOM". Allowed values are defined as follows:

* `"SINE"`: a sine wave
* `"SQUARE"`: a square wave of duty period 0.5
* `"SAWTOOTH"`: a sawtooth wave
* `"TRIANGLE"`: a triangle wave
* `"CUSTOM"`: a custom periodic wave

[[Sound]]
==== 16.4.17 Sound

[source,node]
----
Sound : X3DSoundNode {
  MFNode   [in,out] children   NULL  [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description       ""
  SFVec3f  [in,out] direction  0 0 1 (-∞,∞)
  SFBool   [in,out] enabled    TRUE
  SFFloat  [in,out] intensity  1     [0,1]
  SFVec3f  [in,out] location   0 0 0 (-∞,∞)
  SFFloat  [in,out] maxBack    10    [0,∞)
  SFFloat  [in,out] maxFront   10    [0,∞)
  SFNode   [in,out] metadata   NULL  [X3DMetadataObject]
  SFFloat  [in,out] minBack    1     [0,∞)
  SFFloat  [in,out] minFront   1     [0,∞)
  SFFloat  [in,out] priority   0     [0,1]
  SFNode   [in,out] source     NULL  [X3DSoundSourceNode] 
  SFBool   []       spatialize TRUE
}
----

The Sound node specifies the spatial presentation of a sound in a X3D
scene. The sound is located at a point in the local coordinate system
and emits sound in an elliptical pattern (defined by two ellipsoids).
The ellipsoids are oriented in a direction specified by the _direction_
field. The shape of the ellipsoids may be modified to provide more or
less directional focus from the location of the sound.

The _source_ field specifies the sound source for the Sound node. If the
_source_ field is not specified, the Sound node will not emit audio. The
_source_ field shall specify either an <<AudioClip>> node
or a <<MovieTexture>> node. If a MovieTexture node is
specified as the sound source, the MovieTexture shall refer to a movie
format that supports sound (EXAMPLE  MPEG-1Systems, see
<<I11172_1, ISO/IEC 11172-1>>).

The _children_ field specifies additional audio-graph sound sources for
this node. If multiple input signals are provided by the _source_ and
_children_ fields, all channels are mixed together and merged prior to
node operation.

The __intensity__field adjusts the loudness (decibels) of the sound
emitted by the Sound node.  The _intensity_ field has a value that
ranges from 0.0 to 1.0 and specifies a factor which shall be used to
scale the normalized sample data of the sound source during playback. A
Sound node with an intensity of 1.0 shall emit audio at its maximum
loudness (before attenuation), and a Sound node with an intensity of 0.0
shall emit no audio. Between these values, the loudness should increase
linearly from a -20 dB change approaching an _intensity_ of 0.0 to a 0
dB change at an _intensity_ of 1.0.

NOTE   This is different from the traditional definition of intensity
with respect to sound; see <<COMPMUSIC>>.

The _priority_ field provides a hint for the X3D browser to choose which
sounds to play when there are more active Sound nodes than can be played
at once due to either limited system resources or system load.
<<S16_Concepts, 16.2 Concepts>> describes a recommended algorithm for
determining which sounds to play under such circumstances. The
_priority_ field ranges from 0.0 to 1.0, with 1.0 being the highest
priority and 0.0 the lowest priority.

The _location_ field determines the location of the sound emitter in the
local coordinate system. A Sound node's output is audible only if it is
part of the traversed scene. Sound nodes that are descended from
<<LOD>>, <<Switch>>, or any grouping or prototype node
that disables traversal ( _i.e._, __ __drawing) of its children are not
audible unless they are traversed. If a Sound node is disabled by a
Switch or LOD node, and later it becomes part of the traversal again,
the sound shall resume where it would have been had it been playing
continuously.

The Sound node has an inner ellipsoid that defines a volume of space in
which the maximum level of the sound is audible. Within this ellipsoid,
the normalized sample data is scaled by the _intensity_ field and there
is no attenuation. The inner ellipsoid is defined by extending the
_direction_ vector through the _location_. The _minBack_ and _minFront_
fields specify distances behind and in front of the _location_ along the
_direction_ vector respectively. The inner ellipsoid has one of its foci
at _location_ (the second focus is implicit) and intersects the
_direction_ vector at _minBack_ and _minFront_.

The Sound node has an outer ellipsoid that defines a volume of space
that bounds the audibility of the sound. No sound can be heard outside
of this outer ellipsoid. The outer ellipsoid is defined by extending the
_direction_ vector through the _location_. The _maxBack_ and
__maxFront__fields specify distances behind and in front of the
_location_ along the _direction_ vector respectively. The outer
ellipsoid has one of its foci at _location_ (the second focus is
implicit) and intersects the _direction_ vector at _maxBack_ and
_maxFront_.

The _minFront_, _maxFront_, _minBack_, and _maxBack_ fields are defined
in local coordinates, and shall be greater than or equal to zero. The
_minBack_ field shall be less than or equal to  _maxBack_, and
_minFront_ shall be less than or equal to  _maxFront_. The ellipsoid
parameters are specified in the local coordinate system but the
ellipsoids' geometry is affected by ancestors' transformations.

Between the two ellipsoids, there shall be a linear attenuation ramp in
loudness, from 0 dB at the minimum ellipsoid to -20 dB at the maximum
ellipsoid:

[source,listing]
----
    attenuation = -20 × (d' / d")
----

where d' is the distance along the location-to-viewer vector, measured
from the transformed minimum ellipsoid boundary to the viewer, and d" is
the distance along the location-to-viewer vector from the transformed
minimum ellipsoid boundary to the transformed maximum ellipsoid boundary
(see <<f-Soundnodegeometry, Figure 16.3>>).

[[f-Soundnodegeometry]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Sound.gif[Sound node
geometry,width=408,height=289]

Figure 16.3 — Sound node geometry

The _spatialize_ field specifies if the sound is perceived as being
directionally located relative to the viewer. If the __spatialize__field
is `TRUE` and the viewer is located between the transformed inner
and outer ellipsoids, the viewer's direction and the relative location
of the Sound node should be taken into account during playback. Details
outlining the minimum required spatialization functionality can be found
in <<Soundattenandspatial, 16.2.3 Sound attenuation and spatialization>>. If the _spatialize_ field is `FALSE`,
directional effects are ignored, but the ellipsoid dimensions and
_intensity_ will still affect the loudness of the sound. If the sound
source is multi-channel (`EXAMPLE`  stereo), the source shall
retain its channel separation during playback.

[[SpatialSound]]
==== 16.4.18 SpatialSound

[source,node]
----
SpatialSound : X3DSoundNode  {
  MFNode   [in,out] children          NULL      [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFFloat  [in,out] coneInnerAngle    6.2832    [0,2π]
  SFFloat  [in,out] coneOuterAngle    6.2832    [0,2π]
  SFFloat  [in,out] coneOuterGain     0         (-∞,∞)
  SFString [in,out] description       ""
  SFVec3f  [in,out] direction         0 0 1     (-∞,∞)
  SFString [in,out] distanceModel     "INVERSE" ["LINEAR" "INVERSE" "EXPONENTIAL"]
  SFBool   [in,out] dopplerEnabled    FALSE
  SFBool   [in,out] enabled           TRUE
  SFBool   [in,out] enableHRTF        FALSE
  SFFloat  [in,out] gain              1         (-∞,∞)
  SFFloat  [in,out] intensity         1         [0,1]
  SFVec3f  [in,out] location          0 0 0     (-∞,∞)
  SFFloat  [in,out] maxDistance       10000     [0,∞)
  SFNode   [in,out] metadata          NULL      [X3DMetadataObject]
  SFFloat  [in,out] priority          0         [0,1]
  SFFloat  [in,out] referenceDistance 1         [0,∞)
  SFFloat  [in,out] rolloffFactor     1         [0,∞)
  SFBool   []       spatialize        TRUE
}
----

SpatialSound represents a processing node which positions, emits and
spatializes an audio stream in three-dimensional (3D) space. This node
provides full spatialization of panner capabilities defined by W3C Web
Audio API <<W3C-WebAudio>> within an X3D scene.

The _coneInnerAngle_ is centered along direction and defines the inner
conical volume, inside of which no source gain reduction occurs. The
_coneOuterAngle_ is centered along direction and defines an outer
conical volume, within which the sound gain decreases linearly from full
gain to _coneOuterGain_. Outside of _coneOuterAngle_, gain equals
_coneOuterGain_. The value of _coneOuterAngle_ is greater than or equal
to _coneInnerAngle_. Corresponding gain reductions for 2D and 3D spatial
panning between this source and a viewer (or
<<ListenerPointSource>>) are shown in
<<f-SpatialSoundPanningGainRelationships, Figure 16.4>>.

If the _dopplerEnabled_ field is TRUE then sound sources which are
moving spatially in the transformation hierarchy, relative to the
location of the ListenerPointSource node, shall be modified by applying
velocity-induced frequency shifts corresponding to Doppler effect.

[[f-SpatialSoundPanningGainRelationships]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ConeModelPanner_1.png[SpatialSound and ListenerPointSource Spatial Relationships,width=1000,height=246]

Figure 16.4 — SpatialSound Panning Gain Relationships for viewer (or
ListenerPointSource)

The _direction_, _intensity_, _location_, _priority_, _source_ and
_spatialize_ fields match field definitions for Sound node.

The _referenceDistance_ field is reference distance for reducing volume
as source moves further from the listener. For distances less than this
value, volume is not reduced.

The _rolloffFactor_ field indicates how quickly volume is reduced as
source moves further from listener.

The _distanceModel_ field specifies which algorithm to use for sound
attenuation, corresponding to distance between an audio source and a
listener, as it moves away from the listener.

[loweralpha]
. LINEAR gain model determined by +
`1 - rolloffFactor * (distance - referenceDistance) /(maxDistance - referenceDistance)`
. INVERSE gain model determined by +
`refDistance / (referenceDistance + rolloffFactor *(Math.max(distance, referenceDistance) - referenceDistance))`
. EXPONENTIAL gain model determined by +
`pow((Math.max(distance, referenceDistance) / referenceDistance,-rolloffFactor)`

The _enableHRTF_ field specifies whether to enable Head Related Transfer
Function (HRTF) auralization, if available.

The _maxDistance_ field is the maximum distance where sound is
renderable between source and listener, after which no reduction in
sound volume occurs.

The _children_ field specifies audio-graph sound sources for this node.
If multiple input signals are provided by the _children_ field, all
channels are mixed together and merged prior to node operation.

[[StreamAudioDestination]]
==== 16.4.19 StreamAudioDestination

[source,node]
----
StreamAudioDestination : X3DSoundDestinationNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFString [in,out] mediaDeviceID         ""
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  MFString [in,out] streamIdentifier      []
  SFInt32  [out]    channelCount                     [0,∞)
}
----

StreamAudioDestination is an audio destination representing a
MediaStream with a single MediaStreamTrack whose kind is "audio".

The _streamIdentifier_ field conforms to requirements of W3C Media
Capture and Streams <<W3C-Media>>.

[[StreamAudioSource]]
==== 16.4.20 StreamAudioSource

[source,node]
----
StreamAudioSource : X3DSoundSourceNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  MFString [in,out] streamIdentifier      []
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

StreamAudioSource operates as an audio source whose media is received
from a MediaStream obtained using the WebRTC or Media Capture and
Streams APIs. This media source might originate from a remote microphone
or sound-processing channel provided by a remote peer on a WebRTC call.

The _streamIdentifier_ field conforms to requirements of W3C Media
Capture and Streams <<W3C-Media>>.

[[WaveShaper]]
==== 16.4.21 WaveShaper

[source,node]
----
WaveShaper : X3DSoundProcessingNode {
  SFString [in,out] channelCountMode      "MAX"      ["MAX", "CLAMPED_MAX", "EXPLICIT"] 
  SFString [in,out] channelInterpretation "SPEAKERS" ["SPEAKERS", "DISCRETE"] 
  MFNode   [in,out] children              NULL       [X3DSoundChannelNode,X3DSoundProcessingNode,X3DSoundSourceNode]
  MFFloat  [in,out] curve                 []         [-1,-1]
  SFString [in,out] description           ""
  SFBool   [in,out] enabled               TRUE
  SFFloat  [in,out] gain                  1          (-∞,∞)
  SFNode   [in,out] metadata              NULL       [X3DMetadataObject]
  SFString [in,out] oversample            "NONE"     ["NONE", "2X", "4X"] 
  SFTime   [in,out] pauseTime             0          (-∞,∞)
  SFTime   [in,out] resumeTime            0          (-∞,∞)
  SFTime   [in,out] startTime             0          (-∞,∞)
  SFTime   [in,out] stopTime              0          (-∞,∞)
  SFTime   [in,out] tailTime              0          [0,∞)
  SFInt32  [out]    channelCount                     [0,∞)
  SFTime   [out]    elapsedTime
  SFBool   [out]    isActive
  SFBool   [out]    isPaused
}
----

WaveShaper represents a nonlinear distorter that applies a wave-shaping
distortion curve to the signal. Non-linear waveshaping distortion is
commonly used for both subtle non-linear warming, or more obvious
distortion effects. Arbitrary non-linear shaping curves may be
specified.

The _curve_ field is an array of floating-point numbers describing the
distortion to apply.

The _oversample_ field is specifies what type of oversampling (if any)
should be used when applying the shaping curve. Allowed values follow.
Note that for some applications, avoiding oversampling can produce a
precise shaping curve.

* `"NONE"`: the curve is applied directly to the input samples
with no oversampling.
* `"2X"`: oversample two times to improve the quality of the
processing by avoiding some aliasing.
* `"4X"`: oversample four times for highest quality of the
processing.

[[S16.5_SupportLevels]]
=== 16.5 Support levels

The Sound component provides one level of support as specified in
<<t16_3, Table 16.3>>.

[[t16_3]]
Table 16.3 — Sound component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|*Level* |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Time 1 |  | 

|  |  |_X3DSoundChannelNode_ (abstract) |n/a

|  |  |_X3DSoundDestinationNode_ (abstract) |n/a

|  |  |_X3DSoundNode_ (abstract) |n/a

|  |  |_X3DSoundProcessingNode_ (abstract) |n/a

|  |  |_X3DSoundSourceNode_ (abstract) |n/a

|  |  |AudioClip |All fields fully supported.

|  |  |Sound |All fields fully supported, _children_ field support is
optional.

|*2* |Core 1 +
Time 1 |  | 

|  |  |All level 1 Sound nodes |All fields fully supported.

|  |  |Analyser |All fields fully supported.

|  |  |AudioDestination |All fields fully supported.

|  |  |BiquadFilter |All fields fully supported.

|  |  |BufferAudioSource |All fields fully supported.

|  |  |ChannelMerger |All fields fully supported.

|  |  |ChannelSelector |All fields fully supported.

|  |  |ChannelSplitter |All fields fully supported.

|  |  |Convolver |All fields fully supported.

|  |  |Delay |All fields fully supported.

|  |  |DynamicsCompressor |All fields fully supported.

|  |  |Gain |All fields fully supported.

|  |  |ListenerPointSource |All fields fully supported. Doppler effects
due to relative velocity between ListenerPointSource and sound sources
are optional.

|  |  |MicrophoneSource |All fields fully supported.

|  |  |OscillatorSource |All fields fully supported.

|  |  |PeriodicWave |All fields fully supported.

|  |  |Sound |All fields fully supported.

|  |  |SpatialSound |All fields fully supported. Doppler effects due to
relative velocity between SpatialSound and sound sources are optional.

|  |  |StreamAudioDestination |All fields fully supported.

|  |  |StreamAudioSource |All fields fully supported.

|  |  |WaveShaper |All fields fully supported.

|*3* |Core 1 +
Time 1 |  | 

|  |  |ListenerPointSource |All fields and capabilities fully supported.

|  |  |SpatialSound |All fields and capabilities fully supported.
|===

[[lighting_html]]
== 17 Lighting component

[[S17_Introduction]]
=== 17.1 Introduction

[[S17_Name]]
==== 17.1.1 Name

The name of this component is "Lighting". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S17_Overview]]
==== 17.1.2 Overview

This clause describes the Lighting component of this document. This
includes how light sources are defined and positioned as well as how
lights effect the rendered image. <<t17_1, Table 17.1>> provides
links to the major topics in this clause.

[[t17_1]]
Table 17.1 — Topics

* <<S17Introduction, 17.1 Introduction>>
** <<S17_Name, 17.1.1 Name>>
** <<S17_Overview, 17.1.2 Overview>>
* <<S17_Concepts, 17.2 Concepts>>
** <<LightSourceSemantics, 17.2.1 Light source semantics>>
*** <<LightSourceSemanticsOverview, 17.2.1.1 Overview>>
*** <<ScopingOfLights, 17.2.1.2 Scoping of lights>>
** <<LightingModel, 17.2.2 Lighting model>>
*** <<LightingModelIntroduction, 17.2.2.1 Introduction>>
*** <<LightingTextureSampling, 17.2.2.2 Texture sampling>>
*** <<LightingCommon, 17.2.2.3 Common definitions for all lighting models>>
*** <<LightingUnlit, 17.2.2.4 Unlit lighting model>>
*** <<LightingPhong, 17.2.2.5 Phong lighting model>>
*** <<LightingPhysical, 17.2.2.6 Physical lighting model>>
*** <<GouraudShading, 17.2.2.7 Gouraud shading model>>
*** <<Shadows, 17.2.2.8 Shadows>>
* <<S17_AbstractTypes, 17.3 Abstract types>>
** <<X3DLightNode, 17.3.1 _X3DLightNode_>>
* <<S17_NodeReference, 17.4 Node reference>>
** <<DirectionalLight, 17.4.1 DirectionalLight>>
** <<PointLight, 17.4.2 PointLight>>
** <<SpotLight, 17.4.3 SpotLight>>
* <<S17_SupportLevels, 17.5 Support levels>>

* <<f-SpotLightnode, Figure 17.1 — SpotLight node>>

* <<t17_1, Table 17.1 — Topics>>
* <<t17_2, Table 17.2 — Unlit colour and alpha mapping>>
* <<t17_3, Table 17.3 — Lit colour and alpha mapping>>
* <<t17_4, Table 17.4 — Calculation of the spotlight factor>>
* <<t17_5, Table 17.5 — Calculation of the fog interpolant>>
* <<t17_6, Table 17.6 — Lighting component support levels>>




[[S17_Concepts]]
=== 17.2 Concepts

[[LightSourceSemantics]]
==== 17.2.1 Light source semantics

[[LightSourceSemanticsOverview]]
===== 17.2.1.1 Overview

The following node types are light source nodes:

* <<DirectionalLight>>
* <<PointLight>>
* <<SpotLight>>

PointLight and SpotLight illuminate all objects in the world that fall
within their volume of lighting influence regardless of location within
the transformation hierarchy (by default, when their _global_ field is
`TRUE`). PointLight defines this volume of influence as a sphere
centred at the light (defined by a radius). SpotLight defines the volume
of influence as a solid angle defined by a radius and a cut-off angle.
DirectionalLight nodes illuminate only the objects descended from the
light's parent grouping node, including any descendent children of the
parent grouping nodes (by default, when their _global_ field is
`FALSE`).

Shape nodes are illuminated by the sum of all of the lights in the world
that affect them. This includes the contribution of both the direct and
ambient illumination from light sources. Ambient illumination results
from the scattering and reflection of light originally emitted directly
by light sources. The amount of ambient light is associated with the
individual lights in the scene. This is a gross approximation to how
ambient reflection actually occurs in nature.

Any node used as a source of illumination is derived from
_<<X3DLightNode>>_. All light sources contain an
_intensity_, a _color_, and an _ambientIntensity_ field. The _intensity_
field specifies the brightness of the direct emission from the light,
and the _ambientIntensity_ specifies the intensity of the ambient
emission from the light. Light intensity may range from 0.0 (no light
emission) to infinity. The _color_ field specifies the spectral colour
properties of both the direct and ambient light emission as an RGB
value. The _on_ field specifies whether the light is enabled or
disabled. If the value is `FALSE`, the light is disabled and will
not affect any nodes in the scene. If the value is `TRUE`, the
light will affect other nodes according to the
<<ScopingOfLights, 17.2.1.2 Scoping of lights>>.

Typically lighting _intensity_ values are within range [0,1] for
consistent composability of multiple scenes with independent lights.

In the _physical lighting model_ (see <<LightingPhysical, 17.2.2.6 Physical lighting model>>) the _intensity_ value should correspond to:

* luminous intensity in candela (lm/sr) in case of
<<PointLight>> and <<SpotLight>>.
* illuminance in lux (lm/m^2^) in case of
<<DirectionalLight>>.

In the physical lighting model, the _ambientIntensity_ value is unused.

In the case of the _unlit lighting model_ all lights are ignored. See
the <<LightingUnlit, 17.2.2.4 Unlit lighting model>>.

[[ScopingOfLights]]
===== 17.2.1.2 Scoping of lights

Each light type defines a _global_ field that determines whether the
light is global or scoped. Global lights illuminate all objects that
fall within their volume of lighting influence. Scoped lights only
illuminate objects that are in the same transformation hierarchy as the
light; _i.e._, only the children and descendants of its enclosing parent
group are illuminated. This allows the creation of realistic effects
such as lights that illuminate a single room.

[[LightingModel]]
==== 17.2.2 Lighting model


[[S17_Introduction]]
===== 17.2.2.1 Introduction

The X3D lighting model provides detailed equations that specify the
colours to apply to each geometric object. For each object, the values
of the material, color, and/or texture currently being applied to the
object are combined with the lights illuminating the object and the
currently bound _<<X3DFogObject>>_ (if specified). These
equations are designed to simulate the physical properties of light
striking a surface.

If a programmable shader is defined for an <<Appearance>>
node, the lighting model shall be disabled and replaced by the
functionality implemented by the shader program. See
<<shaders_html, 31 Programmable shaders component>> for more
information.

NOTE  Geometry nodes that represent lines or points do not support
lighting.

[[LightingTextureSampling]]
===== 17.2.2.2 Texture sampling

A grayscale texture is exactly equivalent to using an RGB texture with
all 3 components (red, green, blue) equal.

A texture without an alpha channel is exactly equivalent to using a
texture with an alpha channel filled with 1 (indicating opaque).

[[LightingCommon]]
===== 17.2.2.3 Common definitions for all lighting models

The declarations and definitions below are presented using pseudocode
similar to shading language code (see
<<Shaderlanguageoptions, 31.2.2.1 Shader language options>>).

* The function declarations look like this:
_functionName(typeOfParameter1parameter1,typeOfParameter2parameter2,
...)_. Type names are underlined.
* The types can be X3D nodes, scalars (float), vectors with 2, 3 or 4
components (vector2, vector3, vector4), universal type (vectorAny which
can represent any vector or scalar).
* In function definitions, we often extract vector components with
syntax like: _thisVector.rgb_ (converts vector4 to vector3, discarding
alpha channel) or _thisVector.a_ (converts vector4 to float, extracting
alpha channel value).
* The symbol × performs a component-wise multiplication of vectors.
* The symbol · is a modified vector dot product that always returns
value >= 0, defined like this:
+
_x · y = max(0.0, dotProduct(x, y))_

The _mixTexture(vector4color,X3DTextureNodetexture)_ function, used in
the equations below, takes care of mixing an RGBA color with the RGBA
value sampled from the texture at the given shape point.

* If the _texture_ is `NULL`, then this function just returns
unmodified _color_.
* Otherwise, if the _texture_ is not a _MultiTexture_, then
+
_mixTexture(color, texture) = color × textureSample(texture)_
+
The _textureSample(texture)_ is a function sampling the texture
(recovering a single color from an array of pixels), with the correct
texture coordinates and transformation.
+
In effect the _color_ modulates the color from the texture.
** _color.rgb = white = (1, 1, 1)_ results in the pure color of the
texture,
** _color.rgb = black = (0, 0, 0)_ results in a black output, regardless
of the texture.
+
The alpha (opacity) values are multiplied too, hence:
** _color.a_ equal 1 (transparency equal 0) results in an alpha equal to
that of the texture,
** _color.a_ equal 0 (transparency equal 1) results in an alpha of 0
regardless of the value in the texture.
* Otherwise, if the _texture_ is a _MultiTexture_, then the _mixTexture_
modifies this color following the <<MultiTexture>> mode
specification. This is only possible when the _MultiTexture_ is provided
in the _Appearance.texture_ field. See
<<CoexistenceMaterialTexturesWithAppearanceTexture>> for details when multi-texturing is used.

The _lerp(floatfactor,vectorAnyx,vectorAnyy)_ function performs a
standard linear interpolation, applicable to scalars or vectors of any
dimension:

_lerp(factor, x, y) = x * (1 - factor) + y * factor = x + (y - x) *
factor_

The _occlusion(vector4color)_ function, used in the equations below for
_Phong_ and _physical_ lighting model, is used to apply the
_occlusionTexture_ effect that can be specified in these nodes.

* If the _occlusionTexture_ was not provided (left `NULL`) then
this function just returns unmodified _color_.
* If the _occlusionTexture_ was provided, then
+
_occlusion(color) = lerp(occlusionStrength, color, color *
textureSample(occlusionTexture).r)_
+
In effect, the _occlusionTexture_ multiplies the input _color_ when
_occlusionStrength_ is 1.0. the _occlusionTexture_ has no effect when
when _occlusionStrength_ is 0.0. Values in-between of
_occlusionStrength_ allow to smoothly interpolate between these two
states.

The _applyColorPerVertex(vector4color)_ is used to change the _color_ in
case geometry uses _Color_ or _ColorRGBA_ nodes. All the lighting models
use this function, although it affects a different parameter:
_emissiveParameter_ in case of _unlit_ model, _diffuseParameter_ in case
of _Phong_ model, and _baseParameter_ in case of _physical_ model. The
function returns:

* The interpolated per-vertex colour, or per-face colour, from the
_Color_ node, if the _Color_ node is provided in the geometry _color_
field.
+
Resulting _rgb_ is derived from the values in the _Color_ node.
+
Resulting _a_ (alpha component) is taken from input _color.a_ in this
case.
* Otherwise, the interpolated per-vertex colour, or per-face colour,
from the _ColorRGBA_ node, if the _ColorRGBA_ node is provided in the
geometry _color_ field.
+
Resulting _rgba_ vector is derived from the values in the _ColorRGBA_
node.
* Otherwise (if the geometry _color_ field is empty) then it returns
unmodified _color_.

The future X3D versions may introduce an option for _Color_ and
_ColorRGBA_ to multiply the input color, instead of replacing it.

Moreover we define the following vectors:

* *`+N+`* = normalized normal vector at this point on geometry. This
vector is interpolated from vertex normals specified in a node derived
from _<<X3DNormalNode>>_ or calculated by the X3D
browser. It is modified by the _normalTexture_ providing normals in the
tangent space (see
<<X3DOneSidedMaterialNode>> definition).
* *`+V+`* = normalized vector from point on geometry to viewer's
position.

The following definitions are specific to a light source _i_, which is
indicated by a subscript in this text:

* *`+L+`~`+i+`~* is, conceptually, _direction to the light i_. It is
precisely defined like this:
** *`+L+`~`+i+`~* =
(<<PointLight>>/<<SpotLight>>) normalized
vector from point on geometry to light source i position
** *`+L+`~`+i+`~* = (<<DirectionalLight>>) negated
and normalized direction of light source i
* _attenuation~i~= 1 / max(c~1~ + c~2~ × lightDistance + c~3~ ×
lightDistance^2^ , 1)_
+
where
+
c~1~, c~2~, c~3~ are the values from light i _attenuation_ field.
+
_lightDistance_ is the distance from light to point on geometry, in
light's coordinate system.
* _on~i~_ = 1, if light source _i_ affects this point on the geometry or
0 if it does not.
+
The following conditions indicate that light source i does not affect
this geometry:
. if the geometry is farther away than _radius_ for PointLight or
SpotLight
. if the geometry is outside the enclosing
_<<X3DGroupingNode>>_ in case of lights with _global_
`FALSE`
. if the _lightSource.on_ field is `FALSE`.
* _shadowTest~i~_ scales down the light contribution if the light source
is obscured by a shape casting shadow.
** _shadowTest~i~_ is 1.0 if the light source _i_ has _shadows_ field
equal `FALSE`.
** Otherwise, _shadowTest~i~_ is 1.0 if the light source _i_ has
_shadows_ field equal `TRUE` but nothing obscures the light. That
is, there is no Shape (that has _visible_ and _castShadow_ equal
`TRUE`) between the light source position and the given point.
The _DirectionalLight_ is treated like a _point in infinity_ for this
purpose, which means that shadow rays are all parallel to the light
direction.
** Otherwise, _shadowTest~i~_ is _1.0 - shadowIntensity_. This case
occurs when _shadows_ field equals `TRUE` and the light is
obscured. For example, _shadowIntensity_ equal 1.0 (the default) means
that light contribution drops to zero when the light is obscured by the
shadow caster.
* _lightColor~i~_ equals the _color_ field of light source _i_.
* _spot~i~_ is the spotlight factor. It calculates intensity within the
<<SpotLight>> cone. <<t17_4, Table 17.4>>
specifies how it is calculated. It relies on the following terms:
** _spotDirection~i~_ = normalized SpotLight i _direction_ field.
** _spotAngle = arcCosine( *`+-L+`*· spotDirection~i~)_

[[t17_4]]
Table 17.4 — Calculation of the spotlight factor

[cols=",",options="header",]
|===
|Condition (in order) |spot ~*i*~ *=*
|light~i~ is _PointLight_ or _DirectionalLight_ |1

|spotAngle ≥ SpotLight.cutOffAngle |0

|spotAngle ≤ SpotLight.beamWidth |1

|SpotLight.beamWidth  < spotAngle < lightSource.cutOffAngle |(spotAngle
- SpotLight.cutOffAngle) / (SpotLight.beamWidth - SpotLight.cutOffAngle)
|===

The _applyFog(vector4color)_ is used to change the _color_ using the
currently bound fog node. Is it used by all lighting models, as the last
operation performed on the color. The definition is:

_applyFog(color) = lerp(fogInterpolant(fogDistance), fogColor, color)_

where:

* _fogInterpolant_ is the fog interpolant, see
<<t17_5, Table 17.5>> for calculation.
* _fogDistance_ is the distance from point on geometry to viewer's
position, in coordinate system of the currently bound fog node.
* _fogColor_ is the currently bound fog node's _color_.
* _fogVisibility_ is the currently bound fog node's _visibilityRange_,
in the same coordinate system as _fogDistance_.

[[t17_5]]
Table 17.5 — Calculation of the fog interpolant

[cols=",",options="header",]
|===
|Condition |fogInterpolant(fogDistance)
|no fog |1

|_fogType_ "LINEAR", _fogDistance_ < _fogVisibility_ |(_fogVisibility_ -
_fogDistance_) / _fogVisibility_

|_fogType_ "LINEAR", _fogDistance_ [.underline]#># _fogVisibility_ |0

|_fogType_ "EXPONENTIAL", _fogDistance_ < _fogVisibility_ |exp(-
_fogDistance_ / (_fogVisibility_ - _fogDistance_))

|_fogType_ "EXPONENTIAL", _fogDistance_ [.underline]#># _fogVisibility_
|0
|===

[[LightingUnlit]]
===== 17.2.2.4 Unlit lighting model

A <<Shape>> node is unlit if either of the following is true:

. The shape's _appearance_ field is `NULL` (default).
. The _material_ field in the Appearance node is `NULL`
(default).
. The _material_ field in the Appearance node contains a node of type
<<UnlitMaterial>>.

In the first two cases above, the rendering is exactly equivalent as if
the _Appearance_ node was provided (not `NULL`), and the
_material_ field inside contained an _UnlitMaterial_ with all the fields
at their default. Effectively, it means a _white untextured unlit_
material is the default.

NOTE  Geometry nodes that represent lines or points do not support
lighting if the normal vectors for them are not provided.

If the shape is unlit, the RGBA color of the shape at each point on the
shape's geometry is calculated using this equation:

_fragmentColor =
applyFog(mixTexture(applyColorPerVertex(emissiveParameter),
emissiveTextureParameter))_

where:

* _emissiveParameter.rgb_ (RGB channels) are taken from
_UnlitMaterial.emissiveColor_.
* _emissiveParameter.a_ (alpha channel) is taken from _1 -
UnlitMaterial.transparency_.
* _emissiveTextureParameter_ is equal to:
** _emissiveTexture_ of the _UnlitMaterial_ node, if it is not
`NULL`.
** Otherwise, _Appearance.texture_, if the _UnlitMaterial_ has
_emissiveTexture_ equal `NULL`, but _Appearance.texture_ is not
`NULL`. See
<<CoexistenceMaterialTexturesWithAppearanceTexture>>.
** Otherwise (if both the _UnlitMaterial.emissiveTexture_ and
_Appearance.texture_ are `NULL`) then _emissiveTextureParameter_
is `NULL`. In other words, the _mixTexture(...)_ function used
above simply returns the unmodified
_applyColorPerVertex(emissiveParameter)_.

[[LightingPhong]]
===== 17.2.2.5 Phong lighting model

The <<Shape>> node is lit with a _Phong lighting model_ if the
<<Appearance>> node is specified for the Shape, and the
_material_ field contains a <<Material>> node.

NOTE   This node is simply called _Material_ for historical reasons.
Conceptually, you should think about it now as a _PhongMaterial_.

The rendered fragment (pixel) color is determined by these equations:

_fragmentColor = applyFog(emissiveParameter +
occlusion(sumOverAllLights(lightContribution~i~)))_

_lightContribution~i~= on~i~ × shadowTest~i~ × lightColor~i~ ×
attenuation~i~ × spot~i~ × (ambient~i~+ diffuse~i~+ specular~i~)_

An ideal X3D implementation will evaluate the following lighting
equation at each point on a lit surface. The means that we advise using
_Phong shading_ and assume it when writing equations below. For
implementations that perform _Gouraud shading_ see
<<GouraudShading, 17.2.2.8 Gouraud shading>> section.

The meaning of all the terms is explained below.

*Material parameters*

First, the parameters whose value does not depend on the light source:

The material _diffuseParameter_ is calculated as follows:

_diffuseParameter = mixTexture(applyColorPerVertex(diffuseParameter),
diffuseTextureParameter)_ where:

* _diffuseParameter.a_ (RGB channels) is taken from
_Material.diffuseColor_.
* _diffuseParameter.a_ (alpha channel) is taken from _1 -
Material.transparency_.
* _diffuseTextureParameter_ is equal to:
** _diffuseTexture_ of the _Material_ node, if it is not `NULL`.
** Otherwise, _Appearance.texture_, if the _Material_ has
_diffuseTexture_ equal `NULL`, but _Appearance.texture_ is not
`NULL`. See
<<CoexistenceMaterialTexturesWithAppearanceTexture>>.
** Otherwise (if both the _Material.diffuseTexture_ and
_Appearance.texture_ are `NULL`) then _diffuseTextureParameter_
is `NULL`. In other words, the _mixTexture(...)_ function used
above simply returns the unmodified
_applyColorPerVertex(diffuseParameter)_.

The remaining parameters are defined below:

* _ambientParameter = ambientIntensity ×diffuseParameter.rgb×
textureSample(ambientTexture).rgb_
* _emissiveParameter = emissiveColor ×
textureSample(emissiveTexture).rgb_
* _specularParameter = specularColor ×
textureSample(specularTexture).rgb_
* _shininessParameter = shininess × textureSample(shininessTexture).a ×
128_

In the above equations, if the given texture is `NULL` then
behave as if the _textureSample(texture)_ returned a white opaque value
(1, 1, 1, 1).

*Light parameters*

Now we can define terms that depend on the light source:

* _ambient~i~= lightSource.ambientIntensity × ambientParameter_
* _diffuse~i~ = lightSource.intensity × diffuseParameter × ( *`+N+`*·
*`+L+`*)_
* _specular~i~ = lightSource.intensity × specularParameter × ( *`+N+`*·
(( *`+L+`* + *`+V+`*) /| **`+L+`**+ **`+V+`**|))^shininessParameter^_

The _Phong_ lighting equations are based on the simple illumination
equations given in <<FOLEY>> and <<OPENGL>>.

[[LightingPhysical]]
===== 17.2.2.6 Physical lighting model

The <<Shape>> node is lit with a _Physical lighting model_ if
the <<Appearance>> node are specified for the Shape, and
the _material_ field contains a <<PhysicalMaterial>>
node. We perform in this case a _physically-based rendering_.

The rendered fragment (pixel) color is determined by these equations:

_fragmentColor = applyFog(emissiveParameter +
occlusion(sumOverAllLights(lightContribution~i~)))_

_lightContribution~i~= on~i~ × shadowTest~i~ × lightColor~i~ ×
attenuation~i~ × spot~i~ × physicalLightContribution~i~_

The input values used by the physical lighting equation are as follows:

_baseParameter = mixTexture(applyColorPerVertex(baseParameter),
baseTextureParameter)_ where:

* _baseParameter.a_ (RGB channels) is taken from
_PhysicalMaterial.baseColor_.
* _baseParameter.a_ (alpha channel) is taken from _1 -
PhysicalMaterial.transparency_.
* _baseTextureParameter_ is equal to:
** _baseTexture_ of the _PhysicalMaterial_ node, if it is not
`NULL`.
** Otherwise, _Appearance.texture_, if the _PhysicalMaterial_ has
_baseTexture_ equal `NULL`, but _Appearance.texture_ is not
`NULL`. See
<<CoexistenceMaterialTexturesWithAppearanceTexture>>.
** Otherwise (if both the _PhysicalMaterial.baseTexture_ and
_Appearance.texture_ are `NULL`) then _baseTextureParameter_ is
`NULL`. In other words, the _mixTexture(...)_ function used above
simply returns the unmodified _applyColorPerVertex(baseParameter)_.

_metallicParameter = PhysicalMaterial.metallic ×
textureSample(PhysicalMaterial.metallicRoughnessTexture).b_

_roughnessParameter = PhysicalMaterial.roughness ×
textureSample(PhysicalMaterial.metallicRoughnessTexture).g_

If the _metallicRoughnessTexture_ is NULL, then _metallicParameter_ and
_roughnessParameter_ are just equal to (respectively) _metallic_ and
_roughness_ values given by the _PhysicalMaterial_ node.

The physical lighting model uses the _baseParameter_,
_metallicParameter_ and _roughnessParameter_ to calculate the
_physicalLightContribution~i~_ value in accordance with the physically
based rendering equations as specified in <<GLTF, 2.[GLTF>>].

[[GouraudShading]]
===== 17.2.2.7 Gouraud shading model

An ideal X3D implementation will evaluate the lighting equation at each
point on a lit surface. The lighting equations in previous sections
assume that you use _Phong shading_ (not to be confused with _Phong
lighting model_). In case of _Phong shading_, lighting is calculated at
each fragment (pixel of the screen).

However, some implementations perform _Gouraud shading_, either by
default, or as an option for the user (for efficiency), or as a fallback
for an older GPUs. In such case, the lighting equations given above
cannot be reproduced precisely. In Gouraud shading, you calculate
lighting per-vertex, which means that it does not make sense to use
texture information to modify material parameters.

In case when _Gouraud shading_ is used we recommend this algorithm:

* The vertex shader calculates lighting equations, ignoring any texture
information (as if all the textures were `NULL`).
* The fragment shader multiplies the resulting interpolated color by the
_main texture_. The _main texture_ is:
** _Material.diffuseTexture_, if Phong _Material_ node is used.
** _UnlitMaterial.emissiveTexture_, if _UnlitMaterial_ node is used.
** _PhysicalMaterial.baseTexture_, if _PhysicalMaterial_ node is used.
+
If the given texture is `NULL`, then use the
_Appearance.texture_. If the _Appearance.texture_ is also NULL, no
texture is used.
+
All channels (RGB and alpha) are affected by the _main texture_.
+
This method of determining the _main texture_ is deliberately 100%
consistent with:
. The way how the _Appearance.texture_ cooperates with textures inside
the materials, following section
<<CoexistenceMaterialTexturesWithAppearanceTexture>>. _Appearance.texture_ may be used in place
of _Material.diffuseTexture_, or _UnlitMaterial.emissiveTexture_, or
_PhysicalMaterial.baseTexture_.
. The determination which texture contains the alpha channel that is
multiplied by material _transparency_. We take it from alpha channel of
_Material.diffuseTexture_, or _UnlitMaterial.emissiveTexture_, or
_PhysicalMaterial.baseTexture_.

This recommendation tries to preserve the intended look as much as
possible in _Gouraud shading_.

NOTE   This recommendation actually does not change anything in case of
_UnlitMaterial_. And this is correct, _Gouraud shading_ actually does
not change how the _UnlitMaterial_ can be implemented.

NOTE   When using _PhysicalMaterial_ on older hardware, some
implementations may fall back to the _Phong_ lighting model. If this is
necessary, we recommend using _PhysicalMaterial.baseColor_ as the
_Phong_ diffuse factor, and _PhysicalMaterial.baseTexture_ as the
texture to multiply the resulting color.

[[Shadows]]
===== 17.2.2.8 Shadows

Geometric objects can cast shadows, meaning that the amount of light
reaching a given surface is decreased if a light source is obscured by
occluding geometry. Intervening geometry is only considered for
occlusion effects when the _X3DShapeNode_ field _castShadow_ is TRUE.

Multiple light sources can have shadows enabled. Lighting contributions
from each light source, and the intensity of corresponding shadows that
reduce light available at end points, are each computed independently
before reaching lit surface points.

High-fidelity physical effects such as umbra, penumbra and antumbra may
be optionally applied. X3D browser implementations are allowed some
variations in shadow rendering.


=== 17.3 Abstract types

[[X3DLightNode]]
==== 17.3.1 _X3DLightNode_

[source,node]
----
X3DLightNode : X3DChildNode { 
  SFFloat [in,out] ambientIntensity 0     [0,1]
  SFColor [in,out] color            1 1 1 [0,1]
  SFBool  [in,out] global           FALSE
  SFFloat [in,out] intensity        1     [0,∞) 
  SFNode  [in,out] metadata         NULL  [X3DMetadataObject]
  SFBool  [in,out] on               TRUE
  SFBool  [in,out] shadows          FALSE
  SFFloat [in,out] shadowIntensity  1     [0,1]
}
----

The _X3DLightNode_ abstract node type is the base type from which all
node types that serve as light sources are derived. A description of the
_ambientIntensity_, _color_, _intensity_, and _on_ fields is in
<<LightSourceSemantics, 17.2.1 Light source semantics>>. A description
of the _global_ field is in <<ScopingOfLights, 17.2.1.2 Scoping of lights>>.

The _shadows_ field indicates whether or not lighting from this node
casts a shadow behind illuminated _X3DShapeNode_ geometry.

The _shadowIntensity_ field defines how much light is obscured by shapes
that cast shadows, ranging from 0 (light not obscured, no visible
shadows) to 1 (light completely obscured, full-intensity shadows). The
_shadowIntensity_ field has no effect when the _shadows_ field is FALSE.


=== 17.4 Node reference

[[DirectionalLight]]
==== 17.4.1 DirectionalLight

[source,node]
----
DirectionalLight : X3DLightNode {
  SFFloat [in,out] ambientIntensity 0      [0,1]
  SFColor [in,out] color            1 1 1  [0,1]
  SFVec3f [in,out] direction        0 0 -1 (-∞,∞)
  SFBool  [in,out] global           FALSE
  SFFloat [in,out] intensity        1      [0,∞)
  SFNode  [in,out] metadata         NULL   [X3DMetadataObject]
  SFBool  [in,out] on               TRUE
  SFBool  [in,out] shadows          FALSE
  SFFloat [in,out] shadowIntensity  1     [0,1]
}
----

The DirectionalLight node defines a directional light source that
illuminates along rays parallel to a given 3-dimensional vector. A
description of the _ambientIntensity_, _color_, _intensity_, and _on_
fields is in <<LightSourceSemantics, 17.2.1 Light source semantics>>.
A description of the _global_ field is in <<ScopingOfLights, 17.2.1.2 Scoping of lights>>.

The _direction_ field specifies the direction vector of the illumination
emanating from the light source in the local coordinate system. Light is
emitted along parallel rays from an infinite distance away. A
directional light source illuminates only the objects in its enclosing
parent group. The light may illuminate everything within this coordinate
system, including all children and descendants of its parent group. The
accumulated transformations of the parent nodes affect the light.

DirectionalLight nodes do not attenuate with distance. A precise
description of X3D's lighting equations is contained in
<<LightingModel, 17.2.2 Lighting model>>.

[[PointLight]]
==== 17.4.2 PointLight

[source,node]
----
PointLight : X3DLightNode {
  SFFloat [in,out] ambientIntensity 0     [0,1]
  SFVec3f [in,out] attenuation      1 0 0 [0,∞)
  SFColor [in,out] color            1 1 1 [0,1]
  SFBool  [in,out] global           TRUE
  SFFloat [in,out] intensity        1     [0,∞)
  SFVec3f [in,out] location         0 0 0 (-∞,∞)
  SFNode  [in,out] metadata         NULL  [X3DMetadataObject]
  SFBool  [in,out] on               TRUE
  SFFloat [in,out] radius           100   [0,∞)
  SFBool  [in,out] shadows          FALSE
  SFFloat [in,out] shadowIntensity  1     [0,1]
}
----

The PointLight node specifies a point light source at a 3D location in
the local coordinate system. A point light source emits light equally in
all directions; that is, it is omnidirectional. PointLight nodes are
specified in the local coordinate system and are affected by ancestor
transformations. A description of the _global_ field is in
<<ScopingOfLights, 17.2.1.2 Scoping of lights>>.

Subclause <<LightSourceSemantics, 17.2.1 Light source semantics>>,
contains a detailed description of the _ambientIntensity_, _color_, and
_intensity_ fields.

A PointLight node illuminates geometry within _radius_ length base units
of its _location_. Both radius and location are affected by ancestors'
transformations (scales affect _radius_ and transformations affect
_location_). The _radius_ field shall be greater than or equal to zero.

PointLight node's illumination falls off with distance as specified by
three _attenuation_ coefficients. The attenuation factor is:

   _1/max(attenuation[0] + attenuation[1]_ × _r + attenuation[2]_ × _r_
^_2_^, _ 1)_

where _r_ is the distance from the light to the surface being
illuminated. The default is no attenuation. An _attenuation_ value of
(0, 0, 0) is identical to (1, 0, 0). Attenuation values shall be greater
than or equal to zero. A detailed description of X3D's lighting
equations is contained in <<LightingModel, 17.2.2 Lighting model>>.

[[SpotLight]]
==== 17.4.3 SpotLight

[source,node]
----
SpotLight : X3DLightNode {
  SFFloat [in,out] ambientIntensity 0        [0,1]
  SFVec3f [in,out] attenuation      1 0 0    [0,∞)
  SFFloat [in,out] beamWidth        π*3/16   (0,π/2]
  SFColor [in,out] color            1 1 1    [0,1]
  SFFloat [in,out] cutOffAngle      π/2      (0,π/2]
  SFVec3f [in,out] direction        0 0 -1   (-∞,∞)
  SFBool  [in,out] global           TRUE
  SFFloat [in,out] intensity        1        [0,∞)
  SFVec3f [in,out] location         0 0 0    (-∞,∞)
  SFNode  [in,out] metadata         NULL     [X3DMetadataObject]
  SFBool  [in,out] on               TRUE
  SFFloat [in,out] radius           100      [0,∞)
  SFBool  [in,out] shadows          FALSE
  SFFloat [in,out] shadowIntensity  1        [0,1]
}
----

The SpotLight node defines a light source that emits light from a
specific point along a specific direction vector and constrained within
a solid angle. Spotlights may illuminate geometry nodes that respond to
light sources and intersect the solid angle defined by the SpotLight.
Spotlight nodes are specified in the local coordinate system and are
affected by ancestors' transformations. A description of the _global_
field is in <<ScopingOfLights, 17.2.1.2 Scoping of lights>>.

A detailed description of _ambientIntensity_, _color_, _intensity_, and
the lighting equations of X3D is provided in
<<LightSourceSemantics, 17.2.1 Light source semantics>>. More
information on lighting concepts can be found in
<<LightingModel, 17.2.2 Lighting model>>, including a detailed
description of the X3D lighting equations.

The _location_ field specifies a translation offset of the centre point
of the light source from the light's local coordinate system origin.
This point is the apex of the solid angle which bounds light emission
from the given light source. The _direction_ field specifies the
direction vector of the light's central axis defined in the local
coordinate system.

The _on_ field specifies whether the light source emits light. If _on_
is `TRUE`, the light source is emitting light and may illuminate
geometry in the scene. If _on_ is `FALSE`, the light source does
not emit light and does not illuminate any geometry.

The _radius_ field specifies the radial extent of the solid angle and
the maximum distance from _location_ that may be illuminated by the
light source. The light source does not emit light outside this radius.
The _radius_ shall be greater than or equal to zero.

Both radius and location are affected by ancestors' transformations
(scales affect _radius_ and transformations affect _location_).

The _cutOffAngle_ field specifies the outer bound of the solid angle.
The light source does not emit light outside of this solid angle. The
_beamWidth_ field specifies an inner solid angle in which the light
source emits light at uniform full intensity. The light source's
emission intensity drops off from the inner solid angle ( _beamWidth_)
to the outer solid angle ( _cutOffAngle_) as described in the following
equations:

[source,listing]
----
    angle = the angle between the Spotlight's direction vector and
            the vector from the Spotlight location to the point to be illuminated
    if (angle ≥ cutOffAngle):
        multiplier = 0
    else if (angle ≤ beamWidth):
        multiplier = 1
    else:
        multiplier = (angle - cutOffAngle) / (beamWidth - cutOffAngle)
    intensity(angle) = SpotLight.intensity × multiplier
----

If the _beamWidth_ is greater than the _cutOffAngle_, _beamWidth_ is
defined to be equal to the _cutOffAngle_ and the light source emits full
intensity within the entire solid angle defined by _cutOffAngle_. Both
_beamWidth_ and _cutOffAngle_ shall be greater than 0.0 and less than or
equal to π/2. <<f-SpotLightnode, Figure 17.1>> depicts the
_beamWidth_, _cutOffAngle_, _direction_, _location_, and _radius_ fields
of the SpotLight node.

[[f-SpotLightnode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/spotlight.gif[SpotLight
node,width=396,height=297]

Figure 17.1 — SpotLight node

SpotLight illumination falls off with distance as specified by three
_attenuation_ coefficients. The attenuation factor is:

   _1 /max(attenuation[0] + attenuation[1]_ × _r + attenuation[2]_ ×
_r_^2^ , 1 _)_

where _r_ is the distance from the light to the surface being
illuminated. The default is no attenuation. An _attenuation_ value of
(0, 0, 0) is identical to (1, 0, 0). Attenuation values shall be greater
than or equal to zero. A detailed description of X3D's lighting
equations is contained in <<LightingModel, 17.2.2 Lighting model>>.

[[S17.5_SupportLevels]]
=== 17.5 Support levels

The Lighting component provides three levels of support as specified in
<<t17_6, Table 17.6>>.

[[t17_6]]
Table 17.6 — Lighting component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|*Level* |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Shape 1 | |

| | |_X3DLightNode_ (abstract) |n/a

| | |DirectionalLight |Not scoped by parent Group or Transform.

| | | |Support for Gouraud and Phong shading.

|*2* |Core 1 +
Shape 1 | | 

| | |All Level 1 Lighting nodes |All fields as supported in Level 1.

| | |PointLight |_radius_ optionally supported. Linear attenuation.

| | |SpotLight |_beamWidth_ optionally supported. _radius_ optionally
supported. Linear attenuation.

|*3* |Core 1 +
Shape 2 | |

| | |All Level 2 Lighting nodes |All fields fully supported.

| | |EnvironmentLight |All fields fully supported.

| | | |Support for Physical and Unlit lighting models.
|===

[[texturing_html]]
== 18 Texturing component

[[S18_Introduction]]
=== 18.1 Introduction

[[S18_Name]]
==== 18.1.1 Name

The name of this component is "Texturing". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S18_Overview]]
==== 18.1.2 Overview

This clause describes the Texturing component of this document. This
includes how textures are specified and how they are positioned on the
subject geometry. <<t18_1, Table 18.1>> provides links to the major
topics in this clause.

[[t18_1]]
Table 18.1 — Topics

* <<S18Introduction, 18.1 Introduction>>
** <<S18_Name, 18.1.1 Name>>
** <<S18_Overview, 18.1.2 Overview>>
* <<S18_Concepts, 18.2 Concepts>>
** <<TextureMapFormats, 18.2.1 Texture map formats>>
** <<TextureMapImageFormats, 18.2.2 Texture map image formats>>
** <<S18_TextureCoordinates, 18.2.3 Texture coordinates>>
** <<Multitexturing, 18.2.4 Multitexturing>>
** <<ProgrammableShaders, 18.2.5 Programmable shaders>>
* <<S18_AbstractTypes, 18.3 Abstract types>>
** <<X3DSingleTextureCoordinateNode, 18.3.1 _X3DSingleTextureCoordinateNode_>>
** <<X3DSingleTextureNode, 18.3.2 _X3DSingleTextureNode_>>
** <<X3DSingleTextureTransformNode, 18.3.3 _X3DSingleTextureTransformNode_>>
** <<X3DTexture2DNode, 18.3.4 _X3DTexture2DNode_>>
** <<X3DTextureCoordinateNode, 18.3.5 _X3DTextureCoordinateNode_>>
** <<X3DTextureNode, 18.3.6 _X3DTextureNode_>>
** <<X3DTextureTransformNode, 18.3.7 _X3DTextureTransformNode_>>
* <<S18_NodeReference, 18.4 Node reference>>
** <<ImageTexture, 18.4.1 ImageTexture>>
** <<MovieTexture, 18.4.2 MovieTexture>>
** <<MultiTexture, 18.4.3 MultiTexture>>
** <<MultiTextureCoordinate, 18.4.4 MultiTextureCoordinate>>
** <<MultiTextureTransform, 18.4.5 MultiTextureTransform>>
** <<PixelTexture, 18.4.6 PixelTexture>>
** <<TextureCoordinate, 18.4.7 TextureCoordinate>>
** <<TextureCoordinateGenerator, 18.4.8 TextureCoordinateGenerator>>
** <<TextureProperties, 18.4.9 TextureProperties>>
** <<TextureTransform, 18.4.10 TextureTransform>>
* <<S18_SupportLevels, 18.5 Support levels>>

* <<f-TextureMapCoordSystem, Figure 18.1 — Texture map coordinate system>>
* <<f-Lightmapexample, Figure 18.2 — Lightmap example>>

* <<t18_1, Table 18.1 — Topics>>
* <<t18_2, Table 18.2 — Comparison of single texture and multitexture attributes>>
* <<t18_3, Table 18.3 —Multitexture values for __mode__field>>
* <<t18_4, Table 18.4 —Multitexture values for __source__field>>
* <<t18_5, Table 18.5 —Multitexture values for __function__field>>
* <<t18_6, Table 18.6 — Texture coordinate generation modes>>
* <<t18_7, Table 18.7 — Texture boundary modes>>
* <<t18_8, Table 18.8 — Texture magnification modes>>
* <<t18_9, Table 18.9 — Texture minification modes>>
* <<t18_10, Table 18.10 — Texture compression modes>>
* <<t18_11, Table 18.11 — Texturing component support levels>>




[[S18_Concepts]]
=== 18.2 Concepts

[[TextureMapFormats]]
==== 18.2.1 Texture map formats

Node types specifying texture maps include <<Background>>,
<<ImageTexture>>, <<MovieTexture>>,
<<MultiTexture>>,
<<MultiTextureTransform, PixelTexture>>, descendants of
<<X3DEnvironmentTextureNode>>, descendants
of <<X3DTexture3DNode>>. Texture maps are 2D or 3D
or cubemap images that contain an array of colour values describing the
texture.

Depending on the number of channels, the following texture types are
possible:

[loweralpha]
. _Intensity textures_ (one channel)
. _Intensity plus alpha opacity textures_ (two channels)
. _Full RGB textures_ (three channels)
. _Full RGB plus alpha opacity textures_ (four channels)

Note that image formats specify alpha ( _i.e._, opacity), not
transparency (where alpha = 1 − transparency).

See <<LightingTextureSampling, 17.2.2.2 Texture sampling>> for a
description of how the various texture types are applied.

The textures described in this component, _"Texturing"_, only support
two-dimensional map formats. See <<texture3D_html, 33 Texturing3D component>>
for a description of the use of 3D textures and
<<environmentalTexturing_html, 34 Cube map environmental texture component>>
for a description of the use of cube map textures.

[[TextureMapImageFormats]]
==== 18.2.2 Texture map image formats

Texture nodes that require support for the PNG (see
<<I15948>>) image format shall interpret the PNG pixel
formats in the following way:

[loweralpha]
. Greyscale pixels without alpha or simple transparency are treated as
intensity textures.
. Greyscale pixels with alpha or simple transparency are treated as
intensity plus alpha textures.
. RGB pixels without alpha channel or simple transparency are treated as
full RGB textures.
. RGB pixels with alpha channel or simple transparency are treated as
full RGB plus alpha textures.

If the image specifies colours as indexed-colour ( _i.e._, palettes or
colourmaps), the following semantics shall be used (where `greyscale'
refers to a palette entry with equal red, green, and blue values):

[loweralpha, start=5]
. If all the colours in the palette are greyscale and there is no
transparency chunk, it is treated as an intensity texture.
. If all the colours in the palette are greyscale and there is a
transparency chunk, it is treated as an intensity plus opacity texture.
. If any colour in the palette is not grey and there is no transparency
chunk, it is treated as a full RGB texture.
. If any colour in the palette is not grey and there is a transparency
chunk, it is treated as a full RGB plus alpha texture.

Texture nodes that require support for JPEG files (see
<<JPEG>>) shall interpret JPEG files as follows:

[loweralpha, start=9]
. Greyscale files (number of components equals 1) are treated as
intensity textures.
. YCbCr files are treated as full RGB textures.
. No other JPEG file types are required. It is recommended that other
JPEG files are treated as a full RGB textures.

Texture nodes that support MPEG files (see <<I11172_1, ISO/IEC 11172-1>>]) shall treat MPEG files as full RGB textures.

Texture nodes that recommend support for GIF files (see
<<GIF>>) shall follow the applicable semantics described above
for the PNG format.

Texture nodes that recommend support for Joint Photographic Experts
Group (JPEG) 2000, Geographic Tagged Image File Format (GeoTIFF),
National Imagery Transmission Format (NITF) or Basic Image Interchange
Format (BIIF) formats shall follow the applicable semantics described
above for the PNG format.

[[S18_TextureCoordinates]]
==== 18.2.3 Texture coordinates

Texture maps are defined in a 2D coordinate system (s, t) that ranges
from [0.0, 1.0] in both directions. The bottom edge of the image
corresponds to the S-axis of the texture map, and left edge of the image
corresponds to the T-axis of the texture map. The lower-left pixel of
the image corresponds to s=0, t=0, and the top-right pixel of the image
corresponds to s=1, t=1. Texture maps may be viewed as two dimensional
colour functions that, given an _(s, t)_ coordinate, return a colour
value _colour(s, t)_. These relationships are depicted in
<<f-TextureMapCoordSystem, Figure 18.1>>.

[[f-TextureMapCoordSystem]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ImageTexture.gif[Texture
map coord system,width=413,height=228]

Figure 18.1 — Texture map coordinate system

The texture map nodes <<ImageTexture>>,
<<MovieTexture>>, and <<PixelTexture>>
contain two fields, _repeatS_ and _repeatT_, that specify how the
texture wraps in the S and T directions. If _repeatS_ is `TRUE`
(the default), the texture map is repeated outside the [0.0, 1.0]
texture coordinate range in the S direction so that it fills the shape.
If _repeatS_ is `FALSE`, the texture coordinates are clamped in
the S direction to lie within the [0.0, 1.0] range. The _repeatT_ field
is analogous to the _repeatS_ field.

Textures nodes with a _textureProperties_ field allow fined grained
control of the texture setup including further modes for handling
clamping and repeating texture coordinates and specifying how a texture
should be filtered. Texture nodes with a provided
<<TextureProperties>> node shall ignore the
settings of _repeatS_ and _repeatT_ and shall use the provided values in
the _boundaryMode_ fields.

Each vertex-based geometry node (
_e.g._, <<IndexedFaceSet>> and
<<ElevationGrid>>) uses a set of 2D texture coordinates
that map textures to vertices. Texture coordinates for geometry nodes
are specified using the <<TextureCoordinate>> and
<<TextureCoordinateGenerator>> nodes.
Texture map values (ImageTexture, MovieTexture, and PixelTexture) range
from [0.0, 1.0] along the S-axis and T-axis. However, texture coordinate
values may be in the range (−∞,∞). Texture coordinates identify a
location (and thus a colour value) in the texture map. The horizontal
coordinate _s_ is specified first, followed by the vertical coordinate
_t_.

If the texture map is repeated in a given direction (S-axis or T-axis),
a texture coordinate C (s or t) is mapped into a texture map that has N
pixels in the given direction as follows:

[source,listing]
----
    Texture map location = (C − floor(C)) × N
----

If the texture map is not repeated, the texture coordinates are clamped
to the 0.0 to 1.0 range as follows:

[source,listing]
----
    Texture map location = N,     if C > 1.0,
                         = 0.0,   if C < 0.0,
                         = C × N, if 0.0 ≤ C ≤ 1.0.
----

Texture coordinates may be transformed (scaled, rotated, translated) by
supplying a <<TextureTransform>> node as a component
of the texture's containing <<Appearance>> node.

Details on repeating textures are specific to texture map node types
described in ImageTexture, MovieTexture, and PixelTexture.

Texture coordinates are reapplied (or else recomputed if initially NULL)
whenever the corresponding vertex-based geometry changes.

[[Multitexturing]]
==== 18.2.4 Multitexturing

Multiple textures may be applied to a single geometry node and blended
according to a predefined set of operations. This enables a variety of
visual effects that include light mapping and environment mapping.
Multiple textures may be applied using multi-stage or multi-pass
techniques, depending upon the available hardware. The number of
textures to be blended may have a significant impact on performance,
depending upon the available hardware.

<<f-Lightmapexample, Figure 18.2>> depicts an example of light
mapping, simulating a pre-lit object. Texture 2 is added on top of
texture 1.

[[f-Lightmapexample]]
Base Texture
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/MTimage002.gif[ Base Texture,width=128,height=128] +
Lightmap image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/MTimage004.jpg[ Plus
Lightmap,width=128,height=128] = Result
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/MTimage006.jpg[equals Result,width=128,height=128]

Figure 18.2 — Lightmap example

Multitexturing is accomplished using the
<<MultiTexture>>,
<<MultiTextureCoordinate>>, and
<<MultiTextureTransform>> nodes. MultiTexture
specifies a grouping of single textures and texture transformations.
MultiTextureCoordinate specifies a grouping of texture coordinates to be
used with the associated textures. MultiTextureTransform specifies a
grouping of texture transforms to be used with the associated textures.

<<t18_2, Table 18.2>> compares the usage
of single texture and multitexture attributes within
<<Appearance>> and geometry nodes.

[[t18_2]]
Table 18.2: Comparison of single
texture and multitexture attributes

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Texture Node appearance.texture |Texture Transform |Texture coordinate
geometry.texCoord |Texture mode
|*ImageTexture* \{ ...} |*appearance.textureTransform* +
*TextureTransform* \{} |*TextureCoordinate* \{ *coord* [ ] } |implicit
in lighting model: +
`["REPLACE" "MODULATE"]`

|*MultiTexture* \{ +
*texture* [ +
ImageTexture \{ ...} +
ImageTexture \{ ...} +
]} |*MultiTexture* \{ +
*textureTransform* [ +
TextureTransform \{ ...} +
TextureTransform \{ ...} +
]} |*MultiTextureCoordinate* \{ +
*coord* [ +
TextureCoordinate \{ coord [ ] }TextureCoordinate \{ coord [ ] } +
]} |*MultiTexture* \{ +
*mode* [.code]#[ +
"MODULATE" +
"MODULATE" +
]#}
|===

[[ProgrammableShaders]]
==== 18.2.5 Programmable shaders

If a programmable shader is defined for the <<Appearance>>
node containing textures, texture mapping shall be disabled. Textures
defined shall be considered as sources of input and/or output for a
programmable shader. See <<Perobjectattributes, 31.2.2.5 Per-object attributes>> for details on how to map textures to shader program inputs.


=== 18.3 Abstract types

[[X3DSingleTextureCoordinateNode]]
==== 18.3.1 _X3DSingleTextureCoordinateNode_

[source,node]
----
X3DSingleTextureCoordinateNode : X3DTextureCoordinateNode {
  SFString [in,out] mapping  ""
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all texture coordinate
nodes which specify texture coordinates for a single texture. See
<<TextureMapping, 12.2.4 Texture mapping specified in material nodes>>
for a description how it interacts with texture specification inside
materials.

This abstract type applies to all texture coordinate nodes except
<<MultiTextureCoordinate>>.

[[X3DSingleTextureNode]]
==== 18.3.2 _X3DSingleTextureNode_

[source,node]
----
X3DSingleTextureNode : X3DTextureNode {
  SFString [in,out] description       ""
  SFNode   [in,out] metadata          NULL [X3DMetadataObject]
  SFNode   []       textureProperties NULL [TextureProperties]
}
----

This abstract node type is the base type for all texture node types that
define a single texture. A single texture can be used to influence a
parameter of various material nodes in the <<shape_html, Shape component>>,
and it can be a child of <<MultiTexture>>.

This abstract type applies to all texture nodes except
<<MultiTexture>>.

The _textureProperties_ field allows fine control over a texture's
application, as described in <<S18_TextureCoordinates, 18.2.3 Texture coordinates>>.

[[X3DSingleTextureTransformNode]]
==== 18.3.3 _X3DSingleTextureTransformNode_

[source,node]
----
X3DSingleTextureTransformNode : X3DTextureTransformNode {
  SFString [in,out] mapping  ""
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all texture transform nodes
which specify texture coordinate transformation for a single texture.
See <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>> for a description how it interacts with texture specification
inside materials.

This abstract type applies to all texture transformation nodes except
<<MultiTextureTransform>>.

[[X3DTexture2DNode]]
==== 18.3.4 _X3DTexture2DNode_

[source,node]
----
X3DTexture2DNode : X3DSingleTextureNode {

  SFString [in,out] description       ""
  SFNode   [in,out] metadata          NULL [X3DMetadataObject]
  SFBool   []       repeatS           TRUE
  SFBool   []       repeatT           TRUE
  SFNode   []       textureProperties NULL [TextureProperties]
}
----

This abstract node type is the base type for all node types which
specify 2D sources for texture images.

[[X3DTextureCoordinateNode]]
==== 18.3.5 _X3DTextureCoordinateNode_

[source,node]
----
X3DTextureCoordinateNode : X3DGeometricPropertyNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all node types which
specify texture coordinates. It adds a new geometric property node type
to those specified in <<rendering_html, 11 Rendering component>>.

[[X3DTextureNode]]
==== 18.3.6 _X3DTextureNode_

[source,node]
----
X3DTextureNode : X3DAppearanceChildNode {
  SFString [in,out] description ""
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all node types which
specify sources for texture images.

The _description_ field provides textual information about the image
data.

[[X3DTextureTransformNode]]
==== 18.3.7 _X3DTextureTransformNode_

[source,node]
----
X3DTextureTransformNode : X3DAppearanceChildNode { 
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base type for all node types which
specify a transformation of texture coordinates.


=== 18.4 Node reference

[[ImageTexture]]
==== 18.4.1 ImageTexture

[source,node]
----
ImageTexture : X3DTexture2DNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0    [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0 [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL   [X3DMetadataObject]
  MFString [in,out] url                  []     [URI]
  SFBool   []       repeatS              TRUE 
  SFBool   []       repeatT              TRUE
  SFNode   []       textureProperties    NULL   [TextureProperties]
}
----

The ImageTexture node defines a texture map by specifying an image file
and general parameters for mapping to geometry.

The texture is read from the URL specified by the _url_ field. When the
_url_ field contains no values ([]), texturing is disabled. X3D browsers
shall support the JPEG (see <<JPEG, 2. JPEG>>) and PNG
(see <<I15948, ISO/IEC 15948>>) image file formats. In addition, X3D
browsers may support other image formats (`EXAMPLE` CGM,
<<I8632, ISO/IEC 8632>>) that can be rendered into a 2D image. Support
for the GIF format (see <<GIF>>) is also recommended (including
transparency). Details on the _url_ field can be found in
<<URLs, 9.2.1 URLs, URNs and URIs>>.

See <<S18_Concepts, 18.2 Concepts>>, for a general description of texture
maps.

See <<lighting_html, 17 Lighting component>> for a description of
lighting equations and the interaction between textures, materials, and
geometry appearance.

[[MovieTexture]]
==== 18.4.2 MovieTexture

[source,node]
----
MovieTexture : X3DTexture2DNode, X3DSoundSourceNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0    [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0 [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] enabled              TRUE
  SFInt32  [in,out] gain                 1      [-∞,∞)
  SFBool   [in,out] load                 TRUE
  SFBool   [in,out] loop                 FALSE
  SFNode   [in,out] metadata             NULL   [X3DMetadataObject]
  SFTime   [in,out] pauseTime            0      (-∞,∞)
  SFFloat  [in,out] pitch                1.0    (0,∞)
  SFTime   [in,out] resumeTime           0      (-∞,∞)
  SFFloat  [in,out] speed                1.0    (-∞,∞)
  SFTime   [in,out] startTime            0      (-∞,∞)
  SFTime   [in,out] stopTime             0      (-∞,∞)
  MFString [in,out] url                  []     [URI]
  SFTime   [out]    duration_changed   
  SFTime   [out]    elapsedTime   
  SFBool   [out]    isActive   
  SFBool   [out]    isPaused   
  SFBool   []       repeatS              TRUE
  SFBool   []       repeatT              TRUE
  SFNode   []       textureProperties    NULL   [TextureProperties]
}
----

The MovieTexture node defines a time dependent texture map (contained in
a movie file) and parameters for controlling the movie and the texture
mapping. A MovieTexture node can also be used as the source of sound
data for a <<Sound>> node. In this special case, the
MovieTexture node is not used for rendering.

The _url_ field that defines the movie data shall support MPEG1-Systems
(audio and video) or MPEG1-Video (video-only) movie file formats as
defined in <<I11172_1, ISO/IEC 11172-1>>. Details on the _url_ field
can be found in <<URLs, 9.2.1 URLs, URNs and URIs>>.

MovieTexture nodes can be referenced by an <<Appearance>>
node's _texture_ field (as a movie texture) and by a <<Sound>>
node's _source_ field (as an audio source only).

As soon as the movie is loaded, a _duration_changed_ field is sent. This
indicates the duration of the movie in seconds. This field value can be
read (for instance, by a <<Script>> node) to determine the
duration of a movie. A value of "-1" implies the movie has not yet
loaded or the value is unavailable for some reason.

The cycle of a MovieTexture node is the length of time in seconds for
one playing of the movie at the specified _speed_.

The _pitch_ field specifies a multiplier for the rate at which sampled
sound is played. Values for the _pitch_ field shall be greater than
zero. Changing the _pitch_ field affects both the pitch and playback
speed of a sound. A _set_pitch_ event to an active MovieTexture node is
ignored and no _pitch_changed_ field is generated. If _pitch_ is set to
2.0, the sound shall be played one octave higher than normal and played
twice as fast. For a sampled sound, the _pitch_ field alters the
sampling rate at which the sound is played. The proper implementation of
pitch control for MIDI (or other note sequence sound clips) is to
multiply the tempo of the playback by the _pitch_ value and adjust the
MIDI Coarse Tune and Fine Tune controls to achieve the proper pitch
change.

A _duration_changed_ event is sent whenever there is a new value for the
"normal" duration of the clip. Typically, this will only occur when the
current _url_ in use changes and the sound data has been loaded,
indicating that the clip is playing a different sound source. The
duration is the length of time in seconds for one cycle of the audio for
a _pitch_ set to 1.0. Changing the _pitch_ field will not trigger a
_duration_changed_ event. A duration value of "−1" implies that the
sound data has not yet loaded or the value is unavailable for some
reason. A _duration_changed_ event shall be generated if the
MovieTexture node is loaded when the X3D file is read or the
MovieTexture node is added to the scene graph.

The _speed_ field indicates how fast the movie shall be played. A
_speed_ of 2 indicates the movie plays twice as fast. The
_duration_changed_ output is not affected by the _speed_ field.
_set_speed_ events are ignored while the movie is playing. A negative
_speed_ implies that the movie will play backwards.

If a MovieTexture node is inactive when the movie is first loaded, frame
0 of the movie texture is displayed if _speed_ is non-negative or the
last frame of the movie texture is shown if _speed_ is negative (see
<<Time-dependent, 8.2.4 Time-dependent nodes>>). A MovieTexture node
shall display frame 0 if _speed_ = 0. For positive values of _speed_, an
active MovieTexture node displays the frame at movie time _t_ as follows
( _i.e._, in the movie's local time system with frame 0 at time 0 with
_speed_ = 1):

[source,listing]
----
    t = (now − startTime) modulo (duration/speed)
----

If _speed_ is negative, the MovieTexture node displays the frame at
movie time:

[source,listing]
----
    t = duration - ((now - startTime) modulo |duration/speed|)
----

When a MovieTexture node becomes inactive, the frame corresponding to
the time at which the MovieTexture became inactive will remain as the
texture.

See <<S18_Concepts, 18.2 Concepts>>, for a general description of texture
maps.

<<lighting_html, 17 Lighting component>> contains details on lighting
equations and the interaction between textures, materials, and
geometries.

[[MultiTexture]]
==== 18.4.3 MultiTexture

[source,node]
----
MultiTexture : X3DTextureNode {
  SFFloat  [in,out] alpha       1     [0,1]
  SFColor  [in,out] color       1 1 1 [0,1]
  SFString [in,out] description ""
  MFString [in,out] function    []
  SFNode   [in,out] metadata    NULL  [X3DMetadataObject]
  MFString [in,out] mode        []
  MFString [in,out] source      []
  MFNode   [in,out] texture     []    [X3DSingleTextureNode]
}
----

The MultiTexture node specifies the application of several individual
textures to a 3D object to achieve a more complex visual effect.
MultiTexture can be used as a value for the texture field in an
<<Appearance>> node.

The _texture_ field contains a list of texture nodes ( _e.g._,
<<ImageTexture>>, <<PixelTexture>>, and
<<MovieTexture>>). The texture field may not contain
another MultiTexture node.

The _color_ and _alpha_ fields define base RGB and alpha values for
`SELECT` mode operations.

The _mode_ field controls the type of blending operation. The available
mode values are shown in <<t18_3, Table 18.3>> and
include `MODULATE` for a lit Appearance, REPLACE for
an unlit Appearance, and several variations of the two. The value chosen
for the _mode_ field may also specify the blending mode for the alpha
channel.

EXAMPLE  The mode value '"`MODULATE","REPLACE`"' specifies Color
= (Arg1.color × Arg2.color, Arg1.alpha).

The number of used texture stages is determined by the length of the
texture field. If there are fewer mode values, the default mode is
"`MODULATE`".

[[t18_3]]
Table 18.3 — Multitexture values for _mode_
field

[width="100%",cols="50%,50%",options="header",]
|===
|_mode_ value |Description
|`"MODULATE"` |Multiply texture color with current color +
Arg1 × Arg2

|`"REPLACE"` |Replace current color +
Arg2

|`"MODULATE2X"` |Multiply the components of the arguments, and
shift the products to the left 1 bit (effectively multiplying them by 2)
for brightening.

|`"MODULATE4X"` |Multiply the components of the arguments, and
shift the products to the left 2 bits (effectively multiplying them by
4) for brightening.

|`"ADD"` |Add the components of the arguments +
Arg1 + Arg2

|`"ADDSIGNED"` |Add the components of the arguments with a -0.5
bias, making the effective range of values from −0.5 through 0.5.

|`"ADDSIGNED2X"` |Add the components of the arguments with a -0.5
bias, and shift the products to the left 1 bit.

|`"SUBTRACT"` |Subtract the components of the second argument
from those of the first argument. +
Arg1 − Arg2

|`"ADDSMOOTH"` |Add the first and second arguments, then subtract
their product from the sum. +
Arg1 + Arg2 − Arg1 × Arg2 = Arg1 + (1 − Arg1) × Arg2

|`"BLENDDIFFUSEALPHA"` |Linearly blend this texture stage, using
the interpolated alpha from each vertex. +
Arg1 × (Alpha) + Arg2 × (1 − Alpha)

|`"BLENDTEXTUREALPHA"` |Linearly blend this texture stage, using
the alpha from this stage's texture. +
Arg1 × (Alpha) + Arg2 × (1 − Alpha)

|`"BLENDFACTORALPHA"` |Linearly blend this texture stage, using
the alpha factor from the MultiTexture node. +
Arg1 × (Alpha) + Arg2 × (1 − Alpha)

|`"BLENDCURRENTALPHA"` |Linearly blend this texture stage, using
the alpha taken from the previous texture stage. +
Arg1 × (Alpha) + Arg2 × (1 − Alpha)

|`"MODULATEALPHA_ADDCOLOR"` |Modulate the color of the second
argument, using the alpha of the first argument; then add the result to
argument one. +
Arg1.RGB + Arg1.A × Arg2.RGB

|`"MODULATEINVALPHA_ADDCOLOR"` |Similar to
MODULATEALPHA_ADDCOLOR, but use the inverse of the alpha of the first
argument. +
(1 − Arg1.A) × Arg2.RGB + Arg1.RGB

|`"MODULATEINVCOLOR_ADDALPHA"` |Similar to
MODULATECOLOR_ADDALPHA, but use the inverse of the color of the first
argument. +
(1 − Arg1.RGB) × Arg2.RGB + Arg1.A

|`"OFF"` |Turn off the texture unit

|`"SELECTARG1"` |Use color argument 1 +
Arg1

|`"SELECTARG2"` |Use color argument 1 +
Arg2 

|`"DOTPRODUCT3"` |Modulate the components of each argument (as
signed components), add their products, then replicate the sum to all
color channels, including alpha. +
This can do either diffuse or specular bump mapping with correct input.
Performs the function (Arg1.R × Arg2.R + Arg1.G × Arg2.G + Arg1.B ×
Arg2.B) where each component has been scaled and offset to make it
signed. The result is replicated into all four (including alpha)
channels.
|===

The _source_ field determines the colour source for the second argument.
<<t18_4, Table 18.4>> lists valid values for the
_source_ field. Typically, there are the same number of _source_ field
values as textures. Otherwise, the default _source_ field value is used.

[[t18_4]]
Table 18.4 — MultiTexture values for
_source_ field

[cols=",",options="header",]
|===
|_source_ value |Description
|`""` (empty string) |The second argument color (ARG2) is the
color from the previous rendering stage (DIFFUSE for first stage).

|`"DIFFUSE"` |The texture argument is the diffuse color
interpolated from vertex components during Gouraud shading.

|`"SPECULAR"  ` |The texture argument is the specular color
interpolated from vertex components during Gouraud shading.

|`"FACTOR"` |The texture argument is the factor (color, alpha)
from the texture provided for the current stage of the MultiTexture
node.
|===

The _function_ field defines an optional function to be applied to the
argument after the mode has been evaluated.
<<t18_5, Table 18.5>> lists valid values for the
_function_ field. Typically, there are the same number of _function_
field values as textures. Otherwise, the default _function_ field value
is used.

[[t18_5]]
Table 18.5 — MultiTexture values for
_function_ field

[cols=",",options="header",]
|===
|_function_ value |Description
|"" (empty string) |No function is applied.

|`"COMPLEMENT"` |Invert the argument so that, if the result of
the argument were referred to by the variable x, the value would be 1.0
minus x.

|`"ALPHAREPLICATE"` |Replicate the alpha information to all color
channels before the operation completes.
|===

[[MultiTextureCoordinate]]
==== 18.4.4 MultiTextureCoordinate

[source,node]
----
MultiTextureCoordinate : X3DTextureCoordinateNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
  MFNode [in,out] texCoord NULL [X3DSingleTextureCoordinateNode]
}
----

MultiTextureCoordinate supplies multiple texture coordinates per vertex.
This node can be used to set the texture coordinates for the different
texture channels. It can be used to provide texture coordinates:

* For the texture specified in the _Appearance.texture_ field. This
includes a _MultiTexture_ node. In this case the order of the texture
coordinates shall match the order of texture nodes within the
_MultiTexture.texture_ list.
* For any texture specified within material nodes using fields like
_Material.diffuseTexture_, _PhysicalMaterial.baseTexture_. In this case,
the _mapping_ field of the child
<<X3DSingleTextureCoordinateNode>>
node shall correspond to the appropriate _xxxTextureMapping_ value in
the material. See <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>> for details.

Each entry in the texCoord field may contain a
<<TextureCoordinate>>,
<<TextureCoordinateGenerator>> or other
<<X3DSingleTextureCoordinateNode>>
descendant node.

Example:

[source,listing]
----
Shape { 
  appearance Appearance { 
    texture MultiTexture {  
      mode [ "MODULATE" "MODULATE" ] 
      texture [ 
        ImageTexture { url "brick.jpg")  
        ImageTexture { repeatS FALSE repeatT FALSE url "light_gray.png"} 
      ]
    }
  }
  geometry IndexedFaceSet {  
      ... 
    texCoord MultiTextureCoordinate {
      texCoord [ 
        TextureCoordinate { ... } 
        TextureCoordinate { ... } 
      ] 
    }
  }
}
----

Using a _MultiTextureCoordinate_ with exactly one child is always
equivalent to using this child directly. That is, these two constructs
(in X3D classic encoding) are _exactly equivalent_ for the purpose of
texture coordinate determination:

. {blank}
+
[source,listing]
----
IndexedFaceSet {
  texCoord TextureCoordinate {
    point [ 0 0, 1 1 ]
  }
}
----
. {blank}
+
[source,listing]
----
IndexedFaceSet {
  texCoord MultiTextureCoordinate {
    texCoord [
      TextureCoordinate {
        point [ 0 0, 1 1 ]
      }
    ]
  }
}
----

When the _MultiTexture_ node is used in _Appearance.texture_ field, and
there is not enough texture coordinates in the _MultiTextureCoordinate_,
texture coordinates for the last channel are replicated along the other
channels.

[[MultiTextureTransform]]
==== 18.4.5 MultiTextureTransform

[source,node]
----
MultiTextureTransform : X3DTextureTransformNode { 
  SFNode [in,out] metadata         NULL [X3DMetadataObject]
  MFNode [in,out] textureTransform NULL [X3DSingleTextureTransformNode]
}
----

MultiTextureTransform supplies multiple texture transforms per
appearance. This node can be used to set the texture transform for each
of the different texture channels. It can be used to transform texture
coordinates:

* For the texture specified in the _Appearance.texture_ field. This
includes a _MultiTexture_ node. In this case the order of the texture
transformations shall match the order of texture nodes within the
_MultiTexture.texture_ list.
* For any texture specified within material nodes using fields like
_Material.diffuseTexture_, _PhysicalMaterial.baseTexture_. In this case,
the _mapping_ field of the child
<<X3DSingleTextureTransformNode>> node
shall correspond to the appropriate _xxxTextureMapping_ value in the
material. See <<TextureMapping, 12.2.4 Texture mapping specified in material nodes>> for details.

Each entry in the _textureTransform_ field shall contain an
<<X3DSingleTextureTransformNode>> or
`NULL`.

Example:

[source,listing]
----
Shape { 
  appearance Appearance { 
    texture MultiTexture {  
      mode [ "MODULATE" "MODULATE" ] 
      texture [ 
        ImageTexture { url "brick.jpg")  
        ImageTexture { repeatS FALSE repeatT FALSE url "light_gray.png"} 
      ]
    }

    textureTransform MultiTextureTransform {
      textureTransform [  
    TextureTransform {}  
    TextureTransform { scale 0.5 0.5 } 
      ]
    } 
  }
}
----

Note that we treat a <<MultiTextureTransform>>
with a single child always the same as using this child directly. That,
is these two constructs are equivalent, for the purpose of texture
transformation determination:

. {blank}
+
[source,listing]
----
Appearance {
  textureTransform TextureTransform {
    scale 10 10
  }
}
----
. {blank}
+
[source,listing]
----
Appearance {
  textureTransform MultiTextureTransform {
    textureTransform [
      TextureTransform {
        scale 10 10
      }
    ]
  }
}
      
----

When the _MultiTexture_ node is used in _Appearance.texture_ field, and
there is not enough texture coordinates in the _MultiTextureTransform_,
identity matrices (no transformation) shall be used for all remaining
channels.

[[PixelTexture]]
==== 18.4.6 PixelTexture

[source,node]
----
PixelTexture : X3DTexture2DNode {
  SFString [in,out] description       ""
  SFImage  [in,out] image             0 0 0
  SFNode   [in,out] metadata          NULL  [X3DMetadataObject]
  SFBool   []       repeatS           TRUE
  SFBool   []       repeatT           TRUE
  SFNode   []       textureProperties NULL  [TextureProperties]
}
----

The PixelTexture node defines a 2D image-based texture map as an
explicit array of pixel values ( _image_ field) and parameters
controlling tiling repetition of the texture onto geometry.

The _repeatS_ and _repeatT_ fields specify how the texture wraps in the
S and T directions. If _repeatS_ is `TRUE` (the default), the
texture map is repeated outside the 0-to-1 texture coordinate range in
the S direction so that it fills the shape. If _repeatS_ is
`FALSE`, the texture coordinates are clamped in the S direction
to lie within the 0.0 to 1.0 range. The _repeatT_ field is analogous to
the _repeatS_ field.

See <<S18_Concepts, 18.2 Concepts>>, for a general description of texture
maps.

See <<lighting_html, 17 Lighting component>> for a description of how
the texture values interact with the appearance of the geometry.
<<SFImageAndMFImage, 5.7 SFImage and MFImage>> describes the
specification of an image.

[[TextureCoordinate]]
==== 18.4.7 TextureCoordinate

[source,node]
----
TextureCoordinate : X3DSingleTextureCoordinateNode {
  SFString [in,out] mapping  ""
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
  MFVec2f  [in,out] point    []   (-∞,∞)
}
----

The TextureCoordinate node is a geometry property node that specifies a
set of 2D texture coordinates used by vertex-based geometry nodes
(EXAMPLE  <<IndexedFaceSet>> and
<<ElevationGrid>>) to map textures to vertices.

[[TextureCoordinateGenerator]]
==== 18.4.8 TextureCoordinateGenerator

[source,node]
----
TextureCoordinateGenerator : X3DSingleTextureCoordinateNode {
  SFString [in,out] mapping   ""
  SFNode   [in,out] metadata  NULL     [X3DMetadataObject]
  SFString [in,out] mode      "SPHERE" (see Table 18.6)
  MFFloat  [in,out] parameter []       (see Table 18.6)
}
----

TextureCoordinateGenerator supports the automatic generation of texture
coordinates for geometric shapes.

This node can be used to set the texture coordinates for a node with a
texCoord field.

_The mode_ field describes the algorithm used to compute texture
coordinates, as depicted in <<t18_6, Table 18.6>>.

[[t18_6]]
Table 18.6 — Texture coordinate generation
modes

[width="100%",cols="50%,50%",options="header",]
|===
|_mode_ value |Description
|`"SPHERE"` |Creates texture coordinates for a spherical
environment or "chrome" mapping based on the vertex normals transformed
to camera space. +
u = Nx/2 + 0.5 +
v = Ny/2 + 0.5 +
where u and v are the texture coordinates being computed, and Nx and Ny
are the x and y components of the camera-space vertex normal. If the
normal has a positive x component, the normal points to the right, and
the u coordinate is adjusted to address the texture appropriately.
Likewise for the v coordinate: positive y indicates that the normal
points up. The opposite is of course true for negative values in each
component. If the normal points directly at the camera, the resulting
coordinates should receive no distortion. The +0.5 bias to both
coordinates places the point of zero-distortion at the center of the
sphere map, and a vertex normal of (0, 0, z) addresses this point. Note
that this formula does not take account for the z component of the
normal.

|`"CAMERASPACENORMAL"` |Use the vertex normal, transformed to
camera space, as input texture coordinates, resulting coordinates are in
−1 to 1 range.

|`"CAMERASPACEPOSITION"` |Use the vertex position, transformed to
camera space, as input texture coordinates

|`"CAMERASPACEREFLECTIONVECTOR"` |Use the reflection vector,
transformed to camera space, as input texture coordinates. The
reflection vector is computed from the input vertex position and normal
vector. +
R=2 × DotProd(E,N) × N − E; +
In the preceding formula, R is the reflection vector being computed, E
is the normalized position-to-eye vector, and N is the camera-space
vertex normal. +
Resulting coordinates are in −1 to 1 range.

|`"SPHERE-LOCAL"` |Sphere mapping but in local coordinates

|`"COORD"` |use vertex coordinates

|`"COORD-EYE"` |use vertex coordinates transformed to camera
space

|`"NOISE"` |computed by applying Perlin solid noise function on
vertex coordinates, parameter contains scale and translation [scale.x
scale.y scale.z translation.x translation.y translation.z]

|`"NOISE-EYE"` |same as above but transform vertex coordinates to
camera space first

|`"SPHERE-REFLECT"` a|
similar to "CAMERASPACEREFLECTIONVECTOR" with optional index of
refraction, parameter[0] contains index of refraction

Resulting coordinates are in −1 to 1 range.

|`"SPHERE-REFLECT-LOCAL"` |Similar to "SPHERE-REFLECT",
parameter[0] contains index of refraction, parameter[1 to 3] the eye
point in local coordinates. By animating parameter [1 to 3] the
reflection changes with respect to the point. +
Resulting coordinates are in −1 to 1 range.
|===

Some modes may be hardware accelerated. Some modes are view dependent.

[[TextureProperties]]
==== 18.4.9 TextureProperties

[source,node]
----
TextureProperties : X3DNode
  SFFloat     [in,out] anisotropicDegree   1.0       [1,∞)
  SFColorRGBA [in,out] borderColor         0 0 0 0   [0,1] (deprecated v4.0)
  SFInt32     [in,out] borderWidth         0         [0,1] (deprecated v4.0)
  SFString    [in,out] boundaryModeR       "REPEAT"  (see Table 18.7)
  SFString    [in,out] boundaryModeS       "REPEAT"  (see Table 18.7)
  SFString    [in,out] boundaryModeT       "REPEAT"  (see Table 18.7)
  SFString    [in,out] magnificationFilter "DEFAULT" (see Table 18.8)
  SFNode      [in,out] metadata            NULL      [X3DMetadataObject]
  SFString    [in,out] minificationFilter  "DEFAULT" (see Table 18.9)
  SFString    [in,out] textureCompression  "DEFAULT" (see Table 18.10)
  SFFloat     [in,out] texturePriority     0         [0,1]
  SFBool      []       generateMipMaps     FALSE
}
----

TextureProperties allows fine control over a texture's application.

This node can be used to set the texture properties for a node with a
_textureProperties_ field. A texture with a TextureProperties node will
ignore the _repeatS_ and _repeatT_ fields on the texture.

_The anisotropicDegree_ field describes the minimum degree of anisotropy
to account for in texture filtering. A value of 1 implies no anisotropic
filtering. Values above the system's maximum supported value will be
clamped to the maximum allowed. X3D browsers are allowed to use higher
values as deemed appropriate.

The _borderColor_ field (deprecated v4.0) describes the color to use for
border pixels.

The _borderWidth_ field (deprecated v4.0) describes the number of pixels
to use for a texture border.

The _boundaryModeS_ field describes the way S texture coordinate
boundaries are handled, as depicted in
<<t18_7, Table 18.7>>.

The _boundaryModeT_ field describes the way T texture coordinate
boundaries are handled, as depicted in
<<t18_7, Table 18.7>>.

The _boundaryModeR_ field describes the way R texture coordinate
boundaries are handled, as depicted in
<<t18_7, Table 18.7>>. This field only applies to
three dimensional textures and shall be ignored by other texture types.

The _magnificationFilter_ field describes the way textures are filtered
when the image is smaller than the screen space representation. Valid
values are depicted in <<t18_8, Table 18.8>>.

The _minificationFilter_ field describes the way textures are filtered
when the image is larger than the screen space representation. Valid
values are depicted in <<t18_9, Table 18.9>>.
Modes with MIPMAP in the name require mipmaps. If mipmaps are not
provided, the mode shall pick the corresponding non-mipmapped mode (
_e.g._, `AVG_PIXEL_NEAREST_MIPMAP` becomes `AVG_PIXEL`).

The _texturePriority_ field describes the texture residence priority for
allocating texture memory. Zero indicates the lowest priority and 1
indicates the highest priority. Values are clamped to the range [0,1].

The _textureCompression_ field specifies the preferred image compression
method to be used during rendering. Valid values are depicted in
<<t18_10, Table 18.10>>.

The _generateMipMaps_ field describes whether mipmaps should be
generated for the texture. Mipmaps are required for filtering modes with
MIPMAP in their value.

[[t18_7]]
Table 18.7 — Texture boundary modes

[width="100%",cols="50%,50%",options="header",]
|===
|boundary mode value |Description
|`"CLAMP"` |Clamp texture coordinates to the range [0,1]

|`"CLAMP_TO_EDGE"` |Clamp texture coordinates such that a border
texel is never sampled. +
Coordinates are clamped to the range [1/(2N), 1 - 1/(2N)], where N is
the size of the texture in the direction of clamping.

|`"CLAMP_TO_BOUNDARY"` |Clamp texture coordinates such that
texture samples are border texels for fragments +
whose corresponding texture coordinate is sufficiently outside the range
[0,1]. +
Texture coordinates are clamped to the range [-1/(2N), 1 + 1/(2N)].

|`"MIRRORED_REPEAT"` |Texture coordinates are mirrored and then
clamped as in CLAMP_TO_EDGE

|`"REPEAT"` |Repeat a texture across the fragment. Ignore the
integer part of the texture coordinates, using only the fractional part.
|===

[[t18_8]]
Table 18.8 — Texture magnification
modes

[cols=",",options="header",]
|===
|magnificationFilter value |Description
|`"AVG_PIXEL"` |Select the weighted average of the four texture
elements that are closest to the center of the pixel being textured.

|`"DEFAULT"` |Select the X3D browser-specified default
magnification mode.

|`"FASTEST"` |Select the fastest method available.

|`"NEAREST_PIXEL"` |Select the texture element that is nearest to
the center of the pixel being textured.

|`"NICEST"` |Select the highest quality method available.
|===

[[t18_9]]
Table 18.9 — Texture minification modes

[cols=",",options="header",]
|===
|minificationFilter value |Description
|`"AVG_PIXEL"` |Select the weighted average of the four texture
elements that are closest to the center of the pixel being textured.

|`"AVG_PIXEL_AVG_MIPMAP"` |Performs tri-linear filtering. Choose
the two mipmaps that most closely match the size of the pixel being
textured and use the weighted average of the four texture elements that
are closest to the center of the pixel to produce a texture value from
each mipmap. The final texture value is a weighted average of those two
values.

|`"AVG_PIXEL_NEAREST_MIPMAP"` |Choose the mipmap that most
closely matches the size of the pixel being textured and use the
weighted average of the four texture elements that are closest to the
center of the pixel to produce a texture value.

|`"DEFAULT"` |Select the X3D browser-specified default
minification mode.

|`"FASTEST"` |Select the fastest method available. Mipmaps shall
be used, if available.

|`"NEAREST_PIXEL"` |Select the texture element that is nearest to
the center of the pixel being textured.

|`"NEAREST_PIXEL_AVG_MIPMAP"` |Choose the two mipmaps that most
closely match the size of the pixel being textured and use the texture
element nearest to the center of the pixel to produce a texture value
from each mipmap. The final texture value is a weighted average of those
two values.

|`"NEAREST_PIXEL_NEAREST_MIPMAP"` |Choose the mipmap that most
closely matches the size of the pixel being textured and use the texture
element nearest to the center of the pixel) to produce a texture value.

|`"NICEST"` |Select the highest quality method available. Mipmaps
shall be used, if available.
|===

[[t18_10]]
Table 18.10 — Texture compression modes

[cols=",",options="header",]
|===
|textureCompression value |Description
|`"DEFAULT"` |Select the X3D browser-specified default
compression mode.

|`"FASTEST"` |Select the fastest compression mode available.

|`"HIGH"` |Select the compression mode with the greatest amount
of compression.

|`"LOW"` |Select the compression mode with the least amount of
compression.

|`"MEDIUM"` |Select a compression mode with a moderate amount of
compression.

|`"NICEST"` |Select the compression mode that produces the
highest quality effect.
|===

[[TextureTransform]]
==== 18.4.10 TextureTransform

[source,node]
----
TextureTransform : X3DSingleTextureTransformNode {
  SFVec2f  [in,out] center      0 0  (-∞,∞)
  SFString [in,out] mapping     ""
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
  SFFloat  [in,out] rotation    0    (-∞,∞)
  SFVec2f  [in,out] scale       1 1  (-∞,∞)
  SFVec2f  [in,out] translation 0 0  (-∞,∞)
}
----

The TextureTransform node defines a 2D transformation that is applied to
texture coordinates (see <<TextureCoordinate>>).
This node affects the way textures coordinates are applied to the
geometric surface. The transformation consists of (in order):

[loweralpha]
. a translation;
. a rotation about the centre point;
. a non-uniform scale about the centre point.

These parameters support changes to the size, orientation, and position
of textures on shapes. Note that these operations appear reversed when
viewed on the surface of geometry. For example, a _scale_ value of (2 2)
will scale the texture coordinates and have the net effect of shrinking
the texture size by a factor of 2 (texture coordinates are twice as
large and thus cause the texture to repeat). A translation of (0.5 0.0)
translates the texture coordinates +.5 units along the S-axis and has
the net effect of translating the texture −0.5 along the S-axis on the
geometry's surface. A rotation of π/2 of the texture
coordinates results in a −π/2 rotation of the texture on the
geometry.

The _center_ field specifies a translation offset in texture coordinate
space about which the _rotation_ and _scale_ fields are applied. The
_scale_ field specifies a scaling factor in S and T of the texture
coordinates about the _center_ point. _scale_ values shall be in the
range (−∞,∞). The _rotation_ field specifies a rotation in angle base
units of the texture coordinates about the _center_ point after the
scale has been applied. A positive rotation value makes the texture
coordinates rotate counterclockwise about the centre, thereby rotating
the appearance of the texture itself clockwise. The _translation_ field
specifies a translation of the texture coordinates.

In matrix transformation notation, where _Tc_ is the untransformed
texture coordinate, _Tc'_ is the transformed texture coordinate, _C_ (
_center_), _T_ ( _translation_), _R_ ( _rotation_), and _S_ ( _scale_)
are the intermediate transformation matrices,

[source,listing]
----
    Tc' = −C × S × R × C × T × Tc
----

NOTE  This transformation order is the reverse of the
<<Transform>> node transformation order since the texture
coordinates, not the texture, are being transformed ( _i.e._, the
texture coordinate system).

[[S18.5_SupportLevels]]
=== 18.5 Support levels

The Texturing component provides three levels of support as specified in
<<t18_7, Table 18.7>>.

[[t18_11]]
Table 18.11 — Texturing component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | |
| | |_X3DSingleTextureCoordinateNode_ (abstract) |n/a
| | |_X3DSingleTextureNode_ (abstract) |n/a
| | |_X3DSingleTextureTransformNode_ (abstract) |n/a
| | |_X3DTextureCoordinateNode_ (abstract) |n/a
| | |_X3DTextureNode_ (abstract) |n/a
| | |_X3DTexture2DNode_ (abstract) |n/a
| | |_X3DTextureTransformNode_ (abstract) |n/a
| | |ImageTexture |All fields fully supported.
| | |PixelTexture |All fields fully supported.
| | |TextureCoordinate |All fields fully supported.
|  |  |TextureTransform |All field fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | | 
| |  |All Level 1 Texturing nodes |All fields as supported in Level 1.
| | |MultiTextureCoordinate |All fields fully supported.
|  |  |MultiTextureTransform |All fields fully supported.
| | |TextureCoordinateGenerator |All fields fully supported.
|  |  |TextureProperties |All fields fully supported.
|*3* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | | 
| | |All Level 2 Texturing nodes |All fields as supported in Level 2.
| | |MultiTexture |All fields fully supported.
|*4* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | | 
| | |All Level 3 Texturing nodes |All fields as supported in Level 3.
| | |MovieTexture |All fields fully supported.
|===

[[interpolators_html]]
== 19 Interpolation component

[[S19_Introduction]]
=== 19.1 Introduction

[[S19_Name]]
==== 19.1.1 Name

The name of this component is "Interpolation". This name shall be used
when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S19_Overview]]
==== 19.1.2 Overview

This subclause describes the Interpolation component of this document.
<<t19_1, Table 19.1>> provides links to the major topics in this
subclause.

[[t19_1]]
Table 19.1 — Topics

* <<S19Introduction, 19.1 Introduction>>
** <<S19_Name, 19.1.1 Name>>
** <<S19_Overview, 19.1.2 Overview>>
* <<S19_Concepts, 19.2 Concepts>>
** <<Interpolators, 19.2.1 Interpolators>>
** <<Linearinterpolation, 19.2.2 Linear interpolation>>
** <<NonlinearInterpolation, 19.2.3 Non-linear interpolation>>
** <<HermiteSplineInterpolation, 19.2.4 Hermite spline interpolation>>
* <<S19_AbstractTypes, 19.3 Abstract types>>
** <<X3DInterpolatorNode, 19.3.1 _X3DInterpolatorNode_>>
* <<S19_NodeReference, 19.4 Node reference>>
** <<ColorInterpolator, 19.4.1 ColorInterpolator>>
** <<CoordinateInterpolator, 19.4.2 CoordinateInterpolator>>
** <<CoordinateInterpolator2D, 19.4.3 CoordinateInterpolator2D>>
** <<EaseInEaseOut, 19.4.4 EaseInEaseOut>>
** <<NormalInterpolator, 19.4.5 NormalInterpolator>>
** <<OrientationInterpolator, 19.4.6 OrientationInterpolator>>
** <<PositionInterpolator, 19.4.7 PositionInterpolator>>
** <<PositionInterpolator2D, 19.4.8 PositionInterpolator2D>>
** <<ScalarInterpolator, 19.4.9 ScalarInterpolator>>
** <<SplinePositionInterpolator, 19.4.10 SplinePositionInterpolator>>
** <<SplinePositionInterpolator2D, 19.4.11 SplinePositionInterpolator2D>>
** <<SplineScalarInterpolator, 19.4.12 SplineScalarInterpolator>>
** <<SquadOrientationInterpolator, 19.4.13 SquadOrientationInterpolator>>
* <<S19_SupportLevels, 19.5 Support levels>>

* <<t19_1, Table 19.1 — Topics>>
* <<t19_2, Table 19.2 — Interpolation component support levels>>

* <<f-EaseInEaseOut, Figure 19.1 — EaseInEaseOut algorithm illustration>>




[[S19_Concepts]]
=== 19.2 Concepts

This clause includes six Interpolator nodes all of which provide
keyframe-based animation capability.

[[Interpolators]]
==== 19.2.1 Interpolators

The Interpolator nodes provide interpolation between animation key frame
values. The following node types are Interpolator nodes, each based on
the type of value that is interpolated:

* <<ColorInterpolator>>
* <<CoordinateInterpolator>>
* <<CoordinateInterpolator2D>>
* <<NormalInterpolator>>
* <<OrientationInterpolator>>
* <<PositionInterpolator>>
* <<PositionInterpolator2D>>
* <<ScalarInterpolator>>
* <<SplinePositionInterpolator>>
* <<SplinePositionInterpolator2D>>
* <<SplineScalarInterpolator>>
* <<SquadOrientationInterpolator>>
* <<EaseInEaseOut>>

All Interpolator nodes are based on the abstract type
<<X3DInterpolatorNode>>.

[[Linearinterpolation]]
==== 19.2.2 Linear interpolation

The X3D interpolator nodes specified in this clause are designed for
linear key framed animation. Each of these nodes defines a
piecewise-linear function, _f(t)_, on the interval `(−∞,∞)`. The
piecewise-linear function is defined by _n_ values of _t_, called _key_,
and the _n_ corresponding values of _f(t)_, called _keyValue_. The keys
shall be monotonically non-decreasing, otherwise the results are
undefined.

An interpolator node evaluates _f(t)_ given any value of _t_ (via the
_fraction_ field) as follows: Let the _n_ keys _t~0~_, _t~1~_, _t~2~_,
..., _t~n−1~_ partition the domain __(−__∞,∞ _)_ into the _n+1_
subintervals given by __(-__∞, _t~0~)_, _[t~0~_, _t~1~)_, _[t~1~_,
_t~2~)_, ... , _[t~n−1~_, __+__∞ _)_. Also, let the _n_ values _v~0~_,
_v~1~_, _v~2~_, ..., _v~n-1~_ be the values of _f(t)_ at the associated
key values. The piecewise-linear interpolating function, _f(t)_, is
defined to be:

    _f(t)_ = _v~0~_,    if _t ≤ t~0~_, +
         = _v~n−1~_,   if _t ≥ t~n−1~_, +
         = _linterp(t, v~i~_, _v~i+1~)_,    if _t~i~≤ t ≤ t~i+1~_, +
 +
     where _linterp(t,x,y)_ is the linear interpolant, +
           _i_ belongs to _\{0,1,..., n−2}_. +

The third conditional value of _f(t)_ allows the defining of multiple
values for a single key, ( _i.e._, limits from both the left and right
at a discontinuity in _f(t))_. The first specified value is used as the
limit of _f(t)_ from the left, and the last specified value is used as
the limit of _f(t)_ from the right. The value of _f(t)_ at a multiply
defined key is indeterminate, but should be one of the associated limit
values.

[[NonlinearInterpolation]]
==== 19.2.3 Non-linear interpolation

This component also provides non-linear interpolator nodes that provide
for smoother animation than the linear interpolator nodes. Linear
interpolators tend to produce animations that have a discontinuous
velocity vectors. The transitions at the keys produce a noticeably jerky
effect which will not occur when using non-linear interpolator nodes.

The non-linear interpolator nodes consist of three spline interpolator
nodes for 3D, 2D, and scalar interpolation. These three nodes use the
Hermite spline interpolation with adjustments to accommodate non-uniform
key intervals (see <<HermiteSplineInterpolation, 19.2.4 Hermite spline interpolation>>). The
<<SquadOrientationInterpolator>> node
supports non-linear orientation interpolation.

Each of non-linear interpolator nodes provides a SFBool _closed_ field
that specifies whether the interpolator should provide a closed loop,
with continuous velocity vectors as the interpolator transitions from
the last key to the first key. If the velocity vectors at the first and
last keys are specified, the closed field is ignored. If the keyValues
at the first and last key are not identical, the closed field is
ignored.

The SFBool _normalizeVelocity_ field specifies whether the velocity
vectors are to be transformed into tangency vectors. If the
_normalizeVelocity_ field has value `TRUE`, the _keyVelocity_
values are normalized, thus converting them to tangency vectors. In this
case, the vectors are normalized to produce smooth speed transitions, as
described mathematically below in
<<HermiteSplineInterpolation, 19.2.4 Hermite spline interpolation>>.
The magnitude of the specified velocity vectors is ignored.

If the _normalizeVelocity_ field has value `FALSE`, the units
specified in the velocity field are defined to be 
`length/cycleInterval`.

EXAMPLE  Using a
<<SplinePositionInterpolator>>, in which
the velocity at a key is specified to be (0, 0, 1), and the
cycleInterval that drives the interpolator is 4 seconds, the actual
speed of the object at that key is 0.25 metres per second (assuming the
initial base units have been specified).

In addition to the interpolation nodes, this component provides a node
that modifies the time fraction that is typically fed from the
<<TimeSensor>> node into the interpolator node. This is
the <<EaseInEaseOut>> node. It allows for a
deceleration as the interpolator approaches a key, and an acceleration
as the interpolator exits a key. Authors can route time fraction events
into the EaseInEaseOut node. The EaseInEaseOut node will then send out a
modified time fraction, which can them be routed into one or more
interpolators.

[[HermiteSplineInterpolation]]
==== 19.2.4 Hermite spline interpolation

The <<SplinePositionInterpolator>>,
<<SplinePositionInterpolator2D>>, and
the <<SplineScalarInterpolator>> nodes all
use the Hermite spline interpolation with adjustments to accommodate
non-uniform key intervals. These three nodes all use the same algorithm
which is described below.

The algorithm used by these interpolators is as follows. It defines the
output value sent form the _value_changed_ field for a given segment of
the interpolation, between key(i), and key(i+1). This segment is valid
when the fraction value satisfies (t~i~ ≤ fraction < t~i+1~), where t~i~
is the key at (i), and t~i+1~ is the key at (i+1).

The local fraction will vary from zero to one between the two keys, as
follows:

____
s = (t - t~i~) / (t~i+1~ - t~i~)
____

The velocity vectors at key (i) and key (i+1) are denoted by *T*~i~ and
*T*~i+1~ respectively. These velocity vectors need not be unit vectors.
The magnitude of these vectors specifies the relative speed of the
interpolation.

If the size of the _keyVelocity_ field is equal to the size of the
_keyValue_ field, the values of *T* used below should come from the
_keyVelocity_ field. If the size of the _keyVelocity_ field is 2, the
first value is used as the velocity vector for the first key, and the
second value is used as the velocity for the last key. If the size of
the _keyVelocity_ field is anything other than those two values, the
_keyVelocity_ field is ignored. Any velocity vectors that are not
specified will be calculated using the following algorithm:

The _keyValue_ at key (i) is denoted as *v*~i~ and the _keyValue_ at key
(i+1) is denoted as *v*~i+1~.

With those parameters defined, the _value_changed_ value ( *v*~s~) can
be calculated as follows:

____
*v*~s~ = *S*^T^ *H C*
____

where

____
[cols=",,,,,,,,,,",]
|===
|**S**= |s^3^ |  |**H**= |2 |-2 |1 |1 |  |**C**= |*v*~i~
| |s^2^ | | |-3 |3 |-2 |-1 | | |*v*~i+1~
| |s | | |0 |0 |1 |0 | | |*T*^0^~i~
| |1 | | |1 |0 |0 |0 | | |*T*^1^~i+1~
|===
____

The values of *T*^0^~i~ and *T*^1^~i+1~ are defined as follows: +
 +
The standard Hermite spline assumes that the keys are equally spaced.
Since this is not a valid assumption, these values are ajusted to
calculate *T*^0^~i~ and *T*^1^~i+1~ as follows. If the velocity vector
is specified by the author, the value of *T*~i~ is extracted from the
_keyVelocity_ field for the specific key. +
 +
If the velocity vector is not specified, it is calculated as follows:

____
*T*~i~ = ( *v*~i+1~ - *v*~i-1~) / 2
____

There are special cases as specified below:

If the velocity vector is specified, and the _normalizeVelocity_ flag
has value `FALSE`, the velocity at the key is set to the
corresponding value of the _keyVelocity_ field:

____
*T*~i~ = keyVelocity[ i ]
____

If the velocity vector is specified, and the _normalizeVelocity_ flag is
`TRUE`, the velocity at the key is set using the corresponding
value of the _keyVelocity_ field:

____
*T*~i~ = keyVelocity[i] × (D~tot~ / |keyVelocity[i]|)
____

where:

____
D~tot~ is the sum of the distance between all adjacent keys.
____

or

____
D~tot~ = SUM\{i=0, i < n-1}(|vi - vi+1|)
____

Lastly, to accommodate the non-uniform key intervals, the values of
*T*^0^~i~ and *T*^1^~i~ are calculated as follows:

____
*T*^0^~i~ = **F^+^**i *T*~i~ +
*T*^1^~i~ = *F^-^*~i~ *T*~i~
____

where:

____
*F^-^*~i~  = 2 (t~i+1~ - t~i~) / (t~i+1~ - t~i-1~) +
**F^+^**i = 2 (t~i~ - t~i-1~) / (t~i+1~ - t~i-1~)
____

If the interpolator is closed, the values of the _key_ and _keyValue_
used in these calculations should wrap appropriately:

____
t~-1~ = t~N-2~ +
v~-1~ = v~N-2~ +
t~N~ = t~1~ +
v~N~ = v~1~
____

If the interpolator is not closed, and the first and last velocity
vectors are not specified by the author, the values are calculated as
follows:

____
*T*^0^~0~ = *T*^1^~0~ = *T*^0^~N-1~ = *T*^1^~N-1~ = 0
____

If the interpolator is not closed, and the first and last velocity
vectors are specified by the author, the values are calculated as
follows:

____
*T*^0^~0~ = *T*~0~ +
*T*^1^~N-1~ = *T*~N-1~
____

where N is the size of the _keyValue_ field.

Additional information on the Hermite algorithm is available in
<<CATROM>>. +


=== 19.3 Abstract types

[[X3DInterpolatorNode]]
==== 19.3.1 _X3DInterpolatorNode_

[source,node]
----
X3DInterpolatorNode : X3DChildNode { 
  SFFloat      [in]     set_fraction       (-∞,∞)
  MFFloat      [in,out] key           []   (-∞,∞)
  MF<type>     [in,out] keyValue      []
  SFNode       [in,out] metadata      NULL [X3DMetadataObject]
  [S|M]F<type> [out]    value_changed
}
----

The abstract node _X3DInterpolatorNode_ forms the basis for all types of
interpolators specified in this clause.

The _key_ field contains the list of key times, which might appear as:

[source,listing]
----
    key [0 0.25 0.65 0.75 1]
----

to indicate there are five key frames in this node. The _keyValue_ field
contains values for the target field, one complete set of values for
each key. Interpolator nodes containing no keys in the _key_ field shall
not produce any events. However, an input event that replaces an empty
_key_ field with one that contains keys will cause the interpolator node
to produce events the next time that a _set_fraction_ event is received.

The _set_fraction_ inputOnly field receives an SFFloat event and causes
the interpolator node function to evaluate, resulting in a
_value_changed_ output event of the specified type with the same
timestamp as the _set_fraction_ event.

The contents of the _keyValue_ and _value_changed_ fields are dependent
on the type of the node ( _e.g._, the PositionInterpolator fields use
MFVec3f values). Each value or set of values in the _keyValue_ field
corresponds in order to the parameter value in the _key_ field.

For interpolator nodes that produce a single value, results are
undefined if the number of values in the _key_ field is not the same as
the number of values in the _keyValue_ field.

For interpolator nodes that produce multiple values, the _keyValue_
field is an __n__x _m_ array of values, where _n_ is the number of
values in the _key_ field and _m_ is the number of values at each key
frame. Each _m_ values in the _keyValue_ field correspond, in order, to
a parameter value in the _key_ field. Each _value_changed_ event shall
contain _m_ interpolated values. Results are undefined if the number of
values in the _keyValue_ field is not a positive integer multiple of the
number of values in the _key_ field.

If an _X3DInterpolatorNode_ _value_changed_ outputOnly field is read
before it receives any inputs, _keyValue_[0] is returned if _keyValue_
is not empty. If _keyValue_ is empty ( _i.e._, [ ]), the initial value
for the respective field type is returned (`EXAMPLE`  (0, 0, 0)
for SFVec3f); see <<fieldTypes_html, 5 Field type reference>> for
initial event values.

The location of an _X3DInterpolatorNode_ in the transformation hierarchy
has no effect on its operation. For example, if a parent of an
interpolator node is a <<Switch>> node with _whichChoice_ set
to −1 ( _i.e._, ignore its children), the interpolator continues to
operate as specified (receives and sends events).

A typical simplified structure for a key frame animation implementation
involves a <<TimeSensor>>, ROUTEs, and the target node.

[source,listing]
----
  Transform { 
    Shape 
       IndexedFaceSet { coordIndex='... −1 ... >
           Coordinate DEF='Moved' point [ x y z, ... ] #    t0Geometry
       }                  
    } 
  } 

  CoordinateInterpolator DEF='Mover' 
      key [t0 t1 t2 ]            #     list of key times, 0 to 1
      keyValue ' x y z, ... '    #     one geometry per key time 

  TimeSensor DEF='Timer' cycleInterval 5 loop TRUE 

  ROUTE Timer.fraction_changed TO Mover.set_value  
  ROUTE Mover.value_changed TO Moved.point 
----

In typical operation, the key frame _set_fraction_ event arrives from a
TimeSensor to signal that the time value has advanced. This value varies
from 0 to 1 depending upon where the TimeSensor is in its cycle time.

EXAMPLE  If the TimeSensor has a cycleTime of 10 seconds, and 5 seconds
has elapsed in its cycle, the _set_fraction_ value will be 0.5.

In this sample structure, the <<IndexedFaceSet>>
contains a <<Coordinate>> field named _Moved_. This
defines the time equals zero geometry for the node. The
<<CoordinateInterpolator>> node named _Mover_
contains the list of key frame times and the corresponding sets of
coordinates in the keyValue field. When the _set_fraction_ event arrives
for _key_, the corresponding interpolated _keyValue_ is sent to the
target Coordinate node for rendering.


=== 19.4 Node reference

[[ColorInterpolator]]
==== 19.4.1 ColorInterpolator

[source,node]
----
ColorInterpolator : X3DInterpolatorNode {
  SFFloat [in]     set_fraction       (-∞,∞)
  MFFloat [in,out] key           []   (-∞,∞)
  MFColor [in,out] keyValue      []   [0,1]
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  SFColor [out]    value_changed
}
----

The ColorInterpolator node interpolates among a list of MFColor key
values to produce an SFColor (RGB) _value_changed_ event. The number of
colours in the _keyValue_ field shall be equal to the number of key
frames in the _key_ field. The _keyValue_ field and _value_changed_
events are defined in RGB colour space. A linear interpolation using the
value of _set_fraction_ as input is performed in HSV space (see
<<FOLEY>> for description of RGB and HSV colour spaces). The
results are undefined when interpolating between two consecutive keys
with complementary hues.

[[CoordinateInterpolator]]
==== 19.4.2 CoordinateInterpolator

[source,node]
----
CoordinateInterpolator : X3DInterpolatorNode {
  SFFloat [in]     set_fraction       (-∞,∞)
  MFFloat [in,out] key           []   (-∞,∞)
  MFVec3f [in,out] keyValue      []   (-∞,∞)
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  MFVec3f [out]    value_changed
}
----

The CoordinateInterpolator node linearly interpolates among a list of
MFVec3f values to produce an MFVec3f _value_changed_ event. The number
of coordinates in the _keyValue_ field shall be an integer multiple of
the number of key frames in the _key_ field. That integer multiple
defines how many coordinates will be contained in the _value_changed_
events.

[[CoordinateInterpolator2D]]
==== 19.4.3 CoordinateInterpolator2D

[source,node]
----
CoordinateInterpolator2D : X3DInterpolatorNode {
  SFFloat [in]     set_fraction       (-∞,∞)
  MFFloat [in,out] key           []   (-∞,∞)
  MFVec2f [in,out] keyValue      []   (-∞,∞)
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  MFVec2f [out]    value_changed
}
----

This node linearly interpolates among a list of MFVec2f values to
produce an MFVec2f _value_changed_ event. The number of coordinates in
the _keyValue_ field shall be an integer multiple of the number of key
frames in the _key_ field. That integer multiple defines how many
coordinates will be contained in the _value_changed_ events.

[[EaseInEaseOut]]
==== 19.4.4 EaseInEaseOut

[source,node]
----
EaseInEaseOut :  X3DChildNode {
  SFFloat [in]     set_fraction                  (-∞,∞)
  MFVec2f [in,out] easeInEaseOut            []   (-∞,∞)
  MFFloat [in,out] key                      []   (-∞,∞) 
  SFNode  [in,out] metadata                 NULL [X3DMetadataObject]
  SFFloat [out]    modifiedFraction_changed
}
----

The EaseInEaseOut node supports controlled gradual transitions by
specifying modifications for TimeSensor node fractions. The
EaseInEaseOut node receives a _set_fraction_ field event. It uses the
values of the _key_ field and the _easeInEaseOut_ field to modify that
fraction which is then issued as a _modifiedFraction_changed_ event.

The first components of each pair of _easeInEaseOut_ field Vec2f values
correspond to the easeIn/easeOut features following each key as the
interpolator progresses. The second components of each pair of
_easeInEaseOut_ field Vec2f values correspond to the easeIn/easeOut
features as the interpolator progresses between _keyValues_.

The values of the _easeInEaseOut_ field range from zero to one. At zero,
there is no modification of the fraction.

The scope of the easeOut effect on the local fraction is equal to the
easeOut value.

EXAMPLE 1  If the easeOut value is 0.4, the object will accelerate out
of the previous key and reach a constant speed at 40% of the way from
the previous key to the next key.

The scope of the easeIn effect on the local fraction begins when the
local fraction reaches (1.0 - easeIn).

EXAMPLE 2  If the easeIn value is 0.3, the object will transition from a
constant speed, and begin to decelerate when unmodified local fraction
reaches 0.7 (70% of the way from the previous key to the next key).

If the sum of the previous easeIn value, plus the next easeIn value is
greater than 1.0, both values are scaled by the same amount so that the
sum of the values is equal 1.0. In that case, there is no period of
constant speed.

The algorithm for computing the _modifiedFraction_changed_ value is:

[loweralpha]
. Let u be the value of the _set_fraction_ field, representing the
proportion the distance between key~i~ and key~i+1~.
. Let e~out~ be the easeOut value for key~i~; ( _i.e._, easeOut =
_easeInEaseOut_~i~.y).
. Let e~in~ be the easeIn value for key~i+1~; ( _i.e._, easeIn =
_easeInEaseOut_~i+1~.x).
. Let S be the sum of e~in~and e~out~.
. If S < 0, _modifiedFraction_changed_ is set to u.
. If S > 1.0, divide e~in~ and e~out~ by S.
. Compute t = 1.0 / (2.0 - e~out~ - e~in~).
. If u < e~out~, _modifiedFraction_changed_ is set to: +
    (t / e~out~) × u^2^
. If u < 1.0 - e~in~, _modifiedFraction_changed_ is set to: +
    (t × (2u - e~out~))
. Else, _modifiedFraction_changed_ is set to: +
    1.0 - ((t × (1.0 - u)^2^) / e~in~)

<<f-EaseInEaseOut, Figure 19.1>> illustrates the algorithm above.

[[f-EaseInEaseOut]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/EaseInEaseOut.png[EaseInEaseOut algorithm
illustration,width=508,height=287]

Figure 19.1 —  EaseInEaseOut algorithm illustration

The easeInEaseOut field values shall be monotonically non-decreasing,
otherwise results are undefined.

[[NormalInterpolator]]
==== 19.4.5 NormalInterpolator

[source,node]
----
NormalInterpolator : X3DInterpolatorNode {
  SFFloat [in]     set_fraction       (-∞,∞)
  MFFloat [in,out] key           []   (-∞,∞)
  MFVec3f [in,out] keyValue      []   (-∞,∞)
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  MFVec3f [out]    value_changed
}
----

The NormalInterpolator node interpolates among a list of normal vector
sets specified by the _keyValue_ field to produce an MFVec3f
_value_changed_ event. The output vector, _value_changed_, shall be a
set of normalized vectors.

Values in the _keyValue_ field shall be of unit length. The number of
normals in the _keyValue_ field shall be an integer multiple of the
number of key frames in the _key_ field. That integer multiple defines
how many normals will be contained in the _value_changed_ events.

Normal interpolation shall be performed on the surface of the unit
sphere. That is, the output values for a linear interpolation from a
point P on the unit sphere to a point Q also on the unit sphere shall
lie along the shortest arc (on the unit sphere) connecting points P and
Q. Also, equally spaced input fractions shall result in arcs of equal
length. The results are undefined if P and Q are diagonally opposite.

[[OrientationInterpolator]]
==== 19.4.6 OrientationInterpolator

[source,node]
----
OrientationInterpolator : X3DInterpolatorNode {
  SFFloat    [in]     set_fraction       (-∞,∞)
  MFFloat    [in,out] key           []   (-∞,∞)
  MFRotation [in,out] keyValue      []   [-1,1] or (-∞,∞)
  SFNode     [in,out] metadata      NULL [X3DMetadataObject]
  SFRotation [out]    value_changed
}
----

The OrientationInterpolator node interpolates among a list of rotation
values specified in the _keyValue_ field to produce an SFRotation
_value_changed_ event. These rotations are absolute in object space and
therefore are not cumulative. The _keyValue_ field shall contain exactly
as many rotations as there are key frames in the _key_ field.

An orientation represents the final position of an object after a
rotation has been applied. An OrientationInterpolator interpolates
between two orientations by computing the shortest path on the unit
sphere between the two orientations. The interpolation is linear in arc
length along this path. The results are undefined if the two
orientations are diagonally opposite.

If two consecutive _keyValue_ values exist such that the arc length
between them is greater than π, the interpolation will take
place on the arc complement. For example, the interpolation between the
orientations

____
(0, 1, 0, 0) and (0, 1, 0, 5.0)
____

is equivalent to the rotation between the orientations

____
(0, 1, 0, 2π) and (0, 1, 0, 5.0).
____

[[PositionInterpolator]]
==== 19.4.7 PositionInterpolator

[source,node]
----
PositionInterpolator : X3DInterpolatorNode {
  SFFloat [in]     set_fraction       (-∞,∞)
  MFFloat [in,out] key           []   (-∞,∞)
  MFVec3f [in,out] keyValue      []   (-∞,∞)
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  SFVec3f [out]    value_changed
}
----

The PositionInterpolator node linearly interpolates among a list of 3D
vectors to produce an SFVec3f _value_changed_ event. The _keyValue_
field shall contain exactly as many values as in the _key_ field.

[[PositionInterpolator2D]]
==== 19.4.8 PositionInterpolator2D

[source,node]
----
PositionInterpolator2D : X3DInterpolatorNode {
  SFFloat [in]     set_fraction       (-∞,∞)
  MFFloat [in,out] key           []   (-∞,∞)
  MFVec2f [in,out] keyValue      []   (-∞,∞)
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  SFVec2f [out]    value_changed
}
----

The PositionInterpolator2D node linearly interpolates among a list of 2D
vectors to produce an SFVec2f _value_changed_ event. The _keyValue_
field shall contain exactly as many values as in the _key_ field.

[[ScalarInterpolator]]
==== 19.4.9 ScalarInterpolator

[source,node]
----
ScalarInterpolator : X3DInterpolatorNode {
  SFFloat [in]     set_fraction       (-∞,∞)
  MFFloat [in,out] key           []   (-∞,∞)
  MFFloat [in,out] keyValue      []   (-∞,∞)
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  SFFloat [out]    value_changed
}
----

The ScalarInterpolator node linearly interpolates among a list of
SFFloat values to produce an SFFloat _value_changed_ event. This
interpolator is appropriate for any parameter defined using a single
floating point value.

EXAMPLE 1  width fields

EXAMPLE 2  radius fields

EXAMPLE 3  intensity fields

The _keyValue_ field shall contain exactly as many numbers as there are
key frames in the _key_ field.

[[SplinePositionInterpolator]]
==== 19.4.10 SplinePositionInterpolator

[source,node]
----
SplinePositionInterpolator : X3DInterpolatorNode {
  SFFloat [in]     set_fraction            (-∞,∞)
  SFBool  [in,out] closed            FALSE
  MFFloat [in,out] key               []    (-∞,∞)
  MFVec3f [in,out] keyValue          []    (-∞,∞)
  MFVec3f [in,out] keyVelocity       []    (-∞,∞)
  SFNode  [in,out] metadata          NULL  [X3DMetadataObject]
  SFBool  [in,out] normalizeVelocity FALSE
  SFVec3f [out]    value_changed
}
----

The SplinePositionInterpolator node non-linearly interpolates among a
list of 3D vectors to produce an SFVec3f _value_changed_ event. The
_keyValue_, _keyVelocity_, and _key_ fields shall each have the same
number of values.

The `+normalizeVelocity+` field is as defined in
<<NonlinearInterpolation, 19.2.3 Non-linear interpolation>>.

[[SplinePositionInterpolator2D]]
==== 19.4.11 SplinePositionInterpolator2D

[source,node]
----
SplinePositionInterpolator2D : X3DInterpolatorNode {
  SFFloat [in]     set_fraction            (-∞,∞)
  SFBool  [in,out] closed            FALSE
  MFFloat [in,out] key               []    (-∞,∞)
  MFVec2f [in,out] keyValue          []    (-∞,∞)
  MFVec2f [in,out] keyVelocity       []    (-∞,∞)
  SFNode  [in,out] metadata          NULL  [X3DMetadataObject]
  SFBool  [in,out] normalizeVelocity FALSE
  SFVec2f [out]    value_changed
}
----

The SplinePositionInterpolator2D node non-linearly interpolates among a
list of 2D vectors to produce an SFVec2f _value_changed_ event. The
_keyValue_, _keyVelocity_, and _key_ fields shall each have the same
number of values.

The `+normalizeVelocity+` field is as defined in
<<NonlinearInterpolation, 19.2.3 Non-linear interpolation>>.

[[SplineScalarInterpolator]]
==== 19.4.12 SplineScalarInterpolator

[source,node]
----
SplineScalarInterpolator : X3DInterpolatorNode {
  SFFloat [in]     set_fraction            (-∞,∞)
  SFBool  [in,out] closed            FALSE
  MFFloat [in,out] key               []    (-∞,∞)
  MFFloat [in,out] keyValue          []    (-∞,∞)
  MFFloat [in,out] keyVelocity       []    (-∞,∞)
  SFNode  [in,out] metadata          NULL  [X3DMetadataObject]
  SFBool  [in,out] normalizeVelocity FALSE
  SFFloat [out]    value_changed
}
----

The SplineScalarInterpolator node non-linearly interpolates among a list
of floats to produce an SFFloat _value_changed_ event. The _keyValue_,
_keyVelocity_, and _key_ fields shall each have the same number of
values.

The `+normalizeVelocity+` field is as defined in
<<NonlinearInterpolation, 19.2.3 Non-linear interpolation>>.

[[SquadOrientationInterpolator]]
==== 19.4.13 SquadOrientationInterpolator

[source,node]
----
SquadOrientationInterpolator : X3DInterpolatorNode {
  SFFloat    [in]     set_fraction            (-∞,∞)
  MFFloat    [in,out] key               []    (-∞,∞)
  MFRotation [in,out] keyValue          []    (-∞,∞)
  SFNode     [in,out] metadata          NULL  [X3DMetadataObject]
  SFBool     [in,out] normalizeVelocity FALSE
  SFRotation [out]    value_changed
}
----

The SquadOrientationInterpolator node non-linearly interpolates among a
list of rotations to produce an SFRotation _value_changed_ event. The
_keyValue_ field shall have the same number of values and the _key_
field.

The `+normalizeVelocity+` field is as defined in
<<NonlinearInterpolation, 19.2.3 Non-linear interpolation>>.

The SquadOrientationInterpolator uses the industry standard Squad method
for smoothly interpolating orientations. Squad is an acronym for
Spherical Cubic Interpolation. The Linear
<<OrientationInterpolator>> described in
<<OrientationInterpolator, 19.4.6 OrientationInterpolator>> provides
spherical linear interpolation. The SquadOrientationInterpolator applies
the spline interpolation approach described above to interpolation in
quaternion space. For more information on Squad interpolation, see
<<SHOE>>.

[[S19.5_SupportLevels]]
=== 19.5 Support levels

The Interpolation component provides three levels of support as
specified in <<t19_2, Table 19.2>>.

[[t19_2]]
*Table 19.2 —* Interpolation component support
levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 | |
|  | |_X3DInterpolatorNode_ (abstract) |n/a
|  | |CoordinateInterpolator |All fields fully supported.
| | |OrientationInterpolator |All fields fully supported.
| | |PositionInterpolator |All fields fully supported.
| | |ScalarInterpolator |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 | |
| | |All Level 1 Interpolator nodes |All fields fully supported.
| | |ColorInterpolator |All fields fully supported.
| | |NormalInterpolator |All fields fully supported.
|*3* |Core 1 +
Grouping 1 +
Shape 1 | |
| | |All Level 2 Interpolator nodes |All fields fully supported.
|  |  |CoordinateInterpolator2D |All fields fully supported.
|  |  |PositionInterpolator2D |All fields fully supported.
|*4* |Core 1 +
Grouping 1 +
Shape 1 |  | 
|  |  |All Level 3 Interpolator nodes |All fields fully supported.
|  |  |EaseInEaseOut |All fields fully supported.
|  |  |SplinePositionInterpolator |All fields fully supported.
|  |  |SplinePositionInterpolator2D |All fields fully supported.
|  |  |SplineScalarInterpolator |All fields fully supported.
|*5* |Core 1 +
Grouping 1 +
Shape 1 |  | 
|  |  |All Level 4 Interpolator nodes |All fields fully supported.
|  |  |SquadOrientationInterpolator |All fields fully supported.
|===

[[pointingDeviceSensor_html]]
== 20 Pointing device sensor component

[[S20_Introduction]]
=== 20.1 Introduction

[[S20_Name]]
==== 20.1.1 Name

The name of this component is "PointingDeviceSensor". This name shall be
used when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S20_Overview]]
==== 20.1.2 Overview

This clause describes the Pointing Device Sensor component of this
document. Pointing device sensor nodes detect pointing events from
user-interface devices, defining activities such as a user selecting a
piece of geometry. This includes how pointing device sensors operate
conceptually as well as which varieties of pointing device sensors are
provided. <<t20_1, Table 20.1>> provides links to the major topics
in this clause.

[[t20_1]]
Table 20.1 — Topics

* <<S20Introduction, 20.1 Introduction>>
** <<S20_Name, 20.1.1 Name>>
** <<S20_Overview, 20.1.2 Overview>>
* <<S20_Concepts, 20.2 Concepts>>
** <<OverviewOfPointingDeviceSensors, 20.2.1 Overview of pointing device sensors>>
** <<DragSensors, 20.2.2 Drag sensors>>
** <<Activatingandmanipulating, 20.2.3 Activating and manipulating pointing device sensors>>
* <<S20_AbstractTypes, 20.3 Abstract types>>
** <<X3DDragSensorNode, 20.3.1 _X3DDragSensorNode_>>
** <<X3DPointingDeviceSensorNode, 20.3.2 _X3DPointingDeviceSensorNode_>>
** <<X3DTouchSensorNode, 20.3.3 _X3DTouchSensorNode_>>
* <<S20_NodeReference, 20.4 Node reference>>
** <<CylinderSensor, 20.4.1 CylinderSensor>>
** <<PlaneSensor, 20.4.2 PlaneSensor>>
** <<SphereSensor, 20.4.3 SphereSensor>>
** <<TouchSensor, 20.4.4 TouchSensor>>
* <<S20_SupportLevels, 20.5 Support levels>>

* <<t20_1, Table 20.1 — Topics>>
* <<t20_2, Table 20.2 — Pointing device sensor component support levels>>




[[S20_Concepts]]
=== 20.2 Concepts

[[OverviewOfPointingDeviceSensors]]
==== 20.2.1 Overview of pointing device sensors

Pointing device sensors detect user pointing events such as the user
clicking on a piece of geometry (
_i.e._, <<TouchSensor>>). The following node types are
pointing device sensors:

* <<CylinderSensor>>
* <<PlaneSensor>>
* <<SphereSensor>>
* <<TouchSensor>>

The <<Anchor>> node is also considered a pointing device
sensor for the purpose of detecting user picking. However, it does not
extend from the
_<<X3DPointingDeviceSensorNode>>_
interface.

Other components may add additional pointing device sensors.

A pointing device sensor is activated when the user locates the pointing
device over geometry that is influenced by that specific pointing device
sensor. Pointing device sensors have influence over all geometry that is
descended from the sensor's parent groups. In the case of the Anchor
node, the Anchor node itself is considered to be the parent group.
Typically, the pointing device sensor is a sibling to the geometry that
it influences. In other cases, the sensor is a sibling to groups which
contain geometry ( _i.e._, are influenced by the pointing device
sensor).

The appearance properties of the geometry do not affect activation of
the sensor. In particular, transparent materials or textures shall be
treated as opaque with respect to activation of pointing device sensors.

For a given user activation, the lowest enabled pointing device sensor
in the hierarchy is activated. All other pointing device sensors above
the lowest enabled pointing device sensor are ignored. The hierarchy is
defined by the geometry node over which the pointing device sensor is
located and the entire hierarchy upward. If there are multiple pointing
device sensors tied for lowest, each of these is activated
simultaneously and independently, possibly resulting in multiple sensors
activating and generating output simultaneously. This feature allows
combinations of pointing device sensors ( _e.g._, TouchSensor and
PlaneSensor). If a pointing device sensor appears in the transformation
hierarchy multiple times (DEF/USE), it shall be tested for activation in
all of the coordinate systems in which it appears.

If a pointing device sensor is not enabled when the pointing device
button is activated, it will not generate events related to the pointing
device until after the pointing device is deactivated and the sensor is
enabled ( _i.e._, enabling a sensor in the middle of dragging does not
result in the sensor activating immediately).

[[DragSensors]]
==== 20.2.2 Drag sensors

_Drag sensors_ are a subset of pointing device sensors. There are three
types of drag sensors: <<CylinderSensor>>,
<<PlaneSensor>>, and <<SphereSensor>>.
Drag sensors have two outputOnly fields in common, _trackPoint_changed_
and _<value>_changed_. These outputOnly fields send events for each
movement of the activated pointing device according to their "virtual
geometry" ( _e.g._, cylinder for CylinderSensor). The
_trackPoint_changed_ outputOnly field sends the intersection point of
the _bearing_ with the drag sensor's virtual geometry. The
_<value>_changed_ outputOnly field sends the sum of the relative change
since activation plus the sensor's _offset_ field. The type and name of
_<value>_changed_ depends on the drag sensor type: _rotation_changed_
for CylinderSensor, _translation_changed_ for PlaneSensor, and
_rotation_changed_ for SphereSensor.

To simplify the application of these sensors, each node has an _offset_
and an _autoOffset_ exposed field. When the sensor generates events as a
response to the activated pointing device motion, _<value>_changed_
sends the sum of the relative change since the initial activation plus
the _offset_ field value. If _autoOffset_ is `TRUE` when the
pointing device is deactivated, the _offset_ field is set to the
sensor's last _<value>_changed_ value and _offset_ sends an
_offset_changed_ output event. This enables subsequent grabbing
operations to accumulate the changes. If _autoOffset_ is `FALSE`,
the sensor does not set the _offset_ field value at deactivation (or any
other time).

[[Activatingandmanipulating]]
==== 20.2.3 Activating and manipulating pointing device sensors

The pointing device controls a pointer in the virtual world. While
activated by the pointing device, a sensor will generate events as the
pointer moves. Typically the pointing device may be categorized as
either 2D ( _e.g._, conventional mouse) or 3D ( _e.g._, wand). It is
suggested that the pointer controlled by a 2D device is mapped onto a
plane a fixed distance from the viewer and perpendicular to the line of
sight. The mapping of a 3D device may describe a 1:1 relationship
between movement of the pointing device and movement of the pointer.

The position of the pointer defines a bearing which is used to determine
which geometry is being indicated. When implementing a 2D pointing
device it is suggested that the bearing is defined by the vector from
the viewer position through the location of the pointer. When
implementing a 3D pointing device it is suggested that the bearing is
defined by extending a vector from the current position of the pointer
in the direction indicated by the pointer.

In all cases the pointer is considered to be indicating a specific
geometry when that geometry is intersected by the bearing. If the
bearing intersects multiple sensors' geometries, only the sensor nearest
to the pointer will be eligible for activation.


=== 20.3 Abstract types

[[X3DDragSensorNode]]
==== 20.3.1 _X3DDragSensorNode_

[source,node]
----
X3DDragSensorNode : X3DPointingDeviceSensorNode { 
  SFBool   [in,out] autoOffset         TRUE
  SFString [in,out] description        ""
  SFBool   [in,out] enabled            TRUE
  SFNode   [in,out] metadata           NULL [X3DMetadataObject]
  SFBool   [out]    isActive
  SFBool   [out]    isOver
  SFVec3f  [out]    trackPoint_changed
}
----

This abstract node type is the base type for all drag-style pointing
device  sensors.

[[X3DPointingDeviceSensorNode]]
==== 20.3.2 _X3DPointingDeviceSensorNode_

[source,node]
----
X3DPointingDeviceSensorNode : X3DSensorNode {
  SFString [in,out] description ""
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
  SFBool   [out]    isActive
  SFBool   [out]    isOver
}
----

This abstract node type is the base type for all pointing device
sensors.

[[X3DTouchSensorNode]]
==== 20.3.3 _X3DTouchSensorNode_

[source,node]
----
X3DTouchSensorNode : X3DPointingDeviceSensorNode { 
  SFString [in,out] description ""
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
  SFBool   [out]    isActive
  SFBool   [out]    isOver
  SFTime   [out]    touchTime
}
----

This abstract node type is the base type for all touch-style pointing
device sensors.


=== 20.4 Node reference

[[CylinderSensor]]
==== 20.4.1 CylinderSensor

[source,node]
----
CylinderSensor : X3DDragSensorNode { 
  SFBool     [in,out] autoOffset         TRUE
  SFRotation [in,out] axisRotation       0 1 0 0
  SFString   [in,out] description        ""
  SFFloat    [in,out] diskAngle          π/12    [0,π/2]
  SFBool     [in,out] enabled            TRUE
  SFFloat    [in,out] maxAngle           -1      [-2π,2π]
  SFNode     [in,out] metadata           NULL    [X3DMetadataObject]
  SFFloat    [in,out] minAngle           0       [-2π,2π]
  SFFloat    [in,out] offset             0       (-∞,∞)
  SFBool     [out]    isActive
  SFBool     [out]    isOver
  SFRotation [out]    rotation_changed
  SFVec3f    [out]    trackPoint_changed
}
----

The CylinderSensor node maps pointer motion ( _e.g._, a mouse or wand)
into a rotation on an invisible cylinder that is aligned with the Y-axis
of the local sensor coordinate system. The local sensor coordinate
system is created by applying the _axisRotation_ field value to the
local coordinate system. The CylinderSensor uses the descendent geometry
of its parent node to determine whether it is liable to generate events.

The _description_ field in the CylinderSensor node specifies a textual
description of the CylinderSensor node. This may be used by X3D
browser-specific user interfaces that wish to present users with more
detailed information about the CylinderSensor.

The _enabled_ field enables and disables the CylinderSensor node. If
`TRUE`, the sensor reacts appropriately to user events. If
`FALSE`, the sensor does not track user input or send events. If
_enabled_ receives a `FALSE` event and _isActive_ is
`TRUE`, the sensor becomes disabled and deactivated, and outputs
an _isActive_ `FALSE` event. If _enabled_ receives a
`TRUE` event the sensor is enabled and ready for user activation.

A CylinderSensor node generates events when the pointing device is
activated while the pointer is indicating any descendent geometry nodes
of the sensor's parent group. See <<Activatingandmanipulating, 20.2.3 Activating and manipulating pointing device sensors>>, for more details
on using the pointing device to activate the CylinderSensor.

Upon activation of the pointing device while indicating the sensor's
geometry, an _isActive_ `TRUE` event is sent. The initial acute
angle between the bearing vector and the local sensor coordinate system
Y-axis of the CylinderSensor node determines whether the sides of the
invisible cylinder or the caps (disks) are used for manipulation. If the
initial angle is less than the _diskAngle_, the geometry is treated as
an infinitely large disk lying in the Y=0 plane of the local sensor
coordinate system and coincident with the initial intersection point.
Dragging motion is mapped into a rotation around the +Y-axis vector of
the local sensor coordinate system. The perpendicular vector from the
initial intersection point to this Y-axis defines zero rotation about
the Y-axis of the local sensor coordinate system. For each subsequent
position of the bearing, a _rotation_changed_ event is sent that equals
the sum of the rotation about the +Y-axis vector of the local sensor
coordinate system (from the initial intersection to the new
intersection) plus the _offset_ value. _trackPoint_changed_ events
reflect the unclamped drag position on the surface of this disk. When
the pointing device is deactivated and _autoOffset_ is `TRUE`,
_offset_ is set to the last rotation angle and an _offset_changed_ event
is generated. See <<DragSensors, 20.2.2 Drag sensors>>, for a more
general description of _autoOffset_ and _offset_ fields.

If the initial acute angle between the bearing vector and the local
sensor coordinate system Y-axis of the CylinderSensor node is greater
than or equal to _diskAngle_, the sensor behaves like a cylinder. The
shortest distance between the point of intersection (between the bearing
and the sensor's geometry) and the Y-axis of the parent group's local
coordinate system determines the radius of an invisible cylinder used to
map pointing device motion and marks the zero rotation value. For each
subsequent position of the bearing, a _rotation_changed_ event is sent
that equals the sum of the right-handed rotation from the original
intersection about the +Y-axis vector plus the _offset_ value.
_trackPoint_changed_ events reflect the unclamped drag position on the
surface of the invisible cylinder. When the pointing device is
deactivated and _autoOffset_ is `TRUE`, _offset_ is set to the
last rotation angle and an _offset_changed_ event is generated. More
details are available in <<DragSensors, 20.2.2 Drag sensors>>.

When the sensor generates an _isActive_ `TRUE` event, it grabs
all further motion events from the pointing device until it is released
and generates an _isActive_ `FALSE` event (other pointing device
sensors shall not generate events during this time). Motion of the
pointing device while _isActive_ is `TRUE` is referred to as a
"drag" operation. If a 2D pointing device is in use, _isActive_ events
will typically reflect the state of the primary button associated with
the device ( _i.e._,  _isActive_ is `TRUE` when the primary
button is pressed and `FALSE` when it is released). If a 3D
pointing device ( _e.g._, a wand) is in use, _isActive_ events will
typically reflect whether the pointer is within or in contact with the
sensor's geometry.

While the pointing device is activated, _trackPoint_changed_ and
_rotation_changed_ events are output and are interpreted from pointing
device motion based on the sensor's local coordinate system at the time
of activation. _trackPoint_changed_ events represent the unclamped
intersection points on the surface of the invisible cylinder or disk. If
the initial angle results in cylinder rotation (as opposed to disk
behaviour) and if the pointing device is dragged off the cylinder while
activated, X3D browsers may interpret this in a variety of ways (
_e.g._, clamp all values to the cylinder and continuing to rotate as the
point is dragged away from the cylinder). Each movement of the pointing
device while _isActive_ is `TRUE` generates _trackPoint_changed_
and _rotation_changed_ events.

The _minAngle_ and _maxAngle_ fields clamp _rotation_changed_ events to
a range of values. If _minAngle_ is greater than _maxAngle_,
_rotation_changed_ events are not clamped. The _minAngle_ and _maxAngle_
fields are restricted to the range [-2π, 2π].

More information about this behaviour is described in
<<S20_Concepts, 20.2 Concepts>>.

[[PlaneSensor]]
==== 20.4.2 PlaneSensor

[source,node]
----
PlaneSensor : X3DDragSensorNode { 
  SFBool     [in,out] autoOffset          TRUE
  SFRotation [in,out] axisRotation        0 0 1 0
  SFString   [in,out] description         ""
  SFBool     [in,out] enabled             TRUE
  SFVec2f    [in,out] maxPosition         -1 -1 (-∞,∞)
  SFNode     [in,out] metadata            NULL  [X3DMetadataObject]
  SFVec2f    [in,out] minPosition         0 0   (-∞,∞)
  SFVec3f    [in,out] offset              0 0 0 (-∞,∞)
  SFBool     [out]    isActive
  SFBool     [out]    isOver
  SFVec3f    [out]    trackPoint_changed
  SFVec3f    [out]    translation_changed
}
----

The PlaneSensor node maps pointing device motion into two-dimensional
translation in a plane parallel to the Z=0 plane of the local sensor
coordinate system. The local sensor coordinate system is created by
applying the _axisRotation_ field value to the local coordinate system.
The PlaneSensor node uses the descendent geometry of its parent node to
determine whether it is liable to generate events.

The _description_ field in the PlaneSensor node specifies a textual
description of the PlaneSensor node. This may be used by X3D
browser-specific user interfaces that wish to present users with more
detailed information about the PlaneSensor.

The _enabled_ field enables and disables the PlaneSensor. If _enabled_
is `TRUE`, the sensor reacts appropriately to user events. If
_enabled_ is `FALSE`, the sensor does not track user input or
send events. If _enabled_ receives a `FALSE` event and _isActive_
is `TRUE`, the sensor becomes disabled and deactivated, and
outputs an _isActive_ `FALSE` event. If _enabled_ receives a
`TRUE` event, the sensor is enabled and made ready for user
activation.

The PlaneSensor node generates events when the pointing device is
activated while the pointer is indicating any descendent geometry nodes
of the sensor's parent group. See <<Activatingandmanipulating, 20.2.3 Activating and manipulating pointing device sensors>>, for details on
using the pointing device to activate the PlaneSensor.

Upon activation of the pointing device ( _e.g._, mouse button down)
while indicating the sensor's geometry, an _isActive_ `TRUE`
event is sent. Pointer motion is mapped into relative translation in the
_tracking plane_, (a plane parallel to the local sensor coordinate
system Z=0 plane and coincident with the initial point of intersection).
For each subsequent movement of the bearing, a _translation_changed_
event is output which corresponds to the sum of the relative translation
from the original intersection point to the intersection point of the
new bearing in the plane plus the _offset_ value. The sign of the
translation is defined by the Z=0 plane of the local sensor coordinate
system. _trackPoint_changed_ events reflect the unclamped drag position
on the surface of this plane. When the pointing device is deactivated
and _autoOffset_ is `TRUE`, _offset_ is set to the last
_translation_changed_ value and an _offset_changed_ event is generated.
More details are provided in <<DragSensors, 20.2.2 Drag sensors>>.

When the sensor generates an _isActive_ `TRUE` event, it grabs
all further motion events from the pointing device until it is
deactivated and generates an _isActive_ `FALSE` event. Other
pointing device sensors shall not generate events during this time.
Motion of the pointing device while _isActive_ is `TRUE` is
referred to as a "drag" operation. If a 2D pointing device is in use,
_isActive_ events typically reflect the state of the primary button
associated with the device ( _i.e._,  _isActive_ is `TRUE` when
the primary button is pressed, and is `FALSE` when it is
released). If a 3D pointing device ( _e.g._, wand) is in use, _isActive_
events typically reflect whether the pointer is within or in contact
with the sensor's geometry.

_minPosition_ and _maxPosition_ may be set to clamp
_translation_changed_ events to a range of values as measured from the
origin of the Z=0 plane of the local sensor coordinate system. If the X
or Y component of _minPosition_ is greater than the corresponding
component of _maxPosition_, _translation_changed_ events are not clamped
in that dimension. If the X or Y component of _minPosition_ is equal to
the corresponding component of _maxPosition_, that component is
constrained to the given value. This technique provides a way to
implement a line sensor that maps dragging motion into a translation in
one dimension.

While the pointing device is activated and moved, _trackPoint_changed_
and _translation_changed_ events are sent. _trackPoint_changed_ events
represent the unclamped intersection points on the surface of the
tracking plane. If the pointing device is dragged off of the tracking
plane while activated ( _e.g._, above horizon line), X3D browsers may
interpret this in a variety ways ( _e.g._, clamp all values to the
horizon). Each movement of the pointing device, while _isActive_ is
`TRUE`, generates _trackPoint_changed_ and _translation_changed_
events.

Further information about this behaviour can be found in
<<S20_Concepts, 20.2 Concepts>>.

[[SphereSensor]]
==== 20.4.3 SphereSensor

[source,node]
----
SphereSensor : X3DDragSensorNode { 
  SFBool     [in,out] autoOffset         TRUE
  SFString   [in,out] description        ""
  SFBool     [in,out] enabled            TRUE
  SFNode     [in,out] metadata           NULL    [X3DMetadataObject]
  SFRotation [in,out] offset             0 1 0 0 [-1,1],(-∞,∞)
  SFBool     [out]    isActive
  SFBool     [out]    isOver
  SFRotation [out]    rotation_changed
  SFVec3f    [out]    trackPoint_changed
}
----

The SphereSensor node maps pointing device motion into spherical
rotation about the origin of the local coordinate system. The
SphereSensor node uses the descendent geometry of its parent node to
determine whether it is liable to generate events.

The _description_ field in the SphereSensor node specifies a textual
description of the SphereSensor node. This may be used by X3D
browser-specific user interfaces that wish to present users with more
detailed information about the SphereSensor.

The _enabled_ field enables and disables the SphereSensor node. If
_enabled_ is `TRUE`, the sensor reacts appropriately to user
events. If _enabled_ is `FALSE`, the sensor does not track user
input or send events. If _enabled_ receives a `FALSE` event and
_isActive_ is `TRUE`, the sensor becomes disabled and
deactivated, and outputs an _isActive_ `FALSE` event. If
_enabled_ receives a `TRUE` event the sensor is enabled and ready
for user activation.

The SphereSensor node generates events when the pointing device is
activated while the pointer is indicating any descendent geometry nodes
of the sensor's parent group. See <<Activatingandmanipulating, 20.2.3 Activating and manipulating pointing device sensors>>, for details on
using the pointing device to activate the SphereSensor.

Upon activation of the pointing device ( _e.g._, mouse button down) over
the sensor's geometry, an _isActive_ `TRUE` event is sent. The
vector defined by the initial point of intersection on the
SphereSensor's geometry and the local origin determines the radius of
the sphere that is used to map subsequent pointing device motion while
dragging. The virtual sphere defined by this radius and the local origin
at the time of activation is used to interpret subsequent pointing
device motion and is not affected by any changes to the sensor's
coordinate system while the sensor is active. For each position of the
bearing, a _rotation_changed_ event is sent which corresponds to the sum
of the relative rotation from the original intersection point plus the
_offset_ value. _trackPoint_changed_ events reflect the unclamped drag
position on the surface of this sphere. When the pointing device is
deactivated and _autoOffset_ is `TRUE`, _offset_ is set to the
last _rotation_changed_ value and an _offset_changed_ event is
generated. See <<S20_Concepts, 20.2 Concepts>>, for more details.

When the sensor generates an _isActive_ `TRUE` event, it grabs
all further motion events from the pointing device until it is released
and generates an _isActive_ `FALSE` event (other pointing device
sensors shall not generate events during this time). Motion of the
pointing device while _isActive_ is `TRUE` is termed a "drag"
operation. If a 2D pointing device is in use, _isActive_ events will
typically reflect the state of the primary button associated with the
device ( _i.e._,  _isActive_ is `TRUE` when the primary button is
pressed and `FALSE` when it is released). If a 3D pointing device
( _e.g._, wand) is in use, _isActive_ events will typically reflect
whether the pointer is within (or in contact with) the sensor's
geometry.

While the pointing device is activated, _trackPoint_changed_ and
_rotation_changed_ events are output. _trackPoint_changed_ events
represent the unclamped intersection points on the surface of the
invisible sphere. If the pointing device is dragged off the sphere while
activated, X3D browsers may interpret this in a variety of ways (
_e.g._, clamp all values to the sphere or continue to rotate as the
point is dragged away from the sphere). Each movement of the pointing
device while _isActive_ is `TRUE` generates _trackPoint_changed_
and _rotation_changed_ events.

Further information about this behaviour can be found in
<<S20_Concepts, 20.2 Concepts>>.

[[TouchSensor]]
==== 20.4.4 TouchSensor

[source,node]
----
TouchSensor : X3DTouchSensorNode { 
  SFString [in,out] description         ""
  SFBool   [in,out] enabled             TRUE
  SFNode   [in,out] metadata            NULL [X3DMetadataObject]
  SFVec3f  [out]    hitNormal_changed
  SFVec3f  [out]    hitPoint_changed
  SFVec2f  [out]    hitTexCoord_changed
  SFBool   [out]    isActive
  SFBool   [out]    isOver
  SFTime   [out]    touchTime
}
----

A TouchSensor node tracks the location and state of the pointing device
and detects when the user points at geometry contained by the
TouchSensor node's parent group.

The _description_ field in the TouchSensor node specifies a textual
description of the TouchSensor node. This may be used by X3D
browser-specific user interfaces that wish to present users with more
detailed information about the TouchSensor.

A TouchSensor node can be enabled or disabled by sending it an _enabled_
event with a value of `TRUE` or `FALSE`. If the
TouchSensor node is disabled, it does not track user input or send
events.

The TouchSensor generates events when the pointing device points toward
any geometry nodes that are descendants of the TouchSensor's parent
group. See <<Activatingandmanipulating, 20.2.3 Activating and manipulating pointing device sensors>>, for more details on using the
pointing device to activate the TouchSensor.

The _isOver_ field reflects the state of the pointing device with regard
to whether it is pointing towards the TouchSensor node's geometry or
not. When the pointing device changes state from a position such that
its bearing does not intersect any of the TouchSensor node's geometry to
one in which it does intersect geometry, an _isOver_ `TRUE` event
is generated. When the pointing device moves from a position such that
its bearing intersects geometry to one in which it no longer intersects
the geometry, or some other geometry is obstructing the TouchSensor
node's geometry, an _isOver_ `FALSE` event is generated. These
events are generated only when the pointing device has moved and changed
`over' state. Events are not generated if the geometry itself is
animating and moving underneath the pointing device.

As the user moves the bearing over the TouchSensor node's geometry, the
point of intersection (if any) between the bearing and the geometry is
determined. Each movement of the pointing device, while _isOver_ is
`TRUE`, generates _hitPoint_changed_, _hitNormal_changed_ and
_hitTexCoord_changed_ events. _hitPoint_changed_ events contain the 3D
point on the surface of the underlying geometry, given in the
TouchSensor node's coordinate system. _hitNormal_changed_ events contain
the surface normal vector at the _hitPoint_. _hitTexCoord_changed_
events contain the texture coordinates of that surface at the
_hitPoint_. The values of _hitTexCoord_changed_ and _hitNormal_changed_
events are computed as appropriate for the associated shape.

If _isOver_ is `TRUE`, the user may activate the pointing device
to cause the TouchSensor node to generate _isActive_ events ( _e.g._, by
pressing the primary mouse button). When the TouchSensor node generates
an _isActive_ `TRUE` event, it grabs all further motion events
from the pointing device until it is released and generates an
_isActive_ `FALSE` event (other pointing device sensors will not
generate events during this time). Motion of the pointing device while
_isActive_ is `TRUE` is termed a "drag" operation. If a 2D
pointing device is in use, _isActive_ events reflect the state of the
primary button associated with the device ( _i.e._, _isActive_ is
`TRUE` when the primary button is pressed and `FALSE` when
it is released). If a 3D pointing device is in use, _isActive_ events
will typically reflect whether the pointing device is within (or in
contact with) the TouchSensor node's geometry.

The field _touchTime_ is generated when all three of the following
conditions are true:

[loweralpha]
. The pointing device was pointing towards the geometry
when it was initially activated ( _isActive_
is `TRUE`).
. The pointing device is currently pointing towards the
geometry ( _isOver_ is `TRUE`).
. The pointing device is deactivated ( _isActive_
`FALSE` event is also generated).

More information about this behaviour is described in
<<S20_Concepts, 20.2 Concepts>>.

[[S20.5_SupportLevels]]
=== 20.5 Support levels

The Pointing Device Sensor component provides one level of support as
specified in <<t20_2, Table 20.2>>.

[[t20_2]]
*Table 20.2 — Pointing device sensor component
support levels*

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 | |
| | |_X3DDragSensorNode_ (abstract) |n/a
| | |_X3DPointingDeviceSensorNode_ (abstract) |n/a
| | |_X3DTouchSensorNode_ (abstract) |n/a
| | |CylinderSensor |All fields fully supported.
| | |PlaneSensor |All fields fully supported.
| | |SphereSensor |All fields fully supported.
| | |TouchSensor |All fields fully supported.
|===

[[keyDeviceSensor_html]]
== 21 Key device sensor component

[[S21_Introduction]]
=== 21.1 Introduction

[[S21_Name]]
==== 21.1.1 Name

The name of this component is "KeyDeviceSensor". This name shall be used
when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.3.4 Component statement>>).

[[S21_Overview]]
==== 21.1.2 Overview

This clause describes the Key Device Sensor component of this document.
This includes how individual keystrokes and a series of keystrokes are
inserted into an X3D world. <<t21_1, Table 21.1>> provides links to
the major topics in this clause.

[[t21_1]]
Table 21.1 — Topics

* <<S21Introduction, 21.1 Introduction>>
** <<S21_Name, 21.1.1 Name>>
** <<S21_Overview, 21.1.2 Overview>>
* <<S21_Concepts, 21.2 Concepts>>
* <<S21_AbstractTypes, 21.3 Abstract types>>
** <<X3DKeyDeviceSensorNode, 21.3.1 _X3DKeyDeviceSensorNode_>>
* <<S21_NodeReference, 21.4 Node reference>>
** <<KeySensor, 21.4.1 KeySensor>>
** <<StringSensor, 21.4.2 StringSensor>>
* <<S21_SupportLevels, 21.5 Support levels>>

* <<t21_1, Table 21.1 — Topics>>
* <<t21_2, Table 21.2 — Action key values>>
* <<t21_3, Table 21.3 — Key Device Sensor component support levels>>




[[S21_Concepts]]
=== 21.2 Concepts

The following node types are keydevice sensors:

* <<KeySensor>>
* <<StringSensor>>

KeySensors generate an event whenever the state of a key associated with
the physical key device changes while the KeySensor is active. The
identification of the key whose state has changed is returned by the
event.

StringSensors generate an event whenever the termination string
specified for the StringSensor is identified. The UTF-8 characters
preceding the termination string are returned by the
event. StringSensors also generate interim events whenever the string
under construction changes. This allows prompting of the string during
construction.

One keyboard-style key device is assumed to be available either as a
physical device or through emulation whenever the sensor component is
supported. For a key device to generate input to a key device sensor,
the key device shall be active. Key devices are active when:

[loweralpha]
. The X3D world has focus in the supporting user interface; and
. The key device sensor has its _isActive_ field set to `TRUE`.

The _isActive_ event generated by a change of the state of the
_isActive_ field can be used for prompting.

A key device sensor is enabled when its _enabled_ field is set to
`TRUE`. This causes the _isActive_ field of the keydevice sensor
to be set to `TRUE`. Also, any other key device sensor which may
be active will be sent an _enabled_ event with value `FALSE`.
Only one key device sensor may be active at a time


=== 21.3 Abstract types

[[X3DKeyDeviceSensorNode]]
==== 21.3.1 _X3DKeyDeviceSensorNode_

[source,node]
----
X3DKeyDeviceSensorNode : X3DSensorNode {
  SFString [in,out] description ""
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL [X3DMetadataObject]
  SFBool   [out]    isActive         
}
----

This abstract node type is the base type for all sensor node types that
operate using key devices.


=== 21.4 Node reference

[[KeySensor]]
==== 21.4.1 KeySensor

[source,node]
----
KeySensor : X3DKeyDeviceSensorNode {
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFNode   [in,out] metadata         NULL [X3DMetadataObject]
  SFInt32  [out]    actionKeyPress   
  SFInt32  [out]    actionKeyRelease 
  SFBool   [out]    altKey           
  SFBool   [out]    controlKey       
  SFBool   [out]    isActive         
  SFString [out]    keyPress         
  SFString [out]    keyRelease       
  SFBool   [out]    shiftKey         
}
----

A KeySensor node generates events when the user presses keys on the
keyboard. A KeySensor node can be enabled or disabled by sending it an
_enabled_ event with a value of `TRUE` or `FALSE`. If the
KeySensor node is disabled, it does not track keyboard input or send
events.

_keyPress_ and _keyRelease_ events are generated as keys which produce
characters are pressed and released on the keyboard. The value of these
events is a string of length 1 containing the single UTF-8 character
associated with the key pressed. The set of UTF-8 characters that can be
generated will vary between different keyboards and different
implementations.

_actionKeyPress_ and _actionKeyRelease_ events are generated as 'action'
keys are pressed and released on the keyboard. The value of these events
are in <<t21_2, Table 21.2>>:

[[t21_2]]
*Table 21.2 — Action key values*

[cols=",,,,,",]
|===
|KEY |VALUE |KEY |VALUE |KEY |VALUE
|HOME |13 |END |14 |PGUP |15
|PGDN |16 |UP |17 |DOWN |18
|LEFT |19 |RIGHT |20 |F1-F12 |1-12
|===

_shiftKey_, _controlKey_, and _altKey_ events are generated as each of
the shift, control, and alt keys on the keyboard is respectively pressed
and released. Their value is `TRUE` when the key is pressed and
`FALSE` when the key is released.

When a key is pressed, the KeySensor sends an _isActive_ event with
value `TRUE`. Once the key is released, the KeySensor sends an
_isActive_ event with value `FALSE`.

The KeySensor is not affected by its position in the transformation
hierarchy.

Recommended default key mappings for navigation are described in
<<behaviours_html, Annex G Recommended navigation behaviours>>.

[[StringSensor]]
==== 21.4.2 StringSensor

[source,node]
----
StringSensor  : X3DKeyDeviceSensorNode {
  SFBool   [in,out] deletionAllowed TRUE
  SFString [in,out] description     ""
  SFBool   [in,out] enabled         TRUE
  SFNode   [in,out] metadata        NULL [X3DMetadataObject]
  SFString [out]    enteredText       
  SFString [out]    finalText         
  SFBool   [out]    isActive          
}
----

A StringSensor node generates events as the user presses keys on the
keyboard. A StringSensor node can be enabled or disabled by sending it
an _enabled_ event with a value of `TRUE` or `FALSE`. If
the StringSensor node is disabled, it does not track keyboard input or
send events.

_enteredText_ events are generated as keys which produce characters are
pressed on the keyboard. The value of this event is the UTF-8 string
entered including the latest character struck. The set of UTF-8
characters that can be generated will vary between different keyboards
and different implementations.

If a _deletionAllowed_ has value `TRUE`, the previously entered
character in the _enteredText_ is removed when the X3D
browser-recognized value for deleting the preceding character of a
string is entered. Typically, this value is defined by the local
operating system. If _deletionAllowed_ has value `FALSE`,
characters may only be added to the string; deletion of characters shall
not be allowed. Should the X3D browser-recognized value for deleting the
preceding character is entered, it shall be ignored.

The _finalText_ event is generated whenever the X3D browser-recognized
value for terminating a string is entered. Typically, this value is
defined by the local operating system. When this recognition occurs, the
_finalText_ field generates an event with value equal to that of
_enteredText_. After the _finalText_ field event has been generated, the
_enteredText_ field is set to the empty string but no event is
generated.

When the user begins typing, the StringSensor sends an _isActive_ event
with value `TRUE`. When the string is terminated, the
StringSensor sends an _isActive_ event with value `FALSE`.

The StringSensor is not affected by its position in the transformation
hierarchy.

[[S21.5_SupportLevels]]
=== 21.5 Support levels

The Key Device Sensor component provides 2 levels of support as
specified in <<t21_3, Table 21.3>>.

[[t21_3]]
*Table 21.3 — Key device sensor component support
levels*

[cols="^,,,",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 | |

| | |_X3DKeyDeviceSensorNode_ (abstract) |n/a

| | |KeySensor |All fields fully supported.

|*2* |Core 1 | |

| | |All Level 1 Key Device Sensor nodes |All fields as supported in
Level 1.

| | |StringSensor |All fields fully supported.
|===

[[environmentalSensor_html]]
== 22 Environmental sensor component

[[S22_Introduction]]
=== 22.1 Introduction

[[S22_Name]]
==== 22.1.1 Name

The name of this component is "EnvironmentalSensor". This name shall be
used when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S22_Overview]]
==== 22.1.2 Overview

This clause describes the Environmental Sensor component of this
document. Environmental sensor nodes emit events indicating user
activity in the scene environment, usually based on interactions between
the viewer and the world. <<t22_1, Table 22.1>> provides links to
the major topics in this clause.

[[t22_1]]
Table 22.1 — Topics

* <<S22Introduction, 22.1 Introduction>>
** <<S22_Name, 22.1.1 Name>>
** <<S22_Overview, 22.1.2 Overview>>
* <<S22_Concepts, 22.2 Concepts>>
* <<S22_AbstractTypes, 22.3 Abstract types>>
** <<X3DEnvironmentalSensorNode, 22.3.1 _X3DEnvironmentalSensorNode_>>
* <<S22_NodeReference, 22.4 Node reference>>
** <<ProximitySensor, 22.4.1 ProximitySensor>>
** <<TransformSensor, 22.4.2 TransformSensor>>
** <<VisibilitySensor, 22.4.3 VisibilitySensor>>
* <<S22_SupportLevels, 22.5 Support levels>>

* <<t22_1, Table 22.1 — Topics>>
* <<t22_2, Table 22.2 — Environmental sensor component support levels>>




[[S22_Concepts]]
=== 22.2 Concepts

Environment sensors are nodes which emit events based on some event
which occurs within the environment, usually an interaction between two
elements within the world. Most environment sensors events occur because
of an interaction between the viewer and the world. However, an
environment sensor event may also occur because of an interaction
between a non-manipulable piece of hardware ( _e.g._, a clock) and the
world, between two objects in the world, or an event over the network.

Environmental sensors include:

* <<Collision>>
* <<ProximitySensor>>
* <<TransformSensor>>
* <<VisibilitySensor>>

The <<Collision>> grouping node detects when the user
collides with objects in the virtual world. Proximity, collision, and
visibility sensors are each processed independently of whether others
exist or overlap. See <<navigation_html, 23 Navigation component>> for
more information.

The <<ProximitySensor>> detects when the user
navigates into a specified region in the world.

The <<TransformSensor>> detects when for the target
object specified enters, exits, or is transformed within a specified
rectangular parallelepiped.

The <<VisibilitySensor>> detects when a specific
part of the world becomes visible to the user.

When environmental sensors are inserted into the transformation
hierarchy and before the presentation is updated ( _i.e._, read from
file or created by a script), they shall generate events indicating any
conditions which the sensor is intended to detect. The conditions for
individual sensor types to generate these initial events are defined in
the individual node specifications in <<S22_NodeReference, 22.4 Node reference>>.


=== 22.3 Abstract types

[[X3DEnvironmentalSensorNode]]
==== 22.3.1 _X3DEnvironmentalSensorNode_

[source,node]
----
X3DEnvironmentalSensorNode : X3DSensorNode {
  SFVec3f/d [in,out] center      0 0 0 (-∞,∞)
  SFString  [in,out] description ""
  SFBool    [in,out] enabled     TRUE
  SFNode    [in,out] metadata    NULL  [X3DMetadataObject]
  SFVec3f   [in,out] size        0 0 0  [0,∞)
  SFTime    [out]    enterTime
  SFTime    [out]    exitTime
  SFBool    [out]    isActive
}
----

The X3DEnvironmentalSensorNode abstract node type is the base type for
the environmental sensor nodes <<ProximitySensor>>,
<<TransformSensor>> and
<<VisibilitySensor>>.

The _center_ field defines the center location of the specified sensor
volume.

The _size_ field defines the effective volume of the sensor. A default
value of `0 0 0` means that the sensor has no active volume and
is essentially disabled.


=== 22.4 Node reference

[[ProximitySensor]]
==== 22.4.1 ProximitySensor

[source,node]
----
ProximitySensor : X3DEnvironmentalSensorNode {
  SFVec3f    [in,out] center                   0 0 0 (-∞,∞)
  SFString   [in,out] description              ""
  SFBool     [in,out] enabled                  TRUE
  SFNode     [in,out] metadata                 NULL  [X3DMetadataObject]
  SFVec3f    [in,out] size                     0 0 0 [0,∞)
  SFTime     [out]    enterTime
  SFTime     [out]    exitTime
  SFVec3f    [out]    centerOfRotation_changed
  SFBool     [out]    isActive
  SFRotation [out]    orientation_changed
  SFVec3f    [out]    position_changed
}
----

The ProximitySensor node generates events when the viewer enters, exits,
and moves within a region in space (defined by a box). A proximity
sensor is enabled or disabled by sending it an _enabled_ event with a
value of `TRUE` or `FALSE`. A disabled sensor does not
send events.

A ProximitySensor node generates _isActive_ `TRUE`/`FALSE`
events as the viewer enters and exits the rectangular box defined by its
_center_ and _size_ fields. X3D browsers shall interpolate viewer
positions and timestamp the _isActive_ events with the exact time the
viewer first intersected the proximity region. The _center_ field
defines the centre point of the proximity region in object space. The
_size_ field specifies a vector which defines the width (x), height (y),
and depth (z) of the box bounding the region. The components of the
_size_ field shall be greater than or equal to zero. ProximitySensor
nodes are affected by the hierarchical transformations of their parents.

The _enterTime_ event is generated whenever the _isActive_ `TRUE`
event is generated (user enters the box), and _exitTime_ events are
generated whenever an _isActive_ `FALSE` event is generated (user
exits the box).

The _centerOfRotation_changed_ field sends events whenever the user is
contained within the proximity region and the center of rotation of the
viewer for `EXAMINE` mode changes with respect to the
ProximitySensor node's coordinate system. This may result when the bound
<<Viewpoint>> nodes's center of rotation changes, when a
new viewpoint is bound, when the user changes the center of rotation
through the X3D browser's user interface, or from changes to the
ProximitySensor node's coordinate system. _centerOfRotation_changed_
events are only generated when the currently bound
<<NavigationInfo>> node includes `LOOKAT`
navigation. For more information, see <<X3DViewpointNode, 23.3.1 _X3DViewpointNode_>> and <<NavigationInfo, 23.4.4. NavigationInfo>>.

The _position_changed_ and _orientation_changed_ fields send events
whenever the user is contained within the proximity region and the
position and orientation of the viewer changes with respect to the
ProximitySensor node's coordinate system including enter and exit times.
The viewer movement may be a result of a variety of circumstances
resulting from X3D browser navigation, ProximitySensor node's coordinate
system changes, or bound Viewpoint node's position or orientation
changes.

Each ProximitySensor node behaves independently of all other
ProximitySensor nodes. Every enabled ProximitySensor node that is
affected by the viewer's movement receives and sends events, possibly
resulting in multiple ProximitySensor nodes receiving and sending events
simultaneously. Unlike <<TouchSensor>> nodes, there is no
notion of a ProximitySensor node lower in the scene graph "grabbing"
events.

Instanced (DEF/USE) ProximitySensor nodes use the union of all the boxes
to check for enter and exit. A multiply instanced ProximitySensor node
will detect enter and exit for all instances of the box and send
enter/exit events appropriately. For non-overlapping bounding boxes,
_position_changed_ and _orientation_changed_ events are calculated
relative to the coordinate system associated with the bounding box in
which the proximity was detected. However, the results are undefined if
the any of the boxes of a multiply instanced ProximitySensor node
overlap.

A ProximitySensor node that surrounds the entire world has an
_enterTime_ equal to the time that the world was entered. This event can
be used to start up animations or behaviours as soon as a world is
loaded or as soon as the _enabled_ field of the ProximitySensor is set
to TRUE. A ProximitySensor node with a box containing zero volume (
_i.e._, any _size_ field element of 0.0) cannot generate events. This is
equivalent to setting the _enabled_ field to `FALSE`.

A ProximitySensor read from an X3D file shall generate _isActive_
`TRUE`, _position_changed_, _orientation_changed_ and _enterTime_
events if the sensor is enabled and the viewer is inside the proximity
region or as soon as the ProximitySensor is enabled. A ProximitySensor
inserted into the transformation hierarchy shall generate _isActive_
`TRUE`, _position_changed_, _orientation_changed_ and _enterTime_
events if the sensor is enabled and the viewer is inside the proximity
region. A ProximitySensor removed from the transformation hierarchy
shall generate _isActive_ `FALSE`, _position_changed_,
_orientation_changed_ and _exitTime_ events if the sensor is enabled and
the viewer is inside the proximity region.

[[TransformSensor]]
==== 22.4.2 TransformSensor

[source,node]
----
TransformSensor : X3DEnvironmentalSensorNode {
  SFVec3f    [in,out] center              0 0 0 (-∞,∞)
  SFString   [in,out] description         ""
  SFBool     [in,out] enabled             TRUE
  SFNode     [in,out] metadata            NULL  [X3DMetadataObject]
  SFVec3f    [in,out] size                0 0 0 [0,∞)
  SFNode     [in,out] targetObject        NULL  [X3DGroupingNode|X3DShapeNode]
  SFTime     [out]    enterTime
  SFTime     [out]    exitTime
  SFBool     [out]    isActive
  SFRotation [out]    orientation_changed
  SFVec3f    [out]    position_changed
}
----

The TransformSensor node generates events when its target object enters,
exits, and moves within a region in space (defined by a box). The target
object can be any valid _<<X3DShapeNode>>_ or
_<<X3DGroupingNode>>_ node. A TransformSensor is
enabled or disabled by sending it an _enabled_ event with a value of
`TRUE` or `FALSE`. A disabled sensor does not send events.

A TransformSensor node generates _isActive_ `TRUE`/`FALSE`
events as the target object enters and exits the rectangular box defined
by its _center_ and _size_ fields. X3D browsers shall timestamp the
_isActive_ events with the exact time the target object first
intersected the proximity region. The _center_ field defines the centre
point of the proximity region in object space. The _size_ field
specifies a vector that defines the width (x), height (y), and depth (z)
of the box bounding the region. The components of the _size_ field shall
be greater than or equal to zero. TransformSensor nodes are affected by
the hierarchical transformations of their parents.

The _enterTime_ event is generated whenever the _isActive_ `TRUE`
event is generated (target object enters the box), and _exitTime_ events
are generated whenever an _isActive_ `FALSE` event is generated
(target object exits the box).

The _position_changed_ and _orientation_changed_ fields send events
whenever the target object is contained within the proximity region and
the position and orientation of the target object changes with respect
to the TransformSensor node's coordinate system including enter and exit
times. The object movement may be a result of a variety of circumstances
resulting from the TransformSensor node's coordinate system changes,
changes to the target object's position or orientation, or changes to
the coordinate system of any of the ancestors or the target object.

Each TransformSensor node behaves independently of all other
TransformSensor nodes. Every enabled TransformSensor node that is
affected by the target object's movement receives and sends events,
possibly resulting in multiple TransformSensor nodes receiving and
sending events simultaneously. Unlike TouchSensor nodes, there is no
notion of a TransformSensor node lower in the scene graph "grabbing"
events.

Instanced (DEF/USE) TransformSensor nodes use the union of all the boxes
to check for enter and exit. A multiply instanced TransformSensor node
will detect enter and exit for all instances of the box and send
enter/exit events appropriately. For non-overlapping bounding boxes,
_position_changed_ and _orientation_changed_ events are calculated
relative to the coordinate system associated with the bounding box in
which the proximity was detected. However, the results are undefined if
the any of the boxes of a multiply instanced TransformSensor node
overlap.

A TransformSensor node with a box containing zero volume ( _i.e._, any
_size_ field element of 0.0) cannot generate events. This is equivalent
to setting the _enabled_ field to `FALSE`.

A TransformSensor read from an X3D file shall generate _isActive_
 `TRUE`, _position_changed_, _orientation_changed_ and
_enterTime_ events if the sensor is enabled and the target object is
inside the proximity region. A TransformSensor inserted into the
transformation hierarchy shall generate _isActive_ `TRUE`,
_position_changed_, _orientation_changed_ and _enterTime_ events if the
sensor is enabled and the target object is inside the proximity region.
A TransformSensor removed from the transformation hierarchy shall
generate _isActive_ `FALSE`, _position_changed_,
_orientation_changed_ and _exitTime_ events if the sensor is enabled and
the target object is inside the proximity region.

[[VisibilitySensor]]
==== 22.4.3 VisibilitySensor

[source,node]
----
VisibilitySensor : X3DEnvironmentalSensorNode {
  SFVec3f  [in,out] center      0 0 0 (-∞,∞)
  SFString [in,out] description ""
  SFBool   [in,out] enabled     TRUE
  SFNode   [in,out] metadata    NULL  [X3DMetadataObject]
  SFVec3f  [in,out] size        0 0 0 [0,∞)
  SFTime   [out]    enterTime
  SFTime   [out]    exitTime
  SFBool   [out]    isActive
}
----

The VisibilitySensor node detects visibility changes of a rectangular
box as the user navigates the world. VisibilitySensor is typically used
to detect when the user can see a specific object or region in the scene
in order to activate or deactivate some behaviour or animation. The
purpose is often to attract the attention of the user or to improve
performance. Intermediate occluding geometry between the current
viewpoint and the sensed volume has no effect on the behavior of the
VisibilitySensor.

The _enabled_ field enables and disables the VisibilitySensor node. If
_enabled_ is set to `FALSE`, the VisibilitySensor node does not
send events. If _enabled_ is `TRUE`, the VisibilitySensor node
detects changes to the visibility status of the box specified and sends
events through the _isActive_ field. A `TRUE` event is output to
_isActive_ when any portion of the box impacts the rendered view. A
`FALSE` event is sent when the box has no effect on the view. X3D
browsers shall guarantee that, if _isActive_ is `FALSE`, the box
has absolutely no effect on the rendered view. X3D browsers may err
liberally when _isActive_ is `TRUE`. For example, the box may
affect the rendering.

The fields _center_ and _size_ specify the object space location of the
box centre and the extents of the box ( _i.e._, width, height, and
depth). The VisibilitySensor node's box is affected by hierarchical
transformations of its parents. The components of the _size_ field shall
be greater than or equal to zero.

The _enterTime_ event is generated whenever the _isActive_ `TRUE`
event is generated, and _exitTime_ events are generated whenever
_isActive_ `FALSE` events are generated. A VisibilitySensor read
from an X3D file shall generate _isActive_ `TRUE` and _enterTime_
events if the sensor is enabled and the visibility box is visible. A
VisibilitySensor inserted into the transformation hierarchy shall
generate _isActive_ `TRUE` and _enterTime_ events if the sensor
is enabled and the visibility box is visible. A VisibilitySensor removed
from the transformation hierarchy shall generate _isActive_
`FALSE` and _exitTime_ events if the sensor is enabled and the
visibility box is visible.

Each VisibilitySensor node behaves independently of all other
VisibilitySensor nodes. Every enabled VisibilitySensor node that is
affected by the user's movement receives and sends events, possibly
resulting in multiple VisibilitySensor nodes receiving and sending
events simultaneously. Unlike TouchSensor nodes, there is no notion of a
VisibilitySensor node lower in the scene graph "grabbing" events.
Multiply instanced VisibilitySensor nodes ( _i.e._, DEF/USE) use the
union of all the boxes defined by their instances. An instanced
VisibilitySensor node shall detect visibility changes for all instances
of the box and send events appropriately.

[[S22.5_SupportLevels]]
=== 22.5 Support levels

The Environmental Sensor component provides two levels of support as
specified in <<t22_2, Table 22.2>>. Level 1 is intended to
enable automatic animations by supporting a simplified ProximitySensor
node. Level 2 provides full environment sensing support.

[[t22_2]]
*Table 22.2 — Environmental sensor* component
support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes |Support
|*1* |Core 1 +
Time 1 +
Grouping 1 +
Navigation 1 | |

| | |_X3DEnvironmentSensorNode_ (abstract) |n/a

| | |ProximitySensor |_position_changed_ optionally supported. +
_orientation_changed_ optionally supported.

|*2* |Core 1 +
Time 1 +
Grouping 1 +
Navigation 1 | |

| | |All Level 1 Environmental Sensor nodes |All fields as supported in
Level 1.

| | |ProximitySensor |All fields fully supported.

| | |VisibilitySensor |All fields fully supported.

|*3* |Core 1 +
Time 1 +
Grouping 1 +
Navigation 1 |  | 

|  |  |All Level 2 Environmental Sensor nodes |All fields as supported
in Level 2.

|  |  |TransformSensor |All fields fully supported.
|===

[[navigation_html]]
== 23 Navigation component

[[S23_Introduction]]
=== 23.1 Introduction

[[S23_Name]]
==== 23.1.1 Name

The name of this component is "Navigation". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S23_Overview]]
==== 23.1.2 Overview

This clause describes the Navigation component of this document. The
Navigation component specifies how a user can effectively and
intuitively move through and around an X3D scene. <<t23_1, Table 23.1>> provides links to the major topics in this clause.

[[t23_1]]
Table 23.1 — Topics

* <<S23Introduction, 23.1 Introduction>>
** <<S23_Name, 23.1.1 Name>>
** <<S23_Overview, 23.1.2 Overview>>
* <<S23_Concepts, 23.2 Concepts>>
** <<OverviewOfNavigation, 23.2.1 An overview of navigation>>
** <<Navigationparadigms, 23.2.2 Navigation paradigms>>
** <<Viewingmodel, 23.2.3 Viewing model>>
** <<Collisiondetection, 23.2.4 Collision detection and terrain following>>
** <<ViewpointList, 23.2.5 Viewpoint list>>
* <<S23_AbstractTypes, 23.3 Abstract types>>
** <<X3DViewpointNode, 23.3.1 _X3DViewpointNode_>>
* <<S23_NodeReference, 23.4 Node reference>>
** <<Billboard, 23.4.1 Billboard>>
** <<Collision, 23.4.2 Collision>>
** <<LOD, 23.4.3 LOD>>
** <<NavigationInfo, 23.4.4 NavigationInfo>>
** <<OrthoViewpoint, 23.4.5 OrthoViewpoint>>
** <<Viewpoint, 23.4.6 Viewpoint>>
** <<ViewpointGroup, 23.4.7 ViewpointGroup>>
* <<S23_SupportLevels, 23.5 Support levels>>

* <<t23_1, Table 23.1 — Topics>>
* <<t23_2, Table 23.2 — Navigation component support levels>>




[[S23_Concepts]]
=== 23.2 Concepts

[[OverviewOfNavigation]]
==== 23.2.1 An overview of navigation

Navigation is the capability of users to interact with the X3D browser
using one or more input devices to affect the view it presents.
Navigation support is not required for all profiles.

Every X3D scene can be thought of as containing a _viewpoint_ from which
the objects in the scene are presented to the viewer. Navigation permits
the user to change the position and orientation of the viewpoint with
respect to the remainder of the scene thereby enabling the user to move
through the scene and examine objects in the scene.

The <<NavigationInfo>> node (see
<<NavigationInfo, 23.4.4 NavigationInfo>>) specifies the
characteristics of the desired navigation behaviour, but the exact user
interface is X3D browser-dependent. Nodes derived from
<<X3DViewpointNode, _X3DViewpointNode_>> (see
<<X3DViewpointNode, 23.3.1 _X3DViewpointNode_>>) specify key locations
and orientations in the world to which the user may be moved via SAI
services or X3D browser-specific user interfaces.

[[Navigationparadigms]]
==== 23.2.2 Navigation paradigms

The X3D browser may allow the user to modify the location and
orientation of the viewer in the virtual world using a navigation
paradigm. Many different navigation paradigms are possible, depending on
the nature of the virtual world and the task the user wishes to perform.
For instance, a walking paradigm would be appropriate in an
architectural walkthrough application, while a flying paradigm might be
better in an application exploring interstellar space. Examination is
another common use for X3D, where the scene contains one or more objects
which the user wishes to view from many angles and distances.

The <<NavigationInfo>> node has a _type_ field that
specifies the navigation paradigm for this world. The actual user
interface provided to accomplish this navigation is X3D
browser-dependent. See <<NavigationInfo, 23.4.4 NavigationInfo>>, for
details.

[[Viewingmodel]]
==== 23.2.3 Viewing model

The X3D browser controls the location and orientation of the viewer in
the world, based on input from the user (using the X3D browser-provided
navigation paradigm) and the motion of the currently bound
_<<X3DViewpointNode>>_ node (and its coordinate
system). The X3D author can place any number of viewpoints in the world
at important places from which the user might wish to view the world.
Each viewpoint is described by an _X3DViewpointNode_ node. Viewpoint
nodes exist in their parent's coordinate system, and both the viewpoint
and the coordinate system may be changed to affect the view of the world
presented by the X3D browser. Only one viewpoint is bound at a time. A
detailed description of how _X3DViewpointNode_ nodes operate is
specified in <<BindableChildrenNodes, 7.2.2 Bindable children nodes>>
and <<X3DViewpointNode, 23.3.1 _X3DViewpointNode_>>.

Navigation is performed relative to the viewpoint's location and does
not affect the location and orientation values of an _X3DViewpointNode_
node. The location of the viewer may be determined with a
<<ProximitySensor>> node (see
<<ProximitySensor, 22.4.1 ProximitySensor>>).

This document specifies two node types derived from _X3DViewpointNode_.
The <<Viewpoint>> node specifies a perspective viewpoint
while the <<OrthoViewpoint>> node specifies an
orthographic viewpoint.

[[Collisiondetection]]
==== 23.2.4 Collision detection and terrain following

In profiles in which collision detection is required, the
<<NavigationInfo>> types of `WALK`,
`FLY`, and `NONE` shall strictly support collision
detection between the user's avatar and other objects in the scene by
prohibiting navigation and/or adjusting the position of the viewpoint.
However, the NavigationInfo types `ANY` and `EXAMINE` may
temporarily disable collision detection during navigation, but shall not
disable collision detection during the normal execution of the world.
See <<NavigationInfo, 23.4.4 NavigationInfo>>, for details on the
various navigation types.

Collision nodes can be used to generate events when viewer and objects
collide, and can be used to designate that certain objects should be
treated as not being subject to collision detection and should not be
recognized as terrain for navigation modes that require terrain
following to be supported. X3D browser support for inter-object
collision is not specified.

NavigationInfo nodes can be used to specify certain parameters often
used by X3D browser navigation paradigms. The size and shape of the
viewer's avatar determines how close the avatar may be to an object
before a collision is considered to take place. These parameters can
also be used to implement _terrain following_ by keeping the avatar a
certain distance above the ground. They can additionally be used to
determine how short an object shall be for the viewer to automatically
step up onto it instead of colliding with it.

[[ViewpointList]]
==== 23.2.5 Viewpoint list

The viewpoint list is an optional X3D browser-provided feature that
lists currently available viewpoints for user information and selection.

Viewpoints are listed in the order corresponding to the extended scene
graph. Thus viewpoints contained in <<Inline>> nodes and nodes
that are instances of prototypes are loaded in the order defined by the
scene, even if load time delays are different from scene-specified
order. This has no effect on specification-defined eligibility for first
bound viewpoint. Viewpoints that are removed from the scene are no
longer eligible for the viewpoint list.

Selecting a viewpoint from a viewpoint list will first unbind the
current viewpoint before binding the selected viewpoint. When
_retainUserOffsets_ is `FALSE`, the viewer is returned to the
originally defined viewpoint position/orientation after local
navigation. Such a return to the defined viewpoint can occur either by
reselection of current viewpoint from the viewpoint list, or else by
using the PgUp key (as defined in
<<SelectFromMultipleViewpoints, Annex G.2 Select from multiple viewpoints>>).


=== 23.3 Abstract types

[[X3DViewpointNode]]
==== 23.3.1 _X3DViewpointNode_

[source,node]
----
X3DViewpointNode : X3DBindableNode {
  SFBool     [in]     set_bind
  SFVec3f/d  [in,out] centerOfRotation  0 0 0     (-∞,∞)
  SFString   [in,out] description       ""
  SFFloat    [in,out] farDistance       -1        -1 or (0,∞)
  SFBool     [in,out] jump              TRUE
  SFNode     [in,out] metadata          NULL      [X3DMetadataObject]
  SFNode     [in,out] navigationInfo    NULL      [NavigationInfo]
  SFFloat    [in,out] nearDistance      -1        -1 or (0,∞)
  SFRotation [in,out] orientation       0 0 1 0   (-∞,∞)
  SFVec3f/d  [in,out] position          0 0 10    (-∞,∞)
  SFBool     [in,out] retainUserOffsets FALSE
  SFBool     [in,out] viewAll           FALSE
  SFTime     [out]    bindTime
  SFBool     [out]    isBound
}
----

A node of node type _X3DViewpointNode_ defines a specific location in
the local coordinate system from which the user may view the scene.
_X3DViewpointNode_ nodes are bindable children nodes (see
<<BindableChildrenNodes, 7.2.2 Bindable children nodes>>) and thus
there exists an _X3DViewpointNode_ stack in the X3D browser in which the
top-most _X3DViewpointNode_ node on the stack is the currently active
_X3DViewpointNode_ node. If a `TRUE` value is sent to the
_set_bind_ field of an _X3DViewpointNode_ node, it is moved to the top
of the _X3DViewpointNode_ node stack and activated. When an
_X3DViewpointNode_ node is at the top of the stack, the user's view is
conceptually re-parented as a child of the _X3DViewpointNode_ node. All
subsequent changes to the _X3DViewpointNode_ node's coordinate system
change the user's view ( _e.g._, changes to any ancestor transformation
nodes or to the _X3DViewpointNode_ node's _position_ or _orientation_
fields). Sending a _set_bind_ `FALSE` event removes the
_X3DViewpointNode_ node from the stack and produces _isBound_
`FALSE` and _bindTime_ events. If the popped _X3DViewpointNode_
node is at the top of the _X3DViewpointNode_ stack, the user's view is
re-parented to the next entry in the stack. More details on binding
stacks can be found in <<BindableChildrenNodes, 7.2.2 Bindable children nodes>>. When an _X3DViewpointNode_ node is moved to the top of
the stack, the existing top of stack _X3DViewpointNode_ node sends an
_isBound_ `FALSE` event and is pushed down the stack.

An author can automatically move the user's view through the world by
binding the user to either an _X3DViewpointNode_ node and then animating
either the _X3DViewpointNode_ node or the transformations above it. X3D
browsers shall allow the user view to be navigated relative to the
coordinate system defined by the _X3DViewpointNode_ node (and the
transformations above it) even if the _X3DViewpointNode_ node or its
ancestors' transformations are being animated.

The _bindTime_ field sends the time at which the _X3DViewpointNode_ node
is bound or unbound. This can happen:

[loweralpha]
. during loading;
. when a _set_bind_ event is sent to the _X3DViewpointNode_ node;
. when the X3D browser binds to the _X3DViewpointNode_ node through its
user interface described below.

The _position_ and _orientation_ fields of the _X3DViewpointNode_ node
specify relative locations in the local coordinate system. _Position_ is
relative to the coordinate system's origin (0,0,0), while _orientation_
specifies a rotation relative to the default orientation. In the default
position and orientation, the viewer is on the Z-axis looking down the
−Z-axis toward the origin with +X to the right and +Y straight up.
_X3DViewpointNode_ nodes are affected by the transformation hierarchy.

Navigation types (see <<NavigationInfo, 23.4.4 NavigationInfo>>) that
require a definition of a down vector ( _e.g._, terrain following) shall
use the negative Y-axis of the coordinate system of the currently bound
_X3DViewpointNode_ node. Likewise, navigation types that require a
definition of an up vector shall use the positive Y-axis of the
coordinate system of the currently bound _X3DViewpointNode_ node. The
_orientation_ field of the _X3DViewpointNode_ node does not affect the
definition of the down or up vectors. This allows the author to separate
the viewing direction from the gravity direction.

The _jump_ field specifies whether the user's view "jumps" to the
position and orientation of a bound _X3DViewpointNode_ node or remains
unchanged. This jump is instantaneous and discontinuous in that no
collisions are performed and no <<ProximitySensor>>
nodes are checked in between the starting and ending jump points. If the
user's position before the jump is inside a ProximitySensor the
_exitTime_ of that sensor shall send the same timestamp as the bind
field. Similarly, if the user's position after the jump is inside a
ProximitySensor the _enterTime_ of that sensor shall send the same
timestamp as the bind field. Regardless of the value of _jump_ at bind
time, the relative viewing transformation between the user's view and
the current _X3DViewpointNode_ node shall be stored with the current
_X3DViewpointNode_ node for later use when _un-jumping_ (
_i.e._, popping the _X3DViewpointNode_ binding stack from an
_X3DViewpointNode_ node with _jump_ `TRUE`). The following
summarizes the bind stack rules (see <<BindableChildrenNodes, 7.2.2 Bindable children nodes>>) with additional rules regarding
_X3DViewpointNode_ nodes (displayed in boldface type):

[loweralpha, start=4]
. During read, the first encountered _X3DViewpointNode_ node is bound by
pushing it to the top of the _X3DViewpointNode_ node stack. If an
_X3DViewpointNode_ node name is specified in the URL that is being read,
this named _X3DViewpointNode_ node is considered to be the first
encountered _X3DViewpointNode_ node. Nodes contained within Inline nodes
(see <<Inline, 9.4.2 Inline>>), within the strings passed to the
Browser.createX3DFromString() method, or within files passed to the
Browser.createX3DFromURL() method (see <<I19775_2, ISO/IEC 19775-2>>)
are not candidates for the first encountered _X3DViewpointNode_ node.
The first node within a prototype instance is a valid candidate for the
first encountered _X3DViewpointNode_ node. The first encountered
_X3DViewpointNode_ node sends an isBound `TRUE` event.
. When a set_bind `TRUE` event is received by an
_X3DViewpointNode_ node,
[arabic]
.. If it is not on the top of the stack: The relative
transformation from the current top of stack _X3DViewpointNode_ node to
the user's view is stored with the current top of stack
__X3DViewpointNode__node. The current top of stack node sends an
_isBound_ `FALSE` event. The new node is moved to
the top of the stack and becomes the currently bound X3DViewpointNode
node. The new _X3DViewpointNode_ node (top of stack) sends an _isBound_
`TRUE` event. If _jump_ is `TRUE` for the new
_X3DViewpointNode_ node, the user's view is instantaneously "jumped" to
match the values in the _position_ and __orientation__fields of the new
__X3DViewpointNode__node.
.. If the node is already at the top of the stack, this event has no
affect.
. When a _set_bind_ `FALSE` event is received by an
_X3DViewpointNode_ node in the stack, it is removed from the stack. If
it was on the top of the stack,
[arabic]
.. it sends an _isBound_ `FALSE` event,
.. the next node in the stack becomes the currently bound
_X3DViewpointNode_ node ( _i.e._, pop) and issues an _isBound_
`TRUE` event,
.. if its _jump_ field value is`#TRUE`#, the user's view is
instantaneously "jumped" to the _position_ and __orientation__of the
next _X3DViewpointNode_ node in the stack with the stored
relative transformation of this next __X3DViewpointNode__node applied.
. If a _set_bind_ `FALSE` event is received by a node not in the
stack, the event is ignored and _isBound_ events are not sent.
. When a node replaces another node at the top of the stack, the
_isBound_ `TRUE` and `FALSE` events from the two nodes are
sent simultaneously ( _i.e._, with identical timestamps).
. If a bound node is deleted, it behaves as if it received a _set_bind_
`FALSE` event (see c. above).

The _jump_ field may change after an _X3DViewpointNode_ node is bound.
The rules described above still apply. If _jump_ was `TRUE` when
the _X3DViewpointNode_ node is bound, but changed to `FALSE`
before the _set_bind_ `FALSE` is sent, the _X3DViewpointNode_
node does not _un-jump_ during unbind. If _jump_ was `FALSE` when
the _X3DViewpointNode_ node is bound, but changed to `TRUE`
before the _set_bind_ `FALSE` is sent, the _X3DViewpointNode_
node does perform the _un-jump_ during unbind.

Note that there are two other mechanisms that result in the binding of a
new _X3DViewpointNode_:

[loweralpha, start=10]
. An <<Anchor>> node's _url_ field specifies a
"#X3DViewpointNodeName".
. A script invokes the `loadURL()` method and the URL argument
specifies a "#X3DViewpointNodeName".

Both of these mechanisms override the _jump_ field value of the
specified _X3DViewpointNode_ node (#X3DViewpointNodeName) and assume
that _jump_ is `TRUE` when binding to the new _X3DViewpointNode_.
The behaviour of the viewer transition to the newly bound
_X3DViewpointNode_ depends on the currently bound
<<NavigationInfo>> node's _type_ field value (see
<<NavigationInfo, 23.4.4 NavigationInfo>>).

The _fieldOfView_ field specifies a preferred minimum viewing angle from
this _X3DViewpointNode_ in angle base units. A small field of view
roughly corresponds to a telephoto lens; a large field of view roughly
corresponds to a wide-angle lens. The field of view shall be greater
than zero and smaller than π. The value of _fieldOfView_
represents the minimum viewing angle in any direction axis perpendicular
to the view. For example, a X3D browser with a rectangular viewing
projection shall have the following relationship:

   display width    tan(FOV~horizontal~/2) +
   -------------- = ------------------- +
   display height   tan(FOV~vertical~/2) +

where the smaller of display width or display height determines which
angle equals the _fieldOfView_ (the larger angle is computed using the
relationship described above). The larger angle shall not exceed
π and may force the smaller angle to be less than
_fieldOfView_ in order to sustain the aspect ratio.

The _description_ field specifies a textual description of the
_X3DViewpointNode_ node. This may be used by X3D browser-specific user
interfaces. If an _X3DViewpointNode_'s _description_ field is empty it
is recommended that the X3D browser not present this _X3DViewpointNode_
in its X3D browser-specific user interface.

The _centerOfRotation_ field specifies a center about which to rotate
the user's eyepoint when in `EXAMINE` mode. The
_centerOfRotation_ field is in the same local coordinate system as the
current viewpoint node's _position_ and _orientation_ fields, in
accordance with <<S4_TransformationHierarchy, 4.3.5 Transformation hierarchy>>. If the X3D browser does not provide the ability to spin
around the object in `EXAMINE` mode, or `LOOKAT` is not in
the list of allowed navigation modes, this field shall be ignored. For
additional information, see <<NavigationInfo, 23.4.4 NavigationInfo>>
and <<ProximitySensor, 22.4.1 ProximitySensor>>.

The URL syntax "`.../scene.wrl`X3DViewpointNodeName#" specifies
the user's initial view when loading "scene.wrl" to be the first
X3DViewpointNode node in the X3D file that appears as `DEF X3DViewpointNodeName X3DViewpointNode {...}`. This overrides the
first _X3DViewpointNode_ node in the X3D file as the initial user view,
and a _set_bind_ `TRUE` message is sent to the X3DViewpointNode
node named "X3DViewpointNodeName". If the _X3DViewpointNode_ node named
"X3DViewpointNodeName" is not found, the X3D browser shall use the first
_X3DViewpointNode_ node in the X3D file ( _i.e._, the normal default
behaviour). The URL syntax "`#X3DViewpointNodeName`" ( _i.e._, no
file name) specifies an _X3DViewpointNode_ within the existing X3D file.
If this URL is loaded ( _e.g._, Anchor node's _url_ field or
`loadURL()` method is invoked by a Script node), the
_X3DViewpointNode_ node named "X3DViewpointNodeName" is bound (a
_set_bind_ `TRUE` event is sent to this X3DViewpointNode node).

The _retainUserOffsets_ field indicates whether a viewpoint needs to
retain (`TRUE`) or reset to zero (`FALSE`) any prior user
navigation offsets from defined viewpoint position, orientation. When a
node of type _X3DViewpointNode_ is bound, user navigation offsets are
reinitialized if the associated _retainUserOffsets_ is `TRUE`.

The _navigationInfo_ field defines a dedicated NavigationInfo node for
this X3DViewpointNode. The specified NavigationInfo node receives a
_set_bind_ `TRUE` event at the time when the parent node is bound
and receives a _set_bind_ `FALSE` at the time when the parent
node is unbound.

If provided and positive, the values for _nearDistance_ and
_farDistance_ determine the near and far clipping plane distances when
the X3DViewpointNode is bound. Otherwise these values may be determined
using NavigationInfo guidelines for the bound NavigationInfo node,
including when the X3DViewpointNode is unbound.

If _nearDistance_ is defined, it shall be less than the defined
_farDistance_ (if provided) or the corresponding visibilityLimit value
defined by NavigationInfo. If _farDistance_ is defined, it shall be
greater than the defined _nearDistance_ (if provided) or the
corresponding value defined by NavigationInfo.

A default value of -1 for _nearDistance_ or _farDistance_ means that the
field has no effect on currently active view-frustum boundaries.

Each type of viewpoint defines the specific actions associated with the
_viewAll_ field.


=== 23.4 Node reference

[[Billboard]]
==== 23.4.1 Billboard

[source,node]
----
Billboard : X3DGroupingNode {
  MFNode  [in]     addChildren             [X3DChildNode]
  MFNode  [in]     removeChildren          [X3DChildNode]
  SFVec3f [in,out] axisOfRotation 0 1 0    (-∞,∞)
  MFNode  [in,out] children       []       [X3DChildNode]
  SFBool  [in,out] bboxDisplay    FALSE
  SFNode  [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool  [in,out] visible        TRUE
  SFVec3f []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f []       bboxSize       -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The Billboard node is a grouping node that transforms the coordinate
system of its children so that the local Z-axis of the children turns to
point at the viewer within the limitations of its rotational axis.

The _axisOfRotation_ field specifies which axis to use to perform the
rotation. This axis is defined in the local coordinate system.

When the _axisOfRotation_ field is not (0, 0, 0), the following steps
describe how to rotate the billboard to face the viewer:

[loweralpha]
. Compute the vector from the Billboard node's origin to the viewer's
position. This vector is called the _billboard-to-viewer_ vector.
. Compute the plane defined by the _axisOfRotation_ and the
billboard-to-viewer vector.
. Rotate the local Z-axis of the billboard into the plane from b.,
pivoting around the _axisOfRotation_.

When the _axisOfRotation_ field is set to (0, 0, 0), the special case of
_viewer-alignment_ is indicated. In this case, the object rotates to
keep the billboard's local Y-axis parallel with the Y-axis of the
viewer. This special case is distinguished by setting the
_axisOfRotation_ to (0, 0, 0). The following steps describe how to align
the billboard's Y-axis to the Y-axis of the viewer:

[loweralpha, start=4]
. Compute the billboard-to-viewer vector.
. Rotate the Z-axis of the billboard to be collinear with the
billboard-to-viewer vector and pointing towards the viewer's position.
. Rotate the Y-axis of the billboard to be parallel and oriented in the
same direction as the Y-axis of the viewer.

If the _axisOfRotation_ and the billboard-to-viewer line are coincident,
the plane cannot be established and the resulting rotation of the
billboard is undefined. For example, if the _axisOfRotation_ is set to
(0,1,0) (Y-axis) and the viewer flies over the billboard and peers
directly down the Y-axis, the results are undefined.

Multiple instances of Billboard nodes (DEF/USE) operate as expected:
each instance rotates in its unique coordinate system to face the
viewer.

<<Groupingandchildrennodes, 10.2.1 Grouping and children node types>>
provides a description of the _children_, _addChildren_, and
_removeChildren_ fields.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the Billboard node's children. This is a hint that may be used
for optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the children at
any time. A default _bboxSize_ value, (-1, -1, -1), implies that the
bounding box is not specified and if needed shall be calculated by the
X3D browser. A description of the _bboxCenter_ and _bboxSize_ fields is
contained in <<Boundingboxes, 10.2.2 Bounding boxes>>.

[[Collision]]
==== 23.4.2 Collision

[source,node]
----
Collision : X3DGroupingNode, X3DSensorNode {
  MFNode   [in]     addChildren             [X3DChildNode]
  MFNode   [in]     removeChildren          [X3DChildNode]
  MFNode   [in,out] children       []       [X3DChildNode]
  SFBool   [in,out] bboxDisplay    FALSE
  SFString [in,out] description    ""
  SFBool   [in,out] enabled        TRUE
  SFNode   [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool   [in,out] visible        TRUE
  SFTime   [out]    collideTime
  SFBool   [out]    isActive
  SFVec3f  []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f  []       bboxSize       -1 -1 -1 [0,∞) or −1 −1 −1
  SFNode   []       proxy          NULL     [X3DChildNode]
}
----

The Collision node is a grouping node that specifies the collision
detection properties for its children (and their descendants), specifies
surrogate objects that replace its children during collision detection,
and sends events signalling that a collision has occurred between the
avatar and the Collision node's geometry or surrogate. By default, all
geometric nodes in the scene are collidable with the viewer except
<<IndexedLineSet>> and <<PointSet>>. X3D
browsers shall detect geometric collisions between the avatar (see
<<NavigationInfo, 23.3.4 NavigationInfo>>) and the scene's geometry
and prevent the avatar from "entering" the geometry. See
<<Collisiondetection, 23.2.4 Collision detection and terrain following>>
for general information on collision detection.

If there are no Collision nodes specified in a X3D file, X3D browsers
shall detect collisions between the avatar and all objects during
navigation.

<<Groupingandchildrennodes, 10.2.1 Grouping and children node types>>
contains a description of the _children_, _addChildren_, and
_removeChildren_ fields.

The Collision node's _enabled_ field enables and disables collision
detection as well as terrain following when the navigation type requires
it. If _enabled_ is set to `FALSE`, the children and all
descendants of the Collision node shall not be checked for collision or
terrain, even though they are drawn. This includes any descendant
Collision nodes that have _enabled_ set to `TRUE` ( _i.e._,
setting _enabled_ to `FALSE` turns collision off for every child
node below it).

The value of the _isActive_ field indicates the current state of the
Collision node. An _isActive_ `TRUE` event is generated when a
collision occurs. An _isActive_ `FALSE` event is generated when a
collision no longer occurs.

Collision nodes with the _enabled_ field set to `TRUE` detect the
nearest collision with their descendant geometry (or proxies). When the
nearest collision is detected, the collided Collision node sends the
time of the collision through its _collidable_ field. If a Collision
node contains a child, descendant, or proxy (see below) that is a
Collision node, and both Collision nodes detect that a collision has
occurred, both send a _collideTime_ event at the same time. A
_collideTime_ event shall be generated if the avatar is colliding with
collidable geometry when the Collision node is read from a X3D file or
inserted into the transformation hierarchy.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the Collision node's children. This is a hint that may be used
for optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the children at
any time. A default _bboxSize_ value, (-1, -1, -1), implies that the
bounding box is not specified and if needed shall be calculated by the
X3D browser. More details on the _bboxCenter_ and _bboxSize_ fields can
be found in <<Boundingboxes, 10.2.2 Bounding boxes>>.

The collision proxy, defined in the _proxy_ field, is any legal child
node as described in <<Groupingandchildrennodes, 10.2.1 Grouping and children node types>> that is used as a substitute for the Collision
node's children during collision detection. The proxy is used strictly
for collision detection; it is not drawn.

If the value of the _enabled_ field is `TRUE` and the _proxy_
field is non-`NULL`, the _proxy_ field defines the scene on which
collision detection is performed. If the _proxy_ value is `NULL`,
collision detection is performed against the _children_ of the Collision
node.

If _proxy_ is specified, any descendant children of the Collision node
are ignored during collision detection. If _children_ is empty,
_enabled_ is `TRUE`, and _proxy_ is specified, collision
detection is performed against the proxy but nothing is displayed. In
this manner, invisible collision objects may be supported.

The _collideTime_ field generates an event specifying the time when the
avatar (see <<NavigationInfo, 23.3.4 NavigationInfo>>) makes contact
with the collidable children or proxy of the Collision node. An ideal
implementation computes the exact time of collision. Implementations may
approximate the ideal by sampling the positions of collidable objects
and the user. The <<NavigationInfo>> node contains
additional information for parameters that control the avatar size.

[[LOD]]
==== 23.4.3 LOD

[source,node]
----
LOD : X3DGroupingNode {
  MFNode  [in]     addChildren               [X3DChildNode]
  MFNode  [in]     removeChildren            [X3DChildNode]
  MFNode  [in,out] children         []       [X3DChildNode]
  SFBool  [in,out] bboxDisplay      FALSE
  SFNode  [in,out] metadata         NULL     [X3DMetadataObject]
  SFBool  [in,out] visible          TRUE
  SFInt32 [out]    level_changed
  SFVec3f []       bboxCenter       0 0 0    (-∞,∞)
  SFVec3f []       bboxSize         -1 -1 -1 [0,∞) or −1 −1 −1
  SFVec3f []       center           0 0 0    (-∞,∞)
  SFBool  []       forceTransitions FALSE
  MFFloat []       range            []       [0,∞) 
}
----

The LOD node specifies various levels of detail or complexity for a
given object, and provides hints allowing X3D browsers to automatically
choose the appropriate version of the object based on the distance from
the user. The _children_ field contains a list of nodes that represent
the same object or objects at varying levels of detail, ordered from
highest level of detail to the lowest level of detail.

The _range_ field specifies the ideal distances at which to switch
between the levels. If no values are provided, the X3D browser is
allowed to dynamically choose transition ranges based on performance.

The _forceTransitions_ field specifies whether X3D browsers are allowed
to disregard level distances in order to provide better performance. A
_forceTransitions_ value of `TRUE` specifies that every
transition should be performed regardless of any internal optimizations
that might be available. A _forceTransitions_ value of `FALSE`
specifies that X3D browsers are allowed to disregard level distances in
order to provide better performance.

<<Groupingandchildrennodes, 10.2.1 Grouping and children node types>>
contains details on the types of nodes that are legal values for
_children_.

The _center_ field is a translation offset in the local coordinate
system that specifies the centre of the LOD node for distance
calculations.

The number of nodes in the _children_ field shall exceed the number of
values in the _range_ field by one ( _i.e._, N+1 _children_ nodes for N
_range_ values). If provided, the _range_ field contains monotonically
increasing values that shall be greater than zero. In order to calculate
which level to display, first the distance is calculated from the
viewer's location, transformed into the local coordinate system of the
LOD node (including any scaling transformations), to the _center_ point
of the LOD node. Then, the LOD node evaluates the step function _L(d)_
to choose a level for a given value of _d_ (where _d_ is the distance
from the viewer position to the centre of the LOD node).

Let _n_ ranges, _R_ ~_0_~, _R_ ~_1_~, _R_ ~_2_~, ..., _R_ ~_n_-1~,
partition the domain (0, + _infinity_) into __n__+1 subintervals given
by (0,  _R_ ~_0_~), [ _R_ ~_0_~,  _R_ ~_1_~)... , [ _R_ ~_n_-1~, +
_infinity_). Also, let _n_ levels _L_ ~_0_~, _L_ ~_1_~, _L_ ~_2_~, ...,
_L_ ~_n_-1~ be the values of the step function _L(d)_. The level,
_L(d)_, for a given distance _d_ is defined as follows:

    L(d) = L~0~,   if d < R~0~, +
         = L~i+1~, if R~i~ ≤ d < R~i+1~, for −1 < i < n−1, +
         = L~n−1~, if d ≥ R~n−1~. +

The _L(d)^th^_ node of the _children_ field is that which is displayed.
The L(d)^th^ node of the children field (denoted by L~i~ in the equation
above) is that which is displayed. When L(d) is activated for display,
the LOD node generates a _level_changed_ event with value `i`
where the value of i identifies which value of L was activated for
display.

Specifying too few levels will result in the last level being used
repeatedly for the lowest levels of detail. If more levels than ranges
are specified, the extra levels are ignored. An empty range field is an
exception to this rule. This case is a hint to the X3D browser that it
may choose a level automatically to maintain a constant display rate.
Each value in the _range_ field shall be greater than the previous
value.

LOD nodes are evaluated top-down in the scene graph. Only the
descendants of the currently selected _children_ node are rendered. All
nodes under an LOD node continue to receive and send events regardless
of which LOD node's _level_ is active.

EXAMPLE  If an active <<TimeSensor>> node is contained
within an inactive level of an LOD node, the TimeSensor node sends
events regardless of the LOD node's state.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the LOD node's children. This is a hint that may be used for
optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the child with
the largest bounding box at any time. A default _bboxSize_ value, (−1,
−1, −1), implies that the bounding box is not specified and, if needed,
is calculated by the X3D browser. A description of the _bboxCenter_ and
_bboxSize_ fields is contained in <<Boundingboxes, 10.2.2 Bounding boxes>>.

NOTE:  Nested LOD nodes with overlapping range intervals can lead
to unexpected or undefined behaviour.

[[NavigationInfo]]
==== 23.4.4 NavigationInfo

[source,node]
----
NavigationInfo : X3DBindableNode {
  SFBool   [in]     set_bind
  MFFloat  [in,out] avatarSize      [0.25 1.6 0.75]   [0,∞)
  SFBool   [in,out] headlight       TRUE
  SFNode   [in,out] metadata        NULL              [X3DMetadataObject]
  SFFloat  [in,out] speed           1.0               [0,∞)
  SFTime   [in,out] transitionTime  1.0               [0, ∞)
  MFString [in,out] transitionType  ["LINEAR"]        ["TELEPORT","LINEAR", "ANIMATE",...]
  MFString [in,out] type            ["EXAMINE" "ANY"] ["ANY","WALK","EXAMINE","FLY",
                                                       "LOOKAT","NONE","EXPLORE",...]
  SFFloat  [in,out] visibilityLimit 0.0               [0,∞)
  SFTime   [out]    bindTime
  SFBool   [out]    isBound
  SFBool   [out]    transitionComplete
}
----

The NavigationInfo node contains information describing the physical
characteristics of the viewer's avatar and viewing model. NavigationInfo
node is a bindable node (see <<BindableChildrenNodes, 7.2.2 Bindable children nodes>>). Whenever the current _X3DViewpointNode_ node changes,
the current NavigationInfo node shall be re-parented to it by the X3D
browser. Whenever the current NavigationInfo node changes, the new
NavigationInfo node shall be re-parented to the current Viewpoint node
by the X3D browser.

If a `TRUE` value is sent to the _set_bind_ field of a
NavigationInfo node, the node is pushed onto the top of the
NavigationInfo node stack. When a NavigationInfo node is bound, the X3D
browser uses the fields of the NavigationInfo node to set the navigation
controls of its user interface and the NavigationInfo node is
conceptually re-parented under the currently bound _X3DViewpointNode_
node. All subsequent scaling changes to the current _X3DViewpointNode_
node's coordinate system automatically change aspects (see below) of the
NavigationInfo node values used in the X3D browser ( _e.g._, scale
changes to any ancestors' transformations). A `FALSE` value sent
to _set_bind_ pops the NavigationInfo node from the stack, results in an
_isBound_ `FALSE` event, and pops to the next entry in the stack
which shall be re-parented to the current _X3DViewpointNode_ node.
<<BindableChildrenNodes, 7.2.2 Bindable children nodes>> has more
details on binding stacks.

The _type_ field specifies an ordered list of navigation paradigms that
specify a combination of navigation types and the initial navigation
type. The navigation type of the currently bound NavigationInfo node
determines the user interface capabilities of the X3D browser. For
example, if the currently bound NavigationInfo node's _type_ is
"`WALK`", the X3D browser shall present a "`WALK`"
navigation user interface paradigm (see below for description of
`WALK`). X3D browsers shall recognize at least the following
navigation types: "`ANY`", "`WALK`", "`EXAMINE`",
"`FLY`", "`LOOKAT`", and "`NONE`" with support as
specified in <<t23_2, Table 23.2>>.

If "`ANY`" does not appear in the _type_ field list of the
currently bound NavigationInfo, the X3D browser's navigation user
interface shall be restricted to the recognized navigation types
specified in the list. In this case, X3D browsers shall not present a
user interface that allows the navigation type to be changed to a type
not specified in the list. However, if any one of the values in the
_type_ field are "`ANY`", the X3D browser may provide any type of
navigation interface, and allow the user to change the navigation type
dynamically. Furthermore, the first recognized type in the list shall be
the initial navigation type presented by the X3D browser's user
interface.

"`ANY`" navigation specifies that the X3D browser may choose the
navigation paradigm that best suits the content and provide a user
interface to allow the user to change the navigation paradigm
dynamically. The results are undefined if the currently bound
NavigationInfo's _type_ value is "`ANY`" and Viewpoint
transitions (see <<Viewpoint, 23.3.5 Viewpoint>>) are triggered by the
Anchor node (see <<Anchor, 9.4.1 Anchor>>) or the `loadURL()`
scripting method (see <<I19775_2, Part 2 of ISO/IEC 19775>>).

"`WALK`" navigation is used for exploring a virtual world on foot
or in a vehicle that rests on or hovers above the ground. It is strongly
recommended that `WALK` navigation define the up vector in the +Y
direction and provide some form of terrain following and gravity in
order to produce a walking or driving experience. If the bound
NavigationInfo's _type_ is "`WALK`", the X3D browser shall
strictly support collision detection (see <<Collision, 23.3.2 Collision>>).

"`FLY`" navigation is similar to `WALK` except that
terrain following and gravity may be disabled or ignored. There shall
still be some notion of "up" however. If the bound NavigationInfo's
_type_ is "`FLY`", the X3D browser shall strictly support
collision detection (see <<Collision, 23.3.2 Collision>>).

"`LOOKAT`" navigation is used to explore a scene by navigating to
a particular object. Selecting an object with "`LOOKAT`":

[loweralpha]
. Moves the viewpoint directly to some convenient viewing distance from
the bounding box center of the selected object, with the viewpoint
orientation set to aim the view at the approximate centre of the object;
. Sets the center of rotation in the currently bound Viewpoint node to
the approximate centre of the selected object.

"`EXAMINE`" navigation is used for viewing individual objects.
"`EXAMINE`" shall provide the ability to orbit or spin the user's
eyepoint about the center of rotation in response to user actions. The
center of rotation for moving the viewpoint around the object and
determining the viewpoint orientation is specified in the currently
bound _X3DViewpointNode_ node (see <<X3DViewpointNode, 23.3.1 _X3DViewpoinNode_>>). The X3D browser shall strictly support collision
detection (see <<Collision, 23.4.2 Collision>>) and shall trigger exit
and enter events throughout `EXAMINE` operations. +
 +
"`LOOKAT`" navigation in combination with "`EXAMINE`" is
used to explore a scene by navigating to a particular object, then being
able to conveniently navigate in order to examine the object from
different orientations. If content specifies both "`LOOKAT`" and
"`EXAMINE`" types, any "`LOOKAT`" operations shall change
the center of rotation for subsequent "`EXAMINE`" operations.

"`NONE`" navigation disables and removes all X3D browser-specific
navigation user interface forcing the user to navigate using only
mechanisms provided in the scene, such as Anchor nodes or scripts that
include `loadURL()`. "`NONE`" has an effect only when it
is the first supported navigation type. If "`NONE`" is not the
first supported navigation type, it has no effect.

`"EXPLORE"` navigation is used to provide consistent keystroke
navigation for both geospatial and Cartesian modes. When
`"EXPLORE"` mode is active:

[loweralpha]
. Dragging left and right while holding the left button down causes
viewpoint rotation about a vertical axis that passes through the point
of rotation. This vertical axis is always perpendicular to the viewpoint
vector. Motion in the left direction rotates the viewpoint clockwise (as
viewed from the top) about the vertical axis. Rotation is tied to the
motion of the pointing device; there is no damping or delay.
. Dragging the up and down while holding the left button down causes
rotation about a horizontal axis that passes through the point of
rotation. Motion in the up direction rotates the viewpoint clockwise (as
viewed from the right) about the horizontal axis. Rotation is tied to
the motion of the pointing device; there is no damping or delay.
. Holding the Ctrl key (or other key that may be user-selectable) down
modifies the left button down drag movement such that up and down
(Y-axis) movement causes the viewpoint to zoom toward and from the point
of rotation. Left and right motion while Ctrl is held down has no
effect. Shift and Ctrl (or other keys that may be user-selectable) held
at the same time also enables zoom but disables TouchSensors.
. Holding the Alt key (or other key that may be user-selectable)
modifies the movement such that motion of the pointing device while the
left button is held down is translated into a pan of the viewpoint in a
plane passing through the viewpoint perpendicular to the vector pointing
to the point of rotation. Shift and Alt (or other keys that may be
user-selectable) held at the same time also enables pan but disables
TouchSensors.
. The point of rotation can be set by holding the Shift key (or other
key that may be user-selectable) while pointing at an object and
clicking the left button. To provide feedback that the point has been
selected, the viewpoint shall zoom about twenty percent of the distance
toward that point.
. If the pointer is positioned over a TouchSensor, the pointer icon
shall change its appearance to indicate that a left click will activate
the TouchSensor.
. Holding the Shift key (or other key that may be user-selectable)
overrides any TouchSensor that the pointer may be over and forces the
pointing device to function as the viewpoint navigation tool; _i.e._,
drag operations cause rotation, click operations cause center of
rotation point selection.

Whether user-selectable alternatives to the Shift, Ctrl, and/or Alt are
provided is X3D browser-dependent. If provided, the method by which such
alternatives are specified is also X3D browser-dependent.

If the NavigationInfo type is "`WALK`", "`FLY`",
"`EXAMINE`", or "`NONE`" or a combination of these types (
_i.e._, "`ANY`" is not in the list), _X3DViewpointNode_
transitions (see <<X3DViewpointNode, 23.3.1 _X3DViewpointNode_>>)
triggered by the <<Anchor>> node (see <<Anchor, 9.4.1 Anchor>>) or the `#loadURL()`#scripting method (see
<<I19775_2, Part 2 of ISO/IEC 19775>>) shall be implemented as a jump
from the old _X3DViewpointNode_ to the new _X3DViewpointNode_ with
transition effects that shall not trigger events besides the exit and
enter events caused by the jump.

Browsers may create X3D browser-specific navigation type extensions. It
is recommended that extended _type_ names include a unique suffix (
_e.g._, HELICOPTER_mydomain.com) to prevent conflicts.
_X3DViewpointNode_ transitions (see <<Viewpoint, 23.3.5 Viewpoint>>)
triggered by the Anchor node (see <<Anchor, 9.4.1 Anchor>>) or the
`#loadURL()`#scripting method (see <<I19775_2, Part 2 of ISO/IEC 19775>>) are undefined for extended navigation types. If none of
the types are recognized by the X3D browser, the default "`ANY`"
is used. These strings values are case sensitive ("`any`" is not
equal to "`ANY`").

The _transitionType_ field specifies an ordered list of paradigms that
determine the manner in which the X3D browser moves the viewer when a
new Viewpoint node is bound. X3D browsers shall recognize and support at
least the following transition types: "`TELEPORT`",
"`LINEAR`", and "`ANIMATE`". For value
"`TELEPORT`", the transition shall be immediate without any
intervening positions. For value "`LINEAR`", the X3D browser
shall perform a linear interpolation of the position and orientation
values. For value "`ANIMATE`", the X3D browser shall perform a
X3D browser-specific animation effect. If all values are unrecognized or
the field is empty, the default value of "`LINEAR`" shall be
used. This field applies to any transitions between positions and
orientations including Viewpoint bindings and "`LOOKAT`"
navigation type.

The _transitionTime_ field specifies the duration of any viewpoint
transition. The transition starts when the next Viewpoint node is bound.
The duration of the transition depends on the value of the
_transitionType_ field. If _transitionType_ is "`TELEPORT`", the
transition is instantaneous and completes at the same time it starts. A
transition type of "`LINEAR`" indicates that the transition lasts
the number of seconds specified by the first value in the
_transitionTime_ field. If _transitionType_ is "`ANIMATE`",
_transitionTime_ provides X3D browser-dependent parameters to the X3D
browsers viewpoint animation engine. When a transition completes, a
_transitionComplete_ event is signaled.

The _speed_ field specifies the rate at which the viewer travels through
a scene in speed base units. Since X3D browsers may provide mechanisms
to travel faster or slower, this field specifies the default, average
speed of the viewer when the NavigationInfo node is bound. If the
NavigationInfo _type_ is "`EXAMINE`", _speed_ shall not affect
the viewer's rotational speed. Scaling in the transformation hierarchy
of the currently bound Viewpoint node (see above) scales the _speed_;
parent translation and rotation transformations have no effect on
_speed_. Speed shall be non-negative. Zero speed indicates that the
avatar's position is stationary, but its orientation and field of view
may still change. If the navigation _type_ is "`NONE`", the
_speed_ field has no effect.

The _avatarSize_ field specifies the user's physical dimensions in the
world for the purpose of collision detection and terrain following. It
is a multi-value field allowing several dimensions to be specified. The
first value shall be the allowable distance between the user's position
and any collision geometry (as specified by a <<Collision>>
node) before a collision is detected. The second shall be the height
above the terrain at which the X3D browser shall maintain the viewer.
The third shall be the height of the tallest object over which the
viewer can move. This allows staircases to be built with dimensions that
can be ascended by viewers in all X3D browsers. The transformation
hierarchy of the currently bound Viewpoint node scales the _avatarSize_.
Translations and rotations have no effect on _avatarSize_.

For purposes of terrain following, the X3D browser maintains a notion of
the _down_ direction (down vector), since gravity is applied in the
direction of the down vector. This down vector shall be along the
negative Y-axis in the local coordinate system of the currently bound
_X3DViewpointNode_ node ( _i.e._, the accumulation of the
_X3DViewpointNode_ node's ancestors' transformations, not including the
_X3DViewpointNode_ node's _orientation_ field).

Geometry beyond the _visibilityLimit_ may not be rendered. A value of
0.0 indicates an infinite _visibilityLimit_. The _visibilityLimit_ field
is restricted to be greater than or equal to zero.

The _speed_, _avatarSize_ and _visibilityLimit_ values are all scaled by
the transformation being applied to the currently bound
_X3DViewpointNode_ node. If there is no currently bound
_X3DViewpointNode_ node, the values are interpreted in the world
coordinate system. This allows these values to be automatically adjusted
when binding to a _X3DViewpointNode_ node that has a scaling
transformation applied to it without requiring a new NavigationInfo node
to be bound as well. The results are undefined if the scale applied to
the _X3DViewpointNode_ node is non-uniform.

The _headlight_ field specifies whether a X3D browser shall turn on a
headlight. A headlight is a directional light that always points in the
direction the user is looking. Setting this field to `TRUE`
allows the X3D browser to provide a headlight, possibly with user
interface controls to turn it on and off. Scenes that enlist precomputed
lighting (EXAMPLE  radiosity solutions) can turn the
headlight off. The headlight shall have __intensity __= 1, _color_
= (1 1 1), __ambientIntensity __= 0.0, and __direction __= (0 0 −1).

It is recommended that the near clipping plane be set to one-half of the
collision radius as specified in the _avatarSize_ field. Setting the
near plane to this value prevents excessive clipping of objects just
above the collision volume, and also provides a region inside the
collision volume for content authors to include geometry intended to
remain fixed relative to the viewer. Such geometry shall not be occluded
by geometry outside of the collision volume.

[[OrthoViewpoint]]
==== 23.4.5 OrthoViewpoint

[source,node]
----
OrthoViewpoint : X3DViewpointNode { 
  SFBool     [in]     set_bind
  SFVec3f    [in,out] centerOfRotation  0 0 0         (-∞,∞)
  SFString   [in,out] description       ""
  SFFloat    [in,out] farDistance       -1            -1 or (0,∞)
  MFFloat    [in,out] fieldOfView       -1, -1, 1, 1  (-∞,∞)
  SFBool     [in,out] jump              TRUE
  SFNode     [in,out] metadata          NULL          [X3DMetadataObject]
  SFNode     [in,out] navigationInfo    NULL          [NavigationInfo]
  SFFloat    [in,out] nearDistance      -1            -1 or (0,∞)
  SFRotation [in,out] orientation       0 0 1 0       [-1,1],(-∞,∞)
  SFVec3f    [in,out] position          0 0 10        (-∞,∞)
  SFBool     [in,out] retainUserOffsets FALSE
  SFBool     [in,out] viewAll           FALSE
  SFTime     [out]    bindTime
  SFBool     [out]    isBound
}
----

The OrthoViewpoint node defines a viewpoint that provides an
orthographic view of the scene. An orthographic view is one in which all
projectors are parallel to the projector from _centerOfRotation_ to
_position_.

The _fieldOfView_ field specifies minimum and maximum extents of the
view in units of the local coordinate system. A small field of view
roughly corresponds to a telephoto lens; a large field of view roughly
corresponds to a wide-angle lens.

The extents are grouped in the fieldOfView attribute in the order
(minimum_x, minimum_y, maximum_x, maximum_y). These values shall satisfy

____
minimum_x < maximum_x +
minimum_y < maximum_y
____

The value of _fieldOfView_ represents the minimum viewing extent in any
direction axis perpendicular to the view. Browsers shall render the
orthographic view in the available display frame as large as possible
while retaining uniform scaling in the horizontal and vertical axes. X3D
browsers shall center the view in the display frame.

A X3D browser with a rectangular viewing projection has the following
relationship:

____
[.code]#display width    (maximum_x - minimum_x) +
-------------- = ----------------------- +
display height   (maximum_y - minimum_y) +
#
____

When the _viewAll_ field is set to `TRUE` or a viewpoint is bound
with _viewAll_ field `TRUE`, the current view is modified to
change the _centerOfRotation_ field to match center of bounding box for
entire visible scene, and the _orientation_ field is modified to aim at
that point. Zoom in or out until outside the bounding box for all
models. Finally, the _fieldOfView_ field is modified to encompass the
visibility of all geometry in the bounding box for the entire scene. If
the current view is within a model, any intervening geometry does not
block the change in position. No collision detection or proximity
sensing occurs when zooming. If needed, near and far clipping planes
shall be adjusted to allow viewing the entire scene. When the value of
the _viewAll_ field is changed from `TRUE` to `FALSE`, no
change in the current view occurs.

[[Viewpoint]]
==== 23.4.6 Viewpoint

[source,node]
----
Viewpoint : X3DViewpointNode { 
  SFBool     [in]     set_bind
  SFVec3f    [in,out] centerOfRotation  0 0 0   (-∞,∞)
  SFString   [in,out] description       ""
  SFFloat    [in,out] farDistance       -1      -1 or (0,∞)
  SFFloat    [in,out] fieldOfView       π/4     (0,π)
  SFBool     [in,out] jump              TRUE
  SFNode     [in,out] metadata          NULL    [X3DMetadataObject]
  SFNode     [in,out] navigationInfo    NULL    [NavigationInfo]
  SFFloat    [in,out] nearDistance      -1      -1 or (0,∞)
  SFRotation [in,out] orientation       0 0 1 0 [-1,1],(-∞,∞)
  SFVec3f    [in,out] position          0 0 10  (-∞,∞)
  SFBool     [in,out] retainUserOffsets FALSE
  SFBool     [in,out] viewAll           FALSE
  SFTime     [out]    bindTime
  SFBool     [out]    isBound
}
----

The Viewpoint node defines a viewpoint that provides a perspective view
of the scene. A perspective view is one in which all projectors coalesce
at _position_.

The _fieldOfView_ field specifies a preferred minimum viewing angle from
this viewpoint in angle base units. A small field of view roughly
corresponds to a telephoto lens; a large field of view roughly
corresponds to a wide-angle lens. The field of view shall be greater
than zero and smaller than π. The value of _fieldOfView_
represents the minimum viewing angle in any direction axis perpendicular
to the view.

A X3D browser with a rectangular viewing projection has the following
relationship:

____
[.code]#display width    tan(FOV~horizontal~/2) +
-------------- = ------------------- +
display height   tan(FOV~vertical~/2)#
____

where the smaller of display width or display height determines which
angle equals the _fieldOfView_ (the larger angle is computed using the
relationship described above). The larger angle shall not exceed
π and may force the smaller angle to be less than
_fieldOfView_ in order to sustain the aspect ratio.

When the _viewAll_ field is set to `TRUE` or a viewpoint is bound
with _viewAll_ field `TRUE`, the current view is modified to
change the _centerOfRotation_ field to match center of bounding box for
entire visible scene, and the _orientation_ field is modified to aim at
that point. Finally, position is zoomed in or out until the bounding box
containing the entire scene is fully within the current viewing window.
If the current view is within a model, any intervening geometry does not
block the change in position. No collision detection or proximity
sensing occurs when zooming. If needed, _nearDistance_ and _farDistance_
shall be adjusted to allow viewing the entire scene. When the value of
the _viewAll_ field is changed from `TRUE` to `FALSE`, no
change in the current view occurs.

[[ViewpointGroup]]
==== 23.4.7 ViewpointGroup

[source,node]
----
ViewpointGroup : X3DChildNode { 
  SFVec3f  [in,out] center            0 0 0 (-∞,∞)
  MFNode   [in,out] children          NULL  [X3DViewpointNode|ViewpointGroup]
  SFString [in,out] description       ""
  SFBool   [in,out] displayed         TRUE
  SFNode   [in,out] metadata          NULL  [X3DMetadataObject]
  SFBool   [in,out] retainUserOffsets FALSE
  SFVec3f  [in,out] size              0 0 0 [0,∞)
}
----

The ViewpointGroup node is used to control display of viewpoints on the
viewpoint list. Use of ViewpointGroup allows a viewpoint list to have a
tree structure, similar to a bookmark list.

The _children_ field is a sequence of nodes of type
_<<X3DViewpointNode>>_.

The _description_ field provides a simple description or navigation hint
to be displayed for this ViewpointGroup.

The _displayed_ field determines whether this ViewpointGroup is
displayed in the current viewpoint list.

The _center_ and _size_ fields are defined identically as the
corresponding <<ProximitySensor>> definitions. The
_center_ field provides a position offset from origin of local
coordinate system. The _size_ field provides the size of a proximity box
within which the ViewpointGroup is usable and displayed on the viewpoint
list. A _size_ field of `0 0 0` specifies that the ViewpointGroup
is always usable and displayable.

The _retainUserOffsets_ field specifies whether the user is returned to
the originally defined viewpoint position/orientation after local
navigation (see <<ViewpointList, 23.2.5 Viewpoint list>>).

[[S23.5_SupportLevels]]
=== 23.5 Support levels

The Navigation component provides two levels of support as specified in
<<t23_2, Table 23.2>>.

[[t23_2]]
Table 23.2 — Navigation component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes |Support
|*1* |Core 1 |  | 

|  |  |_X3DViewpointNode_ |n/a

| | |NavigationInfo |avatarSize optionally supported. +
_speed_ optionally supported. +
_type_ support for at least `"ANY"`, `"FLY"`,
`"EXAMINE"`, and `"NONE"`. +
_visibilityLimit_ optionally supported.

| | |Viewpoint |All other fields fully supported.

|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Environmental sensor 2 | |

| | |All Level 1 Navigation nodes |All fields fully supported.

|  |  |NavigationInfo |_type_ support for at least `"ANY"`,
`"FLY"`, `"EXAMINE"`, `"WALK"`, `"LOOKAT"`,
and `"NONE"`. +
All other fields fully supported.

| |  |Billboard |All fields fully supported.

| | |Collision |All fields fully supported.

| | |LOD |All fields fully supported.

|* 3* |Core 1 +
Grouping 1 +
Shape 1 +
Environmental sensor 2 |  | 

| | |All Level 2 Navigation nodes |All fields fully supported.

|  |  |OrthoViewpoint |All fields fully supported.

|  |  |ViewpointGroup |All fields fully supported.
|===

[[environmentalEffects_html]]
== 24 Environmental effects component

[[S24_Introduction]]
=== 24.1 Introduction

[[S24_Name]]
==== 24.1.1 Name

The name of this component is "EnvironmentalEffects". This name shall be
used when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S24_Overview]]
==== 24.1.2 Overview

This clause describes the Environmental Effects component of this
document . Nodes in this component support the creation of realistic
environmental effects such as panoramic backgrounds and fog.
<<t24_1, Table 24.1>> provides links to the major topics in this
clause.

[[t24_1]]
Table 24.1 — Topics

* <<S24Introduction, 24.1 Introduction>>
** <<S24_Name, 24.1.1 Name>>
** <<S24_Overview, 24.1.2 Overview>>
* <<S24_Concepts, 24.2 Concepts>>
** <<Backgrounds, 24.2.1 Backgrounds>>
** <<FogSemantics, 24.2.2 Fog semantics>>
*** <<FogSemanticsOverview, 24.2.2.1 Overview>>
*** <<GlobalFogSemantics, 24.2.2.2 Global fog semantics>>
*** <<LocalFogSemantics, 24.2.2.3 Local fog semantics>>
*** <<LocalAndBindableFogInteraction, 24.2.2.4 Local and bindable fog interaction>>
*** <<FogColourCalculation, 24.2.2.5 Fog colour calculation>>
* <<S24_AbstractTypes, 24.3 Abstract types>>
** <<X3DBackgroundNode, 24.3.1 _X3DBackgroundNode_>>
** <<X3DFogObject, 24.3.2 _X3DFogObject_>>
* <<S24_NodeReference, 24.4 Node reference>>
** <<Background, 24.4.1 Background>>
** <<Fog, 24.4.2 Fog>>
** <<FogCoordinate, 24.4.3 FogCoordinate>>
** <<LocalFog, 24.4.4 LocalFog>>
** <<TextureBackground, 24.4.5 TextureBackground>>
* <<S24_SupportLevels, 24.5 Support levels>>

* <<f-BackgroundNode, Figure 24.1 — _X3DBackgroundNode_ field relationships>>

* <<t24_1, Table 24.1 — Topics>>
* <<t24_2, Table 24.2 — Environmental effects component support levels>>




[[S24_Concepts]]
=== 24.2 Concepts

[[Backgrounds]]
==== 24.2.1 Backgrounds

Background nodes are used to specify a colour backdrop that simulates
ground and sky, as well as a background texture, or _panorama_, that is
placed behind all geometry in the scene and in front of the ground and
sky. Background nodes are specified in the local coordinate system and
are affected by the accumulated rotation of their ancestors as described
below. X3D supports two kinds of background nodes: a simple background
node that contains a set of _url_ fields for specifying static image
files that compose the backdrop (see <<Background, 24.4.1 Background>>), and a complex background node containing arbitrary
X3DTexture nodes that compose the backdrop (see
<<TextureBackground, 24.4.3 TextureBackground>>). Both types of
background node descend from the abstract node type
_<<X3DBackgroundNode>>_. Applications should use
the <<Background>> node for simplicity, and the
<<TextureBackground>> node for more flexibility and
additional features.

Background nodes are bindable nodes as described in
<<BindableChildrenNodes, 7.2.2 Bindable children nodes>>. There exists
a Background stack, in which the top-most
_<<X3DBackgroundNode>>_ node on the stack is the
currently active _X3DBackgroundNode_. To move an _X3DBackgroundNode_
node to the top of the stack, a `TRUE` value is sent to the
_set_bind_ field. Once active, the _X3DBackgroundNode_ node is then
bound to the X3D browser's view. A `FALSE` value sent to
_set_bind_ removes the _X3DBackgroundNode_ from the stack and unbinds it
from the X3D browser's current view.

The backdrop is conceptually a partial sphere (the ground) enclosed
inside of a full sphere (the sky) in the local coordinate system with
the viewer placed at the centre of the spheres. Both spheres have
infinite radius and each is painted with concentric circles of
interpolated colour perpendicular to the local Y-axis of the sphere. The
_X3DBackgroundNode_ node is subject to the accumulated rotations of its
ancestors' transformations. Scaling and translation transformations are
ignored. The sky sphere is always slightly farther away from the viewer
than the ground partial sphere causing the ground to appear in front of
the sky where they overlap.

The _skyColor_ field specifies the colour of the sky at various angles
on the sky sphere. Angles for skyColor are specified in angle base
units. The following assumes that the angle base units are radians. The
equivalent values apply if an angle base unit other than radians is
specified.The first value of the _skyColor_ field specifies the colour
of the sky at 0.0 radians representing the zenith ( _i.e._, straight up
from the viewer). The _skyAngle_ field specifies the angles from the
zenith in which concentric circles of colour appear. The zenith of the
sphere is implicitly defined to be 0.0 radians, the natural horizon is
at π/2 radians, and the nadir ( _i.e._, straight down from the
viewer) is at π radians. _skyAngle_ is restricted to
non-decreasing values in the range [0.0, π]. There shall be
one more _skyColor_ value than there are _skyAngle_ values. The first
colour value is the colour at the zenith, which is not specified in the
_skyAngle_ field. If the last _skyAngle_ is less than π, then
the colour band between the last _skyAngle_ and the nadir is clamped to
the last _skyColor_. The sky colour is linearly interpolated between the
specified _skyColor_ values.

The _groundColor_ field specifies the colour of the ground at the
various angles on the ground partial sphere. Angles for _groundColor_
are specified in angle base units. The following assumes that the angle
base units are radians. The equivalent values apply if an angle base
unit other than radians is specified. The first value of the
_groundColor_ field specifies the colour of the ground at 0.0 radians
representing the nadir ( _i.e._, straight down from the user). The
_groundAngle_ field specifies the angles from the nadir that the
concentric circles of colour appear. The nadir of the sphere is
implicitly defined at 0.0 radians. _groundAngle_ is restricted to
non-decreasing values in the range [0.0, π/2]. There shall be
one more _groundColor_ value than there are _groundAngle_ values. The
first colour value is for the nadir which is not specified in the
_groundAngle_ field. If the last _groundAngle_ is less than
π/2, the region between the last _groundAngle_ and the equator
is non-existant. The ground colour is linearly interpolated between the
specified _groundColor_ values.

The _back_, _bottom_, _front_, _left_, _right_, and _top_ fields specify
a set of images that define a background panorama between the ground/sky
backdrop and the scene's geometry. The panorama consists of six images,
each of which is mapped onto a face of an infinitely large cube
contained within the backdrop spheres and centred in the local
coordinate system. The images are applied individually to each face of
the cube. On the front, back, right, and left faces of the cube, when
viewed from the origin looking down the negative Z-axis with the Y-axis
as the view up direction, each image is mapped onto the corresponding
face with the same orientation as if the image were displayed normally
in 2D ( _back_ to back face, _front_ to front face, _left_ to left face,
and _right_ to right face _)_. On the top face of the cube, when viewed
from the origin looking along the +Y-axis with the +Z-axis as the view
up direction, the _top_ image is mapped onto the face with the same
orientation as if the image were displayed normally in 2D. On the bottom
face of the box, when viewed from the origin along the negative Y-axis
with the negative Z-axis as the view up direction, the _bottom_ image is
mapped onto the face with the same orientation as if the image were
displayed normally in 2D.

<<f-BackgroundNode, Figure 24.1>> illustrates the _X3DBackgroundNode_
node backdrop and background textures.

Alpha values in the panorama images ( _i.e._, two or four component
images) specify that the panorama is semi-transparent or transparent in
regions, allowing earlier rendered layers or the _groundColor_ and
_skyColor_ to be visible.

See <<texturing_html, 18 Texturing component>> for a general
description of texture maps.

Often, the _bottom_ and _top_ images will not be specified, to allow sky
and ground to show. The other four images may depict surrounding
mountains or other distant scenery.

[[f-BackgroundNode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/background.gif[Background
node,width=615,height=312]

*Figure 24.1 —* _X3DBackgroundNode_ field relationships

Panorama images may be one component (greyscale), two component
(greyscale plus alpha), three component (full RGB colour), or
four-component (full RGB colour plus alpha).

Ground colours, sky colours, and panoramic images do not translate with
respect to the viewer, though they do rotate with respect to the viewer.
That is, the viewer can never get any closer to the background, but can
turn to examine all sides of the panorama cube, and can look up and down
to see the concentric rings of ground and sky (if visible).

_X3DBackgroundNode_ nodes are not affected by
_<<X3DFogObject>>_ nodes. Therefore, if a
_X3DBackgroundNode_ node is active ( _i.e._, bound) while an
_X3DFogObject_ node is active, the _X3DBackgroundNode_ node will be
displayed with no fogging effects. It is the author's responsibility to
set the _X3DBackgroundNode_ values to match the _X3DFogObject_ node
values (`EXAMPLE`  ground colours fade to fog colour with
distance and panorama images tinted with fog colour).
_X3DBackgroundNode_ nodes are not affected by light sources.

[[FogSemantics]]
==== 24.2.2 Fog semantics

[[FogSemanticsOverview]]
===== 24.2.2.1 Overview

This document supports two types of fog:  global and local.

[[GlobalFogSemantics]]
===== 24.2.2.2 Global fog semantics

Global fog applies to the entire world and is specified using a
<<Fog>> node. Global fog blends the colours of all objects with
the fog colour based on distance from the object to the camera. The
further the distance the greater the amount of fog colour.

[[LocalFogSemantics]]
===== 24.2.2.3 Local fog semantics

Local fog applies only within the same transformation hierarchy that
contains the <<LocalFog>> node. This limits the effect of
the fog to subsets of the world and supports the creation of realistic
effects such as a smoke-filled room inside a larger building that is not
smoke-filled. If a local fog and a global fog are both defined and
active, the lighting contribution from the local fog shall be used
instead of the global effect.

Local fog effects shall not affect nodes derived from
_<<X3DBackgroundNode>>_.

[[LocalAndBindableFogInteraction]]
===== 24.2.2.4 Local and bindable fog interaction

If a global <<Fog>> node is bound and a <<LocalFog>>
node is enabled, the LocalFog node shall have precedence over the
globally bound Fog node in determining the fog colour contribution to
the lighting equations defined in <<lighting_html, 17 Lighting component>>.

[[FogColourCalculation]]
===== 24.2.2.5 Fog colour calculation

During the traversal of the scene graph, if more than one
<<LocalFog>> node is encountered in the path from the root
to a given renderable leaf node, only the contribution of the LocalFog
instance closest to the leaf node shall be used. All other fog values
shall be ignored.


=== 24.3 Abstract types

[[X3DBackgroundNode]]
==== 24.3.1 _X3DBackgroundNode_

[source,node]
----
X3DBackgroundNode : X3DBindableNode { 
  SFBool  [in]     set_bind
  MFFloat [in,out] groundAngle   []      [0,π/2]
  MFColor [in,out] groundColor   []      [0,1]
  SFNode  [in,out] metadata      NULL    [X3DMetadataObject]
  MFFloat [in,out] skyAngle      []      [0,π]
  MFColor [in,out] skyColor      0 0 0   [0,1]
  SFFloat [in,out] transparency  0       [0,1]
  SFTime  [out]    bindTime
  SFBool  [out]    isBound
}
----

_X3DBackgroundNode_ is the abstract type from which all backgrounds
inherit. _X3DBackgroundNode_ is a bindable node that, when bound,
defines the panoramic background for the scene. For complete information
on backgrounds, see <<Backgrounds, 24.2.1 Backgrounds>>.

[[X3DFogObject]]
==== 24.3.2 _X3DFogObject_

[source,node]
----
X3DFogObject {
  SFColor  [in,out] color           1 1 1    [0,1]
  SFString [in,out] fogType         "LINEAR" ["LINEAR"|"EXPONENTIAL"]
  SFFloat  [in,out] visibilityRange 0        [0,∞)
}
----

_X3DFogObject_ is the abstract interface that describes a node that
influences the lighting equation through the use of fog semantics. It
defines the basic colour and rendering effects that influence the
lighting equations as described in <<lighting_html, 17 Lighting component>>.


=== 24.4 Node reference

[[Background]]
==== 24.4.1 Background

[source,node]
----
Background : X3DBackgroundNode {
  SFBool   [in]     set_bind
  MFString [in,out] backUrl      []    [URI]
  MFString [in,out] bottomUrl    []    [URI]
  MFString [in,out] frontUrl     []    [URI]
  MFFloat  [in,out] groundAngle  []    [0,π/2]
  MFColor  [in,out] groundColor  []    [0,1]
  MFString [in,out] leftUrl      []    [URI]
  SFNode   [in,out] metadata     NULL  [X3DMetadataObject]
  MFString [in,out] rightUrl     []    [URI]
  MFFloat  [in,out] skyAngle     []    [0,π]
  MFColor  [in,out] skyColor     0 0 0 [0,1]
  MFString [in,out] topUrl       []    [URI]
  SFFloat  [in,out] transparency 0     [0,1]
  SFTime   [out]    bindTime
  SFBool   [out]    isBound
}
----

A background node that uses six static images to compose the backdrop.
The common fields of the Background node are described in
<<S24_Concepts, 24.2 Concepts>>. For the _backUrl_, _bottomUrl_,
_frontUrl_, _leftUrl_, _rightUrl_, _topUrl_ fields, X3D browsers shall
support the JPEG (see <<JPEG>>) and PNG (see
<<I15948, ISO/IEC 15948>>) image file formats, and in addition, may
support any other image format (EXAMPLE  CGM) that can be
rendered into a 2D image. Support for the GIF (see <<GIF>>)
format is recommended (including transparency). More detail on the _url_
fields can be found in <<URLs, 9.2.1 URLs, URNs and URIs>>.

[[Fog]]
==== 24.4.2 Fog

[source,node]
----
Fog : X3DBindableNode, X3DFogObject {
  SFBool   [in]     set_bind
  SFColor  [in,out] color           1 1 1    [0,1]
  SFString [in,out] fogType         "LINEAR" ["LINEAR"|"EXPONENTIAL"]
  SFNode   [in,out] metadata        NULL     [X3DMetadataObject]
  SFFloat  [in,out] visibilityRange 0        [0,∞)
  SFTime   [out]    bindTime
  SFBool   [out]    isBound
}
----

The Fog node provides a way to simulate atmospheric effects by blending
objects with the colour specified by the _color_ field based on the
distances of the various objects from the viewer. The distances are
calculated in the coordinate space of the Fog node. The
_visibilityRange_ specifies the distance in length base units (in the
local coordinate system) at which objects are totally obscured by the
fog. Objects located outside the _visibilityRange_ from the viewer are
drawn with a constant colour of _color_. Objects very close to the
viewer are blended very little with the fog _color_. A _visibilityRange_
of 0.0 disables the Fog node. The _visibilityRange_ is affected by the
scaling transformations of the Fog node's parents; translations and
rotations have no affect on _visibilityRange_. Values of the
_visibilityRange_ field shall be in the range [0,∞).

Since Fog nodes are bindable children nodes (see
<<BindableChildrenNodes, 7.2.2 Bindable children nodes>>), a Fog node
stack exists, in which the top-most Fog node on the stack is currently
active. To push a Fog node onto the top of the stack, a `TRUE`
value is sent to the _set_bind_ field. Once active, the Fog node is
bound to the X3D browser view. A `FALSE` value sent to
_set_bind_, pops the Fog node from the stack and unbinds it from the X3D
browser viewer. More details on the Fog node stack can be found in
<<BindableChildrenNodes, 7.2.2 Bindable children nodes>>.

The _fogType_ field controls how much of the fog colour is blended with
the object as a function of distance. If _fogType_ is "`LINEAR`",
the amount of blending is a linear function of the distance, resulting
in a depth cueing effect. If _fogType_ is "`EXPONENTIAL`," an
exponential increase in blending is used, resulting in a more natural
fog appearance.

The effect of fog on lighting calculations is described in
<<lighting_html, 17 Lighting component>>.

[[FogCoordinate]]
==== 24.4.3 FogCoordinate

[source,node]
----
FogCoordinate : X3DGeometricPropertyNode {
  MFFloat [in,out] depth    []   [0,1]
  SFNode  [in,out] metadata NULL [X3DMetadataObject]
}
----

This node defines a set of explicit fog depths on a per-vertex basis.
This depth value shall be applied per-vertex and used to replace the
automatically generated depth. Fog coordinates take precedence over
implicitly generated depths; specifying fog coordinates will result in
the implicit depth (specified by the _visibilityRange_ field of a node
derived from _<<X3DFogObject>>_) being ignored. Details
on lighting equations can be found in <<LightingModel, 17.2.2 Lighting model>>.

One depth value per vertex shall be supplied. If the user does not
provide a  sufficient number of depth values, the last value defined
shall be replicated for any further vertices. If too many depth values
are supplied, the excess depth values shall be ignored.

[[LocalFog]]
==== 24.4.4 LocalFog

[source,node]
----
LocalFog : X3DChildNode, X3DFogObject {
  SFColor  [in,out] color           1 1 1    [0,1]
  SFBool   [in,out] enabled         TRUE
  SFString [in,out] fogType         "LINEAR" ["LINEAR"|"EXPONENTIAL"]
  SFNode   [in,out] metadata        NULL     [X3DMetadataObject]
  SFFloat  [in,out] visibilityRange 0        [0,∞)
}
----

The LocalFog node provides a way to simulate atmospheric effects by
blending objects with the colour specified by the color field based on
the distances of the various objects from the viewer. The distances are
calculated in the coordinate space of the LocalFog node. The
_visibilityRange_ field specifies the distance in metres (in the local
coordinate system) at which objects are totally obscured by the fog.
Objects located outside the _visibilityRange_ from the viewer are drawn
with a constant colour of _color_. Objects very close to the viewer are
blended very little with the fog color. A _visibilityRange_ of 0.0
disables the LocalFog node. The _visibilityRange_ is affected by the
scaling transformations of the parents of the LocalFog node;
translations and rotations have no affect on _visibilityRange_.

The _fogType_ field controls how much of the fog colour is blended with
the object as a function of distance. If _fogType_ is `"LINEAR"`,
the amount of blending is a linear function of the distance, resulting
in a depth-cueing effect. If _fogType_ is `"EXPONENTIAL"`, an
exponential increase in blending is used, resulting in a more natural
fog appearance.

The effect of fog on lighting calculations is described in
<<lighting_html, 17 Lighting component>>.

[[TextureBackground]]
==== 24.4.5 TextureBackground

[source,node]
----
TextureBackground : X3DBackgroundNode {
  SFBool  [in]     set_bind
  SFNode  [in,out] backTexture   NULL  [X3DTexture2DNode|MultiTexture]
  SFNode  [in,out] bottomTexture NULL  [X3DTexture2DNode|MultiTexture]
  SFNode  [in,out] frontTexture  NULL  [X3DTexture2DNode|MultiTexture]
  MFFloat [in,out] groundAngle   []    [0,π/2]
  MFColor [in,out] groundColor   []    [0,1]
  SFNode  [in,out] leftTexture   NULL  [X3DTexture2DNode|MultiTexture]
  SFNode  [in,out] metadata      NULL  [X3DMetadataObject]
  SFNode  [in,out] rightTexture  NULL  [X3DTexture2DNode|MultiTexture]
  MFFloat [in,out] skyAngle      []    [0,π]
  MFColor [in,out] skyColor      0 0 0 [0,1]
  SFNode  [in,out] topTexture    NULL  [X3DTexture2DNode|MultiTexture]
  SFFloat [in,out] transparency  0     [0,1]
  SFTime  [out]    bindTime
  SFBool  [out]    isBound
}
----

The TextureBackground node uses six individual texture nodes to compose
the backdrop. Unlike the <<Background>> node, which only
supports static image formats referenced by URL fields, the contents of
the TextureBackground node can be arbitrary texture types, including
<<ImageTexture>>, <<PixelTexture>>,
<<MovieTexture>> and <<MultiTexture>>.
The common fields of the TextureBackground node are described in
<<S24_Concepts, 24.2 Concepts>>.

TextureBackground supports the creation of rich backgrounds with
animation. It also allows the world author to attach load sensors (see
<<S9_LoadSensor, 9.4.3 LoadSensor>>) to the node's texture fields to
receive notification of when elements of the background are loaded.

TextureBackground supports a _transparency_ value that allows the scene
to overlay other elements in an application. A _transparency_ value of
zero specifies that the background is fully opaque obscuring all content
in the underlying window. A _transparency_ value of one specifies that
the background specified by the TextureBackground node is fully
transparent causing the TextureBackground to not be visible so that all
underlying content appears as the background. The value of the
_transparency_ field is applied to the _skyColor_ and _groundColor_ by
first converting the _transparency_ value to an alpha value using the
formula:

____
`alpha = (1 - transparency)`
____

The alpha value is then multiplied against the components of the
_skyColor_ and _groundColor_ (including the alpha component, if
provided) to obtain the color that is applied to the underlying window
content. The _transparency_ value is not applied to the six texture
fields. Transparency of these fields can be achieved by using alpha
values within their images.

For the _backTexture_, _bottomTexture_, _frontTexture_, _leftTexture_,
_rightTexture_, _topTexture_ fields, X3D browsers shall support any
X3DTexture node types supported in the currently supported profile.

[[S24.5_SupportLevels]]
=== 24.5 Support levels

The Environmental Effects component provides three levels of support as
specified in <<t24_2, Table 24.2>>. Level 1 is intended to
support simple backgrounds for lightweight profiles. Level 2 provides
additional environmental effects, including full background features,
fog, and limited texture backgrounds. Level 3 provides full support for
texture backgrounds.

[[t24_2]]
*Table 24.2 —* Environmental effects component
support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Time 1 +
Grouping 1 | |

| | |_X3DBackgroundNode_ (abstract) |n/a

| | |_X3DFogObject_ (abstract) |n/a

| | |Background |_groundAngle_ and _groundColor_ optionally supported.
_backURL_, _frontURL_, _leftURL_, _rightURL_, _topURL_ optionally
supported. _skyAngle_ optionally supported. One _skyColor_.

|*2* |Core 1 +
Time 1 +
Grouping 1 | |

| | |All Level 1 Environmental Effects nodes |All fields fully
supported.

| | |Fog |All fields fully supported.

|*3* |Core 1 +
Time 1 +
Grouping 1 |  | 

| | |All Level 2 Environmental Effects nodes |All fields fully
supported.

| | |TextureBackground |All fields fully supported.

|*4* |Core 1 +
Time 1 +
Grouping 1 |  | 

| | |All Level 3 Environmental Effects nodes |All fields fully
supported.

| | |FogCoordinate |All fields fully supported.

|  |  |LocalFog |All fields fully supported.
|===

[[geospatial_html]]
== 25 Geospatial Component

[[S25_Introduction]]
=== 25.1 Introduction

[[S25_Name]]
==== 25.1.1 Name

The name of this component is "Geospatial". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S25_Overview]]
==== 25.1.2 Overview

This clause describes the Geospatial component of this document. This
includes how to associate real world locations to elements in the X3D
world as well as specifying nodes particularly tuned for geospatial
applications. <<t25_1, Table 25.1>> provides links to the major
topics in this clause.

[[t25_1]]
Table 25.1 — Topics

* <<S25Introduction, 25.1 Introduction>>
** <<S25_Name, 25.1.1 Name>>
** <<S25_Overview, 25.1.2 Overview>>
* {blank}
+
<<S25_Concepts, 25.2 Concepts>>
** <<S25_ConceptsOverview, 25.2.1 Overview>>
** <<Spatialreferenceframes, 25.2.2 Spatial reference frames>>
** <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>
** <<Specifyinggeospatialcoords, 25.2.4 Specifying geospatial coordinates>>
** <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>
** <<navigationissues, 25.2.6 Geospatial navigation issues>>
* {blank}
+
<<S25_NodeReference, 25.3 Node reference>>
** <<GeoCoordinate, 25.3.1 GeoCoordinate>>
** <<GeoElevationGrid, 25.3.2 GeoElevationGrid>>
** <<GeoLocation, 25.3.3 GeoLocation>>
** <<GeoLOD, 25.3.4 GeoLOD>>
** <<GeoMetadata, 25.3.5 GeoMetadata>>
** <<GeoOrigin, 25.3.6 GeoOrigin>> 
** <<GeoPositionInterpolator, 25.3.7 GeoPositionInterpolator>>
** <<GeoProximitySensor, 25.3.8 GeoProximitySensor>>
** <<GeoTouchSensor, 25.3.9 GeoTouchSensor>>
** <<GeoTransform, 25.3.10 GeoTransform>>
** <<GeoViewpoint, 25.3.11 GeoViewpoint>>
* <<S25_SupportLevels, 25.4 Support levels>>

* <<f-LoadingGeoLODlevels, Figure 25.1 — Loading of GeoLOD levels>>

* <<t25_1, Table 25.1 — Topics>>
* <<t25_2, Table 25.2 — Supported spatial reference frames>>
* <<t25_3, Table 25.3 — Supported earth ellipsoids>>
* <<t25_4, Table 25.4 — Supported earth geoids>>
* <<t25_5, Table 25.5 — GeoMetadata keywords and values>>
* <<t25_6, Table 25.6 — Geospatial component support levels>>




[[S25_Concepts]]
=== 25.2 Concepts

[[S25_ConceptsOverview]]
==== 25.2.1 Overview

This section contains discussions of various important concepts that are
integral to the Geospatial component, providing support for geographic
and geospatial applications. This support includes the ability to embed
geospatial coordinates in certain X3D nodes, to support high-precision
geospatial modeling, and to handle large multi-resolution terrain
databases. These concepts are described below. The Geospatial component
includes conventions that are defined by the Spatial Reference Model
(see <<I18026, ISO/IEC 18026>>).

In total, the following nodes comprise the Geospatial component. These
nodes are defined as follows.

* <<GeoCoordinate>>
* <<GeoElevationGrid>>
* <<GeoLocation>>
* <<GeoLOD>>
* <<GeoMetadata>>
* <<GeoOrigin>>
* <<GeoPositionInterpolator>>
* <<GeoProximitySensor>>
* <<GeoTouchSensor>>
* <<GeoTransform>>
* <<GeoViewpoint>>

[[Spatialreferenceframes]]
==== 25.2.2 Spatial reference frames

X3D defines an implicit Cartesian, right-handed three-dimensional
coordinate system for modeling purposes, as defined in
<<Standardunitscoordinates, 4.3.6 Standard units and coordinate system>>. However, most geo-referenced data are provided in a geodetic or
projective spatial reference frame. A geodetic (or geographic) spatial
reference frame is related to the ellipsoid used to model the earth, for
example the latitude/longitude system. A projective spatial reference
frame employs a projection of the ellipsoid onto some simple surface
such as a cone or a cylinder, for example, the Lambert Conformal Conic
(LCC) or the Universal Transverse Mercator (UTM) projections. In order
to be useful to the geospatial community, X3D provides support for a
number of nodes that can use spatial reference frames for modeling
purposes. The spatial reference frames supported by X3D are defined in
<<t25_2, Table 25.2>>.

[[t25_2]]
Table 25.2 — Supported spatial reference
frames

[cols=",",]
|===
|Code |Name
|*GD* |Geodetic spatial reference frame
|*GC* |Geocentric spatial reference frame
|*UTM* |Universal Transverse Mercator
|*WM* |Web Mercator
|===

The code GDC shall be synonymous to GD, and the code GCC shall be
synonymous to GC. However, these two synonyms may be subject to future
deprecation. In addition to these spatial reference frames, X3D defines
23 standard ellipsoids in order to model the shape of the earth. These
are all defined in <<t25_3, Table 25.3>>.

[[t25_3]]
Table 25.3 — Supported earth ellipsoids

[width="100%",cols="25%,25%,25%,25%",]
|===
|Code |Ellipsoid Name |*Semi-Major Axis* +
*(metres)* |*InverseFlattening* +
*(F^-1^)*
|*AA* |Airy 1830 |6377563.396 |299.3249646
|*AM* |Modified Airy |6377340.189 |299.3249646
|*AN* |Australian National |6378160 |298.25
|*BN* |Bessel 1841 (Namibia) |6377483.865 |299.1528128
|*BR* |Bessel 1841 (Ethiopia Indonesia...) |6377397.155 |299.1528128
|*CC* |Clarke 1866 |6378206.4 |294.9786982
|*CD* |Clarke 1880 |6378249.145 |293.465
|*EA* |Everest (India 1830) |6377276.345 |300.8017
|*EB* |Everest (Sabah & Sarawak) |6377298.556 |300.8017
|*EC* |Everest (India 1956) |6377301.243 |300.8017
|*ED* |Everest (W. Malaysia 1969) |6377295.664 |300.8017
|*EE* |Everest (W. Malaysia & Singapore 1948) |6377304.063 |300.8017
|*EF* |Everest (Pakistan) |6377309.613 |300.8017
|*FA* |Modified Fischer 1960 |6378155 |298.3
|*HE* |Helmert 1906 |6378200 |298.3
|*HO* |Hough 1960 |6378270 |297
|*ID* |Indonesian 1974 |6378160 |298.247
|*IN* |International 1924 |6378388 |297
|*KA* |Krassovsky 1940 |6378245 |298.3
|*RF* |Geodetic Reference System 1980 (GRS 80) |6378137 |298.257222101
|*SA* |South American 1969 |6378160 |298.25
|*WD* |WGS 72 |6378135 |298.26
|*WE* |WGS 84 |6378137 |298.257223563
|===

Finally, X3D supports the specification of a geoid representing mean sea
level. The list of geoids supported is presented in
<<t25_4, Table 25.4>>.

[[t25_4]]
Table 25.4 — Supported earth geoids

[cols=",",]
|===
|Code |Name
|*WGS84* |WGS84 geoid
|===

Internally, an X3D browser will transform all geographic coordinates
into earth-fixed geocentric coordinates ( _i.e._, an (x,y,z)
displacement from the center of the earth in units of length base
units). This is a 3D Cartesian coordinate system that best integrates
with X3D's implicit coordinate system. In addition, an offset may be
applied to these geocentric coordinates if a <<GeoOrigin>>
node is supplied (see <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>). The resulting coordinates are cast to
single-precision and are the final values used for rendering. This
process means that we provide support for increased precision around an
area of interest, and also enable data specified in multiple spatial
reference frames to be fused into a single context.

[[SpecifyingSpatialReferenceFrame]]
==== 25.2.3 Specifying a spatial reference frame

All the X3D nodes that allow inclusion of geographic coordinates support
a field called _geoSystem_. This field is used to specify the particular
spatial reference frame that will be used for the geospatial coordinates
in that node. This is an MFString field that can include a number of
arguments to fully designate the spatial reference frame. Each argument
appears in a separate string within the MFString array. Argument
matching is case sensitive. Optional arguments may appear in any order.
The following values are supported.

* " *GD*" - Geodetic spatial reference frame (latitude/longitude). An
optional argument may be used to specify the ellipsoid using one of the
ellipsoid codes that are defined in <<t25_3, Table 25.3>>.
If no ellipsoid is specified, then `"WE"` is assumed ( _i.e._,
the WGS84 ellipsoid). An optional `"WGS84"` string can be
specified if you wish all elevations to relative to the WGS84 geoid (
_i.e._, mean sea level) (see <<t25_4, Table 25.4>>);
otherwise, all elevations will be relative to the ellipsoid. An example
spatial reference frame definition of this format is `[ "GD", "WD" ]`
for a geodetic spatial reference frame based upon the WGS72
ellipsoid with all elevations being relative to that ellipsoid.

* " *UTM*" - Universal Transverse Mercator. One further required
argument shall be supplied for UTM in order to specify the zone number
(1..60). This is given in the form "Z<n>", where <n> is the zone number.
An optional argument of `"S"` may be supplied in order to specify
that the coordinates are in the southern hemisphere (otherwise, northern
hemisphere will be assumed). A further optional argument may be used to
specify the ellipsoid using one of the ellipsoid codes that are defined
in <<t25_3, Table 25.3>>. If no ellipsoid is specified,
then `"WE"` is assumed ( _i.e._, the WGS84 ellipsoid). An
optional `"WGS84"` string can be specified if you wish all
elevations to relative to the WGS84 geoid ( _i.e._, mean sea level (see
<<t25_4, Table 25.4>>)); otherwise, all elevations will be
relative to the ellipsoid. An example spatial reference frame definition
of this format is `[ "UTM", "Z10", "S", "easting_first" ]` for a
southern hemisphere UTM spatial reference frame in zone 10 with all
elevations being with respect to mean sea level.

* " *GC*" - Earth-fixed Geocentric with respect to the WGS84 ellipsoid.
No additional arguments are supported. An example spatial reference
frame definition of this format is `[ "GC" ]`.

* " *WM*" - Web Mercator projection used for all web mapping (slippy
maps). An example spatial reference frame definition of this format is
`[ "WM" ]`.

If no geoSystem field is specified, the default value is [ GD", "WE" ].

[[Specifyinggeospatialcoords]]
==== 25.2.4 Specifying geospatial coordinates

Once the spatial reference frame has been defined, a single geographic
coordinate is specified as an SFVec3d. Lists of geographic coordinates
are encoded as an MFVec3d. The meaning of each component value depends
upon the particular spatial reference frame that was defined via the
_geoSystem_ field in the same node. Given the following _geoSystem_
definitions, the meaning of each component is defined as follows.

* *GD*: (<latitude>, <longitude>, <elevation>) or (<longitude>,
<latitude>, <elevation>). The order of latitude and longitude is
controlled by the _geoSystem_ field. If `"latitude_first"` is
specified, the order is latitude then longitude. If
`"longitude_first"` is specified, the order is longitude then
latitude. If neither is specified, `"latitude_first"` is the
default. Elevation is always specified third. Latitude and longitude are
given in units of angle base units. The following assumes an angle base
unit of degrees. If a UNIT statement for angle base units has been
provided, the following values for latitude and/or longitude should be
suitable converted to that angle base units. Latitude is in the range
−90..+90, and longitude can be in the range −180..+180 or 0..360 (0 deg
longitude is the same point in both cases). Longitudinal values are
relative to the Greenwich Prime Meridian. Elevation is given in units of
length base units above the ellipsoid (the default) or above the WGS84
geoid (if you supplied the `"WGS84"` parameter in the _geoSystem_
field). +
 +
EXAMPLE  (37.4506, −122.1834, 0) is the latitude/longitude
coordinate for Menlo Park, California, USA.

* *UTM*: (<northing>, <easting>, <elevation>) or (<easting>, <northing>,
<elevation>). The order of northing and easting is controlled by the
_geoSystem_ field. If `"northing_first"` is specified, the order
is northing then easting. If `"easting_first"` is specified, the
order is easting then northing. If neither is specified,
`"northing_first"` is the default. Elevation is always specified
third. Northings, eastings, and elevation are all given in units of
length base units. The zone of the coordinate, and whether it is in the
southern hemisphere, are defined in the _geoSystem_ string. Elevation is
given with reference to the ellipsoid (the default) or the WGS84 geoid
(if the `"WGS84"` parameter is specified in the _geoSystem_
field). +
 +
EXAMPLE  (4145173, 572227, 0) is the zone 10 northern
hemisphere UTM coordinate for Menlo Park, California, USA.

* *GC*: (<x>, <y>, <z>). These values are all given in units of metres.
The coordinate represents an offset from the center of the planet, based
upon the WGS84 ellipsoid. The z-axis passes through the poles while the
x-axis cuts through the latitude/longitude coordinate (0,0) degrees. +
 +
EXAMPLE  (−2700301, −4290762, 3857213) is the geocentric
coordinate for Menlo Park, California, USA.

* *WM*: (<x>, <y>, <elevation>). These values are all given in units of
metres. The x and y values represent Web Mercator coordinates with an
origin at 0 degrees latitude and longitude, based upon the WGS84
ellipsoid. The elevation is also with respect to the WGS84 ellipsoid. +
 +
EXAMPLE  (-13601393.87, 4502102.12, 0) is the Web Mercator
coordinate for Menlo Park, California, USA.

[[high-precisioncoords]]
==== 25.2.5 Dealing with high-precision coordinates

Most computer graphics systems, including X3D, use single-precision
floating point values to model and render all geometry. This is a
natural design constraint since computer graphics typically deals with
small screens (up to around 1600 x 1280 pixels), and locally bounded
regions. As a result, there is no need to use double-precision values
because any increases in accuracy that it brings would be lost in
sub-pixel noise.

However, single-precision is insufficient to model data over the range
of the earth at accurate ground resolutions. With only 23 bits of
mantissa, a coordinate can be accurate to only one part in 8 million
(2^23^-1); or about 6 or 7 decimal digits of precision. Since the
equatorial radius of the earth (considered as an example planetary body)
is 6,378,137 m (under the WGS84 ellipsoid), it is not possible to
achieve resolutions better than around 0.8 metres using single-precision
floating point numbers (6,378,137 / 8,388,607 = 0.8). Below this
threshold, various floating point rounding artifacts such as vertices
coalescing and camera jitter will occur.

This geo-referencing problem is one avoided by establishing a
geo-referenced local coordinate system (LCS). An absolute geo-referenced
location is defined as the origin of the LCS. This becomes the reference
point that correlates to the X3D world's (0,0,0) origin. Any subsequent
geospatial locations are translated into X3D's Cartesian coordinate
system relative to this LCS origin. Moreover, by allowing the user to
define these local frames easily, the creator of the geo-referenced data
uses the accuracy of a single-precision floating point representation by
creating X3D worlds of only limited local extent. This is the purpose of
the GeoOrigin node as specified via the _geoOrigin_ field of the
geographic X3D nodes. The GeoOrigin node and all _geoOrigin_ fields are
often unnecessary since X3D browsers can automatically provide local
origins as necessary).

To illustrate this concept, imagine an example where the
<<GeoOrigin>> is specified as (310385.0 e, 4361550.0 n, 0
m, zone 13) in UTM coordinates. This may be transformed to a
double-precision geocentric coordinate of (−1459877.12, −4715646.92,
4025213.19). Then a supplied absolute UTM coordinate of (310400.0 e,
4361600.0 n, 0 m, zone 13) may be transformed internally to a geocentric
coordinate of (−1459854.51, −4715620.48, 4025252.11). Finally, this
absolute geocentric coordinate can be transformed to a single-precision
local Cartesian coordinate system by subtracting the GeoOrigin location
to give (22.61, 26.44, 38.92), which is within single-precision range.

[[navigationissues]]
==== 25.2.6 Geospatial navigation issues

There are a number of navigation issues that are specific to the task of
browsing large geographic areas. One important issue is addressed here,
that of elevation scaled velocity.

The velocity at which users can navigate around a world should depend
upon their height above the terrain.

EXAMPLE  When flying over the coast at a height of 100 metres above the
terrain, a velocity of 100 metres per second might be considered
relatively fast. However, when approaching the earth from outer space, a
velocity of 100 metres per second would be intolerably slow. Creators of
geographic visualization systems have therefore learned to scale the
velocity of the user's navigation in an attempt to maintain a constant
pixel flow across the screen. A simple linear relationship between
velocity and the user's elevation above an ellipsoid such as WGS84 often
provides an acceptable and easily computable solution to this problem.
This behavior is addressed by the <<GeoViewpoint>> node.


=== 25.3 Node reference

[[GeoCoordinate]]
==== 25.3.1 GeoCoordinate

[source,node]
----
GeoCoordinate : X3DCoordinateNode {
  SFNode   [in,out] metadata  NULL        [X3DMetadataObject]
  MFVec3d  [in,out] point     []          (-∞,∞)
  SFNode   []       geoOrigin NULL        [GeoOrigin] 
  MFString []       geoSystem ["GD","WE"] (see 25.2.3)  
}
----

The GeoCoordinate node specifies a list of coordinates in a spatial
reference frame. It is used in the _coord_ field of vertex-based
geometry nodes including <<IndexedFaceSet>>,
<<IndexedLineSet>>, and <<PointSet>>.

The _geoOrigin_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The _point_ array is used to contain the actual geospatial coordinates
and should be provided in a format consistent with that specified for
the particular _geoSystem_ (see above). The geospatial coordinates are
transparently transformed into a geocentric, curved-earth
representation. For example, this would allow a geographer to create a
X3D world where all coordinates are specified in terms of latitude,
longitude, and elevation.

[[GeoElevationGrid]]
==== 25.3.2 GeoElevationGrid

[source,node]
----
GeoElevationGrid : X3DGeometryNode {
  MFDouble [in]     set_height
  SFNode   [in,out] color           NULL        [X3DColorNode]
  SFNode   [in,out] metadata        NULL        [X3DMetadataObject]
  SFNode   [in,out] normal          NULL        [X3DNormalNode]
  SFNode   [in,out] texCoord        NULL        [X3DTextureCoordinateNode]
  SFFloat  [in,out] yScale          1.0         [0,∞)
  SFBool   []       ccw             TRUE
  SFBool   []       colorPerVertex  TRUE
  SFDouble []       creaseAngle     0           [0,∞)
  SFVec3d  []       geoGridOrigin   0 0 0       (-∞,∞)
  SFNode   []       geoOrigin       NULL        [GeoOrigin] 
  MFString []       geoSystem       ["GD","WE"] (see 25.2.3)
  MFDouble []       height          [0 0]       (-∞,∞)
  SFBool   []       normalPerVertex TRUE
  SFBool   []       solid           TRUE
  SFInt32  []       xDimension      0           (0,∞)
  SFDouble []       xSpacing        1.0         [0,∞)
  SFInt32  []       zDimension      0           (0,∞)
  SFDouble []       zSpacing        1.0         [0,∞)
}
----

The GeoElevationGrid node specifies a uniform grid of elevation values
within some spatial reference frame. These are then transparently
transformed into a geocentric, curved-earth representation. For example,
this would allow a geographer to create a height field where all
coordinates are specified in terms of latitude, longitude, and
elevation.

The fields _color_, _colorPerVertex_, _texCoord_, _normal_, and
_normalPerVertex_ all have the same meaning as for
<<ElevationGrid>> (see <<ElevationGrid, 13.3.4 ElevationGrid>>). Similarly, if necessary, tessellation is applied as
specified in <<ElevationGrid, 13.3.4 ElevationGrid>>.

The _ccw_, _solid_, and _creaseAngle_ fields are described in
<<Commongeometryfields, 11.2.3 Common geometry fields>>.

The _geoOrigin_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The _geoGridOrigin_ field specifies the geographic coordinate for the
south-west corner (bottom-left) of the dataset. This value should be
specified as described in <<Specifyinggeospatialcoords, 25.2.4 Specifying geospatial coordinates>>.

The _height_ array contains _xDimension_ × _zDimension_ floating point
values that represent elevation above the ellipsoid or the geoid, as
appropriate. These values are given in row-major order from west to
east, south to north. When the _geoSystem_ is `"GD"`, _xSpacing_
refers to the number of units of longitude in angle base units between
adjacent height values and _zSpacing_ refers to the number of units of
latitude in angle base units between vertical height values. When the
geoSystem is `"UTM"`, _xSpacing_ refers to the number of eastings
(length base units) between adjacent height values and _zSpacing_ refers
to the number of northings (length base units) between vertical height
values.

EXAMPLE  If xDimension = _n_ and the grid spans _d_ units horizontally,
the xSpacing value should be set to:

____
_d_ / ( __n__−1).
____

The _yScale_ value can be used to produce a vertical exaggeration of the
data when it is displayed. By default, this value is 1.0 (no
exaggeration). If this value is set greater than 1.0, all heights will
appear larger than actual.

[[GeoLocation]]
==== 25.3.3 GeoLocation

[source,node]
----
GeoLocation : X3DGroupingNode {
  MFNode   [in]     addChildren                [X3DChildNode]
  MFNode   [in]     removeChildren             [X3DChildNode]
  MFNode   [in,out] children       []          [X3DChildNode]
  SFBool   [in,out] bboxDisplay    FALSE
  SFVec3d  [in,out] geoCoords      0 0 0       (-∞,∞)
  SFNode   [in,out] metadata       NULL        [X3DMetadataObject]
  SFBool   [in,out] visible        TRUE
  SFNode   []       geoOrigin      NULL        [GeoOrigin] 
  MFString []       geoSystem      ["GD","WE"] (see 25.2.3)
  SFVec3f  []       bboxCenter     0 0 0       (-∞,∞)
  SFVec3f  []       bboxSize       -1 -1 -1    [0,∞) or −1 −1 −1
}
----

The GeoLocation node provides the ability to geo-reference any standard
X3D model. That is, to take an ordinary X3D model, contained within the
_children_ field of the node, and to specify its geospatial location.
This node is a grouping node that can be thought of as a Transform node.
However, the GeoLocation node specifies an absolute location, not a
relative one, so content developers should not nest GeoLocation nodes
within each other.

The _geoOrigin_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The geometry of the nodes in _children_ is to be specified in units of
metres in X3D coordinates relative to the location specified by the
_geoCoords_ field. The _geoCoords_ field should be provided in the
format described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The _geoCoords_ field can be used to dynamically update the geospatial
location of the model; for example, an event might be sent from a
<<GeoPositionInterpolator>> node.

In addition to placing a X3D model at the correct geospatial location,
the GeoLocation node will also adjust the orientation of the model
appropriately. The standard X3D coordinate system specifies that the +Y
axis = up, +Z = out of the screen, and +X = towards the right. The
GeoLocation node will set the orientation so that the +Y axis is the up
direction for that local area (the normal to the tangent plane on the
ellipsoid), −Z points towards the north pole, and +X is east.

[[GeoLOD]]
==== 25.3.4 GeoLOD

[source,node]
----
GeoLOD : X3DChildNode, X3DBoundedObject {
  SFBool   [in,out] bboxDisplay    FALSE
  SFNode   [in,out] metadata       NULL        [X3DMetadataObject]
  SFBool   [in,out] visible        TRUE
  MFNode   [out]    children                   [X3DChildNode]
  SFInt32  [out]    level_changed
  SFVec3d  []       center         0 0 0       (-∞,∞)
  MFString []       child1Url      []          [URI]
  MFString []       child2Url      []          [URI]
  MFString []       child3Url      []          [URI]
  MFString []       child4Url      []          [URI]
  SFNode   []       geoOrigin      NULL        [GeoOrigin] 
  MFString []       geoSystem      ["GD","WE"] (see 25.2.3)
  SFFloat  []       range          10          [0,∞)
  MFString []       rootUrl        []          [URI]
  MFNode   []       rootNode       []          [X3DChildNode]
  SFVec3f  []       bboxCenter     0 0 0       (-∞,∞)
  SFVec3f  []       bboxSize       -1 -1 -1    [0,∞) or −1 −1 −1
}
----

The GeoLOD node provides a terrain-specialized form of the
<<LOD>> node. It is a grouping node that specifies two different
levels of detail for an object using a tree structure, where 0 to 4
children can be specified, and also efficiently manages the loading and
unloading of these levels of detail.

The level of detail is switched depending upon whether the user is
closer or farther than _range_ length base units from the geospatial
coordinate _center_. If provided, the _range_ field contains
monotonically increasing values that shall be greater than zero. If no
values are provided, the X3D browser is allowed to dynamically choose
transition ranges based on performance.

The _center_ field should be specified as described in
<<Specifyinggeospatialcoords, 25.2.4 Specifying geospatial coordinates>>.

The _geoOrigin_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The _visible_ field specifies whether or not the content within a node
is visually displayed. The value of this field has no effect on
animation behaviors, collision behaviors, event passing, or other
non-visual characteristics.

When the user is outside the specified range, only the geometry for
_rootUrl_ or _rootNode_ are displayed. When the viewer enters the
specified range, this geometry is replaced with the contents of the four
children files defined by _child1Url_ through _child4Url_. The four
children files are loaded into memory only when the user is within the
specified range. Similarly, these are unloaded from memory when the user
leaves this range. <<f-LoadingGeoLODlevels, Figure 25.1>> illustrates
this process. The child URLs shall be arranged in the same order as in
the figure; _i.e._, _child1Url_ represents the bottom-left quadtree
child. It is valid to specify less than four child URLs; in which case,
the GeoLOD should switch to the children nodes when all of the specified
URLs have been loaded. This latter feature can support tree structures
other than quadtrees, such as binary trees.

[[f-LoadingGeoLODlevels]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/geolod.gif[GeoLOD
Figure,width=381,height=192]

Figure 25.1 — Loading of GeoLOD levels

The _rootUrl_ and _rootNode_ fields provide two different ways to
specify the geometry of the root tile. You may use one or the other. The
_rootNode_ field lets you include the geometry for the root tile
directly within the X3D file; whereas the _rootUrl_ field lets you
specify a URL for a file that contains the geometry. The result of
specifying a value for both of these fields is undefined.

The _children_ field is used to expose a portion of the scene graph for
the currently loaded set of nodes. The value returned as an event is an
MFNode containing the currently selected tile. This will either be the
node specified by the _rootNode_ field or the nodes specified by the
_child1Url_, _child2Url_, _child3Url_, and _child4Url_ fields. The
GeoLOD node shall generate a new _children_ output event each time the
scene graph is changed (EXAMPLE whenever nodes are loaded or
unloaded). When the new children event is generated, the GeoLOD node
shall also generate a _level_changed_ event with value 0 or 1, where 0
indicates the _rootNode_ field and 1 indicates the nodes specified by
the _child1Url_, _child2Url_, _child3Url_, and _child4Url_ fields.

The GeoLOD node may optionally be implemented with support for a cache
of the most recent nodes that have been loaded. This cache should be
global across all GeoLOD instances in a scene. This will improve
performance when navigating large terrain models by avoiding excessive
loading and unloading when a user makes small changes in viewpoint.

NOTE:  Nested GeoLOD nodes can lead to unexpected or undefined
behaviour.

[[GeoMetadata]]
==== 25.3.5 GeoMetadata

[source,node]
----
GeoMetadata : X3DInfoNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0  [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0  [0,∞)
  MFNode   [in,out] data                 []
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL [X3DMetadataObject]
  MFString [in,out] summary              []
  MFString [in,out] url                  []   [URI]
}
----

The GeoMetadata node supports the specification of metadata describing
any number of geospatial nodes. This is similar to a
<<WorldInfo>> node, but specifically for describing
geospatial information.

There are a number of standards and representations for geospatial
metadata. Rather than adopt any particular standard, the purpose of the
GeoMetadata node is to provide links to any of these complete metadata
descriptions, with the option to also supply a short, human-readable
summary. More specific metadata can be specified using the _metadata_
field available in each node.

The _url_ field is used to specify a hypertext link to an external,
complete metadata description. Multiple URL strings can be specified in
order to provide alternative locations for the same metadata
information. The summary field may be used to specify the format of the
metadata in the case where this cannot be deduced easily.

The _summary_ string array contains a set of keyword/value pairs, with
each keyword and its subsequent value contained in a separate string;
_i.e._, there should always be an even (or zero) number of strings. This
provides a simple, extensible mechanism to include metadata elements
that are human-readable and easy to parse.
<<t25_5, Table 25.5>> specifies a number of keywords and
the format that should be used to describe their values. If an unknown
keyword is found, it (and its associated value) are ignored.

[[t25_5]]
Table 25.5 — GeoMetadata keywords and values

[cols=",",]
|===
|Keyword |Value

|title |A name to succinctly identify the dataset to user. For example,
"San Francisco, CA".

|description |A brief textual description or summary of the content of
the dataset. For example, "LANDSAT 7 satellite imagery taken over
northern Scotland".

|coordinateSystem |The spatial reference frame used to represent the
data ( _e.g._, GD, UTM, or LCC). The list of valid codes that can be
used in this field are defined in <<I18026, ISO/IEC 18026>>. In the
case of UTM, the zone number should also be specified in the format "UTM
Z _x_", where the zone number is in the range [1,60]. For example, "UTM
Z11".

|horizontalDatum |The name of the geodetic datum. The list of valid
codes that can be used in this field are defined in <<I18026, ISO/IEC 18026>>. For example, "W84".

|verticalDatum |The name of the vertical datum (geoid). The list of
valid codes that can be used in this field are defined in
<<I18026, ISO/IEC 18026>>. For example, "W84".

|ellipsoid |The name of the geodetic ellipsoid. The list of valid codes
that can be used in this field are defined in <<I18026, ISO/IEC 18026>>. For example, "WE".

|extent |The bounding coordinates for the dataset given in spatial
reference frame specified by the _coordinateSystem_ keyword. These are
provided in the order eastmost, southmost, westmost, northmost. An
example for GD is: "-180.0 -90.0 180.0 90.0".

|resolution |The resolution, or ground sample distance, given in units
of length base units. For example, "30".

|originator |A string defining the originator of the data, for example
the author, agency, organization, publisher, etc. For example, "John
Doe, Any Corporation, Some Town, Some Country"

|copyright |Any appropriate copyright declaration that pertains to the
data. For example, "(c) Copyright 2000, Any Corporation. All rights
reserved. Freely distributable."

|date |A single date/time, or a date/time range, defining the valid time
period to which the data pertains. Dates are specified in the format
"YYYY MM DD [HH:MM]". Years in the current time period should be
specified using four digits (`EXAMPLE`  "1999" or "2001"). Years
can have other than four digits and can be negative. A date range is
specified by supplying two values separated by a "-" (hyphen) character.
An optional time can be supplied should this level of accuracy be
required. Times are to be specified in 24-hour format with respect to
GMT. For example, "1999 01 01 00:00 - 1999 12 31 23:59".

|metadataFormat |A string that specifies the format of the external
metadata description specified by the _url_ field of the GeoMetadata
node. For example, "FGDC", "ISO TC211", "CEN TC287", or "OGC".

|dataUrl |A hypertext link to the source data used to create the X3D
node(s) to which this metadata pertains. Multiple _dataUrl_
keyword/value pairs can be specified in order to provide alternative
locations for the same source data. For example,
"https://www.foo.bar/data/sf1".

|dataFormat |A free-text string that describes the format of the source
data used to create the X3D node(s) to which this metadata pertains.
This refers to the source data specified by the _dataUrl_ keyword (if
present). For example, "USGS 5.5-min DEM".
|===

Metadata values from the _summary_ field can be equivalently encoded via
MetadataSet containing related X3DMetadataObject nodes.

The _data_ field is used to list all of the other nodes in a scene by
DEF name that reference the data described in the GeoMetadata node. For
example, if the GeoMetadata node is describing a height field grid, the
appropriate <<GeoElevationGrid>> node might be
included inside the _data_ field. The nodes in the _data_ field are not
rendered, so DEF/USE can be used in order to first describe them and
then to use them in the scene graph. This approach allows associating
multiple data nodes with a single GeoMetadata node, specifying multiple
GeoMetadata nodes within a single scene, and also provides a mechanism
to easily locate all of the data that pertain to any particular metadata
entry. If the data field is not specified, it is assumed that the
GeoMetadata node pertains to the entire scene.

[[GeoOrigin]]
==== 25.3.6 GeoOrigin

[source,node]
----
GeoOrigin : X3DNode {
  SFVec3d  [in,out] geoCoords 0 0 0       (-∞,∞)
  SFNode   [in,out] metadata  NULL        [X3DMetadataObject]
  MFString []       geoSystem ["GD","WE"] (see 25.2.3)
  SFBool   []       rotateYUp FALSE
}
----

The GeoOrigin node defines an absolute geospatial location and an
implicit local coordinate frame against which geometry is referenced.
This node is used to translate from geographical coordinates into a
local Cartesian coordinate system which can be managed by the X3D
browser.

GeoOrigin node usage is discouraged because different models built with
separate GeoOrigin nodes cannot be easily combined. GeoOrigin is still
needed in some situations to achieve correct visual fidelity. Relevant
GeoOrigin examples may include fine positioning in a global context, to
aid deployment to handheld devices which may use lower-precision
arithmetic in their graphics pipelines.

The _geoCoords_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The _rotateYUp_ field is used to specify whether coordinates of nodes
that use this GeoOrigin are to be rotated such that their up direction
is aligned with the X3D Y axis. The default behavior is to not perform
this operation. This means that the local up direction will depend upon
the location of the GeoOrigin with respect to the planet surface. The
principal reason for performing the rotation is to ensure that standard
navigation modes such as "`FLY`" and "`WALK`", which
assume that +Y = up, will function correctly. Specifying _rotateYUp_ to
be `TRUE` may incur an extra computational overhead in order to
perform the rotation for each point.

[[GeoPositionInterpolator]]
==== 25.3.7 GeoPositionInterpolator

[source,node]
----
GeoPositionInterpolator : X3DInterpolatorNode {
  SFFloat  [in]     set_fraction                 (-∞,∞)
  MFFloat  [in,out] key              []          (-∞,∞)
  MFVec3d  [in,out] keyValue         []
  SFNode   [in,out] metadata         NULL        [X3DMetadataObject]
  SFVec3d  [out]    geovalue_changed
  SFVec3f  [out]    value_changed
  SFNode   []       geoOrigin        NULL        [GeoOrigin] 
  MFString []       geoSystem        ["GD","WE"] (see 25.2.3)
}
----

The GeoPositionInterpolator node provides an interpolator capability
where key values are specified in geographic coordinates and the
interpolation is performed within the specified spatial reference frame.

The _geoOrigin_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The fields _key_, _set_fraction_, and _value_changed_ have the same
meaning as in the PositionInterpolator node.

The _keyValue_ array is used to contain the actual coordinates and
should be provided in a format consistent with that specified for the
particular _geoSystem_.

The _geovalue_changed_ field outputs the the interpolated coordinate in
the spatial reference frame specified by _geoSystem_. This can be passed
to other GeoX3D nodes that support a field of this form ( _e.g._,
<<GeoViewpoint>> and <<GeoLocation>>).

[[GeoProximitySensor]]
==== 25.3.8 GeoProximitySensor

[source,node]
----
GeoProximitySensor : X3DEnvironmentalSensorNode {
  SFVec3d    [in,out] center                   0 0 0       (-∞,∞)
  SFString   [in,out] description              ""
  SFBool     [in,out] enabled                  TRUE
  SFVec3d    [in,out] geoCenter                0 0 0       (-∞,∞)
  SFNode     [in,out] metadata                 NULL        [X3DMetadataObject]
  SFVec3f    [in,out] size                     0 0 0       [0,∞)
  SFVec3f    [out]    centerOfRotation_changed
  SFTime     [out]    enterTime
  SFTime     [out]    exitTime
  SFVec3d    [out]    geoCoord_changed
  SFBool     [out]    isActive
  SFRotation [out]    orientation_changed
  SFVec3f    [out]    position_changed
  SFNode     []       geoOrigin                NULL        [GeoOrigin] 
  MFString   []       geoSystem                ["GD","WE"] (see 25.2.3)
}
----

The GeoProximitySensor node generates events when the viewer enters,
exits, and moves within a region in space (defined by a box). +
 +
A GeoProximitySensor node generates _isActive_ events as the viewer
enters and exits the rectangular box defined by its _geoCenter_ and
_size_ fields. This box is oriented tangent to the ellipsoid in a local
coordinate system. Starting with version 3.3, the _geoCenter_ field is
renamed _center_. +
 +
The fields _geoSystem_ and _geoOrigin_ are described in
<<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>> and 
high-precision coordinates], respectively. +
 +
The _geoCoord_changed_ generates an event that returns the geospatial
coordinates of the viewer's position in the spatial reference frame
specified by _geoSystem_ for the viewer's position whenever a
_position_changed_ event is generated. The _geoCoord_changed_ value
corresponds to the world position returned by _position_changed_.

The remaining fields are defined in <<ProximitySensor, 22.4.1 ProximitySensor>>.

[[GeoTouchSensor]]
==== 25.3.9 GeoTouchSensor

[source,node]
----
GeoTouchSensor : X3DTouchSensorNode {
  SFString [in,out] description         ""
  SFBool   [in,out] enabled             TRUE
  SFNode   [in,out] metadata            NULL        [X3DMetadataObject]
  SFVec3f  [out]    hitNormal_changed
  SFVec3f  [out]    hitPoint_changed
  SFVec2f  [out]    hitTexCoord_changed
  SFVec3d  [out]    hitGeoCoord_changed
  SFBool   [out]    isActive
  SFBool   [out]    isOver
  SFTime   [out]    touchTime
  SFNode   []       geoOrigin           NULL        [GeoOrigin] 
  MFString []       geoSystem           ["GD","WE"] (see 25.2.3)
}
----

A GeoTouchSensor node tracks the location and state of a pointing device
and detects when the user points at geometry contained by the parent
group of the GeoTouchSensor. This node provides the same functionality
as a <<TouchSensor>> but also provides the ability to
return the geographic coordinate under the pointing device.

The _description_ field in the GeoTouchSensor node specifies a textual
description of the GeoTouchSensor node. This may be used by X3D
browser-specific user interfaces that wish to present users with more
detailed information about the GeoTouchSensor.

A GeoTouchSensor can be enabled or disabled by sending an event of value
`TRUE` or `FALSE` to the _enabled_ field. A disabled
GeoTouchSensor does not track user input or send events.

The _geoOrigin_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The fields _hitNormal_changed_, _hitPoint_changed_,
_hitTexCoord_changed_, _isActive_, _isOver_, and _touchTime_ all have
the same meaning as in the TouchSensor node.

The _hitGeoCoord_changed_ field is generated while the pointing device
is pointing towards the GeoTouchSensor's geometry ( _i.e._, when
_isOver_ is `TRUE`). It is a field containing the geospatial
coordinate for the point of intersection between the pointing device's
location and the underlying geometry. The value of the geoSystem string
defines the spatial reference frame of the geospatial coordinate. For
example, given the default geoSystem value of "GD", the
_hitGeoCoord_changed_ field will be in the format (<latitude>
<longitude> <elevation>) (see <<Specifyinggeospatialcoords, 25.2.4 Specifying geospatial coordinates>>).

[[GeoTransform]]
==== 25.3.10 GeoTransform

[source,node]
----
GeoTransform : X3DGroupingNode {
  MFNode     [in]     addChildren                  [X3DChildNode]
  MFNode     [in]     removeChildren               [X3DChildNode]
  MFNode     [in,out] children         []          [X3DChildNode]
  SFBool     [in,out] bboxDisplay      FALSE
  SFVec3d    [in,out] geoCenter        0 0 0       (-∞,∞)
  SFNode     [in,out] metadata         NULL        [X3DMetadataObject]
  SFRotation [in,out] rotation         0 0 1 0     [-1,1] or (-∞,∞)
  SFVec3f    [in,out] scale            1 1 1       (-∞,∞) 
  SFRotation [in,out] scaleOrientation 0 0 1 0     [-1,1] or (-∞,∞)
  SFVec3f    [in,out] translation      0 0 0       (-∞,∞)
  SFBool     [in,out] visible          TRUE
  SFVec3f    []       bboxCenter       0 0 0       (-∞,∞)
  SFVec3f    []       bboxSize         -1 -1 -1    [0,∞) or −1 −1 −1
  SFNode     []       geoOrigin        NULL        [GeoOrigin] 
  MFString   []       geoSystem        ["GD","WE"] (see 25.2.3)
}
----

The GeoTransform node is a grouping node that defines a coordinate
system for its children to support the translation and orientation of
geometry built using GeoCoordinate nodes within the local world
coordinate system. The X-Z plane of a GeoTransform coordinate system is
tangent to the ellipsoid of the spatial reference frame at the location
specified by the _geoCenter_ field.

The _geoCenter_ field specifies, in the spatial reference frame
specified by the _geoSystem_ field, the location at which the local
coordinate system is centered. +
 +
The fields _geoSystem_ and _geoOrigin_ are described in
<<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>> and 
high-precision coordinates], respectively. +
 +
The remaining fields are defined in <<Transform, 10.4.4 Transform>>.

[[GeoViewpoint]]
==== 25.3.11 GeoViewpoint

[source,node]
----
GeoViewpoint : X3DViewpointNode {
  SFBool     [in]     set_bind
  SFVec3d    [in,out] centerOfRotation  0 0 0             (-∞,∞)
  SFString   [in,out] description       ""
  SFFloat    [in,out] farDistance       -1                -1 or (0,∞)
  SFFloat    [in,out] fieldOfView       π/4               (0,π)
  SFBool     [in,out] jump              TRUE
  SFNode     [in,out] metadata          NULL              [X3DMetadataObject]
  SFNode     [in,out] navigationInfo    NULL              [NavigationInfo]
  SFFloat    [in,out] nearDistance      -1                -1 or (0,∞)
  SFRotation [in,out] orientation       0 0 1 0           (-∞,∞) or -1 1
  SFVec3d    [in,out] position          0 0 100000        (-∞,∞)
  SFBool     [in,out] retainUserOffsets FALSE
  SFBool     [in,out] viewAll           FALSE
  SFTime     [out]    bindTime
  SFBool     [out]    isBound
  SFNode     []       geoOrigin         NULL              [GeoOrigin] 
  MFString   []       geoSystem         ["GD","WE"]       (see 25.2.3)
  SFFloat    []       speedFactor       1.0               [0,∞)
}
----

The GeoViewpoint node allows the specification of a viewpoint in terms
of a geospatial coordinate. This node can be used wherever a
<<Viewpoint>> node can be used and can be combined with
Viewpoint nodes in the same scene. The _fieldOfView_, _jump_,
_description_, _set_bind_, _bindTime_, and _isBound_ fields and events
have the same behavior as the standard Viewpoint node. When a
GeoViewpoint node is bound, it overrides the currently bound Viewpoint
and NavigationInfo nodes in the scene.

The _geoOrigin_ field is used to specify a local coordinate frame for
extended precision as described in <<high-precisioncoords, 25.2.5 Dealing with high-precision coordinates>>.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<SpecifyingSpatialReferenceFrame, 25.2.3 Specifying a spatial reference frame>>.

The _position_ is used to define the actual coordinate at which the
viewpoint is to be located. It should be provided in a format consistent
with that specified by _geoSystem_. There is also a _set_position_ field
which can be routed from the _geovalue_changed_ field of a
<<GeoPositionInterpolator>> node in order to
animate the position of the GeoViewpoint.

The _orientation_ string defines a relative orientation from the local
orientation frame that is defined by the position field. By default, the
orientation of the viewpoint will always be aligned such that the +Y
axis is the up vector for the local area (the normal to the tangent
plane on the ellipsoid), -Z points towards the north pole, and +X is
east. Therefore, if a GeoViewpoint is created that always looked
straight down, no matter where on the planetary body is being observed,
an _orientation_ value of [ 1 0 0 -1.57 ] is used. The _set_orientation_
field can be routed from the _value_changed_ field of an
<<OrientationInterpolator>> in order to
animate the orientation of the GeoViewpoint.

The GeoViewpoint node may be implemented as if there is an embedded
NavigationInfo node that is bound and unbound with the GeoViewpoint
node. As such, a X3D browser should internally set the _speed_,
_avatarSize_, and _visibilityLimit_ fields to an appropriate value for
the viewpoint's elevation. The X3D browser should also continually
update the speed field as the user moves in order to support elevation
scaled velocity (see <<navigationissues, 25.2.6 Geospatial navigation issues>>). It is recommended that the speed of user interaction be
defined as:

____
_( elevation / 10.0 )_ speed base units
____

where _elevation_ is the user's elevation above the WGS84 ellipsoid in
units of speed base units. It is also recommended that the same scaling
factor be applied to the _avatarSize_ vector.

The _speedFactor_ field of the GeoViewpoint node is used as a multiplier
to the elevation-based velocity that the node sets internally; _i.e._,
this is a relative value and not an absolute speed as is the case for
the NavigationInfo node.

The _viewAll_ field controls behavior in the same manner as occurs for
<<Viewpoint>> node.

[[S25.4_SupportLevels]]
=== 25.4 Support levels

The Geospatial component provides one level of support as specified in
<<t25_6, Table 25.6>>.

[[t25_6]]
Table 25.6 — Geospatial component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|*Level* |Prerequisites |*Nodes/Features* |Support
|*1* |Core 1 +
Time 1 +
Networking 1 +
Grouping 3 +
Rendering 1 +
Shape 1 +
Geometry3D 1 +
Interpolator 1 +
Point device sensor 1 +
Navigation 1 |  |
|  | |GeoCoordinate |All fields fully supported.
|  |  |GeoElevationGrid |All fields fully supported.
|  |  |GeoLocation |All fields fully supported.
|  |  |GeoLOD |All fields fully supported.
|  |  |GeoMetadata |All fields fully supported.
|  |  |GeoOrigin |All fields fully supported.
|  |  |GeoPositionInterpolator |All fields fully supported.
|  |  |GeoTouchSensor |All fields fully supported.
|  |  |GeoViewpoint |All fields fully supported.
|* 2* |Core 1 +
Time 1 +
Networking 1 +
Grouping 3 +
Rendering 1 +
Shape 1 +
Geometry3D 1 +
Interpolator 1 +
Environmental device sensor 1 +
Navigation 1 |  | 
|  |  |All Level 1 Geospatial nodes |All fields fully supported.
|  |  |GeoProximitySensor |All fields fully supported.
|  |  |GeoTransform |All fields fully supported.
|===

[[hanim_html]]
== 26 HAnim Component

[[S26_Introduction]]
=== 26.1 Introduction

[[S26_Name]]
==== 26.1.1 Name

The name of this component is " HAnim". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S26_Overview]]
==== 26.1.2 Overview

This clause describes the Humanoid Animation (HAnim) component of this
document. <<t26_1, Table 26.1>> provides links to the major topics
in this clause. The HAnim component of X3D defines the node bindings and
other specifics for implementing ISO/IEC 19774 (see
<<I19774>>) within X3D.

[[t26_1]]
Table 26.1 — Topics

* <<S26Introduction, 26.1 Introduction>>
** <<S26_Name, 26.1.1 Name>>
** <<S26_Overview, 26.1.2 Overview>>
* <<S26_Concepts, 26.2 Concepts>>
* <<S26_NodeReference, 26.3 Node reference>>
** <<HAnimDisplacer, 26.3.1 HAnimDisplacer>>
** <<HAnimHumanoid, 26.3.2 HAnimHumanoid>>
** <<HAnimJoint, 26.3.3 HAnimJoint>>
** <<HAnimMotion, 26.3.4 HAnimMotion>>
** <<HAnimSegment, 26.3.5 HAnimSegment>>
** <<HAnimSite, 26.3.6 HAnimSite>>
* <<S26_SupportLevels, 26.4 Support levels>>

* <<t26_1, Table 26.1 — Topics>>
* <<t26_2, Table 26.2 — Humanoid animation (HAnim) component support levels>>




[[S26_Concepts]]
=== 26.2 Concepts

This component maps the functionality defined in <<I19774, ISO/IEC 19774>> to a set of X3D nodes. The semantics for these nodes are as
specified therein.


=== 26.3 Node reference

[[HAnimDisplacer]]
==== 26.3.1 HAnimDisplacer

[source,node]
----
HAnimDisplacer : X3DGeometricPropertyNode {
  MFInt32  [in,out] coordIndex    []   [0,∞) 
  SFString [in,out] description   ""
  MFVec3f  [in,out] displacements []
  SFNode   [in,out] metadata      NULL [X3DMetadataObject]
  SFString [in,out] name          ""
  SFFloat  [in,out] weight        0.0  (-∞,∞)
}
----

Applications may need to alter the shape of individual segments. At the
most basic level, this is done by writing to the _point_ field of the
node found in the _coord_ field of the <<HAnimSegment>> node.

In some cases, the application may need to be able to identify specific
groups of vertices within an HAnimSegment.

EXAMPLE  The application may need to know which vertices
within the skull HAnimSegment comprise the left eyebrow.

It may also require "hints" as to the direction in which each vertex
should move. That information is stored in a node called an
HAnimDisplacer. The HAnimDisplacers for a particular HAnimSegment are
stored in the _displacers_ field of that HAnimSegment.

Each field is described in <<I19774, ISO/IEC 19774>>.

[[HAnimHumanoid]]
==== 26.3.2 HAnimHumanoid

[source,node]
----
HAnimHumanoid : X3DChildNode, X3DBoundedObject {
  SFVec3f    [in,out] center                0 0 0    (-∞,∞)
  SFString   [in,out] description           ""
  SFBool     [in,out] bboxDisplay           FALSE
  MFString   [in,out] info                  []
  MFVec3f    [in,out] jointBindingPositions []       (-∞,∞)
  MFRotation [in,out] jointBindingRotations []       [-1,1] or (-∞,∞)
  MFVec3f    [in,out] jointBindingScales    []       (0,∞)
  MFNode     [in,out] joints                []       [HAnimJoint]
  SFInt32    [in,out] loa                   -1       [-1,4]
  SFNode     [in,out] metadata              NULL     [X3DMetadataObject]
  MFNode     [in,out] motions               []       [HAnimMotion]
  MFBool     [in,out] motionsEnabled        []
  SFString   [in,out] name                  ""
  SFRotation [in,out] rotation              0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] scale                 1 1 1    (0,∞)
  SFRotation [in,out] scaleOrientation      0 0 1 0  [-1,1] or (-∞,∞)
  MFNode     [in,out] segments              []       [HAnimSegment]
  MFNode     [in,out] sites                 []       [HAnimSite]
  SFString   [in,out] skeletalConfiguration "BASIC"
  MFNode     [in,out] skeleton              []       [HAnimJoint, HAnimSite]
  MFNode     [in,out] skin                  []       [Group, LOD, Shape, Switch, Transform, IndexedFaceSet, IndexedFanSet, IndexedLineSet, IndexedQuadSet, IndexedTriangleSet, IndexedTriangleStripSet]
  SFNode     [in,out] skinBindingCoords     NULL     [Coordinate|CoordinateDouble]
  SFNode     [in,out] skinBindingNormals    NULL     [X3DNormalNode]
  SFNode     [in,out] skinCoord             NULL     [Coordinate|CoordinateDouble]
  SFNode     [in,out] skinNormal            NULL     [X3DNormalNode]
  SFVec3f    [in,out] translation           0 0 0    (-∞,∞)
  SFString   [in,out] version               "2.0"    ["2.0"] 
  MFNode     [in,out] viewpoints            []       [HAnimSite]
  SFBool     [in,out] visible               TRUE
  SFVec3f    []       bboxCenter            0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize              -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The HAnimHumanoid node is used to store human-readable data such as
author and copyright information, as well as to store references to the
<<HAnimJoint>>, <<HAnimMotion>>, <<HAnimSegment>>, and <<HAnimSite>> nodes
in addition to serving as a container for the entire humanoid. Thus, it
serves as an essential node for moving the humanoid through its
environment.

Each field is described in <<I19774, ISO/IEC 19774>>.

Metadata values from the _info_ field can be equivalently encoded via
MetadataSet containing related X3DMetadataObject nodes.

[[HAnimJoint]]
==== 26.3.3 HAnimJoint

[source,node]
----
HAnimJoint : X3DGroupingNode {
  MFNode     [in]     addChildren               [HAnimJoint,HAnimSegment]
  MFNode     [in]     removeChildren            [HAnimJoint,HAnimSegment]
  SFVec3f    [in,out] center           0 0 0    (-∞,∞)`
  MFNode     [in,out] children         []       [HAnimJoint,HAnimSegment]
  SFString   [in,out] description      ""
  MFNode     [in,out] displacers       []       [HAnimDisplacer]
  SFBool     [in,out] bboxDisplay      FALSE
  SFRotation [in,out] limitOrientation 0 0 1 0  [-1,1] or (-∞,∞)
  MFFloat    [in,out] llimit           [0 0 0]  (-∞,∞)
  SFNode     [in,out] metadata         NULL     [X3DMetadataObject]
  SFString   [in,out] name             ""
  SFRotation [in,out] rotation         0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] scale            1 1 1    (0,∞)
  SFRotation [in,out] scaleOrientation 0 0 1 0  [-1,1] or (-∞,∞)
  MFInt32    [in,out] skinCoordIndex   []       [0,∞)
  MFFloat    [in,out] skinCoordWeight  []       [0,1]
  MFFloat    [in,out] stiffness        [0 0 0]  [0,1]
  SFVec3f    [in,out] translation      0 0 0    (-∞,∞)
  MFFloat    [in,out] ulimit           [0 0 0]  (-∞,∞)
  SFBool     [in,out] visible          TRUE
  SFVec3f    []       bboxCenter       0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize         -1 -1 -1 [0,∞) or −1 −1 −1
}
----

Each joint in the body is represented by an HAnimJoint node, which is
used to define the relationship of each body segment to its immediate
parent. A child HAnimSegment node provides a visual representation of
the skeleton segment.

An HAnimJoint may only be a child of another HAnimJoint node or a child
within the _skeleton_ field in the case of the HAnimJoint used as a
humanoid root ( _i.e._, an HAnimJoint may not be a child of an
<<HAnimSegment>>).

The HAnimJoint node is also used to store other joint-specific
information. In particular, a joint _name_ is provided so that
applications can identify each HAnimJoint node at run-time. The
HAnimJoint node may contain hints for inverse-kinematics systems that
wish to control the HAnim figure. These hints include the upper and
lower joint limits, the orientation of the joint limits, and a
_stiffness_ (resistance) value.

The _llimit_, _ulimit_, and _stiffness_ fields shall contain three
values or else be an empty array. An empty _llimit_, _ulimit_, or
_stiffness_ array is equivalent to 0 0 0. Behavior is undefined when
array length is 1, 2, or greater than 3.

NOTE  These limits are not enforced by any mechanism within the scene
graph of the humanoid, and are provided for information purposes only.
Use of this information and enforcement of the joint limits is up to the
application.

Humanoid authors and tools are free to implement the HAnimJoint node
however they choose. In particular, they may choose to use a single
polygonal mesh to represent a humanoid, rather than having a separate
<<IndexedFaceSet>> for each body segment. In such a
case, an HAnimJoint would be responsible for moving the vertices that
correspond to a particular body segment and all the segments descended
from it.

Each field is described in <<I19774, ISO/IEC 19774>>.

[[HAnimMotion]]
==== 26.3.4 HAnimMotion

[source,node]
----
HAnimMotion : X3DChildNode {
  SFBool   [in]     next
  SFBool   [in]     previous
  SFString [in,out] channels         ""
  MFBool   [in,out] channelsEnabled  []
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFInt32  [in,out] endFrame         0      [0,∞)
  SFTime   [in,out] frameDuration    0.1    (0,∞)
  SFInt32  [in,out] frameIncrement   1      (-∞,∞)
  SFInt32  [in,out] frameIndex       0      [0,∞)
  SFString [in,out] joints           ""                  
  SFInt32  [in,out] loa              -1     [-1,4]
  SFBool   [in,out] loop             FALSE
  SFNode   [in,out] metadata         NULL   [X3DMetadataObject]
  SFString [in,out] name             ""
  SFInt32  [in,out] startFrame       0      [0,∞)
  MFFloat  [in,out] values           []     (-∞,∞)
  SFTime   [out]    cycleTime               [0,∞)
  SFTime   [out]    elapsedTime             (0,∞)
  SFInt32  [out]    frameCount              [0,∞)
}
----

HAnimMotion is used for motion animation of Humanoid characters. Raw
motion data, for example, motion capture data, details the number of
frames, the frame display time, and the parameter values for the motion
from each channel at each frame.

Each field is described in <<I19774, ISO/IEC 19774>>.

[[HAnimSegment]]
==== 26.3.5 HAnimSegment

[source,node]
----
HAnimSegment : X3DGroupingNode {
  MFNode   [in]     addChildren                          [X3DChildNode]
  MFNode   [in]     removeChildren                       [X3DChildNode]
  SFBool   [in,out] bboxDisplay      FALSE
  SFVec3f  [in,out] centerOfMass     0 0 0               (-∞,∞)
  MFNode   [in,out] children         []                  [X3DChildNode]
  SFNode   [in,out] coord            NULL                [Coordinate|CoordinateDouble]
  SFString [in,out] description      ""
  MFNode   [in,out] displacers       []                  [HAnimDisplacer]
  SFFloat  [in,out] mass             0                   [0,∞)
  SFNode   [in,out] metadata         NULL                [X3DMetadataObject]
  MFFloat  [in,out] momentsOfInertia [0 0 0 0 0 0 0 0 0] [0,∞)
  SFString [in,out] name             ""
  SFBool   [in,out] visible          TRUE
  SFVec3f  []       bboxCenter       0 0 0               (-∞,∞)
  SFVec3f  []       bboxSize         -1 -1 -1            [0,∞) or −1 −1 −1
}
----

Each body segment is stored in an HAnimSegment node, providing a visual
representation of the skeleton segment. Parent/child translation and
rotation relationships are defined in parent/child HAnimSegment nodes.

The HAnimSegment node is a grouping node that will typically contain
either a number of <<Shape>> nodes or perhaps
<<Transform>> nodes that position the body part within its
coordinate system as defined in <<I19774, ISO/IEC 19774>>. The use of
LOD nodes is recommended if the geometry of the HAnimSegment is complex.

Each field is described in <<I19774, ISO/IEC 19774>>.

[[HAnimSite]]
==== 26.3.6 HAnimSite

[source,node]
----
HAnimSite : X3DGroupingNode {
  MFNode     [in]     addChildren               [X3DChildNode]
  MFNode     [in]     removeChildren            [X3DChildNode]
  SFVec3f    [in,out] center           0 0 0    (-∞,∞)
  MFNode     [in,out] children         []       [X3DChildNode]
  SFString   [in,out] description      ""
  SFBool     [in,out] bboxDisplay      FALSE
  SFBool     [in,out] visible          TRUE
  SFNode     [in,out] metadata         NULL     [X3DMetadataObject]
  SFString   [in,out] name             ""
  SFRotation [in,out] rotation         0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] scale            1 1 1    (0,∞)
  SFRotation [in,out] scaleOrientation 0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] translation      0 0 0    [-1,1] or (-∞,∞)
  SFVec3f    []       bboxCenter       0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize         -1 -1 -1 [0,∞) or −1 −1 −1
}
----

An HAnimSite node serves three purposes. The first is to define an "end
effecter" location that can be used by an inverse kinematics system. The
second is to define an attachment point for accessories such as jewelry
and clothing. The third is to define a location for a virtual camera in
the reference frame of an HAnimSegment (such as a view "through the
eyes" of the humanoid for use in multi-user worlds).

Each field is described in <<I19774, ISO/IEC 19774>>.

[[S26.4_SupportLevels]]
=== 26.4 Support levels

The HAnim component provides 3 levels of support as specified in
<<t26_2, Table 26.2>>.

[[t26_2]]
*Table 26.2 — Humanoid animation (HAnim) component
support levels*

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Geometry3D 2 +
Shape 1 +
Texturing 1 +
Navigation 2 |HAnimHumanoid skeleton support |

| | |HAnimDisplacer |All fields fully supported.
| | |HAnimHumanoid  |All fields fully supported except _skin, skinCoord,
skinNormal, skinBindingCoord, skinBindingNormal, motions_ and
_motionsEnabled_ fields optional.
| | |HAnimJoint     |All fields fully supported except _skinCoordIndex_ and
_skinCoordWeight_ fields optional.
| | |HAnimSegment   |All fields fully supported.
| | |HAnimSite      |All fields fully supported.

|*2* |Core 1 +
Grouping 1 +
Geometry3D 2 +
Shape 1 +
Texturing 1 +
Navigation 2 |HAnimHumanoid skin support |

| | |HAnimDisplacer |All fields fully supported.
| | |HAnimHumanoid  |All fields fully supported except _motions_ and _motionsEnabled_ fields optional.
| | |HAnimJoint     |All fields fully supported.
| | |HAnimSegment   |All fields fully supported.
| | |HAnimSite      |All fields fully supported.

|*3* |Core 1 +
Grouping 1 +
Geometry3D 2 +
Shape 1 +
Texturing 1 +
Navigation 2 |Motion animation support |

| | |HAnimDisplacer |All fields fully supported.
| | |HAnimHumanoid  |All fields fully supported.
| | |HAnimJoint     |All fields fully supported.
| | |HAnimMotion    |All fields fully supported.
| | |HAnimSegment   |All fields fully supported.
| | |HAnimSite      |All fields fully supported.
|===

[[nurbs_html]]
== 27 NURBS Component

[[S27_Introduction]]
=== 27.1 Introduction

[[S27_Name]]
==== 27.1.1 Name

The name of this component is "NURBS". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S27_Overview]]
==== 27.1.2 Overview

This subclause describes the Non-uniform Rational B-Spline (NURBS)
component of this document. <<t27_1, Table 27.1>> provides links to
the major topics in this subclause.

[[t27_1]]
Table 27.1 — Topics

* <<S27Introduction, 27.1 Introduction>>
** <<S27_Name, 27.1.1 Name>>
** <<S27_Overview, 27.1.2 Overview>>
* <<S27_Concepts, 27.2 Concepts>>
** <<OverviewOfNurbs, 27.2.1 Overview of NURBS>>
** <<NURBS-relatednodes, 27.2.2 NURBS-related nodes>>
** <<CommonGeometryFieldsAndCorrectness, 27.2.3 Common geometry fields and correctness>>
** <<Tessellationstrategies, 27.2.4 Tessellation strategies>>
** <<TrimmedNURBS, 27.2.5 Trimmed NURBS>>
* <<S27_AbstractTypes, 27.3 Abstract types>>
** <<X3DNurbsControlCurveNode, 27.3.1 _X3DNurbsControlCurveNode_>>
** <<X3DNurbsSurfaceGeometryNode, 27.3.2 _X3DNurbsSurfaceGeometryNode_>>
** <<X3DParametricGeometryNode, 27.3.3 _X3DParametricGeometryNode_>>
* <<S27_NodeReference, 27.4 Node reference>>
** <<Contour2D, 27.4.1 Contour2D>>
** <<ContourPolyline2D, 27.4.2 ContourPolyline2D>>
** <<NurbsCurve, 27.4.3 NurbsCurve>>
** <<NurbsCurve2D, 27.4.4 NurbsCurve2D>>
** <<NurbsOrientationInterpolator, 27.4.5 NurbsOrientationInterpolator>>
** <<NurbsPatchSurface, 27.4.6 NurbsPatchSurface>>
** <<NurbsPositionInterpolator, 27.4.7 NurbsPositionInterpolator>>
** <<NurbsSet, 27.4.8 NurbsSet>>
** <<NurbsSurfaceInterpolator, 27.4.9 NurbsSurfaceInterpolator>>
** <<NurbsSweptSurface, 27.4.10 NurbsSweptSurface>>
** <<NurbsSwungSurface, 27.4.11 NurbsSwungSurface>>
** <<NurbsTextureCoordinate, 27.4.12 NurbsTextureCoordinate>>
** <<NurbsTrimmedSurface, 27.4.13 NurbsTrimmedSurface>>
* <<S27_SupportLevels, 27.5 Support levels>>

* <<f-NurbsCurve, Figure 27.1 — NurbsCurve>>
* <<f-NurbsPatchSurface, Figure 27.2 — NurbsPatchSurface>>
* <<f-NurbsSweptSurface, Figure 27.3 — NurbsSweptSurface>>
* <<f-NurbsSwungSurface, Figure 27.4 — NurbsSwungSurface>>
* <<f-NurbsTrimmedSurface, Figure 27.5 — NurbsTrimmedSurface>>

* <<t27_1, Table 27.1 — Topics>>
* <<t27_2, Table 27.2 — NURBS component support levels>>




[[S27_Concepts]]
=== 27.2 Concepts

[[OverviewOfNurbs]]
==== 27.2.1 Overview of NURBS

Non-uniform Rational B-Splines (NURBS) provide a convenient and
efficient manner to generate curved lines and surfaces which can be
smooth at any viewing distance. Since these surfaces are generated
parametrically, only a small amount of data need be provided for
describing complex surfaces.

[[NURBS-relatednodes]]
==== 27.2.2 NURBS-related nodes

The characteristics of a NURBS surfaces and curves are defined according
to the mathematical definitions for Non-Uniform Rational B-Spline
geometry.

There are many construction techniques including:

[loweralpha]
. special cases of NURBS surfaces such as sphere, cylinder or Bezier
surfaces;
. Extrusion/swept surfaces, constructed given a spine curve and a
cross-section curve either or both of which can be NURBS curves;
. surfaces of revolution, constructed given a circle/arc and a NURBS
cross-section curve;
. skinned surfaces constructed from a set of curves;
. Gordon surfaces interpolating two sets of curves;
. Coons patches, a bi-cubic blended surface constructed from four border
curves;
. Surfaces interpolating a set of points.

For this standard, it is assumed that creation of such surfaces is only
a construction step at authoring time and that the surface will be
represented as one of the _<<X3DParametricGeometryNode>>_ nodes for
X3D run-time delivery.

[[CommonGeometryFieldsAndCorrectness]]
==== 27.2.3 Common geometry fields and correctness

Background information on NURBS and some implementation strategies are
described in <<NURBS>>.

NURBS require input to be specified using control points, weights, knots
and the order. Each of these inputs are defined using separate fields of
the appropriate data type.

The control points and the corresponding _weight_ values are held in
separate fields. This separation also allows independent animation of
the _controlPoint_ fields using a
<<CoordinateInterpolator>> node.

All nodes that use NURBs principles use the same field names (or u/v
variations on them for the surface case). Those field names shall be
interpreted as follows:

The _order_ field defines the order of curve. From a mathematical point
of view, the curve is defined by a polynomial of the degree `+order-1+`.
The value of _order_ shall be greater than or equal to 2. An
implementation may limit order to a certain number. If it does so, then
a warning shall be generated and the surface not displayed. An
implementation shall at least support orders 2,3 and 4. The number of
control points shall be at least equal to the order of the curve. The
order defines the number of adjacent control points that influence a
given control point.

The _controlPoint_ field defines the
_<<X3DCoordinateNode>>_ instance that provides the
source of coordinates used to control the curve or surface. Depending on
the weight value and the order, this piecewise linear curve is
approximated by the resulting parametric curve. The number of control
points shall be equal to or greater than the order. A closed B-Spline
curve can be specified by repeating the limiting control points,
specifying a periodic knot vector, and setting the _closed_ field to
`TRUE`. If the last control point is not identical to the first
or there exists a non-unitary value of weight within `(order-1)`
control points of the seam, the _closed_ field is ignored.

A _weight_ value that shall be greater than zero is assigned to each
_controlPoint_. The ordering of the values is equivalent to the ordering
of the control point values. The number of values shall be identical to
the number of control points. If the length of the weight vector is 0,
the default weight 1.0 is assumed for each control point, thus defining
a non-Rational curve. If the number of weight values is less than the
number of control points, all weight values shall be ignored and a value
of 1.0 shall be used.

The _knots_ field defines the knot vector. The number of knots shall be
equal to the number of control points plus the order of the curve. The
order shall be non-decreasing. Within the knot vector there may not be
more than `+order-1+` consecutive knots of equal value. If the length of
a knot vector is 0 or not the exact number required ( _numcontrolPoint +
order_), a default uniform knot vector is computed.

[[Tessellationstrategies]]
==== 27.2.4 Tessellation strategies

Because low-level real-time rendering systems currently can handle only
planar triangles, a NURBS surface needs to be broken down ( _i.e._,
tessellated) into a set of triangles approximating the true surface.

Tessellation can be done in different coordinate spaces:

[loweralpha]
. Tessellation in object space and the internal computation of the
equivalent to an X3D <<IndexedFaceSet>>.
. Transforming the control vertices to screen space, and tessellation in
screen space

There are different methods to determine tessellation points on the
surface:

[loweralpha, start=3]
. fixed tessellation based on a absolute number of subdivisions;
. adaptive tessellation based on chord length;
. adaptive tessellation based on the angle between two triangles;
. view dependent tessellation, fine tessellation near silhouette edges.

This standard does not specify which method is used to tessellate the
surface. However, the implementation shall render the NURBS such that
the approximation produces a rendered image in which the edges of the
tessellation can not be perceived.

NOTE:  Tessellation in screen space requires the
ability to pass already transformed vertices for rendering. This
requires the application to already light the vertices (see
<<lighting_html, 17 Lighting component>>) and pass the resulting color
and specular RGB values for each vertex of a triangle.

To avoid cracks at the junction of two surfaces, tessellation values of
a whole set of surfaces can be specified in a <<NurbsSet>>.

[[TrimmedNURBS]]
==== 27.2.5 Trimmed NURBS

The trimming curve specifies a NURBS-curve that limits the NURBS surface
in order to create NURBS surfaces that contain holes or have smooth
boundaries. Trimming curves are curves in the parametric space of the
surface.

A trimming region is defined by a set of closed trimming loops in the
parameter space of a surface. When a loop is oriented counter-clockwise,
the area within the loop is retained, and the part outside is discarded.
When the loop is oriented clockwise, the area within the loop is
discarded, and the rest is retained. Loops may be nested, but a nested
loop shall be oriented oppositely from the loop that contains it. The
outermost loop shall be oriented counter-clockwise. Clockwiseness is
determined by viewing the parametric surface from the side defined by
the cross-product between the u and v axes of the parametric space.

A trimming loop consists of a connected sequence of NURBS curves and
piecewise linear curves. The last point of every curve in the sequence
shall be the same as the first point of the next curve, and the last
point of the last curve shall be the same as the first point of the
first curve. Self intersecting curves are not allowed.


=== 27.3 Abstract types

[[X3DNurbsControlCurveNode]]
==== 27.3.1 _X3DNurbsControlCurveNode_

[source,node]
----
X3DNurbsControlCurveNode : X3DNode {
  MFVec2d  [in,out] controlPoint []   (-∞,∞)
  SFNode   [in,out] metadata     NULL [X3DMetadataObject]
}
----

The _X3DNurbsControlCurveNode_ abstract node type is the base type for
all node types that provide control curve information in 2D space.

The control points are defined in 2D coordinate space and interpreted
according to the descendent node type as well as the user of this node
instance.

[[X3DNurbsSurfaceGeometryNode]]
==== 27.3.2 _X3DNurbsSurfaceGeometryNode_

[source,node]
----
X3DNurbsSurfaceGeometryNode : X3DParametricGeometryNode { 
  SFNode   [in,out] controlPoint  NULL  [X3DCoordinateNode]
  SFNode   [in,out] metadata      NULL  [X3DMetadataObject]
  SFNode   [in,out] texCoord      NULL  [X3DTextureCoordinateNode|NurbsTextureCoordinate]
  SFInt32  [in,out] uTessellation 0     (-∞,∞)
  SFInt32  [in,out] vTessellation 0     (-∞,∞)
  MFDouble [in,out] weight        []    (0,∞)
  SFBool   []       solid         TRUE
  SFBool   []       uClosed       FALSE 
  SFInt32  []       uDimension    0     [0,∞)
  MFDouble []       uKnot         []    (-∞,∞)
  SFInt32  []       uOrder        3     [2,∞)
  SFBool   []       vClosed       FALSE 
  SFInt32  []       vDimension    0     [0,∞)
  MFDouble []       vKnot         []    (-∞,∞)
  SFInt32  []       vOrder        3     [2,∞)
}
----

The X3DNurbsSurfaceGeometryNode represents the abstract geometry type
for all types of NURBS surfaces.

_uDimension_ and _vDimension_ define the number of control points in the
u and v dimensions.

_uOrder_ and _vOrder_ define the order of the surface in the u and v
dimensions.

_uKnot_ and _vKnot_ define the knot values of the surface in the u and v
dimensions.

_uClosed_ and _vClosed_ define whether or not the specific dimension is
to be evaluated as a closed surface along the u and v directions,
respectively.

_controlPoint_ defines a set of control points of dimension _uDimension_
× _vDimension_. This set of points defines a mesh where the points do
not have a uniform spacing. _uDimension_ points define a polyline in
u-direction followed by further u-polylines with the v-parameter in
ascending order. The number of control points shall be equal or greater
than the order. A closed surface shall be specified by repeating the
limiting control points and setting the _closed_ field to `TRUE`.
If the _closed_ field is set to `FALSE`, the implementation shall
not be required to smoothly blend the edges of the surface in that
dimension into a continuous surface. A closed surface in either the
u-dimension or the v-dimension shall be specified by repeating the
limiting control points for that dimension and setting the respective
_uClosed_ or _vClosed_ field to `TRUE`. If the last control point
is not identical with the first control point, the field is ignored. If
either the _uClosed_ or the _vClosed_ field is set to `FALSE`,
the implementation shall not be required to smoothly blend the edges of
the surface in that dimension into a continuous surface.

The control vertex corresponding to the control point P[i,j] on the
control grid is:

[source,listing]
----
    P[i,j].x = controlPoint[i + (j × uDimension)].x
    P[i,j].y = controlPoint[i + (j × uDimension)].y
    P[i,j].z = controlPoint[i + (j × uDimension)].z
    P[i,j].w = weight[ i + (j × uDimension)]

    where 0 ≤ i < uDimension and 
          0 ≤ j < vDimension.
----

For an implementation subdividing the surface in a equal number of
subdivision steps, tessellation values might be interpreted in the
following way:

[loweralpha]
. if a tessellation value is greater than 0, the number of tessellation
points is: 

    _tessellation+1_;
 
. if a tessellation value is smaller than 0, the number of tessellation
points is: 

    _−tessellation × (u/v)dimension)+1_;
 
. if a tessellation value is 0, the number of tessellation points is: 

    _(2 × (u/v)dimension)+1_.

For implementations doing tessellations based on chord length,
tessellation values less than zero are interpreted as the maximum chord
length deviation in pixels. Implementations doing fully automatic
tessellation may ignore the tessellation hint parameters.

_texCoord_ provides additional information on how to generate texture
coordinates. By default, texture coordinates in the unit square (or cube
for 3D coordinates) are generated automatically from the parametric
subdivision. A <<NurbsTextureCoordinate>> node
or simply a <<TextureCoordinate>> node can then be
used to compute a texture coordinate given a u/v parameter of the
_<<X3DParametricGeometryNode>>_. The
NurbsTextureCoordinate also supports non-animated surfaces to specify a
"chord length"-based texture coordinate parametrization.

The _solid_ field determines whether the surface is visible when viewed
from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> 
provides a complete description of the _solid_ field. When
__solid__=`#TRUE`# is used, the surface shall be visible only
from the side that appears ccw (counter-clockwise) on the screen,
assuming a surface's quads would be rendered in this order:

[source,listing]
----
point(u  , v );
point(u-1, v );
point(u-1, v-1);
point(u  , v-1);
----

where u is the parameter generating successive points along the u
dimension, and v is the parameter generating successive points along the
v dimension.

[[X3DParametricGeometryNode]]
==== 27.3.3 _X3DParametricGeometryNode_

[source,node]
----
X3DParametricGeometryNode : X3DGeometryNode {
  SFNode [in,out] metadata NULL  [X3DMetadataObject]
}
----

The _X3DParametricGeometryNode_ abstract node type is the base type for
all geometry node types that are created parametrically and use control
points to describe the final shape of the surface. How the control
points are described and interpreted shall be a property of the
individual node type.


=== 27.4 Node reference

[[Contour2D]]
==== 27.4.1 Contour2D

[source,node]
----
Contour2D : X3DNode { 
  MFNode [in]     addChildren         [NurbsCurve2D|ContourPolyline2D]
  MFNode [in]     removeChildren      [NurbsCurve2D|ContourPolyline2D]
  MFNode [in,out] children       []   [NurbsCurve2D|ContourPolyline2D]
  SFNode [in,out] metadata       NULL [X3DMetadataObject]
}
----

The Contour2D node groups a set of curve segments to a composite
contour. The children shall form a closed loop with the first point of
the first child repeated as the last point of the last child, and the
last point of a segment repeated as the first point of the consecutive
one. The segments shall be defined by concrete nodes that implement the
_<<X3DNurbsControlCurveNode>>_ abstract type
nodes, and shall be enumerated in the child field in consecutive order
according to the topology of the contour.

The 2D coordinates used by the node shall be interpreted to lie in the
(u, v) coordinate space defined by the NURBS surface.

[[ContourPolyline2D]]
==== 27.4.2 ContourPolyline2D

[source,node]
----
ContourPolyline2D : X3DNurbsControlCurveNode {
  SFNode  [in,out] metadata     NULL [X3DMetadataObject]
  MFVec2d [in,out] controlPoint []   (-∞, ∞)
}
----

The ContourPolyline2D node defines a piecewise linear curve segment as a
part of a trimming contour in the u,v domain of a surface.

The _controlPoint_ field specifies the end points of each segment of the
piecewise linear curve.

ContourPolyline2D nodes are used as children of the
<<Contour2D>> group.

[[NurbsCurve]]
==== 27.4.3 NurbsCurve

[source,node]
----
NurbsCurve : X3DParametricGeometryNode {
  SFNode   [in,out] controlPoint NULL  [X3DCoordinateNode]
  SFNode   [in,out] metadata     NULL  [X3DMetadataObject]
  SFInt32  [in,out] tessellation 0     (-∞,∞)
  MFDouble [in,out] weight       []    (0,∞)
  SFBool   []       closed       FALSE 
  MFDouble []       knot         []    (-∞,∞)
  SFInt32  []       order        3     [2,∞)
}
----

The NurbsCurve node is a geometry node defining a parametric curve in 3D
space (see <<f-NurbsCurve, Figure 27.1>>)

The _tessellation_ field gives a hint to the curve tessellator by
setting an absolute number of subdivision steps. These values shall be
greater than or equal to the _Order_ field. A value of 0 indicates that
the X3D browser choose a suitable tessellation. Interpretation of values
below 0 is implementation dependent.

For an implementation subdividing the curve into an equal number of
subdivision steps, tessellation values are interpreted as follows:

[loweralpha]
. if a tessellation value is greater than 0, the number of tessellation
points is: 

    _tessellation+1_;
 
. if a tessellation value is smaller than 0, the number of tessellation
points is: 

    _−tessellation × (number of control points)+1_;
 
. if a tessellation value is 0, the number of tessellation points is: 

    _(2 × (number of control points)+1_.

For implementations doing tessellations based on chord length,
tessellation values less than zero are interpreted as the maximum chord
length deviation in pixels. Implementations doing fully automatic
tessellation may ignore the tessellation hint parameters.

[[f-NurbsCurve]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/NurbsCurve.png[NurbsCurve,width=600,height=579]

Figure 27.1 — NurbsCurve

[[NurbsCurve2D]]
==== 27.4.4 NurbsCurve2D

[source,node]
----
NurbsCurve2D : X3DNurbsControlCurveNode {
  MFVec2d  [in,out] controlPoint []    (-∞,∞)
  SFNode   [in,out] metadata     NULL  [X3DMetadataObject]
  SFInt32  [in,out] tessellation 0     (-∞,∞)
  MFDouble [in,out] weight       []    (0,∞)
  SFBool   []       closed       FALSE 
  MFDouble []       knot         []    (-∞,∞)
  SFInt32  []       order        3     [2,∞)
}
----

The NurbsCurve2D node defines a trimming segment that is part of a
trimming contour in the u,v domain of the surface.

NurbsCurve2D nodes are used as children of the
<<Contour2D>> group.

[[NurbsOrientationInterpolator]]
==== 27.4.5 NurbsOrientationInterpolator

[source,node]
----
NurbsOrientationInterpolator : X3DChildNode { 
  SFFloat    [in]     set_fraction       (-∞,∞)
  SFNode     [in,out] controlPoint  NULL [X3DCoordinateNode]
  MFDouble   [in,out] knot          []   (-∞,∞)  
  SFNode     [in,out] metadata      NULL [X3DMetadataObject]
  SFInt32    [in,out] order         3    (2,∞)
  MFDouble   [in,out] weight        []   (0,∞)
  SFRotation [out]    value_changed
}
----

NurbsOrientationInterpolator interpolates the orientation along a 3D
NURBS curve using the same fields as described for the
<<NurbsCurve>> node.

The field _set_fraction_ has the same meaning as in the
<<NurbsPositionInterpolator>>.

Sending a _set_fraction_ input computes a 3D position on the curve, from
which a tangent to the curve at that position is calculated. The tangent
direction shall be oriented to point along the curve from the first knot
value towards the last value. This orientation value shall be then sent
by _value_changed_. Given the same definition for control points, knots,
order and weights, and the same value for _set_fraction_ the orientation
interpolator shall generate the orientation of the tangent of the curve
at the same position as the NurbsPositionInterpolator.

[[NurbsPatchSurface]]
==== 27.4.6 NurbsPatchSurface

[source,node]
----
NurbsPatchSurface : X3DNurbsSurfaceGeometryNode { 
  SFNode   [in,out] controlPoint  NULL  [X3DCoordinateNode]
  SFNode   [in,out] metadata      NULL  [X3DMetadataObject]
  SFNode   [in,out] texCoord      NULL  [X3DTextureCoordinateNode|NurbsTextureCoordinate]
  SFInt32  [in,out] uTessellation 0     (-∞,∞)
  SFInt32  [in,out] vTessellation 0     (-∞,∞)
  MFDouble [in,out] weight        []    (0,∞)
  SFBool   []       solid         TRUE
  SFBool   []       uClosed       FALSE 
  SFInt32  []       uDimension    0     [0,∞)
  MFDouble []       uKnot         []    (-∞,∞)
  SFInt32  []       uOrder        3     [2,∞)
  SFBool   []       vClosed       FALSE 
  SFInt32  []       vDimension    0     [0,∞)
  MFDouble []       vKnot         []    (-∞,∞)
  SFInt32  []       vOrder        3     [2,∞)
}
----

The NurbsPatchSurface node is a contiguous NURBS surface patch.
<<f-NurbsPatchSurface, Figure 27.2>> shows an example of a
NurbsPatchSurface node:

[[f-NurbsPatchSurface]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/NurbsPatchSurface.png[NurbsPatchSurface,width=604,height=481]

Figure 27.2 — NurbsPatchSurface

[[NurbsPositionInterpolator]]
==== 27.4.7 NurbsPositionInterpolator

[source,node]
----
NurbsPositionInterpolator : X3DChildNode { 
  SFFloat  [in]     set_fraction       (-∞,∞)
  SFNode   [in,out] controlPoint  NULL [X3DCoordinateNode]
  MFDouble [in,out] knot          []   (-∞,∞)  
  SFNode   [in,out] metadata      NULL [X3DMetadataObject]
  SFInt32  [in,out] order         3    (2,∞)
  MFDouble [in,out] weight        []   (0,∞)
  SFVec3f  [out]    value_changed
}
----

NurbsPositionInterpolator interpolates the position along a 3D NURBS
curve as specified in <<NurbsCurve, 27.4.3 NurbsCurve>>.

The fields _set_fraction_ and _value_changed_ have the same meaning as
specified in <<PositionInterpolator, 19.4.6 PositionInterpolator>>.

Sending a _set_fraction_ input computes a 3D position on the curve,
which is sent by _value_changed_. The _set_fraction_ value is used as
the input value for the tessellation function. Thereby, the _knot_
corresponds to the _key_ field of a conventional interpolator node;
_i.e._, if the _set_fraction_ value is within [0,1] and the knot vector
within [0,2], only half of the curve is computed.

[[NurbsSet]]
=== *27.4.8 NurbsSet*

[source,node]
----
NurbsSet : X3DChildNode, X3DBoundedObject {
  MFNode  [in]     addGeometry                [X3DParametricGeometryNode]
  MFNode  [in]     removeGeometry             [X3DParametricGeometryNode]
  SFBool  [in,out] bboxDisplay       TRUE
  MFNode  [in,out] geometry          []       [X3DParametricGeometryNode]
  SFNode  [in,out] metadata          NULL     [X3DMetadataObject]
  SFFloat [in,out] tessellationScale 1.0      (0,∞)
  SFBool  [in,out] visible           TRUE
  SFVec3f []       bboxCenter        0 0 0    (-∞,∞)
  SFVec3f []       bboxSize          -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The NurbsSet node groups a set of Nurbs surface nodes to a common group
for rendering purposes only. This informs the X3D browser that the set
of Nurbs surfaces shall be treated as a unit during tessellation to
enforce tessellation continuity along borders. The _tessellationScale_
parameter is scaling the tessellation values in contained Nurbs surface
nodes. A set of Nurbs surfaces that use a matching set of _controlPoint_
along the borders shall result in a common tessellation stepping.

The geometry represented in the children of this node shall not be
directly rendered. It is an informational node only. Surfaces not
represented elsewhere in the transformation hierarchy shall not be
rendered.

The bounds information is provided for optimization purposes only. A X3D
browser may choose to use this information about when to apply trimming
or smooth tessellation between patches based on the bounds information
(EXAMPLE  only smooth when the viewer is within the bounds).

[[NurbsSurfaceInterpolator]]
==== 27.4.9 NurbsSurfaceInterpolator

[source,node]
----
NurbsSurfaceInterpolator : X3DChildNode { 
  SFVec2f  [in]     set_fraction          (-∞,∞)
  SFNode   [in,out] controlPoint     NULL [X3DCoordinateNode]
  SFNode   [in,out] metadata         NULL [X3DMetadataObject]
  MFDouble [in,out] weight           []   (0,∞)
  SFVec3f  [out]    position_changed
  SFVec3f  [out]    normal_changed
  SFInt32  []       uDimension       0    [0,∞)
  MFDouble []       uKnot            []   (-∞,∞)
  SFInt32  []       uOrder           3    [2,∞)
  SFInt32  []       vDimension       0    [0,∞)
  MFDouble []       vKnot            []   (-∞,∞)
  SFInt32  []       vOrder           3    [2,∞)
}
----

NurbsSurfaceInterpolator interpolates over a 3D NURBS surface as
specified in <<NurbsPatchSurface, 27.4.6 NurbsPatchSurface>>.

Sending a _set_fraction_ input computes a 3D position and normal on the
surface for the given u and v coordinates. The computed position on the
surface shall be sent by _position_changed_, and the computed normal
shall be sent by _normal_changed_.

Normals generated by _normal_changed_ events shall point from the ccw
(counter-clockwise) side of the surface, assuming the order of surface
quads is as specified for _X3DNurbsSurfaceGeometryNode_.

[[NurbsSweptSurface]]
==== 27.4.10 NurbsSweptSurface

[source,node]
----
NurbsSweptSurface : X3DParametricGeometryNode { 
  SFNode [in,out] crossSectionCurve NULL [X3DNurbsControlCurveNode]
  SFNode [in,out] metadata          NULL [X3DMetadataObject]
  SFNode [in,out] trajectoryCurve   NULL [NurbsCurve]
  SFBool []       ccw               TRUE
  SFBool []       solid             TRUE
}
----

NurbsSweptSurface describes a generalized surface that defines a path in
3D space and constant cross section that may be 2D or 3D of the path as
illustrated in <<f-NurbsSweptSurface, Figure 27.3>>. Conceptually it
is the NURBS equivalent of the <<Extrusion>> node (see
<<Extrusion, 13.3.5 Extrusion>>) but permits the use of non-closed
cross sections.

[[f-NurbsSweptSurface]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/NurbsSweptSurface.png[NurbsSweptSurface,width=466,height=358]

Figure 27.3 — NurbsSweptSurface

The _crossSectionCurve_ is a 2D curve in the yz-plane that describes the
cross-sectional shape of the object.

The _trajectoryCurve_ is a 3D curve that describes the path over which
to trace the cross-section.

The _solid_ and _ccw_ fields are defined as specified in
<<Commongeometryfields, 11.2.3 Common geometry fields>>. To have the
polygons' normals facing away from the axis, the trajectory curve should
be oriented so that it is moving counterclockwise when looking down the
−Y axis, thus defining a concept of "inside" and "outside".

With _solid_ `TRUE` and _ccw_ `TRUE`, the cylinder is
visible from the outside. Changing _ccw_ to `FALSE` makes it
visible from the inside.

[[NurbsSwungSurface]]
==== 27.4.11 NurbsSwungSurface

[source,node]
----
NurbsSwungSurface : X3DParametricGeometryNode { 
  SFNode [in,out] metadata          NULL [X3DMetadataObject]
  SFNode [in,out] profileCurve      NULL [X3DNurbsControlCurveNode]
  SFNode [in,out] trajectoryCurve   NULL [X3DNurbsControlCurveNode]
  SFBool []       ccw               TRUE
  SFBool []       solid             TRUE
}
----

NurbsSwungSurface describes a generalized surface that defines a path
and constant cross section of the path as illustrated in
<<f-NurbsSwungSurface, Figure 27.4>>.

[[f-NurbsSwungSurface]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/NurbsSwungSurface.png[NurbsSwungSurface,width=389,height=343]

Figure 27.4 — NurbsSwungSurface

The _profileCurve_ is a 2D curve in the yz-plane that describes the
cross-sectional shape of the object.

The _trajectoryCurve_ is a 2D curve in the xz-plane that describes the
path over which to trace the cross-section.

The _solid_ and _ccw_ fields are defined in
<<Commongeometryfields, 11.2.3 Common geometry fields>>. To have the
normals of the polygons facing away from the axis, the trajectory curve
should be oriented so that it is moving counterclockwise when looking
down the −Y axis, thus defining a concept of "inside" and "outside".

With _solid_ `TRUE` and _ccw_ `TRUE`, the cylinder is
visible from the outside. Changing _ccw_ to `FALSE` specifies
that the cylinder is visible from the inside.

[[NurbsTextureCoordinate]]
==== 27.4.12 NurbsTextureCoordinate

[source,node]
----
NurbsTextureCoordinate : X3DNode { 
  MFVec2f  [in,out] controlPoint []   (-∞,∞)
  SFNode   [in,out] metadata     NULL [X3DMetadataObject]
  MFDouble [in,out] weight       []   (0,∞)
  SFInt32  []       uDimension   0    [0,∞)
  MFDouble []       uKnot        []   (-∞,∞)
  SFInt32  []       uOrder       3    [2,∞)
  SFInt32  []       vDimension   0    [0,∞)
  MFDouble []       vKnot        []   (-∞,∞)
  SFInt32  []       vOrder       3    [2,∞)
}
----

The NurbsTextureCoordinate node is a NURBS surface existing in the
parametric domain of its surface host specifying the mapping of the
texture onto the surface.

The parameters are as specified in
<<X3DNurbsSurfaceGeometryNode>> with the
exception that the control points are specified in (u, v) coordinates.

The tessellation process generates 2D texture coordinates. If a
NurbsTextureCoordinate is undefined, texture coordinates are computed by
the client on the basis of parametric step size. Conventional vertex
parameters do not apply on NURBS surfaces because triangles are only
available after polygonalization. However, the conventional texture
transform may be used.

NurbsTextureCoordinate nodes are accessed through the _texCoord_ field
of a node derived from _<<X3DNurbsSurfaceGeometryNode>>_. A
NurbsTextureCoordinate node separately encountered is ignored.

[[NurbsTrimmedSurface]]
==== 27.4.13 NurbsTrimmedSurface

[source,node]
----
NurbsTrimmedSurface : X3DNurbsSurfaceGeometryNode { 
  MFNode   [in]     addTrimmingContour          [Contour2D]
  MFNode   [in]     removeTrimmingContour       [Contour2D]
  SFNode   [in,out] controlPoint          NULL  [X3DCoordinateNode]
  SFNode   [in,out] metadata              NULL  [X3DMetadataObject]
  SFNode   [in,out] texCoord              NULL  [X3DTextureCoordinateNode|NurbsTextureCoordinate]
  MFNode   [in,out] trimmingContour       []    [Contour2D]
  SFInt32  [in,out] uTessellation         0     (-∞,∞)
  SFInt32  [in,out] vTessellation         0     (-∞,∞)
  MFDouble [in,out] weight                []    (0,∞)
  SFBool   []       solid                 TRUE
  SFBool   []       uClosed               FALSE 
  SFInt32  []       uDimension            0     [0,∞)
  MFDouble []       uKnot                 []    (-∞,∞)
  SFInt32  []       uOrder                3     [2,∞)
  SFBool   []       vClosed               FALSE 
  SFInt32  []       vDimension            0     [0,∞)
  MFDouble []       vKnot                 []    (-∞,∞)
  SFInt32  []       vOrder                3     [2,∞)
}
----

The NurbsTrimmedSurface node defines a NURBS surface (see
<<NurbsPatchSurface, 27.4.6 NurbsPatchSurface>>) that is trimmed by a
set of trimming loops. The outermost trimming loop shall be defined in a
counterclockwise direction. An example of a NurbsTrimmedSurface node is
shown in <<f-NurbsTrimmedSurface, Figure 27.5>>.

[[f-NurbsTrimmedSurface]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/NurbsTrimmedSurface.png[NurbsTrimmedSurface,width=580,height=534]

Figure 27.5 — NurbsTrimmedSurface

The _trimmingContour_ field, if specified, shall contain a set of
<<Contour2D>> (see <<Contour2D, 27.4.1 Contour2D>>)
nodes. Trimming loops shall be processed as described for the Contour2D
node. If no trimming contours are defined, the NurbsTrimmedSurface node
shall have the same semantics as the
<<NurbsPatchSurface>> node.

[[S27.5_SupportLevels]]
=== 27.5 Support levels

The Non-uniform Rational B-spline (NURBS) component provides four levels
of support as specified in <<t27_2, Table 27.2>>. Level 1
provides basic NURBS support. Level 2 adds the ability to ensure
controlled tessellation along the boundaries between two NURBS surfaces.
Level 3 adds specialized NURBS nodes. Level 4 adds trimmed NURBS
surfaces.

[[t27_2]]
*Table 27.2 — NURBS component support levels*

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Interpolator 1 +
Texturing 1 +
Rendering 1 | |
| | |_X3DNurbsControlCurveNode_ (abstract) |n/a
|  |  |_X3DNurbsSurfaceGeometryNode_ (abstract) |n/a
|  |  |_X3DParametricGeometryNode_ (abstract) |n/a
| | |NurbsCurve                   |All fields fully supported.
| | |NurbsOrientationInterpolator |All fields fully supported.
| | |NurbsPatchSurface            |All fields fully supported.
| | |NurbsPositionInterpolator    |All fields fully supported.
| | |NurbsSurfaceInterpolator     |All fields fully supported.
| | |NurbsTextureCoordinate       |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Interpolator 1 +
Texturing 1 | |
| | |All Level 1 NURBS nodes |As supported in Level 1.
|  |  |NurbsSet |All fields fully supported.
|*3* |Core 1 +
Grouping 1 +
Shape 1 +
Interpolator 1 +
Texturing 1 | |
| | |All Level 2 NURBS nodes |As supported in Level 2.
| | |NurbsCurve2D      |All fields fully supported.
| | |ContourPolyline2D |All fields fully supported.
| | |NurbsSweptSurface |All fields fully supported.
| | |NurbsSwungSurface |All fields fully supported.
|*4* |Core 1 +
Grouping 1 +
Shape 1 +
Interpolator 1 +
Texturing 1 | |
| | |All Level 3 NURBS nodes |As supported in Level 3.
| | |Contour2D               |All fields fully supported.
| | |NurbsTrimmedSurface     |All fields fully supported.
|===

[[dis_html]]
== 28 Distributed interactive simulation (DIS) component


[[S28_Introduction]]
=== 28.1 Introduction

[[S28_Name]]
==== 28.1.1 Name

The name of this component is "DIS". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S28_Overview]]
==== 28.1.2 Overview

This clause describes the Distributed Interactive Simulation (DIS)
component of this document. The Distributed Interactive Simulation (DIS)
component provides networked interoperability with the IEEE DIS protocol
(see <<IEEE1278>> and <<SISO>>) for sharing
state and conducting real-time platform-level simulations across
multiple host computers. <<t28_1, Table 28.1>> provides links to
the major topics in this clause.

[[t28_1]]
Table 28.1 — Topics

* <<S28Introduction, 28.1 Introduction>>
** <<S28_Name, 28.1.1 Name>>
** <<S28_Overview, 28.1.2 Overview>>
* <<S28_Concepts, 28.2 Concepts>>
** <<OverviewDIS, 28.2.1 Overview of DIS>>
** <<Networkcommunications, 28.2.2 Network communications>>
** <<CommonDISfields, 28.2.3 Common DIS fields>>
* <<S28_NodeReference, 28.3 Node reference>>
** <<DISEntityManager, 28.3.1 DISEntityManager>>
** <<DISEntityTypeMapping, 28.3.2 DISEntityTypeMapping>>
** <<EspduTransform, 28.3.3 EspduTransform>>
** <<ReceiverPdu, 28.3.4 ReceiverPdu>>
** <<SignalPdu, 28.3.5 SignalPdu>>
** <<TransmitterPdu, 28.3.6 TransmitterPdu>>
* <<S28_SupportLevels, 28.4 Support levels>>

* <<t28_1, Table 28.1 — Topics>>
* <<t28_2, Table 28.2 — DIS component support levels>>




[[S28_Concepts]]
=== 28.2 Concepts

[[OverviewDIS]]
==== 28.2.1 Overview of DIS

IEEE 1278 (see <<IEEE1278>> and <<SISO>>) is an
IEEE communications standard for physically based distributed
simulations. Known by the name Distributed Interactive Simulation (DIS),
the standard defines the binary layout of a series of messages used to
transmit simulation information. Often used by military applications,
IEEE 1278 covers a wide range of data, including entity location,
velocity, and orientation, and more obscure features such as electronic
warfare and supply logistics. In addition to its original focus on
military simulations, DIS is also used in civilian applications.

The DIS component consists of the following X3D nodes:

* <<DISEntityManager>>,
* <<DISEntityTypeMapping>>,
* <<EspduTransform>>,
* <<ReceiverPdu>>,
* <<SignalPdu>>, and
* <<TransmitterPdu>>.

Together, these nodes provide the means to send and receive
DIS-compliant messages, called Protocol Data Units (PDUs), across the
network. Together these nodes support seven DIS PDU message types:
Collision, Detonate, Entity State, Fire, Receiver, Signal and
Transmitter. Numerous other DIS PDUs are defined by the DIS protocol,
but corresponding X3D mappings are not defined.

[[Networkcommunications]]
==== 28.2.2 Network communications

DIS messages are typically transmitted on User Datagram Protocol (UDP)
(see <<RFC768, 2.[RFC768>>]) sockets). Multicast, unicast or broadcast
transport mechanisms may be used for network communications. Each of the
X3D DIS nodes communicates via a UDP socket, usually multicast-enabled,
and uses it to read and/or write DIS messages. These messages can be
used to communicate and to modify both position and orientation of
virtual entities in the X3D scene among multiple hosts across the
network. Each DIS implementation is responsible for managing sockets.
New entities are registered by the DIS node to send/receive network
updates. "Entities" are a high-level abstraction; in the case of a
position update, the actual X3D scene-graph object modified may be a
<<Transform>> node (as for
<<EspduTransform>>), and the geometry for an animated
entity is contained in the corresponding children.

[[CommonDISfields]]
==== 28.2.3 Common DIS fields

The DIS nodes have a number of descriptive fields in common relating to
the desired behavior of the DIS node. Common fields include message
header and content information conforming to the DIS standard, network
status, and configuration data needed to establish or modify network
communications. The semantics of field values and syntax of enumeration
values are strictly defined by the IEEE 1278 series and corresponding
SISO standards (see <<IEEE1278>> and <<SISO>>).

Since nodes in the DIS component can receive data from the network,
these nodes are also sensors. Thus, these nodes implement the
X3DNetworkSensorNode interface and include _description_, _enabled_ and
_isActive_ fields.

Common fields relating to description of the desired behavior of the DIS
node are: _isActive_, _timestamp_, _networkMode_, _isStandAlone_,
_isNetworkReader_, _isNetworkWriter_, _readInterval_, and
_writeInterval_.

The _isActive_ field indicates if the node has received a DIS message
(when output as `TRUE`) or not (when output as `FALSE`).
Since DIS entities can be considered inactive after some period of time
(five seconds is specified as the default in <<IEEE1278, IEEE 1278>>)
either event may be received by listening nodes. An implementation may
use a different value.

The _timestamp_ field provides the time (SFTime) at which the DIS
message arrived, referenced to local system time.

The _networkMode_ field indicates if the X3D DIS node is operating in
one of three distinct ways: independently from the network, as a sender
writing updates, or as a receiver reading updates.

* _networkMode_ `standAlone` only connects dynamic behavior via
local ROUTEs and does not send/receive PDUs to/from the network.
* _networkMode_ `networkReader` reads messages at _readInterval_
seconds from the network, which can modify fields in the node upon
receipt. In this mode, the entity geometry in the DIS node ( _e.g._,
<<EspduTransform>>) acts as a remote copy of the
entity that sent the PDUs.
* _networkMode_ `networkWriter` sends messages at _writeInterval_
seconds to the network. In this mode, the entity geometry in the DIS
node ( _e.g._, EspduTransform) acts as the master copy of the entity
originating state updates.

Fields _isStandAlone_, _isNetworkReader_, and _isNetworkWriter_ are
respectively sent as appropriate `TRUE` or `FALSE` events
during initialization of the DIS node and whenever _networkMode_ is
changed. These fields match the state of _networkMode_. One and only one
of these three fields can be `TRUE` at any given time.

The _readInterval_ field is a duration of time in seconds between
checking for receipt of DIS messages. Setting the _readInterval_ field
to zero disables the reading of DIS messages. The _writeInterval_ is a
duration of time in seconds between message transmissions by the node.
Setting the _writeInterval_ field to zero disables the transmission of
DIS messages by the node.

Common fields relating to standard identification of DIS entities are:
_siteID_, _applicationID_, and _entityID_.

The _siteID_ and _applicationID_ fields are used to create the DIS PDU
Simulation Address record. The intent for each simulation exercise is
for each DIS site to be assigned a unique identifier, and each
simulation application at a DIS site assigned an application identifier
unique within that site. Both fields are 16-bit, unsigned numbers. The
_entityID_ field further identifies the DIS entity that is the subject
of the particular PDU (EXAMPLE  an Entity State PDU to update
the location and orientation of a particular simulation entity). The
_entityID_ is an unsigned, 16-bit number.

Each entity in a DIS application is assigned a triplet identifier (
_siteID_, _applicationID_ and _entityID_ fields) that is unique across
all entities in that application and in that particular distributed
exercise. The entity identifier triplet is valid for the duration of the
exercise. One and only one "owner" of the entity is appropriate with
_networkMode_ `+networkWriter+` sender for each entity, while
corresponding nodes can match parameters with _networkMode_
`+networkReader+` to be listeners for that same distributed entity.

Common fields relating to DIS network communications are: _address_,
_port_, _multicastRelayHost_, _multicastRelayPort_, _rtpHeaderExpected_
and _rtpHeaderHeard_.

The _address_ field identifies the multicast address for the message
transmission (EXAMPLE  "224.2.181.145" or "localhost"). The
_port_ field identifies the multicast port (EXAMPLE  62040)
for sending or receiving DIS messages.

Fields _multicastRelayHost_, _multicastRelayPort_, _rtpHeaderExpected_
and _rtpHeaderHeard_ provide networking extensions to the IEEE DIS
protocol (see <<IEEE1278>>) intended to make DIS more
compatible with Internet conventions for unicast and multicast routing
over wide-area networks (WANs). If wide-area multicast is needed but not
available locally, the _multicastRelayHost_ and _multicastRelayPort_
fields are provided as a fallback server address and associated port,
used for creating a unicast tunnel connection to a multicast-connected
relay server. Field _rtpHeaderExpected_ indicates that the Real Time
Protocol (RTP, see <<RFC3550, 2.[RFC3550>>]) header is expected to be
prepended to the DIS PDU message to be sent or received by the node
(when the field is set to `TRUE`. Field _rtpHeaderHeard_
indicates that the RTP header has been prepended to the incoming DIS
message.

The _geoSystem_ field is used to define the spatial reference frame and
is described in <<Specifyingaspatialreference, 25.2.3 Specifying a spatial reference frame>>. +
 +
The geometry of the nodes in children is to be specified in base length
units in X3D coordinates relative to the location specified by the
_geoCoords_ field. The geoCoords field should be provided in the format
described in <<Specifyingaspatialreference, 25.2.3 Specifying a spatial reference frame>>. +
 +
The _geoCoords_ field can be used to dynamically update the geospatial
location of the model; for example an event might be sent from a
GeoPositionInterpolator node.


=== 28.3 Node reference

[[DISEntityManager]]
==== 28.3.1 DISEntityManager

[source,node]
----
DISEntityManager : X3DChildNode {
  SFString [in,out] address         "localhost"
  SFInt32  [in,out] applicationID   0           [0..65535]
  MFNode   [in,out] children        []          [DISEntityTypeMapping]
  SFNode   [in,out] metadata        NULL        [X3DMetadataObject]
  SFInt32  [in,out] port            0           [0..65535]
  SFInt32  [in,out] siteID          0           [0..65535]
  MFNode   [out]    addedEntities               [EspduTransform]
  MFNode   [out]    removedEntities             [EspduTransform]
}
----

DISEntityManager notifies a scene when new DIS ESPDU entities arrive or
current entities leave. DISEntityManager may contain any number of
DISEntityTypeMapping nodes that provide a best-match X3D model to
incoming entity type values. For each new DIS entity, DISEntityManager
thus produces a new EspduTransform node that contains a corresponding
X3D model.

The _children_ field provides a mechanism for automatically creating an
X3D model for a new entity arriving. If a new entity matches the given
DISEntityManager node, an instance of the provided URL is created using
an Inline node and added as a child to the
<<EspduTransform>> specified in the _addedEntities_
field. See <<DISEntityTypeMapping, 28.3.2 DISEntityTypeMapping>> for
details on matching DIS parameters to URLs.

NOTE:  The original name for the DISEntityManager _children_
field in X3D version 3 is _mapping_.

The _addedEntities_ field sends an MFNode output event for any new
entities added during the last network-update time interval. These will
be new EspduTransform nodes.

The _removedEntities_ field sends an MFNode output event for any
entities removed during the last network-update time interval, either
from a network-heartbeat timeout or from an explicit RemoveEntityPDU
action. This node array will contain references to each appropriate
EspduTransform node that is no longer active.

[[DISEntityTypeMapping]]
==== 28.3.2 DISEntityTypeMapping

[source,node]
----
DISEntityTypeMapping : X3DInfoNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0    [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0 [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL   [X3DMetadataObject]
  MFString [in,out] url                  []     [URI]
  SFInt32  []       category             0      [0..255]
  SFInt32  []       country              0      [0..65535]
  SFInt32  []       domain               0      [0..255]
  SFInt32  []       extra                0      [0..255]
  SFInt32  []       kind                 0      [0..255]
  SFInt32  []       specific             0      [0..255]
  SFInt32  []       subcategory          0      [0..255]
}
----

A DISEntityTypeMapping node provides a mapping from DIS Entity type
information to an X3D model. This model provides a visual and behavioral
representation of the entity for usage in X3D simulations. The mappings
are done by selecting the most specific record that fits the entity. A
value of 0 is considered a wildcard. The fields are checked in the
following order: _kind_, _domain_, _country_, _category_, _subcategory_,
_specific_, _extra_. All fields after the first zero encountered shall
be zero as well.

The fields are checked in the following order: kind, domain, country,
category, subcategory, specific, extra.

EXAMPLE  Given an entity whose entity type record was: kind=1, domain=2,
country=3, category=4, subcategory=5, specific=6, extra=7. If the
mapping field of the DISEntityManager contained these nodes:

[source]
....
   DISEntityTypeMapping {
      domain 1
      kind 2
      country 3
      url ["model-a.x3d"]
   }
   DISEntityTypeMapping {
      domain 1
      kind 2
      country 3
      category 4
      url ["model-b.x3d"]
   }
....

Then, an entity using the second node with a url of "model-b.x3d" is
used as its the most specific mapping.

[[EspduTransform]]
==== 28.3.3 EspduTransform

[source,node]
----
EspduTransform : X3DGroupingNode,  X3DNetworkSensorNode { 
  MFNode     [in]     addChildren
  MFNode     [in]     removeChildren
  SFFloat    [in]     set_articulationParameterValue0                         
  SFFloat    [in]     set_articulationParameterValue1                         
  SFFloat    [in]     set_articulationParameterValue2                         
  SFFloat    [in]     set_articulationParameterValue3                         
  SFFloat    [in]     set_articulationParameterValue4                         
  SFFloat    [in]     set_articulationParameterValue5                         
  SFFloat    [in]     set_articulationParameterValue6                         
  SFFloat    [in]     set_articulationParameterValue7                         
  SFString   [in,out] address                                    "localhost"
  SFInt32    [in,out] applicationID                              0            [0..65535]
  MFFloat    [in,out] articulationParameterArray                 []           (-∞,∞)
  SFInt32    [in,out] articulationParameterCount                 0            [0..78]
  MFInt32    [in,out] articulationParameterChangeIndicatorArray  []           [0..255]
  MFInt32    [in,out] articulationParameterDesignatorArray       []           [0..255]
  MFInt32    [in,out] articulationParameterIdPartAttachedToArray []           [0..65535]
  MFInt32    [in,out] articulationParameterTypeArray             []     
  SFBool     [in,out] bboxDisplay                                FALSE
  SFVec3f    [in,out] center                                     0 0 0        (-∞,∞)
  MFNode     [in,out] children                                   []           [X3DChildNode]
  SFInt32    [in,out] collisionType                              0            [0..255]
  SFInt32    [in,out] deadReckoning                              0            [0..255]
  SFString   [in,out] description                                ""
  SFVec3f    [in,out] detonationLocation                         0 0 0        (-∞,∞)
  SFVec3f    [in,out] detonationRelativeLocation                 0 0 0        (-∞,∞)
  SFInt32    [in,out] detonationResult                           0            [0..255]
  SFBool     [in,out] enabled                                    TRUE
  SFInt32    [in,out] entityCategory                             0            [0..255]
  SFInt32    [in,out] entityCountry                              0            [0..65535]
  SFInt32    [in,out] entityDomain                               0            [0..255]
  SFInt32    [in,out] entityExtra                                0            [0..255]
  SFInt32    [in,out] entityID                                   0            [0..65535]
  SFInt32    [in,out] entityKind                                 0            [0..255]
  SFInt32    [in,out] entitySpecific                             0            [0..255]
  SFInt32    [in,out] entitySubcategory                          0            [0..255]
  SFInt32    [in,out] eventApplicationID                         0            [0..65535]
  SFInt32    [in,out] eventEntityID                              0            [0..65535]
  SFInt32    [in,out] eventNumber                                0            [0..65355]
  SFInt32    [in,out] eventSiteID                                0            [0..65535]
  SFBool     [in,out] fired1                                     FALSE
  SFBool     [in,out] fired2                                     FALSE
  SFInt32    [in,out] fireMissionIndex                           0            [0..65535]
  SFFloat    [in,out] firingRange                                0.0          (0,∞)
  SFInt32    [in,out] firingRate                                 0            [0..65535]
  SFInt32    [in,out] forceID                                    0            [0..255]
  SFInt32    [in,out] fuse                                       0            [0..65535]
  SFVec3d    [in,out] geoCoords                                  0 0 0        (-∞,∞)
  SFVec3f    [in,out] linearAcceleration                         0 0 0        (-∞,∞)
  SFVec3f    [in,out] linearVelocity                             0 0 0        (-∞,∞)
  SFString   [in,out] marking                                    ""
  SFNode     [in,out] metadata                                   NULL         [X3DMetadataObject]
  SFString   [in,out] multicastRelayHost                         ""
  SFInt32    [in,out] multicastRelayPort                         0            [0..65535]
  SFInt32    [in,out] munitionApplicationID                      0            [0..65535]
  SFVec3f    [in,out] munitionEndPoint                           0 0 0        (-∞,∞)
  SFInt32    [in,out] munitionEntityID                           0            [0..65535]
  SFInt32    [in,out] munitionQuantity                           0            [0..65535]
  SFInt32    [in,out] munitionSiteID                             0            [0..65535]
  SFVec3f    [in,out] munitionStartPoint                         0 0 0        (-∞,∞)
  SFString   [in,out] networkMode                                "standAlone" ["standAlone"|"networkReader"|"networkWriter"]
  SFInt32    [in,out] port                                       0            [0..65535]
  SFTime     [in,out] readInterval                               0.1          [0,∞)
  SFRotation [in,out] rotation                                   0 0 1 0      [-1,1] or (-∞,∞)
  SFBool     [in,out] rtpHeaderExpected                          FALSE
  SFVec3f    [in,out] scale                                      1 1 1        (-∞,∞)
  SFRotation [in,out] scaleOrientation                           0 0 1 0      [-1,1] or (-∞,∞)
  SFInt32    [in,out] siteID                                     0            [0..65535]
  SFVec3f    [in,out] translation                                0 0 0        (-∞,∞)
  SFBool     [in,out] visible                                    TRUE
  SFInt32    [in,out] warhead                                    0            [0..65535]
  SFTime     [in,out] writeInterval                              1.0          [0,∞)
  SFFloat    [out]    articulationParameterValue0_changed        
  SFFloat    [out]    articulationParameterValue1_changed        
  SFFloat    [out]    articulationParameterValue2_changed        
  SFFloat    [out]    articulationParameterValue3_changed        
  SFFloat    [out]    articulationParameterValue4_changed        
  SFFloat    [out]    articulationParameterValue5_changed        
  SFFloat    [out]    articulationParameterValue6_changed        
  SFFloat    [out]    articulationParameterValue7_changed        
  SFTime     [out]    collideTime                                
  SFTime     [out]    detonateTime                               
  SFTime     [out]    firedTime                                  
  SFBool     [out]    isActive                                   
  SFBool     [out]    isCollided                                                      
  SFBool     [out]    isDetonated                                                    
  SFBool     [out]    isNetworkReader                            
  SFBool     [out]    isNetworkWriter                            
  SFBool     [out]    isRtpHeaderHeard                           
  SFBool     [out]    isStandAlone                               
  SFTime     [out]    timestamp                                  
  SFVec3f    []       bboxCenter                                 0 0 0        (-∞,∞)
  SFVec3f    []       bboxSize                                   -1 -1 -1     [0,∞) or −1 −1 −1
  MFString   []       geoSystem                                  ["GD","WE"]  (see 25.2.3)
}
----

EspduTransform is a _<<X3DGroupingNode>>_ that can
contain most nodes, and also implements the X3DBoundedObject interface.
EspduTransform integrates functionality of the following DIS PDUs:
EntityStatePDU, CollisionPDU, DetonationPDU, FirePDU, CreateEntity, and
RemoveEntity. The following description identifies the fields of the
EspduTransform node that are associated with the content of these PDUs.

As an _X3DGroupingNode_, EspduTransform has _addChildren_ and
_removeChildren_ events to permit modification to the subordinate
structure of the scene graph. The _removeChildren_ event removes nodes
from the EspduTransform's _children_ field. Any nodes in the
_removeChildren_ event that are not in the EspduTransform's _children_
list are ignored. Adding a node to the _children_ field will add that
node to the EspduTransform's set of children. Adding any node to the
EspduTransform's _children_ field that is already in that child list is
illegal. Adding any node to the EspduTransform's _children_ that is an
ancestor of that grouping is illegal.

Fields in the EspduTransform node that were not previously described in
<<CommonDISfields, 28.2.3 Common DIS fields>> are: _translation_,
_rotation_, _center_, _scale_, _scaleOrientation_, _bboxCenter_,
_bboxSize_, _articulationParameterCount_,
_articulationParameterDesignatorArray_,
_articulationParameterChangeIndicatorArray_,
_articulationParameterIdPartAttachedToArray_,
_articulationParameterTypeArray_, _articulationParameterArray_,
_set_articulationParameterValue0_, _set_articulationParameterValue1_,
_set_articulationParameterValue2_, _set_articulationParameterValue3_,
_set_articulationParameterValue4_, _set_articulationParameterValue5_,
_set_articulationParameterValue6_, _set_articulationParameterValue7_,
_articulationParameterValue0_changed_,
_articulationParameterValue1_changed_,
_articulationParameterValue2_changed_,
_articulationParameterValue3_changed_,
_articulationParameterValue4_changed_,
_articulationParameterValue5_changed_,
_articulationParameterValue6_changed_,
_articulationParameterValue7_changed_, _marking_, _forceID_,
_entityKind_, _entityDomain_, _entityCountry_, _entityCategory_,
_entitySubcategory_, _entitySpecific_, _entityExtra_, _linearVelocity_,
_linearAcceleration_, _deadReckoning_, _isCollided_, _collidedTime_,
_eventApplicationID_, _eventSiteID_, _eventEntityID_, _collisionType_,
_eventNumber_, _fired1_, _fired2_, _firedTime_, _munitionStartPoint_,
_munitionEndPoint_, _fireMissionIndex_, _munitionApplicationID_,
_munitionSiteID_, _munitionEntityID_, _warhead_, _fuse_,
_munitionQuantity_, _firingRate_, _firingRange_, _isDetonated_,
_detonateTime_, _detonationLocation_, _detonationRelativeLocation_, and
_detonationResult_.

The Entity State PDU provides notification of a new position and
orientation of an entity, which directly corresponds to the
functionality of the X3D <<Transform>> node. The
_translation_ field corresponds to the new position in the DIS
coordinate system. It is important to distinguish between the X3D
coordinate system and the DIS coordinate system. If (x, y, z) are the
coordinates of a point in the X3D coordinate system, corresponding DIS
coordinates for the same point would be (x, −z, y). Note that only X3D
coordinates are used by the X3D scene. The EspduTransform node
internally performs all conversions to/from DIS coordinates when
writing/reading DIS PDUs to/from the network.

The _rotation_ field provides the rotation of the entity, where the
rotation is performed relative to the value of the _center_ field. The
_scale_ field provides scaling factors along the x, y, z axes, while the
_scaleOrientation_ field provides scaling factors for the specified
_rotation_. The _translation_, _rotation_, _scale_, and _center_ fields
corresponds directly with functionality of the Transform node. The
_bboxCenter_ and _bboxSize_ fields (of the
_<<X3DBoundedObject>>_ interface) specify the center
and size, respectively, of a cube bounding the entity geometry contained
in the EspduTransform grouping node, corresponding to the same fields of
an X3D Transform node.

Articulation parameter inputOnly events and outputOnly events are
provided for the articulationParameters array in order to enable simple
routing of primary events of interest into (and out of) the array. As an
example, if eight articulation parameters were needed for an
EspduTransform controlling the movable parts of a race-car model, each
of these articulation parameters might be individually routed as
necessary. Events into (and out of) articulationParameter subscripts [8]
through [78] are accomplished either by a separate Script node
mechanism, or else by complete routing/replacement using an MFFloat
event.

The _articulationParameterCount_ field (8-bit unsigned integer)
indicates the number of parameters that are being used to describe
articulation of various segments of the entity model. For example, the
orientation of a turret together with the inclination of the gun for a
tank entity may be described by two articulation parameters, or the
orientation of various segments in a humanoid model may be provided by
several articulation parameters. The maximum number of articulated
parameter records in an Entity State PDU is constrained to 78 by the
maximum length of a PDU.

For X3D authoring convenience in ROUTEing events to (or from)
articulation parameters, the first eight articulation parameter values
may be accessed by accessType inputOnly/outputOnly fields (
_set_articulationParameterValue0_, ...,
_set_articulationParameterValue7_ and
_articulationParameterValue0_changed_, ...,
_articulationParameterValue7_changed_).

Fields _articulationParameterDesignatorArray_,
_articulationParameterChangeIndicatorArray_,
_articulationParameterIdPartAttachedToArray_,
_articulationParameterTypeArray_ are arrays that correspond to
additional values provided in each articulation parameter record.
Elements in these arrays correspond to each articulation parameter in
sequential order.

* The Parameter Type Designator entries in the
_articulationParameterDesignatorArray_ indicate if the the parameter
record is for an articulated or attached part. It is represented by an
8-bit enumeration.
* The Change Indicator entries in the _articulationChangeIndicatorArray_
indicate the change of any parameter for the associated articulated
part. This is specified by an 8-bit unsigned integer. The value is
initially set to zero for each exercise and is sequentially incremented
by one for each change in the articulation parameters. The proper
indicator is updated automatically by an X3D DIS implementation upon
receipt of a _set_articulationParameterValue_ event.
* The ID - Part Attached To entries in the
_articulationParameterIdPartAttachedToArray_ identify the articulated
part to which this articulation parameter is attached. The value is
specified by a 16-bit unsigned integer, and is set to zero if the
articulated part is attached directly to the entity.
* The Parameter Type entries in the _articulationParameterTypeArray_ are
specified by 32-bit enumeration values.
* The Parameter Value entries in the _articulationParameterArray_ are
specified by a 64-bit field. The definition of the 64 bits is determined
based on the type of parameter indicated above.

The _marking_ field is a SFString value (with a maximum of 11
characters) corresponding to a selection from an enumerated set of
markings in the DIS standard (for full compliance) or an arbitrary
string for non-compliant applications using the EspduTransform node.

The _forceID_ and _entityKind_ fields are 8-bit identification
enumerations. The _entityDomain_ field (8-bit enumeration) identities
the domain of operation of the entity ( _e.g._, subsurface, surface,
land), except for munition entities. For munition entities, this field
specifies the domain of the target. The _entityCountry_ field (16-bit
enumeration) specifies the country to which the design of the entity is
attributed. The _entityCategory_ field (8-bit enumeration) identifies
the main category that describes the entity. The _entitySubcategory_
field (8-bit enumeration) specifies a subcategory based on the
identified category value. The _entitySpecific_ field (8-bit
enumeration) provides specific information about the entity based on the
identified subcategory field. The _entityExtra_ field (8-bit
enumeration) provides additional information about the entity. The DIS
specification also allows identification of an Alternative Entity Type
containing the same fields (Entity Kind, Domain, Country, Category,
Subcategory, Specific, Extra) as described above.

Enumeration values are provided directly, or in additional references,
as specified by IEEE 1278 (see <<IEEE1278>> and
<<SISO>>).

The _linearVelocity_ and _linearAcceleration_ fields provide the linear
velocity and acceleration vectors, respectively, for dead reckoning
calculations. The dead reckoning algorithm to be applied is identified
in the _deadReckoning_ field (8-bit enumeration).

The CollisionPDU is sent to notify an entity that a collision has
occurred. The issuing entity is identified in the _entityID_ field
described in <<CommonDISfields, 28.2.3 Common DIS fields>>. The
_isCollided_ field is a Boolean value indicating if a collision
(`TRUE`) has occurred. The _collideTime_ field gives the time
(SFTime) at which the collision was determined to have occurred. In a
CollisionPDU message, the _eventSiteID_, _eventApplicationID_,
_eventEntityID_ triplet uniquely identifies the entity colliding with
the issuing entity (when known). The _collisionType_ field (8-bit
enumeration) identifies the type of collision that occurred.

The _eventNumber_ field is set to one for each exercise and incremented
by one for each fire event, collision event, or electromagnetic mission
event.

The FirePDU notifies the simulation that an entity has fired a weapon.
The firing entity is identified in the _entityID_ field described in
<<CommonDISfields, 28.2.3 Common DIS fields>>. Field _fired1_ (set to
`TRUE`) indicates the primary weapon was fired; field _fired2_
(set to `TRUE`) indicates the entity's secondary weapon was
fired. The _firedTime_ field gives the time (SFTime) at which the firing
occurred. Fields _munitionStartPoint_ and _munitionEndPoint_ describe
the path of the munition from firing weapon to detonation or impact. The
_fireMissionIndex_ field identifies the fire mission, if known. The
_firingRange_ field specifies the range (in meters) that an entity's
fire control system has assumed in computing the fire control solution.

In a FirePDU message, the _EventSiteID_, _EventApplicationID_,
_EventEntityID_ triplet uniquely identifies the target entity, when
known. For the FirePDU and DetonationPDU messages, the _munitionSiteID_,
_munitionApplicationID_, _munitionEntityID_ triplet uniquely identifies
the munition entity (if known).

The FirePDU and DetonationPDU messages provide burst descriptor
information in the _warhead_ (16-bit enumeration), _fuse_ (16-bit
enumeration), _munitionQuantity_ (16-bit unsigned integer), and
_firingRate_ (16-bit unsigned integer) fields.

The DetonationPDU provides notification that a munition has detonated or
impacted so that other entities can determine possible damage from the
detonation. The _detonated_ field indicates if detonation has occurred
(`TRUE`). The _detonateTime_ field gives the time (SFTime) at
which the detonation is determined to have occurred. This enables other
entities to determine their position relative to the detonation at the
time the detonation occurred.

The DetonationPDU provides the _detonationLocation_ in world
coordinates, as well as the _detonationRelativeLocation_, the location
of the detonation or impact in the target entity's coordinate system.
The _detonationResult_ field (8-bit enumeration) provides information on
the outcome of the detonation event.

The CreateEntityPDU notifies other entities of a new entity in the
simulation. The _siteID_, _applicationID_, _entityID_ triplet described
in <<CommonDISfields, 28.2.3 Common DIS fields>>, uniquely identifies
the new entity. A CreateEntityPdu is sent upon startup or creation of a
new entity.

The RemoveEntityPDU notifies other entities of the removal of an entity
from the simulation. The _siteID_, _applicationID_, _entityID_ triplet
described in <<CommonDISfields, 28.2.3 Common DIS fields>>, uniquely
identifies the entity to be removed. A RemoveEntityPDU is sent upon
shutdown or removal of an existing entity.

[[ReceiverPdu]]
==== 28.3.4 ReceiverPdu

[source,node]
----
ReceiverPdu : X3DNetworkSensorNode, X3DBoundedObject {
  SFString [in,out] address                  "localhost"
  SFInt32  [in,out] applicationID            0            [0..65535]
  SFBool   [in,out] bboxDisplay              FALSE
  SFString [in,out] description              ""
  SFBool   [in,out] enabled                  TRUE
  SFInt32  [in,out] entityID                 0            [0..65535]
  SFVec3d  [in,out] geoCoords                0 0 0        (-∞,∞)
  SFNode   [in,out] metadata                 NULL         [X3DMetadataObject]
  SFString [in,out] multicastRelayHost       ""
  SFInt32  [in,out] multicastRelayPort       0            [0..65535]
  SFString [in,out] networkMode              "standAlone" ["standAlone"|"networkReader"|"networkWriter"]
  SFInt32  [in,out] port                     0            [0..65535]
  SFInt32  [in,out] radioID                  0            [0..65535]
  SFTime   [in,out] readInterval             0.1          [0,∞)
  SFFloat  [in,out] receivedPower            0.0          [0,∞)
  SFInt32  [in,out] receiverState            0            [0..65535]
  SFBool   [in,out] rtpHeaderExpected        FALSE
  SFInt32  [in,out] siteID                   0            [0..65535]
  SFInt32  [in,out] transmitterApplicationID 0            [0..65535]
  SFInt32  [in,out] transmitterEntityID      0            [0..65535]
  SFInt32  [in,out] transmitterRadioID       0            [0..65535]
  SFInt32  [in,out] transmitterSiteID        0            [0..65535]
  SFBool   [in,out] visible                  TRUE
  SFInt32  [in,out] whichGeometry            1            [-1..∞)
  SFTime   [in,out] writeInterval            1.0          [0,∞)
  SFBool   [out]    isActive                 
  SFBool   [out]    isNetworkReader          
  SFBool   [out]    isNetworkWriter          
  SFBool   [out]    isRtpHeaderHeard         
  SFBool   [out]    isStandAlone             
  SFTime   [out]    timestamp                
  SFVec3f  []       bboxCenter               0 0 0        (-∞,∞)
  SFVec3f  []       bboxSize                 -1 -1 -1     [0,∞) or −1 −1 −1
  MFString []       geoSystem                ["GD","WE"]  (see 25.2.3)
}
----

ReceiverPdu is an _<<X3DChildNode>>_ node, and also
implements the _<<X3DBoundedObject>>_ interface. The
ReceiverPdu transmits the state of radio frequency (RF) receivers
modeled in the simulation. Fields in the ReceiverPdu node that were not
previously described in Common DIS Fields are: _whichGeometry_,
_radioID_, _receivedPower_, _receiverState_, _transmitterSiteID_,
_transmitterApplicationID_, _transmitterEntityID_, and
_transmitterRadioID_.

The _radioID_ field (16-bit unsigned integer) identifies a particular
radio within a given entity ( _entityID_). The _radioID_ is assigned
sequentially, starting with 1. The combination of Entity ID and Radio ID
uniquely identify a radio within a simulation exercise. The
_receivedPower_ field (32-bit flowing point) indicates the RF power
received, after applying any propagation loss and antenna gain. The
field value is in units of decibel-milliwatts (dBm). The _receiverState_
(16-bit enumeration) indicates if the receiver is currently idle or busy
via one of the following enumerated values:

____
0 = off, +
1 = on but not receiving, or +
2 = on and receiving.
____

The _transmitterEntityID_ (16-bit unsigned integer) identifies the
transmitter entity that has emitted the signal being received. The
_transmitterRadioID_ field (16-bit unsigned integer) identifies the
particular radio within the transmitter entity ( _transmitterEntityID_).

The _transmitterSiteID_ field (16-bit unsigned integer) provides the
unique DIS site identifier for the transmitter entity. The
_transmitterApplicationID_ (16-bit unsigned integer) provides the
application identifier for the transmitter entity that is unique within
the DIS site ( _transmitterSiteID_).

The _whichGeometry_ field indicates to the rendering software what
geometry to draw for the receiverPdu node: −1 for no geometry; 0 for
text trace; 1 for default geometry for this node. Additional alternative
geometry modes may optionally be supported by X3D browsers. Lack of
support for higher modes reverts to _whichGeometry_ value of 1.

The _bboxCenter_ and _bboxSize_ fields (of the _X3DBoundedObject_
interface) specify the center and size, respectively, of a cube bounding
the display geometry (if any) for this node.

[[SignalPdu]]
==== 28.3.5 SignalPdu

[source,node]
----
SignalPdu : X3DNetworkSensorNode, X3DBoundedObject {
  SFString [in,out] address            "localhost"
  SFInt32  [in,out] applicationID      0            [0..65535]         
  SFBool   [in,out] bboxDisplay        FALSE
  MFInt32  [in,out] data               []           [0..255]         
  SFInt32  [in,out] dataLength         0            [0..65535]
  SFString [in,out] description                     ""
  SFBool   [in,out] enabled            TRUE
  SFInt32  [in,out] encodingScheme     0            [0..65535]
  SFInt32  [in,out] entityID           0            [0..65535]
  SFVec3d  [in,out] geoCoords          0 0 0        (-∞,∞)
  SFNode   [in,out] metadata           NULL         [X3DMetadataObject]
  SFString [in,out] multicastRelayHost ""
  SFInt32  [in,out] multicastRelayPort 0            [0..65535]
  SFString [in,out] networkMode        "standAlone" ["standAlone"|"networkReader"|"networkWriter"]
  SFInt32  [in,out] port               0            [0..65535]
  SFInt32  [in,out] radioID            0            [0..65535]
  SFTime   [in,out] readInterval       0.1          [0,∞)
  SFBool   [in,out] rtpHeaderExpected  FALSE
  SFInt32  [in,out] sampleRate         0            [0..65535] 
  SFInt32  [in,out] samples            0            [0..65535]
  SFInt32  [in,out] siteID             0            [0..65535]
  SFInt32  [in,out] tdlType            0            [0..65535]
  SFBool   [in,out] visible            TRUE
  SFInt32  [in,out] whichGeometry      1            [-1..∞)
  SFTime   [in,out] writeInterval      1.0          [0,∞)
  SFBool   [out]    isActive
  SFBool   [out]    isNetworkReader
  SFBool   [out]    isNetworkWriter
  SFBool   [out]    isRtpHeaderHeard
  SFBool   [out]    isStandAlone
  SFTime   [out]    timestamp
  SFVec3f  []       bboxCenter         0 0 0        (-∞,∞)
  SFVec3f  []       bboxSize           -1 -1 -1     [0,∞) or −1 −1 −1
  MFString []       geoSystem          ["GD","WE"]  (see 25.2.3)
}
----

SignalPdu is an _<<X3DChildNode>>_ node, and also
implements the _<<X3DBoundedObject>>_ interface.
Transmission of voice, audio or other data is communicated by issuing a
Signal PDU from the SignalPdu node. Fields in the SignalPdu node that
were not previously described in Common DIS Fields are: _radioID_,
_encodingScheme_, _tdlType_, _sampleRate_, _dataLength_, _samples_,
_data_, and _whichGeometry_.

The _radioID_ field identifies a particular radio within a given entity
( _entityID_). The _radioID_ (16-bit unsigned integer) is assigned
sequentially, starting with 1. The combination of Entity ID and Radio ID
uniquely identify a radio within a simulation exercise. The
_encodingScheme_ field (16-bit enumeration) designates both an Encoding
Class enumerated value (2 most significant bits):

____
0 = Encoded Voice; +
1 = Raw Binary Data; +
2 = Application-Specific Data; +
3 = Database Index.
____

and an Encoding Type enumerated value (14 least significant bits):

____
1 = 8-bit mu-law; +
2 = CVSD per MIL-STD-188-113; +
3 = ADPCM per CCITT G.721; +
4 = 16-bit linear PCM; +
5 = 8-bit linear PCM; +
6 = Vector Quantization.
____

The _tdlType_ field (16-bit enumeration) specifies the Tactical Data
Link (TDL) type as an enumerated value when the Encoding Class is
`voice`, `raw binary`, `application-specific`, or
`database index` representation of a TDL message. The field is
set to zero when it is not representing a TDL message.

The _sampleRate_ field (32-bit unsigned integer) gives either (1) the
sample rate in samples per second if the Encoding Class is
`encoded audio` or (2) the data rate in bits per second for data
transmissions. If the Encoding Class is `database index`,
_sampleRate_ is set to zero.

The _samples_ field (16-bit unsigned integer) gives the number of
samples in the PDU if the Encoding Class is `encoded voice`;
otherwise, the field is set to zero.

The _dataLength_ field (16-bit unsigned integer) specifies the number of
bits of digital voice audio or digital data being sent in the Signal
PDU. If the Encoding Class is `database index`, the _dataLength_
field is set to the value 96.

The _data_ field specifies the audio or digital data conveyed by the
radio transmission. The interpretation of the field depends on the value
of the _encodingScheme_ and _tdlType_ fields. Refer to IEEE 1278
(<<IEEE1278>> and <<SISO>>) for details.

The _whichGeometry_ field indicates to the rendering software what
geometry to draw for the SignalPdu node: −1 for no geometry; 0 for text
trace; 1 for default geometry for this node. Additional alternative
geometry modes may optionally be supported by X3D browsers. Lack of
support for higher modes reverts to _whichGeometry_ value of 1.

The _bboxCenter_ and _bboxSize_ fields (of the _X3DBoundedObject_
interface) specify the center and size, respectively, of a cube bounding
the display geometry (if any) for this node.

[[TransmitterPdu]]
==== 28.3.6 TransmitterPdu

[source,node]
----
TransmitterPdu : X3DNetworkSensorNode, X3DBoundedObject { 
  SFString [in,out] address                            "localhost"
  SFVec3f  [in,out] antennaLocation                    0 0 0        (-∞,∞)
  SFInt32  [in,out] antennaPatternLength               0            [0..65535]
  SFInt32  [in,out] antennaPatternType                 0            [0..65535]
  SFInt32  [in,out] applicationID                      0            [0..65535]
  SFBool   [in,out] bboxDisplay                        FALSE
  SFInt32  [in,out] cryptoKeyID                        0            [0..65535]           
  SFInt32  [in,out] cryptoSystem                       0            [0..65535]
  SFString [in,out] description                        ""
  SFBool   [in,out] enabled                            TRUE
  SFInt32  [in,out] entityID                           0            [0..65535] 
  SFInt32  [in,out] frequency                          0            [0,∞)
  SFVec3d  [in,out] geoCoords                          0 0 0        (-∞,∞)
  SFInt32  [in,out] inputSource                        0            [0..255]
  SFInt32  [in,out] lengthOfModulationParameters       0            [0..255]
  SFNode   [in,out] metadata                           NULL         [X3DMetadataObject]
  SFInt32  [in,out] modulationTypeDetail               0            [0..65535]
  SFInt32  [in,out] modulationTypeMajor                0            [0..65535]
  SFInt32  [in,out] modulationTypeSpreadSpectrum       0            [0..65535]
  SFInt32  [in,out] modulationTypeSystem               0            [0..65535]
  SFString [in,out] multicastRelayHost                 ""
  SFInt32  [in,out] multicastRelayPort                 0            [0..65535]
  SFString [in,out] networkMode                        "standAlone" ["standAlone"|"networkReader"|"networkWriter"]
  SFInt32  [in,out] port                               0            [0..65535]
  SFFloat  [in,out] power                              0.0          [0,∞)
  SFInt32  [in,out] radioEntityTypeCategory            0            [0..255]
  SFInt32  [in,out] radioEntityTypeCountry             0            [0..65535]
  SFInt32  [in,out] radioEntityTypeDomain              0            [0..255]
  SFInt32  [in,out] radioEntityTypeKind                0            [0..255]
  SFInt32  [in,out] radioEntityTypeNomenclature        0            [0..255]
  SFInt32  [in,out] radioEntityTypeNomenclatureVersion 0            [0..65535]
  SFInt32  [in,out] radioID                            0            [0..255]
  SFTime   [in,out] readInterval                       0.1          [0,∞)
  SFVec3f  [in,out] relativeAntennaLocation            0 0 0        (-∞,∞)
  SFBool   [in,out] rtpHeaderExpected                  FALSE
  SFInt32  [in,out] siteID                             0            [0..65535]
  SFFloat  [in,out] transmitFrequencyBandwidth         0.0          (-∞,∞)
  SFInt32  [in,out] transmitState                      0            [0..255]
  SFBool   [in,out] visible                            TRUE
  SFInt32  [in,out] whichGeometry                      1            [-1..∞)
  SFTime   [in,out] writeInterval                      1.0          [0,∞)
  SFBool   [out]    isActive                           
  SFBool   [out]    isNetworkReader                    
  SFBool   [out]    isNetworkWriter                    
  SFBool   [out]    isRtpHeaderHeard                   
  SFBool   [out]    isStandAlone                       
  SFTime   [out]    timestamp                          
  SFVec3f  []       bboxCenter                         0 0 0        (-∞,∞)
  SFVec3f  []       bboxSize                           -1 -1 -1     [0,∞) or −1 −1 −1
  MFString []       geoSystem                          ["GD","WE"]  (see 25.2.3)
}
----

TransmitterPdu is an X3DChildNode node, and also implements the
_X3DBoundedObject_ interface. The TransmitterPdu provides detailed
information about a radio transmitter. Fields in the TransmitterPdu node
that were not previously described in Common DIS Fields are: _radioID_,
_radioEntityTypeKind_, _radioEntityTypeDomain_,
_radioEntityTypeCountry_, _radioEntityTypeCategory_,
_radioEntityTypeNomenclature_, _radioEntityTypeNomenclatureVersion_,
_transmitState_, _inputSource_, _antennaLocation_, _antennaPatternType_,
_antennaPatternLength_, _frequency_, _transmitFrequencyBandwidth_,
_power_, _modulationTypeSpreadSpectrum_, _modulationTypeMajor_,
_modulationTypeDetail_, _modulationTypeSystem_,
_lengthOfModulationParameters_, _cryptoSystem_, _cryptoKeyID_,
_relativeAntennaLocation_, and _whichGeometry_.

The _radioID_ field identifies a particular radio within a given entity
( _entityID_). The _radioID_ (16-bit unsigned integer) is assigned
sequentially, starting with 1. The combination of Entity ID and Radio ID
uniquely identify a radio within a simulation exercise.

The radio entity type is described by a combination of fields:
_radioEntityTypeKind_, _radioEntityTypeDomain_,
_radioEntityTypeCountry_, _radioEntityTypeCategory_,
_radioEntityTypeNomenclatureVersion_, and _radioEntityTypeNomenclature_.
The _radioEntityTypeKind_ is an 8-bit enumeration ( _e.g._, value of 7
indicates Entity Kind of "Radio"). The _radioEntityTypeDomain_ field
(8-bit enumeration) designates the domain of operation of the radio
enumerated value:

____
0 = other; +
1 = land; +
2 = air; +
3 = surface; +
4 = subsurface; +
5 = space.
____

The _radioEntityTypeCountry_ field (16-bit enumeration) identifies the
country to which the design of the radio entity is attributed SISO (see
<<IEEE1278>> and <<SISO>>).

The _radioEntityTypeCategory_ field (8-bit enumeration) specifies the
main category describing the radio entity. The
_radioEntityTypeNomenclature_ (16-bit enumeration) specifies the
nomenclature for a particular communications device. Nomenclatures are a
combination of letters and/or numbers arranged in a specific sequence to
provide a short method of identification. The
_radioEntityTypeNomenclatureVersion_ field designates the specific
modification or individual unit type of a series and/or family of
equipment.

The _transmitterState_ field (8-bit enumeration) indicates the
operational state of the transmitter entity enumerated value:

____
0 = off, +
1 = on but not transmitting, or +
2 = on and transmitting.
____

The _inputSource_ (8-bit enumeration) specifies which position or data
port in the entity utilizing the radio is providing the input audio or
data being transmitted enumerated value:

____
0 = other, +
1 = pilot, +
2 = copilot, +
3 = first officer, +
4 = driver, +
5 = loader, +
6 = gunner, +
7 = commander, +
8 = digital data device, or +
9 = intercom.
____

The _antennaLocation_ field provides the location of the transmitter
antenna in the DIS coordinate system.

NOTE  IEEE 1278 (see <<IEEE1278>>) allocates 64-bit
floating point values for the components of the antenna location vector,
whereas it is represented here as SFVec3f for maximum interoperability
with X3D.

The _relativeAntennaLocation_ field provides an offset from the location
of the transmitter entity to simulate placement of antennas some
distance from the transmitter equipment.

The _antennaPatternType_ field (16-bit enumeration) indicates the type
of representation for the radiation pattern from the antenna enumerated
value:

____
0 = omnidirectional; +
1 = beam; +
2 = spherical harmonic.
____

The value of this field determines the interpretation of the Antenna
Pattern Parameter field of the DIS Transmitter PDU. The
_antennaPatternLength_ field (16-bit unsigned integer) specifies the
length of the Antenna Pattern Parameters field in octets (value is a
multiple of 8).

The _frequency_ field specifies the center frequency (in Hertz) being
used by the radio for transmission. Note that IEEE 1278 allocates a
64-bit unsigned integer to represent frequency values, whereas it is
limited to SFInt32 in X3D. The _transmitFrequencyBandwidth_ (32-bit
floating point) identifies the bandpass of the transmitting radio
entity. The _power_ field (32-bit floating point) provides the average
power (in units of dBm) of the radio entity transmission.

Information about the type of modulation used for radio transmission is
represented in the Transmitter PDU by several fields. These fields
identify the signal parameters that are used to determine whether two
radios may interoperate. The _modulationTypeSpreadSpectrum_ field
indicates the spread spectrum technique or combination of techniques in
use enumerated value:

____
0 = frequency hopping; +
1 = pseudo-noise; +
2 = time hopping; +
3-15 are to be determined.
____

The _modulationTypeMajor_ (16-bit enumeration) provides the major
classification of the modulation type enumerated value:

____
0 = other; +
1 = amplitude; +
2 = amplitude and angle; +
3 = angle; +
4 = combination; +
5 = pulse; +
6 = unmodulated.
____

The _modulationTypeDetail_ field (16-bit enumerations) contains detailed
information depending on the Major Modulation Type (
_modulationTypeMajor_). The _modulationTypeSystem_ field (16-bit
enumeration) specifies the interpretation of the modulation parameter
field(s) in the Transmitter PDU (enumerated value):

____
0 = other; +
1 = generic; +
2 = HQ; +
3 = HQII; +
4 = HQIIA; +
5 = SINCGARS; +
6 = CCTT SINCGARS.
____

The _cryptoSystem_ field (16-bit enumeration) identifies the crypto
equipment used enumerated value:

____
0 = other; +
1 = KY-28; +
2 = KY-58; +
3 = Narrow Spectrum Secure Voice (NSVE); +
4 = Wide Spectrum Secure Voice (WSVE); +
5 = SINCGARS ICOM.
____

The _cryptoKeyID_ field (16-bit unsigned integer) indicates whether the
crypto equipment is in the baseband encryption mode or the diphase
encryption mode (high order bit of the 16-bit field) and provides the
key identifier (lower order 15 bits). If the key identifiers of the
transmitter and receiver match, they are considered to be using the same
encryption key (note that this is not an actual crypto key).

The _whichGeometry_ field indicates to the rendering software what
geometry to draw for the TransmitterPdu node: −1 for no geometry; 0 for
text trace; 1 for default geometry for this node. Additional alternative
geometry modes may optionally be supported by X3D browsers. Lack of
support for higher modes reverts to _whichGeometry_ value of 1.

The _bboxCenter_ and _bboxSize_ fields (of the X3DBoundedObject
interface) specify the center and size, respectively, of a cube bounding
the display geometry (if any) for this node.

[[S28.4_SupportLevels]]
=== 28.4 Support levels

The DIS component provides two levels of support as specified in
<<t28_2, Table 28.2>>.

[[t28_2]]
Table 28.2 — DIS component support levels

[width="100%",cols="25%,25%,25%,25%",]
|===
|*Level* |Prerequisites |*Nodes/Features* |Support
|*1* |Core 1 +
Time 1 +
Grouping 3 +
Networking 3 +
Rendering 1 +
Shape 1 +
Geometry3D 1 +
Interpolator 1 +
Point device sensor 1 +
Navigation 1 |  | 
|  |  |EspduTransform |All fields fully supported.
|  |  |ReceiverPDU    |All fields fully supported.
|  |  |SignalPDU      |All fields fully supported.
|  |  |TransmitterPDU |All fields fully supported.
|*2* |Core 1 +
Time 1 +
Grouping 3 +
Networking 3 +
Rendering 1 +
Shape 1 +
Geometry3D 1 +
Interpolator 1 +
Point device sensor 1 +
Navigation 1 |  | 
|  |  |All Level 1 DIS nodes. |All fields fully supported.
|  |  |DISEntityManager       |All fields fully supported.
|  |  |DISEntityTypeMapping   |All fields fully supported.
|===


[[scripting_html]]
== 29 Scripting component

[[S29_Introduction]]
=== 29.1 Introduction

[[S29_Name]]
==== 29.1.1 Name

The name of this component is "Scripting". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S29_Overview]]
==== 29.1.2 Overview

This clause describes the scripting component of this document. This
includes how <<Script>> nodes are used to effect changes in
X3D worlds. <<t29_1, Table 29.1>> provides links to the major
topics in this clause.

[[t29_1]]
Table 29.1 — Topics

* <<S29Introduction, 29.1 Introduction>>
** <<S29_Name, 29.1.1 Name>>
** <<S29_Overview, 29.1.2 Overview>>
* <<S29_Concepts, 29.2 Concepts>>
** <<ScriptingOverview, 29.2.1 Overview>>
** <<Scriptexecution, 29.2.2 Script execution>>
** <<InitializeAndShutdown, 29.2.3 initialize() and shutdown()>>
** <<EventsProcessed, 29.2.4 EventsProcessed()>>
** <<PrepareEvents, 29.2.5 PrepareEvents()>>
** <<directoutputs, 29.2.6 Scripts with direct outputs>>
** <<Asynchronousscripts, 29.2.7 Asynchronous scripts>>
** <<Scriptlanguages, 29.2.8 Script languages>>
** <<Eventhandling, 29.2.9 Event handling>>
** <<Accessingfieldsandevents, 29.2.10 Accessing fields and events>>
* <<S29_AbstractTypes, 29.3 Abstract types>>
** <<X3DScriptNode, 29.3.1 _X3DScriptNode_>>
* <<S29_NodeReference, 29.4 Node reference>>
** <<S29_Script, 29.4.1 Script>>
* <<S29_SupportLevels, 29.5 Support levels>>

* <<t29_1, Table 29.1 — Topics>>
* <<t29_2, Table 29.2 — Script component support levels>>




[[S29_Concepts]]
=== 29.2 Concepts

[[ScriptingOverview]]
==== 29.2.1 Overview

Authors often require that X3D worlds change dynamically in response to
user inputs, external events, and the current state of the world. The
proposition "if the vault is currently closed AND the correct
combination is entered, open the vault" illustrates the type of problem
which may need addressing. These kinds of decisions are expressed
programmatically using the Scene Access Interface (SAI) specified in
Part 2 of ISO/IEC 19775. The programmatic elements are provided
internally from <<Script>> nodes (see <<S29_Script, 29.4.1 Script>>) 
or externally from other application programs. These
application programs are called _scripting environments_. In both cases,
the scripting environment can receive events, process them, and send new
events. Scripting environments can keep track of information between
subsequent executions ( _i.e._, retaining internal state over time).

This clause describes the general mechanisms and semantics of all
scripting access. <<I19775_2, ISO/IEC 19775-2>> defines a set of
abstract scripting services and specific languages bound to those
services. For internal scripting, event processing is performed by a
program or script contained in (or referenced by) the Script node's
_url_ field. This program or script may be written in any programming
language that the X3D browser supports.

[[Scriptexecution]]
==== 29.2.2 Script execution

A <<Script>> node is activated when it receives an event. The
X3D browser shall then execute the program in the Script node's _url_
field (passing the program to an external interpreter if necessary). The
program can perform a wide variety of actions including sending out
events (and thereby changing the scene), performing calculations, and
communicating with servers elsewhere on the Internet. A detailed
description of the ordering of event processing is contained
<<S4_Eventmodel, 4.4.8 Event model>>.

Script nodes may also be executed at initialization and shutdown as
specified in <<InitializeAndShutdown, 29.2.3 __initialize()__and _shutdown()_>>.
Some scripting languages may allow the creation of
separate processes from scripts, resulting in continuous execution (see
<<Asynchronousscripts, 29.2.7 Asynchronous scripts>>).

Script nodes receive events in timestamp order. Any events generated as
a result of processing an event are given timestamps corresponding to
the event that generated them. Conceptually, it takes no time for a
Script node to receive and process an event, even though in practice it
does take some amount of time to execute a Script.

When a _set_url_ event is received by a Script node that contains a
script that has been previously initialized for a different URL, the
_shutdown()_ service of the current script is called (see
<<InitializeAndShutdown, 29.2.3 __initialize()__and _shutdown()_>>.
Until the new script becomes available, the script shall behave as
though it has no executable content. When the new script becomes
available, the _Initialize()_ service is invoked. The limiting case is
when the URL contains inline code that can be immediately executed upon
receipt of the _set_url_ event (EXAMPLE  ecmascript:
protocol). In this case, it can be assumed that the old code is
unloaded and the new code loaded instantaneously, after any dynamic
route requests have been performed.

[[InitializeAndShutdown]]
==== 29.2.3 _initialize()_ and _shutdown()_

The scripting language binding may define an _initialize()_ method. This
method shall be invoked before the X3D browser presents the world to the
user and before any events are processed by any nodes in the same X3D
file as the <<Script>> node containing this script. Events
generated by the _initialize()_ method shall have timestamps less than
any other events generated by the Script node. This allows script
initialization tasks to be performed prior to the user interacting with
the world.

Likewise, the scripting language binding may define a _shutdown()_
method. This method shall be invoked when the corresponding Script node
is deleted or the world containing the Script node is unloaded or
replaced by another world. This method may be used as a clean-up
operation, such as informing external mechanisms to remove temporary
files. No other methods of the script may be invoked after the
_shutdown()_ method has completed, though the _shutdown()_ method may
invoke methods or send events while shutting down. Events generated by
the _shutdown()_ method that are routed to nodes that are being deleted
by the same action that caused the _shutdown()_ method to execute will
not be delivered. The deletion of the Script node containing the
_shutdown()_ method is not complete until the execution of its
_shutdown()_ method is complete.

[[EventsProcessed]]
==== 29.2.4 _eventsProcessed()_

The scripting language binding may define an _eventsProcessed()_ method
that is called after one or more events are received. This method allows
scripts that do not rely on the order of events received to generate
fewer events than an equivalent script that generates events whenever
events are received. If it is used in some other time-dependent way,
_eventsProcessed()_ may be nondeterministic, since different X3D browser
implementations may call _eventsProcessed()_ at different times.

For a single event cascade, a given <<Script>> node's
_eventsProcessed()_ method shall be called at most once. Events
generated from an _eventsProcessed()_ method are given the timestamp of
the last event processed.

[[PrepareEvents]]
==== 29.2.5 _prepareEvents()_

The scripting language binding may define a _prepareEvents()_ method
that is called only once per timestamp. _prepareEvents()_ is called
before any ROUTE processing and allows a <<Script>> to collect
any asynchronously generated data, such as input from a network queue or
the results of calling field listeners, and generate events to be
handled by the X3D browser's normal event processing sequence as if it
were a built-in sensor node.

[[directoutputs]]
==== 29.2.6 Scripts with direct outputs

<<Script>> nodes that have access to other nodes (via SFNode
and MFNode fields) and that have their _directOutput_ field set to
`TRUE` may directly post events to those nodes. They may also
read the last value sent from any of the node's fields.

When setting a value in another node, implementations shall set values
in other nodes by sending input events to the corresponding fields.
These events shall be part of the current event cascade (see
<<ExecutionModel, 4.4.8.3 Execution model>>).

[[Asynchronousscripts]]
==== 29.2.7 Asynchronous scripts

Some languages supported by X3D browsers may allow <<Script>>
nodes to spontaneously generate events, allowing users to create Script
nodes that function like new _<<X3DSensorNode>>_ nodes.
In these cases, the Script is generating the initial events that causes
the event cascade, and the scripting language and/or the X3D browser
shall determine an appropriate timestamp for that initial event. Such
events are then sorted into the event stream and processed like any
other event, following all of the same rules including those for
looping.

[[Scriptlanguages]]
==== 29.2.8 Script languages

The Script node's _url_ field shall allow for both inline scripting and
script reference via a URL. If provided, and language type is not
otherwise specified, then the MIME type of the returned data defines the
language type. Additionally, instructions can be included in-line using
scripting language protocols as defined in
<<ScriptingLanguageProtocols, 9.2.3 Scripting language protocols>> for
the specific language (from which the language type is inferred).

EXAMPLE  The following <<Script>> node has one field named
_start_ and three different URL values specified in the _url_ field:
Java, ECMAScript, and inline ECMAScript:

[source,listing]
----
Script {
 field SFBool start
 url [ "https://foo.com/fooBar.class",
 "https://foo.com/fooBar.js",
 "ecmascript:function start(value, timestamp) { ... }"
 ]
}
----

When a _start_ event is received by the Script node, one of the scripts
found in the _url_ field is executed. The Java platform bytecode is the
first choice, the ECMAScript code is the second choice, and the inline
ECMAScript code the third choice.

A description of order of preference for multiple valued URL fields may
be found in <<X3DUrlObject, 9.3.2 _X3DUrlObject_>>.

[[Eventhandling]]
==== 29.2.9 Event handling

Events received by the <<Script>> node are passed to the
appropriate scripting language method in the script. The method's name
depends on the language type used. In some cases, it is identical to the
name of the field; in others, it is a general callback method for all
events (see the scripting language annexes for details). The method is
passed two arguments: the event value and the event timestamp.

[[Accessingfieldsandevents]]
==== 29.2.10 Accessing fields and events

The fields of a <<Script>> node are accessible from scripting
language methods. Events can be routed to fields of Script nodes and the
fields of Script nodes can be routed to fields of other nodes. Another
Script node with access to this node can access the fields just like any
other node (see <<directoutputs, 29.2.6 Scripts with direct outputs>>).

It is recommended that user-defined field names defined in Script nodes
follow the naming conventions described in <<I19775_2, ISO/IEC 19775-2>>

The field values can be read or written and are persistent across method
call, and changes to a field can notify the node through its update
method.  See <<fieldTypes_html, 5 Field type reference>> for more
information on field types.


=== 29.3 Abstract types

[[X3DScriptNode]]
==== 29.3.1 _X3DScriptNode_ (abstract)

[source,node]
----
X3DScriptNode : X3DChildNode, X3DURLObject {
  SFTime   [in,out] autoRefresh          0.0  [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0  [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL [X3DMetadataObject]

  MFString [in,out] url                  []   [URI]
}
----

This abstract node type is the base type for all scripting nodes.

If the _autoRefresh_ field results in a new script node getting loaded
or the prior script getting reloaded, then all fields are re-initialized
to their initially defined values, and the _initialize()_ method is
invoked, if provided, as defined in <<InitializeAndShutdown, 29.2.3 __initialize()__and _shutdown()_>>.

WARNING  Automatically reloading content can have security
considerations and needs to be considered carefully.


=== 29.4 Node reference

[[S29_Script]]
==== 29.4.1 Script

[source,node]
----
Script : X3DScriptNode {
  SFTime    [in,out] autoRefresh          0.0   [0,∞)
  SFTime    [in,out] autoRefreshTimeLimit 3600.0   [0,∞)
  SFString  [in,out] description          ""
  SFBool    [in,out] load                 TRUE
  SFNode    [in,out] metadata             NULL  [X3DMetadataObject]
  MFString  [in,out] url                  []    [URI]
  SFBool    []       directOutput         FALSE
  SFBool    []       mustEvaluate         FALSE

  # And any number of:
  fieldType [in]     fieldName
  fieldType [in,out] fieldName            initialValue
  fieldType [out]    fieldName
  fieldType []       fieldName            initialValue
}
----

The Script node is used to program behaviour in a scene. Script nodes
typically:

[loweralpha]
. signify a change or user action;
. receive events from other nodes;
. contain a program module that performs some computation;
. effect change somewhere else in the scene by sending events.

Each Script node has associated programming language code, referenced by
the _url_ field, that is executed to carry out the Script node's
function. That code is referred to as the "script" in the rest of this
description. Details on the _url_ field can be found in <<URLs, 9.2.1 URLs, URNs and URIs>>.

Browsers are not required to support any specific language. Detailed
information on scripting languages is described in <<S29_Concepts, 29.2 Concepts>>. Browsers supporting a scripting language for which a language
binding is specified shall adhere to that language binding (see
<<I19777, ISO/IEC 19777>>).

Sometime before a script receives the first event it shall be
initialized (any language-dependent or user-defined _initialize()_ is
performed). The script is able to receive and process events that are
sent to it. Each event that can be received shall be declared in the
Script node using the same syntax as is used in a prototype definition:

[source,listing]
----
    inputOnly    type name
----

The _type_ can be any of the standard X3D fields (as defined in
<<fieldTypes_html, 5 Field type reference>>). _Name_ shall be an
identifier that is unique for this Script node.

The Script node is able to generate events in response to the incoming
events. Each event that may be generated shall be declared in the Script
node using the following syntax:

[source,listing]
----
    outputOnly    type name
----

If the Script node's _mustEvaluate_ field is `FALSE`, the X3D
browser may delay sending input events to the script until its outputs
are needed by the X3D browser. If the _mustEvaluate_ field is
`TRUE`, the X3D browser shall send input events to the script as
soon as possible, regardless of whether the outputs are needed. The
_mustEvaluate_ field shall be set to `TRUE` only if the Script
node has effects that are not known to the X3D browser (such as sending
information across the network). Otherwise, poor performance may result.

Once the script has access to a X3D node (via an SFNode or MFNode value
either in one of the Script node's fields or passed in as an attribute),
the script is able to read the contents of that node's fields. If the
Script node's _directOutput_ field is `TRUE`, the script may also
send events directly to any node to which it has access, and may
dynamically establish or break routes. If _directOutput_ is
`FALSE` (the default), the script may only affect the rest of the
world via events sent through its fields. The results are undefined if
_directOutput_ is `FALSE` and the script sends events directly to
a node to which it has access.

A script is able to communicate directly with the X3D browser to get
information such as the current time and the current world URL. This is
strictly defined generally by the SAI services (see <<I19775_2, Part 2 of ISO/IEC 19775>>) and by the language bindings of the SAI (see
<<I19777, ISO/IEC 19777>>) for the specific scripting language being
used.

The location of the Script node in the scene graph has no affect on its
operation.

EXAMPLE  If a parent of a Script node is a <<Switch>> node
with _whichChoice_ set to "−1" ( _i.e._, ignore its children), the
Script node continues to operate as specified ( _i.e._, it receives and
sends events).

[[S29.5_SupportLevels]]
=== 29.5 Support levels

The Scripting component provides one level of support as specified in
<<t29_2, Table 29.2>>.

[[t29_2]]
*Table 29.2 — Scripting component support levels*

[cols=",,,",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 | |
| | |_X3ScriptNode_ (abstract) |n/a
| | |Script node |All fields fully supported.
|===

[[eventUtilities_html]]
== 30 Event utilities component

[[S30_Introduction]]
=== 30.1 Introduction

[[S30_Name]]
==== 30.1.1 Name

The name of this component is "EventUtilities". This name shall be used
when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S30_Overview]]
==== 30.1.2 Overview

This clause describes the Event Utilities component of this document.
This includes Trigger and Sequencer node types that gives authors the
capability to gate, convert, or sequence numerous event-types for common
interactive applications without the use of a <<Script>> node.
<<t30_1, Table 30.1>> provides links to the major topics in this
subclause.

[[t30_1]]
Table 30.1 — Topics

* <<S30Introduction, 30.1 Introduction>>
** <<S30_Name, 30.1.1 Name>>
** <<S30_Overview, 30.1.2 Overview>>
* <<S30_Concepts, 30.2 Concepts>>
** <<S30_ConceptsOverview, 30.2.1 Overview of event utility nodes>>
** <<MutatingEvents, 30.2.2 Mutating events of Single Field (SF) event types>>
** <<TriggeringEvents, 30.2.3 Triggering events between Single Field (SF) event types>>
** <<SequencingEvents, 30.2.4 Sequencing Single Field (SF) events>>
* <<S30_AbstractTypes, 30.3 Abstract types>>
** <<X3DSequencerNode, 30.3.1 _X3DSequencerNode_>>
** <<X3DTriggerNode, 30.3.2 _X3DTriggerNode_>>
* <<S30_NodeReference, 30.4 Node reference>>
** <<BooleanFilter, 30.4.1 BooleanFilter>>
** <<BooleanSequencer, 30.4.2 BooleanSequencer>>
** <<BooleanToggle, 30.4.3 BooleanToggle>>
** <<BooleanTrigger, 30.4.4 BooleanTrigger>>
** <<IntegerSequencer, 30.4.5 IntegerSequencer>>
** <<IntegerTrigger, 30.4.6 IntegerTrigger>>
** <<TimeTrigger, 30.4.7 TimeTrigger>>
* <<S30_SupportLevels, 30.5 Support levels>> +
 
* <<t30_1, Table 30.1 — Topics>>
* <<t30_2, Table 30.2 — Event utilities component support levels>>




[[S30_Concepts]]
=== 30.2 Concepts

[[S30_ConceptsOverview]]
==== 30.2.1 Overview of event utility nodes

The Event Utilities component consists of 3 basic concepts:

[loweralpha]
. mutating events of Single Field (SF) events of a given type,
. triggering Single Field (SF) events of a given type from events of
other types, and
. sequencing Single Field (SF) events along a timeline (as a discrete
value generator).

These nodes may be composed using ROUTEs to create powerful authoring
scenarios without writing script code. This is especially useful in
profiles where interactivity would be otherwise significantly limited
due to lack of a <<Script>> node.

The location of event utility nodes in the transformation hierarchy has
no effect on their operation. For example, if a parent of a
<<BooleanSequencer>> is a <<Switch>> node
with whichChoice set to −1 ( _i.e._, ignore its children), the
BooleanSequencer continues to operate as specified ( _i.e._, receives
and sends events).

[[MutatingEvents]]
==== 30.2.2 Mutating events of Single Field (SF) event types

Mutator nodes allow content authors to alter values of a given type. In
this part of ISO/IEC 19775, the <<BooleanFilter>> node
accepts a single Boolean input event and generates either a
`TRUE` or `FALSE` output event based on the value of its
input; it also generates an event equal to the negation of its input.
These events allow for the creation of conditional behaviors that would
otherwise require a script.

[[TriggeringEvents]]
==== 30.2.3 Triggering events between Single Field (SF) event-types

Trigger nodes that generate an output event of a given type based on an
input event of a different type are all derived from the
_<<X3DTriggerNode>>_ abstract node type. This document
specifies the following types of _X3DTriggerNode_ nodes:

[loweralpha]
. <<BooleanTrigger>>
. <<IntegerTrigger>>
. <<TimeTrigger>>

The BooleanTrigger node generates an SFBool output event upon receiving
an SFTime input event.

The IntegerTrigger node generates an SFInt32 output event upon receiving
an SFBool input event. The value of the integer can be specified.

The TimeTrigger node generates an SFTime output event upon receiving The
IntegerTrigger node generates an integer output event upon receiving an
SFBool input event.

EXAMPLE  Routing the _isActive_ field of a
<<TouchSensor>> to the TimeTrigger allows the content
creator to start a corresponding <<TimeSensor>> when the
_isActive_ field generates a `TRUE` event.

[[SequencingEvents]]
==== 30.2.4 Sequencing Single Field (SF) events

Sequencer nodes allow content authors to generate a specific sequence of
discrete events over the course of a <<TimeSensor>>'s
output. They are derived from the abstract node type
_<<X3DSequencerNode>>_ and thus share the signature
fields of _set_fraction_ (SFFloat [in]) and _key_ (MFFloat [in,out]).

The _set_fraction_ inputOnly field receives an SFFloat event and causes
the sequencing function to evaluate, resulting in a _value_changed_
output event with the same timestamp as the _set_fraction_ event. The
sequencer node sends only one _value_changed_ output event per _key_[i]
interval. Such sequenced values are not interpolated. The usage of the
_keyValue_ and output fields are dependent on the type of the Sequencer.

<<BooleanSequencer>> and
<<IntegerSequencer>> output a single-value field to
_value_changed_. Each value in the _keyValue_ field corresponds in order
to the parameter value in the _key_ field. Results are undefined if the
number of values in the _key_ field of a sequencer is not the same as
the number of values in the _keyValue_ field.

The specified X3D sequencer nodes are designed for discrete events along
a timeline. Each of these nodes defines a piecewise-linear function,
_f(t)_, on the interval ( _−infinity, +infinity)_. The piecewise-linear
function is defined by _n_ values of _t_, called _key_, and the _n_
corresponding values of _f(t)_, called _keyValue_. The keys shall be
monotonically non-decreasing, otherwise the results are undefined. The
keys are not restricted to any interval.

Each of these nodes evaluates _f(t)_ given any value of _t_ (via the
_fraction_ field) as follows: Let the _n_ keys _t~0~, t~1~, t~2~, ...,
t~n-1~_ partition the domain ( _-infinity, +infinity_) into the __n+__1
subintervals given by (− _infinity_, _t~0~), [t~0~, t~1~), [t~1~, t~2~),
..., [t~n-1~, +infinity)_. Also, let the _n_ values _v~0~, v~1~, v~2~,
..., v~n-1~_ be the values of _f(t)_ at the associated key values. The
discrete value sequencing function, _f(t)_, is defined to be:

    _f(t)_ = _v~i~_ ,    if t~i~ ≤ t < t~n-1~ for 0 ≤ i < n-1; +
         = _v~i~_ ,     if t = t~i~ = t~i+1~; +
         = _v~0~_ ,    if _t ≤ t~0~_; +
         = _v~n−1~_ , if _t ≥ t~n−1~_ +

Note that if more than one key/keyValue pairs are provided for the same
key, only the first defined value for keyValue is used.


=== 30.3 Abstract types

[[X3DSequencerNode]]
==== 30.3.1 _X3DSequencerNode_

[source,node]
----
X3DSequencerNode : X3DChildNode { 
  SFBool       [in]     next
  SFBool       [in]     previous
  SFFloat      [in]     set_fraction       (-∞,∞)
  MFFloat      [in,out] key           []   (-∞,∞)
  MF<type>     [in,out] keyValue      []
  SFNode       [in,out] metadata      NULL [X3DMetadataObject]
  [S|M]F<type> [out]    value_changed
}
----

This abstract node type is the base node type from which all Sequencers
are derived. <<SequencingEvents, 30.2.4 Sequencing Single Field (SF) events>> contains a detailed discussion of Sequencer nodes.

The value of the internal _fraction_ field is initialized at the first
value of the _key_ field, or else has a value of 0 if no _key_ array is
defined.

Receipt of a _next_ event with value `TRUE` triggers the next
output value in _keyValue_ array by issuing a _value_changed_ event with
that value. Receipt of a _previous_ event with value `TRUE`
triggers previous output value in _keyValue_ array. The value of the
internal _fraction_ field is reset to match the corresponding sequential
( _next_ or _previous_) value in the _key_ array.

Sending a `FALSE` event to the _next_ or _previous_ fields has no
effect.

The _next_ or _previous_ trigger events "wrap around" after reaching the
boundary of _keyValue_ array; _i.e._, _next_ goes to initial element
after last, and _previous_ goes to last element after first.

[[X3DTriggerNode]]
==== 30.3.2 _X3DTriggerNode_

[source,node]
----
X3DTriggerNode : X3DChildNode  {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This abstract node type is the base node type from which all trigger nodes are derived.
<<TriggeringEvents, 30.2.3 Triggering events between Single Field (SF) event-types>> 
contains a detailed discussion of Triggers.


=== 30.4 Node Reference

[[BooleanFilter]]
==== 30.4.1 BooleanFilter

[source,node]
----
BooleanFilter : X3DChildNode {
  SFBool [in]     set_boolean
  SFNode [in,out] metadata    NULL [X3DMetadataObject]
  SFBool [out]    inputFalse
  SFBool [out]    inputNegate
  SFBool [out]    inputTrue
}
----

BooleanFilter filters Boolean events, allowing for selective routing of
`TRUE` or `FALSE` values and negation.

When the _set_boolean_ event is received, the BooleanFilter node
generates two events: either _inputTrue_ or _inputFalse_, based on the
Boolean value received; and _inputNegate_, which contains the negation
of the value received.

[[BooleanSequencer]]
==== 30.4.2 BooleanSequencer

[source,node]
----
BooleanSequencer : X3DSequencerNode {
  SFBool  [in]     next
  SFBool  [in]     previous
  SFFloat [in]     set_fraction
  MFFloat [in,out] key           []   (-∞,∞) 
  MFBool  [in,out] keyValue      [] 
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  SFBool  [out]    value_changed
}
----

BooleanSequencer generates sequential _value_changed_ events selected
from the _keyValue_ field when driven from a
<<TimeSensor>> clock. Among other actions, it can
enable/disable lights and sensors, or bind/unbind viewpoints and other
<<X3DBindableNode, _X3DBindableNode_>> nodes using _set_bind_ events.

The _keyValue_ field is made up of a list of `FALSE` and
`TRUE` values.

A BooleanSequencer shall be instanced for every node enabled or bound.

[[BooleanToggle]]
==== 30.4.3 BooleanToggle

[source,node]
----
BooleanToggle : X3DChildNode {
  SFBool [in]     set_boolean
  SFNode [in,out] metadata    NULL  [X3DMetadataObject]
  SFBool [in,out] toggle      FALSE 
}
----

BooleanToggle stores a Boolean value for toggling on/off. When a
_set_boolean_ `TRUE` event is received, the BooleanToggle negates
the value of the _toggle_ field and generates the corresponding
_toggle_changed_ output event. All received _set_boolean_ `FALSE`
events are ignored.

The BooleanToggle can be reset to a specific state by directly setting
the value of the inputOutput _toggle_ field. A _toggle_changed_ event is
then sent with the same value.

[[BooleanTrigger]]
==== 30.4.4 BooleanTrigger

[source,node]
----
BooleanTrigger : X3DTriggerNode {
  SFTime [in]     set_triggerTime
  SFNode [in,out] metadata        NULL [X3DMetadataObject]
  SFBool [out]    triggerTrue 
}
----

BooleanTrigger is a trigger node that generates Boolean events upon
receiving time events.

The _triggerTrue_ event is generated when the BooleanTrigger receives a
_set_triggerTime_ event. The value of _triggerTrue_ shall always be
`TRUE`.

[[IntegerSequencer]]
==== 30.4.5 IntegerSequencer

[source,node]
----
IntegerSequencer : X3DSequencerNode {
  SFBool  [in]     next
  SFBool  [in]     previous
  SFFloat [in]     set_fraction
  MFFloat [in,out] key           []   (-∞,∞) 
  MFInt32 [in,out] keyValue      []   (-∞,∞)
  SFNode  [in,out] metadata      NULL [X3DMetadataObject]
  SFInt32 [out]    value_changed
}
----

The IntegerSequencer node generates sequential discrete _value_changed_
events selected from the _keyValue_ field in response to each
_set_fraction_, _next_, or _previous_ event.

[[IntegerTrigger]]
==== 30.4.6 IntegerTrigger

[source,node]
----
IntegerTrigger : X3DTriggerNode {
  SFBool  [in]     set_boolean
  SFInt32 [in,out] integerKey   -1   (-∞,∞)
  SFNode  [in,out] metadata     NULL [X3DMetadataObject]
  SFInt32 [out]    triggerValue  
}
----

IntegerTrigger handles single _set_boolean_ input events to provide an
integer value for the output event. This is useful for connecting
environmental events such as the <<Switch>> node's
_whichChoice_ field.

The _integerKey_ field is the value that is sent if the IntegerTrigger
node receives a _set_boolean_ `TRUE` event. Resetting the value
of the _integerKey_ field itself generates corresponding
_integerKey_changed_ and _triggerValue_changed_ events that is sent with
that same value.

Upon receiving a _set_boolean_ TRUE event, the IntegerTrigger node
generates a _triggerValue_ event with the current value of _integerKey_.
The _set_boolean_ event shall only be honored if a `TRUE` value
is received.

[[TimeTrigger]]
==== 30.4.7 TimeTrigger

[source,node]
----
TimeTrigger : X3DTriggerNode {
  SFBool [in]     set_boolean
  SFNode [in,out] metadata    NULL [X3DMetadataObject]
  SFTime [out]    triggerTime
}
----

TimeTrigger is a trigger node that generates time events upon receiving
Boolean events.

The _triggerTime_ event is generated when the TimeTrigger receives a
_set_boolean_ event. The value of _triggerTime_ shall be the time at
which _set_boolean_ is received. The value of _set_boolean_ shall be
ignored.

[[S30.5_SupportLevels]]
=== 30.5 Support levels

The Event Utilities component provides one level of support as specified
in <<t30_2, Table 30.2>>. Level 1 provides the
full support for all nodes defined above.

[[t30_2]]
Table 30.2 — Event utilities
component support levels

[width="100%",cols="25%,25%,25%,25%",]
|===
|*Level* |Prerequisites |*Nodes/Features* |Support
|*1* |Core 1 +
Grouping 1 |  | 
|  | |_X3DSequencerNode_ (abstract) |All fields fully supported.
|  | |_X3DTriggerNode_ (abstract) |All fields fully supported.
|  | |BooleanFilter    |All fields fully supported.
|  | |BooleanSequencer |All fields fully supported.
|  | |BooleanToggle    |All fields fully supported.
|  | |BooleanTrigger   |All fields fully supported.
|  | |IntegerSequencer |All fields fully supported.
|  | |IntegerTrigger   |All fields fully supported.
|  | |TimeTrigger      |All fields fully supported.
|===

[[shaders_html]]
== 31 Programmable shaders component

[[S31_Introduction]]
=== 31.1 Introduction

[[S31_Name]]
==== 31.1.1 Name

The name of this component is "Shaders". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S31_Overview]]
==== 31.1.2 Overview

This clause describes the Programmable Shaders component of this
document. This includes how programmable shaders are specified and how
they affect the visual appearance of geometry. <<t31_1, Table 31.1>> provides links to the major topics in this clause.

[[t31_1]]
Table 31.1 — Topics

* <<S31Introduction, 31.1 Introduction>>
** <<S31_Name, 31.1.1 Name>>
** <<S31_Overview, 31.1.2 Overview>>
* <<S31_Concepts, 31.2 Concepts>>
** <<S31_ConceptsOverview, 31.2.1 Overview>>
** <<Shadinglanguages, 31.2.2 Shading languages>>
*** <<Shaderlanguageoptions, 31.2.2.1 Shader language options>>
*** <<Noderepresentation, 31.2.2.2 Node representation>>
*** <<Selecting, 31.2.2.3 Selecting an appropriate shader>>
*** <<Pervertexattributes, 31.2.2.4 Per-vertex attributes>>
*** <<Perobjectattributes, 31.2.2.5 Per-object attributes>>
*** <<Handlingerrors, 31.2.2.6 Handling errors>>
** <<S31_Interaction, 31.2.3 Interaction with other nodes and components>>
*** <<Interactionoverview, 31.2.3.1 Overview>>
*** <<Lighting, 31.2.3.2 Lighting>>
*** <<Geometry, 31.2.3.3 Geometry>>
*** <<S31_LoadSensor, 31.2.3.4 LoadSensor>>
** <<S31_Conformance, 31.2.4 Conformance>>
*** <<Componentsupport, 31.2.4.1 Component support>>
*** <<Nodesupport, 31.2.4.2 Node support>>
*** <<Languagesupport, 31.2.4.3 Language support>>
*** <<Scenegraphinteraction, 31.2.4.4 Scene graph interaction>>
* <<S31_AbstractTypes, 31.3 Abstract types>>
** <<X3DProgrammableShaderObject, 31.3.1 _X3DProgrammableShaderObject_>>
** <<X3DShaderNode, 31.3.2 _X3DShaderNode_>>
** <<X3DVertexAttributeNode, 31.3.3 _X3DVertexAttributeNode_>>
* <<S31_NodeReference, 31.4 Node reference>>
** <<ComposedShader, 31.4.1 ComposedShader>>
** <<FloatVertexAttribute, 31.4.2 FloatVertexAttribute>>
** <<Matrix3VertexAttribute, 31.4.3 Matrix3VertexAttribute>>
** <<Matrix4VertexAttribute, 31.4.4 Matrix4VertexAttribute>>
** <<PackagedShader, 31.4.5 PackagedShader>>
** <<ProgramShader, 31.4.6 ProgramShader>>
** <<ShaderPart, 31.4.7 ShaderPart>>
** <<ShaderProgram, 31.4.8 ShaderProgram>>
* <<S31_SupportLevels, 31.5 Support levels>>

* <<t31_1, Table 31.1 — Topics>>
* <<t31_2, Table 31.2 — Shader language node specifications>>
* <<t31_3, Table 31.3 — Shader component support levels>>




[[S31_Concepts]]
=== 31.2 Concepts

[[S31_ConceptsOverview]]
==== 31.2.1 Overview

Programmable shading provides a method for authors to directly specify
how an object is rendered by providing a method of programmatically
modifying sections of the rendering pipeline. This allows replacement of
the traditional fixed function pipeline of the graphics API to support a
variety of visual effects that typically cannot be implemented using
other node components in this standard.

Shaders are typically defined by two separate program pieces. One piece
is used to modify the vertex values. This piece may also generate values
that can be interpolated between vertex values. Such program pieces are
termed _vertex shaders_. The other piece is used to modify individual
pixels as they are drawn to screen. These program pieces are termed
_fragment shaders_ or _pixel shaders_. Although not currently defined,
future extensions may include other types of shaders that fit into other
places in the graphics pipeline.

[[Shadinglanguages]]
==== 31.2.2 Shader languages

[[Shaderlanguageoptions]]
===== 31.2.2.1 Shader language options

Shader programs can be written in several shading languages. Each
language is specific to the underlying rendering API. Typically a
language for one API ( _e.g._, Microsoft DirectX) is not usable in
another rendering API ( _e.g._, OpenGL) and therefore there is no
mandatory requirement for an X3D browser to implement any specific
language. A browser implementing this component shall be required to
support at least one shading language. The following annexes defines the
interface to three popular shader languages:

* <<shaders_glsl_html, Annex I OpenGL shading language (GLSL) binding>>
* <<shaders_hlsl_html, Annex J Microsoft High Level shading language (HLSL) binding>>
* <<shaders_cg_html, Annex K nVidia Cg shading language binding>>

Shader programs are either defined in a file that can be externally
loaded or defined internally within the X3D world. Typically, a separate
file is used to specify each type of shader (fragment or vertex)
although this is not required.

Some formats are being developed that allow all shaders to be collected
together into a single file and used directly by the rendering API. For
these file types, a separate <<PackagedShader>> node
is used. This node is independent of the underlying rendering API,
though the specific file format used within a PackagedShader node may be
specific to a particular rendering API.

[[Noderepresentation]]
===== 31.2.2.2 Node representation

Each shading language option has a node that implements its
functionality. Since each language is quite different, it is not
possible to define a single set of nodes that can represent the entire
capabilities offered. Each language has its own set of nodes that
pertain only to that shading language.

For each set of nodes for a given shading language, there are
language-specific behaviours. Mappings for each of the languages are
defined in their own annex to this document as described in
<<Shaderlanguageoptions, 31.2.2.1 Shader language options>>.
<<t31_2, Table 2>> lists the nodes and which annex shall
be used to define language-specific behaviours:

[[t31_2]]
Table 31.2 — Shader language node specifications

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Shading Language |Nodes      |Annex
|OpenGL GLSLang   |GLSLShader +
GLSLShaderObject  |<<shaders_glsl_html, Annex I>>
|Direct3D HLSL    |HLSLShader |<<shaders_hlsl_html, Annex J>>
|nVidia Cg        |CgShader   |<<shaders_cg_html, Annex K>>
|===

[[Selecting]]
===== 31.2.2.3 Selecting an appropriate shader

Browsers are not expected to be able to handle all the different forms
of shading languages. In fact, most are incompatible with any rendering
API apart from the one for which they are defined.

To allow the author to specify a collection of shader options for the
X3D browser to select and for the X3D browser to choose the shader
version it can run, a fallback mechanism is defined for the _shader_
field of the <<Appearance>> node.

The _shader_ field is an MFNode field that defines the collection of
pertinent shader nodes of various languages in the order of preference.
The first node declared is the highest preference. If the X3D browser
does not support the language defined for the current preference level,
the X3D browser shall set the node’s _isSelected_ field output to
`FALSE`, and move to the next preference. A X3D browser
implementation shall support all nodes if the Programmable Shader
component is supported, but is not required to execute the contained
script in every shader node. Ignored nodes shall remain a functional
part of the scene graph, continuing to interact with the event model as
required by the field access types.

When a shader is found that can be executed by the X3D browser, it shall
set the _isSelected_ field output to `TRUE`.

An X3D browser may select an appropriate shader on grounds other than
just the shading language used.

EXAMPLE  The local hardware not supporting some of the features
requested or the shader running in software rather than hardware are
considered valid reasons for not selecting a shader to run.

[[Pervertexattributes]]
===== 31.2.2.4 Per-vertex attributes

Advanced vertex shaders often need to provide extra information on a per
vertex basis ( _e.g._, temperature information in an analysis system or
weighting values for a skin and bones system). Per-vertex attributes may
be supplied for any geometry that extends
_<<X3DComposedGeometryNode>>_ as described in
<<X3DComposedGeometryNode, 11.3.2 X3DComposedGeometryNode>>. Both
matrix and vector values may be supplied on a per-vertex basis through
nodes that are extended from
_<<X3DVertexAttributeNode>>_.

Each shading language uses a different method of mapping per-vertex
attributes to the user-provided shading language code. The definition of
how to interpret the _name_ field value to the individual shading
language file is defined in the language-specific annex (see
<<t31_2, Table 31.2>>).

Per vertex attributes are mapped 1:1 to each vertex value. When used in
a node derived from _X3DComposedGeometryNode_, the number of values
defined in the node containing the attribute values shall be identical
to the number of coordinate values specified for the geometry node. If
the number of values does not match, the visual result is implementation
specific.

[[Perobjectattributes]]
===== 31.2.2.5 Per-object attributes

Shaders often need to provide specific per-object values ( _e.g._, the
colour of the light). The most common name for one of these values is
_uniform variable_. Uniform variables are defined using custom field
definitions that allow objects to be set as required. The placement of
these fields depends on the shading language itself, as the amount of
customizability is dependent on the shading language.

Field names shall be mapped to the shading API as the uniform variable
name of the identical name in the shader file.

NOTE  Some shading languages cannot handle the full UTF-8 character set
required by this document.

For fields of type SFNode or MFNode, the mapping to the shading language
is dependent on the individual shading language. The applicable language
binding annex specifies the required behaviour (see
<<t31_2, Table 31.2>>).

[[Handlingerrors]]
===== 31.2.2.6 Handling errors

If a shader program does not have valid syntax or the environment does
not contain enough information for the shader to render, implementations
shall track errors during all stages of the shader process and display
them to the X3D browser's console.

A shader that fails during run-time or during the compilation or
validation stages shall not run. A X3D browser shall use the rendering
API's default behaviour for this situation. If a user requires some
fallback behaviour, such as the browser not supporting the shader
capabilities requested, other nodes such as
<<LoadSensor>>, <<Script>>, and/or
<<Switch>> can be used to specify the required visual output.

[[S31_Interaction]]
==== 31.2.3 Interaction with other nodes and components

[[Interactionoverview]]
===== 31.2.3.1 Overview

Programmable shaders typically replace large amounts of functionality
that would be traditionally implemented by the X3D browser. The effect
of each shader language varies depending on the amount of processing
that the user will be required to perform. Some languages may completely
disable anything that would be automatically generated ( _e.g._, texture
coordinates or normals) while others may not. A reasonable assumption is
that everything is disabled for any geometry that has a shader
associated with it. Each language shading definition annex specifies
exactly the semantics that can be expected of the underlying rendering
API, and by implication, the X3D browser.

[[Lighting]]
===== 31.2.3.2 Lighting

If the user provides a fragment shader, the shader shall be responsible
for all lighting associated with the affected geometry. The lighting
definitions in <<lighting_html, 17 Lighting component>> shall be
ignored. Where possible, all of the lighting information such as the
currently set lights, material colours and textures shall be made
available to the shader. Some rendering APIs may not be able to make
available all of this information. In this case, it is acceptable to
provide alternative mapping hints as part of the node definition. The
individual shading language annexes contain more information (see
<<t31_2, Table 31.2>>).

[[Geometry]]
===== 31.2.3.3 Geometry

Since a vertex shader may move the vertex from its original location in
the local coordinate system, it can produce many large-scale side
effects. A major problem is that the X3D browser implementation may have
no idea where the final geometry has been placed. Any action that relies
on knowing the exact position of vertices may fail to act properly. In
particular, terrain following, collision detection and sensors can be
adversely affected.

Because a vertex may be shifted in world space, it is recommended that
if a user requires this ability, a means of giving a rough approximation
of the geometry to the X3D browser should be provided, either through
setting an explicit bounding box on the containing <<Shape>>
node or by providing the source geometry as close to the final output
shape as possible.

EXAMPLE  A fuzzy rabbit shape would start with the source vertices in
the shape of the base rabbit geometry.

[[S31_LoadSensor]]
===== 31.2.3.4 LoadSensor

A shader is considered loaded when the source for the shader program has
been downloaded successfully. A shader is considered valid when the
downloaded file has been compiled and registered with the rendering API,
which then considers it a valid object.

[[S31_Conformance]]
==== 31.2.4 Conformance

[[Componentsupport]]
===== 31.2.4.1 Component support

An implementation shall indicate support for this component if and only
if the user's particular hardware is capable of supporting this
component, either through direct hardware support or software emulation.
If the user's machine is not capable of supporting this component, the
X3D browser shall indicate a failure by stopping at the appropriate
PROFILE or COMPONENT statement of the file, in accordance with
<<PROFILEStatement, 7.2.5.3 PROFILE statement>> or
<<COMPONENTStatement, 7.2.5.4 COMPONENT statement>>.

[[Nodesupport]]
===== 31.2.4.2 Node support

A conformant X3D browser for this component shall support all the nodes
at a given level. However, a conformant X3D browser is not required to
support the corresponding shading language for that node. If a X3D
browser is not supporting the language, the nodes that provide access to
that language shall be read and ignored. These ignored nodes shall still
exist as part of the X3D scene graph, and shall still honour the X3D
event model.

EXAMPLE  Any inputOutput fields shall still be required to implement
output events if a value is written to the input.

[[Languagesupport]]
===== 31.2.4.3 Language support

A X3D browser conformant to this component shall support at least one
shading language as listed in <<t31_2, Table 31.2>>.

[[Scenegraphinteraction]]
===== 31.2.4.4 Scene graph interaction

A shader containing a vertex shader shall be required to be conformant
only to either the explicit bounding boxes or the original source
geometry definition. It is not required to obtain the output vertex
information for use within the scene graph.


=== 31.3 Abstract types

[[X3DProgrammableShaderObject]]
==== 31.3.1 _X3DProgrammableShaderObject_

[source,node]
----
X3DProgrammableShaderObject {
}
----

This abstract interface is the marker for all shader-related node types
that specify arbitrary fields for interfacing with per-object attribute
values.

A concrete _<<X3DProgrammableShaderObject>>_ node
instance is used to program behaviour for a shader in a scene. The
shader is able to receive and process events that are sent to it. Each
event that can be received shall be declared in the shader node using
the same field syntax as is used in a prototype definition:

[source,listing]
----
inputOnly    type name
----

The type can be any of the standard X3D fields (as defined in
<<fieldTypes_html, 5 Field type reference>>). The name shall be an
identifier that is unique for this shader node and is used to map the
value to the shader program's uniform variable of the same name. If a
shader program does not have a matching uniform variable, the field
value is ignored.

OutputOnly fields are not required to generate output events from a
shader. Current hardware shader technology does not support this
capability, though future versions may.

It is recommended that user-defined field or event names defined in
shader nodes follow the naming conventions described in
<<I19775_2, Part 2 of ISO/IEC 19775>>.

[[X3DShaderNode]]
==== 31.3.2 _X3DShaderNode_

[source,node]
----
X3DShaderNode : X3DAppearanceChildNode {
  SFBool   [in]     activate
  SFNode   [in,out] metadata   NULL [X3DMetadataObject]
  SFBool   [out]    isSelected
  SFBool   [out]    isValid
  SFString []       language   ""   ["Cg"|"GLSL"|"HLSL"|...]
}
----

This abstract node type is the base type for all node types that specify
a programmable shader.

The _activate_ field forces the shader to activate the contained
objects. The conditions under which an _activate_ event may be required
are described in OpenGL <<I.5_Eventmodel, I.5 Event model>>, Microsoft
High Level Shading Language (HLSL) <<J.5_Eventmodel, J.5 Event model>>,
and nVidia Cg <<K.6_Eventmodel, K.6 Event model>>.

The _isSelected_ output field is used to indicate that this shader
instance is the one selected for use by the X3D browser. A `TRUE`
value indicates that this instance is in use. A `FALSE` value
indicates that this instance is not in use. The rules for when a X3D
browser decides to select a particular node instance are described in
<<Selecting, 31.2.2.3 Selecting an appropriate shader>>.

The _isValid_ field is used to indicate whether the current shader
objects can be run as a shader program.

EXAMPLE  There are no syntax errors and the hardware can support all the
required features.

The definition of this field may also add additional semantics on a
per-language basis.

The _language_ field is used to indicate to the X3D browser which
shading language is used for the source file(s). This field may be used
as a hint for the X3D browser if the shading language is not immediately
determinable from the source ( _e.g._, a generic MIME type of
`text/plain` is returned). A X3D browser may use this field for
determining which node instance will be selected and to ignore languages
that it is not capable of supporting. Three basic language types are
defined for this document and others may be optionally supported by a
browser.

[[X3DVertexAttributeNode]]
==== 31.3.3 _X3DVertexAttributeNode_

[source,node]
----
X3DVertexAttributeNode : X3DGeometricPropertyNode {
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
  SFString []       name     "" 
}
----

This abstract node type is the base type for all node types that specify
per-vertex attribute information to the shader.

The required _name_ field describes a name that is mapped to the shading
language-specific name for describing per-vertex data. The appropriate
shader language annex (see <<t31_2, Table 31.2>>) annex
contains language-specific binding information.


=== 31.4 Node reference

[[ComposedShader]]
==== 31.4.1 ComposedShader

[source,node]
----
ComposedShader : X3DShaderNode, X3DProgrammableShaderObject {
  SFBool    [in]     activate
  SFNode    [in,out] metadata   NULL [X3DMetadataObject]
  MFNode    [in,out] parts      []   [ShaderPart]
  SFBool    [out]    isSelected
  SFBool    [out]    isValid
  SFString []        language   ""   ["Cg"|"GLSL"|"HLSL"|...]

  # And any number of:
  fieldType []       fieldName
  fieldType [in]     fieldName
  fieldType [out]    fieldName
  fieldType [in,out] fieldName
}
----

The ComposedShader node defines a shader where the individual source
files are not individually programmable. All access to the shading
capabilities is defined through a single interface that applies to all
parts.

EXAMPLE  OpenGL Shading Language (GLSL)

The _isValid_ field adds an additional semantic indicating whether the
current shader parts can be linked together to form a complete valid
shader program.

[[FloatVertexAttribute]]
==== 31.4.2 FloatVertexAttribute

[source,node]
----
FloatVertexAttribute : X3DVertexAttributeNode {
  SFNode   [in,out] metadata      NULL [X3DMetadataObject]
  MFFloat  [in,out] value         []   (-∞,∞)
  SFString []       name          ""
  SFInt32  []       numComponents 4    [1..4]
}
----

The FloatVertexAttribute node defines a set of per-vertex
single-precision floating point attributes.

The _numComponents_ field specifies how many consecutive floating point
values should be grouped together per vertex. The length of the _value_
field shall be a multiple of _numComponents_.

The _value_ field specifies an arbitrary collection of floating point
values that will be passed to the shader as per-vertex information. The
specific type mapping to the individual shading language data types is
in the appropriate language-specific annex (see <<t31_2, Table 31.2>>).

[[Matrix3VertexAttribute]]
==== 31.4.3 Matrix3VertexAttribute

[source,node]
----
Matrix3VertexAttribute : X3DVertexAttributeNode {
  SFNode     [in,out] metadata NULL [X3DMetadataObject]
  MFMatrix3f [in,out] value    []   (-∞,∞)
  SFString   []       name     ""
}
----

The Matrix3VertexAttribute node defines a set of per-vertex 3×3 matrix
attributes.

The _value_ field specifies an arbitrary collection of matrix values
that will be passed to the shader as per-vertex information. The
specific type mapping to the individual shading language data types
shall be found in the appropriate language-specific annex (see
<<t31_2, Table 31.2>>).

[[Matrix4VertexAttribute]]
==== 31.4.4 Matrix4VertexAttribute

[source,node]
----
Matrix4VertexAttribute : X3DVertexAttributeNode {
  SFNode     [in,out] metadata NULL [X3DMetadataObject]
  MFMatrix4f [in,out] value    []   (-∞,∞)
  SFString   []       name     ""
}
----

The Matrix4VertexAttribute node defines a set of per-vertex 4×4 matrix
attributes.

The _value_ field specifies an arbitrary collection of matrix values
that will be passed to the shader as per-vertex information. The
specific type mapping to the individual shading language data types
shall be found in the appropriate language-specific annex (see
<<t31_2, Table 31.2>>).

[[PackagedShader]]
==== 31.4.5 PackagedShader

[source,node]
----
PackagedShader : X3DShaderNode, X3DUrlObject, X3DProgrammableShaderObject {
  SFBool    [in]     activate
  SFTime    [in,out] autoRefresh          0.0  [0,∞)
  SFTime    [in,out] autoRefreshTimeLimit 3600.0  [0,∞)
  SFString  [in,out] description          ""
  SFBool    [in,out] load                 TRUE
  SFNode    [in,out] metadata             NULL [X3DMetadataObject]
  MFString  [in,out] url                  []   [URI]
  SFBool    [out]    isSelected
  SFBool    [out]    isValid
  SFString  []       language             ""   ["Cg"|"GLSL"|"HLSL"|...]

  # And any number of:
  fieldType [in]     fieldName
  fieldType [in,out] fieldName initialValue
  fieldType [out]    fieldName
  fieldType []       fieldName initialValue
}
----

A PackagedShader node describes a single file that may contain a number
of shaders and combined effects.

EXAMPLE  The Microsoft .fx file format represents this type of shader
(see <<FX>>).

The shader source is read from the URL specified by the _url_ field.
When the _url_ field contains no values ([]), this object instance is
ignored. The _url_ field is defined in <<URLs, 9.2.1 URLs>>.

The PackagedShader node's _url_ field shall allow for both inline
scripting and script reference via a URL. The MIME-type of the returned
data defines the language type. Additionally, instructions can be
included in-line using scripting language protocols as defined in
<<ScriptingLanguageProtocols, 9.2.3 Scripting language protocols>> for
the specific language (from which the language type is inferred).

No file formats are required to be supported for this node.

The _language_ field may be used to optionally determine the language
type if no MIME-type information is available.

If the _autoRefresh_ field results in a new script getting loaded or the
prior script getting reloaded, then all fields are re-initialized to
their initially defined values, and the _initialize()_ method is
invoked, if provided.

WARNING  Automatically reloading content can have security
considerations and needs to be considered carefully.

[[ProgramShader]]
==== 31.4.6 ProgramShader

[source,node]
----
ProgramShader : X3DShaderNode {
  SFBool   [in]     activate
  SFNode   [in,out] metadata   NULL [X3DMetadataObject]
  MFNode   [in,out] programs   []   [ShaderProgram]
  SFBool   [out]    isSelected
  SFBool   [out]    isValid
  SFString []       language   ""   ["Cg"|"GLSL"|"HLSL"|...]
}
----

The ProgramShader node defines a shader that can consist of one or more
individually programmable, self contained pieces. Each piece,
represented by a ShaderProgram node, shall be a self-contained source
that does not rely on any other source file and can manage one part of
the programmable pipeline ( _e.g._, vertex or fragment processing).

The _programs_ field consists of zero or more
<<ShaderProgram>> node instances. In general, only two
ShaderProgram instances are needed:  one each for vertex and fragment
processing. Each shader language annex shall define the required
behaviour for processing this field.

The _isValid_ field may add an additional semantic to indicate whether
all parts are available.

EXAMPLE  Microsoft's HLSL requires that both vertex and fragment
programs be provided. It specifies that it is an error to provide one
and not the other.

[[ShaderPart]]
==== 31.4.7 ShaderPart

[source,node]
----
ShaderPart : X3DNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0      [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0      [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL     [X3DMetadataObject]
  MFString [in,out] url                  []       [URI]
  SFString []       type                 "VERTEX" ["VERTEX"|"FRAGMENT"|...] 
}
----

The ShaderPart node defines a portion of source code to be used by a
<<ComposedShader>> node. The source code is not
required to be a complete shader for all of the vertex/fragment
processing.

The _type_ field indicates whether this object shall be compiled as a
vertex shader, fragment shader, or other future-defined shader type.

The shader source code is read from the URL specified by the _url_
field. When the _url_ field contains no values ( _i.e._, is an empty
list), this object instance is ignored. The _url_ field is defined in
<<URLs, 9.2.1 URLs>>. Shader source files shall be plain text encoded
as specified for MIME type `text/plain` and interpreted according
to the _type_ field.

If the _autoRefresh_ field results in a new script getting loaded or the
prior script getting reloaded, the _initialize()_ method is invoked, if
provided.

WARNING  Automatically reloading content can have security
considerations and needs to be considered carefully.

[[ShaderProgram]]
==== 31.4.8 ShaderProgram

[source,node]
----
ShaderProgram : X3DNode, X3DUrlObject, X3DProgrammableShaderObject {
  SFTime    [in,out] autoRefresh          0.0      [0,∞)
  SFTime    [in,out] autoRefreshTimeLimit 3600.0      [0,∞)
  SFString  [in,out] description          ""
  SFBool    [in,out] load                 TRUE
  SFNode    [in,out] metadata             NULL     [X3DMetadataObject]
  MFString  [in,out] url                  []       [URI]
  SFString  []       type                 "VERTEX" ["VERTEX"|"FRAGMENT"|...] 

  # And any number of:
  fieldType [in]     fieldName
  fieldType [in,out] fieldName            initialValue
  fieldType [out]    fieldName
  fieldType []       fieldName            initialValue
}
----

The ShaderProgram node provides the source and interface to a self
contained program that occupies one part of the rendering process:
either a vertex or fragment shader.

The _type_ field indicates whether this object shall be compiled as a
vertex shader, fragment shader, or other future-defined shader type.

The shader source is read from the URL specified by the _url_ field.
When the _url_ field contains no values ([]), this object instance is
ignored. The _url_ field is defined in <<URLs, 9.2.1 URLs>>. Shader
source files shall be plain text encoded as specified for MIME type
`text/plain` and interpreted according to the containing node's
language definition.

The ShaderProgram node's _url_ field shall allow for both inline
scripting and script reference via a URL. The _language_ field in the
closest parent node defines the shader language of interest,
alternatively the MIME type of the returned data defines the language
type. Additionally, instructions can be included in-line using scripting
language protocols as defined in <<ScriptingLanguageProtocols, 9.2.3 Scripting language protocols>> for the specific language (from which the
language type is inferred).

If the _autoRefresh_ field results in a new script getting loaded or the
prior script getting reloaded, then all fields are re-initialized to
their initially defined values, and the _initialize()_ method is
invoked, if provided.

WARNING  Automatically reloading content can have security
considerations and needs to be considered carefully.

[[S31.5_SupportLevels]]
=== 31.5 Support levels

The Programmable Shaders component defines a single level of support as
specified in <<t31_3, Table 31.3>>.

[[t31_3]]
Table 31.3 — Programmable shaders component support
levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | |
| | |_X3DProgrammableShaderObject_ |n/a
| | |_X3DShaderNode_ |n/a
| | |_X3DVertexAttributeNode_ |n/a
| | |ComposedShader           |All fields fully supported.
| | |FloatVertexAttribute     |All fields fully supported.
| | |Matrix3VertexAttribute   |All fields fully supported.
| | |Matrix4VertexAttribute   |All fields fully supported.
| | |PackagedShader           |All fields fully supported.
| | |ProgramShader            |All fields fully supported.
| | |ShaderPart               |All fields fully supported.
| | |ShaderProgram            |All fields fully supported.
|===

[[CADGeometry_html]]
== 32 CADGeometry component

[[S32_Introduction]]
=== 32.1 Introduction

[[S32_Name]]
==== 32.1.1 Name

The name of this component is "CADGeometry". The CADGeometry component
provides X3D support for Computer-Aided Design (CAD) model geometry.
This name shall be used when referring to this component in the
COMPONENT statement (see <<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S32_Overview]]
==== 32.1.2 Overview

This clause describes the CADGeometry component of this documentE. This
includes how 3D geometry is specified and what shapes are available.
<<t32_1, Table 32.1>> provides links to the major topics in this
clause.

[[t32_1]]
Table 32.1 — Topics

* <<S32Introduction, 32.1 Introduction>>
** <<S32_Name, 32.1.1 Name>>
** <<S32_Overview, 32.1.2 Overview>>
* <<S32_Concepts, 32.2 Concepts>>
** <<S32_OverviewOfGeometry, 32.2.1 Overview of CAD geometry>>
** <<ProductStructure, 32.2.2 Product Structure Nodes>>
** <<CADLayerRelationships, 32.2.3 CAD layer relationships>>
** <<QuadNodes, 32.2.4 Quad nodes>>
** <<S32_CommonGeometryFields, 32.2.5 Common geometry fields>>
* <<S32_AbstractTypes, 32.3 Abstract Types>>
** <<X3DProductStructureChildNode, 32.3.1 _X3DProductStructureChildNode_>>
* <<S32_NodeReference, 32.4 Node reference>>
** <<CADAssembly, 32.4.1 CADAssembly>>
** <<CADFace, 32.4.2 CADFace>>
** <<CADLayer, 32.4.3 CADLayer>>
** <<CADPart, 32.4.4 CADPart>>
** <<IndexedQuadSet, 32.4.5 IndexedQuadSet>>
** <<QuadSet, 32.4.6 QuadSet>>
* <<S32_SupportLevels, 32.5 Support levels>>

* <<f-QuadSet, Figure 32.1 — QuadSet>>

* <<t32_1, Table 32.1 — Topics>>
* <<t32_2, Table 32.2 — CADGeometry component support levels>>




[[S32_Concepts]]
=== 32.2 Concepts

[[S32_OverviewOfGeometry]]
==== 32.2.1 Overview of geometry

The CADGeometry component consists of two types of nodes: product
structure nodes and quad geometry nodes. Together, these node types are
used to describe CAD-specific data representations for X3D worlds.

[[ProductStructure]]
==== 32.2.2 Product structure nodes

Three nodes maintain CAD structural relationships. These nodes define
the shape of a tangible object. Additional content may be grouped with
these nodes using the CADLayer node. These nodes are, in hierarchy
order:

[loweralpha]
. <<CADAssembly>> represents a product assembly composed
of subassemblies and parts.
. <<CADPart>> is a physical object with a defined shape. It
is composed of CADFace nodes which represent the spatial boundary of the
object.
. <<CADFace>> contains a single Shape node defining one face
of CADPart.

This hierarchy structures the file in a way that facilitates reuse of
the CAD data in different domains.

[[CADLayerRelationships]]
==== 32.2.3 CAD layer relationships

The CADLayer node allows CADAssembly and CADPart nodes to be grouped
together to model relationship beyond assembly structure. It also allows
additional content beyond physical shape to be grouped with CADAssembly
and CADPart nodes. This additional content may include:

* Text nodes containing annotations and dimension information.
* Shape nodes representing abstract geometric relations such as
tolerance data and features.

[[QuadNodes]]
==== 32.2.4 Quad nodes

Quad nodes represent collections of planar quadrilateral polygons. The
<<IndexedQuadSet>> node specifies the vertices using
indices while the <<QuadSet>> node specifies the vertices
directly.

NOTE  Self-intersecting quadrilaterals are ill specified and rendering
results are undefined.

[[S32_CommonGeometryFields]]
==== 32.2.5 Common geometry fields

Several 3D CADGeometry nodes share common fields to describe attributes.
These fields that specify the vertex ordering and whether the shape is
solid are named _ccw_ and _solid_ respectively. Common 3D geometry
fields are described in <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>.


=== 32.3 Abstract types

[[X3DProductStructureChildNode]]
==== 32.3.1 _X3DProductStructureChildNode_

[source,node]
----
X3DProductStructureChildNode : X3DChildNode {
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
  SFString [in,out] name     ""
}
----

The _X3DProductStructureChildNode_ abstract node type marks nodes that
are valid product structure children.


=== 32.4 Node reference

[[CADAssembly]]
==== 32.4.1 CADAssembly

[source,node]
----
CADAssembly : X3DGroupingNode, X3DProductStructureChildNode {
  MFNode   [in]     addChildren
  MFNode   [in]     removeChildren
  MFNode   [in,out] children       []       [X3DChildNode]
  SFBool   [in,out] bboxDisplay    FALSE
  SFNode   [in,out] metadata       NULL     [X3DMetadataObject]
  SFString [in,out] name           ""
  SFBool   [in,out] visible        TRUE
  SFVec3f  []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f  []       bboxSize       -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The CADAssembly node holds a set of assemblies or parts grouped
together.

The _children_ field can contain <<X3DChildNode, _X3DChildNode_>>
types.

The _name_ field specifies the name of the CADAssembly.

[[CADFace]]
==== 32.4.2 CADFace

[source,node]
----
CADFace : X3DProductStructureChildNode, X3DBoundedObject {
  SFNode   [in,out] metadata    NULL     [X3DMetadataObject]
  SFBool   [in,out] bboxDisplay FALSE
  SFString [in,out] name        ""
  SFNode   [in,out] shape       NULL     [Shape|LOD|Transform]
  SFBool   [in,out] visible     TRUE
  SFVec3f  []       bboxCenter  0 0 0    (-∞, ∞)
  SFVec3f  []       bboxSize    -1 -1 -1 [0, ∞) or -1 -1 -1
}
----

The CADFace node holds the geometry representing a face of a part.

The _name_ field specifies the name of the CADFace.

The _shape_ field contains the <<Shape>> node providing the
geometry and appearance for the face, or a <<Transform>>
node relocating its children, or an <<LOD>> node containing
different detail levels of the shape. If an LOD node is provided, each
child of the LOD node shall be a single Shape of varying complexity or
another Transform node. If a Transform node is provided, each child of
the Transform node shall be a single Shape or another Transform or LOD
node. In any case, only zero or one Shape under the CADFace node shall
be active at any time.

[[CADLayer]]
==== 32.4.3 CADLayer

[source,node]
----
CADLayer : X3DGroupingNode {
  MFNode   [in]     addChildren
  MFNode   [in]     removeChildren
  MFNode   [in,out] children       []       [X3DChildNode]
  SFBool   [in,out] bboxDisplay    FALSE
  SFNode   [in,out] metadata       NULL     [X3DMetadataObject]
  SFString [in,out] name           ""
  SFBool   [in,out] visible        TRUE
  SFVec3f  []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f  []       bboxSize       -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The CADLayer node defines a hierarchy of nodes used for showing layer
structure for the CAD model.

The _name_ field describes the content of the layer.

The _children_ field contains all nodes defined for this layer.

[[CADPart]]
==== 32.4.4 CADPart

[source,node]
----
CADPart : X3DGroupingNode, X3DProductStructureChildNode {
  MFNode     [in]     addChildren
  MFNode     [in]     removeChildren
  SFVec3f    [in,out] center           0 0 0    (-∞,∞)
  MFNode     [in,out] children         []       [CADFace]
  SFBool     [in,out] bboxDisplay      FALSE
  SFNode     [in,out] metadata         NULL     [X3DMetadataObject]
  SFString   [in,out] name             ""
  SFRotation [in,out] rotation         0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] scale            1 1 1    (0,∞)
  SFRotation [in,out] scaleOrientation 0 0 1 0  [-1,1] or (-∞,∞)
  SFVec3f    [in,out] translation      0 0 0    (-∞,∞)
  SFBool     [in,out] visible          TRUE
  SFVec3f    []       bboxCenter       0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize         -1 -1 -1 [0,∞) or −1 −1 −1
}
----

The CADPart node is a grouping node that defines a coordinate system for
its children that is relative to the coordinate systems of its
<<S4_TransformationHierarchy, 4.3.5 Transformation hierarchy>> and 
coordinate system] for a description of coordinate systems and
transformations.

The CADPart node represents the location and faces that constitute a
part in the CAD model.

<<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>
provides a description of the _children_, _addChildren_, and
_removeChildren_ fields.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the children of the Part node. This is a hint that may be used
for optimization purposes. The results are undefined if the specified
bounding box is smaller than the actual bounding box of the children at
any time. A default _bboxSize_ value, (-1, -1, -1), implies that the
bounding box is not specified and, if needed, shall be calculated by the
X3D browser. The bounding box shall be large enough at all times to
enclose the union of the group's children's bounding boxes; it shall not
include any transformations performed by the group itself ( _i.e._, the
bounding box is defined in the local coordinate system of the children).

The _translation_, _rotation_, _scale_, _scaleOrientation_ and _center_
fields define a geometric 3D transformation consisting of (in order):

[loweralpha]
. a (possibly) non-uniform scale about an arbitrary point;
. a rotation about an arbitrary point and axis;
. a translation.

The _center_ field specifies a translation offset from the origin of the
local coordinate system (0,0,0). The _rotation_ field specifies a
rotation of the coordinate system. The _scale_ field specifies a
non-uniform scale of the coordinate system. The _scale_ field may have
values that are positive, negative (indicating a reflection), or zero. A
value of zero indicates that any child geometry shall not be displayed.
The _scaleOrientation_ specifies a rotation of the coordinate system
before the scale (to specify scales in arbitrary orientations). The
_scaleOrientation_ applies only to the scale operation. The
_translation_ field specifies a translation to the coordinate system.

Given a 3-dimensional point *P* and Part node, *P* is transformed into
point *P'* in its parent's coordinate system by a series of intermediate
transformations. In matrix transformation notation, where C ( _center_),
SR ( _scaleOrientation_), T ( _translation_), R ( _rotation_), and S (
_scale_) are the equivalent transformation matrices,

[source,listing]
----
  P' = T * C * R * SR * S * -SR * -C * P
----

The following Part node:

[source,listing]
----
CADPart {
  center           C
  rotation         R
  scale            S
  scaleOrientation SR
  translation      T
  children         [...]
}
----

is equivalent to the nested sequence of:

[source,listing]
----
CADPart {
  translation T
  children CADPart {
    translation C
    children CADPart {
      rotation R
      children CADPart {
        rotation SR
        children CADPart {
          scale S
          children CADPart {
            rotation -SR
            children CADPart {
              translation -C
              children [...]
}}}}}}}
----

The name field documents the name of this part.

[[IndexedQuadSet]]
==== 32.4.5 IndexedQuadSet

[source,node]
----
IndexedQuadSet : X3DComposedGeometryNode {
  MFInt32 [in]     set_index       []   [0,∞)
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
  MFInt32 []       index           []   [0,∞)
}
----

The IndexedQuadSet node specifies a 3D shape consisting of a collection
of individual planar quadrilaterals (quads) as depicted in
<<f-QuadSet, Figure 32.1>>. IndexedQuadSet uses the indices in its
_index_ field to specify the vertices of each quad from the _coord_
field. Each quad is formed from a set of four vertices of the
_<<X3DCoordinateNode>>_ node identified by four
consecutive indices from the index field. If the _index_ field does not
contain a multiple of four coordinate values, the remaining vertices
shall be ignored.

The IndexedQuadSet node is specified in the local coordinate system and
is affected by the transformations of its ancestors. Descriptions of the
_color_, _coord_, _normal_, and _texCoord_ fields are provided in the
_<<X3DColorNode>>_, _X3DCoordinateNode_, _<<X3DNormalNode>>_, and
<<X3DTextureCoordinateNode>> nodes,
respectively. If values are provided for the _color_, _normal_ and
_texCoord_ fields, the values are applied in the same manner as the
values from the _coord_ field and there shall be at least as many values
as are present in the _coord_ field. The value of the _colorPerVertex_
field is ignored and always treated as `TRUE`. If the _normal_
field is not supplied, normals shall be generated as follows:

* If _normalPerVertex_ is `TRUE`, the normal at each vertex shall
be the average of the normals for all quads that share that vertex.
* If _normalPerVertex_ is `FALSE`, the normal at each vertex
shall be perpendicular to the face for that quad.

The _solid_ field determines whether the IndexedQuadSet is visible when
viewed from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>> provides a complete description of the _solid_ field.

[[QuadSet]]
==== 32.4.6 QuadSet

[source,node]
----
QuadSet : X3DComposedGeometryNode {
  MFNode  [in,out] attrib          []   [X3DVertexAttributeNode]
  SFNode  [in,out] color           NULL [X3DColorNode]
  SFNode  [in,out] coord           NULL [X3DCoordinateNode]
  SFNode  [in,out] fogCoord        NULL [FogCoordinate]
  SFNode  [in,out] metadata        NULL [X3DMetadataObject]
  SFNode  [in,out] normal          NULL [X3DNormalNode]
  SFNode  [in,out] texCoord        NULL [X3DTextureCoordinateNode]
  SFBool  []       ccw             TRUE
  SFBool  []       colorPerVertex  TRUE
  SFBool  []       normalPerVertex TRUE
  SFBool  []       solid           TRUE
}
----

The QuadSet node specifies a 3D shape consisting of a collection of
individual planar quadrilaterals.

The _coord_ field contains an <<X3DCoordinateNode>>
node that defines the 3D vertices that define the quad. Each quad is
formed from a consecutive set of four vertices of the coordinate node.
If the coordinate node does not contain a multiple of four coordinate
values, the remaining vertices shall be ignored.

<<f-QuadSet, Figure 32.1>> depicts a QuadSet node with two quads. The
ordering of the vertices is also shown.

[[f-QuadSet]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/quadSet.png[QuadSet]

Figure 32.1 — QuadSet node

The QuadSet node is specified in the local coordinate system and is
affected by the transformations of its ancestors. Descriptions of the
_color, coord_, _normal_, and _texCoord_ fields are provided in the
_<<X3DColorNode>>_, _X3DCoordinateNode_, _<<X3DNormalNode>>_, and
<<X3DTextureCoordinateNode>> nodes,
respectively. If values are provided for the _color_, _normal_, and
_texCoord_ fields, there shall be at least as many values as are present
in the _coord_ field. The value of the _colorPerVertex_ field is ignored
and always treated as  `TRUE`. If the _normal_ field is not
supplied, the normal shall be generated as perpendicular to the face for
either version of _normalPerVertex_.

The _solid_ field determines whether the QuadSet is visible when viewed
from the inside. <<S11_CommonGeometryFields, 11.2.3 Common geometry fields>>
provides a complete description of the _solid_ field.

[[S32.5_SupportLevels]]
=== 32.5 Support levels

The CADGeometry component provides two levels of support as specified in
<<t32_2, Table 32.2>>. Level 1 provides quad support. Level 2 adds support
to describe product structure and layers.

[[t32_2]]
Table 32.2 — CADGeometry component support levels

[width="100%",cols="25%,25%,25%,25%",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Rendering 1 +
Shape 1 | |
| | |_X3DProductStructureChildNode_ (abstract) |n/a
| | |IndexedQuadSet |All fields fully supported.
| | |QuadSet        |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Rendering 1 +
Shape 1 | |
| | |CADAssembly    |All fields fully supported.
| | |CADFace        |All fields fully supported.
| | |CADLayer       |All fields fully supported.
| | |CADPart        |All fields fully supported.
|===

[[texture3D_html]]
== 33 Texturing3D component

[[S33_Introduction]]
=== 33.1 Introduction

[[S33_Name]]
==== 33.1.1 Name

The name of this component is "Texturing3D". This name shall be used
when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S33_Overview]]
==== 33.1.2 Overview

This clause describes the Texturing3D component of this document.
<<t33_1, Table 33.1>> provides links to the major topics in this
clause.

[[t33_1]]
Table 33.1 — Topics

* <<S33Introduction, 33.1 Introduction>>
** <<S33_Name, 33.1.1 Name>>
** <<S33_Overview, 33.1.2 Overview>>
* <<S33_Concepts, 33.2 Concepts>>
** <<S33_ConceptsOverview, 33.2.1 Overview>>
** <<S3DTextureconcepts, 33.2.2 3D texturing concepts>>
** <<S33_TextureCoordinates, 33.2.3 Texture coordinates>>
** <<Texturecoordinategeneration, 33.2.4 Texture coordinate generation for primitive objects>>
** <<S33_Texturemapimageformats, 33.2.5 Texture map image formats>>
* <<X3DTexture3DNode, 33.3 Abstract types>>
** <<X3DTexture3DNode, 33.3.1 _X3DTexture3DNode_>>
* <<S33_NodeReference, 33.4 Node reference>>
** <<ComposedTexture3D, 33.4.1 ComposedTexture3D>>
** <<ImageTexture3D, 33.4.2 ImageTexture3D>>
** <<PixelTexture3D, 33.4.3 PixelTexture3D>>
** <<TextureCoordinate3D, 33.4.4 TextureCoordinate3D>>
** <<TextureCoordinate4D, 33.4.5 TextureCoordinate4D>>
** <<TextureTransform3D, 33.4.6 TextureTransform3D>>
** <<TextureTransformMatrix3D, 33.4.7 TextureTransformMatrix3D>>
* <<S33_SupportLevels, 33.5 Support levels>>

* <<f-3DTexture, Figure 33.1 — Illustration of how two 2D images can form a 3D volume of texture>>

* <<t33_1, Table 33.1 — Topics>>
* <<t33_2, Table 33.2 — Texturing component support levels>>




[[S33_Concepts]]
=== 33.2 Concepts

[[S33_ConceptsOverview]]
==== 33.2.1 Overview

This component provides additional texturing extensions to the basic
capabilities defined in X3D. Many applications need to describe surface
properties as data points in a volume of space, rather than a flat
surface. These textures operate with three dimensions. A texture of this
type is termed a _volumetric texture_.

Volumetric textures are essential for advanced rendering effects related
to fog and lighting, as well as industry-specific needs such as medical
and CAD visualization.

[[S3DTextureconcepts]]
==== 33.2.2 3D texturing concepts

3D texturing specifies texel colours based on a volume of space. An
object that is being rendered on that 3D texture effectively cuts a
volume out of the texels provided by the texture.

This document assumes standard commodity hardware that presents 3D
textures as a series of 2D slices of the volume that can then be
interpolated and composited together to form a 3D volume of space. There
is no assumption about the existence of true voxel rendering hardware
capability.

A 3D volume of texture is specified as a number of 2D planes (images) of
data that are ordered in a depth-wise manner. <<f-3DTexture, Figure 33.1>> shows two base images that can be layered together resulting in
the volume of a 3D texture. In this example, the texture would have a
dimension of n × m × 2.

[[f-3DTexture]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/3d_textures.png[Description of 3D texture,width=538,height=343]

Figure 33.1 — Formation of 3D texture from two 2D textures

[[S33_TextureCoordinates]]
==== 33.2.3 Texture coordinates

The coordinate system of the texture is a right-handed coordinate system
as shown in <<f-3DTexture, Figure 33.1>>. The coordinate components
are defined to be (r,s,t) as values along the R, S, and T axes, as
depicted in <<f-3DTexture, Figure 33.1>>.

[[Texturecoordinategeneration]]
==== 33.2.4 Texture coordinate generation for primitive objects

Some geometry nodes are not capable of having 3D texture coordinates set
by the user ( _e.g._, Box and Cone). For these cases, 3D textures
coordinates are automatically generated based on the following rules:

[loweralpha]
. All coordinates are generated in the range [0, 1] for the given axis.
0 is for the minimum value of the coordinate vertex on that axis, and 1
is assigned to the maximum value of the coordinate vertex on that axis.
. Orientation is oriented along the z-axis, looking in the -Z direction
with a zero angle aligned with the axis.
. S coordinate is generated from left to right based on the maximum
extents of the X-axis vertex values.
. T coordinate is generated from top to bottom based on the maximum
extents of the Y-axis vertex values.
. R coordinate is generated from front (+Z) to back (-Z) based on the
maximum extents of the Z-axis vertex values.

The _default 3D texture coordinate generation_ described above is
performed only when the _Appearance.texture_ contains a node derived
from _X3DTexture3DNode_, or when it contains _MultiTexture_ and the
first child of it is _X3DTexture3DNode_. In particular, it means that
using 3D texture has no effect on the default texture coordinate
generation algorithm when this 3D texture is used:

* as a non-first child of _MultiTexture_, which is then placed in
_Appearance.texture_
* as a texture referenced by a material field, like
_Material.diffuseTexture_

In the above two cases, the _default coordinate generation_ still
follows the standard algorithm (described at each particular geometry
node, best suited for 2D textures). The reason for this is that a node
may use multiple textures, both 3D and 2D, and in the above cases it's
impossible for the X3D browser to know which texture generation scheme
(best suited for 3D or 2D texture) is a better default.

[[S33_Texturemapimageformats]]
==== 33.2.5 Texture map image formats

Node types specifying 3D texture maps may supply data with a number of
color components between one and four. The valid types and
interpretations of 3D textures are identical to that for 2D textures.
The definition of texture formats is defined in
<<TextureMapFormats, 18.2.1 Texture map formats>>.


=== 33.3 Abstract types

[[X3DTexture3DNode]]
==== 33.3.1 _X3DTexture3DNode_

[source,node]
----
X3DTexture3DNode : X3DSingleTextureNode {
  SFString [in,out] description       ""
  SFNode   [in,out] metadata          NULL  [X3DMetadataObject]
  SFBool   []       repeatR           FALSE
  SFBool   []       repeatS           FALSE
  SFBool   []       repeatT           FALSE
  SFNode   []       textureProperties NULL  [TextureProperties]
}  
----

This abstract node type is the base type for all node types that specify
3D sources for texture images.

NOTE  The base node type diverges from the standard X3D textures by
making the default repeat modes `FALSE`, rather than `TRUE`.
This is because 3D textures are almost never used in a repeated
rendering mode, and because repeat mode  `TRUE` for 3D textures
can produce odd rendering artifacts.


=== 33.4 Node reference

[[ComposedTexture3D]]
==== 33.4.1 ComposedTexture3D

[source,node]
----
ComposedTexture3D : X3DTexture3DNode {
  SFString [in,out] description       ""
  SFNode   [in,out] metadata          NULL  [X3DMetadataObject]
  MFNode   [in,out] texture           []    [X3DTexture2DNode]
  SFBool   []       repeatR           FALSE
  SFBool   []       repeatS           FALSE
  SFBool   []       repeatT           FALSE
  SFNode   []       textureProperties NULL  [TextureProperties]
}
----

The ComposedTexture3D node defines a 3D image-based texture map as a 
collection of 2D texture sources at various depths and parameters
controlling tiling repetition of the texture onto geometry.

The texture values are interpreted with the first image being at depth 0
and each following image representing an increasing depth value in the R
direction. A user shall provide 2^n^ source textures in this array. The
individual source textures will ignore their _repeat_ field values.

See <<S33_Concepts, 33.2 Concepts>>, for a general description of texture
maps.

See <<texturing_html, 18 Texturing component>> for a general
description of the _<<X3DTexture2DNode>>_ abstract
type and interpretation of rendering for 2D images. When used as a
source for cubic environment maps, the fields _repeatS_ and _repeatT_
fields shall be ignored.

[[ImageTexture3D]]
==== 33.4.2 ImageTexture3D

[source,node]
----
ImageTexture3D : X3DTexture3DNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0    [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0 [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL   [X3DMetadataObject]
  MFString [in,out] url                  []     [URI]
  SFBool   []       repeatR              FALSE
  SFBool   []       repeatS              FALSE
  SFBool   []       repeatT              FALSE
  SFNode   []       textureProperties    NULL   [TextureProperties]
}
----

The ImageTexture3D node defines a texture map by specifying a single
image file that contains complete 3D data and general parameters for
mapping texels to geometry.

The texture is read from the URL specified by the _url_ field. When the
_url_ field contains no values ([]), texturing is disabled. The _url_
field is defined in <<URLs, 9.2.1 URLs, URNs and URIs>>. While
there are no required file formats, it is recommended that one of the
following formats be supported:

[loweralpha]
. DDS (see <<DDS>>),h
. DICOM (see <<DICOM, 2.[DICOM>>]),
. NRRD (see <<NRRD>>), and/or
. .vol (see <<VOL>>).

See <<S33_Concepts, 33.2 Concepts>> for a general description of texture
maps.

[[PixelTexture3D]]
==== 33.4.3 PixelTexture3D

[source,node]
----
PixelTexture3D : X3DTexture3DNode {
  SFString [in,out] description       ""
  MFInt32  [in,out] image             [0 0 0 0]
  SFNode   [in,out] metadata          NULL      [X3DMetadataObject]
  SFBool   []       repeatR           FALSE
  SFBool   []       repeatS           FALSE
  SFBool   []       repeatT           FALSE
  SFNode   []       textureProperties NULL      [TextureProperties]
}
----

The PixelTexture3D node defines a 3D image-based texture map as an
explicit array of pixel values (image field) and parameters controlling
tiling repetition of the texture onto geometry.

The _image_ field describes the raw data to be used for this 3D texture.
The first value of the array is the number of components to the image
and shall be a value between 0 and 4. The following three numbers are
the size of the texture: width, height and depth, respectively. The
remaining values of the array are treated as the pixels for the image.
There shall be at least width × height × depth number of pixel values
provided. Each of the width, height and depth values is required to be a
power of two.

See <<S33_Concepts, 33.2 Concepts>> for a general description of 3D
texture maps.

See <<lighting_html, 17 Lighting component>> for a description of how
the texture values interact with the appearance of the geometry.
<<SFImage, 5.7 SFImage and MFImage>> describes the specification of an
image.

[[TextureCoordinate3D]]
==== 33.4.4 TextureCoordinate3D#

[source,node]
----
TextureCoordinate3D : X3DSingleTextureCoordinateNode {
  SFString [in,out] mapping  ""
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
  MFVec3f  [in,out] point    []   (-∞,∞)
}
----

The TextureCoordinate3D node is a geometry property node that specifies
a set of 3D texture coordinates used by vertex-based geometry nodes ( _e.g._, 
<<IndexedFaceSet>> and <<ElevationGrid>>) to map 3D textures to vertices.

Providing 3D texture coordinates to objects that only have 2D textures
defined shall result in implementation dependent rendering.

[[TextureCoordinate4D]]
==== 33.4.5 TextureCoordinate4D#

[source,node]
----
TextureCoordinate4D : X3DSingleTextureCoordinateNode {
  SFString [in,out] mapping  ""
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
  MFVec4f  [in,out] point    []   (-∞,∞)
}
----

The TextureCoordinate4D node is a geometry property node that specifies
a set of 4D (homogeneous 3D) texture coordinates used by vertex-based
geometry nodes ( _e.g._, <<IndexedFaceSet>> and
<<ElevationGrid>>) to map 3D textures to vertices.

Providing 4D texture coordinates to objects that only have 2D textures
defined shall result in implementation dependent rendering.

[[TextureTransform3D]]
==== 33.4.6 TextureTransform3D#

[source,node]
----
TextureTransform3D : X3DSingleTextureTransformNode {
  SFVec3f    [in,out] center      0 0 0   (-∞,∞)
  SFString   [in,out] mapping     ""
  SFNode     [in,out] metadata    NULL    [X3DMetadataObject]
  SFRotation [in,out] rotation    0 0 1 0 (-∞,∞)
  SFVec3f    [in,out] scale       1 1 1   (-∞,∞)
  SFVec3f    [in,out] translation 0 0 0   (-∞,∞)
}
----

The TextureTransform3D node specifies a 3D transformation that is
applied to texture coordinates (see <<TextureCoordinate3D, 33.4.4 TextureCoordinate3D>>). This node affects the way texture coordinates are
applied to the geometric surface. The transformation consists of (in
order):

[loweralpha]
. a translation;
. a rotation about the centre point; and
. a non-uniform scale about the centre point.

These parameters support changes to the size, orientation, and position
of textures on shapes. These operations appear reversed when viewed on
the surface of geometry.

EXAMPLE  A scale value of (1 2 2) will scale the texture coordinates and
have the net effect of shrinking the texture size by a factor of 2
(texture coordinates are twice as large and thus cause the texture to
repeat) in the T and R dimensions and leave the S dimension unscaled. A
translation of (0.5 0.0 0.0) translates the texture coordinates +0.5
units along the S-axis and has the net effect of translating the texture
-0.5 along the S-axis on the geometry's surface. A rotation of
π/2 of the texture coordinates results in a -π/2
rotation of the texture on the geometry.

The _center_ field specifies a translation offset in texture coordinate
space about which the _rotation_ and _scale_ fields are applied. The
_scale_ field specifies a scaling factor in S, T and R of the texture
coordinates about the center point. All _scale_ values shall be in the
range (-∞,∞). The _rotation_ field specifies a rotation of the texture
coordinates about the center point after the scale has been applied. A
positive rotation value makes the texture coordinates rotate
counterclockwise about the centre, thereby rotating the appearance of
the texture itself clockwise. The _translation_ field specifies a
translation of the texture coordinates.

A 3D transform may be applied to 2D textures. The results are
implementation dependent.

[[TextureTransformMatrix3D]]
==== 33.4.7 TextureTransformMatrix3D#

[source,node]
----
TextureTransformMatrix3D : X3DSingleTextureTransformNode {
  SFString   [in,out] mapping     ""
  SFMatrix4f [in,out] matrix      1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1  (-∞,∞)
  SFNode     [in,out] metadata    NULL    [X3DMetadataObject]
}
----

The _matrix_ field specifies a generalized, unfiltered 4×4
transformation matrix that can be used to modify the texture. Any set of
values is permitted.

[[S33.5_SupportLevels]]
=== 33.5 Support levels

The 3D Texturing component defines two levels of support as specified in
<<t33_2, Table 33.2>>.

[[t33_2]]
Table 33.2 — 3D texturing component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 | |
| | |_X3DTexture3DNode_       |n/a
| | |TextureTransformMatrix3D |All fields fully supported.
| | |TextureTransform3D       |All fields fully supported.
| | |TextureCoordinate3D      |All fields fully supported.
| | |TextureCoordinate4D      |All fields fully supported.
| | |ComposedTexture3D        |All fields fully supported.
| | |PixelTexture3D           |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 | |
| | |ImageTexture3D           |All fields fully supported.
|===

[[environmentalTexturing_html]]
== 34 Cube map environmental texturing component

[[S34_Introduction]]
=== 34.1. Introduction

[[S34_Name]]
==== 34.1.1 Name

The name of this component is "CubeMapTexturing". This name shall be
used when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 COMPONENT statement>>).

[[S34_Overview]]
==== 34.1.2 Overview

This clause describes the cube map environmental texturing component of
this part of ISO/IEC 19775. This includes how additional texturing
effects are defined to produce environmental effects such as reflections
from objects. <<t34_1, Table 34.1>> provides lists the major topics
in this clause.

[[t34_1]]
Table 34.1 — Topics

* <<S34Introduction, 34.1 Introduction>>
** <<S34_Name, 34.1.1 Name>>
** <<S34_Overview, 34.1.2 Overview>>
* <<S34_Concepts, 34.2 Concepts>>
** <<S34_ConceptsOverview, 34.2.1 Overview>>
** <<Texturemapformats, 34.2.2 Texture map formats>>
** <<S34_Texturemapimageformats, 34.2.3 Texture map image formats>>
** <<S34_TextureCoordinates, 34.2.4 Texture coordinates>>
** <<Textureorientation, 34.2.5 Texture orientation>>
* <<S34_AbstractTypes, 34.3 Abstract types>>
** <<X3DEnvironmentTextureNode, 34.3.1 _X3DEnvironmentTextureNode_>>
* <<S34_NodeReference, 34.4. Node reference>>
** <<ComposedCubeMapTexture, 34.4.1 ComposedCubeMapTexture>>
** <<GeneratedCubeMapTexture, 34.4.2 GeneratedCubeMapTexture>>
** <<ImageCubeMapTexture, 34.4.3 ImageCubeMapTexture>>
* <<S34_SupportLevels, 34.5 Support levels>>

* <<f-Textureorientation, Figure 34.1 — Mapping texture sides to the texture coordinate axes>>

* <<t34_1, Table 34.1 — Topics>>
* <<t34_2, Table 34.2 — Environment Texturing component support levels>>




[[S34_Concepts]]
=== 34.2 Concepts

[[S34_ConceptsOverview]]
==== 34.2.1 Overview

Cube map environmental texturing provides cubic environmental texture
mapping capabilities within X3D. Cubic environment maps support
reflection and specular highlighting in a simple way, often in
combination with automatic texture coordinate generation (see
<<S18_TextureCoordinates, 18.2.3 Texture coordinates>>). This component
may be combined with the multitexture abilities of the Texturing
component (see <<Multitexturing, 18.2.4 Multitexturing>>) to provide
advanced visual effects.

Cubic environment maps ignore most of the normal texture settings  (
_e.g._, there are no repeat fields) but they can be mipmapped. The
sources can be drawn from any 2D texture source whether dynamically
generated or provided from somewhere else as images or pixel arrays.

[[Texturemapformats]]
==== 34.2.2 Texture Map Formats

Cubic environment mapping nodes defined as part of this component use a
collection of 2D texture maps to define each side of the cube. These may
contain from one to four component colour values. The interpretation of
the image shall follow the description in <<TextureMapFormats, 18.2.1 Texture map formats>>.

All source images shall be square and provide source data in powers of
two numbers of pixels. Source images in a cubic environment map shall
have identical sizes. Providing differently sized images or rectangular
images shall be an error.

EXAMPLE  It is not valid to define the front image as a 64×64 image and
the left side image as 128×128 pixels.

[[S34_Texturemapimageformats]]
==== 34.2.3 Texture Map Image Formats

Texture nodes that require support for 2D images file formats shall
follow the description defined in <<TextureMapImageFormats, 18.2.2 Texture map image formats>>.

[[S34_TextureCoordinates]]
==== 34.2.4 Texture coordinates

For each texture, the three-dimensional texture coordinates (s,t,r) are
treated as a direction vector from the local origin. Each texel drawn
onto the geometry is treated as the texel in the environment map that is
"seen" from this direction vector.

Texture coordinates for using cubic environment mapped textures are
usually dynamically generated as this is far easier to handle for the
content developer than providing explicit texture coordinates. It is
recommended that an implementation shall also support a minimum of Level
2 Texturing component capabilities (see <<S18_SupportLevels, 18.5 Support levels>>) in addition to this component. Typically, the
`CAMERASPACENORMAL` or `CAMERASPACEREFLECTIONVECTOR` modes
are used.

To specify explicit texture coordinates, the
<<TextureCoordinate3D>> node (see
<<texture3D_html, 33 Texture3D component>>) shall be used.

[[Textureorientation]]
==== 34.2.5 Texture Orientation

Cubic environment maps define a single texture as consisting of six
separate images, one for each side of a cube. This component defines the
six sides as front, back, left, right, top and bottom. These sides shall
be oriented as shown in <<f-Textureorientation, Figure 34.1>>.

[[f-Textureorientation]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/cubeMap.png[Environment map
textures,width=500,height=480]

Figure 34.1 — Mapping texture sides to the texture coordinate axes


=== 34.3 Abstract Types

[[X3DEnvironmentTextureNode]]
==== 34.3.1 _X3DEnvironmentTextureNode_

[source,node]
----
X3DEnvironmentTextureNode : X3DSingleTextureNode {

  SFString [in,out] description       ""
  SFNode   [in,out] metadata          NULL [X3DMetadataObject]
  SFNode   []       textureProperties NULL [TextureProperties]
}
----

This abstract node type is the base type for all node types that specify
cubic environment map sources for texture images.


=== 34.4 Node reference

[[ComposedCubeMapTexture]]
==== 34.4.1 ComposedCubeMapTexture

[source,node]
----
ComposedCubeMapTexture : X3DEnvironmentTextureNode {
  SFNode   [in,out] backTexture       NULL [X3DTexture2DNode]
  SFNode   [in,out] bottomTexture     NULL [X3DTexture2DNode]
  SFString [in,out] description       ""
  SFNode   [in,out] frontTexture      NULL [X3DTexture2DNode]
  SFNode   [in,out] leftTexture       NULL [X3DTexture2DNode]
  SFNode   [in,out] metadata          NULL [X3DMetadataObject]
  SFNode   [in,out] rightTexture      NULL [X3DTexture2DNode]
  SFNode   [in,out] topTexture        NULL [X3DTexture2DNode]
  SFNode   []       textureProperties NULL [TextureProperties]
}
----

The ComposedCubeMapTexture node defines a cubic environment map source
as an explicit set of images drawn from individual 2D texture nodes.

NOTE:  The original names for ComposedCubeMapTexture fields
_backTexture_, _bottomTexture_, _frontTexture_, _leftTexture_,
_rightTexture_, and _topTexture_ in X3D version 3 are _back_, _bottom_,
_front_, _left_, _right_, and _top_, respectively. 

See <<S34_Concepts, 34.2 Concepts>> for a general description of cube map
environmental texture maps.

See <<texturing_html, 18 Texturing component>> for a general
description of the X3DTexture2DNode abstract type and interpretation of
rendering for 2D images. When used as a source for cubic environment
maps, the fields _repeatS_ and _repeatT_ fields shall be ignored.

[[GeneratedCubeMapTexture]]
==== 34.4.2 GeneratedCubeMapTexture

[source,node]
----
GeneratedCubeMapTexture : X3DEnvironmentTextureNode {
  SFString [in,out] description       ""
  SFNode   [in,out] metadata          NULL   [X3DMetadataObject]
  SFString [in,out] update            "NONE" ["NONE"|"NEXT_FRAME_ONLY"|"ALWAYS"]
  SFInt32  []       size              128    (0,∞)
  SFNode   []       textureProperties NULL   [TextureProperties]
}
----

The GeneratedCubeMapTexture node defines a cubic environment map that
sources its data from internally generated images, rendered from a
virtual situated perspective in the scene.

The viewpoint of the generated texture is based on the location and
orientation of the associated geometry in world space.

NOTE  An object trying to render itself in the scene graph can cause
infinite loops in the renderer implementation and is thus not permitted.

The field of view shall be π/2 radians (or the equivalent
angle base units) with an aspect ratio of 1:1.

The _size_ field indicates the resolution of the generated images in
number of pixels per side.

The _update_ field can be used to request a regeneration of the texture.
Setting this field to `"ALWAYS"` will cause the texture to be
rendered every frame. A value of `"NONE"` will stop rendering so
that no further updates are performed even if the contained scene graph
changes. When the value is set to `"NEXT_FRAME_ONLY"`, it is an
instruction to render the texture at the end of this frame, and then not
render it again. In this case, the update frame indicator is set to this
frame; at the start of the next frame, the update value shall be
automatically set back to `"NONE"` to indicate that the rendering
has already taken place. Since this is a change of value for the
_update_ field, an output event is automatically generated.

[[ImageCubeMapTexture]]
==== 34.4.3 ImageCubeMapTexture

[source,node]
----
ImageCubeMapTexture : X3DEnvironmentTextureNode, X3DUrlObject {
  SFTime   [in,out] autoRefresh          0.0    [0,∞)
  SFTime   [in,out] autoRefreshTimeLimit 3600.0 [0,∞)
  SFString [in,out] description          ""
  SFBool   [in,out] load                 TRUE
  SFNode   [in,out] metadata             NULL   [X3DMetadataObject]
  MFString [in,out] url                  []     [URI]
  SFNode   []       textureProperties    NULL   [TextureProperties]
}
----

The ImageCubeMapTexture node defines a cubic environment map source as a
single file format that contains multiple images, one for each side.

The texture is read from the URL specified by the _url_ field. When the
_url_ field contains no values, texturing is disabled. The _url_ field
is defined in <<URLs, 9.2.1 URLs, URNs and URIs>>. X3D browsers
are not required to support any specific cube map environment texture
format. It is recommended that X3D browsers support the Microsoft DDS
cube map environment texture file format (see <<DDS>>).

See <<S18_Concepts, 18.2 Concepts>> for a general description of texture
maps.

[[S34.5_SupportLevels]]
=== 34.5 Support levels

The Cube map environmental texturing component defines three levels of
support as specified in <<t34_2, Table 34.2>>.

[[t34_2]]
Table 34.2 — Cube map environmental texturing
component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 | |
| | |_X3DEnvironmentTextureNode_ |n/a
| | |ComposedCubeMapTexture |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 | |
| | |ImageCubeMapTexture |All fields fully supported.
|*3* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 | |
| | |GeneratedCubeMapTexture |All fields fully supported.
|===

[[layering_html]]
== 35 Layering component

[[S35_Introduction]]
=== 35.1 Introduction

[[S35_Name]]
==== 35.1.1 Name

The name of this component is "Layering". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S35_Overview]]
==== 35.1.2 Overview

This subclause describes the Layering component of this International
Standard. This includes how to layer a set of subscene layers into a
composite scene. <<t35_1, Table 35.1>> provides links to the major
topics in this subclause.

[[t35_1]]
Table 35.1 — Topics

* <<S35Introduction, 35.1 Introduction>>
** <<S35_Name, 35.1.1 Name>>
** <<S35_Overview, 35.1.2 Overview>>
* <<S35_Concepts, 35.2 Concepts>>
** <<OverviewOfLayering, 35.2.1 Overview of layering>>
** <<LayerSets, 35.2.2 Layer sets>>
** <<Layers, 35.2.3 Layers>>
** <<S35_Viewports, 35.2.4 Viewports>>
* <<S35_AbstractTypes, 35.3 Abstract types>>
** <<X3DLayerNode, 35.3.1 _X3DLayerNode_>>
** <<X3DViewportNode, 35.3.2 _X3DViewportNode_>>
* <<S35_NodeReference, 35.4 Node reference>>
** <<Layer, 35.4.1 Layer>>
** <<LayerSet, 35.4.2 LayerSet>>
** <<Viewport, 35.4.3 Viewport>>
* <<S35_SupportLevels, 35.5 Support levels>>

* <<t35_1, Table 35.1 — Topics>>
* <<t35_2, Table 35.2 — Layering component support levels>>


[[S35_Concepts]]
=== 35.2 Concepts

[[OverviewOfLayering]]
==== 35.2.1 Overview of layering

A scene is embodied by the basic concept of layering.  A scene is
defined to consist of a sequence of layers and the order in which they
are to be rendered.

[[LayerSets]]
==== 35.2.2 Layer sets

A layer set is defined to be an ordered list of
_<<X3DLayerNode>>_ nodes that form a scene. The layers
are assigned ordinals according to their position in the list in the
<<LayerSet>> node. The rendering order is specified by the
order field. Thus, the layer first specified in the order field will be
the first layer rendered and will appear to be below any other layers.
The layer last specified in the order field will be the last layer
rendered and will correspondingly appear to be on top of all other
layers.

The LayerSet node may make access to some of its content public by using
the EXPORT statement to identify public names.

Only one LayerSet node is allowed and shall be a root node.

[[Layers]]
==== 35.2.3 Layers

Each subscene is specified by a single
_<<X3DLayerNode>>_ node that contains its definition.
The _<<X3DLayerNode>>_ nodes may contain any child nodes
allowed in grouping nodes. Hence, _<<X3DLayerNode>>_
nodes may be used to create special effects such as heads up displays or
non-transforming control elements. Each
_<<X3DLayerNode>>_ node contains its own binding stacks
and thus has its own viewpoints and navigation.

[[S35_Viewports]]
==== 35.2.4 Viewports

The output to a surface can be constrained further by using an
_<<X3DViewportNode>>_ node. These nodes are special
grouping nodes that each define a set of clipping bounds within the
extent of a surface within which the children nodes of the
_<<X3DViewportNode>>_ will appear. This provides
support for the typical front/side/back/oblique views used by CAD
systems.

=== 35.3 Abstract types

[[X3DLayerNode]]
==== 35.3.1 _X3DLayerNode_

[source,node]
----
X3DLayerNode : X3DNode, X3DPickableObject {
  SFNode   [in,out] metadata    NULL  [X3DMetadataObject]
  MFString [in,out] objectType  "ALL" ["ALL","NONE","TERRAIN",...]
  SFBool   [in,out] pickable    TRUE
  SFNode   [in,out] viewport    NULL  [X3DViewportNode]
  SFBool   [in,out] visible     TRUE
}
----

The _X3DLayerNode_ abstract node type is the base node type for layer
nodes.

The _pickable_ field determines if pick traversal is to be performed for
this layer. An _X3DLayerNode_ node specified with _pickable_ set to
`FALSE` does not participate in picking operations.

The _viewport_ field constrains the output of the layer to a sub-region
of the render surface.

The _visible_ field specifies whether or not the content within a node
is visually displayed. The value of this field has no effect on
animation behaviors, collision behaviors, event passing, or other
non-visual characteristics.

[[X3DViewportNode]]
==== 35.3.2 _X3DViewportNode_

[source,node]
----
X3DViewportNode : X3DGroupingNode {
  MFNode  [in]     addChildren             [X3DChildNode]
  MFNode  [in]     removeChildren          [X3DChildNode]
  MFNode  [in,out] children       []       [X3DChildNode]
  SFBool  [in,out] bboxDisplay    FALSE
  SFNode  [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool  [in,out] visible        TRUE
  SFVec3f []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f []       bboxSize       -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The _X3DViewportNode_ abstract node type is the base node type for
viewport nodes. Nodes of this type specify a boundary to which all
content affected by the node is to be clipped. The boundary is specified
in units appropriate for the surface on which the content is to be
rendered.

More details on the children, addChildren, and removeChildren fields can
be found in <<S10_Concepts, 10.2 Concepts>>.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the children. This is a hint that may be used for optimization
purposes. The results are undefined if the specified bounding box is
smaller than the actual bounding box of the children at any time. The
default _bboxSize_ value, (-1, -1, -1), implies that the bounding box is
not specified and, if needed, shall be calculated by the X3D browser.
More details on the _bboxCenter_ and _bboxSize_ fields can be found in
<<BoundingBoxes, 10.2.2 Bounding boxes>>.

=== 35.4 Node Reference

[[Layer]]
==== 35.4.1 Layer

[source,node]
----
Layer : X3DLayerNode { 
  MFNode   [in]     addChildren          [X3DChildNode]
  MFNode   [in]     removeChildren       [X3DChildNode]
  MFNode   [in,out] children       []    [X3DChildNode]
  SFNode   [in,out] metadata       NULL  [X3DMetadataObject]
  MFString [in,out] objectType     "ALL" ["ALL","NONE","TERRAIN",...]
  SFBool   [in,out] pickable       TRUE
  SFNode   [in,out] viewport       NULL  [X3DViewportNode]
  SFBool   [in,out] visible        TRUE
}
----

The Layer node specifies a _children_ field that contains a list of
nodes that define the contents of the layer.

<<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>
provides a description of the _children_, _addChildren_, and
_removeChildren_ fields.

[[LayerSet]]
==== 35.4.2 LayerSet

[source,node]
----
LayerSet : X3DNode { 
  SFInt32 [in,out]  activeLayer 0    [0,∞)
  MFNode  [in,out]  layers      []   [X3DLayerNode]
  SFNode  [in,out]  metadata    NULL [X3DMetadataObject]
  MFInt32 [in,out]  order       [0]  [0,∞)
}
----

The LayerSet node specifies a list of layers and a rendering order.

The _activeLayer_ field specifies the layer in which navigation takes
place.

The list defined by _layers_ contains the constituent parts of the
scene. Each layer is assigned an ordinal number depending on its
position in the list. Ordinals start with the numeral 0 representing the
first item in the list.

The list defined by the the _order_ field specifies the order in which
the layers are rendered. Each number specified corresponds to the
ordinals of the layers. The _order_ field may contain repetitions of the
ordinals, in which case the corresponding layer is rendered again. If
the _order_ field contains numbers that are not ordinals assigned to
layers, such numbers are ignored. Layers included in the _layers_ field
that are not listed in the _order_ field are not rendered.

Object picking according to the _pickable_ field of a Layer node occurs
even if that Layer is not visible.

Nodes that are not part of a layer are considered to be the first nodes
in layer 0.

[[Viewport]]
==== 35.4.3 Viewport

[source,node]
----
Viewport : X3DViewportNode, X3DBoundedObject {
  MFNode  [in]     addChildren             [X3DChildNode]
  MFNode  [in]     removeChildren          [X3DChildNode]
  MFNode  [in,out] children       []       [X3DChildNode]
  MFFloat [in,out] clipBoundary   0 1 0 1  [0,1]
  SFBool  [in,out] bboxDisplay    FALSE
  SFNode  [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool  [in,out] visible        TRUE
  SFVec3f []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f []       bboxSize       -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The Viewport node is a grouping node that specifies a set of rectangular
clip boundaries against which the children nodes are clipped as they are
rendered.

The _clipBoundary_ field is specified in fractions of the normal render
surface in the sequence left/right/bottom/top. When the children are
rendered, the output will only appear in the specified subset of the
render surface.

=== 35.5 Support levels

The Layering component provides one level of support as specified in
<<t35_2, Table 35.2>>. Level 1 provides the support for
scenes and layers.

[[t35_2]]
Table 35.2 — Layering component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|*Level* |Prerequisites |*Nodes* |Support
|*1* |Core 1; +
Grouping 1 |  | 
|  |  |_X3DLayerNode_ |n/a
|  |  |_X3DViewportNode_ |n/a
|  |  |Layer |All fields fully supported.
|  |  |LayerSet |All fields fully supported.
|  |  |Viewport |All fields fully supported.
|===

[[layout_html]]
== 36 Layout component

[[S36_Introduction]]
=== 36.1 Introduction

[[S36_Name]]
==== 36.1.1 Name

The name of this component is "Layout". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S36_Overview]]
==== 36.1.2 Overview

This subclause describes the Layout component of this document. This
includes how to precisely position content in a scene in relation to the
rendered results. <<t36_1, Table 36.1>> provides links to the major
topics in this subclause.

[[t36_1]]
Table 36.1 — Topics

* <<S36Introduction, 36.1 Introduction>>
** <<S36_Name, 36.1.1 Name>>
** <<S36_Overview, 36.1.2 Overview>>
* <<S36_Concepts, 36.2 Concepts>>
** <<OverviewLayout, 36.2.1 Overview>>
** <<PixelSpecificAddressing, 36.2.2 Pixel-specific addressing>>
** <<S36_Viewports, 36.2.3 Viewports>>
* <<S36_AbstractTypes, 36.3 Abstract types>>
** <<X3DLayoutNode, 36.3.1 _X3DLayoutNode_>>
* <<S36_NodeReference, 36.4 Node reference>>
** <<Layout, 36.4.1 Layout>>
** <<LayoutGroup, 36.4.2 LayoutGroup>>
** <<LayoutLayer, 36.4.3 LayoutLayer>>
** <<ScreenFontStyle, 36.4.4 ScreenFontStyle>>
** <<ScreenGroup, 36.4.5 ScreenGroup>>
* <<S36_SupportLevels, 36.4 Support levels>>

* <<t36_1, Table 36.1 — Topics>>
* <<t36_2, Table 36.2 — Layout component support levels>>




[[S36_Concepts]]
=== 36.2 Concepts

[[OverviewLayout]]
==== 36.2.1 Overview

This component provides a set of nodes that allow users to better
integrate 2D content with 3D content. In X3D, authors have historically
generated a Heads-Up Display (HUD) by placing content in a group that
moves along with the user’s viewpoint. This approach is limited in that
the author has limited control over where the HUD geometry is rendered
relative to the display viewport.

EXAMPLE  There is no way to ensure that the content will be aligned with
a particular edge of the display viewport.

This component provides several nodes that enable the integration of 2D
content into the 3D scene. It allows for constructing a hierarchy of
rectangular regions that are well suited to contain 2D content, but can
also contain 3D content. These 2D regions are not affected by the user
navigation or the bound _<<X3DViewpointNode>>_. They
are aligned relative to the main scene viewport, or the 2D region that
act as its parent. +
 +
This component also contains a
_<<X3DFontStyleNode>>_ node that can render text so
that it appears identical to typical 2D applications, with the eye
soothing technique of anti-aliasing.

[[PixelSpecificAddressing]]
==== 36.2.2 Pixel-specific addressing

This component also provides utilities that allowing content authors the
ability to scale and locate 2D regions and content using pixel-specific
addressing. Therefore, some of the nodes and options in this component
are dependent on the concept of pixel-based display devices. It is
recognized that some implementations do not use such devices. Therefore,
those pixel-specific nodes and options are not applicable to those
implementations. The pixel-specific nodes and options are contained in a
support level designated for pixel-specific concepts.

A node is specified that can exist anywhere in the scene hierarchy. This
node forces a scale so that one unit is one pixel.

[[S36_Viewports]]
==== 36.2.3 Viewports

The output to a surface can be constrained further by using an
_<<X3DViewportNode>>_ node. This node is a special
grouping node that defines a set of clipping bounds within the extent of
a surface within which the children nodes of the viewport will appear.
This provides support for the typical front/side/back/oblique views used
by CAD systems.


=== 36.3 Abstract types

[[X3DLayoutNode]]
==== 36.3.1 _X3DLayoutNode_

[source,node]
----
X3DLayoutNode : X3DChildNode {
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

This is the base node type for layout nodes.


=== 36.4 Node Reference

[[Layout]]
==== 36.4.1 Layout

[source,node]
----
Layout : X3DLayoutNode { 
  MFString [in,out] align       ["CENTER","CENTER"] ["LEFT"|"CENTER"|"RIGHT"],["BOTTOM"|"CENTER"|"TOP"] 
  SFNode   [in,out] metadata    NULL                [X3DMetadataObject]
  MFFloat  [in,out] offset      [0,0]               (-∞,∞)
  MFString [in,out] offsetUnits ["WORLD","WORLD"]   ["WORLD"|"FRACTION"|"PIXEL"],["WORLD"|"FRACTION"|"PIXEL"] 
  MFString [in,out] scaleMode   ["NONE","NONE"]     ["NONE"|"FRACTION"|"STRETCH"|"PIXEL"],["NONE"|"FRACTION"|"STRETCH"|"PIXEL"] 
  MFFloat  [in,out] size        [1,1]               (0,∞)
  MFString [in,out] sizeUnits   ["WORLD","WORLD"]   ["WORLD"|"FRACTION"|"PIXEL"],["WORLD"|"FRACTION"|"PIXEL"] 
}
----

The Layout node is used in the layout field of the
<<LayoutLayer>> and <<LayoutGroup>> nodes.
The Layout node provides all the parameters that are required to define
the size and location of a 2D rectangular region that is associated with
the containing node. Also, it contains a field that defines how the
content of the containing node shall be scaled. +
 +
The fields of interest in the Layout node are MFString and MFFloat
fields. All have two elements. The first value corresponds to the
horizontal direction and the second field corresponds to the vertical
direction. If a field has a length of one, that value applies to both
the horizontal and vertical directions. If the _align_ field has only
one value, that value shall be `"CENTER"`. +
 +
The width and height of the layout rectangle is defined by two values in
the _size_ field. The _sizeUnits_ field specifies how to interpret the
size values. If the value of the _sizeUnits_ field is
`"FRACTION"`, the size of the corresponding dimension is
interpreted as a fraction of the corresponding parent’s dimension.

EXAMPLE  If the _size_ value is (0.25, 0.5) and the value of _sizeUnits_
([`"FRACTION"`, `"FRACTION"`]), the width of the region is
one quarter of the width of the parent and the height of the region is
one half of the height of the parent.

A _sizeUnits_ value of `"WORLD"` specifies that the corresponding
_size_ value is interpreted using the current world units of the parent
node. Since the LayoutLayer node does not have a parent, a value of
`"WORLD"` is equivalent to a value of `"FRACTION"`.
Lastly, a _sizeUnits_ value of `"PIXEL"` specifies that the
corresponding size value is in pixel units.

NOTE  Implementations that do not support the concept of a pixel are not
required to support the `"PIXEL"` option.

The values of the _align_, _offset_, and _offsetUnits_ fields are used
to determine the location of the layout region. First, the _align_ field
values align the sized rectangle to an edge or center of the parent
rectangle. Then, the offset is applied using the units specified in the
_offsetUnits_ field. The first value of the _align_ field corresponds to
the horizontal alignment. The value `"LEFT"` specifies that the
left side of this rectangle shall be aligned with the left side of the
parent rectangle. The value `"RIGHT"` specifies that the right
side of this rectangle shall be aligned with the right side of the
parent rectangle. The value `"CENTER"` specifies that this
rectangle shall be horizontally centred in its parent. Similarly, the
second _align_ field value aligns the vertical position of the rectangle
to either the `"TOP"`, `"BOTTOM"` or `"CENTER"` of the parent rectangle. 

After the alignment is applied, the values of the _offset_ field are
used to translate the location of this rectangle after the initial
alignment. The value of the offset field is interpreted using the value
of the _offsetUnits_ field, using the same options and logic as the
_sizeUnits_ field, described above. 

The scaleMode field specifies how the scale of the parent is modified.
The _scale_ field has two values, the first specifies the horizontal
scale and the second value specifies the vertical scale. A _scaleMode_
field value of `"NONE"` specifies that the corresponding scale
value is not modified. Instead, the scale is inherited from its parent.
Since a LayoutLayer node does not have a parent, the value of
`"NONE"` reverts to `"FRACTION"`. A _scaleMode_ value of
`"FRACTION"` specifies a scale in the corresponding direction so
that one unit is equal to the dimension (width or height) of this
rectangle. A value of `"PIXEL"` specifies a scale in the
corresponding direction such that one unit is equal to one pixel.

NOTE  Implementations that do not support the concept of a pixel are not
required to support this `"PIXEL"` option.

A _scaleMode_ value of `"STRETCH"` specifies a scale in the
corresponding direction such that the resulting scale in the horizontal
direction is equal to the scale in the vertical direction, thus
producing a uniform scale. If one of the dimensions has a _scaleMode_
value of `"STRETCH"`, and the other dimension has a value other
than `"STRETCH"`, the scale for the dimension that is not
`"STRETCH"` shall be computed first and the dimension
corresponding to the value of `"STRETCH"` can then be computed to
achieve a uniform scale. If both components of the _scaleMode_ field are
`"STRETCH"`, the scale component corresponding to the larger
dimension of the rectangular region is set so that one unit is equal to
the dimension of the rectangle, and the other scale component is set so
that the resulting scale in the horizontal and vertical directions are
the same.

[[LayoutGroup]]
==== 36.4.2 LayoutGroup

[source,node]
----
LayoutGroup : X3DGroupingNode {
   MFNode  [in]     addChildren          [X3DChildNode]
   MFNode  [in]     removeChildren       [X3DChildNode]
   MFNode  [in,out] children       []    [X3DChildNode]
   SFBool  [in,out] bboxDisplay    FALSE
   SFNode  [in,out] layout         NULL  [X3DLayoutNode]
   SFNode  [in,out] metadata       NULL  [X3DMetadataObject]
   SFNode  [in,out] viewport       NULL  [X3DViewportNode]
   SFBool  [in,out] visible        TRUE
   SFVec3f []       bboxCenter     0 0 0 (-∞,∞)
   SFVec3f []       bboxSize       0 0 0 (-∞,∞)
}
----

The LayoutGroup is a grouping node whose children are related by a
common layout within a parent layout. Thus, a LayoutGroup can only be a
child of a <<LayoutLayer>> node or another LayoutGroup node.

The layout field contains an _<<X3DLayoutNode>>_ node
that specifies the information required to locate and size the layout
region of the LayoutGroup node relative to its parent’s layout region
and to scale the contents of the LayoutGroup. The content of the
LayoutGroup is clipped by the specified viewport.

<<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>
specifies the _children_, _addChildren_, and _removeChildren_ fields.

The origin of the node is always in the center of its layout region.
Thus, children (with the exception of LayoutGroup) are specified in a
coordinate system whose origin is located at the center of the rectangle
and can be transformed from that location.

The LayoutGroup node does not directly have any pixel dependent
concepts. However, the LayoutGroup node does contain a Layout node that
does have pixel-specific options.

[[LayoutLayer]]
==== 36.4.3 LayoutLayer

[source,node]
----
LayoutLayer : X3DLayerNode { 
  MFNode   [in]     addChildren          [X3DChildNode]
  MFNode   [in]     removeChildren       [X3DChildNode]
  MFNode   [in,out] children       []    [X3DChildNode]
  SFNode   [in,out] layout         NULL  [X3DLayoutNode]
  SFNode   [in,out] metadata       NULL  [X3DMetadataObject]
  MFString [in,out] objectType     "ALL" ["ALL","NONE","TERRAIN",...]
  SFBool   [in,out] pickable    TRUE
  SFNode   [in,out] viewport       NULL  [X3DViewportNode]
  SFBool   [in,out] visible        TRUE
}
----

The LayoutLayer node specifies a _children_ field that contains a list
of nodes that define the subscene.

<<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>
specifies the _children_, _addChildren_, and _removeChildren_ fields.

An <<OrthoViewpoint>> node is automatically
established as the default node on the binding stack. Although not
restricted to require this, the LayoutLayer node is typically used as
the last rendered node in a <<LayerSet>> ordering.

The _layout_ field contains an instance of
_<<X3DLayoutNode>>_ that contains the information
required to locate and size the LayoutLayer node’s rectangular region
relative to the main viewport, and to scale the content of the
LayoutLayer. The content of the LayoutLayer is clipped by the defined
rectangular region.

[[ScreenFontStyle]]
==== 36.4.4 ScreenFontStyle

[source,node]
----
ScreenFontStyle : X3DFontStyleNode {
  SFNode   [in,out] metadata    NULL    [X3DMetadataObject]
  MFString [in,out] family      "SERIF"
  SFBool   [in,out] horizontal  TRUE
  MFString [in,out] justify     "BEGIN" ["BEGIN"|"END"|"FIRST"|"MIDDLE"|""],["BEGIN"|"END"|"FIRST"|"MIDDLE"|""] 
  SFString [in,out] language    ""
  SFBool   [in,out] leftToRight TRUE
  SFFloat  [in,out] pointSize   12.0    (0,∞)
  SFFloat  [in,out] spacing     1.0     [0,∞)
  SFString [in,out] style       "PLAIN" ["PLAIN"|"BOLD"|"ITALIC"|"BOLDITALIC"|""]
  SFBool   [in,out] topToBottom TRUE
}
----

The ScreenFontStyle node specifies font styles in terms of the
characteristics of a particular presentation surface upon which the text
is to be rendered.

The fields in the ScreenFontStyle node are the same as those in the
<<FontStyle>> node with a single exception:  the _size_
field of the FontStyle node is replaced with a _pointSize_ field. The
_pointSize_ field specifies the size of text in points. Thus, the
distance between the baseline of each line of text is ( _spacing_  ×
_pointSize_) in the appropriate direction.

Otherwise, the attributes are as specified in <<FontStyle, 15.4.1 FontStyle>> and <<TextFormatting, 15.2.2 Text formatting>>.

[[ScreenGroup]]
==== 36.4.5 ScreenGroup

[source,node]
----
ScreenGroup : X3DGroupingNode {
  MFNode  [in]     addChildren             [X3DChildNode]
  MFNode  [in]     removeChildren          [X3DChildNode]
  MFNode  [in,out] children       []       [X3DChildNode]
  SFBool  [in,out] bboxDisplay    FALSE
  SFNode  [in,out] metadata       NULL     [X3DMetadataObject]
  SFBool  [in,out] visible        TRUE
  SFVec3f []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f []       bboxSize       -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The ScreenGroup node is a node derived from
<<X3DGroupingNode>> with one additional functional
feature:  it modifies the scale in such a way that one unit is equal to
one pixel in both the horizontal and vertical directions.

If the ScreenGroup node is a child of a <<Billboard>> node
that is screen-aligned ( _i.e._, has an _axisOfRotation_ value of
(0,0,0)), the children of the ScreenGroup shall be both screen-aligned
and scaled so that one unit is equal to one pixel. This allows users to
place screen-aligned and screen-scaled content into the 3D scene. It
will maintain its location in the 3D scene but can be occluded by other
geometry that lies in front. Additionally, it can occlude other geometry
that lies in back.

<<GroupingAndChildrenNodes, 10.2.1 Grouping and children node types>>
specifies the _children_, _addChildren_, and _removeChildren_ fields.

The _bboxCenter_ and _bboxSize_ fields specify a bounding box that
encloses the children. This is a hint that may be used for optimization
purposes. The results are undefined if the specified bounding box is
smaller than the actual bounding box of the children at any time. The
default _bboxSize_ value, (-1, -1, -1), implies that the bounding box is
not specified and, if needed, shall be calculated by the X3D browser.
More details on the _bboxCenter_ and _bboxSize_ fields can be found in
<<BoundingBoxes, 10.2.2 Bounding boxes>>.

[[S36.5_SupportLevels]]
=== 36.5 Support levels

The Layout component provides two levels of support as specified in
<<t36_2, Table 36.2>>. Level 1 provides the basic support
for layout. Level 2 provides for pixel-specific addressing.

[[t36_2]]
Table 36.2 — Layout component support levels

[width="100%",cols="25%,25%,25%,25%",options="header",]
|===
|*Level* |Prerequisites |*Nodes* |Support
|*1* |Core 1 +
Grouping 1 +
Layering 1 |  | 

|  |  |_X3DLayoutNode_ |n/a

|  |  |Layout |All fields fully supported except `"PIXEL"` values
optionally supported.

|  |  |LayoutGroup |All fields fully supported.

|  |  |LayoutLayer |All fields fully supported.

|*2* |Core 1 +
Grouping 1 +
Layering 1 +
Text 1 |  | 

|  |  |All Level 1 nodes |All fields fully supported.

|  |  |ScreenFontStyle |All fields fully supported.

|  |  |ScreenGroup |All fields fully supported.
|===

[[rigidBodyPhysics_html]]
== 37 Rigid body physics component

[[S37_Introduction]]
=== 37.1 Introduction

[[S37_Name]]
==== 37.1.1 Name

The name of this component is "RigidBodyPhysics". This name shall be
used when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S37_Overview]]
==== 37.1.2 Overview

This clause describes how to model rigid bodies and their interactions
through the application of basic physics principles to effect motion.
<<t37_1, Table 37.1>> provides links to the major topics in this
clause.

[[t37_1]]
Table 37.1 — Topics

* <<S37Introduction, 37.1 Introduction>>
** <<S37_Name, 37.1.1 Name>>
** <<S37_Overview, 37.1.2 Overview>>
* <<S37_Concepts, 37.2 Concepts>>
** <<S37_ConceptsOverview, 37.2.1 Overview>>
** <<ConceptsBodies, 37.2.2 Bodies>>
*** <<EventModelEvaluation, 37.2.2.1 Event model evaluation>>
*** <<S37_TransformationHierarchy, 37.2.2.2 Transformation hierarchy>>
** <<ConceptsJoints, 37.2.3 Joints>>
*** <<JointDescriptions, 37.2.3.1 What a joint describes>>
*** <<RangeOfMotionLimits, 37.2.3.2 Range of motion limits>>
** <<CoordinateSystems, 37.2.4 Coordinate systems>>
*** <<InitialCoordinateSystem, 37.2.4.1 Initial coordinate system>>
*** <<BreakingJoints, 37.2.4.2 Breaking joint>>
*** <<CollisionContacts, 37.2.4.3 Collision contact description>>
* <<S37_AbstractTypes, 37.3 Abstract types>>
** <<X3DNBodyCollidableNode, 37.3.1 _X3DNBodyCollidableNode_>>
** <<X3DNBodyCollisionSpaceNode, 37.3.2 _X3DNBodyCollisionSpaceNode_>>
** <<X3DRigidJointNode, 37.3.3 _X3DRigidJointNode_>>
* <<S37_NodeReference, 37.4 Node reference>>
** <<BallJoint, 37.4.1 BallJoint>>
** <<CollidableOffset, 37.4.2 CollidableOffset>>
** <<CollidableShape, 37.4.3 CollidableShape>>
** <<CollisionCollection, 37.4.4 CollisionCollection>>
** <<CollisionSensor, 37.4.5 CollisionSensor>>
** <<CollisionSpace, 37.4.6 CollisionSpace>>
** <<Contact, 37.4.7 Contact>>
** <<DoubleAxisHingeJoint, 37.4.8 DoubleAxisHingeJoint>>
** <<MotorJoint, 37.4.9 MotorJoint>>
** <<RigidBody, 37.4.10 RigidBody>>
** <<RigidBodyCollection, 37.4.11 RigidBodyCollection>>
** <<SingleAxisHingeJoint, 37.4.12 SingleAxisHingeJoint>>
** <<SliderJoint, 37.4.13 SliderJoint>>
** <<UniversalJoint, 37.4.14 UniversalJoint>>
* <<S37_SupportLevels, 37.5 Support levels>>

* <<t37_1, Table 37.1 — Topics>>
* <<t37_2, Table 37.2 — __appliedParameters__valid values>>
* <<t37_3, Table 37.3 — Rigid body physics component support levels>>




[[S37_Concepts]]
=== 37.2 Concepts

[[S37_ConceptsOverview]]
==== 37.2.1 Overview

This component provides the ability to influence the visual output of
the scene graph in accordance to some of the laws of physics. Only the
subset of the laws of physics known as rigid body physics is supported.
Rigid body physics models deal with objects as solid, unchangeable sets
of mass with a velocity. These bodies can be connected together with the
use of various forms of joints, that allow one body's motion to effect
another.

Rigid body physics evaluation requires the solving of many different
factors in parallel, typically through the use of ordinary differential
equations. Because these equations are heavily floating point based,
their accuracy is highly dependent on both the implementation of the
solver and the computing hardware. Due to this non-precise nature of the
calculations, modelling rigid body physics requires a lot of care and
attention to detail. Small changes can very quickly lead to numerical
instability resulting in visual representations that may make the model
look like it is exploding. Most of the node definitions in this
component include factors that can be modified to trade off accuracy in
visual output for the stability of the calculations. In many cases, the
two are inversely proportional. That is, a more-accurate simulation has
a far greater chance of suffering numerical instability than a
less-accurate simulation. Intersection collisions between bodies and the
way that they interact per presentation frame can have significant
effects on the application visuals.

A consequence of this problem is that using physically accurate values
for masses and sizes in the physics model is not likely to produce the
best results, or even lead to a stable simulation. The physics modelling
presented by this component is independent of the visuals
representation, allowing the model author to create a stable physical
model that does not have strict dependencies on the visual model that is
driven by the physics.

[[IntegrationWithX3D]]
==== 37.2.2 Integration with X3D

[[EventModelEvaluation]]
===== 37.2.2.1 Event model evaluation

Evaluating the physics model within the constraints of the X3D event
model requires the ability to evaluate time in discrete time chunks.
Such modelling is typically performed using _differential time-step
simulation_ or _discrete event simulation_.

Evaluation of controlling state variables and corresponding sending of
events for the physics model is performed once per presentation frame.
Since the user needs to be able to present model behavior on a
frame-by-frame basis, this requires that the physics model is evaluated
after all possible user input has been received for that presentation
frame. Thus, physics model evaluation is performed just after Step d in
<<ExecutionModel, 4.4.8.3 Execution model>>. After evaluating the
physics model, the results are used to further modify the existing scene
graph immediately before rendering is performed.

Physics modelling libraries typically require fixed-length time
intervals between iterations for high-fidelity computation. A real-time
3D graphics environment typically varies the presentation frame rates
based on:

[loweralpha]
. the current content in view,
. scripting, and
. other interactions.

An implementation of this document shall be responsible for keeping the
physics time-interval evaluations synchronized with the varying
presentation frame time intervals.

Some nodes in this component produce output events that describe state
of the physics model, such as the current separation between two bodies
or the rate of separation between them. These values are exposed as a
set of sensors that can be used to track the output of the physics model
and report it at the start of the next presentation frame, in accordance
with X3DSensorNode behaviors.

[[S37_TransformationHierarchy]]
===== 37.2.2.2 Transformation hierarchy

The nodes defined in this component are not part of the visual
transformation hierarchy. Instead, the nodes may be linked to parts of
the scene graph that are part of the transformation hierarchy in order
to affect their motion. They may also be linked as part of the n-body
object collision-detection capabilities so that a i coordinated system
of graphics and physics may be modelled.

[[ConceptsBodies]]
==== 37.2.3 Bodies

A body represents a section of mass in the system that can be affected
by the physics model. A body is represented by the following properties:

[loweralpha]
. mass,
. density model,
. position and orientation,
. linear velocity,
. angular velocity, and
. various forces and torques applied.

A body is a standalone object within a collection. Bodies are influenced
by joints that connect this body to another within the collection.
Bodies are not required to be connected by a joint and may exist as a
standalone entity. All bodies exist within the world space of their
collection. There is no predefined concept of a transformation hierarchy
of bodies within bodies.

[[ConceptsJoints]]
==== 37.2.4 Joints

[[JointDescriptions]]
===== 37.2.4.1 What a joint describes

A joint is used to connect two bodies together in a way that imposes a
set of constraints on the movement of the two bodies relative to one
another. Many different joint types are provided allowing the user to
constrain the motions of the bodies according to the desired physical
properties.

[[RangeOfMotionLimits]]
===== 37.2.4.2 Range of motion limits

Each of the joints has a range of motion through which they can travel.
This range of motion may be radial angles or linear distance. Typically
these values are limited to a single rotation in any one axis.

EXAMPLE 1  2π radians indicates full rotatability.

Each joint contains a set of fields that can be used to limit the range
of motions to less than full ability. These fields are termed _stops_.

A stop is defined by its value and a number of parameters to control the
effects output from the physics engine. Firstly, a stop may permit some
amount of bouncing due to the action of the joint hitting it. These same
values are also used to perform internal self-correction of objects that
have interpenetrated due to the discrete time step intervals that the
evaluation of the physics model uses.

EXAMPLE 2  In the real world, a lot of stops have a rubber cushion on
the end to absorb the impacts and help return the joint to the central
position.

[[CoordinateSystems]]
==== 37.2.5 Coordinate systems

[[InitialCoordinateSystem]]
===== 37.2.5.1 Initial coordinate system

When the two bodies are initially placed in the scene, their initial
positions define the resting coordinate frames of reference for the two
bodies on that joint. Output values from those joints are then relative
to this initial position.

The anchor position and axis values of joints are always specified in
world coordinate positions, regardless of whether the two joining bodies
have been offset or not.

Mass is defined in kilograms. It is important to note that rigid body
physics models, due to inaccuracy in floating point calculations, may
have difficulty modeling physical interactions with full fidelity.
Values provided may be defined in relative proportions rather than
absolute physical values. This will help the model stay stable over long
calculation periods.

[[BreakingJoints]]
===== 37.2.5.2 Breaking joints

Each joint node will have two output-only fields that indicate the
calculated location of the relative positions within their own frame of
reference. By comparing the difference between these two values, it is
possible to determine if the joint has broken as a result of the input
from the last presentation frame. If the joint broke, the difference
between the two values will be non-zero (although the author should also
allow a small tolerance due to the inaccuracy of floating point
calculations).

[[CollisionContacts]]
===== 37.2.5.3 Collision contact description

When a collision is found between two objects, it is described with the
following details:

[loweralpha]
. a unit vector describing the surface normal from body 1 to body 2 at
the point of contact,
. a primary direction of motion for body 1 relative to body 2, and
. a second direction that is perpendicular to both the normal and the
primary direction is implied for the purposes of providing various sets
of coefficients.

The <<CollisionCollection>> node specifies a set
of default coefficients to use for all contacts unless overridden by
geometry-specific information. These coefficients are generally
described using SFVec2f fields. The 2D vector describes the coefficients
for the primary direction for the first value and secondary direction
for the second value.


=== 37.3 Abstract types

[[X3DNBodyCollidableNode]]
==== 37.3.1 _X3DNBodyCollidableNode_

[source,node]
----
X3DNBodyCollidableNode : X3DChildNode, X3DBoundedObject {
  SFBool     [in,out] bboxDisplay FALSE
  SFBool     [in,out] enabled     TRUE
  SFNode     [in,out] metadata    NULL     [X3DMetadataObject]
  SFRotation [in,out] rotation    0 0 1 0  [0,1]
  SFVec3f    [in,out] translation 0 0 0    (-∞,∞)
  SFBool     [in,out] visible     TRUE
  SFVec3f    []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize    -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The _X3DNBodyCollidableNode_ abstract node type represents objects that
act as the interface between the rigid body physics, collision geometry
proxy, and renderable objects in the scene graph hierarchy.

The _enabled_ field is used to specify whether a collidable object is
eligible for collision-detection interactions.

The _translation_ and _rotation_ fields define an offset from, and
rotation about, the body's center that the collidable node occupies.
This can be used to place the collidable geometry in a different
location relative to the actual rigid body that has the physics model
being applied.

[[X3DNBodyCollisionSpaceNode]]
==== 37.3.2 _X3DNBodyCollisionSpaceNode_

[source,node]
----
X3DNBodyCollisionSpaceNode : X3DNode, X3DBoundedObject {
  SFBool  [in,out] bboxDisplay FALSE
  SFBool  [in,out] enabled     TRUE
  SFNode  [in,out] metadata    NULL     [X3DMetadataObject]
  SFBool  [in,out] visible     TRUE
  SFVec3f []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f []       bboxSize    -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The _X3DNBodyCollisionSpaceNode_ abstract node type represents objects
that act as a self-contained spatial collection of objects that can
interact through collision-detection routines. Different types of spaces
may be defined depending on spatial organization or other optimization
mechanisms.

The _enabled_ field specifies whether the collision space is to be
considered during collision processing.

[[X3DRigidJointNode]]
==== 37.3.3 _X3DRigidJointNode_

[source,node]
----
X3DRigidJointNode : X3DNode {
  SFNode   [in,out] body1       NULL   [RigidBody]
  SFNode   [in,out] body2       NULL   [RigidBody]
  MFString [in,out] forceOutput "NONE" ["ALL","NONE",...]
  SFNode   [in,out] metadata    NULL   [X3DMetadataObject]
}
----

The _X3DRigidJointNode_ abstract node type is the base type for all
joint types.

The _body1_ and _body2_ fields indicate the two RigidBody nodes
connected by this joint.

The _forceOutput_ field is used to control which output fields are to be
generated for the next presentation frame. In physics models, the amount
of data that can be generated per presentation frame can be quite
extensive, particularly in complex models with a large number of joints.
A typical application will need only a few of them, if any at all. This
field is used to control which of those outputs the author requires to
be generated. The values of the array are to describe the names,
exactly, of the output field(s) that are to be updated at the start of
the next presentation frame. Two special values are defined:
`"ALL"` and `"NONE"`. If `"ALL"` is specified
anywhere in the array, all fields are to be updated. If `"NONE"`
is specified, no updates are performed. If the list of values is empty,
it shall be treated as if `"NONE"` were specified. Other values
provided in addition to `"NONE"` shall be ignored.

Because computers are not guaranteed to be accurate in their
mathematical calculations and because of the nature of the discrete time
steps in the evaluation mechanisms, the behaviour of the system will not
be 100% accurate.

EXAMPLE  Objects may intersect that should not and joints may break that
should not.

Every joint type will have a set of joint-specific fields that define a
set of error correction conditions. This error correction conditions
provide guidance as to how to automatically correct for internally
calculated errors including such errors as object interpenetration. In
addition, these error correction conditions can be used to control how
quickly the errors should be corrected. Fast corrections may not always
be desirable for the appropriate visual output required.


=== 37.4 Node reference

[[BallJoint]]
==== 37.4.1 BallJoint

[source,node]
----
BallJoint : X3DRigidJointNode {
  SFVec3f  [in,out] anchorPoint      0 0 0
  SFNode   [in,out] body1            NULL   [RigidBody]
  SFNode   [in,out] body2            NULL   [RigidBody]
  MFString [in,out] forceOutput      "NONE" ["ALL","NONE",...]
  SFNode   [in,out] metadata         NULL   [X3DMetadataObject]
  SFVec3f  [out]    body1AnchorPoint
  SFVec3f  [out]    body2AnchorPoint
}
----

The BallJoint node represents an unconstrained joint between two bodies
that pivot about a common anchor point.

_body1AnchorPoint_ and _body2AnchorPoint_ represent the output that
describes where the _anchorPoint_ is relative to the two bodies local
coordinate reference frame. This can be used to detect if the joint has
caused a separation if the two values are not the same for a given frame
of reference.

[[CollidableOffset]]
==== 37.4.2 CollidableOffset

[source,node]
----
CollidableOffset : X3DNBodyCollidableNode, X3DBoundedObject {
  SFBool     [in,out] bboxDisplay FALSE
  SFBool     [in,out] enabled     TRUE
  SFNode     [in,out] metadata    NULL     [X3DMetadataObject]
  SFRotation [in,out] rotation    0 0 1 0  [0,1]
  SFVec3f    [in,out] translation 0 0 0    (-∞,∞)
  SFBool     [in,out] visible     TRUE
  SFVec3f    []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize    -1 -1 -1 [0,∞) or -1 -1 -1
  SFNode     []       collidable  NULL     [X3DNBodyCollidableNode]
}
----

The CollidableOffset node is used to reposition a piece of geometry
relative to the center of the owning body while keeping it consistent
within the geometry space.

The _collidable_ field holds a reference to a single nested item of a
collidable scene graph. If there are multiple transformation paths to
this reference, the results are undefined.

[[CollidableShape]]
==== 37.4.3 CollidableShape

[source,node]
----
CollidableShape : X3DNBodyCollidableNode  {
  SFBool     [in,out] bboxDisplay FALSE
  SFBool     [in,out] enabled     TRUE
  SFNode     [in,out] metadata    NULL     [X3DMetadataObject]
  SFRotation [in,out] rotation    0 0 1 0  [0,1]
  SFVec3f    [in,out] translation 0 0 0    (-∞,∞)
  SFBool     [in,out] visible     TRUE
  SFVec3f    []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize    -1 -1 -1 [0,∞) or -1 -1 -1
  SFNode     []       shape       NULL     [Shape]
}
----

The CollidableShape node represents the glue between the
collision-detection system, the rigid body model, and the renderable
scene graph. Its job is to take a single piece of geometry wrapped in a
<<Shape>> node and provide a way for the physics model body to
move the geometry. In addition, it allows the collision detection system
to determine the location of the geometry primitives that it uses for
collision management. When placed under a part of the transformation
hierarchy, it can be used to visually represent the movement of the
object.

The _shape_ field uses the geometry proxy for specifying which geometry
best represents the collidable object.

NOTE  Since the shape node is still writable, it is strongly recommended
that the author not dynamically change the Shape node's _geometry_ field
as it may have large performance impacts due to optimizations used by
the collision system.

Not all geometry types are mappable to the collision node type.

EXAMPLE  PointSet

If the containing shape node is given an explicit bounding box size, the
geometry shall be approximated using that shape for the purposes of
collision detection. If there is no bounding box, the results are
implementation-dependent.

[[CollisionCollection]]
==== 37.4.4 CollisionCollection

[source,node]
----
CollisionCollection : X3DChildNode, X3DBoundedObject {
  MFString [in,out] appliedParameters        "BOUNCE" ["BOUNCE","USER_FRICTION","FRICTION_COEFFICIENT_2","ERROR_REDUCTION",
                                                       "CONSTANT_FORCE","SPEED_1","SPEED_2","SLIP_1","SLIP_2"]
  SFBool   [in,out] bboxDisplay                       FALSE
  SFFloat  [in,out] bounce                   0        [0,1]
  MFNode   [in,out] collidables              []       [X3DNBodyCollisionSpaceNode,
                                                       X3DNBodyCollidableNode]
  SFString [in,out] description              ""
  SFBool   [in,out] enabled                  TRUE
  SFVec2f  [in,out] frictionCoefficients     0 0      [0,∞)
  SFNode   [in,out] metadata                 NULL     [X3DMetadataObject]
  SFFloat  [in,out] minBounceSpeed           0.1      [0,∞)
  SFVec2f  [in,out] slipFactors              0 0      (-∞,∞)
  SFFloat  [in,out] softnessConstantForceMix 0.0001   [0,1]
  SFFloat  [in,out] softnessErrorCorrection  0.8      [0,1]
  SFVec2f  [in,out] surfaceSpeed             0 0      (-∞,∞)
  SFBool   [in,out] visible                  TRUE
  SFVec3f  []       bboxCenter               0 0 0    (-∞,∞)
  SFVec3f  []       bboxSize                 -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The CollisionCollection node holds a collection of objects in the
_collidables_ field that can be managed as a single entity for
resolution of inter-object collisions with other groups of collidable
objects. A group consists of both collidable objects as well as spaces
that may be collided against each other. A set of parameters are
provided that specify default values that will be assigned to all
<<Contact>> nodes generated from the
<<CollisionSensor>> node. A user may then override
the individual Contact node by inserting a script between the output of
the sensor and the input to the
<<RigidBodyCollection>> node if it is desired to
process the contact stream.

The _enabled_ field is used to control whether the collision-detection
system for this collection should be run at the end of this presentation
frame. A value of `TRUE` enables it while a value of
`FALSE` disables it. A CollisionSensor node watching this
collection does not report any outputs for this collection for this
presentation frame if it is not enabled.

The _bounce_ field indicates how bouncy the surface contact is. A value
of 0 indicates no bounce at all while a value of 1 indicates maximum
bounce.

The _minBounceSpeed_ field indicates the minimum speed, in speed base
units, that an object shall have before an object will bounce. If the
object is below this speed, it will not bounce, effectively having an
equivalent value for the _bounce_ field of zero.

The _surfaceSpeed_ field defines the speed in the two friction
directions in speed base units. This is used to indicate if the contact
surface is moving independently of the motion of the bodies.

EXAMPLE  a conveyor belt.

The _softnessConstantForceMix_ value applies a constant force value to
make the colliding surfaces appear to be somewhat soft.

The _softnessErrorCorrection_ determines how much of the collision error
should be fixed in a set of evaluations. The value is limited to the
range of [0,1]. A value of 0 specifies no error correction while a value
of 1 specifies that all errors should be corrected in a single step.

The _appliedParameters_ indicates globally which parameters are to be
applied to the collision outputs when passing information into the the
rigid body physics system. These parameters specify a series of defaults
that apply to all contacts generated. Individual contacts may override
which values are applicable, if needed, by setting the field of the same
name in the contact itself. The valid values are specified in
<<t37_2, Table 37.2>>:

[[t37_2]]
Table 37.2 — _appliedParameters_
valid values

[cols=",",options="header",]
|===
|Value |Meaning
|`"BOUNCE"` |The bounce field value is used.

|`"USER_FRICTION"` |The system will normally calculate the
friction direction vector that is perpendicular to the contact normal.
This setting indicates that the user-supplied value in this contact
should be used.

|`"FRICTION_COEFFICIENT_2`" |The _frictionCoefficients_ field
values are used.

|`"ERROR_REDUCTION"` |The _softnessErrorCorrection_ field value
in the contact evaluation should be used.

|`"CONSTANT_FORCE"` |The _softnessConstantForceMix_ field value
in the contact evaluation should be used.

|`"SPEED_1"` |The _surfaceSpeed_ field value first component is
used.

|`"SPEED_2"` |The _surfaceSpeed_ field value second component is
used.

|`"SLIP_1"` |The _slipFactors_ field value first component is
used.

|`"SLIP_2"` |The _slipFactors_ field value second component is
used.
|===

[[CollisionSensor]]
==== 37.4.5 CollisionSensor

[source,node]
----
CollisionSensor : X3DSensorNode {
  SFNode   [in,out] collider      NULL [CollisionCollection]
  SFString [in,out] description   ""
  SFBool   [in,out] enabled       TRUE
  SFNode   [in,out] metadata      NULL [X3DMetadataObject]
  MFNode   [out]    intersections      [X3DNBodyCollidableNode]
  MFNode   [out]    contacts           [Contact]
  SFBool   [out]    isActive
}
----

The CollisionSensor node is used to send collision-detection information
into the scene graph for user processing. The collision-detection system
does not require an instance of a CollisionSensor node to be present in
the scene in order for the physics model to run. The CollisionSensor
node is used to report contact information should the information be
required for other purposes.

The _collider_ field specifies a CollisionCollection node that holds a
_collidables_ field of nodes and spaces that are to be included in
collision-detection computations.

The _contacts_ field is used to report contacts that were generated as a
result of the scene graph changes last presentation frame. This field
generates instances of the <<Contact>> node.

NOTE  While it is possible to route from this field to the
_set_contacts_ field of the
<<RigidBodyCollection>> node, it is strongly
advised that this not be done. The collision system will have already
taken these into account internally and processed them in the visual
results from the last presentation frame. Setting the values again to
the RigidBodyCollection node will result in undefined behaviour.

The _contacts_ field is only available when using the RigidBodyPhysics
support level 2 and above.

The CollisionSensor shall be considered active ( _isActive_
`TRUE`) when contacts were detected as a result of movement of
the watched objects during the last presentation frame.

The _intersections_ field is used to report the colliding geometry that
was detected during the previous presentation frame.

[[CollisionSpace]]
==== 37.4.6 CollisionSpace

[source,node]
----
CollisionSpace : X3DNBodyCollisionSpaceNode {
  MFNode  [in,out] collidables NULL     [X3DNBodyCollisionSpaceNode, X3DNBodyCollidableNode]
  SFBool  [in,out] bboxDisplay FALSE
  SFBool  [in,out] enabled     TRUE
  SFNode  [in,out] metadata    NULL     [X3DMetadataObject]
  SFBool  [in,out] useGeometry FALSE
  SFBool  [in,out] visible     TRUE
  SFVec3f []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f []       bboxSize    -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The CollisionSpace node holds a collection of objects in the
_collidables_ field that can be considered as a single entity for
resolution of inter-object collisions with other groups of collidable
objects. A group consists of both collidable objects as well as nested
collections. This grouping allows creation of efficient collision
detection scenarios by grouping functional sets of objects together.
Spaces may be collided against each other to determine if the larger
group of objects are anywhere near each other. If there is some
intersection between two spaces, or between a collidable space and a
collidable object, the system will traverse into the contained objects
looking for finer resolution on exactly which objects collided together.

The _useGeometry_ field indicates whether the collision-detection code
should check for collisions down to the level of geometry or only make
approximations using the bounds of the geometry. Using the geometry will
be more accurate but slower. In most cases, just testing against the
bounds of the object is sufficient.

[[Contact]]
==== 37.4.7 Contact

[source,node]
----
Contact : X3DNode {
  MFString [in,out] appliedParameters        "BOUNCE" ["BOUNCE","USER_FRICTION","FRICTION_COEFFICIENT_2","ERROR_REDUCTION",
                                                       "CONSTANT_FORCE","SPEED_1","SPEED_2","SLIP_1","SLIP_2"]
  SFNode   [in,out] body1                    NULL     [RigidBody]
  SFNode   [in,out] body2                    NULL     [RigidBody]
  SFFloat  [in,out] bounce                   0        [0,1]
  SFVec3f  [in,out] contactNormal            0 1 0    (-∞,∞)
  SFFloat  [in,out] depth                    0        (-∞,∞)
  SFVec2f  [in,out] frictionCoefficients     0 0      [0,∞)
  SFVec3f  [in,out] frictionDirection        0 1 0    (-∞,∞)
  SFNode   [in,out] geometry1                NULL     [X3DNBodyCollidableNode]
  SFNode   [in,out] geometry2                NULL     [X3DNBodyCollidableNode]
  SFNode   [in,out] metadata                 NULL     [X3DMetadataObject]
  SFFloat  [in,out] minBounceSpeed           0        [0,∞)
  SFVec3f  [in,out] position                 0 0 0    (-∞,∞)
  SFVec2f  [in,out] slipCoefficients         0 0      (-∞,∞)
  SFFloat  [in,out] softnessConstantForceMix 0.0001   [0,1]
  SFFloat  [in,out] softnessErrorCorrection  0.8      [0,1]
  SFVec2f  [in,out] surfaceSpeed             0 0      (-∞,∞)
}
----

The Contact node specifies information concerning a contact between
collidable objects and/or spaces.

The _body1_ and _body2_ fields specify two top-level nodes that should
be evaluated in the physics model as a single set of interactions with
respect to each other.

The _geometry1_ and _geometry2_ fields specify information about _body1_
and _body2_.

The _position_ field indicates the exact location of the contact that
was made between the two objects.

The _contactNormal_ field is a unit vector describing the normal between
the two colliding bodies.

The _depth_ field indicates how deep the current intersection is along
the normal vector.

The _frictionDirection_ field is used to control the vector that
describes which way friction is to be applied to the contact location.
If there is no friction, the direction should be set to 0, 0, 0.

The _bounce_ field indicates how bouncy the surface contact is. A value
of 0 indicates no bounce at all while a value of 1 indicates maximum
bounce.

The _minBounceSpeed_ field indicates the minimum speed, in speed base
units, that an object shall have before an object will bounce. If the
object is below this speed, it will not bounce, effectively having an
equivalent value for the _bounce_ field of zero.

The _surfaceSpeed_ field defines the speed in the two friction
directions in speed base units. This is used to indicate whether the
contact surface is moving independently of the motion of the bodies.

EXAMPLE  A conveyor belt mechanism may be stationary while its belt is
moving. The object being placed on the conveyor belt will not be
affected by the motion of the belt until it is in contact with it.

The _softnessConstantForceMix_ value applies a constant force value to
make the colliding surfaces appear to be somewhat soft.

The _softnessErrorCorrection_ determines how much of the collision error
should be fixed in a set of evaluations. The value is limited to the
range of [0,1] where 0 specifies no error correction while a value of 1
specifies that all errors should be corrected in a single step.

The _appliedParameters_ indicates globally which parameters are to be
applied to the collision outputs when passing information into the the
rigid body physics system. These parameters specify a series of defaults
that apply to all contacts generated. Individual contacts may override
which values are applicable, if needed, by setting the field of the same
name in the contact itself. The valid values are specified in
<<t37_2, Table 37.2>>.

[[DoubleAxisHingeJoint]]
==== 37.4.8 DoubleAxisHingeJoint

[source,node]
----
DoubleAxisHingeJoint : X3DRigidJointNode {
  SFVec3f  [in,out] anchorPoint               0 0 0
  SFVec3f  [in,out] axis1                     1 0 0
  SFVec3f  [in,out] axis2                     0 1 0
  SFNode   [in,out] body1                     NULL   [RigidBody]
  SFNode   [in,out] body2                     NULL   [RigidBody]
  SFFloat  [in,out] desiredAngularVelocity1   0      (-∞,∞)
  SFFloat  [in,out] desiredAngularVelocity2   0      (-∞,∞)
  MFString [in,out] forceOutput               "NONE" ["ALL","NONE",...]
  SFFloat  [in,out] maxAngle1                 π      [-2π,2π]
  SFFloat  [in,out] maxTorque1                0      (-∞,∞)
  SFFloat  [in,out] maxTorque2                0      (-∞,∞)
  SFNode   [in,out] metadata                  NULL   [X3DMetadataObject]
  SFFloat  [in,out] minAngle1                 -π     [-2π,2π]
  SFFloat  [in,out] stop1Bounce               0      [0,1]
  SFFloat  [in,out] stop1ConstantForceMix     0.001  [0,∞)
  SFFloat  [in,out] stop1ErrorCorrection      0.8    [0,1]
  SFFloat  [in,out] suspensionErrorCorrection 0.8    [0,1]
  SFFloat  [in,out] suspensionForce           0      [0,∞)
  SFVec3f  [out]    body1AnchorPoint
  SFVec3f  [out]    body1Axis
  SFVec3f  [out]    body2AnchorPoint
  SFVec3f  [out]    body2Axis
  SFFloat  [out]    hinge1Angle
  SFFloat  [out]    hinge1AngleRate
  SFFloat  [out]    hinge2Angle
  SFFloat  [out]    hinge2AngleRate
}
----

The DoubleAxisHingeJoint node represents a joint that has two
independent axes that are located around a common anchor point. Field
_axis1_ is specified relative to the first body (specified by the
_body1_ field) and field _axis2_ is specified relative to the second
body (specified by the _body2_ field). Field _axis1_ can have limits and
a motor, field _axis2_ can only have a motor. If an axis field has value
`+0 0 0+`, the corresponding axis is disabled and the motor does not
apply a force or torque along that axis.

The _minAngle1_ and _maxAngle1_ fields are used to control the maximum
angles through which the hinge is allowed to travel. A hinge may not
travel more than π radians (or the equivalent angle base
units) in either direction from its initial position.

The _stop1Bounce_ field is used to set how bouncy the minimum and
maximum angle stops are for field _axis1_. A value of zero means they
are not bouncy while a value of 1 means maximum bounciness (full
reflection of force arriving at the stop).

The _stopErrorCorrection1_ and _suspensionErrorCorrection_ fields
describe how quickly the system should resolve intersection errors due
to floating point inaccuracies. This value ranges between 0 and 1. A
value of 0 means no correction at all while a value of 1 indicates that
all errors should be corrected in a single step.

The _stopConstantForceMix1_ and _suspensionForce_ fields can be used to
apply damping to the calculations by violating the normal constraints by
applying a small, constant force to those calculations. This allows
joints and bodies to be a fraction springy, as well as helping to
eliminate numerical instability. The larger the value, the more soft
each of the constraints being evaluated. A value of zero indicates hard
constraints so that everything is exactly honoured. By combining the
_stopErrorCorrection1_ and _stopConstantForceMix1_ fields and/or the
_suspensionErrorCorrection_ and _suspensionForce_ fields, various
effects, such as spring-driven or spongy connections, can be emulated.

The _maxTorque1_ field defines the maximum amount of torque that the
motor can apply on field _axis1_ in order to achieve the
_desiredAngularVelocity1_ value. Similarly, _maxTorque2_ controls the
maximum amount of torque to achieve _desiredAngularVelocity2_ on field
_axis2_.

The __hinge__X _Angle_ output fields report the current relative angle
between the two bodies in angle base units and the __hinge__X
_angleRate_ field describes the rate at which that angle is currently
changing in angular velocity base units.

The body anchor point and body axis output fields report the current
location of the anchor point relative to the corresponding body. This
can be used to determine if the joint has broken.

[[MotorJoint]]
==== 37.4.9 MotorJoint

[source,node]
----
MotorJoint : X3DRigidJointNode {
  SFFloat  [in,out] axis1Angle           0      [-π,π]
  SFFloat  [in,out] axis1Torque          0      (-∞,∞)
  SFFloat  [in,out] axis2Angle           0      [-π,π]
  SFFloat  [in,out] axis2Torque          0      (-∞,∞)
  SFFloat  [in,out] axis3Angle           0      [-π,π]
  SFFloat  [in,out] axis3Torque          0      (-∞,∞)
  SFNode   [in,out] body1                NULL   [RigidBody]
  SFNode   [in,out] body2                NULL   [RigidBody]
  SFInt32  [in,out] enabledAxes          1  [0,3]
  MFString [in,out] forceOutput          "NONE" ["ALL","NONE",...]
  SFNode   [in,out] metadata             NULL   [X3DMetadataObject]
  SFVec3f  [in,out] motor1Axis           1 0 0
  SFVec3f  [in,out] motor2Axis           0 1 0
  SFVec3f  [in,out] motor3Axis           0 0 1
  SFFloat  [in,out] stop1Bounce          0      [0,1]
  SFFloat  [in,out] stop1ErrorCorrection 0.8    [0,1]
  SFFloat  [in,out] stop2Bounce          0      [0,1]
  SFFloat  [in,out] stop2ErrorCorrection 0.8    [0,1]
  SFFloat  [in,out] stop3Bounce          0      [0,1]
  SFFloat  [in,out] stop3ErrorCorrection 0.8    [0,1]
  SFFloat  [out]    motor1Angle
  SFFloat  [out]    motor1AngleRate
  SFFloat  [out]    motor2Angle
  SFFloat  [out]    motor2AngleRate
  SFFloat  [out]    motor3Angle
  SFFloat  [out]    motor3AngleRate
  SFBool   []       autoCalc             FALSE
}
----

The MotorJoint node allows control of the relative angular velocities
between the two bodies (specified by the _body1_ and _body2_ fields)
associated with a joint. This can be especially useful with a
<<BallJoint>> where there is no restriction on the angular
degrees of freedom.

The _autoCalc_ field is used to control whether external events can
provide the individual angle rotations during each presentation frame,
or if they are to be automatically calculated from the motor's
implementation.

The motorAxis fields define the axis vector of the corresponding axis.
If any motorAxis field has value `+0 0 0+`, the corresponding axis is
disabled and the motor does not apply a force or torque along that axis.
The _motorAxis1_ field is anchored to the global frame of reference, the
_motorAxis2_ field is anchored to the frame of reference for _body1_,
and the _motorAxis3_ field is anchored to the frame of reference for
_body2_.

The three axis-angle fields _axis1Angle_, _axis2Angle_ and _axis3Angle_
provide angles (in angle base units) for this frame of reference for the
corresponding motor axis when in user-calculated mode.

The three axis-torque fields _axis1Torque_, _axis2Torque_ and
_axis3Torque_ define the torque value applied about each axis.

When the _autoCalc_ field is set to `FALSE`, the _enabledAxes_
field indicates how many axes can currently be controlled and modified.
If the value is zero, the motor is effectively disabled. If the value is
1, only _motor1Axis_ is enabled, a value of 2 has _motor1Axis_ and
_motor2Axis_ enabled, and a value of 3 has all axes enabled.

The motor angle output fields provide the calculated angle (in angle
base units) for this motor joint from the last presentation frame. The
motor angle rate output fields describe the rate, in angular velocity
base units, that the motor is turning.

The stop bounce fields describe how much the joint should bounce the
body back on the corresponding axis if the joint limit has been reached
or exceeded. A value of zero indicates no bounce at all, and a value of
one says that it should bounce with velocity equal and opposite to the
collision velocity of the contact.

The stop error correction fields describe the amount of error correction
to be performed in a time step when the joint reaches the limit on the
corresponding axis. A value of zero means no error correction is to be
performed and a value of one means all error should be corrected in a
single step.

[[RigidBody]]
==== 37.4.10 RigidBody

[source,node]
----
RigidBody : X3DNode, X3DBoundedObject {
  SFFloat    [in,out] angularDampingFactor 0.001   [0,1]
  SFVec3f    [in,out] angularVelocity      0 0 0   (-∞,∞)
  SFBool     [in,out] autoDamp             FALSE
  SFBool     [in,out] autoDisable          FALSE
  SFBool     [in,out] bboxDisplay          FALSE
  SFVec3f    [in,out] centerOfMass         0 0 0   (-∞,∞)
  SFFloat    [in,out] disableAngularSpeed  0       [0,∞)
  SFFloat    [in,out] disableLinearSpeed   0       [0,∞)
  SFTime     [in,out] disableTime          0       [0,∞)
  SFBool     [in,out] enabled              TRUE
  SFVec3f    [in,out] finiteRotationAxis  0 0 0 0 1 0   [-1,1]
  SFBool     [in,out] fixed                FALSE
  MFVec3f    [in,out] forces               []
  MFNode     [in,out] geometry             []      [X3DNBodyCollidableNode]
  SFMatrix3f [in,out] inertia              1 0 0
                                           0 1 0
                                           0 0 1
  SFFloat    [in,out] linearDampingFactor  0.001   [0,1]
  SFVec3f    [in,out] linearVelocity       0 0 0   (-∞,∞)
  SFFloat    [in,out] mass                 1       (0,∞)
  SFNode     [in,out] massDensityModel     NULL    [Sphere, Box, Cone]
  SFNode     [in,out] metadata             NULL    [X3DMetadataObject]
  SFRotation [in,out] orientation          0 0 1 0 [0,1]
  SFVec3f    [in,out] position             0 0 0   (-∞,∞)
  MFVec3f    [in,out] torques              []
  SFBool     [in,out] useFiniteRotation    FALSE
  SFBool     [in,out] useGlobalGravity     TRUE
  SFBool     [in,out] visible     TRUE
  SFVec3f    []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f    []       bboxSize    -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The RigidBody node describes a body and its properties that can be
affected by the physics model. A body is modelled as a collection of
shapes that describe mass distribution rather than renderable geometry.
Bodies are connected together using Joints and are represented by
geometry.

The _geometry_ field is used to connect the body modelled by the physics
engine implementation to the real geometry of the scene through the use
of collidable nodes. This allows the geometry to be connected directly
to the physics model as well as collision detection. Collidable nodes
have their location set to the same location as the body instance in
which they are located. Their position and location are not relative to
this object, unless otherwise defined.

The _massDensityModel_ field is used to describe the geometry type and
dimensions used to calculate the mass density in the physics model. This
geometry has no renderable property, other than for defining the model
of the mass density. It is not rendered, nor modified by the physics
model.

The _finiteRotationAxis_ field specifies a vector around which the
object rotates. The _finiteRotationAxis_ field shall be a non-degenerate
vector; a value of `+0 0 0+` is not allowed.

The _useFiniteRotation_ field is used to influence the way the body's
rotation is calculated. In very fast rotating objects, such as a wheel
of a car, an infinitely small time step can cause the modelling to
explode. The default value is to use the faster infinite mode. Setting
the field value to `TRUE` uses the finite calculation model.
Using the finite model is more costly to compute but will be more
accurate for high rotation speed bodies.

The _useGlobalGravity_ field is used to indicate whether this particular
body should be influenced by the containing
<<RigidBodyCollection>>'s _gravity_ setting. A
value of `TRUE` indicates that the gravity is used, a value of
`FALSE` indicates that it is not used. This only applies to this
body instance. Contained sub-bodies shall not be affected by this
setting.

The _inertia_ field represents a 3x2 3x3 inertia tensor matrix. If the
set values are less than six items, the results are implementation
dependent. If the value set is greater than six values, only the first
six values of the array are used.

The _fixed_ field is used to indicate that this body does not move. Any
calculations involving collisions with this body should take into
account that this body does not move. This is useful for representing
objects such as the ground, walls etc. that can be collided with, have
an effect on other objects, but are not capable of moving themselves.

The _mass_ field indicates the mass of the body in mass base units. All
bodies shall have a non-zero mass, with the default value of 1 mass base
unit.

The damping factor fields, _linearDampingFactor_ and
_angularDampingFactor_, allow the user to instruct the implementation to
automatically damp the motion of the body over time. The value of the
field is used to take a multiple of the value calculated in the last
presentation frame and apply it in opposition to the current motion for
this presentation frame. Damping is useful to provide an appearance of
frictional forces and also to prevent the body from exploding due to
numerical instability of the physics model calculations. Damping is
proportional to the current velocity and/or rotation of the object. The
application of damping is controlled through the use of the _autoDamp_
field. When the value is `FALSE`, no damping is applied. When the
value is `TRUE`, rotational and translational damping is
calculated and applied.

EXAMPLE  The body is calculated in the previous presentation frame to
have a velocity of (0 1 0). A damping factor of 0.01 is active. In this
next simulation time step, a force of 0.01 × (0 1 0) × -1 is applied to
the object.

The _torques_ and _forces_ fields define zero or more sets of torque and
force values that are applied to the object every presentation frame.
These are continuously applied until reset to zero by the user.

The velocity fields are used to provide a constant velocity value to the
object every presentation frame. If both forces and velocity are
defined, the velocity is used only on the first presentation frame that
the node is active, and then the forces are applied. The velocity fields
then report the changed values as a result of the application of the
physics model in each presentation frame. Setting a new value to the
appropriate field will reset the body's velocity for the next
presentation frame. Caution should be used in doing this as the
underlying physics models may assume some amount of caching between time
step evaluations and instantaneous velocity changes may lead to
numerical instability.

The _position_ and _orientation_ fields are used to set the initial
conditions of this body's location in world space. After the initial
conditions have been set, these fields are used to report the current
information based on the most recent physics model evaluation. Setting
new values will cause the objects to be moved to the new location and
orientation for the start of the next evaluation cycle. Care should be
used in manually changing the _position_ and _orientation_ as the
underlying physics models may cache information between time step
evaluations and sudden instantaneous changes may lead to numerical
instability.

The disable fields define conditions for when the body ceases to
considered as part of the rigid body calculations and should be
considered as at rest. Due to the numerical instability of physics
models, even bodies initially declared to be at rest may gain some
amount of movement, even when not affected by an external forces. These
values define tolerances for which the physics model should start to
ignore this object in any calculation, thus resulting in them being
actually at rest and not subject to these instability conditions. Once
any one of these values is achieved, the body is considered as being at
rest unless acted upon by an external force ( _e.g._, collision or
action of connected joint). By default, this automatic disabling is
turned off. It may be enabled by setting the _autoDisable_ field to
`TRUE`.

The _enabled_ field controls whether the information in this node is
submitted to the physics engine for processing. If the _enabled_ field
is set `TRUE`, the node is submitted to the physics engine. If
the _enabled_ field is set `FALSE`, the node is not submitted to
the physics engine for processing.

[[RigidBodyCollection]]
==== 37.4.11 RigidBodyCollection

[source,node]
----
RigidBodyCollection : X3DChildNode, X3DBoundedObject {
  MFNode  [in]     set_contacts                     [Contact] 
  SFBool  [in,out] autoDisable             FALSE
  SFBool  [in,out] bboxDisplay             FALSE
  MFNode  [in,out] bodies                  []       [RigidBody]
  SFFloat [in,out] constantForceMix        0.0001   [0,∞)
  SFFloat [in,out] contactSurfaceThickness 0        [0,∞)
  SFFloat [in,out] disableAngularSpeed     0        [0,∞)
  SFFloat [in,out] disableLinearSpeed      0        [0,∞)
  SFTime  [in,out] disableTime             0       [0,∞)
  SFBool  [in,out] enabled                 TRUE
  SFFloat [in,out] errorCorrection         0.8      [0,1]
  SFVec3f [in,out] gravity                 0 -9.8 0
  SFInt32 [in,out] iterations              10       [0,∞)
  MFNode  [in,out] joints                  []       [X3DRigidJointNode]
  SFFloat [in,out] maxCorrectionSpeed      -1       [0,∞) or -1
  SFNode  [in,out] metadata                NULL     [X3DMetadataObject]
  SFBool  [in,out] preferAccuracy          FALSE
  SFBool  [in,out] visible                 TRUE
  SFVec3f []       bboxCenter              0 0 0    (-∞,∞)
  SFVec3f []       bboxSize                -1 -1 -1 [0,∞) or -1 -1 -1
  SFNode  []       collider                NULL     [CollisionCollection]
}
----

The RigidBodyCollection node represents a system of bodies that will
interact within a single physics model. The collection is not a
renderable part of the scene graph nor are its children as a typical
model may need to represent the geometry for physics separately, and in
less detail, than those needed for visuals.

The _bodies_ field contains a collection of the top-level nodes that
comprise a set of bodies that should be evaluated as a single set of
interactions.

The _joints_ field is used to register all the joints between the bodies
contained in this collection. If a joint is connected between bodies in
two different collections, the result is implementation-dependent. If a
joint instance is registered with more than one collection, the results
are implementation dependent. Joints not registered with any collection
are not evaluated.

The _enabled_ field is used to control whether the physics model for
this collection should be run for this presentation frame.

The _contactSurfaceThickness_ field represents how far bodies may
interpenetrate after a collision. This allows simulation of softer
bodies that may deform somewhat during collision. The default value is
zero.

NOTE  Since a value of 0 may cause jittering due to floating point
inaccuracy, a typically small value of 0.001 length base units may be
useful.

The _gravity_ field indicates direction and strength (in acceleration
base units) of the local gravity vector for this collection of bodies.
The default gravity is standard earth gravity of 9.8 meters/second^2^
downwards.

The _set_contacts_ input field is used to provide per-frame sets of
information about contacts between bodies during this presentation
frame. These contacts are then used to modify the location of the bodies
within the scene graph when the physics model is evaluated at the end of
the presentation frame. For efficiency, a user may reuse instances of
the Contact node for each presentation frame rather than allocating a
new instance per presentation frame. An X3D browser implementation shall
not make assumptions about the same object instance having the same
values each presentation frame.

The _preferAccuracy_ field is used to provide a performance hint to the
underlying evaluation about whether the user prefers to have very
accurate models or fast models. Accuracy comes at a large penalty in
both speed and memory usage, but may not be needed most of the time. The
default setting is to optimize for speed rather than accuracy.

The _iterations_ field is used to control how many iterations over the
collections of joints and bodies are to be performed each time the model
is evaluated. Rigid body physics is a process of iterative refinement in
order to maintain reasonable performance. As the number of iterations
grow, the more stable the final results are at the cost of increasing
evaluation time. Since maintaining real-time performance is a trade off
between accuracy and frame rate, this setting allows the user to control
that trade off to a limited extent.

The _errorCorrection_ field is a rate factor that describes how quickly
the system should resolve intersection errors due to floating point
inaccuracies. This value ranges between 0 and 1. A value of 0 means no
correction at all is performed, a value of 0.8 indicates that 80% of
each error is corrected in a single step, while a value of 1 indicates
that all errors should be each error is completely corrected in a single
step.

 +
The _maxCorrectionSpeed_ field limits the amount of change that can be
applied to resolve intersection error, effectively modifying object
positions, using an absolute value of speed. A value of -1 indicates
that no speed limitation exists, while a value of 0 indicates that no
corrections are allowed.

The _constantForceMix_ field can be used to apply damping to the
calculations by violating the normal constraints by applying a small,
constant force to those calculations. This allows joints and bodies to
be a fraction springy, as well as helping to eliminate numerical
instability. The larger the value, the more soft each of the constraints
being evaluated. A value of zero indicates hard constraints so that
everything is exactly honoured. By combining the _errorCorrection_ and
_constantForceMix_ fields, various effects, such as spring-driven or
spongy connections, can be emulated.

The _collider_ field associates a collision collection with this rigid
body collection allowing seamless updates and integration without the
need to use the X3D event model.

The disable fields define conditions for when the body ceases to
considered as part of the rigid body calculations and should be
considered as at rest. Due to the numerical instability of physics
models, even bodies initially declared to be at rest may gain some
amount of movement, even when not affected by an external forces. These
values define tolerances for which the physics model should start to
ignore this object in any calculation, thus resulting in them being
actually at rest and not subject to these instability conditions. Once
any one of these values is achieved, the body is considered as being at
rest, unless acted upon by an external force ( _e.g._, collision or
action of connected joint). By default, this automatic disabling is
turned off. It may be enabled by setting the _autoDisable_ field to
`TRUE`.

[[SingleAxisHingeJoint]]
==== 37.4.12 SingleAxisHingeJoint

[source,node]
----
SingleAxisHingeJoint : X3DRigidJointNode {
  SFVec3f  [in,out] anchorPoint         0 0 0
  SFVec3f  [in,out] axis                0 1 0
  SFNode   [in,out] body1               NULL   [RigidBody]
  SFNode   [in,out] body2               NULL   [RigidBody]
  MFString [in,out] forceOutput         "NONE" ["ALL","NONE",...]
  SFFloat  [in,out] maxAngle            π      [-2π,2π]
  SFFloat  [in,out] minAngle            -π     [-2π,2π]
  SFNode   [in,out] metadata            NULL   [X3DMetadataObject]
  SFFloat  [in,out] pickable            -π
  SFFloat  [in,out] stopBounce          0      [0,1]
  SFFloat  [in,out] stopErrorCorrection 0.8    [0,1]
  SFFloat  [out]    angle
  SFFloat  [out]    angleRate
  SFVec3f  [out]    body1AnchorPoint
  SFVec3f  [out]    body2AnchorPoint
}
----

This node represents a joint with a single axis about which to rotate.
As the name suggests, this is a joint that works like a traditional door
hinge. The axis of the hinge is defined to be along the unit vector
described in the _axis_ field and centered on the _anchorPoint_
described in world coordinates. The objects on each side of the hinge
are specified by the _body1_ and _body2_ fields. If the field _axis_ has
value `+0 0 0+`, rotation about the axis is disabled.

The _minAngle_ and _maxAngle_ fields are used to control the maximum
angles through which the hinge is allowed to travel. A hinge may not
travel more than π radians (or the equivalent angle base
units) in either direction from its initial position.

The _stopBounce_ field describes how much the joint should bounce the
body back if the joint limit has been reached or exceeded. A value of
zero indicates no bounce at all, and a value of one says that it should
bounce with velocity equal and opposite to the collision velocity of the
contact.

The _stopErrorCorrection_ field describes the amount of error correction
to be performed in a time step when the joint reaches the limit. A value
of zero means no error correction is to be performed and a value of one
means all error should be corrected in a single step.

The _angle_ output field reports the current relative angle between the
two bodies in angle base units and the _angleRate_ field describes the
rate at which that angle is currently changing in angular velocity base
units.

The body anchor point output fields report the current location of the
anchor point relative to the corresponding body. This can be used to
determine if the joint has broken.

[[SliderJoint]]
==== 37.4.13 SliderJoint

[source,node]
----
SliderJoint : X3DRigidJointNode {
  SFVec3f  [in,out] axis                0 1 0
  SFNode   [in,out] body1               NULL   [RigidBody]
  SFNode   [in,out] body2               NULL   [RigidBody]
  MFString [in,out] forceOutput         "NONE" ["ALL","NONE",...]
  SFFloat  [in,out] maxSeparation       1      [0,∞)
  SFNode   [in,out] metadata            NULL   [X3DMetadataObject]
  SFFloat  [in,out] minSeparation       0      [0,∞)
  SFFloat  [in,out] sliderForce         0      [-∞,∞)
  SFFloat  [in,out] stopBounce          0      [0,1]
  SFFloat  [in,out] stopErrorCorrection 1      [0,1]
  SFFloat  [out]    separation
  SFFloat  [out]    separationRate
}
----

The SliderJoint node represents a joint where all movement between the
bodies specified by the _body1_ and _body2_ fields is constrained to a
single dimension along a user-defined axis.

The _axis_ field indicates which axis along which the two bodies will
act. The value should represent a normalized vector. The _axis_ field
shall be a non-degenerate vector; a value of `+0 0 0+` is not allowed.

The _sliderForce_ field value is used to apply a force (specified in
force base units) along the axis of the slider in equal and opposite
directions to the two bodies. A positive value applies a force such that
the two bodies accelerate away from each other, while a negative value
applies a force such that the two bodies accelerate toward each other.

If _minSeparation_ is greater than _maxSeparation_, the stops become
ineffective as if the object has no stops at all.

The _separation_ output field is used to indicate the final separation
of the two bodies.

The _separationRate_ output field is used to indicate the change in
separation over time since the last update.

The _stopBounce_ field describes how much the joint should bounce the
body back if the joint limit has been reached or exceeded. A value of
zero indicates no bounce at all, and a value of one indicates that it
should bounce with velocity equal and opposite to the collision velocity
of the contact.

The _stopErrorCorrection_ field describes the amount of error correction
to be performed in a time step when the joint reaches the limit. A value
of zero means no error correction is to be performed and a value of one
means all error should be corrected in a single step.

[[UniversalJoint]]
==== 37.4.14 UniversalJoint

[source,node]
----
UniversalJoint : X3DRigidJointNode {
  SFVec3f  [in,out] anchorPoint          0 0 0
  SFVec3f  [in,out] axis1                1 0 0
  SFVec3f  [in,out] axis2                0 1 0
  SFNode   [in,out] body1                NULL   [RigidBody]
  SFNode   [in,out] body2                NULL   [RigidBody]
  MFString [in,out] forceOutput          "NONE" ["ALL","NONE",...]
  SFNode   [in,out] metadata             NULL   [X3DMetadataObject]
  SFFloat  [in,out] stop1Bounce          0      [0,1]
  SFFloat  [in,out] stop1ErrorCorrection 0.8    [0,1]
  SFFloat  [in,out] stop2Bounce          0      [0,1]
  SFFloat  [in,out] stop2ErrorCorrection 0.8    [0,1]
  SFVec3f  [out]    body1AnchorPoint
  SFVec3f  [out]    body1Axis
  SFVec3f  [out]    body2AnchorPoint
  SFVec3f  [out]    body2Axis
}
----

A universal joint is like a BallJoint that constrains an extra degree of
rotational freedom. Given the axis specified by the _axis1_ field on the
body specified by the _body1_ field, and the axis specified by the
_axis2_ field on body2 that is perpendicular to _axis1_, the
UniversalJoint node keeps the axes perpendicular to each other. Thus,
rotation of the two bodies about the direction perpendicular to the two
axes will be equal. If an axis field has value `+0 0 0+`, rotation about
that axis is disabled.

The vectors specified by the _axis1_ and _axis2_ fields shall be
perpendicular. If not, the interactions are undefined.

The stop bounce fields describe how much the joint should bounce the
body back on the corresponding axis if the joint limit has been reached
or exceeded. A value of zero indicates no bounce at all, and a value of
one indicates that it should bounce with velocity equal and opposite to
the collision velocity of the contact.

The stop error correction fields describe the amount of error correction
to be performed in a time step when the joint reaches the limit on the
corresponding axis. A value of zero means no error correction is to be
performed and a value of one means all error should be corrected in a
single step.

The body anchor point and body axis output fields report the current
location of the anchor point relative to the corresponding body. This
can be used to determine if the joint has broken.

[[S37.5_SupportLevels]]
=== 37.5 Support levels

The Rigid Body Physics component defines two levels of support as
specified in <<t37_3, Table 37.3>>.

[[t37_3]]
Table 37.3 — Rigid body physics component support
levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Geometry3D 1 + | |
| | |_X3DNBodyCollidableNode_ |n/a
| | |_X3DNBodyCollisionSpaceNode_ |n/a
| | |CollidableOffset |All fields fully supported.
| | |CollidableShape |All fields fully supported.
| | |CollisionCollection |All fields fully supported.
| | |CollisionSensor |All fields fully supported except _contacts_.
| | |CollisionSpace |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Geometry3D 1 | |
| | |_X3DRigidJointNode_ |n/a
| | |BallJoint |All fields fully supported.
| | |CollisionSensor |All fields fully supported.
| | |Contact |All fields fully supported.
| | |DoubleAxisHingeJoint |All fields fully supported.
| | |MotorJoint |All fields fully supported.
| | |RigidBody |All fields fully supported.
| | |RigidBodyCollection |All fields fully supported.
| | |SingleAxisHingeJoint |All fields fully supported.
| | |SliderJoint |All fields fully supported.
| | |UniversalJoint |All fields fully supported.
|===

[[picking_html]]
== 38 Picking component

[[S38_Introduction]]
=== 38.1 Introduction

[[S38_Name]]
==== 38.1.1 Name

The name of this component is "Picking". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S38_Overview]]
==== 38.1.2 Overview

This component provides the ability to test for arbitrary object
collision in a somewhat limited form. In traditional 3D graphics
terminology, this is termed picking. The intention is not to support
full n-body object collision, but to provide an extended set of basic
capabilities to provide some limited custom interactions, such as
terrain following. <<t38_1, Table 38.1>> provides links to the
major topics in this clause.

[[t38_1]]
Table 38.1 — Topics

* <<S38Introduction, 38.1 Introduction>>
** <<S38_Name, 38.1.1 Name>>
** <<S38_Overview, 38.1.2 Overview>>
* <<S38_Concepts, 38.2 Concepts>>
** <<OverviewOfPickingSensors, 38.2.1 Overview>>
** <<EventModelInteraction, 38.2.2 Event model interaction>>
** <<S38_TransformationHierarchy, 38.2.3 Transformation Hierarchy>>
* <<S38_AbstractTypes, 38.3 Abstract types>>
** <<X3DPickableObject, 38.3.1 _X3DPickableObject_>>
** <<X3DPickSensorNode, 38.3.2 _X3DPickSensorNode_>>
* <<S38_NodeReference, 38.4 Node reference>>
** <<LinePickSensor, 38.4.1 LinePickSensor>>
** <<PickableGroup, 38.4.2 PickableGroup>>
** <<PointPickSensor, 38.4.3 PointPickSensor>>
** <<PrimitivePickSensor, 38.4.4 PrimitivePickSensor>>
** <<VolumePickSensor, 38.4.5 VolumePickSensor>>
** <<S38_SupportLevels, 38.5 Support levels>>

* <<f-LineIntersection, Figure 38.1 — Illustration of the different conditions of intersections of lines and coplanar polygons>>

* <<t38_1, Table 38.1 — Topics>>
* <<t38_2, Table 38.2 — Picking component support levels>>




[[S38_Concepts]]
=== 38.2 Concepts

[[OverviewOfPickingSensors]]
==== 38.2.1 Overview

This component provides a means of testing for object intersection that
permits a greater degree of programmable interaction of content. Various
types of geometrical elements may be used to test for intersection
between the renderable scene graph and the nodes provided by this
component. When one or more intersections are found, the results are
reported using the sensor model of this document and are then available
for further processing by the event model.

Intersection testing consists of two parts: an object representing the
type of intersection to be created and a scene graph tree to be tested.
The intersecting object is represented by nodes that extend the
_X3DPickSensorNode_ abstract type. Instances of _X3DPickableObject_ mark
a scene graph subtree as a target for testing.

[[EventModelInteraction]]
==== 38.2.2 Event model interaction

Picking is performed between rendered frames of the event model. A user
sets up the picking request in one frame by placing, in the desired
location, a node derived from _X3DPickSensorNode_. Such a node is termed
a _pick sensor_. At the start of the next frame any intersections are
reported from the pick sensor.

Picking notification is performed at the start of the frame for all
enabled pick sensors when all other sensors are processed (see
<<ExecutionModel, 4.4.8.3 Execution model>> step b).  Disabled pick
sensors do not need to be evaluated. This allows the user to manipulate
geometry and have the pick results returned at the start of the frame,
thus ensuring a fixed, known state at all times.

[[S38_TransformationHierarchy]]
==== 38.2.3 Transformation Hierarchy

Testing for intersection tests is a global action within each execution
context. pick sensors may report intersections with contained contexts,
but only to the wrapper and not the contents of that context.

EXAMPLE  Picking against a scene that contains an Inline node will
return the Inline node as the picked geometry rather than a node from
the contents of the geometry.

A pick sensor is located at the desired position and orientation in the
scene graph using the transformation hierarchy. The pick sensor is
affected by translation, orientation and scale operations. If a
non-uniform scale is applied to the pick sensor, the results are
dependent on the selected component level.

The picked objects are those that have been given to that specific pick
sensor instance in its _pickTarget_ field.  All transformations above
those picked objects are applied to the picking process. Picking is
performed in world coordinate space after transformations have been
applied to both the pick sensor and the target nodes.

Sections of the scene graph contained by a _X3DPickableObject_ are used
for additional filtering of the picking operations. The pickable object
has a set of flags defined in the _objectType_ field that can be used to
classify sections of the scene graph so that picking will only report
intersections in those classifications.

EXAMPLE  A pickable object classifies itself as a "WATER" object and the
pick sensor declares that it is picking for "GROUND" objects. Even
though the pick sensor intersects with the picking object, no result is
returned because the pickable object and the pick sensor do not have the
same object type category.

When reporting results requires specific geometry intersection points,
the results are reported in the local coordinate space of the pick
sensor.


=== 38.3 Abstract types

[[X3DPickableObject]]
==== 38.3.1 _X3DPickableObject_

[source,node]
----
X3DPickableObject {
  MFString [in,out] objectType "ALL" ["ALL","NONE","TERRAIN",...]
  SFBool   [in,out] pickable   TRUE
}
----

The _X3DPickableObject_ abstract interface marks a node as being capable
of having customized picking performed on its contents or children.

The _pickable_ field is used to independently control whether picking
may be performed on this node or its children. Setting the value to
`FALSE` will remove the children from the list of potential
matches for picking. This only affects children that are accessed
through the transformation hierarchy of the parent. If one or more of
the children of this instance is accessible through another
transformation hierarchy through DEF/USE that still has picking enabled,
they shall still be pickable through that path only. Object picking
according to the _pickable_ field occurs even if the object is not
rendered visibly.

The _objectType_ field specifies a label that is used in the picking
process. Each string specified is treated as an independent label that
needs to be matched against the same type in one of the pick sensor
instances.

EXAMPLE  Labeling a group with the value `"WATER"` and then
attempting to intersect a pick sensor with _objectType_
`"GROUND"` would fail as the _objectType_ values are not
matching.

The special object type `"ALL"` means that it is available for
picking regardless of the type specified by the pick sensor. The special
value "NONE" overrides the presence of any other string values in this
_objectType_ field, thereby disabling picking for this node. The
presence of special value "ALL" indicates that all _objectType_ values
defined within the scope defined by the construct derived from
X3DPickableObject are eligible. If both "NONE" and "ALL" are specified,
the special value "NONE" applies. The user may define any values for
_objectType_.

[[X3DPickSensorNode]]
==== 38.3.2 _X3DPickSensorNode_

[source,node]
----
X3DPickSensorNode : X3DSensorNode {
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFNode   [in,out] metadata         NULL        [X3DMetadataObject]
  SFString [in,out] matchCriterion   "MATCH_ANY" ["MATCH_ANY"|"MATCH_EVERY"|"MATCH_ONLY_ONE"]
  MFString [in,out] objectType       "ALL"       ["ALL","NONE","TERRAIN",...]
  SFNode   [in,out] pickingGeometry  NULL        [X3DGeometryNode]
  MFNode   [in,out] pickTarget       []          [X3DGroupingNode|X3DShapeNode|Inline]
  MFNode   [out]    pickedGeometry
  SFBool   [out]    isActive
  SFString []       intersectionType "BOUNDS"    ["GEOMETRY"|"BOUNDS"|...]
  SFString []       sortOrder        "CLOSEST"   ["ANY"|"CLOSEST"|"ALL"|"ALL_SORTED"|...] 
}
----

The _X3DPickSensorNode_ abstract node type is the base type that
represents the lowest common denominator of picking capabilities. An
_X3DPickSensorNode_ is a type of _X3DSensorNode_. The field _isActive_
is `TRUE` whenever there is a picked item available. If the
intersecting object is not picked by the picking geometry, the pick
sensor is not active.

The _intersectionType_ field specifies the precision of the collision
computation. When testing intersections, "BOUNDS" indicates that the
_pickingGeometry_ is intersected with the bounding box of the pickable
object, whereas "GEOMETRY" indicates that the _pickingGeometry_ is
intersected with the geometry of the pickable object. The
_intersectionType_ constants may be extended by the individual concrete
node to provide additional options.

EXAMPLE 1  An _intersectionType_ may be used to specify the specific
algorithm used for the detection.

The _objectType_ field lists the types of object that are to be tested
for intersections. The special value "NONE" overrides the presence of
any other string values in this objectType field, thereby disabling
picking for this node. The presence of the "ALL" special value indicates
that all __objectType__s are potential pick targets. If both "NONE" and
"ALL" are specified, the value "NONE" applies. An arbitrary label (such
as "TERRAIN") may be specified here as well as the predefined types.
Such a label indicates that only pickable objects with an identical
label may be picked.

The _matchCriterion_ field defines whether the X3DPickSensorNode pick
matches one or more _objectType_ value(s), as follows:

* "`MATCH_ANY`" means that any match of _objectType_ values is
acceptable.
* "`MATCH_EVERY`" means that every _objectType_ value in the
X3DPickSensorNode shall match an _objectType_ value in the
X3DPickableObject.
* "`MATCH_ONLY_ONE`" means that one and only one _objectType_
value can match.

The _pickingGeometry_ field specifies the exact coordinates of the
geometry that will be performing the intersection testing. The
acceptable range of node types and how they are to be interpreted shall
be defined by the individual concrete nodes.

The _pickTarget_ field specifies the list of nodes against which the
picking operation should be performed. All nodes declared in this field
and their descendents shall be evaluated for intersections based on the
specific sensor definition. If a descendent of the nodes declared in
this field includes another _X3DPickSensorNode_ instance, the children
of the descendent _X3DPickSensorNode_'s _pickTarget_ field are not
considered for picking.

The _pickedGeometry_ field communicates the node or nodes that have been
found to intersect with the picking geometry from the last time this
node performed a picking operation. The values provided shall be
dependent on the setting of the _sortOrder_ field.

The _sortOrder_ field has four predefined values. Browser
implementations may define additional values and algorithms beyond these
four required values.

* `#"ANY"  `#Any single object that satisfies the picking
conditions for this pick sensor. Consistency of results is not
guaranteed.
* `#"ALL"  `#Every object that satisfies the picking conditions
for this pick sensor shall be returned.
* `#"ALL_SORTED"  `#Every object that satisfies the picking
conditions for this pick sensor shall be returned with the order of the
output fields provided in a distance-sorted order from closest to
farthest away. The exact algorithm for sorting is defined by the
individual node definitions.
* `#"CLOSEST"  `#The closest object by distance that satisfies
the conditions of this pick sensor. The exact algorithm for distance
determination shall be defined by the individual node definitions.


=== 38.4 Node reference

[[LinePickSensor]]
==== 38.4.1 LinePickSensor

[source,node]
----
LinePickSensor : X3DPickSensorNode {
  SFString [in,out] description             ""
  SFBool   [in,out] enabled                 TRUE
  SFString [in,out] matchCriterion          "MATCH_ANY" ["MATCH_ANY"|"MATCH_EVERY"|"MATCH_ONLY_ONE"]
  SFNode   [in,out] metadata                NULL        [X3DMetadataObject]
  MFString [in,out] objectType              "ALL"       ["ALL","NONE","TERRAIN",...]
  SFNode   [in,out] pickingGeometry         NULL        [IndexedLineSet|LineSet]
  MFNode   [in,out] pickTarget              []          [X3DGroupingNode|X3DShapeNode|Inline]
  SFBool   [out]    isActive
  MFNode   [out]    pickedGeometry
  MFVec3f  [out]    pickedNormal
  MFVec3f  [out]    pickedPoint
  MFVec3f  [out]    pickedTextureCoordinate
  SFString []       intersectionType        "BOUNDS"    ["GEOMETRY"|"BOUNDS"|...]
  SFString []       sortOrder               "CLOSEST"   ["ANY"|"CLOSEST"|"ALL"|"ALL_SORTED"|...] 
}
----

The LinePickSensor node picks one or more line segments as the test
object with which to pick. As a line intersect generates a known point
in space, normal, geometry and texCoord information can be returned that
is useful. +

Line picking, for sort order determination is based on the pair of
coordinates that defines the line segment. The first declared vertex of
the segment is defined to be the start of the line to which the
intersection points are closest.

When the picking line segment intersects a coplanar polygon and one
vertex lies outside the polygon, the intersection point(s) will be those
on the edge(s) of the polygon (see Figure 38.1 (a)). If the entire
segment lies entirely within the polygon then the intersection point
shall be defined to be the start point of the segment. For concave
polygons where both ends of the segment lie in the polygon but the line
exits the polygon for some portion (see
<<f-LineIntersectionConditions, Figure 38.1>> (b)), the intersection
points are the intersecting edges of the polygon, where sort order is
defined as in the previous paragraph.

[[f-LineIntersectionConditions]][[f-LineIntersection]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/LineIntersection.png[Illustration of Line Intersection conditions,width=600,height=300]

Figure 38.1 — Illustration of the different conditions of intersections
of lines and coplanar polygons. (a) One end point contained in the
polygon and one external. (b)Both end points internal to the polygon.
Point A is the start point of the line and the numbers indicate the sort
order that shall be returned.

Picked texture coordinates are in three dimensions. If the target object
has multiple textures defined, only the texture coordinates for the
first texture are returned. All other textures are ignored. If the
target texture coordinate has two dimensions, the third coordinate (z
component of an SFVec3f) shall be zero.

[[PickableGroup]]
==== 38.4.2 PickableGroup

[source,node]
----
PickableGroup : X3DGroupingNode, X3DPickableObject {
  MFNode   [in]     addChildren
  MFNode   [in]     removeChildren
  SFBool   [in,out] bboxDisplay    FALSE
  MFNode   [in,out] children       []       [X3DChildNode]
  SFString [in,out] description    ""
  SFNode   [in,out] metadata       NULL     [X3DMetadataObject]
  MFString [in,out] objectType     "ALL"    ["ALL","NONE","TERRAIN",...]
  SFBool   [in,out] pickable       TRUE
  SFBool   [in,out] visible        TRUE
  SFVec3f  []       bboxCenter     0 0 0    (-∞,∞)
  SFVec3f  []       bboxSize       -1 -1 -1 [0,∞) or -1 -1 -1
}
----

A PickableGroup node is an X3DGroupingNode that contains _children_ that
are marked as being of a given classification of picking types, as well
as the ability to enable or disable picking of the _children_.

<<X3DPickableObject, 38.3.1 _X3DPickableObject_>> and 
X3DGroupingNode]. +

[[PointPickSensor]]
==== 38.4.3 PointPickSensor

[source,node]
----
PointPickSensor : X3DPickSensorNode {
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFString [in,out] matchCriterion   "MATCH_ANY" ["MATCH_ANY"|"MATCH_EVERY"|"MATCH_ONLY_ONE"]
  SFNode   [in,out] metadata         NULL        [X3DMetadataObject]
  MFString [in,out] objectType       "ALL"       ["ALL","NONE","TERRAIN",...]
  SFNode   [in,out] pickingGeometry  NULL        [PointSet]
  MFNode   [in,out] pickTarget       []          [X3DGroupingNode|X3DShapeNode|Inline]
  SFBool   [out]    isActive
  MFNode   [out]    pickedGeometry
  MFVec3f  [out]    pickedPoint
  SFString []       intersectionType "BOUNDS"    ["GEOMETRY"|"BOUNDS"|...]
  SFString []       sortOrder        "CLOSEST"   ["ANY"|"CLOSEST"|"ALL"|"ALL_SORTED"|...] 
}
----

The PointPickSensor node tests one or more points in space as lying
inside the provided target geometry. For each of the picked points
intersecting the geometry, the point coordinate is returned as an
element in the pickedPoint field, and the corresponding geometry node
(inside which each intersection point lies) is returned as an element of
the pickedGeometry field.

Because points represent an infinitely small location in space, the
`"CLOSEST"` and `"ALL_SORTED"` sort orders are defined to
mean `"ANY"` and `"ALL"` respectively.

[[PrimitivePickSensor]]
==== 38.4.4 PrimitivePickSensor

[source,node]
----
PrimitivePickSensor : X3DPickSensorNode {
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFString [in,out] matchCriterion   "MATCH_ANY" ["MATCH_ANY"|"MATCH_EVERY"|"MATCH_ONLY_ONE"]
  SFNode   [in,out] metadata         NULL        [X3DMetadataObject]
  MFString [in,out] objectType       "ALL"       ["ALL","NONE","TERRAIN",...]
  SFNode   [in,out] pickingGeometry  NULL        [Cone|Cylinder|Sphere|Box]
  MFNode   [in,out] pickTarget       []          [X3DGroupingNode|X3DShapeNode|Inline]
  SFBool   [out]    isActive
  MFNode   [out]    pickedGeometry
  SFString []       intersectionType "BOUNDS"    ["GEOMETRY"|"BOUNDS"|...]
  SFString []       sortOrder        "CLOSEST"   ["ANY"|"CLOSEST"|"ALL"|"ALL_SORTED"|...] 
}
----

The PrimitivePickSensor node picks against the target geometry using one
of the basic primitive object types specified in the _pickingGeometry_
field.

Boolean fields used to control visibility of subsections of a primitive
are ignored when evaluating the picking routines.

EXAMPLE  A cylinder missing the end caps is still treated as an enclosed
cylinder.

Sorting is defined based on the primitive type as follows:

[loweralpha]
. For Cone, the closest picked primitive is defined to be that closest
to the vertex point.
. For Cylinder, Box, and Sphere, the closest picked primitive is defined
to be that closest to the centre.

[[VolumePickSensor]]
==== 38.4.5 VolumePickSensor

[source,node]
----
VolumePickSensor : X3DPickSensorNode {
  SFString [in,out] description      ""
  SFBool   [in,out] enabled          TRUE
  SFString [in,out] matchCriterion   "MATCH_ANY" ["MATCH_ANY"|"MATCH_EVERY"|"MATCH_ONLY_ONE"]
  SFNode   [in,out] metadata         NULL        [X3DMetadataObject]
  MFString [in,out] objectType       "ALL"       ["ALL","NONE","TERRAIN",...]
  SFNode   [in,out] pickingGeometry  NULL        [X3DGeometryNode]
  MFNode   [in,out] pickTarget       []          [X3DGroupingNode|X3DShapeNode|Inline]
  SFBool   [out]    isActive
  MFNode   [out]    pickedGeometry
  SFString []       intersectionType "BOUNDS"    ["GEOMETRY"|"BOUNDS"|...]
  SFString []       sortOrder        "CLOSEST"   ["ANY"|"CLOSEST"|"ALL"|"ALL_SORTED"|...] 
}
----

The VolumePickSensor picks against an arbitrary volume defined by the
geometry. The volume is defined by the convex hull of the enclosing
planes of the provided geometry. If the provided volume is not manifold,
the pick results are undefined.

A pick is successful if any vertex of the pickTarget geometry intersects
the volume defined by the pickingGeometry.  The sort order is based on
the distance between the centers of the bounds of the picking geometry
and the picked geometry.

[[S38.5_SupportLevels]]
=== 38.5 Support levels

The Picking component provides three levels of support as specified in
<<t38_2, Table 38.2>>.

[[t38_2]]
Table 38.2 — Picking component support levels

[width="100%",cols="25%,25%,25%,25%",]
|===
|Level |Prerequisites |Nodes/Features |Support

|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | |

| | |_X3DPickSensorNode_ |n/a

| | |_X3DPickableObject_ |n/a

| | |LinePickSensor |All fields fully supported.

| | |PickableGroup |All fields fully supported.

| | |PointPickSensor |All fields fully supported.

|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 |  | 

|  |  |All Level 1 nodes |All fields fully supported.

|  |  |PrimitivePickSensor |All fields fully supported. Non uniform
scale not supported.

|*3* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 |  | 

|  |  |All Level 2 nodes |All fields fully supported.

|  |  |PrimitivePickSensor |All fields fully supported. Non-uniform
scale supported.

|  |  |VolumePickSensor |All fields fully supported.
|===

[[followers_html]]
== 39 Followers component

Extensible 3D (X3D) +
Part 1: Architecture and base components

39 Followers component

[[S39_Introduction]]
=== 39.1 Introduction

[[S39_Name]]
==== 39.1.1 Name

The name of this component is "Followers". This name shall be used when
referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S39_Overview]]
==== 39.1.2 Overview

This clause describes the Followers component of this document. Follower
nodes support dynamic creation of smooth parameter transitions of chaser
and follower nodes at run time. <<t39_1, Table 39.1>> provides
links to the major topics in this clause.

[[t39_1]]
Table 39.1 — Topics

* <<S39Introduction, 39.1 Introduction>>
** <<S39_Name, 39.1.1 Name>>
** <<S39_Overview, 39.1.2 Overview>>
* <<S39_Concepts, 39.2 Concepts>>
* <<S39_AbstractTypes, 39.3 Abstract types>>
** <<X3DChaserNode, 39.3.1 _X3DChaserNode_>>
** <<X3DDamperNode, 39.3.2 _X3DDamperNode_>>
** <<X3DFollowerNode, 39.3.3 _X3DFollowerNode_>>
* <<S39_NodeReference, 39.4 Node reference>>
** <<ColorChaser, 39.4.1 ColorChaser>>
** <<ColorDamper, 39.4.2 ColorDamper>>
** <<CoordinateChaser, 39.4.3 CoordinateChaser>>
** <<CoordinateDamper, 39.4.4 CoordinateDamper>>
** <<OrientationChaser, 39.4.5 OrientationChaser>>
** <<OrientationDamper, 39.4.6 OrientationDamper>>
** <<PositionChaser, 39.4.7 PositionChaser>>
** <<PositionChaser2D, 39.4.8 PositionChaser2D>>
** <<PositionDamper, 39.4.9 PositionDamper>>
** <<PositionDamper2D, 39.4.10 PositionDamper2D>>
** <<ScalarChaser, 39.4.11 ScalarChaser>>
** <<ScalarDamper, 39.4.12 ScalarDamper>>
** <<TexCoordChaser2D, 39.4.13 TexCoordChaser2D>>
** <<TexCoordDamper2D, 39.4.14 TexCoordDamper2D>>
* <<S39_SupportLevels, 39.5 Support levels>>

* <<f-CalculatingTheOutputOfAnX3DFollowerNode, Figure 39.1 — Calculating the output of an _X3DFollowerNode_>>
* <<f-ConceptOfAnX3DDamperNode, Figure 39.2 — Concept of an _X3DDamperNode_>>
* <<f-ModeOfOperationOfAnX3DFollowerNode, Figure 39.3 — Mode of operation of an _X3DFollowerNode_>>

* <<t39_1, Table 39.1 — Topics>>
* <<t39_2, Table 39.2 — Followers component support levels>>




[[S39_Concepts]]
=== 39.2 Concepts

The group of _Follower_ nodes supports the creation of transitions of
parameters at runtime (dynamically) by receiving a destination value
upon which they create an animation that transitions their output value
from its current value towards the newly set destination value.

In case a transition triggered by reception of a previous destination
value is not yet finished while the new destination is received, both
the new and old transition are merged, so that a smooth animation is
created where the previous movement degrades and gradually becomes a
movement towards the new destination which is then eventually reached.

_Follower_ nodes accomplish the transition by implementing **f**inite
**i**mpulse **r**esponse (FIR) filters and **i**nfinite **i**mpulse
**r**esponse (IIR) filters from the field of system theory. Due to this
filter distinction, the _Follower_ nodes are divided into _Chaser_ nodes
(FIR) and _Damper_ nodes (IIR).

Like _TimeSensor_ nodes, _Follower_ nodes often send output events at
times when they have not received input events. Their behaviour is
completely determined by the events they receive from the scene graph
itself at earlier times.

_Follower_ nodes are not affected by their position in the
transformation hierarchy nor are they affected by the state of
containing <<Switch>> nodes, <<LOD>> nodes and other
nodes that affect the visibility of their children.


=== 39.3 Abstract types

[[X3DChaserNode]]
==== 39.3.1 _X3DChaserNode_

[source,node]
----
X3DChaserNode : X3DFollowerNode {
  [S|M]F<type> [in]     set_destination
  [S|M]F<type> [in]     set_value
  SFNode       [in,out] metadata           NULL  [X3DMetadataObject]
  SFBool       [out]    isActive
  [S|M]F<type> [out]    value_changed
  SFTime       []       duration           1     [0,∞)
  [S|M]F<type> []       initialDestination 
  [S|M]F<type> []       initialValue
}
----

The _X3DChaserNode_ abstract node type calculates the output on
_value_changed_ as a finite impulse response (FIR) based on the events
received on _set_destination_ in the following manner.

Each time an event is received on _set_destination_, a transition _A~n~_
from the previously received destination to the new destination is
created according to Equation (1). The data types of all variables are
floating point numbers, or integers in the case of indices, except for
_d~n~_, _d~n-1~_, _A~n~(t)_ and _O(t)_. These variables have the data
type of the node ( _e.g._, _SFVec3f_ or _SFColor_).

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/equation39.3.1-1revised.png[Equation (1),height=90]

where:

_T~n~_ is the point in time where the event has been received +
_D_ is the value of the _duration_ field +
_d~n~_ is the new destination value received with the event +
_d~n-1~_ is the value that was the destination before the event +
_R(x)_ is the core function of the filter:

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/equ-2.png[Equation (2)]

All the transitions created for every event on _set_destination_ are
added together to form the output on _value_changed_.

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/equ-3.png[Equation (3)]

where _l_ is the number of events received so far on _set_destination_.
If _k_ is set to 0, _d~-1~_ is the value of the _initialValue_ field and
_d~0~_ is the value of _initialDestination_. This way the initial
transition determined by these two fields is produced.

Theoretically the start index _k_ might be always set to zero meaning
that all _set_destination_ events since initialization are to be stored.
However, _k_ can be increased without changing the result _O(t)_ as long
as the time stamp _T~k-1~_ is more than _D_ seconds before the current
time stamp. This is due to the facts:

[loweralpha]
. after a period of _D_ seconds (the _duration_ field), the transitions
_A~n~(t)_ are constantly _d~n~- d~n-1~_~;~ and
. _d~k-1~_ is the sum of all differences _d~n~- d~n-1~_ so far.

This way the _X3DChaserNode_ implementation remembers the values and
time stamps of all _set_destination_ events received in the last period
of _duration_ seconds plus the value received latest before that period.
For calculating the current value of _value_changed_, the
_X3DChaserNode_ uses that latest received value as a starting point (
_d~k-1~_) and adds to it all transitions _A~n~(t)_ generated by the
stored events.

A more optimal implementation might divide the time-line into
equidistant time-slots and store only the latest _set_destination_ event
received for each time-slot. This way a fixed length array might be used
for describing the input during the period of the last _duration_
seconds. This however can create little jumps in the animation created
at _value_changed_ since a _set_destination_ event may cause the
beginning of a transition being produced and may then be replaced by a
later event received in the same time-slot. To avoid this, events are
associated with the end of the time-slot rather than with the time-stamp
when they are received.

Thus, the output reaches the value received at _set_destination_ up to
the length of a time-slot later than is dictated by the _duration_
field. To compensate, an implementation shall subtract the length of a
time-slot from _duration_ and use the result for _D_.

It is suggested that the implementation uses (about) 10 time-slots per
duration _duration_ as depicted in
<<f-CalculatingTheOutputOfAnX3DFollowerNode, Figure 39.1>>.

[[f-CalculatingTheOutputOfAnX3DFollowerNode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/follower_2.png[CalculatingOutput]

Figure 39.1 — Calculating the output of an _X3DFollowerNode_

The above diagram illustrates how an implementation calculates the
output at an arbitrary point in time. Figure 39.1 depicts only four
time-slots per duration _D_. The period goes from the current time-stamp
_Now_ back by _D_ seconds, not necessarily matching the grid of the time
slots. The events _d~1~_ and _d~2~_ have happened before this period and
are therefore summarized by the value of _d~2~_. The event _d~3~_
however falls into the period of _D_ seconds. It is moved towards the
end of the time-slot it falls into and generates the transition
_A~3~(t)_ with the amplitude _d~3~- d~2~_. The event _d~4~_ gets ignored
because it is followed by _d~5~_ in the same time-slot. Therefore only
_d~5~_ generates a transition, which is _A~5~(t)_. The amplitude of
_A~5~(t)_ is _d~5~- d~3~_ because _d~4~_ got ignored. The output _O(t)_
is thus calculated as specified in Equation (4):

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/equ-4.png[Equation (4)]

When the current time-stamp has advanced until after the end of curve
_A~3~(t)_, which is when the time-slot containing event _d~3~_ is no
longer part of the last _D_ seconds, the start value for the addition
_d~2~_ is replaced with _d~3~_ and the curve _A~3~(t)_ is removed from
the addition, so that _O(t) = d~3~ + A~5~(t)_.

The above diagram uses four time-slots per duration _D_. With the above
recommendations of making _D_ one time-slot shorter than the _duration_
field specifies, this means that a time-slot is a fifth of what is
specified by _duration_.

[[X3DDamperNode]]
==== 39.3.2 _X3DDamperNode_

[source,node]
----
X3DDamperNode : X3DFollowerNode {
  [S|M]F<type> [in]     set_destination
  [S|M]F<type> [in]     set_value
  SFNode       [in,out] metadata           NULL   [X3DMetadataObject]
  SFTime       [in,out] tau                0.3    [0,∞)
  SFFloat      [in,out] tolerance          -1     -1 or [0,∞)
  SFBool       [out]    isActive
  [S|M]F<type> [out]    value_changed
  [S|M]F<type> []       initialDestination
  [S|M]F<type> []       initialValue
  SFInt32      []       order              3     [0..5]
}
----

The _X3DDamperNode_ abstract node type creates an IIR response that
approaches the destination value according to the shape of the
_e_-function only asymptotically but very quickly.

An _X3DDamperNode_ node is parameterized by the _tau_, _order_ and
_tolerance_ fields. Internally, it consists of a set of linear
first-order filters each of which processes the output of the previous
filter as shown in <<f-ConceptOfAnX3DDamperNode, Figure 39.2>>. The
input of the first filter is fed by the values received on
_set_destination_ and the output of the last filter goes to the
_value_changed_ field.

[[f-ConceptOfAnX3DDamperNode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/follower_3.png[Concept of an X3DDamperNode,width=662,height=106]

Figure 39.2 — Concept of an _X3DDamperNode_

The calculations of the output for the current time-stamp _T~n~_ for
each filter are based on the output of that filter from the previous
time-stamp _T~n-1~_ and the current input using the Equation (5):

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/equ-5.png[Equation(5)]

The field _order_ specifies the number of such internal filters.
Specifying zero for _order_ means that no filter is used. In this case
the events received on _set_destination_ are forwarded directly to
_output_changed_. The larger the value for _order_, the smoother the
output on _value_changed_ becomes, but more computational delay can be
introduced. Since values larger than five do not introduce any more
smoothing, the allowed range for _order_ values is limited to a maximum
of five.

The field _tau_ specifies the time-constant of the internal filters and
thus the speed that the output of an _X3DDamperNode_ responds to the
input. Its value is assigned to the variable _tau_ in the above
equation. A value of zero for _tau_ means immediate response and the
events received on _set_destination_ are forwarded directly to
_output_changed_. The field _tau_ specifies how long it takes the output
of an internal filter to reach the value of its input by 63% ( _1 -
1/e_). The remainder after that period is reduced by 63% during another
period of _tau_ seconds provided that the input of the filter does not
change. This behavior can be exposed if _order_ is set to one.

Since the output of an _X3DDamperNode_ approaches the input value only
asymptotically, there shall be a means to determine when the destination
value can be assumed to be reached and the node can stop emitting values
and set _isActive_ to `FALSE`. This is governed by the
_tolerance_ field. if _tolerance_ is set to its default value -1, the
X3D browser implementation is allowed to find a good way for detecting
the end of a transition. X3D browsers that do not have an elaborate
algorithm can just use 0.001 as the tolerance value instead. If a value
larger than zero is specified for _tolerance_, the X3D browser shall
calculate the difference between output and input for each internal
filter being used and stop the animation only when all filters fall
below that limit or are equal to it. If zero is specified for
_tolerance_, a transition should be stopped only if input and output
match exactly for all internal filters. This can happen if _set_value_
receives an event.

An implementation shall test for end of transition before it calculates
the new output value. Then, the implementation shall either assign the
_destination value_ to the _output value_, if the difference falls below
the tolerance limit, or calculate an updated output value.

[[X3DFollowerNode]]
==== 39.3.3 _X3DFollowerNode_

[source,node]
----
X3DFollowerNode : X3DChildNode {
  [S|M]F<type> [in]     set_destination
  [S|M]F<type> [in]     set_value
  SFNode       [in,out] metadata           NULL [X3DMetadataObject]
  SFBool       [out]    isActive
  [S|M]F<type> [out]    value_changed
  [S|M]F<type> []       initialDestination
  [S|M]F<type> []       initialValue
}
----

The abstract node _X3DFollowerNode_ forms the basis for all nodes
specified in this clause. The data type place holder _[S|M]F<type>_
evaluates to the same data type for all fields of a specialization of
the abstract node class _X3DFollowerNode_.

An _X3DFollowerNode_ maintains an internal state that consists of a
_current value_ and a _destination value_. Both values are of the same
data type into which the term _[S|M]F<type>_ evaluates for a given
specialization. It is the _'data type of the node'_. In certain cases of
usage, the terms _input_ and _output_ fit better for _destination value_
and _current value_, respectively.

Whenever the _current value_ differs from the _destination value_, the
current value gradually changes until it reaches the _destination value_
producing a smooth transition. It generally moves towards the
_destination value_ but, if a transition triggered by a previous
_destination value_ is still in progress, it may take a short while
until the movement becomes a movement towards the new destination value.
<<f-ModeOfOperationOfAnX3DFollowerNode, Figure 39.3>> depicts this
action.

[[f-ModeOfOperationOfAnX3DFollowerNode]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/follower_1.png[ModeOfOperation]

Figure 39.3 — Mode of operation of an _X3DFollowerNode_

The _value_changed_ outputOnly field outputs the current value of the
internal state.

The _set_destination_ inputOnly field receives new destination values,
resulting in the _value_changed_ field sending output values in most
cases.

The initializeOnly fields, _initialDestination_ and _initialValue_,
initialize the internal state of the _X3DFollowerNode_. The _current
value_ receives the value of _initialValue_ and the _destination value_
receives the value of _initialDestination_. If both fields have the same
values, the _X3DFollowerNode_ sends that value through the
_value_changed_ field in a single event upon initialization. If both
fields have different values, the _X3DFollowerNode_ creates an animation
from the value of _initialValue_ towards the value of
_initialDestination_. The shape of that transition is the same as if the
_current value_ internal state had always been at the value of
_initialValue_ and the node had just received the _destination value_.

With the _set_value_ inputOnly field, one can immediately force the
_current value_ towards a certain value. When the _X3DFollowerNode_
receives a value on _set_value_, any current transition is stopped and
the _current value_ assumes that value. The _value_changed_ field
outputs that value and then moves towards the value currently set for
the _destination value_. This animation has the same shape as if the
_current value_ had already been at the newly received value for a long
time and the node had just received an event on _set_destination_
carrying the value of the currently set _destination value_.

One can achieve various results by sending certain values to
_set_value_, _set_destination_ or both at the same time:

* *__set_destination__and __set_value__receive different values:* +
A transition is created that goes from the value of _set_value_ towards
the value of _set_destination_. The transition is independent of the
previous history of the node. With most parameter settings, the
transition starts with zero speed and then accelerates towards the
destination.
* *__set_destination__and __set_value__receive the same value:* +
_Output_changed_ assumes the specified value immediately and stays
there. No transition is created.
* *__set_value__receives the value __value_changed__currently has:* +
_Value_changed_ stops moving immediately and begins a new transition
towards the currently set _destination value_. With most parameter
settings, the result is that _value_changed_ stops moving and then
accelerates towards the _destination value_ to which it was already
targeted.
* *__set_value__receives the value currently set as destination:* +
The _output_changed_ value jumps to the _destination value_ immediately.
* *__set_destination__and __set_value__both receive the current value of
_value_changed_:* +
The transition produced comes to an immediate halt at its current value.

The _isActive_ outputOnly field identifies the beginning and end of a
transition. It sends `TRUE` before _set_value_ begins animating
and it sends `FALSE` after _set_value_ has reached the
_destination_ or has been stopped by another means. When _set_value_
receives an event while _isActive_ is `TRUE`, _isActive_ sends
`FALSE` after _value_changed_ has output the received value. If
_isActive_ is `FALSE` at that moment, _isActive_ generates no
event.


=== 39.4 Node reference

[[ColorChaser]]
==== 39.4.1 ColorChaser

[source,node]
----
ColorChaser : X3DChaserNode {
  SFColor [in]     set_destination
  SFColor [in]     set_value
  SFNode  [in,out] metadata           NULL        [X3DMetadataObject]
  SFBool  [out]    isActive
  SFColor [out]    value_changed
  SFTime  []       duration           1           [0,∞)
  SFColor []       initialDestination 0.8 0.8 0.8 [0,1]
  SFColor []       initialValue       0.8 0.8 0.8 [0,1]
}
----

The ColorChaser animates transitions for single colour values. Whenever
the _set_destination_ field receives a floating point number, the
_value_changed_ creates a transition from its current value to the newly
set number. It creates a smooth transition that ends _duration_ seconds
after the last number has been received.

When _set_value_ receives a colour value, any transition currently in
process is stopped and _value_changed_ sends this value immediately,
creating a jump. The field _initialValue_ can be used to set the initial
value of _value_changed_. The field _initialDestination_ should be set
to the same value unless a transition to a certain value is to be
created right after the scene is loaded or right after the ColorChaser
node is created dynamically.

[[ColorDamper]]
==== 39.4.2 ColorDamper

[source,node]
----
ColorDamper : X3DDamperNode {
  SFColor [in]     set_destination
  SFColor [in]     set_value
  SFNode  [in,out] metadata           NULL        [X3DMetadataObject]
  SFTime  [in,out] tau                0.3         [0,∞)
  SFFloat [in,out] tolerance          -1          -1 or [0,∞)
  SFBool  [out]    isActive
  SFColor [out]    value_changed
  SFColor []       initialDestination 0.8 0.8 0.8 [0,1]
  SFColor []       initialValue       0.8 0.8 0.8 [0,1]
  SFInt32 []       order              3           [0..5]
}
----

The ColorDamper animates colour values. Whenever the _set_destination_
field receives a colour, the ColorDamper node creates a transition from
the current colour to the newly set colour. The transition created
approaches the newly set position asymptotically during a time period of
approximately three to four times the value of the field _tau_ depending
on the desired accuracy and the value of _order_. The _order_ field
specifies the smoothness of the transition.

When _set_value_ receives a colour, any transition currently in process
is stopped and _value_changed_ sends this value immediately, creating a
jump to the new colour. The field _initialValue_ can be used to set the
initial colour. The field _initialDestination_ should be set to the same
value unless a transition to a certain colour is to be created right
after the scene is loaded or right after the ColorDamper node is created
dynamically.

[[CoordinateChaser]]
==== 39.4.3 CoordinateChaser

[source,node]
----
CoordinateChaser : X3DChaserNode {
  MFVec3f [in]     set_destination
  MFVec3f [in]     set_value
  SFNode  [in,out] metadata           NULL  [X3DMetadataObject]
  SFBool  [out]    isActive
  MFVec3f [out]    value_changed
  SFTime  []       duration           1     [0,∞)
  MFVec3f []       initialDestination 0 0 0
  MFVec3f []       initialValue       0 0 0
}
----

The CoordinateChaser animates transitions for array of 3D vectors (
_e.g._, the coordinates of a mesh). Whenever the _set_destination_ field
receives an array of 3D vectors, the _value_changed_ creates a
transition from its current value to the newly set number. It creates a
smooth transition that ends _duration_ seconds after the last number has
been received.

When _set_value_ receives an array of 3D vectors, any transition
currently in process is stopped and _value_changed_ sends this value
immediately, creating a jump. The field _initialValue_ can be used to
set the initial value of _value_changed_. The field _initialDestination_
should be set to the same value unless a transition to a certain value
is to be created right after the scene is loaded or right after the
CoordinateChaser node is created dynamically.

[[CoordinateDamper]]
==== 39.4.4 CoordinateDamper

[source,node]
----
CoordinateDamper : X3DDamperNode {
  MFVec3f [in]     set_destination
  MFVec3f [in]     set_value
  SFNode  [in,out] metadata           NULL  [X3DMetadataObject]
  SFTime  [in,out] tau                0.3   [0,∞)
  SFFloat [in,out] tolerance          -1    -1 or [0,∞)
  SFBool  [out]    isActive
  MFVec3f [out]    value_changed
  MFVec3f []       initialDestination 0 0 0
  MFVec3f []       initialValue       0 0 0
  SFInt32 []       order              3     [0..5]
}
----

The CoordinateDamper animates transitions for an array of 3D vectors (
_e.g._, the coordinates of a mesh). Whenever the _set_destination_ field
receives an array of 3D vectors, _value_changed_ begins sending an array
of the same length, where each element moves from its current value
towards the value at the same position in the array received. Each
element approaches its destination value asymptotically during a time
period of approximately three to four times the value of the field _tau_
depending on the desired accuracy and the value of _order_. The _order_
field specifies the smoothness of the transition. The transition ends
when all elements have reached their destination.

When _set_value_ receives an event, any transition currently in process
is stopped and _value_changed_ sends this array immediately, creating a
jump. The field _initialValue_ can be used to set the initial value of
_value_changed_. The field _initialDestination_ should be set to the
same value unless a transition to a certain 3D vector value is to be
created right after the scene is loaded or right after the
CoordinateDamper node is created dynamically.

The MFVec3f arrays that are sent to the _set_destination_ or _set_value_
field shall have the same length (number of elements). The length of the
arrays shall not change over time. Values assigned to
_initialDestination_ or _initialValue_ shall either be an empty array or
an array with the same number of elements as is sent to the
_set_destination_ or _set_value_ fields. In any other case, the behavior
is not defined.

[[OrientationChaser]]
==== 39.4.5 OrientationChaser

[source,node]
----
OrientationChaser : X3DChaserNode {
  SFRotation [in]     set_destination
  SFRotation [in]     set_value
  SFNode     [in,out] metadata           NULL    [X3DMetadataObject]
  SFBool     [out]    isActive
  SFRotation [out]    value_changed
  SFTime     []       duration           1       [0,∞)
  SFRotation []       initialDestination 0 1 0 0
  SFRotation []       initialValue       0 1 0 0
}
----

The OrientationChaser animates transitions for orientations. If the
_value_changed_ field is routed to a _rotation_ field of a _Transform_
node that contains an object, whenever the _set_destination_ field
receives an orientation, the OrientationChaser node rotates the object
from its current orientation to the newly set orientation. It creates a
smooth transition that ends _duration_ seconds after the last
orientation has been received.

When _set_value_ receives an orientation, any transition currently in
process is stopped and the object jumps directly to the given
orientation. The field _initialValue_ can be used to set the initial
orientation of the object. The field _initialDestination_ should be set
to the same value unless a transition to a certain orientation is to be
created right after the scene is loaded or right after the
OrientationChaser node is created dynamically.

The OrientationChaser node can be implemented by combining Equations
(1), (2), and (3) to form Equation (6):

image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/equ-6.png[Equation (6)]

This leads to the following loop expressed in pseudo code:

    var Result= _d~k-1~_; +
    for (var n from k to l) \{ +
        var Delta = _d~n~- d~n-1~_; +
        Result = Result + Delta × _R(...)_; +
    } +
    _O(t)_ = Result;

Since _d~k-1~_, _d~n~_, _d~n-1~_ and thus `Result` contain
rotation values (SFRotation), the above code shall be converted to use
operations available for rotations. This can be achieved using the
_slerp_ operation. For the following, let `slerp(A, B, t)` be a
function that calculates the linear spherical interpolation from _A_ to
_B_ by the amount _t_. Let also `Core(.)` be a function that
calculates _R(...)_ and let `Buffer` be an array so that
`Buffer[i]` evaluates to _d~i~_. Then, the above loop can be
implemented as:

    var Result= Buffer[k-1]; +
    for(var n from k to l) \{ +
        var Delta = Buffer[n-1].inverse().multiply(Buffer[n]); +
        Result = slerp(Result, Result.multiply(Delta), Core(...)); +
    } +
    _O(t)_ = Result;

[[OrientationDamper]]
==== 39.4.6 OrientationDamper

[source,node]
----
OrientationDamper : X3DDamperNode {
  SFRotation [in]     set_destination
  SFRotation [in]     set_value
  SFNode     [in,out] metadata           NULL    [X3DMetadataObject]
  SFTime     [in,out] tau                0.3     [0,∞)
  SFFloat    [in,out] tolerance          -1      -1 or [0,∞)
  SFBool     [out]    isActive
  SFRotation [out]    value_changed
  SFRotation []       initialDestination 0 1 0 0
  SFRotation []       initialValue       0 1 0 0
  SFInt32    []       order              3       [0..5]
}
----

The OrientationDamper animates transitions of orientations. If the
_value_changed_ field is routed to a _rotation_ field of a
<<Transform>> node that contains an object, then, whenever
the _set_destination_ field receives an orientation, the
OrientationDamper node rotates the object from its current orientation
to the newly set orientation. It creates a transition that approaches
the newly set orientation asymptotically during a time period of
approximately three to four times the value of the field _tau_ depending
on the desired accuracy and the value of _order_. Through this
asymptotic approach of the destination orientation, a very smooth
transition is created. The _order_ field specifies the smoothness of the
transition.

When _set_value_ receives an orientation, any transition currently in
process is stopped and the object jumps directly to the given
orientation. The field _initialValue_ can be used to set the initial
orientation of the object. The field _initialDestination_ should be set
to the same value unless a transition to a certain orientation is to be
created right after the scene is loaded or right after the
OrientationDamper node is created dynamically.

The OrientationDamper node is implemented by calculating Equation (5)
for each internal filter. For SFRotation values, the equation is
equivalent to the following term:

    output = input.slerp(output, alpha);

where:

    output: _o~n~_ or _o~n-1~_, respectively +
    input:  _d~n~_ +
    alpha:  _e^-ΔT/τ^_

[[PositionChaser]]
==== 39.4.7 PositionChaser

[source,node]
----
PositionChaser : X3DChaserNode {
  SFVec3f [in]     set_destination
  SFVec3f [in]     set_value
  SFNode  [in,out] metadata           NULL  [X3DMetadataObject]
  SFBool  [out]    isActive
  SFVec3f [out]    value_changed
  SFTime  []       duration           1     [0,∞)
  SFVec3f []       initialDestination 0 0 0
  SFVec3f []       initialValue       0 0 0
}
----

The PositionChaser animates transitions for 3D vectors. If the
_value_changed_ field is routed to a _translation_ field of a
<<Transform>> node that contains an object, then, whenever
the _set_destination_ field receives a 3D position, the PositionChaser
node moves the object from its current position to the newly set
position. It creates a smooth transition that ends _duration_ seconds
after the last position has been received.

When _set_value_ receives a position, any transition currently in
process is stopped and the object jumps directly to the given position.
The field _initialValue_ can be used to set the initial position of the
object. The field _initialDestination_ should be set to the same value
unless a transition to a certain position is to be created right after
the scene is loaded or right after the PositionChaser node is created
dynamically.

[[PositionChaser2D]]
==== 39.4.8 PositionChaser2D

[source,node]
----
PositionChaser2D : X3DChaserNode {
  SFVec2f [in]     set_destination
  SFVec2f [in]     set_value
  SFNode  [in,out] metadata           NULL  [X3DMetadataObject]
  SFBool  [out]    isActive
  SFVec2f [out]    value_changed
  SFTime  []       duration           1     [0,∞)
  SFVec2f []       initialDestination 0 0
  SFVec2f []       initialValue       0 0
}
----

The PositionChaser2D animates transitions for 2D vectors. Whenever the
_set_destination_ field receives a 2D vector the _value_changed_ creates
a transition from its current 2D vector value to the newly set value. It
creates a smooth transition that ends _duration_ seconds after the last
2D vector has been received.

When _set_value_ receives a 2D vector, any transition currently in
process is stopped and _value_changed_ sends this value immediately. The
field _initialValue_ can be used to set the initial initial value of
_value_changed_. The field _initialDestination_ should be set to the
same value unless a transition to a certain 2D vector value is to be
created right after the scene is loaded or right after the
PositionChaser2D node is created dynamically.

[[PositionDamper]]
==== 39.4.9 PositionDamper

[source,node]
----
PositionDamper : X3DDamperNode {
  SFVec3f [in]     set_destination
  SFVec3f [in]     set_value
  SFNode  [in,out] metadata           NULL  [X3DMetadataObject]
  SFTime  [in,out] tau                0.3   [0,∞)
  SFFloat [in,out] tolerance          -1    -1 or [0,∞)
  SFBool  [out]    isActive
  SFVec3f [out]    value_changed
  SFVec3f []       initialDestination 0 0 0
  SFVec3f []       initialValue       0 0 0
  SFInt32 []       order              3     [0..5]
}
----

The PositionDamper animates transitions for 3D vectors. If the
_value_changed_ field is routed to a _translation_ field of a
<<Transform>> node that contains an object, then, whenever
the _set_destination_ field receives a 3D position, the PositionDamper
node moves the object from its current position to the newly set
position. It creates a transition that approaches the newly set position
asymptotically during a time period of approximately three to four times
the value of the field _tau_ depending on the desired accuracy and the
value of _order_. Through this asymptotic approach of the destination
value, a smooth transition is created. The _order_ field specifies the
smoothness of the transition.

When _set_value_ receives a position, any transition currently in
process is stopped and the object jumps directly to the given position.
The field _initialValue_ can be used to set the initial position of the
object. The field _initialDestination_ should be set to the same value
unless a transition to a certain position is to be created right after
the scene is loaded or right after the PositionDamper node is created
dynamically.

[[PositionDamper2D]]
==== 39.4.10 PositionDamper2D

[source,node]
----
PositionDamper2D : X3DDamperNode {
  SFVec2f [in]     set_destination
  SFVec2f [in]     set_value
  SFNode  [in,out] metadata           NULL [X3DMetadataObject]
  SFTime  [in,out] tau                0.3  [0,∞)
  SFFloat [in,out] tolerance          -1   -1 or [0,∞)
  SFBool  [out]    isActive
  SFVec2f [out]    value_changed
  SFVec2f []       initialDestination 0 0
  SFVec2f []       initialValue       0 0
  SFInt32 []       order              3    [0..5]
}
----

The PositionDamper2D animates transitions for 2D vectors. Whenever the
_set_destination_ field receives a 2D vector, the _value_changed_
creates a transition from its current 2D vector value to the newly set
value. It creates a transition that approaches the newly set 2D vector
asymptotically during a time period of approximately three to four times
the value of the field _tau_ depending on the desired accuracy and the
value of _order_. The _order_ field specifies the smoothness of the
transition.

When _set_value_ receives a 2D vector, any transition currently in
process is stopped and _value_changed_ sends this value immediately,
creating a jump. The field _initialValue_ can be used to set the initial
initial value of _value_changed_. The field _initialDestination_ should
be set to the same value unless a transition to a certain 2D vector
value is to be created right after the scene is loaded or right after
the PositionChaser2D node is created dynamically.

[[ScalarChaser]]
==== 39.4.11 ScalarChaser

[source,node]
----
ScalarChaser : X3DChaserNode {
  SFFloat [in]     set_destination
  SFFloat [in]     set_value
  SFNode  [in,out] metadata           NULL [X3DMetadataObject]
  SFBool  [out]    isActive
  SFFloat [out]    value_changed
  SFTime  []       duration           1    [0,∞)
  SFFloat []       initialDestination 0
  SFFloat []       initialValue       0
}
----

The ScalarChaser animates transitions for single float values. Whenever
the _set_destination_ field receives a floating point number, the
_value_changed_ creates a transition from its current value to the newly
set number. It creates a smooth transition that ends _duration_ seconds
after the last number has been received.

When _set_value_ receives a floating point number, any transition
currently in process is stopped and _value_changed_ sends this value
immediately, creating a jump. The field _initialValue_ can be used to
set the initial initial value of _value_changed_. The field
_initialDestination_ should be set to the same value unless a transition
to a certain value is to be created right after the scene is loaded or
right after the ScalarChaser node is created dynamically.

[[ScalarDamper]]
==== 39.4.12 ScalarDamper

[source,node]
----
ScalarDamper : X3DDamperNode {
  SFFloat [in]     set_destination
  SFFloat [in]     set_value
  SFNode  [in,out] metadata           NULL  [X3DMetadataObject]
  SFTime  [in,out] tau                0.3   [0,∞)
  SFFloat [in,out] tolerance          -1    -1 or [0,∞)
  SFBool  [out]    isActive
  SFFloat [out]    value_changed
  SFFloat []       initialDestination 0
  SFFloat []       initialValue       0
  SFInt32 []       order              3     [0..5]
}
----

The ScalarDamper animates transitions for single float values. If the
_value_changed_ field is routed to a _transparency_ field of a Material
node, then, whenever the _set_destination_ field receives a single float
value, the ScalarDamper node creates a transition from its current value
to the newly set value. It creates a transition that approaches the
newly set value asymptotically during a time period of approximately
three to four times the value of the field _tau_ depending on the
desired accuracy and the value of order. Through this asymptotic
approach of the destination value, a smooth transition is created. The
_order_ field specifies the smoothness of the transition.

When _set_value_ receives a value, any transition currently in process
is stopped and _value_changed_ sends this value immediately, creating a
jump to the new value. The field _initialValue_ can be used to set the
initial value of the node. The field _initialDestination_ should be set
to the same value unless a transition to a certain value is to be
created right after the scene is loaded or right after the ScalarDamper
node is created dynamically.

[[TexCoordChaser2D]]
==== 39.4.13 TexCoordChaser2D

[source,node]
----
TexCoordChaser2D : X3DChaserNode {
  MFVec2f [in]     set_destination
  MFVec2f [in]     set_value
  SFNode  [in,out] metadata           NULL [X3DMetadataObject]
  SFBool  [out]    isActive
  MFVec2f [out]    value_changed
  SFTime  []       duration           1    [0,∞)
  MFVec2f []       initialDestination []
  MFVec2f []       initialValue       []
}
----

The TexCoordChaser2D animates transitions for an array of 2D vectors (
_e.g._, the texture coordinates of a mesh). Whenever the
_set_destination_ field receives an array of 2D vectors, the
_value_changed_ creates a transition from its current value to the newly
set number. It creates a smooth transition that ends _duration_ seconds
after the last number has been received.

When _set_value_ receives an array of 2D vectors, any transition
currently in process is stopped and _value_changed_ sends this value
immediately, creating a jump. The field _initialValue_ can be used to
set the initial value of _value_changed_. The field _initialDestination_
should be set to the same value unless a transition to a certain value
is to be created right after the scene is loaded or right after the
TexCoordChaser2D node is created dynamically.

[[TexCoordDamper2D]]
==== 39.4.14 TexCoordDamper2D

[source,node]
----
TexCoordDamper2D : X3DDamperNode {
  MFVec2f [in]     set_destination
  MFVec2f [in]     set_value
  SFNode  [in,out] metadata           NULL [X3DMetadataObject]
  SFTime  [in,out] tau                0.3  [0,∞)
  SFFloat [in,out] tolerance          -1   -1 or [0,∞)
  SFBool  [out]    isActive
  MFVec2f [out]    value_changed
  MFVec2f []       initialDestination []
  MFVec2f []       initialValue       []
  SFInt32 []       order              3    [0..5]
}
----

The TexCoordDamper2D node animates transitions for an array of 2D
vectors ( _e.g._, the texture coordinates of a mesh). Whenever the
_set_destination_ field receives an array of 2D vectors, _value_changed_
begins sending an array of the same length, where each element moves
from its current value towards the value at the same position in the
array received. Each element approaches its destination value
asymptotically during a time period of approximately three to four times
the value of the field _tau_ depending on the desired accuracy and the
value of _order_. The _order_ field specifies the smoothness of the
transition. The transition ends when all elements have reached their
destination.

When _set_value_ receives an event, any transition currently in process
is stopped and _value_changed_ sends this array immediately, creating a
jump. The field _initialValue_ can be used to set the initial value of
_value_changed_. The field _initialDestination_ should be set to the
same value unless a transition to a certain 2D vector value is to be
created right after the scene is loaded or right after the
CoordinateDamper node is created dynamically.

The MFVec2f arrays that are sent to the _set_destination_ or _set_value_
field shall have the same length (number of elements). The length of the
arrays shall not change over time. Values assigned to
_initialDestination_ or _initialValue_ shall either be an empty array or
an array with the same number of elements as is sent to the
_set_destination_ or _set_value_ fields. In any other case, the behavior
is not defined.

[[S39.5_SupportLevels]]
=== 39.5 Support levels

The Followers component provides one level of support as specified in
<<t39_2, Table 39.2>>.

[[t39_2]]
*Table 39.2 — Followers* component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 |  | 
|  |  |_X3DChaserNode_ |n/a
|  |  |_X3DDamperNode_ |n/a
|  |  |_X3DFollowerNode_ |n/a
|  |  |ColorChaser |All fields fully supported.
|  |  |ColorDamper |All fields fully supported.
|  |  |CoordinateChaser |All fields fully supported.
|  |  |CoordinateDamper |All fields fully supported.
|  |  |OrientationChaser |All fields fully supported.
|  |  |OrientationDamper |All fields fully supported.
|  |  |PositionChaser |All fields fully supported.
|  |  |PositionChaser2D |All fields fully supported.
|  |  |PositionDamper |All fields fully supported.
|  |  |PositionDamper2D |All fields fully supported.
|  |  |ScalarChaser |All fields fully supported.
|  |  |ScalarDamper |All fields fully supported.
|  |  |TexCoordChaser |All fields fully supported.
|  |  |TexCoordDamper |All fields fully supported.
|===

[[particleSystems_html]]
== 40 Particle systems component

[[S40_Introduction]]
=== 40.1 Introduction

[[S40_Name]]
==== 40.1.1 Name

The name of this component is "ParticleSystems". This name shall be used
when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S40_Overview]]
==== 40.1.2 Overview

This component specifies how to model particles and their interactions
through the application of basic physics principles to affect motion.
<<t40_1, Table 40.1>> provides links to the major topics in this
clause.

[[t40_1]]
Table 40.1 — Topics

* <<S40Introduction, 40.1 Introduction>>
** <<S40_Name, 40.1.1 Name>>
** <<S40_Overview, 40.1.2 Overview>>
* <<S40_Concepts, 40.2 Concepts>>
** <<S40_ConceptsOverview, 40.2.1 Overview>>
** <<PhysicsModels, 40.2.2 Physics models>>
** <<ColourRamps, 40.2.3 Colour ramps>>
** <<RandomnessAndVariation, 40.2.4 Randomness and variation>>
** <<EventModelInteraction, 40.2.5 Event model interaction>>
** <<InteractionWithOtherComponents, 40.2.6 Interaction with other components>>
* <<S40_AbstractTypes, 40.3 Abstract types>>
** <<X3DParticleEmitterNode, 40.3.1 _X3DParticleEmitterNode_>>
** <<X3DParticlePhysicsModelNode, 40.3.2 _X3DParticlePhysicsModelNode_>>
* <<S40_NodeReference, 40.4 Node reference>>
** <<BoundedPhysicsModel, 40.4.1 BoundedPhysicsModel>>
** <<ConeEmitter, 40.4.2 ConeEmitter>>
** <<ExplosionEmitter, 40.4.3 ExplosionEmitter>>
** <<ForcePhysicsModel, 40.4.4 ForcePhysicsModel>>
** <<ParticleSystem, 40.4.5 ParticleSystem>>
** <<PointEmitter, 40.4.6 PointEmitter>>
** <<PolylineEmitter, 40.4.7 PolylineEmitter>>
** <<SurfaceEmitter, 40.4.8 SurfaceEmitter>>
** <<VolumeEmitter, 40.4.9 VolumeEmitter>>
** <<WindPhysicsModel, 40.4.10 WindPhysicsModel>>
* <<S40_SupportLevels, 40.5 Support levels>>

* <<t40_1, Table 40.1 — Topics>>
* <<t40_2, Table 40.2 — Particle systems component support levels>>




[[S40_Concepts]]
=== 40.2 Concepts

[[S40_ConceptsOverview]]
==== 40.2.1 Overview

A particle system specifies a process for rendering such effects as
fire, smoke, and snow. Although various physics models are available, it
is not meant to be used as a simulation engine for testing particle
behaviour models. Thus, particle systems are designed for visual
effects, not rigid analysis systems.

A particle system is a shape node type as both appearance and texturing
need to be controlled in order to create realistic particle system
effects. A particle system in and of itself is not considered geometry
because it dynamically creates and destroys geometrically shaped
particles on the fly. A particle system also has other factors feeding
into the visual output different from a typical geometry node.

EXAMPLE  Particles may have time-varying colour values.

The geometry node of a shape node is not used at the first support
level. If a node supports both levels of the specification, the geometry
node takes preference over the _geometryType_ field.

Particles are generated using the current geometry, allowing particle
geometry to be changed over time. Old particles that are still current
when the specified geometry changes continue to use the original
geometry.

[[PhysicsModels]]
==== 40.2.2 Physics models

To allow aggregating a collection of nodes with a particular physics
model,  an _X3DParticlePhysicsModelNode_ abstract node type is provided
that is used to derive nodes in which all children nodes of that group
are bound by the specified physics model. This can be used to support
simple effects such as gravity. The physics models are designed to be
composable.

EXAMPLE  The <<BoundedPhysicsModel>> node can be
used with an extrusion as the geometry and then a
<<WindPhysicsModel>> node can be used with the
geometry to produce smoke tunneling effects.

[[ColourRamps]]
==== 40.2.3 Colour ramps

A colour ramp is used to specify the colour cycle over time. A colour
ramp is a variation on the normal use of a colour interpolator. The key
represents relative time values from the start of the lifetime of the
particle. There should be the same number of colours in the node as
there are key values. If not, the smaller number of the two values shall
be used. For particles that last longer than the last time value, the
colour associated with the last time value shall be continued for the
rest of the lifetime of the particle.

[[RandomnessAndVariation]]
==== 40.2.4 Randomness and variation

Many nodes describe emission as using a random pattern. The random
generation model shall use a linear distribution of equal probability
across the defined output spectrum.

Nodes that describe a _variation_ field allow for deviation from the
described main field value. The _variation_ field is the maximum bound
of that value, described as a proportion of the original value. A
_variation_ field value of zero does not allow any randomness.

EXAMPLE  If field has a value of 10, a variation of 0.25 will allow
values to be randomly generated in the range of 7.5 to 12.5. The same
field with a value of 1 will only allow a range of randomly generated
values between 0.75 and 1.25.

[[EventModelInteraction]]
==== 40.2.5 Event model interaction

Evaluation of emission and interactions of particles are performed as
specified in <<ExecutionModel, 4.4.8.3 Execution model>>. All changes
made during current event cascade are first applied. Then, the particles
are generated, particle system physics are applied, and rendering of the
particles takes place.

Particle systems interact with navigation, pointing device sensors,
collision detection and picking according to the underlying geometry
type. Point particles, point sprite particles and line particles cannot
be picked; other types of particles can be picked.

[[InteractionWithOtherComponents]]
==== 40.2.6 Interaction with other components

There are many different ways to implement particle systems. This
specification does not require any particular technology or means of
implementation. However, a popular implementation is to use programmable
shaders to perform the per-frame evaluation of the particles. While it
is not advised, it is possible and legal to supply programmable shaders
as part of the particle system's _appearance_ field. If the user
supplies a programmable shader, the implementation shall use a
CPU-generated model for this case.

The physics model nodes in this component are independent of the physics
evaluation defined in <<rigidBodyPhysics_html, 37 Rigid body physics component>>.
This document does not explicitly prohibit interaction
between the two models, but does not cater for direct implementation of
one by the other ( _e.g._, use of hardware accelerated physics cards to
implement particle systems).


=== 40.3 Abstract types

[[X3DParticleEmitterNode]]
==== 40.3.1 _X3DParticleEmitterNode_

[source,node]
----
X3DParticleEmitterNode : X3DNode {
  SFFloat [in,out] mass        0    [0,∞)
  SFNode  [in,out] metadata    NULL [X3DMetadataObject]
  SFBool  [in,out] on          TRUE
  SFFloat [in,out] speed       0    [0,∞)
  SFFloat [in,out] surfaceArea 0    [0,∞)
  SFFloat [in,out] variation   0.25 [0,∞)
}
----

The _X3DParticleEmitterNode_ abstract type represents any node that is
an emitter of particles. The shape and distribution of particles is
dependent on the type of the concrete node.

The _on_ field specifies whether the particle emitter node is enabled or
disabled. If the value is FALSE, the node is disabled and no new
particles are emitted. If the value is TRUE, particles are emitted. If
the node is generating particles and value of the _on_ field is
subsequently set to FALSE, no further particles are emitted and
already-existing particles finish their expected presentation.

The _speed_ field specifies an initial linear speed that will be
imparted to all particles, in speed derived units. It does not signify
the direction of the particles. The directional component of the
velocity is specified by the concrete node representation.

The _variation_ field specifies a multiplier for the randomness that is
used to control the range of possible output values. The bigger the
value, the more random the output and the bigger the range of possible
initial values possible. A variation of zero does not allow any
randomness.

The _mass_ field specifies the basic mass of each particle in mass base
units. Mass is needed if gravity or other force-related calculations are
to be performed per-particle.

The _surfaceArea_ field specifies the surface area of the particle in
area derived units. Surface area is used for calculations such as wind
effects per particle. The _surfaceArea_ field value represents an
average frontal area that would be presented to the wind, assuming a
spherical model for each particle ( _i.e._, the surface area is the same
regardless of direction).

[[X3DParticlePhysicsModelNode]]
==== 40.3.2 _X3DParticlePhysicsModelNode_

[source,node]
----
X3DParticlePhysicsModelNode : X3DNode { 
  SFBool [in,out] enabled  TRUE
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

The _X3DParticlePhysicsModelNode_ abstract type represents any node that
applies a form of constraints on the particles after they have been
generated.

The _enabled_ field specifies whether this physics model is currently
being applied to the particles.


=== 40.4 Node reference

[[BoundedPhysicsModel]]
==== 40.4.1 BoundedPhysicsModel

[source,node]
----
BoundedPhysicsModel : X3DParticlePhysicsModelNode { 
  SFBool [in,out] enabled  TRUE
  SFNode [in,out] geometry NULL [X3DGeometryNode]
  SFNode [in,out] metadata NULL [X3DMetadataObject]
}
----

The BoundedPhysicsModel node specifies a physics model that applies a
user-defined set of geometrical bounds to the particles.

The _geometry_ field specifies a piece of geometry that models the
bounds that constrain the location of the particles. When a particle
touches the surface of the bounds, it is reflected. The particles may be
restricted to an inside location or an outside location. All geometry
defined by the bounds are considered to be non-solid, regardless of the
setting of the _solid_ field. It does not matter whether the particle
impacts the front or back side of the geometry. Particles are reflected
at the same angle to the normal of the surface to which they impact,
continuing in the same direction. The calculation of the correct normal
is determined by the rules of the geometry that forms the bounds.

EXAMPLE  A particle can be made to bounce off an elevation grid
representing terrain.

[[ConeEmitter]]
==== 40.4.2 ConeEmitter

[source,node]
----
ConeEmitter : X3DParticleEmitterNode { 
  SFFloat [in,out] angle       π/4   [0,π]
  SFVec3f [in,out] direction   0 1 0 [-1,1]
  SFFloat [in,out] mass        0     [0,∞)
  SFNode  [in,out] metadata    NULL  [X3DMetadataObject]
  SFBool  [in,out] on          TRUE
  SFVec3f [in,out] position    0 0 0
  SFFloat [in,out] speed       0     [0,∞)
  SFFloat [in,out] surfaceArea 0     [0,∞)
  SFFloat [in,out] variation   0.25  [0,∞)
}
----

The ConeEmitter node is an emitter that generates all the available
particles from a specific point in space. Particles are emitted from the
single point specified by the _position_ field emanating in a direction
randomly distributed within the cone specified by the _angle_ and
_direction_ fields at the speed specified by the _speed_ field. The
_direction_ field shall be a non-degenerate vector; a value of `+0 0 0+`
is not allowed.

[[ExplosionEmitter]]
==== 40.4.3 ExplosionEmitter

[source,node]
----
ExplosionEmitter : X3DParticleEmitterNode { 
  SFFloat [in,out] mass        0     [0,∞)
  SFNode  [in,out] metadata    NULL  [X3DMetadataObject]
  SFBool  [in,out] on          TRUE
  SFVec3f [in,out] position    0 0 0
  SFFloat [in,out] speed       0     [0,∞)
  SFFloat [in,out] surfaceArea 0     [0,∞)
  SFFloat [in,out] variation   0.25  [0,∞)
}
----

The ExplosionEmitter node is an emitter that generates all the available
particles from a specific point in space at the initial time. Particles
are emitted from the single point specified by the _position_ field in
all directions at the speed specified by the _speed_ field.

[[ForcePhysicsModel]]
==== 40.4.4 ForcePhysicsModel

[source,node]
----
ForcePhysicsModel : X3DParticlePhysicsModelNode { 
  SFBool  [in,out] enabled  TRUE
  SFVec3f [in,out] force    0 -9.8 0 (∞,∞)
  SFNode  [in,out] metadata NULL     [X3DMetadataObject]
}
----

The ForcePhysicsModel node specifies a physics model that applies a
constant force value to the particles. Force may act in any given
direction vector at any strength.

The _force_ field is used to indicate the strength and direction of the
force ( _e.g._, gravity) that should be applied. Force is specified in
force base units. If the particles are defined to have zero mass by the
emitter, the ForcePhysicsModel node has no effect.

[[ParticleSystem]]
==== 40.4.5 ParticleSystem

[source,node]
----
ParticleSystem : X3DShapeNode { 
  SFNode   [in,out] appearance        NULL      [X3DAppearanceNode]
  SFBool   [in,out] bboxDisplay       FALSE
  SFBool   [in,out] castShadow        TRUE
  SFBool   [in,out] createParticles   TRUE
  SFNode   [in,out] geometry          NULL      [X3DGeometryNode]
  SFBool   [in,out] enabled           TRUE
  SFFloat  [in,out] lifetimeVariation 0.25      [0,1]
  SFInt32  [in,out] maxParticles      200       [0,∞)
  SFNode   [in,out] metadata          NULL      [X3DMetadataObject]
  SFFloat  [in,out] particleLifetime  5         [0,∞)
  SFVec2f  [in,out] particleSize      0.02 0.02 [0,∞)
  SFBool   [in,out] visible           TRUE
  SFBool   [out]    isActive
  SFVec3f  []       bboxCenter        0 0 0
  SFVec3f  []       bboxSize          -1 -1 -1  [0,∞) or -1 -1 -1
  SFNode   []       color             NULL      [X3DColorNode]
  MFFloat  []       colorKey          []        [0,∞)
  SFNode   []       emitter           NULL      [X3DParticleEmitterNode]
  SFString []       geometryType      "QUAD"    ["LINE"|"POINT"|"QUAD"|"SPRITE"|"TRIANGLE"|"GEOMETRY"|...]
  MFNode   []       physics           []        [X3DParticlePhysicsModelNode]
  SFNode   []       texCoord          NULL      [TextureCoordinate|TextureCoordinateGenerator]
  MFFloat  []       texCoordKey       []        [0,∞)
}
----

The ParticleSystem node specifies a complete particle system.

The _geometryType_ field specifies the type of geometry that should be
used to represent individual particles. Typically, a particle is
calculated as a point in space at which the geometry is placed and then
rendered using the appearance attributes.

The types of geometry are defined to render in the following way:

* `"LINE"`:  A line is drawn along the particle's current
velocity vector, for this frame, centered about the particle's position.
The length of the line is specified by the particle's height from the
_particleSize_ field value.
* `"POINT"`:  A point geometry is rendered at the particle's
position.
* `"QUAD"`:  A 2D quad is rendered aligned in the local
coordinate space of the particle system with the face normal pointing
along the positive Z axis. Individual quads are not aligned to the
user's eye position but are affected in depth by the physics model. The
particle's position is at the center of the quad.
* `"SPRITE"`:  A point sprite that uses a 2D point position to
locate a screen-aligned quad at the center of the particle's location is
rendered.
* "`TRIANGLE"`:  A 2D quad is rendered using a pair of triangles
aligned in the local coordinate space of the particle system with the
face normal pointing along the positive Z axis. Individual triangles are
not aligned to the user's eye position, but are affected in depth by the
physics model. The particle's position is at the center of the triangle.
* "`GEOMETRY`":  The geometry specified by the _geometry_ field
is rendered for each particle using the local coordinate system.
Changing the value of the _geometry_ field or the definition of the
geometry node shall be applied during current computation of the next
frame to be rendered.

The _geometry_ field specifies the geometry to be used for each particle
when the _geometryType_ field has value "`GEOMETRY`".

The _appearance_ field holds information that is used for the geometry.
All effects, such as material colours and/or multi-textures, are applied
to each particle. If a texture coordinate ramp and key is supplied with
this geometry, it shall be used in preference to any automatic texture
coordinate generation. If automatic texture coordinate generation is
used, results shall be based on the entire volume that the particles
consume, not locally applied to each particle.

Procedural shaders may also be supplied. The particle system shall
manage the position of all particles each frame. This position becomes
the initial geometry input to the shader.

The _emitter_ field specifies the type of emitter geometry and
properties that the particles are given for their initial positions.
After being created, the individual particles are then manipulated
according to the physics model(s) specified in the _physics_ field.

The _enabled_ field enables or disables all contained _emitter_ nodes,
without changing values of their respective _on_ fields.

The _color_ and _colorKey_ fields specify how to change the base colour
of the particle over the lifetime of an individual particle. The
_colorKey_ field represents the time of the particle in seconds, while
the _color_ field holds a series of colour values to be used at the
given key points in time. Between keys, colour values are interpreted in
a linear HSV space, using the same rules defined for the
<<ColorInterpolator>> node. The colour values are
defined as per-vertex colour values. Consequently, if an appearance node
with material is provided, the material properties will override the
colour ramp.

NOTE:  the original name for the ParticleSystem _color_ field in
X3D version 3 is _colorRamp_.

The _isActive_ outputOnly field indicates whether the particle system is
currently running, based on the setup of the node.

EXAMPLE  Using an explosion emitter that generates all of its particles
at the first time and has them all die at a fixed time later, the
particle system will only run for a short amount of time. After that,
nothing is visible on-screen or the particle geometry does not need
updating any more.

The _isActive_ field sends a value of `FALSE` when activity has
stopped occurring. A particle system without an emitter set can never be
active. If the emitter is defined by an EXTERNPROTO that has not yet
resolved, _isActive_ shall initially be `FALSE`, until the point
the EXTERNPROTO has loaded and is verified as being a correct node type.
If these validity checks pass, _isActive_ is set to `TRUE` and
this defines the local time zero to start the particle effects.

The _enabled_ field controls whether this ParticleSystem is currently
active and rendering particles this frame. Setting this value to
`FALSE` will immediately remove all visible particles from the
scene from the next frame onwards. Setting the field to `TRUE`
will start the system again from a local time zero. It does not start
off from where it was previously. In doing so, it will issue another
value of `TRUE` for _isActive_. If a value of `FALSE` is
set for _enabled_, _isActive_ will also be set to `FALSE`.

The _createParticles_ field is used to control whether any further new
particles should be created. This allows the user to stop production of
new particles, but keep those already existing in the scene to continue
to animate. This differs from the _enabled_ field that would immediately
remove all particles. The _createParticles_ field keeps the existing
particles in existence until the end of their lifetimes. If there are no
particles left in the scene, the system is still considered both active
and enabled.

The _maxParticles_ field specifies the maximum number of particles to be
generated at one time (subject to player limitations). Support for at
least 10,000 particles is required.

The _particleLifetime_ field specifies the nominal duration in seconds
of any particle.

The _lifetimeVariation_ field specifies the proportion of the total
lifetime that is the amount of allowed linear random variation from the
value specified by the _particleLifetime_ field.

The _particleSize_ field describes the dimensions in length base units
of the width and height of each particle. Changing this value
dynamically will only change new particles created after the change.
Particles created before this timestamp will remain at the old size.
This field only effects particles using `"LINE"`,
`"QUAD"`, `"SPRITE"`, and `"TRIANGLE"` geometry
types.

The _texCoord_ and _texCoordKey_ fields control the texture coordinates
of the provided texture(s) in the Appearance node, over time. Particle
systems frequently like to change the texture on a particle as it ages,
yet there is no good way of accomplishing this through standard
interpolators because interpolators have no concept of particle time.
This pair of fields hold time-dependent values for the texture
coordinates to be applied to the particle. When a particle reaches the
next time stamp it moves to the next set of texture coordinates. There
is no interpolation of the texture coordinates, just sequenced according
to the times defined by _texCoordKey_.

The node placed in _texCoord_ shall have enough values to work with the
numbers required by _geometryType_. The following numbers and rules for
mapping texture coordinates to the quad shall be used:

* `"LINE"`: The coordinates are paired such that the coordinate
with lowest value index is associated with the end of the line that is
closest to the emitter location and the coordinate with the next higher
index is associated with the end of the line furthest from the emitter
location. Each timestamp increases the index into the ramp by two.
* `"POINT"`: Texture coordinates are ignored.
* `"QUAD"`:  Assuming a quad facing the current viewer position,
coordinates are defined in a counter-clockwise order starting at the
lower-left corner.
* `"SPRITE"`: Texture coordinates are ignored for this type. Each
particle uses the entire supplied texture.
* `"TRIANGLE"`: Assuming two triangles facing the user, only four
coordinates are supplied, representing the four corners of the quad. The
order is the same as for `"QUAD"`.
* `"GEOMETRY"`: Texture coordinates ramps are ignored for this
type. Texture coordinates from the geometry representation are used or
automatic texture coordinate generation from the appearance node is
used.

NOTE:  the original name for the ParticleSystem _texCoord_ field
in X3D version 3 is _texCoordRamp_.

[[PointEmitter]]
==== 40.4.6 PointEmitter

[source,node]
----
PointEmitter : X3DParticleEmitterNode { 
  SFVec3f [in,out] direction   0 1 0 [-1,1]
  SFFloat [in,out] mass        0     [0,∞)
  SFNode  [in,out] metadata    NULL  [X3DMetadataObject]
  SFBool  [in,out] on          TRUE
  SFVec3f [in,out] position    0 0 0
  SFFloat [in,out] speed       0     [0,∞)
  SFFloat [in,out] surfaceArea 0     [0,∞)
  SFFloat [in,out] variation   0.25  [0,∞)
}
----

The PointEmitter node is an emitter that generates particles from the
point in space specified by the _position_ field. Particles are emitted
in the specified direction and speed.

The _direction_ field is a normalized unit vector that specifies a
direction along which the particles are to be emitted. If the vector has
value (0,0,0), particles are emitted in random directions.

[[PolylineEmitter]]
==== 40.4.7 PolylineEmitter

[source,node]
----
PolylineEmitter : X3DParticleEmitterNode { 
  MFInt32 [in]     set_coordIndex
  SFNode  [in,out] coord          NULL  [X3DCoordinateNode]
  SFVec3f [in,out] direction      0 1 0 [-1,1]
  SFFloat [in,out] mass           0     [0,∞)
  SFNode  [in,out] metadata       NULL  [X3DMetadataObject]
  SFBool  [in,out] on             TRUE
  SFFloat [in,out] speed          0     [0,∞)
  SFFloat [in,out] surfaceArea    0     [0,∞)
  SFFloat [in,out] variation      0.25  [0,∞)
  MFInt32 []       coordIndex     -1    [0,∞) or -1
}
----

The PolylineEmitter node emits particles along a single polyline. The
coordinates for the line along which particles should be randomly
generated are taken from a combination of the _coord_ and _coordIndex_
fields. The starting point for generating particles is randomly
distributed along this line and given the initial speed and direction.
If no coordinates are available, the PolylineEmitter node shall act like
a point source located at the local origin.

[[SurfaceEmitter]]
==== 40.4.8 SurfaceEmitter

[source,node]
----
SurfaceEmitter : X3DParticleEmitterNode {
  SFFloat [in,out] mass           0     [0,∞)
  SFNode  [in,out] metadata       NULL  [X3DMetadataObject]
  SFBool  [in,out] on             TRUE
  SFFloat [in,out] speed          0     [0,∞)
  SFFloat [in,out] surfaceArea    0     [0,∞)
  SFFloat [in,out] variation      0.25  [0,∞)
  SFNode  []       surface        NULL  [X3DGeometryNode]
}
----

The SurfaceEmitter node is an emitter that generates particles from the
surface of an object. New particles are generated by randomly choosing a
point on that surface. Particles are generated with an initial direction
of the normal to that point (including any normal averaging due to
_normalPerVertex_ and _creaseAngle_ field settings). If the surface is
indicated as not being solid ( _solid_ field set to `FALSE`),
randomly choose from which side of the surface to emit, negating the
normal direction when generating from the back side. Only valid geometry
shall be used.

The _surface_ field specifies the geometry to be used as the emitting
surface.

EXAMPLE  A cylinder with both end caps turned off would only generate
particles along the side of the cylinder. It would be an error to
generate a particle with an initial direction that is not perpendicular
to the axis.

NOTE  The _set_coordIndex_ and _coordIndex_ were nonfunctional and
removed in X3D version 4.0.

[[VolumeEmitter]]
==== 40.4.9 VolumeEmitter

[source,node]
----
VolumeEmitter : X3DParticleEmitterNode { 
  MFInt32 [in]     set_coordIndex
  SFNode  [in,out] coord          NULL  [X3DCoordinateNode]
  SFVec3f [in,out] direction      0 1 0 [-1,1]
  SFFloat [in,out] mass           0     [0,∞)
  SFNode  [in,out] metadata       NULL  [X3DMetadataObject]
  SFBool  [in,out] on             TRUE
  SFFloat [in,out] speed          0     [0,∞)
  SFFloat [in,out] surfaceArea    0     [0,∞)
  SFFloat [in,out] variation      0.25  [0,∞)
  MFInt32 []       coordIndex     -1    [0,∞) or -1
  SFBool  []       internal       TRUE
}
----

A VolumeEmitter node emits particles from random positions on the
surface of a volume, which then propagate either inside or outside the
given closed geometry volume.

The _internal_ field indicates whether particles are generated
internally or else externally to the defined volume.

[[WindPhysicsModel]]
==== 40.4.10 WindPhysicsModel

[source,node]
----
WindPhysicsModel : X3DParticlePhysicsModelNode { 
  SFVec3f [in,out] direction  1 0 0 [-1,1]
  SFBool  [in,out] enabled    TRUE
  SFFloat [in,out] gustiness  0.1   [0,∞)
  SFNode  [in,out] metadata   NULL  [X3DMetadataObject]
  SFFloat [in,out] speed      0.1   [0,∞)
  SFFloat [in,out] turbulence 0     [0,1]
}
----

The WindPhysicsModel node specifies a physics model that applies a wind
effect to the particles. The wind has a random variation factor that
allows for the gustiness of the wind to be modelled.

The _direction_ field specifies the direction in which the wind is
travelling in the form of a  normalized, unit vector. The _direction_
field shall be a non-degenerate vector; a value of `+0 0 0+` is not
allowed.

The _speed_ field specifies the current wind speed in speed derived
units. From the wind speed, the force applied per unit-area on the
particle is calculated using the following formula. Particle speed is
not accelerated faster than current wind speed.

____
pressure = 10^(2 × log(speed))^ × 0.64615
____

The _gustiness_ specifies how much the wind speed varies from the
average value defined by the _speed_ field. The wind speed variation is
calculated once per frame and applied equally to all particles.

The _turbulence_ field specifies how much the wind acts directly in line
with the direction, and how much variation is applied in directions
other than the wind direction. A _turbulence_ value of 0 means no
turbulence, while a _turbulence_ value of 1 means maximum turbulence.
This is determined per-particle to model how the particle is affected by
turbulence.

[[S40.5_SupportLevels]]
=== 40.5 Support levels

The Particle Systems component provides two levels of support as
specified in <<t40_2, Table 40.2>>.

[[t40_2]]
*Table 40.2 — Particle systems component support
levels*

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 | |

| | |_X3DParticleEmitterNode_ |n/a

| | |_X3DParticlePhysicsModelNode_ |n/a

|  |  |ConeEmitter |All fields fully supported.

| | |ExplosionEmitter |All fields fully supported.

| | |ForcePhysicsModel |All fields fully supported.

| | |ParticleSystem |All fields fully supported, except
`"SPRITE"` and "`GEOMETRY`" geometry types and the
_geometry_ field.

|  |  |PointEmitter |All fields fully supported.

|  |  |PolylineEmitter |All fields fully supported.

|  |  |WindPhysicsModel |All fields fully supported.

|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 |  | 

|  |  |All Level 1 nodes |All fields supported as specified for Level 1
except as specified below.

|  |  |BoundedPhysicsModel |All fields fully supported.

|  |  |ParticleSystem |All fields fully supported, except 
"`GEOMETRY`" geometry type and the _geometry_ field.

|  |  |SurfaceEmitter |All fields fully supported.

|  |  |VolumeEmitter |All fields fully supported.

|*3* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 |  | 

|  |  |All Level 2 nodes |All fields fully supported.

|  |  |ParticleSystem |All fields fully supported.
|===

[[volume_html]]
== 41 Volume rendering component

[[S41_Introduction]]
=== 41.1 Introduction

[[S41_Name]]
==== 41.1.1 Name

The name of this component is "VolumeRendering". This name shall be used
when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S41_Overview]]
==== 41.1.2 Overview

This component provides the ability to specify and render volumetric
data sets. <<t41_1, Table 41.1>> provides links to the major topics
in this clause.

[[t41_1]]
Table 41.1 — Topics

* <<S41Introduction, 41.1 Introduction>>
** <<S41_Name, 41.1.1 Name>>
** <<S41_Overview, 41.1.2 Overview>>
* <<S41_Concepts, 41.2 Concepts>>
** <<S41_ConceptsOverview, 41.2.1 Overview>>
** <<RepresentingVolumetricData, 41.2.2 Representing volumetric data>>
*** <<RegistrationAndScaling, 41.2.2.1 Registration and scaling>>
*** <<DataRepresentation, 41.2.2.2 Data representation>>
**** <<S3DTextureDefinition, 41.2.2.2.1 3D texture definition>>
**** <<VectorAndNormalRepresentation, 41.2.2.2.2 Vector and normal representation>>
**** <<DataOptimization, 41.2.2.2.3 Data optimization>>
*** <<SegmentationInformation, 41.2.2.3 Segmentation information>>
*** <<TensorRepresentation, 41.2.2.4 Tensor representation>>
*** <<VisualRepresentation, 41.2.2.5 Visual representation>>
** <<InteractionWithOtherNodesAndComponents, 41.2.3 Interaction with other nodes and components>>
*** <<InteractionOverview, 41.2.3.1 Overview>>
*** <<Lighting, 41.2.3.2 Lighting>>
*** <<Geometry, 41.2.3.3 Geometry>>
** <<S41_Conformance, 41.2.4 Conformance>>
*** <<Dimensionality, 41.2.4.1 Dimensionality>>
*** <<HardwareRequirements, 41.2.4.2 Hardware requirements>>
*** <<SceneGraphInteraction, 41.2.4.3 Scene graph interaction>>
* <<S41_AbstractTypes, 41.3 Abstract types>>
** <<X3DComposableVolumeRenderStyleNode, 41.3.1 _X3DComposableVolumeRenderStyleNode_>>
** <<X3DVolumeDataNode, 41.3.2 _X3DVolumeDataNode_>>
** <<X3DVolumeRenderStyleNode, 41.3.3 _X3DVolumeRenderStyleNode_>>
* <<S41_NodeReference, 41.4 Node reference>>
** <<BlendedVolumeStyle, 41.4.1 BlendedVolumeStyle>>
** <<BoundaryEnhancementVolumeStyle, 41.4.2 BoundaryEnhancementVolumeStyle>>
** <<CartoonVolumeStyle, 41.4.3 CartoonVolumeStyle>>
** <<ComposedVolumeStyle, 41.4.4 ComposedVolumeStyle>>
** <<EdgeEnhancementVolumeStyle, 41.4.5 EdgeEnhancementVolumeStyle>>
** <<IsoSurfaceVolumeData, 41.4.6 IsoSurfaceVolumeData>>
** <<OpacityMapVolumeStyle, 41.4.7 OpacityMapVolumeStyle>>
** <<ProjectionVolumeStyle, 41.4.8 ProjectionVolumeStyle>>
** <<SegmentedVolumeData, 41.4.9 SegmentedVolumeData>>
** <<ShadedVolumeStyle, 41.4.10 ShadedVolumeStyle>>
** <<SilhouetteEnhancementVolumeStyle, 41.4.11 SilhouetteEnhancementVolumeStyle>>
** <<ToneMappedVolumeStyle, 41.4.12 ToneMappedVolumeStyle>>
** <<VolumeData, 41.4.13 VolumeData>>
* <<S41_SupportLevels, 41.5 Support levels>>

* <<t41_1, Table 41.1 — Topics>>
* <<t41_2, Table 41.2 — Mapping of texture colour components to 3D coordinates>>
* <<t41_3, Table 41.3 — Weight function types>>
* <<t41_4, Table 41.4 — Transfer function to weight mapping>>
* <<t41_5, Table 41.5 — Transfer function mapping from texture type to texture coordinate>>
* <<t41_6, Table 41.6 — Transfer function mapping from texture type to output colour>>
* <<t41_7, Table 41.7 — Volume rendering component support levels>>

* <<f-BlendedVolumeStyle, Figure 41.1 — Torso in BlendedVolumeStyle>>
* <<f-BoundaryEnhancementVolumeStyle, Figure 41.2 — Default volume style on left and BoundaryEnhancementVolumeStyle on right>>
* <<f-CartoonVolumeStyle, Figure 41.3 — Default volume style on left and CartoonVolumeStyle on right>>
* <<f-ComposedVolumeStyle, Figure 41.4 — Default volume style on left and ComposedVolumeStyle on right>>
* <<f-EdgeEnhancementVolumeStyle, Figure 41.5 — Default volume style on left and EdgeEnhancementVolumeStyle on right>>
* <<f-IsoSurfaceVolumeData, Figure 41.6 — IsoSurface volume data using CartoonVolumeStyle>>
* <<f-OpacityMapVolumeStyle, Figure 41.7 — Default volume style on left and OpacityMapVolumeStyle on right>>
* <<f-LMIPThreshold, Figure 41.8 — Illustration of values selected when using MIP or LMIP volume rendering styles>>
* <<f-ProjectionVolumeStyle, Figure 41.9 — Default volume style on left and MIP ProjectionVolumeStyle on right>>
* <<f-SegmentedVolumeData, Figure 41.10 — Segmented volume data using OpacityMapVolumeStyle and ToneMappedVolumeStyle>>
* <<f-ShadedVolumeStyle, Figure 41.11 — Default volume style on left and ShadedVolumeStyle on right>>
* <<f-SilhouetteEnhancementVolumeStyle, Figure 41.12 — Default volume style on left and SilhouetteEnhancementVolumeStyle on right>>
* <<f-ToneMappedVolumeStyle, Figure 41.13 — Default volume style on left and ToneMappedVolumeStyle on right>>
* <<f-VolumeData, Figure 41.14 — Volume data using default volume style>>




[[S41_Concepts]]
=== 41.2 Concepts

[[S41_ConceptsOverview]]
==== 41.2.1 Overview

Volume rendering is an alternate form of visual data representation
compared to the traditional polygonal form used in the rest of this
document. Whereas polygons represent a portion of an infinitely thin
plane, volume data represents a three-dimensional portion of space. When
polygonal data representing a volume in space is sliced, such as with a
clipping plane, there is empty space. In the same situation, volumetric
data shows the internals of that volume.

There are many different techniques for implementing rendering of
volumetric data. This component does not define the technique used to
render the data, only the type of visual output to be produced. In
addition, it defines several different types of data representations for
which the renderings may be applied. To implement some of the
higher-complexity representations, the implementer may need to use a
more complex rendering technique than the simpler representations
(though this is not required). Each of the rendering nodes represents
the visual output required, not the technique used to implement that
visual output. Most of the rendering styles defined in this component
are formally defined in <<%5BFOLEY%5D, FOLEY>>.

[[RepresentingVolumetricData]]
==== 41.2.2 Representing volumetric data

[[RegistrationAndScaling]]
===== 41.2.2.1 Coordinate system

Volumetric data consists of a set of aligned 2D textures. The coordinate
system places the 2D textures in the volume such that each 2D texture
lies in the XY-plane, with the depth increasing away from the viewer
along the +Z axis.

NOTE  This, effectively, inverts the 3D texture coordinates for the R
axis direction, which defines them to have depth increasing along the -Z
axis (see <<f-3DTexture, Figure 33.1>>).

The volume is centered around the local origin and is subject to the
parent transformation hierarchy, including scales, shears and rotations.

==== 41.2.2.1 Registration and scaling

Volumetric data represents volume information that often comes from the
real world or is computationally generated.

EXAMPLE  Human body scans are from the real world while simulated stress
analysis of an engine part is computationally generated.

The volumetric data is typically part of a larger environment space and
thus needs to be located within that space so that volumes for different
parts ( _e.g._, an arm and leg of a single human) may be presented in a
spatially correct manner. Typically, volumes are not a unit cube in
size. Thus, additional dimensional information accompanies the volume to
indicate its true size in the local coordinate system.

[[DataRepresentation]]
===== 41.2.2.2 Data representation

[[S3DTextureDefinition]]
===== 41.2.2.2.1 3D texture definition

Volume rendering requires the data be provided in a volumetric form.
This component uses the 3D texturing component (see
<<texture3D_html, 33 Texturing3D component>>) to represent the raw
volume data, but without rendering that data directly onto polygonal
surfaces. Volumetric rendering may make use of multiple 3D textures to
generate a final visual form.

Data may be represented using between one and four colour components.
How each colour component is to be interpreted as part of the rendering
is defined for each node. Some nodes may require a specific minimum
number of components or define that anything more than a specific number
are to be ignored. Providing extra data may not be helpful to the
implementation. In cases where not enough components are provided (
_e.g._, a surface normal texture only being defined with a one or two
component colour image), the entire data source is ignored.

[[VectorAndNormalRepresentation]]
===== 41.2.2.2.2 Vector and normal representation

Some nodes make use of 3D textures to convey data other than colour.

EXAMPLE  Normal or other vector information may be included.

For the purposes of representing 3D information, the 3D texture
components shall be interpreted as defined by
<<t41_2, Table 41.2>>.

[[t41_2]]
Table 41.2 —
Mapping of texture colour components to 3D coordinates

[cols=",",options="header",]
|===
|Color Component |3D Coordinate
|Red |X
|Green |Y
|Blue |Z
|Alpha |Ignored
|===

If the texture provided for the field does not contain enough colour
components for the data to be represented, it shall be ignored and the
node's default behaviour used.

If a rendering style requires a surface normal value and is required to
implicitly calculate one, the normal at a given voxel is the normalized
gradient of the scalar field at that voxel location.

[[DataOptimization]]
===== 41.2.2.2.3 Data optimization

An implementation is free to provide whatever data reduction techniques
are appropriate during pre-processing prior to rendering. Within a
specific volume data representation, the implementation may also perform
its own optimization techniques.

EXAMPLE  Automatic mipmapping may occur.

Volume visualization data sets are not required to be represented in
sizes that are powers of two. Implementations may need to internally pad
the texture sizes for passing to the underlying rendering engine, but
user-provided content is not required to do this.

[[SegmentationInformation]]
===== 41.2.2.3 Segmentation information

The volume data may optionally represent segmented data sets. Doing so
requires representing the data in a slightly different manner than a
standard volume data set. Therefore, a separate node is provided.
Segmentation data takes the form of an additional volume of data where
each voxel represents a segment ID value in addition to other values
represented in each voxel. The segmentation information is used by the
rendering process to control how each voxel is to be rendered. It is not
unusual to use segmentation information to render each segment
identifier with a different style.

EXAMPLE  Bone may be rendered using isosurfaces while skin may be
rendered using tone shading.

[[TensorRepresentation]]
===== 41.2.2.4 Tensor representation

This document does not explicitly handle or represent tensor data (
_i.e._, higher-order products of functions that are each applied to a
set of variables). Nevertheless, tensor information may be rendered
using the techniques in this International Standard even though no
direct data is being transmitted. It is recommended that, if an
application needs to know about the existence of tensor data, the
metadata capabilities of this document also be used.

[[VisualRepresentation]]
===== 41.2.2.5 Visual representation

Volumetric data is typically given as a 3D rectangular block of
information. Turning that densely packed information into something
meaningful where internal structures may be discernable is the job of
the rendering process. However, there is not a single uniform approach
to volume rendering. A technique that is good for exposing structures
for medical visualization may be poor for fluid simulation
visualization.

To allow for the production of different visual outputs, the Volume
rendering component separates the scenegraph into two sets of
responsibilities:

[loweralpha]
. nodes for representing the volume data, and
. nodes for rendering that volume data in different ways.

In this way, the same rendering process may be used for different sets
of volume data where varying rendering styles may be used to highlight
different structures within the one volume.

Many rendering techniques map volume data to a visual representation
through the use of another texture known as a Transfer function. This
secondary texture defines the colours to use, acting as a form of lookup
table. Transfer functions can be defined in one, two, or three
dimensions. A one-dimensional texture capability can be achieved through
the use of a 2D texture that is only one pixel wide.

[[InteractionWithOtherNodesAndComponents]]
==== 41.2.3 Interaction with other nodes and components

[[InteractionOverview]]
===== 41.2.3.1 Overview

Volumetric rendering requires a completely different implementation path
from traditional polygonal rendering. The data represents not only
surface information, but also colour and potentially lighting
information as well. As such, volume rendering occupies the role in the
renderable scenegraph of an X3DShapeNode rather than as individual
geometry or appearance information.

[[Lighting]]
===== 41.2.3.2 Lighting

Volumetric rendering is not required to follow the standard lighting
equations specified in <<lighting_html, 17 Lighting component>>. Many
techniques include the ability to self-light and self-shadow using
information from the parent scene graph ( _e.g._, light scoping).

The volume data is rendered using one or more rendering styles. Each
rendering style defines its own lighting equation that takes the colour
and opacity value from the previously evaluated style, modifies the
lighting equation according to the local style rules, and generates an
output colour and opacity value. The first rendering style that is
applied to the voxel obtains the source values directly from the voxel
data using the colour and/or opacity channels as needed. Typically, the
first rendering style the used to render the volume data are transfer
functions and the <<OpacityMapVolumeStyle>>.

Many of these rendering styles involve non-photorealistic rendering
effects. Each style presents its own lighting equation specifying how to
get from the underlying voxel representation to the contributed output
colour. The following are some common terms that are found in the
lighting equations:

* O~v~: The initial opacity of the object prior to the use of this
rendering style. If this is the first rendering style applied to the
object, this is the value of the alpha component of the voxel being
evaluated.
* O~g~: The output opacity of the object resulting from evaluating this
rendering style.
* C~v~: The initial colour of the object prior to the use of this
rendering style. If this is the first rendering style applied to the
object, this is the value of the colour components of the voxel being
applied.
* C~g~ The output colour of the object resulting from evaluating this
rendering style.
* Δf: The normalized value gradient of the voxel. This is the rate of
change of the value relative to the values in neighbouring voxels.
* *V*: The vector from the viewer's position to the voxel being
evaluated, in the local coordinate space of the volume data.
* *n*: The local surface normal. This may be provided by the user
through another 3D texture that contains a surface normal for each voxel
or else is internally calculated through algorithmic means.
* *L*~i~: Light direction vector from light source _i_. Typically, this
is part of a summation over all light sources affecting the volume.

When determining the view direction for any lighting or rendering
calculations, the view direction is calculated from the user's current
location in the world to the current voxel being processed. Lighting and
rendering style calculations are assumed to be individually calculated
for each voxel.

[[Geometry]]
===== 41.2.3.3 Geometry

The volumetric rendering nodes representing geometry are leaf nodes in
the renderable tree. Volumetric nodes may exist as part of a shared
scene graph with DEF/USE.

[[S41_Conformance]]
==== 41.2.4 Conformance

[[Dimensionality]]
===== 41.2.4.1 Dimensionality

The minimum required voxel dimensions that shall be supported are
256x256x256.

[[HardwareRequirements]]
===== 41.2.4.2 Hardware requirements

There are no specific requirements for hardware acceleration of this
component. In addition, this component does not define the specific
implementation strategy to be used by a given rendering style. It is as
equally valid to implement the code using simple multi-pass rendering as
it is to use hardware shaders.

[[SceneGraphInteraction]]
===== 41.2.4.3 Scene graph interaction

For minimum conformance, sensor nodes that require interaction with the
geometry ( _e.g._, TouchSensor) shall provide intersection information
based on the volume's bounds. An implementation may optionally provide
real intersection information based on performing ray casting into the
volume space and reporting the first non-transparent voxel hit.

Navigation and collision detection also require a minimal conformance
requirement of using the bounds of the volume. In addition, the
implementation may allow greater precision with non-opaque voxels in a
similar manner to the sensor interactions.


=== 41.3 Abstract types

[[X3DComposableVolumeRenderStyleNode]]
==== 41.3.1 _X3DComposableVolumeRenderStyleNode_

[source,node]
----
X3DComposableVolumeRenderStyleNode : X3DVolumeRenderStyleNode {
  SFBool   [in,out] enabled  TRUE
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
}
----

The _X3DComposableVolumeRenderStyleNode_ abstract node type is the base
type for all node types that allow rendering styles to be sequentially
composed together to form a single renderable output. The output of one
style may be used as the input of the next style. Composition in this
manner is performed using the
<<ComposedVolumeStyle>> node.

[[X3DVolumeDataNode]]
==== 41.3.2 _X3DVolumeDataNode_

[source,node]
----
X3DVolumeDataNode : X3DChildNode, X3DBoundedObject { 
  SFVec3f [in,out] dimensions  1 1 1    (0,∞)
  SFBool  [in out] bboxDisplay FALSE
  SFNode  [in,out] metadata    NULL     [X3DMetadataObject]
  SFBool  [in out] visible     TRUE
  SFVec3f []       bboxCenter  0 0 0    (-∞,∞)
  SFVec3f []       bboxSize    -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The _X3DVolumeDataNode_ abstract node type is the base type for all node
types that describe volumetric data to be rendered. It sits at the same
level as the polygonal _X3DShapeNode_ (see <<X3DShapeNode, 12.3.4 _X3DShapeNode_>>) within the scene graph structure, but defines
volumetric data rather than polygonal data.

The _dimensions_ field specifies the dimensions of this geometry in the
local coordinate space using standard X3D length base units. It is
assumed the volume is centered around the local origin. If the
_bboxSize_ field is set, it typically has the same value as the
_dimensions_ field.

If one of the dimension values is zero, the _X3DVolumeDataNode_ shall be
rendered as a plane. If two of the dimension values are zero, the
_X3DVolumeDataNode_ shall be rendered as a line. If all three dimension
values are zero, the _X3DVolumeDataNode_ shall be rendered as a point.

[[X3DVolumeRenderStyleNode]]
==== 41.3.3 _X3DVolumeRenderStyleNode_

[source,node]
----
X3DVolumeRenderStyleNode : X3DNode {
  SFBool   [in,out] enabled  TRUE
  SFNode   [in,out] metadata NULL [X3DMetadataObject]
}
----

The _X3DVolumeRenderStyleNode_ abstract node type is the base type for
all node types that specify a specific visual rendering style to be used
when rendering volume data.

The _enabled_ field defines whether this rendering style is currently
applied to the volume data. If the field is set to  `FALSE`, the
rendering shall not be applied. The result of rendering with the
_enabled_ field set to  `FALSE` shall act as though no volume
data is provided. Effectively, this allows turning on and off volume
rendering of specific parts of the volume without needing to add or
remove style definitions from the volume data node.


=== 41.4 Node reference

[[BlendedVolumeStyle]]
==== 41.4.1 BlendedVolumeStyle

[source,node]
----
BlendedVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFBool   [in,out] enabled                 TRUE
  SFNode   [in,out] metadata                NULL       [X3DMetadataObject]
  SFNode   [in,out] renderStyle             NULL       [X3DComposableVolumeRenderStyleNode]
  SFNode   [in,out] voxels                  NULL       [X3DTexture3DNode]         
  SFFloat  [in,out] weightConstant1         0.5        [0,1]
  SFFloat  [in,out] weightConstant2         0.5        [0,1]
  SFString [in,out] weightFunction1         "CONSTANT" ["CONSTANT", "ALPHA1", "ALPHA2", "TABLE",
                                                        "ONE_MINUS_ALPHA1", "ONE_MINUS_ALPHA2"] 
  SFString [in,out] weightFunction2         "CONSTANT" ["CONSTANT", "ALPHA1", "ALPHA2", "TABLE",
                                                        "ONE_MINUS_ALPHA1", "ONE_MINUS_ALPHA2"] 
  SFNode   [in,out] weightTransferFunction1 NULL       [X3DTexture2DNode]
  SFNode   [in,out] weightTransferFunction2 NULL       [X3DTexture2DNode]
}
----

The BlendedVolumeStyle combines the rendering of the parent volume data
set and the rendering of a second specified volume data set into one by
blending the values according to a weight function. The first data set
is the data set that is specified by the parent VolumeData or
SegmentedVolumeData node. The second data set and its render style is
defined by the _voxels_ and _renderStyle_ fields specified by this
BlendedVolumeStyle node. For the latter case, the value specified by the
_renderStyle_ field is applied to the voxels specified by the _voxels_
field. The result is blended with the current state of voxels from the
parent VolumeData or SegmentedVolumeData node. Those voxels are either
the original parent voxels with default OpacityMapVolumeStyle applied or
the result of any previous renderStyle values having been applied by a
ComposedVolumeStyle node.

The final colour is determined by:

____
C~g~ = clamp~[0-1]~(C~v~ × w1 + C~blend~ × w2) +
O~g~ = clamp~[0-1]~(O~v~ × w1 + O~blend~ × w2)
____

where C~blend~ and O~blend~ is the color and alpha value of the second
data set after the rendering style has been applied. The values of w1
and w2 depend on the _weightFunction1_ and _weightFunction2_ fields,
respectively, as defined in <<t41_3, Table 41.3>>.

[[t41_3]]
Table 41.3 — Weight function types

[cols=",,",options="header",]
|===
|Value |Description of weightFunction1 |Description of weightFunction2
| `"CONSTANT"` |Use _weightConstant1_. |Use __weightConstant__2.

|`"ALPHA1"` |Use O~v~. |Use O~v~.

|`"ALPHA2"` |Use O~blend~. |Use O~blend~.

| `"ONE_MINUS_ALPHA1"` |Use 1 - O~v~. |Use 1 - O~v~.

| `"ONE_MINUS_ALPHA2"` |Use 1 - O~blend~. |Use 1 - O~blend~.

|`"TABLE"` |Use the lookup value for texture coordinate  (O~v~,
O~blend~) in _weightTransferFunction1_ and map to weight value according
to <<t41_4, Table 41.4>> or use O~v~ if
_weightTransferFunction1_ is `NULL`. |Use the lookup value for
texture coordinate  (O~v~, O~blend~) in __weightTransferFunction__2 and
map to weight value according to
<<t41_4, Table 41.4>> or use O~v~ if
__weightTransferFunction__2 is `NULL`.
|===

The _weightTransferFunction1_ and _weightTransferFunction2_ fields
specify two-dimensional textures that are used to determine the weight
values when the corresponding weight function is set to
`"TABLE"`. The output weight value depends on the number of
components in the textures as specified in
<<t41_4, Table 41.4>>.

[[t41_4]]
Table 41.4 — Transfer function
to weight mapping

[cols="^,,",options="header",]
|===
|*Number of Texture Components* |*Texel Components* |Weight
|1 |Luminance (L) |Luminance component (L)
|2 |Luminance Alpha (LA) |Luminance component (L)
|3 |RGB |Red component (R)
|4 |RGBA |Red component (R)
|===

<<f-BlendedVolumeStyle, Figure 41.1>> depicts a human torso and part
of a skull (OpacityMapRenderStyle) blended with a blue/yellow
tone-mapped volume of the internal organs. The image shows how
BlendedVolumeStyle allows two different volumes to be combined, each
with its own render style.

[[f-BlendedVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Blended_Body_Internals.png[Blended_Body_Internals.png,width=512,height=512]

Figure 41.1 — Torso in BlendedVolumeStyle

[[BoundaryEnhancementVolumeStyle]]
==== 41.4.2 BoundaryEnhancementVolumeStyle

[source,node]
----
BoundaryEnhancementVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFFloat     [in,out] boundaryOpacity  0.9     [0,1]
  SFBool      [in,out] enabled          TRUE
  SFNode      [in,out] metadata         NULL    [X3DMetadataObject]
  SFFloat     [in,out] opacityFactor    2       [0,∞)
  SFFloat     [in,out] retainedOpacity  0.2     [0,1]
  SFNode      [in,out] surfaceNormals   NULL    [X3DTexture3DNode]
}
----

The BoundaryEnhancementVolumeStyle node provides boundary enhancement
for the volume rendering style. In this rendering style, the colour
rendered is based on the gradient magnitude. Faster-changing gradients
(surface normals) are darker than slower-changing gradients. Thus,
regions of different density are made more visible relative to parts
that are of relatively constant density. Additional information may be
found in [<<VIS2002>>].

The _boundaryOpacity_ field is the factored amount of the gradient
enhancement to use.

The _opacityFactor_ field is a power term (exponent in the equation
below) that controls the slope of the opacity curve.

The _retainedOpacity_ field specifies the normalized proportion of the
initial opacity that is retained and mixed into the output.

The _surfaceNormals_ field contains a 3D texture with at least three
component values. Each voxel in the texture represents the surface
normal direction for the corresponding voxel in the base data source.
This texture should be identical in dimensions to the source data. If
not, the implementation may interpolate or average between adjacent
voxels to determine the average normal at the voxel required. If this
field is empty, the implementation shall automatically determine the
surface normal using algorithmic means.

The output opacity for this rendering style is obtained by combining a
fraction of the volume's original opacity with the _boundaryOpacity_
field, which is an enhancement based on the local boundary strength (
_i.e._, magnitude of the gradient between adjacent voxels). Colour
components from the input are transferred unmodified to the output. The
function used is:

____
O~g~ = O~v~ (k~gc~ + k~gs~(|Δf|)^k~ge~)
____

where

* the operator "^" means "to the power"
* O~g~ is the computed opacity of the voxel
* O~v~ is the original opacity of the voxel
* k~gc~ is the amount of initial opacity to mix into the output (
_retainedOpacity_).
* k~gs~ is the factored amount of the gradient enhancement to use (
_boundaryOpacity_).
* k~ge~ is the power function to control the slope of the opacity curve
to highlight the set of data ( _opacityFactor_).
* |Δf| is the absolute value of the forward difference between the
current and next voxel.

<<f-BoundaryEnhancementVolumeStyle, Figure 41.2>> shows a basic image
of ventricles of the brain on the left and an image of ventricles of the
brain using BoundaryEnhancementVolumeStyle on the right.

[[f-BoundaryEnhancementVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Ventricles_Basic_Boundary.png[Ventricles_Basic_Boundary.png,width=800,height=404]

Figure 41.2 — On the left, the ventricle with default render style and
default field values. On the right, the ventricle using
BoundaryEnhancementVolumeStyle with default values: boundaryOpacity=0.9,
opacityFactor=2, and retainedOpacity=0.2.

[[CartoonVolumeStyle]]
==== 41.4.3 CartoonVolumeStyle

[source,node]
----
CartoonVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFInt32     [in,out] colorSteps       4       [1,64]
  SFBool      [in,out] enabled          TRUE
  SFNode      [in,out] metadata         NULL    [X3DMetadataObject]
  SFColorRGBA [in,out] orthogonalColor  1 1 1 1 [0,1]
  SFColorRGBA [in,out] parallelColor    0 0 0 1 [0,1]
  SFNode      [in,out] surfaceNormals   NULL    [X3DTexture3DNode]
}
----

The CartoonVolumeStyle generate a cartoon-style non-photorealistic
rendering of the associated volumetric data. Cartoon rendering uses two
colours that are rendered in a series of distinct flat-shaded sections
based on the local surface normal's closeness to the average normal with
no gradients in between.

The _surfaceNormals_ field contains a 3D texture with at least three
component values. Each voxel in the texture represents the surface
normal direction for the corresponding voxel in the base data source.
This texture should be identical in dimensions to the source data. If
not, the implementation may interpolate or average between adjacent
voxels to determine the average normal at the voxel required. If this
field is empty, the implementation shall automatically determine the
surface normal using algorithmic means.

The _parallelColor_ field specifies the colour to be used for surface
normals that are orthogonal to the viewer's current location (where the
plane of the surface itself is parallel to the user's view direction).

The _orthogonalColor_ field specifies the colour to be used for surface
normals that are parallel to the viewer's current location (the plane of
the surface itself is orthogonal to the user's view direction). Surfaces
that are backfacing are not rendered and shall have no colour calculated
for them.

The _colorSteps_ field indicates how many distinct colours are taken
from the interpolated colours and used to render the object. If the
value is 1, no colour interpolation takes place and only the orthogonal
colour is used to render the surface. For any other value, the colours
are interpolated between _parallelColor_ and _orthogonalColor_ in HSV
colour space for the RGB components, and linearly for the alpha
component.

To determine the colours to be used, the angles for the surface normal
relative to the view position are used. The range [0, π/2] is divided by
_colourSteps_. (The two ends of the spectrum are not interpolated in
this way and shall use the specified field values). For each of the
interpolated ranges, other than the two ends, the midpoint angle is
determined and the interpolated colour value is computed using that
point.

EXAMPLE  Using the default field values for CartoonVolumeStyle, the
following RGBA colour are computed:

* 1,1,1,1 for angles [0, π/8)
* 0.625,0.625,0.625,1 for angles [π/8, π/4),
* 0.375,0.375,0.375,1 for angles [π/4, 3π/8),
* 0,0,0,1 for angles [3π/8, π/2]

<<f-CartoonVolumeStyle, Figure 41.3>> shows a basic image of a
backpack on the left and an image of the backpack using
CartoonVolumeStyle on the right.

[[f-CartoonVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Backpack_Basic_Cartoon.png[Backpack_Basic_Cartoon.png,width=800,height=445]

Figure 41.3 — Default volume style on left and CartoonVolumeStyle on
right

[[ComposedVolumeStyle]]
==== 41.4.4 ComposedVolumeStyle

[source,node]
----
ComposedVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFBool [in,out] enabled     TRUE
  SFNode [in,out] metadata    NULL  [X3DMetadataObject]
  MFNode [in,out] renderStyle []    [X3DComposableVolumeRenderStyleNode]
}
----

The ComposedVolumeStyle node is a rendering style node that allows
compositing multiple rendering styles together into a single rendering
pass.

EXAMPLE  ComposedVolumeStyle is used to render a simple volume with both
edge and silhouette rendering styles.

The _renderStyle_ field contains a list of contributing rendering style
nodes or node references that can be applied to the object. The
implementation shall apply each rendering style strictly in the order
declared starting with the first rendering style in the _renderStyle_
field.

<<f-ComposedVolumeStyle, Figure 41.4>> shows a basic image of a
backpack on the left and an image of the backpack using
ComposedVolumeStyle on the right that combines
EdgeEnhancementVolumeStyle with SilhouetteEnhancementVolumeStyle.

[[f-ComposedVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Backpack_Basic_Composed.png[Backpack_Basic_Composed.png]

Figure 41.4 — Default volume style on left and ComposedVolumeStyle on
right

[[EdgeEnhancementVolumeStyle]]
==== 41.4.5 EdgeEnhancementVolumeStyle

[source,node]
----
EdgeEnhancementVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFColorRGBA [in,out] edgeColor         0 0 0 1 [0,1]
  SFBool      [in,out] enabled           TRUE
  SFFloat     [in,out] gradientThreshold 0.4     [0,π]
  SFNode      [in,out] metadata          NULL    [X3DMetadataObject]
  SFNode      [in,out] surfaceNormals    NULL    [X3DTexture3DNode]
}
----

The EdgeEnhancementVolumeStyle node specifies edge enhancement for the
volume rendering style. Enhancement of the basic volume is provided by
darkening voxels based on their orientation relative to the view
direction. Perpendicular voxels are coloured according to the
_edgeColor_ while voxels parallel are not changed at all. A threshold
can be set where the proportion of how close to parallel the direction
needs to be before no colour changes are made.

The _gradientThreshold_ field defines the minimum angle (in radians)
away from the view direction vector for the surface normal before any
enhancement is applied.

The _edgeColor_ field defines the colour to be used to highlight the
edges.

The _surfaceNormals_ field contains a 3D texture with at least three
component values. Each voxel in the texture represents the surface
normal direction for the corresponding voxel in the base data source.
This texture should be identical in dimensions to the source data. If
not, the implementation may interpolate or average between adjacent
voxels to determine the average normal at the voxel required. If this
field is empty, the implementation shall automatically determine the
surface normal using algorithmic means.

The final colour is determined by:

C~g~ =  C~v~ if (| *n* . **V**|) ≥ cos(gradientThreshold); +
        C~v~ × (| *n* . **V**|) + edgeColor × (1 - (| *n* . **V**|))
otherwise.

O~g~ = O~v~

<<f-EdgeEnhancementVolumeStyle, Figure 41.5>> shows a basic image of a
human brain on the left and an image of the human brain using
EdgeEnhancementVolumeStyle on the right.

[[f-EdgeEnhancementVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Brain_Basic_Edge.png[Brain_Basic_Edge.png,width=798,height=343]

Figure 41.5 — Default volume style on left and
EdgeEnhancementVolumeStyle on right

[[IsoSurfaceVolumeData]]
==== 41.4.6 IsoSurfaceVolumeData

[source,node]
----
IsoSurfaceVolumeData : X3DVolumeDataNode {
  SFFloat [in,out] contourStepSize  0        (-∞,∞)
  SFVec3f [in,out] dimensions       1 1 1    (0,∞)
  SFBool  [in out] bboxDisplay      FALSE
  SFNode  [in,out] gradients        NULL     [X3DTexture3DNode]
  SFNode  [in,out] metadata         NULL     [X3DMetadataObject]
  MFNode  [in,out] renderStyle      []       [X3DVolumeRenderStyleNode]
  SFFloat [in,out] surfaceTolerance 0        [0,∞)
  MFFloat [in,out] surfaceValues    []       (-∞,∞)
  SFNode  [in,out] voxels           NULL     [X3DTexture3DNode]
  SFBool  [in out] visible          TRUE
  SFVec3f []       bboxCenter       0 0 0    (-∞,∞)
  SFVec3f []       bboxSize         -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The IsoSurfaceVolumeData node specifies one or more surfaces extracted
from a voxel data set. A surface is defined as the boundary between
regions in the volume where the voxel values are larger than a given
value (the iso value) on one side of the boundary and smaller on the
other side and the gradient magnitude is larger than _surfaceTolerance_.
The _gradients_ field may be used to provide explicit per-voxel gradient
direction information for determining surface boundaries rather than
having it implicitly calculated by the implementation.

This data representation has one of three possible modes of operation
based on the values of the two fields _surfaceValues_ and
_contourStepSize_.

. If _surfaceValues_ has a single value defined, render the isosurface
that corresponds to that value.
. If the _surfaceValues_ field has a single defined _contourStepSize_
that is non-zero, also render all isosurfaces that are multiples of that
step size from the initial surface value.

____
EXAMPLE  With a surface value of 0.25 and a step size of 0.1, any
additional isosurfaces at 0.05, 0.15, 0.35, 0.45, ... shall also be
rendered. If _contourStepSize_ is left at the default value of zero,
only that single isovalue is rendered as a surface.

NOTE  The _contourStepSize_ is allowed to be negative so that stepping
proceeds in a negative direction.
____

. If _surfaceValues_ has more than a single value defined, the
_contourStepSize_ field is ignored and surfaces corresponding to the
listed _surfaceValues_ amounts are rendered.

For each isosurface extracted from the data set, a separate render style
may be assigned using the _renderStyle_ node. The rendering styles are
taken from the _renderStyles_ field corresponding to the index of the
surface value defined. In the case where automatic contours are being
extracted using the step size, the explicit surface value shall use the
first declared render style. Then render styles are assigned starting
from the smallest iso-value. In all cases, if there are insufficient
render styles defined for the number of isosurfaces to be rendered, the
last style shall be used for all surfaces that do not have an explicit
style assigned.

O~v~ is defined to be 1 for this volume data regardless of the number of
components in the provided volume data texture.

<<f-IsoSurfaceVolumeData, Figure 41.6>> shows an IsoSurfaceVolume
image of a skull using CartoonVolumeStyle.

[[f-IsoSurfaceVolumeData]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/isoSurface-cartoon-high_skull.png[Skull_IsoSurface_Cartoon,width=400,height=392]

Figure 41.6 — IsoSurface volume data using CartoonVolumeStyle

[[OpacityMapVolumeStyle]]
==== 41.4.7 OpacityMapVolumeStyle

[source,node]
----
OpacityMapVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFBool [in,out] enabled          TRUE
  SFNode [in,out] metadata         NULL [X3DMetadataObject]
  SFNode [in,out] transferFunction NULL [X3DTexture2DNode,X3DTexture3DNode]
}
----

The OpacityMapVolumeStyle specifies that the associated volumetric data
is to be rendered using the opacity mapped to a transfer function
texture. This is the default rendering style if no other
X3DComposableVolumeRenderStyleNode is defined for the volume data.

The _transferFunction_ field holds a single texture representation in
either two or three dimensions that maps the voxel data values to a
specific colour output. If no value is supplied for this field, the
default implementation shall generate a 256x1 alpha-only image that
blends from completely transparent at pixel 0 to fully opaque at pixel
255.The texture may be any number of dimensions and any number of
components. The voxel values are used as lookup coordinates into the
transfer function texture, where the texel value represents the output
colour.

Components are mapped from the voxel data to the transfer function in a
component-wise fashion. The first component of the voxel data is an
index into the first dimension of the _transferFunction_ texture (S).
Similarly, T, R, and Q are indices into the second, third, and fourth
dimensions of the _transferFunction_ texture (see
<<t41_5, Table 41.5>>). If there
are more components defined in the voxel data than there dimensions in
the transfer function, the extra components are ignored. If there are
more dimensions in the transfer function texture than the voxel data,
the extra dimensions in the transfer function are ignored (effectively
treating the voxel component data as a value of zero for the extra
dimension). This mapping locates the texel value in the texture, which
is then used as the output for this style.

[[t41_5]]
Table 41.5 — Transfer
function mapping from texture type to texture coordinate

[cols="^,,",options="header",]
|===
|Number of Texture Components |Texture Components |Transfer Function
Texture Coordinates
|1 |Luminance |S ← luminance (L)

|2 |Luminance Alpha |S, T ← luminance, alpha (LA)

|3 |RGB |S, T, R ← red, green, blue (RGB)

|4 |RGBA |S, T, R, Q ← red, green, blue, alpha (RGBA)
|===

 The colour value is treated like a normal texture with the colour
mapping as defined in <<t41_6, Table 41.6>>.

[[t41_6]]
Table 41.6 — Transfer
function mapping from texture type to output colour

[cols=",^,^,^,^",options="header",]
|===
|Texture Components |Red |Green |Blue |Alpha
|Luminance (L) |L |L |L |1
|Luminance Alpha (LA) |L |L |L |A
|RGB |R |G |B |1
|RGBA |R |G |B |A
|===

<<f-OpacityMapVolumeStyle, Figure 41.7>> shows a basic image of a
backpack on the left and an image of the backpack using
OpacityMapVolumeStyle on the right.

[[f-OpacityMapVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Backpack_Basic_Opacity.png[Backpack_Basic_Opacity,width=800,height=400]

Figure 41.7 — Default volume style on left and OpacityMapVolumeStyle on
right

[[ProjectionVolumeStyle]]
==== 41.4.8 ProjectionVolumeStyle

[source,node]
----
ProjectionVolumeStyle : X3DVolumeRenderStyleNode {
  SFBool   [in,out] enabled            TRUE
  SFNode   [in,out] metadata           NULL  [X3DMetadataObject]
  SFFloat  [in,out] intensityThreshold 0     [0,1]
  SFString [in,put] type               "MAX" ["MAX", "MIN", "AVERAGE"]
}
----

The ProjectionVolumeStyle volume style node uses the voxel data directly
to generate output colour based on the values of voxel data along the
viewing rays from the eye point.

If the value of type is `"MAX"`, The Maximum Intensity Projection
(MIP) algorithm is used to generate the output colour. This rendering
style also includes the option to use the extended form of Local Maximum
Intensity Projection (LMIP, see <<LMIP>>). The output colour
is determined by projecting rays into the voxel data from the viewer
location and finding the maximum voxel value found along that ray. If
the _intensityThreshold_ value is non-zero, rendering will use the first
maximum value encountered that exceeds the threshold rather than the
maximum found along the entire ray. <<f-LMIPThreshold, Figure 41.8>>
illustrates the difference in rendered value between LMIP and MIP.

[[f-LMIPThreshold]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/LMIP_threshold.png[Illustration of
LMIP versus MIP values]#

Figure 41.8 — Illustration of values selected when using MIP or LMIP
volume rendering styles

If the value of _type_ is `"MIN"`, Minimum Intensity Projection
is used. This works similar to Maximum Intensity Projection with the
difference that the minimum voxel value along the ray is used.

If the value of _type_ is `"AVERAGE"`, Average Intensity
Projection is used. In this case the average value of all voxels along
the ray is used as the output colour. The _intensityThreshold_ field is
ignored. This is a simple approximation of X-Ray.

Since the output of this node is a set of intensity values, all colour
components have the same value. The intensity is derived from the
average of all colour components of the voxel data (though typical usage
will only use single component textures). The Alpha channel is passed
through as-is from the underlying data. If there is no alpha channel
provided, a default alpha value of 1 is used.

<<f-ProjectionVolumeStyle, Figure 41.9>> shows a basic image of
ventricles of the brain on the left and an image of the ventricles of
the brain using MIP ProjectionVolumeStyle on the right.

[[f-ProjectionVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Ventricles_Basic_Projection.png[Ventricles_Basic_Projection.png,width=800,height=400]

Figure 41.9 — Default volume style on left and MIP ProjectionVolumeStyle
on right

[[SegmentedVolumeData]]
==== 41.4.9 SegmentedVolumeData

[source,node]
----
SegmentedVolumeData : X3DVolumeDataNode { 
  SFVec3f [in,out] dimensions         1 1 1    (0,∞)
  SFBool  [in out] bboxDisplay        FALSE
  SFNode  [in,out] metadata           NULL     [X3DMetadataObject]
  MFNode  [in,out] renderStyle        []       [X3DVolumeRenderStyleNode]
  MFBool  [in,out] segmentEnabled     []
  SFNode  [in,out] segmentIdentifiers NULL     [X3DTexture3DNode]
  SFBool  [in out] visible            TRUE
  SFNode  [in,out] voxels             NULL     [X3DTexture3DNode]
  SFVec3f []       bboxCenter         0 0 0    (-∞,∞)
  SFVec3f []       bboxSize           -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The SegmentedVolumeData node specifies a segmented volume data set that
allows for representation of different rendering styles for each segment
identifier.

The _renderStyle_ field optionally describes a particular rendering
style to be used. If this field has a non-zero number of values, the
defined rendering style is to be applied to the object. If the object is
segmented, the index of the segment shall look up the rendering style at
the given index in this array of values and apply that style to data
described by that segment identifier. If the _renderStyle_ field is not
specified, the implementation shall use an OpacityMapVolumeStyle node
(see <<OpacityMapVolumeStyle, 41.4.7 OpacityMapVolumeStyle>>) with
default values.

The _voxels_ field holds a 3D texture with the data for each voxel. For
each voxel, there is a corresponding segment identifier supplied in the
_segmentIdentifiers_ field, which contains a single component texture.
If the _segmentIdentifiers_ texture is not identical in size to the main
voxels, it shall be ignored. If it contains more than one colour
component, only the initial component of the colour shall be used to
define the segment identifier.

The _segmentEnabled_ field specifies whether a segment is rendered or
not. The indices of this array corresponds to the segment identifier. A
value at index _i_ of `FALSE` marks any data with the
corresponding segment identifier to not be rendered. If a segment
identifier is used that is greater than the length of the array, the
value is assumed to be `TRUE`.

<<f-SegmentedVolumeData, Figure 41.10>>  shows a segmented volume
image of ventricles of the brain using both OpacityMapVolumeStyle for
some segments ToneMappedVolumeStyle for the highlighted segments.

[[f-SegmentedVolumeData]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/segmented-opacTone_ventricles.png[Ventricles_Segmented_Opacity_Tone,width=400,height=400]

Figure 41.10 — Segmented volume data using OpacityMapVolumeStyle and
ToneMappedVolumeStyle

[[ShadedVolumeStyle]]
==== 41.4.10 ShadedVolumeStyle

[source,node]
----
ShadedVolumeStyle : X3DComposableVolumeRenderStyleNode {
  SFBool   [in,out] enabled        TRUE
  SFBool   [in,out] lighting       FALSE
  SFNode   [in,out] material       NULL                [X3DMaterialNode]
  SFNode   [in,out] metadata       NULL                [X3DMetadataObject]
  SFBool   [in,out] shadows        FALSE
  SFNode   [in,out] surfaceNormals NULL                [X3DTexture3DNode]
  SFString []       phaseFunction  "Henyey-Greenstein" ["Henyey-Greenstein","NONE",...]
}
----

The ShadedVolumeStyle node applies the Blinn-Phong illumination model
(<<BLINN>>, <<PHONG>>) to volume rendering. This
is similar to the model used for polygonal surfaces.

Colour and opacity is determined based on whether a value has been
specified for the _material_ field. If a _material_ field value is
provided, this voxel is considered to be lit using the lighting
equations below. If no _material_ field value is provided, O~c~ is used
as diffuse color in the same lighting equations and the specular and
ambient parts are ignored.

The _lighting_ field controls whether the rendering should calculate and
apply shading effects to the visual output. If lighting is enabled the
lighting equation is defined as:

____
C~g~ = I~Frgb~ × (1 -f~0~) +
        + f~0~ × (C~E rgb~ + SUM(on~i~ × attenuation~i~ × spot~i~ ×
I~Lrgb~ +
                                 × (ambient~i~ + diffuse~i~ + specular
~i~)))

O~g~ = O~v~ × O~m~
____

where:

____
attenuation~i~ = 1 / max(a~1~ + a~2~ × d~L~ + a~3~ × d~L~^²^ , 1) +
ambient~i~ = I~ia~ × C~Drgb~ × C~a +
~ +
diffuse~i~ = I~i~ × C~Drgb~ × ( *`+N+`* · *`+L+`*) +
specular ~i~ = I~i~ × C~Srgb~ × ( *`+N+`* · (( *`+L+`* + *`+V+`*) / |
*`+L+`* + **`+V+`**|))^shininess × 128^
____

and:

____
--
· = modified vector dot product: +
       if dot product < 0, then 0.0, otherwise, dot product +
a~1~ , a~2~, a~3~ = light i _attenuation_ +
d~V~ = distance from this voxel to viewer's position, in coordinate
system of current fog node +
d~L~ = distance from light to voxel, in light's coordinate system +
f~0~ = fog interpolant, see <<t17_5, Table 17.5>> for
calculation +
I~Frgb~ = currently bound fog's __color +
__I ~Lrgb~ = light i _color_ +
I~i~ = light i _intensity_ +
I~ia~ = light i _ambientIntensity +
_ *`+L+`* = (<<PointLight>>/<<SpotLight>>)
normalized vector from this voxel to light source i position +
*`+L+`* = (<<DirectionalLight>>) -direction of light
source i +
*`+N+`* = normalized normal vector at this voxel (interpolated from
vertex normals specified by the _surfaceNormals_ field or automatically
calculated. +
O~m~ = (1 - _X3DMaterialNode_ transparency) if material specified, 1
otherwise +
C~a~ = _<<X3DMaterialNode>>_ _ambientIntensity_ if
material specified, 0 otherwise +
C~Drgb~ = diffuse colour, from a node derived from _X3DMaterialNode_ if
specified, O~c~ otherwise +
C~Ergb~ = _X3DMaterialNode_ _emissiveColor_ if material specified,
RGB(0,0,0) otherwise +
C~Srgb~ = _X3DMaterialNode_ _specularColor_ if material specified,
RGB(0,0,0) otherwise +
on ~i~ = 1, if light source i affects this voxel, +
         0, if light source i does not affect this voxel.

____
The following conditions indicate that light source i does not affect
this voxel:

. if the voxel is farther away than _radius_ for PointLight or
SpotLight;
. if the volume is outside the enclosing
_<<X3DGroupingNode>>_ and/or if the _on_ field is
`FALSE;`
. if the _lighting_ field of this volume is `FALSE`.
____

shininess = _X3DMaterialNode_ _shininess_ if material specified, 0
otherwise +
spotAngle = arccosine( *`+-L+`* · *`+spotDir+`*~i~) +
spot ~BW~ = SpotLight i beamWidth +
spot ~CO~ = SpotLight i _cutOffAngle_ +
spot ~i~ = spotlight factor, see <<t17_4, Table 17.4>> for
calculation +
*`+spotDir+`*~i~ = normalized SpotLight i _direction_ +
SUM: sum over all light sources i +
*`+V+`* = normalized vector from the voxel to viewer's position

--
____

If the _lighting_ field is `FALSE`, the diffuse color is used
without any shading effects.

____
C~g~ = C~D rgb~

O~g~ = O~v~ × O~m~
____

The _surfaceNormals_ field contains a 3D texture with at least three
component values. Each voxel in the texture represents the surface
normal direction for the corresponding voxel in the base data source.
This texture should be identical in dimensions to the source data. If
not, the implementation may interpolate or average between adjacent
voxels to determine the average normal at the voxel required. If this
field is empty, the implementation shall automatically determine the
surface normal using algorithmic means.

The _shadows_ field controls whether the rendering should calculate and
apply shadows to the visual output (using global illumination model). A
value of `FALSE` requires that no shadowing be applied. A value
of `TRUE` requires that shadows be applied to the object. If the
_lighting_ field is set to  `FALSE`, this field shall be ignored
and no shadows generated.

The _phaseFunction_ field is used to define the scattering model for use
in an implementation using global illumination. The name defines the
model type, based on standard algorithms externally defined to this
document . The valid values are "NONE"(which means no scattering) and
"Henyey-Greenstein" which is the Henyey-Greenstein phase function
defined in <<%5BHENYEY%5D, HENYEY>>. Browsers may choose to support
other values. If a value is specified that is not supported by the X3D
browser, "Henyey-Greenstein" shall be used.

<<f-ShadedVolumeStyle, Figure 41.11>> shows a basic image of a human
brain on the left and an image of the human brain using
ShadedVolumeStyle on the right.

[[f-ShadedVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Brain_Basic_Shaded.png[Brain_Basic_Shaded.png,width=800,height=352]

Figure 41.11 — Default volume style on left and ShadedVolumeStyle on
right

[[SilhouetteEnhancementVolumeStyle]]
==== 41.4.11 SilhouetteEnhancementVolumeStyle

[source,node]
----
SilhouetteEnhancementVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFBool  [in,out] enabled                   TRUE
  SFNode  [in,out] metadata                  NULL [X3DMetadataObject]
  SFFloat [in,out] silhouetteBoundaryOpacity 0    [0,1]
  SFFloat [in,out] silhouetteRetainedOpacity 1    [0,1]
  SFFloat [in,out] silhouetteSharpness       0.5  [0,∞)
  SFNode  [in,out] surfaceNormals            NULL [X3DTexture3DNode]
}
----

The SilhouetteEnhancementVolumeStyle specifies that the associated
volumetric data shall be rendered with silhouette enhancement.
Enhancement of the basic volume is provided by darkening voxels based on
their orientation relative to the view direction. This orientation is
determined by the _surfaceNormals_ value corresponding to each voxel.
Perpendicular voxels are coloured according to the _edgeColor_ while
parallel voxels are not changed at all. A threshold can be set where the
proportion of how close to perpendicular the direction shall be before
the values are made more opaque:

____
O~g~ = O~v~ × (k~sc~ + k~ss~(1 - | *n* . **V**|) ^ k~se~)
____

where

* O~g~ is the computed opacity of the voxel
* O~v~ is the original opacity of the voxel
* *n* is the surface normal
* *V* is the view vector
* k~sc~ controls the scaling of non-silhouette regions (
_silhouetteRetainedOpacity_)
* k~ss~ is the amount of the silhouette enhancement to use (
_silhouetteBoundaryOpacity_)
* k~se~ is a power function to control the sharpness of the silhouette.
( _silhouetteSharpness_)

The _surfaceNormals_ field contains a 3D texture with at least three
component values. Each voxel in the texture represents the surface
normal direction for the corresponding voxel in the base data source.
This texture should be identical in dimensions to the source data. If
not, the implementation may interpolate or average between adjacent
voxels to determine the average normal at the voxel required. If this
field is empty, the implementation shall automatically determine the
surface normal using algorithmic means.

<<f-SilhouetteEnhancementVolumeStyle, Figure 41.12>> shows a basic
image of a skull on the left and an image of the skull using
SilhouetteEnhancementVolumeStyle on the right.

[[f-SilhouetteEnhancementVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Skull_Basic_Silhouette.png[Skull_Basic_Silhouette,width=797,height=400]

Figure 41.12 — Default volume style on left and
SilhouetteEnhancementVolumeStyle on right

[[ToneMappedVolumeStyle]]
==== 41.4.12 ToneMappedVolumeStyle

[source,node]
----
ToneMappedVolumeStyle : X3DComposableVolumeRenderStyleNode { 
  SFColorRGBA [in,out] coolColor      0 0 1 0 [0,1]
  SFBool      [in,out] enabled        TRUE
  SFNode      [in,out] metadata       NULL    [X3DMetadataObject]
  SFNode      [in,out] surfaceNormals NULL    [X3DTexture3DNode]
  SFColorRGBA [in,out] warmColor      1 1 0 0 [0,1]
}
----

The ToneMappedVolumeStyle node specifies that the associated volumetric
data is to be rendered using the Gooch shading model of two-toned
warm/cool colouring (see <<GOOCH1>>,
<<GOOCH2>>). Two colours are defined, a warm colour and a
cool colour. The renderer shades between them based on the orientation
of the voxel relative to the user. This is not the same as the basic
isosurface shading and lighting. The following colour formula is used:

____
cc = (1 + *L*~i~ . *n*) × 0.5 +
C~g~ = Σ ~(all i)~ (cc × warmColor + (1 - cc) × coolColor)
____

where

* *L*~i~ is the vector to light source i
* *n* is the surface normal
* C~g~ is the resulting colour that is to be used to represent the voxel

The _warmColor_ and _coolColor_ fields specify the two colours to be
used at the limits of the spectrum. The _warmColor_ field is used for
surfaces facing towards the light, while the _coolColor_ is used for
surfaces facing away from the light direction.

The _surfaceNormals_ field contains a 3D texture with at least three
component values. Each voxel in the texture represents the surface
normal direction for the corresponding voxel in the base data source.
This texture should be identical in dimensions to the source data. If
not, the implementation may interpolate or average between adjacent
voxels to determine the average normal at the voxel required. If this
field is empty, the implementation shall automatically determine the
surface normal using algorithmic means.

The final output colour is determined by combining the interpolated
colour value C~g~ with the opacity of the corresponding voxel. Colour
components of the voxel are ignored.

<<f-ToneMappedVolumeStyle, Figure 41.13>> shows a basic image of
ventricles of the brain on the left and an image of the ventricles of
the brain using ToneMappedVolumeStyle on the right.

[[f-ToneMappedVolumeStyle]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Ventricles_Basic_Tonemapped.png[Ventricles_Basic_Tonemapped.png,width=800,height=400]

Figure 41.13 — Default volume style on left and ToneMappedVolumeStyle on
right

[[VolumeData]]
==== 41.4.13 VolumeData

[source,node]
----
VolumeData : X3DVolumeDataNode { 
  SFVec3f [in,out] dimensions      1 1 1    (0,∞)
  SFBool  [in out] bboxDisplay     FALSE
  SFNode  [in,out] metadata        NULL     [X3DMetadataObject]
  SFNode  [in,out] renderStyle     NULL     [X3DVolumeRenderStyleNode]
  SFNode  [in,out] voxels          NULL     [X3DTexture3DNode]
  SFBool  [in out] visible         TRUE
  SFVec3f []       bboxCenter      0 0 0    (-∞,∞)
  SFVec3f []       bboxSize        -1 -1 -1 [0,∞) or -1 -1 -1
}
----

The VolumeData node specifies a simple non-segmented volume data set
that uses a single rendering style node for the complete volume.

The _renderStyle_ field allows the user to specify a single specific
rendering technique to be used on this volumetric object. If the
_renderStyle_ field is not specified, the implementation shall use an
OpacityMapVolumeStyle node (see <<OpacityMapVolumeStyle, 41.4.7 OpacityMapVolumeStyle>>) with default values.

The _voxels_ field provides the raw voxel information to be used by the
corresponding rendering styles. The value is any _X3DTexture3DNode_ type
and may have any number of colour components defined. The specific
interpretation for the values at each voxel shall be defined by the
value of the _renderStyle_ field.

<<f-VolumeData, Figure 41.14>>  shows a basic volume image of a
backpack using the default rendering style.

[[f-VolumeData]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/Backpack_Default.png[Backpack_Default.png,width=400,height=397]

Figure 41.14 — Volume data using default volume style

[[S41.5_SupportLevels]]
=== 41.5 Support levels

The Volume Rendering component provides three levels of support as
specified in <<t41_7, Table 41.7>>.

[[t41_7]]
*Table 41.7 — Volume rendering component support
levels*

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 |  | 

|  |  |_X3DComposableVolumeRenderStyleNode_ |n/a

|  |  |_X3DVolumeRenderStyleNode_ |n/a

|  |  |_X3DVolumeDataNode_ |n/a

|  |  |OpacityMapVolumeStyle |Only 2D texture transfer functions need be
supported. All other fields fully supported.

|  |  |VolumeData |All fields fully supported.

|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 |  | 

|  |  |All Level 1 nodes |All fields fully supported.

|  |  |BoundaryEnhancementVolumeStyle |All fields fully supported.

|  |  |ComposedVolumeStyle |All fields fully supported.

|  |  |EdgeEnhancementVolumeStyle |All fields fully supported.

|  |  |IsoSurfaceVolumeData |All fields fully supported.

|  |  |OpacityMapVolumeStyle |All fields fully supported. 3D transfer
functions shall be supported.

|  |  |ProjectionVolumeStyle |All fields fully supported

|  |  |SegmentedVolumeData |All fields fully supported.

|  |  |SilhouetteEnhancementVolumeStyle |All fields fully supported.

|  |  |ToneMappedVolumeStyle |All fields fully supported.

|*3* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 |  | 

|  |  |All Level 2 nodes |All fields fully supported.

|  |  |BlendedVolumeStyle |All fields fully supported.

|  |  |CartoonVolumeStyle |All fields fully supported.

|  |  |ComposedVolumeStyle |All fields fully supported.

|  |  |ShadedVolumeStyle |All fields fully supported except shadows.
Shadows supported with at least Phong shading.

|*4* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 |  | 

|  |  |All Level 3 nodes |All fields fully supported.

|  |  |ShadedVolumeStyle |All fields fully supported with at least Phong
shading and  Henyey-Greenstein phase function. Shadows fully supported.
|===

[[textureProjection_html]]
== 42 texture projection component

[[S42_Introduction]]
=== 42.1 Introduction

[[S42_Name]]
==== 42.1.1 Name

The name of this component is "TextureProjection". This name shall be
used when referring to this component in the COMPONENT statement (see
<<COMPONENTStatement, 7.2.5.4 Component statement>>).

[[S42_Overview]]
==== 42.1.2 Overview

This clause describes the Texture projection component of this document.
This includes how texture projections are specified and how they are
positioned on the 3D scene. <<t42_1, Table 42.1>> provides links to
the major topics in this clause.

[[t42_1]]
Table 42.1 — Topics

* <<S42Introduction, 42.1 Introduction>>
** <<S42_Name, 42.1.1 Name>>
** <<S42_Overview, 42.1.2 Overview>>
* <<S42_Concepts, 42.2 Concepts>>
** <<S42_ConceptsOverview, 42.2.1 Overview>>
** <<Projectivetextureconcepts, 42.2.2 Texture projector concepts>>
** <<S42_Texturemapimageformats, 42.2.3 Texture map image formats>>
* <<X3DTextureProjectorNode, 42.3 Abstract types>>
** <<X3DTextureProjectorNode, 42.3.1 _X3DTextureProjectorNode_>>
* <<S42_NodeReference, 42.4 Node reference>>
** <<TextureProjector, 42.4.1 TextureProjector>>
** <<TextureProjectorParallel, 42.4.2 TextureProjectorParallel>>
* <<S42_NodeReference, 42.5 Support levels>>

* <<f-PTMapConcept, Figure 42.1 — Concept of texture projection>>
* <<f-3DTexture-terrain, Figure 42.2 — Application of texture projection for reconstructing a 3D terrain>>
* <<f-3DTexture-endoscope, Figure 42.3 — Application of texture projection for reconstructing an endoscope 3D model>>
* <<f-ParallelTexture, Figure 42.4 — Description of 3D parallel texture projection>>
* <<f-PerspectiveTexture, Figure 42.5 — Description of 3D perspective texture projection>>

* <<t42_1, Table 42.1 — Topics>>
* <<t42_2, Table 42.2 — Support levels>>




[[S42_Concepts]]
=== 42.2 Concepts

[[S42_ConceptsOverview]]
==== 42.2.1 Overview

This component provides additional texturing extensions to the basic
capabilities defined in X3D. Generally, 2D and 3D texture projection has
been used to enhance the quality of an image generated with a camera or
to speed up the generation of an image with respect to a given scene
including several geometric models. However, there are some constraints
for projecting the region and shape of textures over objects. As an
extension of texture projection, the texture image can be projected onto
a 3D scene within the projection volume which is constructed from
projection parameters such as a projection point, a projection direction
and a projection aspect ratio. <<f-PTMapConcept, Figure 42.1>> shows
an example screen shot by applying texture projection to a 3D virtual
scene.

[[f-PTMapConcept]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ptm_concept.png[Description of
Projective texture map,width=500,height=300]

Figure 42.1 — Concept of texture projection

This texture projection is essential for enhanced rendering effects in a
3D scene such as rendering of projected images, visualization of a
terrain surface in GIS applications, and medical visualization.

[[TextureProjectorConcepts]]
==== 42.2.2 Texture projector concepts

The texture projection allows a texture image to be projected onto a 3D
virtual scene inside the projection volume visible from a specific
position called a projection point. The projection volume is determined
by projection parameters depending on two types: parallel and
perspective projections. In a parallel projection, the parallel volume
is a parallelepiped. In a perspective projection, the projection volume
is a rectangular frustum.

The parallel projection can be distinguished into orthographic and
oblique according to the defined projection direction. If all the
projection lines are orthogonal to the projection plane, the projection
is called an orthographic projection. All the projection lines in
oblique projection intersect the projection plane at an oblique angle.
In order to describe the types of parallel projection, the projection
point and projection direction are given as a point and a vector,
respectively. The projection volume in parallel projection can be
defined as a parallelepiped.

The perspective projection can be defined as a field of view angle from
a projection point, an aspect ratio based on width and height, plus near
and far planes. In texture projection generally, a single texture as
well as several texture images can be projected onto a scene in a 3D
virtual world. Furthermore, multiple texture projections can be
performed over a common scene with specific objectives such as
photogrammetry or reconstruction of endoscope images. As shown in
<<f-3DTexture-terrain, Figure 42.2>>, assume that several images are
provided, each of which is taken with a different camera. Construction
of a terrain surface from those images can be performed by displaying
overlapping images obtained after applying several projected textures to
the surface model.

[[f-3DTexture-terrain]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ptmexample1.png[Description of 3D texture,width=500,height=300]

Figure 42.2 — Application of perspective texture projection for
reconstructing a 3D terrain

<<f-3DTexture-endoscope, Figure 42.3>> describes an example for
reconstructing endoscope images over a cylinder by applying texture
projection. In a similar manner, each image is captured from an
endoscope with perspective view information inside a human body.

[[f-3DTexture-endoscope]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ptmexample2.png[Description of 3D texture,width=500,height=300]

Figure 42.3 — Application of perspective texture projection for
reconstructing an endoscope 3D model.

[[S42_Texturemapimageformats]]
==== 42.2.3 Image formats for texture projection

Node types specifying images for texture projection may supply data with
a number of color components between one and four. The valid types and
interpretations of 3D textures are identical to that for 2D textures.
The definition of texture formats is defined in
<<TextureMapFormats, 18.2.1 Texture map formats>>.


=== 42.3 Abstract types

[[X3DTextureProjectorNode]]
==== 42.3.1 _X3DTextureProjectorNode_

[source,node]
----
X3DTextureProjectorNode : X3DLightNode {
  SFFloat  [in,out] ambientIntensity 0      [0,1]
  SFColor  [in,out] color            1 1 1  [0,1]
  SFString [in,out] description      ""
  SFVec3f  [in,out] direction        0 0 1  (-∞,∞)
  SFFloat  [in,out] farDistance      -1     -1 or (0,∞)
  SFBool   [in,out] global           TRUE
  SFFloat  [in,out] intensity        1      [0,∞)
  SFVec3f  [in,out] location         0 0 0  (-∞,∞)
  SFNode   [in,out] metadata         NULL   [X3DMetadataObject]
  SFFloat  [in,out] nearDistance     -1     -1 or (0,∞)
  SFBool   [in,out] on               TRUE
  SFBool   [in,out] shadows          FALSE
  SFFloat  [in,out] shadowIntensity  1      [0,1]
  SFNode   [in,out] texture          NULL   [X3DTexture2DNode]
  SFFloat  [out]    aspectRatio             (0,∞)
}
----

This abstract node type is the base type for all node types that specify
texture projection.

The _aspectRatio_ field is the ratio of image width and height that is
projected.

The _description_ field of this node tells the name of the projector,
and makes the division of different projectors possible.

The _direction_ is the way the projector is heading, and this implies
projection direction.

Each texture projection type defines a _global_ field that determines
whether the texture projection is global or scoped. Global texture
projection performs the texture projections for all objects that fall
within their volume of texture projection influence. Scoped texture
projection only performs the texture projections for objects that are in
the same transformation hierarchy as the texture projection; _i.e._,
only the children and descendants of its enclosing parent group are
illuminated.

The _location_ shows the position of the projector, and this implies
projection point.

The _nearDistance_ and _farDistance_ are the minimum and maximum
distance traveled, respectively, for a projected texture that is shown
on the screen. A default value of -1 for _nearDistance_ or _farDistance_
means that the field has no effect on currently active projection
boundaries.

The _on_ field specifies whether the texture projection is performed or
not. If _on_ is `TRUE`, the texture projection is performed for
geometry objects in the scene. If _on_ is `FALSE`, the texture
projection is not performed for any geometry in the scene.

The _ambientIntensity_, _color_, _global_, _global_, _intensity_, _on_,
_shadows_, _shadowIntensity_, and _texture_ fields are defined in
<<X3DLightingNode>>.

See <<texturing_html, 18 Texturing component>> for a general
description of the _<<X3DTexture2DNode>>_ abstract
type and interpretation of rendering for 2D images.


=== 42.4 Node reference

[[TextureProjector]]
==== 42.4.1 TextureProjector

[source,node]
----
 TextureProjector : X3DTextureProjectorNode {
  SFFloat  [in,out] ambientIntensity 0      [0,1]
  SFColor  [in,out] color            1 1 1  [0,1]
  SFString [in,out] description      ""
  SFVec3f  [in,out] direction        0 0 1  (-∞,∞)
  SFFloat  [in,out] farDistance      -1     -1 or (0,∞)
  SFFloat  [in,out] fieldOfView      π/4    (0,π)
  SFBool   [in,out] global           TRUE
  SFFloat  [in,out] intensity        1      [0,∞)
  SFVec3f  [in,out] location         0 0 0  (-∞,∞)
  SFNode   [in,out] metadata         NULL   [X3DMetadataObject]
  SFFloat  [in,out] nearDistance     -1     -1 or (0,∞)
  SFBool   [in,out] on               TRUE
  SFBool   [in,out] shadows          FALSE
  SFFloat  [in,out] shadowIntensity  1      [0,1]
  SFNode   [in,out] texture          NULL   [X3DTexture2DNode]
  SFVec3f  [in,out] upVector         0 0 1
  SFFloat  [out]    aspectRatio             (0,∞)
}
----

TextureProjector is a light that projects a texture into the scene,
applying the projected texture to any geometry that intersects the
perspective projection volume.

Perspective texture projection is shown in
<<f-PerspectiveTexture, Figure 42.5>>.

[[f-PerspectiveTexture]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ptmperspective.png[Description of perspective texture projection,width=500,height=300]

Figure 42.5 — Description of 3D perspective texture projection

The _aspectRatio_ is the aspect ratio of the width and length which
refers to perspective projection spect ratio.

The _description_ field of this node tells the name of the perspective
projector, and makes the division of different perspective projectors
possible.

The _direction_ is the way the perspective projector is heading, and
this implies to perspective projection direction.

The _fieldOfView_ is the extent of the observable texture that is seen
on the perspective display at any given moment. This value may change
depending on the aspect ratio of the rendering resolution. The default
value of this field is π/4.

The _location_ shows the position of the perspective projector, and this
implies perspective projection point.

The _nearDistance_ and _farDistance_ is the minimum and maximum distance
that is shown on the screen, respectively.

The _upVector_ describes the roll of the camera by saying which point is
"up" in the camera's orientation. The default value of this field is (0
0 1).

EXAMPLE:  TextureProjector

[source]
....
TextureProjector {
  description "Project a red delicious texture"
  direction -1 0 -1
  farDistance 10
  fieldOfView 0.26
  global TRUE
  location 3 3 3
  nearDistance 1
  on TRUE
  upVector 0 1 0
  texture ImageTexture {
    url [ "image/Red_Delicious.jpg" ]
  }
}
....

[[TextureProjectorParallel]]
==== 42.4.2 TextureProjectorParallel

[source,node]
----
TextureProjectorParallel : X3DTextureProjectorNode {
  SFFloat  [in,out] ambientIntensity 0         [0,1]
  SFColor  [in,out] color            1 1 1     [0,1]
  SFString [in,out] description      ""
  SFVec3f  [in,out] direction        0 0 1     (-∞,∞)
  SFFloat  [in,out] farDistance      -1        -1 or (0,∞)
  SFVec4f  [in,out] fieldOfView      -1 -1 1 1 (-∞,∞)
  SFBool   [in,out] global           TRUE
  SFFloat  [in,out] intensity        1         [0,∞)
  SFVec3f  [in,out] location         0 0 0     (-∞,∞)
  SFNode   [in,out] metadata         NULL      [X3DMetadataObject]
  SFFloat  [in,out] nearDistance     -1        -1 or (0,∞)
  SFBool   [in,out] on               TRUE
  SFBool   [in,out] shadows          FALSE
  SFFloat  [in,out] shadowsIntensity 1         [0,1]
  SFNode   [in,out] texture          NULL      [X3DTexture2DNode]
  SFFloat  [out]    aspectRatio                (0,∞)
}
----

TextureProjectorParallel is a light that projects a texture into the
scene, applying the projected texture to any geometry that intersects
the parallel projection volume.

Parallel texture projection is shown in <<f-ParallelTexture, Figure 42.4>>.

[[f-ParallelTexture]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/ptmparallel.png[Description of parallel texture projection,width=500,height=300]

Figure 42.4 — Description of 3D parallel texture projection

The _description_ field of this node tells the name of the perspective
projector, and makes the division of different perspective projectors
possible.

The _location_ shows the position of the perspective projector, and this
implies perspective projection point.

The _direction_ is the way the perspective projector is heading, and
this implies to perspective projection direction.

The _fieldOfView_ is the extent of the observable texture that is seen
on the parallel display at any given moment. This value may change
depending on the aspect ratio of the rendering resolution. The default
value of this field is (-1 -1 1 1).

The _aspectRatio_ is the aspect ratio of the width and length which
refers to perspective projection spect ratio.

The _nearDistance_ and _farDistance_ is the minimum and maximum distance
that is shown on the screen, respectively.

_global_, _on_ and _texture_ fields are the same as illustrated in the
Abstract node.

[[S42.5_SupportLevels]]
=== 42.5 Support levels

The Texture projection component defines levels of support as specified
in <<t42_2, Table 42.2>>.

[[t42_2]]
Table 42.2 — Texture projection component support levels

[width="100%",cols="^25%,25%,25%,25%",options="header",]
|===
|Level |Prerequisites |Nodes/Features |Support
|*1* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 | |
| | |_X3DTextureProjectorNode_ |n/a
| | |TextureProjector |All fields fully supported.
|*2* |Core 1 +
Grouping 1 +
Shape 1 +
Rendering 1 +
Texturing 1 | |
| | |TextureProjectorParallel |All fields fully supported.
|===

[[coreprofile_html]]
== Annex A Core profile (normative)

[[A.1_General]]
=== A.1 General

This annex defines the X3D components which comprise the Core profile.
This includes not only the nodes which shall be supported but also which
fields in the supported nodes may be ignored.

The name of this profile is "Core". This profile is targeted towards:

[loweralpha]
. Absolute minimal file definitions required by X3D,
. Building minimally defined scenes by explicitly specifying the
component and levels required, and
. Allowing a broader range of implementations by eliminating some
complexity of a complete X3D implementation.

[[A.2_Topics]]
=== A.2 Topics

<<tA_1, Table A.1>> provides links to the major topics in this annex.

[[tA_1]]
Table A.1 — Topics

* <<A.1_General, A.1 General>>
* <<A.2_Topics, A.2 Topics>>
* <<A.3_ComponentSupport, A.3 Component support>>
* <<A.4_ConformanceCriteria, A.4 Conformance criteria>>
* <<A.5_NodeSet, A.5 Node set>>
* <<A.6_OtherLimitations, A.6 Other limitations>>

* <<tA_1, Table A.1 — Topics>>
* <<tA_2, Table A.2 — Components and levels>>
* <<tA_3, Table A.3 — Nodes for conforming to the Core profile>>
* <<tA_4, Table A.4 — Other limitations>>


[[A.3_ComponentSupport]]
=== A.3 Component support

<<tA_2, Table A.2>> lists the components and their
levels which shall be supported in the Core profile. Tables A.2 and A.3
describe limitations on required support for nodes and fields contained
within these components.

[[tA_2]]
Table A.2 — Components and levels

[cols=",,",options="header",]
|===
|Component |Level |Reference
|Core |1 |<<S7_SupportLevels, 7.5 Support levels>>
|===

[[A.4_ConformanceCriteria]]
=== A.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tA_2, Table A.2>>.

In <<tA_3, Table A.3>> and <<tA_4, Table A.4>>, the first column defines 
the item for which conformance is being defined. In some cases, general 
limits are defined but are later overridden in specific cases by more
restrictive limits. The second column defines the requirements for a X3D
file conforming to the Core profile; if a X3D file contains any items
that exceed these limits, it may not be possible for a X3D browser
conforming to the Core profile to successfully parse that X3D file. The
third column defines the minimum complexity for a X3D scene that a X3D
browser conforming to the Core profile shall be able to present to the
user. Fields flagged as "not supported" may be supported by X3D browsers
which conform to the Core profile. The word "ignore" in the minimum X3D
browser support column refers only to the display of the item; in
particular, _set__ events to ignored inputOutput fields shall still
generate corresponding __changed_ events.

[[A.5_NodeSet]]
=== A.5 Node set

<<tA_3, Table A.3>> lists the nodes which
shall be supported in the Core profile and specifies any fields in these
nodes for which this profile requires less than full support.

[[tA_3]]
Table A.3 — Nodes for conforming
to the Core profile

[cols=",,",options="header",]
|===
|Item            |X3D File Limit   |Minimum X3D browser Support
|MetadataBoolean |No restrictions. |Full support.
|MetadataDouble  |No restrictions. |Full support.
|MetadataFloat   |No restrictions. |Full support.
|MetadataInteger |No restrictions. |Full support.
|MetadataSet     |No restrictions. |Full support.
|MetadataString  |No restrictions. |Full support.
|===

[[A.6_OtherLimitations]]
=== A.6 Other limitations

<<tA_4, Table A.4>> specifies other aspects of X3D
functionality which are supported by this profile. Note that general
items refer only to those specific nodes listed in
<<tA_3, Table A.3>>.

[[tA_4]]
Table A.4 — Other limitations

[cols=",,",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|All groups  |500 children. |500 children. _bboxCenter_ and _bboxSize_
optionally supported.
|All interpolators |1000 key-value pairs. |1000 key-value pairs.
|All lights  |8 simultaneous lights. |8 simultaneous lights.
|Names for DEF/field |50 utf8 octets. |50 utf8 octets.
|SFBool      |No restrictions. |Full support.
|SFColor     |No restrictions. |Full support.
|SFColorRGBA |No restrictions. |Full support.
|SFDouble    |Mp restrictions. |Full support. Range ±1e±12. Precision 1e-7.
|SFFloat     |No restrictions. |Full support.
|SFImage     |256 width. 256 height. |256 width. 256 height.
|SFInt32     |No restrictions. |Full support.
|SFNode      |No restrictions. |Full support.
|SFRotation  |No restrictions. |Full support.
|SFString    |30,000 utf8 octets. |30,000 utf8 octets.
|SFTime      |No restrictions. |Full support.
|SFVec2d     |15,000 values.   |15,000 values.
|SFVec2f     |15,000 values.   |15,000 values.
|SFVec3d     |15,000 values.   |15,000 values.
|SFVec3f     |15,000 values.   |15,000 values.
|MFColor     |15,000 values.   |15,000 values.
|MFColorRGBA |15,000 values.   |15,000 values.
|MFDouble    |1000 values.     |1000 values.
|MFFloat     |1,000 values.    |1,000 values.
|MFImage     |No restrictions. |Full support.
|MFInt32     |20,000 values.   |20,000 values.
|MFNode      |500 values.      |500 values.
|MFRotation  |1,000 values.    |1,000 values.
|MFString    |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.
|MFTime      |1,000 values.    |1,000 values.
|MFVec2d     |15,000 values.   |15,000 values.
|MFVec2f     |15,000 values.   |15,000 values.
|MFVec3d     |15,000 values.   |15,000 values.
|MFVec3f     |15,000 values.   |15,000 values.
|===

[[interchange_html]]
== Annex B Interchange profile (normative)

[[B.1_General]]
=== B.1 General

This annex defines the X3D components that comprise the Interchange
profile. This includes not only the nodes that shall be supported but
also which fields in the supported nodes may be ignored.

The name of this profile is "Interchange". This profile is targeted
towards:

* Exchange of geometry and animations between authoring systems,
* Possible implementation in a low-footprint engine requiring no
interaction (EXAMPLE  an applet or small X3D browser
plug-in),
* Addressing the limitations of software renders not capable of dealing
with all details of the full X3D lighting model, and
* Allowing a broader range of implementations by eliminating some
complexity of a complete X3D implementation.

[[B.2_Topics]]
=== B.2 Topics

<<tB_1, Table B.1>> provides links to the major topics in this annex.

[[tB_1]]
Table B.1 — Topics

* <<B.1_General, B.1 General>>
* <<B.2_Topics, B.2 Topics in this annex>>
* <<B.3_ComponentSupport, B.3 Component support>>
* <<B.4_ConformanceCriteria, B.4 Conformance criteria>>
* <<B.5_NodeSet, B.5 Node set>>
* <<B.6_OtherLimitations, B.6 Other limitations>>

* <<tB_1, Table B.1 — Topics>>
* <<tB_2, Table B.2 — Components and levels>>
* <<tB_3, Table B.3 — Nodes for conforming to the Interchange profile>>
* <<tB_4, Table B.4 — Other limitations>>


[[B.3_ComponentSupport]]
=== B.3 Component support

<<tB_2, Table B.2>> lists the components and their
levels which shall be supported in the Interchange profile. Tables B.2
and B.3 describe limitations on required support for nodes and fields
contained within these components.

[[tB_2]]
Table B.2 — Components and levels

[cols=",,",options="header",]
|===
|Component     |Level |Reference
|Core          |1     |<<S7_SupportLevels, 7.5 Support levels>>
|Time          |1     |<<S8_SupportLevels, 8.5 Support levels>>
|Networking    |1     |<<S9_SupportLevels, 9.5 Support levels>>
|Grouping      |1     |<<S10_SupportLevels, 10.5 Support levels>>
|Rendering     |3     |<<S11_SupportLevels, 11.5 Support levels>>
|Shape         |1     |<<S12_SupportLevels, 12.5 Support levels>>
|Geometry3D    |2     |<<S13_SupportLevels, 13.4 Support levels>>
|Lighting      |1     |<<S17_SupportLevels, 17.5 Support levels>>
|Texturing     |2     |<<S18_SupportLevels, 18.5 Support levels>>
|Interpolation |2     |<<S19_SupportLevels, 19.5 Support levels>>
|Navigation    |1     |<<S23_SupportLevels, 23.4 Support levels>>
|Environmental effects |1 |<<S24_SupportLevels, 24.5 Support levels>>
|===

[[B.4_ConformanceCriteria]]
=== B.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tB_2, Table B.2>>.

In Tables B.3 and B.4, the first column defines the item for which
conformance is being defined. In some cases, general limits are defined
but are later overridden in specific cases by more restrictive limits.
The second column defines the requirements for a X3D file conforming to
the Interchange profile; if a X3D file contains any items that exceed
these limits, it may not be possible for a X3D browser conforming to the
Interchange profile to successfully parse that X3D file. The third
column defines the minimum complexity for a X3D scene that a X3D browser
conforming to the Interchange profile shall be able to present to the
user. Fields flagged as "not supported" may be supported by X3D browsers
which conform to the Interchange profile. The word "ignore" in the
minimum X3D browser support column refers only to the display of the
item; in particular, _set__ events to ignored inputOutput fields shall
still generate corresponding __changed_ events.

[[B.5_NodeSet]]
=== B.5 Node set

<<tB_3, Table B.3>> lists the
nodes which shall be supported in the Interchange profile and specifies
any fields in these nodes for which this profile requires less than full
support.

[[tB_3]]
Table B.3 — Nodes for conforming to the Interchange profile

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|Appearance |No restrictions. |_textureTransform_ optionally
supported. +
_lineProperties_ not supported. _fillProperties_ not supported.

|Background |No restrictions. |_groundAngle_ and _groundColor_
optionally supported. _backURL_, _frontURL_, _leftURL_, _rightURL_,
_topURL_ optionally supported. _skyAngle_ optionally supported. One
_skyColor_.

|Box |No restrictions. |Full support.

|Color |15,000 colours. |15,000 colours.

|ColorInterpolator |Restrictions as for all interpolators. |Full support
except as for all interpolators.

|ColorRGBA |15,000 colours. |15,000 colours. Alpha component optionally
supported.

|Cone |No restrictions. |Full support.

|Coordinate |65,535 points |65,535 points.

|CoordinateInterpolator |15,000 coordinates per _keyValue_. Restrictions
as for all interpolators. |15,000 coordinates per _keyValue_. Support as
for all interpolators.

|Cylinder |No restrictions. |Full support.

|DirectionalLight |No restrictions. |Not scoped by parent Group or
Transform.

|Group |Restrictions as for all groups. |_addChildren_ optionally
supported. _removeChildren_ optionally supported. Otherwise as for all
groups.

|ImageTexture |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format. |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format.

|IndexedFaceSet |10 vertices per face. 5000 faces. Less than 65,535
indices. a|
_ccw_ optionally supported. _set_colorIndex_ optionally supported.
_set_normalIndex_ optionally supported. _normal_ optionally supported.
Only convex indexed face sets supported. Hence, _convex_ optionally
supported. For _creaseAngle_, only 0 and π radians supported
(or the equivalent if a different angle base unit has been specified).
10 vertices per face. 5000 faces. 65,535 indices in any index field.

Face list shall be well-defined as follows:

. Each face is terminated with -1, including the last face in the array.
. Each face contains at least three non-coincident vertices.
. A given _coordIndex_ is not repeated in a face.
. The vertices of a face shall define a planar polygon.
. The vertices of a face shall not define a self-intersecting polygon.

|IndexedLineSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedTriangleFanSet |5,000 total faces. 15,000 indices in any index
field. |5,000 total faces. 15,000 indices in any index field.

|IndexedTriangleSet |5,000 total faces. 15,000 indices in any index
field. |5,000 total faces. 15,000 indices in any index field.

|IndexedTriangleStripSet |5,000 total faces. 15,000 indices in any index
field. |5,000 total faces. 15,000 indices in any index field.

|LineSet |15,000 total vertices. |15,000 total vertices.

|Material |No restrictions. |_ambientIntensity_ optionally supported.
_shininess_ optionally supported. _specularColor_ optionally supported.
A Material with _emissiveColor_ not equal to (0,0,0), _diffuseColor_
equal to (0,0,0) is an unlit material. One-bit transparency;
transparency values ≥ 0.5 transparent.

|MetadataBoolean |No restrictions. |Full support.

|MetadataDouble |No restrictions. |Full support.

|MetadataFloat |No restrictions. |Full support.

|MetadataInteger |No restrictions. |Full support.

|MetadataSet |No restrictions. |Full support.

|MetadataString |No restrictions. |Full support.

|MultiTexture |No restrictions. |At least one texture displayed per node
with any number specified. Full support.

|MultiTextureCoordinate |15,000 coordinates. |15,000 coordinates.

|MultiTextureTransform |No restrictions. |At least one texture displayed
per node with any number specified. Full support.

|NavigationInfo |No restrictions. |_avatarSize_ optionally supported.
_speed_ optionally supported. _type_ optionally supported.
_visibilityLimit_ optionally supported.

|Normal |15,000 normals |15,000 normals.

|NormalInterpolator |15,000 normals |15,000 normals.

|OrientationInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|PixelTexture |512 width. 512 height. |512 width. 512 height. Display
fully transparent and fully opaque pixels.

|PointSet |5,000 points. |5000 points.

|PositionInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|ScalarInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|Shape |No restrictions. |Full support.

|Sphere |No restrictions. |Full support.

|TextureCoordinate |65,535 coordinates. |65,535 coordinates.

|TextureCoordinateGenerator |No restrictions. |Full support.

|TextureTransform |No restrictions. |Full support.

|TimeSensor |No restrictions. |_pause_, optionally supported. +
_isPaused_, optionally supported. _resumeTime_, optionally supported.

|Transform |Restrictions as for all groups. |_addChildren_ optionally
supported. _removeChildren_ optionally supported. Otherwise, full
support except as for all groups.

|TriangleFanSet |5,000 triangles per fan. 15,000 total triangles. |5,000
triangles per fan. 15,000 total triangles.

|TriangleSet |15,000 triangles |15,000 triangles.

|TriangleStripSet |5,000 triangles per strip. 15,000 total triangles
|5,000 triangles per strip. 15,000 total triangles.

|Viewpoint |No restrictions. |_fieldOfView_ optionally supported. +
_description_ optionally supported.

|WorldInfo |No restrictions. |_info_, _title_ Ignored.
|===

[[B.6_OtherLimitations]]
=== B.6 Other limitations

<<tB_4, Table B.4>> specifies other aspects of X3D
functionality which are supported by this profile. Note that general
items refer only to those specific nodes listed in
<<tB_3, Table B.3>>.

[[tB_4]]
Table B.4 — Other limitations

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|All groups |500 children. |500 children. Ignore _bboxCenter_ and
_bboxSize_.

|All interpolators |1000 key-value pairs. |1000 key-value pairs.

|All lights |8 simultaneous lights. |8 simultaneous lights.

|Names for DEF/field |50 utf8 octets. |50 utf8 octets.

|All _url_ fields |10 URLs. |10 URLs. URN's ignored. +
Support `http', `file', and `ftp' protocols. +
Support relative URLs where relevant.

|SFBool      |No restrictions. |Full support.
|SFColor     |No restrictions. |Full support.
|SFColorRGBA |No restrictions. |Full support.
|SFDouble    |Mp restrictions. |Full support. Range ±1e±12. Precision 1e-7.
|SFFloat     |No restrictions. |Full support.
|SFImage     |512 width. 512 height. |512 width. 512 height.
|SFInt32     |No restrictions. |Full support.
|SFNode      |No restrictions. |Full support.
|SFRotation  |No restrictions. |Full support.
|SFString    |30,000 utf8 octets. |30,000 utf8 octets.
|SFTime      |No restrictions. |Full support.
|SFVec2d     |15,000 values. |15,000 values.
|SFVec2f     |15,000 values. |15,000 values.
|SFVec3d     |15,000 values. |15,000 values.
|SFVec3f     |15,000 values. |15,000 values.
|MFColor     |15,000 values. |15,000 values.
|MFColorRGBA |15,000 values. |15,000 values.
|MFDouble    |1000 values.   |1000 values.
|MFFloat     |1,000 values.  |1,000 values.
|MFImage     |No restrictions. |Full support.
|MFInt32     |20,000 values. |20,000 values.
|MFNode      |500 values.    |500 values.
|MFRotation  |1,000 values.  |1,000 values.
|MFString    |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.
|MFTime      |1,000 values.  |1,000 values.
|MFVec2d     |15,000 values. |15,000 values.
|MFVec2f     |15,000 values. |15,000 values.
|MFVec3d     |15,000 values. |15,000 values.
|MFVec3f     |15,000 values. |15,000 values.
|===

[[interactive_html]]
== Annex C Interactive profile

(normative)

Interactive profile +

[[C.1_General]]
=== C.1 General

This annex defines the X3D components that comprise the Interactive
profile. This includes not only the nodes that shall be supported but
also which fields in the supported nodes may be ignored.

The name of this profile is "Interactive". This profile is targeted
towards:

* implementing a lightweight playback engine that supports rich graphics
and interactivity,
* possible implementation in a low-footprint engine requiring limited
navigation and environmental sensor control (EXAMPLE  an
applet or small X3D browser plug-in), and
* allowing a broader range of implementations by eliminating some
complexity of a complete X3D implementation.

[[C.2_Topics]]
=== C.2 Topics

<<tC_1, Table C.1>> provides links to the major topics in this
annex.

[[tC_1]]
Table C.1 — Topics

* <<C.1_General, C.1 General>>
* <<C.2_Topics, C.2 Topics>>
* <<C.3_ComponentSupport, C.3 Component support>>
* <<C.4_ConformanceCriteria, C.4 Conformance criteria>>
* <<C.5_NodeSet, C.5 Node set>>
* <<C.6_OtherLimitations, C.6 Other limitations>>

* <<tC_1, Table C.1 — Topics>>
* <<tC_2, Table C.2 — Components and levels>>
* <<tC_3, Table C.3 — Nodes for conforming to the Interactive profile>>
* <<tC_4, Table C.4 — Other limitations>>


[[C.3_ComponentSupport]]
=== C.3 Component support

<<tC_2, Table C.2>> lists the components and their
levels which shall be supported in the Interactive profile. Tables C.2
and C.3 describe limitations on required support for nodes and fields
contained within these components.

[[tC_2]]
Table C.2 — Components and levels

[cols=",^,",options="header",]
|===
|Component              |Level |Reference
|Core                   |1 |<<S7_SupportLevels, 7.5 Support levels>>
|Time                   |1 |<<S8_SupportLevels, 8.5 Support levels>>
|Networking             |2 |<<S9_SupportLevels, 9.5 Support levels>>
|Grouping               |2 |<<S10_SupportLevels, 10.5 Support levels>>
|Rendering              |3 |<<S11_SupportLevels, 11.5 Support levels>>
|Shape                  |1 |<<S12_SupportLevels, 12.5 Support levels>>
|Geometry3D             |3 |<<S13_SupportLevels, 13.4 Support levels>>
|Lighting               |2 |<<S17_SupportLevels, 17.5 Support levels>>
|Texturing              |2 |<<S18_SupportLevels, 18.5 Support levels>>
|Interpolation          |2 |<<S19_SupportLevels, 19.5 Support levels>>
|Pointing device sensor |1 |<<S20_SupportLevels, 20.5 Support levels>>
|Key device sensor      |1 |<<S21_SupportLevels, 21.5 Support levels>>
|Environmental sensor   |1 |<<S22_SupportLevels, 22.5 Support levels>>
|Navigation             |1 |<<S23_SupportLevels, 23.4 Support levels>>
|Environmental effects  |1 |<<S24_SupportLevels, 24.5 Support levels>>
|Event utilities        |1 |<<S30_SupportLevels, 30.5 Support levels>>
|===

[[C.4_ConformanceCriteria]]
=== C.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tC_2, Table C.2>>.

In Tables C.3 and C.4, the first column defines the item for which
conformance is being defined. In some cases, general limits are defined
but are later overridden in specific cases by more restrictive limits.
The second column defines the requirements for a X3D file conforming to
the Interactive profile; if a X3D file contains any items that exceed
these limits, it may not be possible for a X3D browser conforming to the
Interactive profile to successfully parse that X3D file. The third
column defines the minimum complexity for a X3D scene that a X3D browser
conforming to the Interactive profile shall be able to present to the
user. Fields flagged as "not supported" may be supported by X3D browsers
which conform to the Interactive profile. The word "ignore" in the
minimum X3D browser support column refers only to the display of the
item; in particular, _set__ events to ignored inputOutput fields shall
still generate corresponding __changed_ events.

[[C.5_NodeSet]]
=== C.5 Node set

<<tC_3, Table C.3>> lists the nodes which shall be supported in the 
Interactive profile and specifies any fields in these nodes for which 
this profile requires less than full support.

[[tC_3]]
Table C.3 — Nodes for conforming to the Interactive profile

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item   |X3D File Limit   |Minimum X3D browser Support
|Anchor |No restrictions. |Full support.

|Appearance |No restrictions. |_textureTransform_ optionally
supported. +
_lineProperties_ not supported. _fillProperties_ not supported.

|Background |No restrictions. |_groundAngle_ and _groundColor_
optionally supported. _backURL_, _frontURL_, _leftURL_, _rightURL_,
_topURL_ optionally supported. _skyAngle_ optionally supported. One
_skyColor_.

|BooleanFilter |No restrictions. |Full support.

|BooleanSequencer |No restrictions. |Full support.

|BooleanToggle |No restrictions. |Full support.

|BooleanTrigger |No restrictions. |Full support.

|Box |No restrictions. |Full support.

|Color |15,000 colours. |15,000 colours.

|ColorInterpolator |Restrictions as for all interpolators. |Full support
as for all interpolators.

|ColorRGBA |15,000 colours. |15,000 colours. Alpha component optionally
supported.

|Cone |No restrictions. |Full support.

|Coordinate |65,535 points |65,535 points.

|CoordinateInterpolator |15,000 coordinates per _keyValue_. Restrictions
as for all interpolators. |15,000 coordinates per _keyValue_. Support as
for all interpolators.

|Cylinder |No restrictions. |Full support.

|CylinderSensor |No restrictions. |Full support.

|DirectionalLight |No restrictions. |Not scoped by parent Group or
Transform.

|ElevationGrid |No restrictions. |_ccw_ optionally supported.

|Group |Restrictions as for all groups. |Support as for all groups.

|ImageTexture |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format. |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format.

|IndexedFaceSet |10 vertices per face. 5000 faces. Less than 65,535
indices. a|
10 vertices per face. 5000 faces. 65,535 indices in any index field.

_ccw_ optionally supported. _set_colorIndex_ optionally supported.
_set_normalIndex_ optionally supported. _normal_ optionally supported.
Only convex indexed face sets supported. Hence, _convex_ optionally
supported. For _creaseAngle_, only 0 and π radians supported.
_normalIndex_ optionally supported.

Face list shall be well-defined as follows:

. Each face is terminated with -1, including the last face in the array.
. Each face contains at least three non-coincident vertices.
. A given _coordIndex_ is not repeated in a face.
. The vertices of a face shall define a planar polygon.
. The vertices of a face shall not define a self-intersecting polygon.

|IndexedLineSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.
_set_colorIndex_ optionally supported. _set_coordIndex_ optionally
supported.

|IndexedTriangleFanSet |5,000 total faces. 15,000 indices in any index
field. |Full support.

|IndexedTriangleSet |5,000 total faces. 15,000 indices in any index
field. |Full support.

|IndexedTriangleStripSet |5,000 total faces. 15,000 indices in any index
field. |Full support.

|Inline |No restrictions. |All fields fully supported except _load_
which is optionally supported.

|IntegerSequencer |No restrictions. |Full support.

|IntegerTrigger |No restrictions. |Full support.

|KeySensor |No restrictions. |Full support.

|LineSet |15,000 total vertices. |15,000 total vertices.

|Material |No restrictions. |_ambientIntensity_ optionally supported.
_shininess_ optionally supported. _specularColor_ optionally supported.
A Material with _emissiveColor_ not equal to (0,0,0), _diffuseColor_
equal to (0,0,0) is an unlit material. One-bit transparency;
transparency values ≥ 0.5 transparent.

|MetadataBoolean |No restrictions. |Full support.

|MetadataDouble |No restrictions. |Full support.

|MetadataFloat |No restrictions. |Full support.

|MetadataInteger |No restrictions. |Full support.

|MetadataSet |No restrictions. |Full support.

|MetadataString |No restrictions. |Full support.

|MultiTexture |No restrictions. |At least two textures displayed per
node with any number specified. Full support.

|MultiTextureCoordinate |15,000 coordinates. |15,000 coordinates.

|MultiTextureTransform |No restrictions. |At least two textures
displayed per node with any number specified. Full support.

|NavigationInfo |No restrictions. |_avatarSize_ optionally supported.
_speed_ optionally supported. _visibilityLimit_ optionally supported.
For _type_, only "ANY", "FLY", "EXAMINE", and "LOOKAT" modes supported.

|Normal |15,000 normals |15,000 normals.

|NormalInterpolator |15,000 normals |15,000 normals except as for all
interpolators.

|OrientationInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|PixelTexture |512 width. 512 height. |512 width. 512 height. Display
fully transparent and fully opaque pixels.

|PlaneSensor |No restrictions. |Full support.

|PointLight |No restrictions. |_radius_ optionally supported. Linear
attenuation.

|PointSet |5000 points. |5000 points.

|PositionInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|ProximitySensor |No restrictions. |_position_changed_ optionally
supported. _orientation_changed_ optionally supported.

|ScalarInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|Shape |No restrictions. |Full support.

|Sphere |No restrictions. |Full support.

|SphereSensor |No restrictions. |Full support.

|SpotLight |No restriction |_beamWidth_ optionally supported. _radius_
optionally supported. Linear attenuation.

|StringSensor |No restrictions. |Full support.

|Switch |No restrictions |Full support.

|TextureCoordinate |15,000 coordinates. |15,000 coordinates.

|TextureCoordinateGenerator |No restrictions. |Full support.

|TextureTransform |No restrictions. |Full support.

|TimeSensor |No restrictions. |_pause_ optionally supported. +
_isPaused_ optionally supported. _resumeTime_ optionally supported.

|TimeTrigger |No restrictions. |Full support.

|TouchSensor |No restrictions. |Full support.

|Transform |Restrictions as for all groups. |Full support except as for
all groups.

|TriangleFanSet |5,000 triangles per fan. 15,000 total triangles. |Full
support.

|TriangleSet |15,000 triangles. |Full support.

|TriangleStripSet |5,000 triangles per strip. 15,000 total triangles.
|Full support.

|Viewpoint |No restrictions. |_fieldOfView_ optionally supported. +
_description_ optionally supported. +
_retainUserOffsets_ optionally supported. +
All other fields fully supported.

|VisibilitySensor |No restrictions. |Always visible.

|WorldInfo |No restrictions. |Full support.
|===

[[C.6_OtherLimitations]]
=== C.6 Other limitations

<<tC_4, Table C.4>> specifies other aspects of X3D
functionality which are supported by this profile. Note that general
items refer only to those specific nodes listed in
<<tC_3, Table C.3>>.

[[tC_4]]
Table C.4 — Other limitations

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|All groups |500 children. |500 children. Ignore _bboxCenter_ and
_bboxSize_.

|All interpolators |1000 key-value pairs. |1000 key-value pairs.

|All lights |8 simultaneous lights. |8 simultaneous lights.

|Names for DEF/field |50 utf8 octets. |50 utf8 octets.

|All _url_ fields |10 URLs. |10 URLs. URN's ignored. +
Support `http', `file', and `ftp' protocols. +
Support relative URLs where relevant.

|SFBool |No restrictions. |Full support.

|SFColor |No restrictions. |Full support.

|SFColorRGBA |No restrictions. |Full support.

|SFDouble |Mp restrictions. |Full support. Range ±1e±12. Precision 1e-7.

|SFFloat |No restrictions. |Full support.

|SFImage |512 width. 512 height. |512 width. 512 height.

|SFInt32 |No restrictions. |Full support.

|SFNode |No restrictions. |Full support.

|SFRotation |No restrictions. |Full support.

|SFString |30,000 utf8 octets. |30,000 utf8 octets.

|SFTime |No restrictions. |Full support.

|SFVec2d |15,000 values. |15,000 values.

|SFVec2f |15,000 values. |15,000 values.

|SFVec3d |15,000 values. |15,000 values.

|SFVec3f |15,000 values. |15,000 values.

|MFColor |15,000 values. |15,000 values.

|MFColorRGBA |15,000 values. |15,000 values.

|MFDouble |1000 values. |1000 values.

|MFFloat |1,000 values. |1,000 values.

|MFImage |No restrictions. |Full support.

|MFInt32 |20,000 values. |20,000 values.

|MFNode |500 values. |500 values.

|MFRotation |1,000 values. |1,000 values.

|MFString |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.

|MFTime |1,000 values. |1,000 values.

|MFVec2d |15,000 values. |15,000 values.

|MFVec2f |15,000 values. |15,000 values.

|MFVec3d |15,000 values. |15,000 values.

|MFVec3f |15,000 values. |15,000 values.
|===

[[MPEG4interactive_html]]
== Annex D MPEG-4 interactive profile

(normative)

MPEG-4 interactive profile +

[[D.1_General]]
=== D.1 General

This annex defines the X3D components which comprise the MPEG-4
interactive profile. This includes not only the nodes which shall be
supported but also which fields in the supported nodes may be ignored.

The name of this profile is "MPEG4Interactive". This profile is targeted
towards:

* providing the base point of interoperability with the MPEG-4 standard
(see <<I14496_1, I14496-1>>),
* implementing a lightweight playback engine that supports rich graphics
and interactivity,
* possible implementation in a low-footprint engine requiring limited
navigation and environmental sensor control (EXAMPLE  an
applet or small X3D browser plug-in), and
* allowing a broader range of implementations by eliminating some
complexity of a complete X3D implementation.

[[D.2_Topics]]
=== D.2 Topics

<<tD_1, Table D.1>> provides links to the major topics in this
annex.

[[tD_1]]
Table D.1 — Topics

* <<D.1_General, D.1 General>>
* <<D.2_Topics, D.2 Topics>>
* <<D.3_ComponentSupport, D.3 Component support>>
* <<D.4_ConformanceCriteria, D.4 Conformance criteria>>
* <<D.5_NodeSet, D.5 Node set>>
* <<D.6_OtherLimitations, D.6 Other limitations>>

* <<tD_1, Table D.1 — Topics>>
* <<tD_2, Table D.2 — Components and levels>>
* <<tD_3, Table D.3 — Nodes for conforming to the MPEG-4 interactive profile>>
* <<tD_4, Table D.4 — Other limitations>>


[[D.3_ComponentSupport]]
=== D.3 Component support

<<tD_2, Table D.2>> lists the components and their
levels which shall be supported in the MPEG-4 interactive profile.
Tables D.2 and D.3 describe limitations on required support for nodes
and fields contained within these components.

[[tD_2]]
Table D.2 — Components and levels

[cols=",,",options="header",]
|===
|Component |Level |Reference
|Core |1 |<<S7_SupportLevels, 7.5 Support levels>>
|Time |1 |<<S8_SupportLevels, 8.5 Support levels>>
|Networking |2 |<<S9_SupportLevels, 9.5 Support levels>>
|Grouping |2 |<<S10_SupportLevels, 10.5 Support levels>>
|Rendering |1 |<<S11_SupportLevels, 11.5 Support levels>>
|Shape |1 |<<S12_SupportLevels, 12.5 Support levels>>
|Geometry3D |2 |<<S13_SupportLevels, 13.4 Support levels>>
|Lighting |2 |<<S17_SupportLevels, 17.5 Support levels>>
|Texturing |1 |<<S18_SupportLevels, 18.5 Support levels>>
|Interpolation |2 |<<S19_SupportLevels, 19.5 Support levels>>
|Pointing device sensor |1 |<<S20_SupportLevels, 20.5 Support levels>>
|Environmental sensor |1 |<<S22_SupportLevels, 22.5 Support levels>>
|Navigation |1 |<<S23_SupportLevels, 23.4 Support levels>>
|Environmental effects |1 |<<S24_SupportLevels, 24.5 Support levels>>
|===

[[D.4_ConformanceCriteria]]
=== D.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tD_2, Table D.2>>.

In Tables D.3 and D.4, the first column defines the item for which
conformance is being defined. In some cases, general limits are defined
but are later overridden in specific cases by more restrictive limits.
The second column defines the requirements for a X3D file conforming to
the MPEG-4 interactive profile; if a X3D file contains any items that
exceed these limits, it may not be possible for a X3D browser conforming
to the MPEG-4 interactive profile to successfully parse that X3D filD.
The third column defines the minimum complexity for a X3D scene that a
X3D browser conforming to the MPEG-4 interactive profile shall be able
to present to the user. Fields flagged as "not supported" may be
supported by X3D browsers which conform to the MPEG-4 interactive
profilD. The word "ignore" in the minimum X3D browser support column
refers only to the display of the item; in particular, _set__ events to
ignored inputOutput fields shall still generate corresponding __changed_
events.

[[D.5_NodeSet]]
=== D.5 Node set

<<tD_3, Table D.3>> lists the nodes that shall be
supported in the MPEG-4 interactive profile and specifies any fields in
these nodes for which this profile requires less than full support.

[[tD_3]]
Table D.3 — Nodes for conforming to the
MPEG-4 Interactive profile

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |File Limit |Minimum X3D browser Support
|Anchor |No restrictions. |_addChildren_ optionally supported.
_removeChildren_ optionally supported. Ignore _parameter_. Ignore
_description_.

|Appearance |No restrictions. |_textureTransform_ optionally
supported. +
_lineProperties_ not supported. _fillProperties_ not supported.

|Background |No restrictions. |_groundAngle_ and _groundColor_
optionally supported. _backURL_, _frontURL_, _leftURL_, _rightURL_,
_topURL_ optionally supported. _skyAngle_ optionally supported. One
_skyColor_.

|Box |No restrictions. |Full support.

|Color |15,000 colours. |15,000 colours.

|ColorInterpolator |Restrictions as for all interpolators. |Full support
as for all interpolators.

|ColorRGBA |15,000 colours. |15,000 colours. Alpha component optionally
supported.

|Cone |No restrictions. |Full support.

|Coordinate |65,535 points |65,535 points.

|CoordinateInterpolator |15,000 coordinates per _keyValuD_. Restrictions
as for all interpolators. |15,000 coordinates per _keyValue_. Support as
for all interpolators.

|Cylinder |No restrictions. |Full support.

|CylinderSensor |No restrictions. |Full support.

|DirectionalLight |No restrictions. |Not scoped by parent Group or
Transform.

|ElevationGrid |No restrictions. |_ccw_ optionally supported.

|Group |Restrictions as for all groups. |Full support except as for all
groups.

|ImageTexture |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format. |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format.

|IndexedFaceSet |10 vertices per facD. 5000 faces. Less than 65,535
indices. a|
_ccw_ optionally supported. _set_colorIndex_ optionally supported.
_set_normalIndex_ optionally supported. _normal_ optionally supported.
Only convex indexed face sets supported. Hence, _convex_ optionally
supported. For _creaseAngle_, only 0 and π radians supported
(or the equivalent if a different angle base unit has been specified).
_normalIndex_ optionally supported. 10 vertices per face. 5000 faces.
65,535 indices in any index field. Face list shall be well-defined as
follows:

. Each face is terminated with −1, including the last face in the array.
. Each face contains at least three non-coincident vertices.
. A given _coordIndex_ is not repeated in a face.
. The vertices of a face shall define a planar polygon.
. The vertices of a face shall not define a self-intersecting polygon.

|IndexedLineSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.
_set_colorIndex_ optionally supported. _set_coordIndex_ optionally
supported.

|Inline |No restrictions. |All fields except _load_ which is optionally
supported.

|LineSet |15,000 total vertices. |15,000 total vertices.

|Material |No restrictions. |_ambientIntensity_ optionally supported.
_shininess_ optionally supported. _specularColor_ optionally supported.
A Material with _emissiveColor_ not equal to (0,0,0), _diffuseColor_
equal to (0,0,0) is an unlit material. One-bit transparency;
transparency values ≥ 0.5 transparent.

|MetadataBoolean |No restrictions. |Full support.

|MetadataDouble |No restrictions. |Full support.

|MetadataFloat |No restrictions. |Full support.

|MetadataInteger |No restrictions. |Full support.

|MetadataSet |No restrictions. |Full support.

|MetadataString |No restrictions. |Full support.

|NavigationInfo |No restrictions. |_avatarSize_ optionally supported.
_speed_ optionally supported. _type_ optionally supported.
_visibilityLimit_ optionally supported.

|NormalInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|OrientationInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|PixelTexture |512 width. 512 height. |512 width. 512 height. Display
fully transparent and fully opaque pixels.

|PlaneSensor |No restrictions. |Full support.

|PointLight |No restrictions. |_radius_ optionally supported. Linear
attenuation.

|PointSet |5000 points. |5000 points.

|PositionInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|ProximitySensor |No restrictions. |_position_changed_ optionally
supported. _orientation_changed_ optionally supported.

|ScalarInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|Shape |No restrictions. |Full support.

|Sphere |No restrictions. |Full support.

|SphereSensor |No restrictions. |Full support.

|SpotLight |No restriction |_beamWidth_ optionally supported. _radius_
optionally supported. Linear attenuation.

|Switch |No restrictions |Full support.

|TextureCoordinate |65,535 coordinates. |65,535 coordinates.

|TextureTransform |No restrictions. |Full support.

|TimeSensor |No restrictions. |_pause_ optionally supported. +
_isPaused_ optionally supported. _resumeTime_ optionally supported.

|TouchSensor |No restrictions. |Full support.

|Transform |Restrictions as for all groups. |Full support except as for
all groups.

|Viewpoint |No restrictions. |_fieldOfView_ optionally supported. +
_description_ optionally supported.

|WorldInfo |No restrictions. |Full support.
|===

[[D.6_OtherLimitations]]
=== D.6 Other limitations

<<tD_4, Table D.4>> specifies other aspects of X3D
functionality that are supported by this profile. Note that general
items refer only to those specific nodes listed in
<<tD_3, Table D.3>>.

[[tD_4]]
Table D.4 — Other limitations

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|All groups |500 children. |500 children. Ignore _bboxCenter_ and
_bboxSize_.

|All interpolators |1000 key-value pairs. |1000 key-value pairs.

|All lights |8 simultaneous lights. |8 simultaneous lights.

|Names for DEF/field |50 utf8 octets. |50 utf8 octets.

|All _url_ fields |10 URLs. |10 URLs. URN's ignored. +
Support `http', `file', and `ftp' protocols. +
Support relative URLs where relevant.

|SFBool |No restrictions. |Full support.

|SFColor |No restrictions. |Full support.

|SFColorRGBA |No restrictions. |Full support.

|SFDouble |Mp restrictions. |Full support. Range ±1e±12. Precision 1e−7.

|SFFloat |No restrictions. |Full support.

|SFImage |256 width. 256 height. |256 width. 256 height.

|SFInt32 |No restrictions. |Full support.

|SFNode |No restrictions. |Full support.

|SFRotation |No restrictions. |Full support.

|SFString |30,000 utf8 octets. |30,000 utf8 octets.

|SFTime |No restrictions. |Full support.

|SFVec2d |15,000 values. |15,000 values.

|SFVec2f |15,000 values. |15,000 values.

|SFVec3d |15,000 values. |15,000 values.

|SFVec3f |15,000 values. |15,000 values.

|MFColor |15,000 values. |15,000 values.

|MFColorRGBA |15,000 values. |15,000 values.

|MFDouble |1000 values. |1000 values.

|MFFloat |1,000 values. |1,000 values.

|MFImage |No restrictions. |Full support.

|MFInt32 |20,000 values. |20,000 values.

|MFNode |500 values. |500 values.

|MFRotation |1,000 values. |1,000 values.

|MFString |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.

|MFTime |1,000 values. |1,000 values.

|MFVec2d |15,000 values. |15,000 values.

|MFVec2f |15,000 values. |15,000 values.

|MFVec3d |15,000 values. |15,000 values.

|MFVec3f |15,000 values. |15,000 values.
|===

[[immersive_html]]
== Annex E Immersive profile

(normative)

Immersive profile +

[[E.1_General]]
=== E.1 General

This annex defines the X3D components which comprise the Immersive
profile. This includes not only the nodes which shall be supported but
also which fields in the supported nodes may be ignored.

The name of this profile is "Immersive". This profile  is targeted
towards:

* implementing immersive virtual worlds with complete navigational and
environmental sensor control and
* implementing the functionality within the X3D architectural framework
analogous to that specified in ISO/IEC 14772-1 for the VRML base profile
of that standard (see <<I14772_1, I14772-1>>).

[[E.2_Topics]]
=== E.2 Topics

<<tE_1, Table E.1>> provides links to the major topics in this
annex.

[[tE_1]]
Table E.1 — Topics

* <<E.1_General, E.1 General>>
* <<E.2_Topics, E.2 Topics>>
* <<E.3_ComponentSupport, E.3 Component support>>
* <<E.4_ConformanceCriteria, E.4 Conformance criteria>>
* <<E.5_NodeSet, E.5 Node set>>
* <<E.6_OtherLimitations, E.6 Other limitations>>

* <<tE_1, Table E.1 — Topics>>
* <<tE_2, Table E.2 — Components and levels>>
* <<tE_3, Table E.3 — Nodes for conforming to the Immersive profile>>
* <<tE_4, Table E.4 — Other limitations>>


[[E.3_ComponentSupport]]
=== E.3 Component support

<<tE_2, Table E.2>> lists the components and their
levels which shall be supported in the Immersive profile. Tables E.2 and
E.3 describe limitations on required support for nodes and fields
contained within these components.

[[tE_2]]
Table E.2 — Components and levels

[cols=",,",options="header",]
|===
|Component |Level |Reference
|Core |2 |<<S7_SupportLevels, 7.5 Support levels>>
|Time |1 |<<S8_SupportLevels, 8.5 Support levels>>
|Networking |3 |<<S9_SupportLevels, 9.5 Support levels>>
|Grouping |2 |<<S10_SupportLevels, 10.5 Support levels>>
|Rendering |3 |<<S11_SupportLevels, 11.5 Support levels>>
|Shape |2 |<<S12_SupportLevels, 12.5 Support levels>>
|Geometry3D |4 |<<S13_SupportLevels, 13.4 Support levels>>
|Geometry2D |1 |<<S14_SupportLevels, 14.4 Support levels>>
|Text |1 |<<S15_SupportLevels, 15.5 Support levels>>
|Sound |1 |<<S16_SupportLevels, 16.5 Support levels>>
|Lighting |2 |<<S17_SupportLevels, 17.5 Support levels>>
|Texturing |3 |<<S18_SupportLevels, 18.5 Support levels>>
|Interpolation |2 |<<S19_SupportLevels, 19.5 Support levels>>
|Pointing device sensor |1 |<<S20_SupportLevels, 20.5 Support levels>>
|Key device sensor |2 |<<S21_SupportLevels, 21.5 Support levels>>
|Environmental sensor |2 |<<S22_SupportLevels, 22.5 Support levels>>
|Navigation |2 |<<S23_SupportLevels, 23.4 Support levels>>
|Environmental effects |2 |<<S24_SupportLevels, 24.5 Support levels>>
|Scripting |1 |<<S29_SupportLevels, 29.5 Support levels>>
|Event utilities |1 |<<S30_SupportLevels, 30.5 Support levels>>
|===

[[E.4_ConformanceCriteria]]
=== E.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tE_2, Table E.2>>.

In <<tE_2, Table E.2>> and
<<tE_3, Table E.3>>, the first column defines the item
for which conformance is being defined. In some cases, general limits
are defined but are later overridden in specific cases by more
restrictive limits. The second column defines the requirements for a X3D
file conforming to the Immersive profile; if a X3D file contains any
items that exceed these limits, it may not be possible for a X3D browser
conforming to the Immersive profile to successfully parse that X3D file.
The third column defines the minimum complexity for a X3D scene that a
X3D browser conforming to the Immersive profile shall be able to present
to the user. The word "ignore" in the minimum X3D browser support column
refers only to the display of the item; in particular, _set__ events to
ignored inputOutput fields shall still generate corresponding __changed_
events.

[[E.5_NodeSet]]
=== E.5 Node set

<<tE_3, Table E.3>> lists the nodes which shall be
supported in the Immersive profile and specifies any fields in these
nodes for which this profile requires less than full support.

[[tE_3]]
Table E.3 — Nodes for conforming to the
Immersive profile

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|Anchor |No restrictions. |Full support.

|Appearance |No restrictions. |_fillProperties_ not supported.

|AudioClip |30 second uncompressed PCM WAV. |30 second uncompressed PCM
WAV.

|Background |No restrictions. |One _skyColor_, one _groundColor_,
panorama images as per ImageTexture.

|Billboard |Restrictions as for all groups. |Full support except as for
all groups.

|BooleanFilter |No restrictions. |Full support.

|BooleanSequencer |No restrictions. |Full support.

|BooleanToggle |No restrictions. |Full support.

|BooleanTrigger |No restrictions. |Full support.

|Box |No restrictions. |Full support.

|Collision |Restrictions as for all groups. |Full support except as for
all groups. Any navigation behaviour acceptable when collision occurs.

|Color |15,000 colours. |15,000 colours.

|ColorInterpolator |Restrictions as for all interpolators. |Full support
except as for all interpolators.

|ColorRGBA |15,000 colours. |15,000 colours. Alpha component optionally
supported.

|Cone |No restrictions. |Full support.

|Coordinate |15,000 points. |15,000 points.

|CoordinateInterpolator |15,000 coordinates per _keyValue_. Restrictions
as for all interpolators. |15,000 coordinates per _keyValue_. Support as
for all interpolators.

|Cylinder |No restrictions. |Full support.

|CylinderSensor |No restrictions. |Full support.

|DirectionalLight |No restrictions. |Not scoped by parent Group or
Transform.

|ElevationGrid |16,000 heights. |16,000 heights.

|Extrusion |(# _crossSection_ points) × (# _spine_ points) ≤ 2,500. |(#
_crossSection_ points) × (# _spine_ points) ≤ 2,500.

|Fog |No restrictions. |Full support.

|FontStyle |No restrictions. |If the values of the text aspects
character set, _family_, _style_ cannot be simultaneously supported, the
order of precedence shall be: 1) character set 2) _family_ 3) _style_.
X3D browser shall display all characters in Table 2 (Basic Latin) and
Table 3 (Latin-1 Supplement) of ISO/IEC 10646-1 (see
<<I10646_1, I10646-1>>).

|Group |Restrictions as for all groups. |Full support except as for all
groups.

|ImageTexture |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format. Restrictions as for PixelTexture. |JPEG
(<<JPEG>>) and PNG (<<I15948>>) format. Support as
for PixelTexture.

|IndexedFaceSet |10 vertices per face. 5000 faces. Less than 15,000
indices. |10 vertices per face. 5000 faces. 15,000 indices in any index
field.

|IndexedLineSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedTriangleFanSet |15,000 total vertices. 15,000 indices in any
index field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedTriangleSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedTriangleStripSet |15,000 total vertices. 15,000 indices in any
index field. |15,000 total vertices. 15,000 indices in any index field.

|Inline |No restrictions. |Full support.

|IntegerSequencer |No restrictions. |Full support.

|IntegerTrigger |No restrictions. |Full support.

|KeySensor |No restrictions. |Full support.

|LineProperties |No restrictions. |Full support.

|LineSet |15,000 total vertices. |15,000 total vertices.

|LoadSensor |No restrictions. |Full support.

|LOD |Restrictions as for all groups. |At least first 4 _level_/ _range_
combinations interpreted, and support as for all groups.

|Material |No restrictions. |Full support.

|MetadataBoolean |No restrictions. |Full support.

|MetadataDouble |No restrictions. |Full support.

|MetadataFloat |No restrictions. |Full support.

|MetadataInteger |No restrictions. |Full support.

|MetadataSet |No restrictions. |Full support.

|MetadataString |No restrictions. |Full support.

|MovieTexture |MPEG1-Systems and MPEG1-Video formats (see
<<I14496_1, I14496-1>>). |MPEG1-Systems and MPEG1-Video formats (see
<<I14496_1, I14496-1>>). Display one active movie texture.

|MultiTexture |No restrictions. |At least two textures displayed per
node with any number specified. Full support.

|MultiTextureCoordinate |15,000 coordinates. |15,000 coordinates.

|MultiTextureTransform |Restrictions as for all groups. |_addChildren_
optionally supported. _removeChildren_ optionally supported. Otherwise,
full support except as for all groups.

|NavigationInfo |No restrictions. |Full support.

|Normal |15,000 normals |15,000 normals

|NormalInterpolator |15,000 normals per _keyValue_. Restrictions as for
all interpolators. |15,000 normals per _keyValue_. Support as for all
interpolators.

|OrientationInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|PixelTexture |512 width. 512 height. |512 width. 512 height. Display
fully transparent and fully opaque pixels.

|PlaneSensor |No restrictions. |Full support.

|PointLight |No restrictions. |_radius_ optionally supported. Linear
attenuation.

|PointSet |5000 points. |5000 points.

|Polyline2D |5000 vertices. |5000 vertices.

|Polypoint2D |5000 points. |5000 points.

|PositionInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|ProximitySensor |No restrictions. |Full support.

|Rectangle2D |No restrictions. |Full support.

|ScalarInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|Script |25 fields of each access type. |25 fields of each access
type. +
No scripting language support required.

|Shape |No restrictions. |Full support.

|Sound |No restrictions. |2 active sounds.

|Sphere |No restrictions. |Full support.

|SphereSensor |No restrictions. |Full support.

|SpotLight |No restriction |_beamWidth_ optionally supported. _radius_
optionally supported. Linear attenuation.

|StringSensor |100 characters per string. 100 strings. |Full support.
100 characters per string. 100 strings.

|Switch |Restrictions as for all groups. |Full support except as for all
groups.

|Text |100 characters per string. 100 strings. |100 characters per
string. 100 strings.

|TextureCoordinate |15,000 coordinates. |15,000 coordinates.

|TextureCoordinateGenerator |No restrictions. |Full support.

|TextureTransform |No restrictions. |Full support.

|TimeSensor |No restrictions. |_pause_ optionally supported. +
_isPaused_ optionally supported. _resumeTime_ optionally supported.

|TimeTrigger |No restrictions. |Full support.

|TouchSensor |No restrictions. |Full support.

|Transform |Restrictions as for all groups. |Full support except as for
all groups.

|TriangleFanSet |15,000 coordinates. |Full support.

|TriangleSet |15,000 coordinates. |Full support.

|TriangleSet2D |15,000 coordinates. |Full support.

|TriangleStripSet |15,000 coordinates. |Full support.

|Viewpoint |No restrictions. |Full support.

|VisibilitySensor |No restrictions. |Always visible.

|WorldInfo |No restrictions. |Full support.
|===

[[E.6_OtherLimitations]]
=== E.6 Other limitations

<<tE_4, Table E.4>>specifies limitations unrelated to
nodes which are imposed by the Immersive profile.

[[tE_4]]
Table E.4 — Other limitations

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|All groups |500 children. |500 children. Ignore _bboxCenter_ and
_bboxSize_.

|All interpolators |1000 key-value pairs. |1000 key-value pairs.

|All lights |8 simultaneous lights. |8 simultaneous lights.

|Names for DEF/PROTO/field |50 utf8 octets. |50 utf8 octets.

|All _url_ fields |10 URLs. |10 URLs. URN's ignored. +
Support 'http', 'file', and 'ftp' protocols. +
Support relative URLs where relevant.

|PROTO/ +
EXTERNPROTO |30 fields of each access type. |30 fields of each access
type.

|EXTERNPROTO | n/a |URL references X3D files conforming to the current
X3D profile/component configuration

|PROTO definition nesting depth |5 levels. |5 levels.

|SFBool |No restrictions. |Full support.

|SFColor |No restrictions. |Full support.

|SFColorRGBA |No restrictions. |Full support.

|SFDouble |No restrictions. |Full support. Range ±1e±12. Precision 1e−7.

|SFFloat |No restrictions. |Full support.

|SFImage |512 width. 512 height. |512 width. 512 height.

|SFInt32 |No restrictions. |Full support.

|SFNode |No restrictions. |Full support.

|SFRotation |No restrictions. |Full support.

|SFString |30,000 utf8 octets. |30,000 utf8 octets.

|SFTime |No restrictions. |Full support.

|SFVec2d |15,000 values. |15,000 values.

|SFVec2f |15,000 values. |15,000 values.

|SFVec3d |15,000 values. |15,000 values.

|SFVec3f |15,000 values. |15,000 values.

|MFColor |15,000 values. |15,000 values.

|MFColorRGBA |15,000 values. |15,000 values.

|MFDouble |1000 values. |1000 values.

|MFFloat |1,000 values. |1,000 values.

|MFImage |No restrictions. |Full support.

|MFInt32 |20,000 values. |20,000 values.

|MFNode |500 values. |500 values.

|MFRotation |1,000 values. |1,000 values.

|MFString |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.

|MFTime |1,000 values. |1,000 values.

|MFVec2d |15,000 values. |15,000 values.

|MFVec2f |15,000 values. |15,000 values.

|MFVec3d |15,000 values. |15,000 values.

|MFVec3f |15,000 values. |15,000 values.
|===

[[fullProfile_html]]
== Annex F Full profile

(normative)

Full profile +

[[F.1_General]]
=== F.1 General

This annex defines the X3D components which comprise the Full profile.
This includes not only the nodes which shall be supported but also which
fields in the supported nodes may be ignored.

The name of this profile is "Full". The Full profile of X3D is comprised
of all features of the standard.

[[F.2_Topics]]
=== F.2 Topics

<<tF_1, Table F.1>> provides links to the major topics in this
annex.

[[tF_1]]
Table F.1 — Topics

* <<F.1_General, F.1 General>>
* <<F.2_Topics, F.2 Topics>>
* <<F.3_ComponentSupport, F.3 Component support>>
* <<F.4_ConformanceCriteria, F.4 Conformance criteria>>
* <<F.5_NodeSet, F.5 Node set>>
* <<F.6_OtherLimitations, F.6 Other limitations>>

* <<tF_1, Table F.1 — Topics>>
* <<tF_2, Table F.2 — Components and levels>>
* <<tF_3, Table F.3 — Nodes for conforming to the Full profile>>
* <<tF_4, Table F.4 — Other limitations>>


[[F.3_ComponentSupport]]
=== F.3 Component support

<<tF_2, Table F.2>> lists the components and their
levels which shall be supported in the Full profile. Tables F.2 and F.3
describe limitations on required support for nodes and fields contained
within these components.

[[tF_2]]
Table F.2 — Components and levels

[cols=",^,",options="header",]
|===
|Component |Level |Reference
|Core |2 |<<S7_SupportLevels, 7.5 Support levels>>

|Time |2 |<<S8_SupportLevels, 8.5 Support levels>>

|Networking |4 |<<S9_SupportLevels, 9.5 Support levels>>

|Grouping |3 |<<S10_SupportLevels, 10.5 Support levels>>

|Rendering |5 |<<S11_SupportLevels, 11.5 Support levels>>

|Shape |4 |<<S12_SupportLevels, 12.5 Support levels>>

|Geometry3D |4 |<<S13_SupportLevels, 13.4 Support levels>>

|Geometry2D |2 |<<S14_SupportLevels, 14.4 Support levels>>

|Text |1 |<<SupportlLevels, 15.5 Support levels>>

|Sound |3 |<<S16_SupportLevels, 16.5 Support levels>>

|Lighting |3 |<<S17_SupportLevels, 17.5 Support levels>>

|Texturing |4 |<<S18_SupportLevels, 18.5 Support levels>>

|Interpolation |5 |<<S19_SupportLevels, 19.5 Support levels>>

|Pointing device sensor |1 |<<S20_SupportLevels, 20.5 Support levels>>

|Key device sensor |2 |<<S21_SupportLevels, 21.5 Support levels>>

|Environmental sensor |3 |<<S22_SupportLevels, 22.5 Support levels>>

|Navigation |3 |<<S23_SupportLevels, 23.4 Support levels>>

|Environmental effects |4 |<<S24_SupportLevels, 24.5 Support levels>>

|Geospatial |2 |<<S25_SupportLevels, 25.4 Support levels>>

|Humanoid animation |3 |<<S26_SupportLevels, 26.4 Support levels>>

|Non-uniform Rational B-Spline (NURBS) |4 |<<S27_SupportLevels, 27.5 Support levels>>

|Distributed interactive simulation |2 |<<S28_SupportLevels, 28.4 Support levels>>

|Scripting |1 |<<S29_SupportLevels, 29.5 Support levels>>

|Event utilities |1 |<<S30_SupportLevels, 30.5 Support levels>>

|Programmable shaders |1 |<<S31_SupportLevels, 31.5 Support levels>>

|CAD geometry |2 |<<S32_SupportLevels, 32.5 Support levels>>

|Texturing3D |2 |<<S33_SupportLevels, 33.5 Support levels>>

|Cube map environmental texturing |3 |<<S34_SupportLevels, 34.5 Support levels>>

|Layering component |1 |<<S35_SupportLevels, 35.5 Support levels>>

|Layout component |2 |<<S36_SupportLevels, 36.5 Support levels>>

|Rigid body physics component |2 |<<S37_SupportLevels, 37.5 Support levels>>

|Picking component |3 |<<S38_SupportLevels, 38.5 Support levels>>

|Followers component |1 |<<S39_SupportLevels, 39.5 Support levels>>

|Particle systems component |3 |<<S40_SupportLevels, 40.5 Support levels>>

|Volume rendering component |4 |<<S41_SupportLevels, 41.5 Support levels>>

|Texture projection component |2 |<<S42_SupportLevels, 42.5 Support levels>>
|===

[[F.4_ConformanceCriteria]]
=== F.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tF_2, Table F.2>>.

In <<tF_3, Table F.3>> and
<<tF_4, Table F.4>>, the first column defines the item
for which conformance is being defined. In some cases, general limits
are defined but are later overridden in specific cases by more
restrictive limits. The second column defines the requirements for a X3D
file conforming to the Full profile; if a X3D file contains any items
that exceed these limits, it may not be possible for a X3D browser
conforming to the Full profile to successfully parse that X3D file. The
third column defines the minimum complexity for a X3D scene that a X3D
browser conforming to the Full profile shall be able to present to the
user. Fields flagged as "not supported" may be supported by X3D browsers
which conform to the Full profile. The word "ignore" in the minimum X3D
browser support column refers only to the display of the item; in
particular, _set__ events to ignored inputOutput fields shall still
generate corresponding __changed_ events.

[[F.5_NodeSet]]
=== F.5 Node set

<<tF_3, Table F.3>> lists the nodes which shall be
supported in the Full profile and specifies any fields in these nodes
for which this profile requires less than full support.

[[tF_3]]
Table F.3 — Nodes for conforming to the Full profile

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|Anchor |No restrictions. |Full support

|Appearance |No restrictions. |Full support.

|Arc2D |No restrictions. |Full support.

|ArcClose2D |No restrictions. |Full support.

|AudioClip |30 second uncompressed PCM WAV. |30 second uncompressed PCM
WAV.

|Background |No restrictions. |Full support.

|BallJoint |No restrictions. |Full support.

|Billboard |Restrictions as for all groups. |Full support except as for
all groups.

|BlendedVolumeStyle |No restrictions. |Full support.

|BooleanFilter |No restrictions. |Full support.

|BooleanSequencer |No restrictions. |Full support.

|BooleanToggle |No restrictions. |Full support.

|BooleanTrigger |No restrictions. |Full support.

|BoundaryEnhancementVolumeStyle |No restrictions. |Full support.

|BoundedPhysicsModel |No restrictions. |Full support.

|Box |No restrictions. |Full support.

|CADAssembly |No restrictions. |Full support.

|CADFace |No restrictions. |Full support.

|CADLayer |No restrictions. |Full support.

|CADPart |No restrictions. |Full support.

|CartoonVolumeStyle |No restrictions. |Full support.

|Circle2D |No restrictions. |Full support.

|ClipPlane |At least six planes. |Full support.

|CollidableOffset |No restrictions. |Full support.

|CollidableShape |No restrictions. |Full support.

|Collision |Restrictions as for all groups. |Full support except as for
all groups. Any navigation behaviour acceptable when collision occurs.

|CollisionCollection |No restrictions. |Full support.

|CollisionSensor |No restrictions. |Full support.

|CollisionSpace |No restrictions. |Full support.

|Color |15,000 colours. |15,000 colours.

|ColorChaser |No restrictions. |Full support.

|ColorDamper |No restrictions. |Full support.

|ColorInterpolator |Restrictions as for all interpolators. |Full support
except as for all interpolators.

|ColorRGBA |15,000 colours. |15,000 colours.

|ComposedCubeMapTexture |No restrictions. |Full support.

|ComposedShader |No restrictions. |Full support.

|ComposedTexture3D |No restrictions. |Full support.

|ComposedVolumeStyle |No restrictions. |Full support.

|Cone |No restrictions. |Full support.

|ConeEmitter |No restrictions. |Full support.

|Contact |No restrictions. |Full support.

|Contour2D |No restrictions. |Full support.

|ContourPolyline2D |1500 control points. |Order 30.

|Coordinate |15,000 points. |15,000 points.

|CoordinateChaser |No restrictions. |Full support.

|CoordinateDamper |No restrictions. |Full support.

|CoordinateDouble |15,000 points. |15,000 points.

|CoordinateInterpolator |15,000 coordinates per _keyValue_. Restrictions
as for all interpolators. |15,000 coordinates per _keyValue_. Support as
for all interpolators.

|CoordinateInterpolator2D |15,000 coordinates per _keyValue_.
Restrictions as for all interpolators. |15,000 coordinates per
_keyValue_. Support as for all interpolators.

|Cylinder |No restrictions. |Full support.

|CylinderSensor |No restrictions. |Full support.

|DirectionalLight |No restrictions. |Full support.

|DISEntityManager |No restrictions. |Full support.

|DISEntityTypeMapping |No restrictions. |Full support.

|Disk2D |No restrictions. |Full support.

|DoubleAxisHingeJoint |No restrictions. |Full support.

|EaseInEaseOut |No restrictions. |Full support.

|EdgeEnhancementVolumeStyle |No restrictions. |Full support.

|ElevationGrid |16,000 heights. |16,000 heights.

|EspduTransform |No restrictions. |Full support.

|ExplosionEmitter |No restrictions. |Full support.

|Extrusion |(# _crossSection_ points)×(# _spine_ points) ≤ 2,500. |(#
_crossSection_ points)×(# _spine_ points) ≤ 2,500.

|FillProperties |No restrictions. |Full support.

|FloatVertexAttribute |No restrictions. |Full support.

|Fog |No restrictions. |Full support.

|FogCoordinate |15,000 coordinates. |15,000 coordinates.

|FontStyle |No restrictions. |If the values of the text aspects
character set, _family_, _style_ cannot be simultaneously supported, the
order of precedence shall be: 1) character set 2) _family_ 3) _style_.
X3D browsers shall display all characters in ISO 8859-1 character set
(see <<I8859-1>>).

|ForcePhysicsModel |No restrictions. |Full support.

|GeneratedCubeMapTexture |No restrictions. |Full support.

|GeoCoordinate |15,000 points. |15,000 points.

|GeoElevationGrid |16,000 heights. |16,000 heights.

|GeoLocation |Restrictions as for all groups. |Full support except as
for all groups.

|GeoLOD |Restrictions as for all groups. |Full support.

|GeoMetadata |No restrictions. |Full support.

|GeoOrigin |No restrictions. |Full support.

|GeoPositionInterpolator |1000 key-value pairs. |1000 key-value pairs.

|GeoProximitySensor |No restrictions. |Full support.

|GeoTouchSensor |No restrictions. |Full support.

|GeoTransform |Restrictions as for all groups. |Full support except as
for all groups.

|GeoViewpoint |No restrictions. |Full support.

|Group |Restrictions as for all groups. |Full support except as for all
groups.

|HAnimDisplacer |No restrictions. |Full support.

|HAnimHumanoid |No restrictions. |Full support.

|HAnimJoint |No restrictions. |Full support.

|HAnimSegment |No restrictions. |Full support.

|HAnimSite |No restrictions. |Full support.

|ImageCubeMapTexture |No restrictions. |Full support.

|ImageTexture |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format. Restrictions as for PixelTexture. |JPEG
(<<JPEG>>) and PNG (<<I15948>>) format. Support as
for PixelTexture.

|ImageTexture3D |No restrictions. |Full support.

|IndexedFaceSet |10 vertices per face. 5000 faces. Less than 15,000
indices. |10 vertices per face. 5000 faces. 15,000 indices in any index
field.

|IndexedLineSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedQuadSet |No restrictions. |Full support.

|IndexedTriangleFanSet |15,000 total vertices. 15,000 indices in any
index field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedTriangleSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedTriangleStripSet |15,000 total vertices. 15,000 indices in any
index field. |15,000 total vertices. 15,000 indices in any index field.

|Inline |No restrictions. |Full support except as for all groups.

|IntegerSequencer |No restrictions. |Full support.

|IntegerTrigger |No restrictions. |Full support.

|IsoSurfaceVolumeData |Minimum dimensions: 512 width, 512 height, 512
depth. |Full support.

|KeySensor |No restrictions. |Full support.

|Layer |No restrictions. |Full support.

|LayerSet |At least six layers. |Full support.

|Layout |No restrictions. |Full support.

|LayoutGroup |No restrictions. |Full support.

|LayoutLayer |No restrictions. |Full support.

|LinePickSensor |No restrictions. |Full support.

|LineProperties |No restrictions. |Full support.

|LineSet |15,000 total vertices. |15,000 total vertices.

|LoadSensor |No restrictions. |Full support.

|LocalFog |No restrictions. |Full support.

|LOD |Restrictions as for all groups. |At least first 4 _level_/ _range_
combinations interpreted, and support as for all groups.

|Material |No restrictions. |Full support

|Matrix3VertexAttribute |No restrictions. |Full support.

|Matrix4VertexAttribute |No restrictions. |Full support.

|MetadataBoolean |No restrictions. |Full support.

|MetadataDouble |No restrictions. |Full support.

|MetadataFloat |No restrictions. |Full support.

|MetadataInteger |No restrictions. |Full support.

|MetadataSet |No restrictions. |Full support.

|MetadataString |No restrictions. |Full support.

|MotorJoint |No restrictions. |Full support.

|MovieTexture |MPEG1-Systems and MPEG1-Video formats (see
<<I14496_1, I14496-1>>). |MPEG1-Systems and MPEG1-Video formats (see
<<I14496_1, I14496-1>>). Display one active movie texture.

|MultiTexture |No restrictions. |At least two textures displayed per
node with any number specified. Full support.

|MultiTextureCoordinate |15,000 coordinates. |15,000 coordinates.

|MultiTextureTransform |Restrictions as for all groups. |_addChildren_
optionally supported. _removeChildren_ optionally supported. Otherwise,
full support except as for all groups.

|NavigationInfo |No restrictions. |Full support.

|Normal |15,000 normals |15,000 normals.

|NormalInterpolator |15,000 normals per _keyValue_. Restrictions as for
all interpolators. |15,000 normals per _keyValue_. Support as for all
interpolators.

|NurbsCurve |1500 control points. |Order 30.

|NurbsCurve2D |1500 control points |Order 30.

|NurbsOrientationInterpolator |Restrictions as for all interpolators.
|Full support except as for all interpolators.

|NurbsPatchSurface |1500 control points. |Order 30.

|NurbsPositionInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|NurbsSet |No restrictions. |Full support.

|NurbsSurfaceInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|NurbsSweptSurface |1500 control points. |Order 30.

|NurbsSwungSurface |1500 control points. |Order 30.

|NurbsTextureCoordinate |1500 control points. |Order 30.

|NurbsTrimmedSurface |1500 control points. 10 contours. |Order 30. 10
contours.

|OrientationChaser |No restrictions. |Full support.

|OrientationDamper |No restrictions. |Full support.

|OrientationInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|OrthoViewpoint |No restrictions. |Full support.

|PackagedShader |No restrictions. |Full support.

|ParticleSystem |No restrictions. |Full support.

|PickableGroup |No restrictions. |Full support.

|PixelTexture |512 width. 512 height. |512 width. 512 height. Display
fully transparent and fully opaque pixels.

|PixelTexture3D |No restrictions. |Full support.

|PlaneSensor |No restrictions. |Full support.

|PointEmitter |No restrictions. |Full support.

|PointLight |No restrictions. |Full support.

|PointPickSensor |No restrictions. |Full support.

|PointSet |5000 points. |5000 points.

|Polyline2D |15,000 vertices. |15,000 vertices.

|PolylineEmitter |No restrictions. |Full support.

|Polypoint2D |5000 points. |5000 points.

|PositionChaser |No restrictions. |Full support.

|PositionChaser2D |No restrictions. |Full support.

|PositionDamper |No restrictions. |Full support.

|PositionDamper2D |No restrictions. |Full support.

|PositionInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|PositionInterpolator2D |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|PrimitivePickSensor |No restrictions. |Full support.

|ProgramShader |No restrictions. |Full support.

|ProjectionVolumeStyle |No restrictions. |Full support.

|ProximitySensor |No restrictions. |Full support.

|QuadSet |No restrictions. |Full support.

|ReceiverPDU |No restrictions. |Full support.

|Rectangle2D |No restrictions. |Full support.

|RigidBody |No restrictions. |Full support.

|RigidBodyCollection |No restrictions. |Full support.

|ScalarChaser |No restrictions. |Full support.

|ScalarDamper |No restrictions. |Full support.

|ScalarInterpolator |Restrictions as for all interpolators. |Full
support except as for all interpolators.

|ScreenFontStyle |No restrictions. |Full support.

|ScreenGroup |No restrictions. |Full support.

|Script |25 fields of each access type. |25 fields of each access
type. +
ECMAScript and Java required.

|SegmentedVolumeData |Minimum dimensions: 512 width, 512 height, 512
depth. |Full support.

|ShadedVolumeStyle |No restrictions. |Full support.

|ShaderPart |No restrictions. |Full support.

|ShaderProgram |No restrictions. |Full support.

|Shape |No restrictions. |Full support.

|SignalPDU |No restrictions. |Full support

|SilhouetteEnhancementVolumeStyle |No restrictions. |Full support.

|SingleAxisHingeJoint |No restrictions. |Full support.

|SliderJoint |No restrictions. |Full support.

|Sound |No restrictions. |Full support

|Sphere |No restrictions. |Full support.

|SphereSensor |No restrictions. |Full support.

|SplinePositionInterpolator |No restrictions. |Full support.

|SplinePositionInterpolator2D |No restrictions. |Full support.

|SplineScalarInterpolator |No restrictions. |Full support.

|SpotLight |No restrictions. |Full support.

|SquadOrientationInterpolator |No restrictions. |Full support.

|StaticGroup |No restrictions. |Full support.

|StringSensor |100 characters per string. 100 strings. |Full support.
100 characters per string. 100 strings.

|SurfaceEmitter |No restrictions. |Full support.

|Switch |Restrictions as for all groups. |Full support except as for all
groups.

|TexCoordChaser2D |No restrictions. |Full support.

|TexCoordDamper2D |No restrictions. |Full support.

|Text |100 characters per string. 100 strings. |100 characters per
string. 100 strings.

|TextureBackground |No restrictions. |All fields fully supported. All
texture node types supported in texture fields.

|TextureCoordinate |15,000 coordinates. |15,000 coordinates.

|TextureCoordinate3D |15,000 coordinates. |15,000 coordinates.

|TextureCoordinate4D |15,000 coordinates. |15,000 coordinates.

|TextureCoordinateGenerator |No restrictions. |Full support.

|TextureProperties |No restrictions. |Full support.

|TextureTransform |No restrictions. |Full support.

|TextureTransform3D |No restrictions. |Full support.

|TextureTransformMatrix3D |No restrictions. |Full support.

|TimeSensor |No restrictions. |Full support.

|TimeTrigger |No restrictions. |Full support.

|TouchSensor |No restrictions. |Full support.

|Transform |Restrictions as for all groups. |Full support except as for
all groups.

|TransformSensor |No restrictions. |Full support.

|TransmitterPDU |No restrictions. |Full support.

|TriangleFanSet |15,000 coordinates. |Full support.

|TriangleSet |15,000 coordinates. |Full support.

|TriangleSet2D |15,000 coordinates. |Full support.

|TriangleStripSet |15,000 coordinates. |Full support.

|TwoSidedMaterial |No restrictions. |Full support.

|UniversalJoint |No restrictions. |Full support.

|Viewpoint |No restrictions. |Full support

|ViewpointGroup |No restrictions. |Full support.

|Viewport |No restrictions. |Full support.

|VisibilitySensor |No restrictions. |Always visible.

|VolumeData |Minimum dimensions: 512 width, 512 height, 512 depth. |Full
support.

|VolumeEmitter |No restrictions. |Full support.

|VolumePickSensor |No restrictions. |Full support.

|WindPhysicsModel |No restrictions. |Full support.

|WorldInfo |No restrictions. |Full support.
|===

[[F.6_OtherLimitations]]
=== F.6 Other limitations

<<tF_4, Table F.4>> specifies other aspects of X3D
functionality which are supported by this profile. Note that general
items refer only to those specific nodes listed in
<<tF_3, Table F.3>>.

[[tF_4]]
Table F.4 — Other limitations

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Item |X3D File Limit |Minimum X3D browser Support
|All groups |500 children |500 children. Ignore _bboxCenter_ and
_bboxSize_.

|All interpolators |1000 key-value pairs |1000 key-value pairs.

|All lights |8 simultaneous lights |8 simultaneous lights.

|Names for DEF/PROTO/field |50 utf8 octets |50 utf8 octets.

|All _url_ fields |10 URLs |10 URLs. URN's ignored. +
Support `http', `file', and `ftp' protocols. +
Support relative URLs where relevant.

|Top-level fields |20 fields |20 fields

|Top-level functions |20 functions |20 functions

|PROTO/ +
EXTERNPROTO |30 fields of each access type |30 fields of each access
type

|EXTERNPROTO |n/a |URL references to X3D files conforming to the current
profile/component configuration.

|PROTO definition nesting depth |5 levels |5 levels.

|SFBool |No restrictions |Full support.

|SFColor |No restrictions |Full support.

|SFColorRGBA |No restrictions |Full support.

|SFDouble |No restrictions |Full support. Range ±1e±12. Precision 1e−7.

|SFFloat |No restrictions. |Full support.

|SFImage |512 width. 512 height. |512 width. 512 height.

|SFInt32 |No restrictions. |Full support.

|SFMatrix3d |No restrictions. |Full support.

|SFMatrix3f |No restrictions. |Full support.

|SFMatrix4d |No restrictions. |Full support.

|SFMatrix4f |No restrictions. |Full support.

|SFNode |No restrictions. |Full support.

|SFRotation |No restrictions. |Full support.

|SFString |30,000 utf8 octets. |30,000 utf8 octets.

|SFTime |No restrictions. |Full support.

|SFVec2d |15,000 values. |15,000 values.

|SFVec2f |15,000 values. |15,000 values.

|SFVec3d |15,000 values. |15,000 values.

|SFVec3f |15,000 values. |15,000 values.

|SFVec4d |15,000 values. |15,000 values.

|SFVec4f |15,000 values. |15,000 values.

|MFColor |15,000 values. |15,000 values.

|MFColorRGBA |15,000 values. |15,000 values.

|MFDouble |1000 values. |1000 values.

|MFFloat |1,000 values. |1,000 values.

|MFImage |No restrictions. |Full support.

|MFInt32 |20,000 values. |20,000 values.

|MFMatrix3d |256 values. |256 values.

|MFMatrix3f |256 values. |256 values.

|MFMatrix4d |256 values. |256 values.

|MFMatrix4f |256 values. |256 values.

|MFNode |500 values. |500 values.

|MFRotation |1,000 values. |1,000 values.

|MFString |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.

|MFTime |1,000 values. |1,000 values.

|MFVec2d |15,000 values. |15,000 values.

|MFVec2f |15,000 values. |15,000 values.

|MFVec3d |15,000 values. |15,000 values.

|MFVec3f |15,000 values. |15,000 values.

|MFVec4d |15,000 values. |15,000 values.

|MFVec4f |15,000 values. |15,000 values.
|===

[[behaviours_html]]
== Annex G Recommended navigation behaviours (informative)


[[G_Introduction]]
=== G.1 Introduction and table of contents

This annex describes basic X3D scene navigation recommended practice.
This recommended practice describes an X3D browser-independent
standardized keyboard interface which implements X3D frequently used
scene interactivity. Features that imply interactivity are fundamental
in X3D. The author expects to be able to specify multiple viewpoints in
a predicable sequence, the ability to point and select, and to enable
continuous navigation within the scene. Likewise the interactor expects
to be able to exercise scene functionality using predictable methods.

This recommended practice is intended to allow use of a core subset of
the functionality of an X3D browser, not unnecessarily limit interactive
functionality which may be provided by an X3D browser.

<<tG_1, Table G.1>> lists the major topics in this annex.

[[tG_1]]
Table G.1 — Topics

* <<IntroductionAndTOC, G.1 Introduction and table of contents>>
* <<SelectFromMultipleViewpoints, G.2 Select from multiple viewpoints>>
* <<EmulatePointDevice, G.3 Emulate pointing device>>
* <<SelectOrActivatePointingDevice, G.4 Select or activate pointing device>>
* <<DisableEnableKeyboard, G.5 Disable/enable keyboard>> +
 
* <<tG_1, Table G.1 Topics>>


[[SelectFromMultipleViewpoints]]
=== G.2 Select from multiple viewpoints

User navigation in X3D environments includes definition of multiple
viewpoints. Where the user is allowed to freely select between
viewpoints, typical controls allow simple selection of:

* Home (Initial) ViewPoint,
* Last (Final) Viewpoint,
* Next Viewpoint in Sequence, and
* Previous Viewpoint in Sequence.

This annex recommends using the following keys:

[source,listing]
----
HOME    Initial Viewpoint 
PGDN    Next Viewpoint 
PGUP    Previous Viewpoint 
END     Final Viewpoint 
----

[[EmulatePointDevice]]
=== G.3 Emulate pointing device

The pointing device is used to control navigation through the scene.
Where the user is allowed to interact using the pointing device, typical
controls allow up/down/right/left pointing device movement to control
movement of the viewpoint.

The objective is not to actually move the screen tracking cursor, but to
allow navigation control as if the tracking cursor or pointer is moved
under control of the pointing device.

This annex recommends using the following (arrow) keys to emulate
relative tracking pointer movement as follows:

[source,listing]
----
UP        Up  
DOWN      Down 
LEFT      Left
RIGHT     Right
----

Movement left/right/up/down refers to motion of the user's view while
navigating.

Activation of these keys causes movement of the viewpoint according to
currently selected navigation type:

[source,listing]
----
WALK:      forward/backward/left/right
FLY:       forward/backward/left/right
EXAMINE:   orbit up/down/left/right around center of rotation
           with camera pointed at center of rotation
----

[[SelectOrActivatePointingDevice]]
=== G.4 Select or activate pointing device

The pointing device is used to provide a means of selecting of a scene
element. Where the user is allowed to use this, the following action is
recommended: activate pointing device (left mouse click).

This annex recommends using the following key:

[source,listing]
----
ENTER  Left Mouse Click
----

[[DisableEnableKeyboard]]
=== G.5 Disable/enable keyboard

It is recommended that the X3D browser provide a means for the author to
enable and disable the keyboard.

[[CADInterchange_html]]
== Annex H CADInterchange profile (normative)

[[H.1_General]]
=== H.1 General

This annex defines the X3D components that comprise the CADInterchange
profile. This annex includes not only the nodes that shall be supported
but also which fields in the supported nodes may be ignored.

The name of this profile is "CADInterchange". This profile is targeted
towards:

* Distillation of computer-aided design (CAD) data to downstream
applications.
* Appropriately supporting Geometry and Appearance capabilities data for
CAD.

[[H.2_Topics]]
=== H.2 Topics

<<tH_1, Table H.1>> provides links to the major topics in this
annex.

[[tH_1]]
Table H.1 — Topics

* <<H.1_General, H.1 General>>
* <<H.2_Topics, H.2 Topics in this annex>>
* <<H.3_ComponentSupport, H.3 Component support>>
* <<H.4_ConformanceCriteria, H.4 Conformance criteria>>
* <<H.5_NodeSet, H.5 Node set>>
* <<H.6_OtherLimitations, H.6 Other limitations>>

* <<tH_1, Table H.1 — Topics>>
* <<tH_2, Table H.2 — Components and levels>>
* <<tH_3, Table H.3 — Nodes for conforming to the CADInterchange profile>>
* <<tH_4, Table H.4 — Other limitations>>
* <<NodeSet, Table H.5 — Node set>>


[[H.3_ComponentSupport]]
=== H.3 Component support

<<tH_2, Table H.2>> lists the components and their
levels which shall be supported in the CADInterchange profile. Tables
H.2 and H.3 describe limitations on required support for nodes and
fields contained within these components.

[[tH_2]]
Table H.2 — Components and levels

[cols=",,",]
|===
|Component   |Level |Reference
|Core        |1 |<<S7_SupportLevels, 7.5 Support levels>>
|Networking  |2 |<<S9_SupportLevels, 9.5 Support levels>>
|Grouping    |1 |<<S10_SupportLevels, 10.5 Support levels>>
|Rendering   |4 |<<S11_SupportLevels, 11.5 Support levels>>
|Shape       |2 |<<S12_SupportLevels, 12.5 Support levels>>
|Lighting    |1 |<<S17_SupportLevels, 17.5 Support levels>>
|Texturing   |2 |<<S18_SupportLevels, 18.5 Support levels>>
|Navigation  |3 |<<S23_SupportLevels, 23.5 Support levels>>
|Shaders     |1 |<<S31_SupportLevels, 31.5 Support levels>>
|CADGeometry |2 |<<S32_SupportLevels, 32.5 Support levels>>
|===

[[H.4_ConformanceCriteria]]
=== H.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tH_2, Table H.2>>.

In Tables H.3 and H.4, the first column defines the item for which
conformance is being defined. In some cases, general limits are defined
but are later overridden in specific cases by more restrictive limits.
The second column defines the requirements for an X3D file conforming to
the CADInterchange profile; if an X3D file contains any items that
exceed these limits, it may not be possible for an X3D browser
conforming to the CADInterchange profile to successfully parse that X3D
file. The third column defines the minimum complexity for an X3D scene
that an X3D browser conforming to the CADInterchange profile shall be
able to present to the user. Fields flagged as "not supported" may be
supported by X3D browsers which conform to the CADInterchange profile.
The word "ignore" in the minimum X3D browser support column refers only
to the display of the item; in particular, _set__ events to ignored
inputOutput fields shall still generate corresponding __changed_ events.

[[H.5_NodeSet]]
=== H.5 Node set

<<tH_3, Table H.3>> lists the nodes which
shall be supported in the CADInterchange profile and specifies any
fields in these nodes for which this profile requires less than full
support.

[[tH_3]]
Table H.3 — Nodes for conforming
to the CADInterchange profile

[width="100%",cols="34%,33%,33%",]
|===
|Item |X3D File Limit |Minimum X3D browser Support

|Anchor |No restrictions. |Full support.

|Appearance |No restrictions. |_fillProperties_ not supported.

|CADAssembly |No restrictions. |Full support.

|CADFace |No restrictions. |Full support.

|CADLayer |No restrictions. |Full Support

|CADPart |No restrictions. |Full support.

|Billboard |No restrictions. |Can treat as just a grouping node, no
runtime requirements

|Collision |No restrictions. |Can treat as just a grouping node, no
runtime requirements

|Color |5,592,405 colours. |5,592,405 colours.

|ColorRGBA |4,194,304 colours. |4,194,304 colours

|Coordinate |16,777,216 points |16,777,216 points.

|DirectionalLight |No restrictions. |Full support.

|FillProperties |No restrictions. |Full support.

|FragmentShader |No restrictions. |Full support.

|Group |Restrictions as for all groups. |_addChildren_ not supported.
_removeChildren_ not supported. Otherwise as for all groups.

|ImageTexture |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format. |JPEG (<<JPEG>>) and PNG
(<<I15948>>) format.

|IndexedLineSet |5,592,405 total vertices. 5,592,405 indices in any
index field. |5,592,405 total vertices. 5,592,405 indices in any index
field.

|IndexedQuadSet |5,592,405 total faces. 5,592,405 indices in any index
field. |5,592,405 total faces. 5,592,405 indices in any index field.

|IndexedTriangleFanSet |5,592,405 total faces. 5,592,405 indices in any
index field. |5,592,405 total faces. 5,592,405 indices in any index
field.

|IndexedTriangleSet |5,592,405 total faces. 5,592,405 indices in any
index field. |5,592,405 total faces. 5,592,405 indices in any index
field.

|IndexedTriangleStripSet |5,592,405 total faces. 5,592,405 indices in
any index field. |5,592,405 total faces. 5,592,405 indices in any index
field.

|Inline |No restrictions. |Optional support for _load_ field. Other
fields full support.

|LineProperties |No restrictions. |Full support.

|LineSet |5,592,405 total vertices. |5,592,405 total vertices.

|LOD |No restrictions. |Runtime switching not required. An
implementation can select one level and display

|Material |No restrictions. |Full support.

|MetadataBoolean |No restrictions. |Full support.

|MetadataDouble |No restrictions. |Full support.

|MetadataFloat |No restrictions. |Full support.

|MetadataInteger |No restrictions. |Full support.

|MetadataSet |No restrictions. |Full support.

|MetadataString |No restrictions. |Full support.

|MultiShader |No restrictions. |Full support.

|MultiTexture |No restrictions. a|
At least one texture displayed per node with any number specified.

Full support.

|MultiTextureCoordinate |15,000 coordinates. |15,000 coordinates.

|MultiTextureTransform |No restrictions. |Full support.

|NavigationInfo |No restrictions. |_avatarSize_ optionally supported.
_speed_ optionally supported. _type_ optionally supported.
_visibilityLimit_ optionally supported.

|Normal |5,592,405 normals |5,592,405 normals.

|OrthoViewpoint |No restrictions. |Full support.

|PixelTexture |512 width. 512 height. |512 width. 512 height. Display
fully transparent and fully opaque pixels.

|PointProperties |No restrictions. |Full support.

|PointSet |5,592,405 points. |5,592,405 points.

|QuadSet |5,592,405 total faces. 5,592,405 indices in any index field.
|5,592,405 total faces. 5,592,405 indices in any index field.

|Shader |No restrictions. |Full support.

|ShaderAppearance |No restrictions. |Full support.

|Shape |No restrictions. |Full support.

|TextureCoordinate |5,592,405 coordinates. |5,592,405 coordinates.

|TextureCoordinateGenerator |No restrictions. |Full support.

|TextureTransform |No restrictions. |Full support.

|Transform |Restrictions as for all groups. |_addChildren_ not
supported. _removeChildren_ not supported. Otherwise, full support
except as for all groups.

|TriangleFanSet |5,592,405 triangles per fan. 5,592,405 total triangles.
|5,592,405 triangles per fan. 5,592,405 total triangles.

|TriangleSet |5,592,405 triangles |5,592,405 triangles

|TriangleStripSet |5,592,405 triangles per strip. 5,592,405 total
triangles |5,592,405 triangles per strip. 5,592,405 total triangles.

|VertexShader |No restrictions. |Full support.

|Viewpoint |No restrictions. |Full support.

|ViewpointGroup |No restrictions. |Full support.

|WorldInfo |No restrictions. |Full support.
|===

[[H.6_OtherLimitations]]
=== H.6 Other limitations

<<tH_4, Table H.4>> specifies other aspects of X3D
functionality which are supported by this profile. Note that general
items refer only to those specific nodes listed in
<<tH_3, Table H.3>>.

[[tH_4]]
Table H.4 — Other limitations

[width="100%",cols="34%,33%,33%",]
|===
|Item |X3D File Limit |Minimum X3D browser Support

|All groups |16777216 children. |16777216 children.

|All lights |8 simultaneous lights. |8 simultaneous lights.

|Names for DEF/field |50 utf8 octets. |50 utf8 octets.

|All _url_ fields |10 URLs. |10 URLs. URN's ignored. +
Support "http", "file", and "ftp" protocols. +
Support relative URLs where relevant.

|SFBool |No restrictions. |Full support.

|SFColor |No restrictions. |Full support.

|SFColorRGBA |No restrictions. |Full support.

|SFDouble |No restrictions. |Full support. Range ±1e±12. Precision 1e-7.

|SFFloat |No restrictions. |Full support.

|SFImage |512 width. 512 height. |512 width. 512 height.

|SFInt32 |No restrictions. |Full support.

|SFNode |No restrictions. |Full support.

|SFRotation |No restrictions. |Full support.

|SFString |30,000 utf8 octets. |30,000 utf8 octets.

|SFTime |No restrictions. |Full support.

|SFVec2d |15,000 values. |15,000 values.

|SFVec2f |15,000 values. |15,000 values.

|SFVec3d |15,000 values. |15,000 values.

|SFVec3f |15,000 values. |15,000 values.

|MFColor |15,000 values. |15,000 values.

|MFColorRGBA |15,000 values. |15,000 values.

|MFDouble |1000 values. |1000 values.

|MFFloat |1,000 values. |1,000 values.

|MFImage |No restrictions. |Full support.

|MFInt32 |20,000 values. |20,000 values.

|MFNode |500 values. |500 values.

|MFRotation |1,000 values. |1,000 values.

|MFString |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.

|MFTime |1,000 values. |1,000 values.

|MFVec2d |15,000 values. |15,000 values.

|MFVec2f |15,000 values. |15,000 values.

|MFVec3d |15,000 values. |15,000 values.

|MFVec3f |15,000 values. |15,000 values.
|===

[[shaders_glsl_html]]
== Annex I OpenGL shading language (GLSL) binding (normative)

[[I.1_General]]
=== I.1 General

This annex defines the mapping of concepts of the programmable shaders
component to the OpenGL Shading Language (GLSL) (see
<<GLSL>>). It applies to a ComposedShader node that sets the
_language_ field to "GLSL".

[[I.2_Topics]]
=== I.2 Topics

<<tI_1, Table I.1>> provides links to the major topics in this annex.

[[tI_1]]
Table I.1 — Topics

* <<I.1_General, I.1 General>>
* <<I.2_Topics, I.2 Topics>>
* <<I.3_Interaction, I.3 Interaction with Other Nodes and Components>>
** <<I.3_Vertexshader, I.3.1 Vertex Shader>>
** <<I.3_Fragmentshader, I.3.2 Fragment Shader>>
** <<I.3_Loadsensor, I.3.3 LoadSensor>>
** <<I.3_Vertexattributes, I.3.4 VertexAttributes>>
* <<I.4_DataTypeMapping, I.4 Data Type Mapping>>
** <<I.4_NodeFields, I.4.1 Node fields>>
** <<I.4_OtherFields, I.4.2 X3D Field types to OpenGL Data Types>>
* <<I.5_Eventmodel, I.5 Event Model>>
** <<I.5_Changingurlfield, I.5.1 Changing URL fields>>
** <<Changingobjectsfield, I.5.2 Changing the _object_ field>>
** <<I.5_Changingattribfield, I.5.3 Changing the _attrib_ field>>
** <<relinkingprograms, I.5.4 Relinking Programs>>
* <<tI_1, Table I.1 — Topics>>
* <<tI_2, Table I.2 — Mapping of X3D texture node types to GLSL sampler types>>
* <<tI_3, Table I.3 — Mapping of X3D Field typesto GLSL data types>>


[[I.3_Interaction]]
=== I.3 Interaction with other nodes and components

[[I.3_Vertexshader]]
==== I.3.1 Vertex shader

The vertex shader replaces the fixed functionality of the vertex
processor. The GLSL specification (see <<GLSL>>) states that
the following functionality is disabled if a vertex shader is supplied:

[loweralpha]
. The model view matrix is not applied to vertex coordinates.
. The projection matrix is not applied to vertex coordinates.
. The texture matrices are not applied to texture coordinates.
. The normals are not transformed to eye coordinates.
. The normals are not rescaled or normalized.
. Texture coordinates are not generated automatically.
. Per-vertex lighting is not performed.
. Color material lighting is not performed.
. Point size distance attenuation is not performed.

[[I.3_Fragmentshader]]
==== I.3.2 Fragment shader

The fragment shader replaces the fixed functionality of the fragment
processor. The GLSL specification  (see <<GLSL>>) states that
the following functionality is disabled if a fragment shader is
supplied:

[loweralpha]
. Textures are not applied.
. Fog is not applied.

[[I.3_Loadsensor]]
==== I.3.3 LoadSensor

The LoadSensor node (See <<S9_LoadSensor, 9.4.3 LoadSensor>>) has two
output fields _isActive_ and _isLoaded_. The _isLoaded_ field behaviour
is unchanged.

The _isActive_ field is defined to issue a `TRUE` event when all
the following conditions have been satisfied:

[loweralpha]
. the content identified by the _url_ field has been successfully
loaded;
. a valid OpenGL program object handle has been created for the shader
object (`GLhandleARB` in OpenGL 1.5 and `uint` in OpenGL
2.0);
. the shader source has been set without error; and
. the shader has been successfully compiled, without error.

The LoadSensor node does not have any interaction with the process of
linking multiple shader objects into a complete shader program.

[[I.3_Vertexattributes]]
==== I.3.4 Vertex attributes

Each vertex attribute node directly maps the _name_ field to the uniform
variable of the same name. If the name is not available as a uniform
variable in the provided shader source, the values of the node shall be
ignored.

The X3D browser implementation shall automatically assign appropriate
internal index values for each attribute.

[[I.4_DataTypeMapping]]
=== I.4 Data type mapping

[[I.4_NodeFields]]
==== I.4.1 Node fields

Fields that are of type SFNode/MFNode are ignored unless the value is of
type _X3DTextureNode_. Field instances of type _X3DTextureNode_ are
mapped according to the appropriate sampler data type. The texture types
are mapped as defined in <<tI_2, Table I.2>>.

[[tI_2]]
Table I.2 — Mapping of X3D texture node types to GLSL sampler types

[cols=",",options="header",]
|===
|X3D texture type            |GLSL variable type
|_X3DTexture2DNode_          |sampler2D.
|_X3DTexture3DNode_          |sampler3D.
|_X3DEnvironmentTextureNode_ |samplerCube.
|===

X3D does not define mappings to the GLSL types sampler1D,
sampler1DShadow and sampler2DShadow.

[[I.4_OtherFields]]
==== I.4.2 X3D Field types to GLSL data types

<<tI_3, Table I.3>> indicates how the X3D field types
shall be mapped to data types used in GLSL.

[[tI_3]]
Table I.3 — Mapping of X3D field types to GLSL
data types

[cols=",",options="header",]
|===
|X3D field type |GLSL variable type
|SFBool |bool
|MFBool |bool[]
|SFInt32 |int
|MFInt32 |int[]
|SFFloat |float
|MFFloat |float[]
|SFDouble |float
|MFDouble |float[]
|SFTime |float
|MFTime |float[]
|SFNode |See <<S4_NodeFields, 4.1 Node fields>>
|MFNode |See <<S4_NodeFields, 4.1 Node fields>>
|SFVec2f |vec2
|MFVec2f |vec2[]
|SFVec3f |vec3
|MFVec3f |vec3[]
|SFVec4f |vec4
|MFVec4f |vec4[]
|SFVec3d |float3
|MFVec3d |float3[]
|SFVec4d |float4
|MFVec4d |float4[]
|SFRotation |vec4
|MFRotation |vec4[]
|SFColor |vec3
|MFColor |vec3[]
|SFColorRGBA |vec4
|MFColorRGBA |vec4[]
|SFImage |int[]
|MFImage |int[]
|SFString |Not supported
|MFString |Not supported
|SFMatrix3f |mat3
|MFMatrix3f |mat3[]
|SFMatrix4f |mat4
|MFMatrix4f |mat4[]
|===

OpenGL defines maximum supported lengths of each array data type, which
may conflict with the minimum support requirements for X3D. OpenGL will
automatically convert double-precision data types to single precision
types.

[[I.5_Eventmodel]]
=== I.5 Event model

[[I.5_Changingurlfield]]
==== I.5.1 Changing URL fields

When the _url_ receives an event changing the value, the X3D browser
shall immediately attempt to download the new source. Upon successful
download, the browser shall attempt to compile the new source and issue
the appropriate LoadSensor events. It shall not automatically relink the
shader program, nor disable the currently running shader. This follows
the semantics of the OpenGL API requirements for separate
register-compile-link steps.

Values defined at load time of the file do not require an explicit
request to relink. It shall be assumed to automatically link once all
the objects have successfully downloaded. If some of the shader source
files are not downloaded or compiled ( _e.g._, due to errors), no
linking will occur for the shader program.

[[Changingobjectsfield]]
==== I.5.2 Changing the _object_ field

If at any time after the initial load, the user changes the values of
the _object_ field, the user shall need to request an explicit relink of
the containing shader program. The containing ComposedShader shall not
automatically relink, nor should it automatically disable the current
shader.

[[I.5_Changingattribfield]]
==== I.5.3 Changing the _attrib_ field

Per-vertex attributes may be defined as one of the fields of
_X3DComposedGeometryNode_. These may be changed at runtime by adding or
removing node instances. Adding new node instances to the field shall
require that the user request an explicit relink in order to make them
visible to the shader.

[[relinkingprograms]]
==== I.5.4 Relinking Programs

The user may, at any time, request that OpenGL re-link the composing
shader objects by sending a `TRUE` value to the _activate_
inputOnly field of the ComposedShader node. Users may need to force a
relink of the ComposedShader under various circumstances, such as
changing the _url_ field of one or more ShaderPart nodes, or adding or
removing ShaderPart nodes. Relinking the shader shall replace the
existing shader with the new executable.

[[shaders_hlsl_html]]
== Annex J Microsoft high level shading language (HLSL) binding (normative)


[[J.1_General]]
=== J.1 General

This annex defines the mapping of concepts of the programmable shaders
component to the Microsoft High Level Shading Language (HLSL) (see
<<HLSL>>). It applies to the ProgramShader, ShaderProgram and
PackagedShader nodes with the _language_ field set to "HLSL".

[[J.2_Topics]]
=== J.2 Topics

<<tJ_1, Table 1>> provides links to the major topics in this annex.

[[tJ_1]]
Table J.1 — Topics

* <<J.1_General, J.1 General>>
* <<J.2_Topics, J.2 Topics>>
* <<J.3_Interaction, J.3 Interaction with other nodes and components>>
** <<J.3_Vertexshader, J.3.1 Vertex shader>>
** <<J.3_Fragmentshader, J.3.2 Fragment shader>>
** <<J.3_Loadsensor, J.3.3 LoadSensor>>
** <<J.3_Vertexattributes, J.3.4 Vertex attributes>>
* <<J.4_DataTypeMapping, J.4 Data type and parameter mappings>>
** <<J.4_NodeFields, J.4.1 Node fields>>
** <<J.4_OtherFields, J.4.2 X3D field types to HLSL data types>>
** <<J.4_Worldstate, J.4.3 X3D world state to HLSL parameter names>>
* <<J.5_Eventmodel, J.5 Event Model>>
** <<J.5_Changingurlfield, J.5.1 Changing URL fields>>
** <<J.5_Changingattribfield, J.5.2 Changing the _attrib_ field>>
** <<J.5_activatingprograms, J.5.3 Activating programs>>
* <<tJ_1, Table J.1 — Topics>>
* <<tJ_2, Table J.2 — Supported Direct3D vertex declaration usage types>>
* <<tJ_3, Table J.3 — Mapping of X3D texture node types to HLSLsampler types>>
* <<tJ_4, Table J.4 — Mapping of X3D material and light node types to HLSL structure declarations>>
* <<tJ_5, Table J.5 — Mapping of X3D field types to HLSL data types>>
* <<tJ_6, Table J.6 — Mapping of X3D world State to HLSL parameter names>>


[[J.3_Interaction]]
=== J.3 Interaction with other nodes and components

[[J.3_Vertexshader]]
==== J.3.1 Vertex shader

The vertex shader replaces the vertex processing done by the Microsoft
Direct3D graphics pipeline. While using a vertex shader, state
information regarding transformation and lighting operations is ignored
by the fixed-function pipeline. The HLSL specification states that the
following functionality is disabled if a vertex shader is supplied:

[loweralpha]
. The model view matrix is not applied to vertex coordinates.
. The projection matrix is not applied to vertex coordinates.
. The texture matrices are not applied to texture coordinates.
. The normals are not transformed to eye coordinates.
. The normals are not rescaled or normalized.
. Texture coordinates are not generated automatically.
. Per vertex lighting is not performed.
. Color material lighting is not performed.
. Point size distance attenuation is not performed.

The fixed-function pipeline Direct3D graphics state is not available for
use within an HLSL shader program. Shaders that wish to make use of this
data, such as material, lighting, texture and transformation matrix
state, shall declare parameters of the appropriate type and pass values
into them via declared fields of the containing ShaderProgram node in
the X3D scene graph. The parameter types and mappings to those types
from built-in X3D values are defined in <<J.4_DataTypeMapping, J.4 Data type and parameter mappings>>.

[[J.3_Fragmentshader]]
==== J.3.2 Fragment Shader

The fragment shader, also know as a _pixel_ shader in HLSL, replaces the
fixed functionality of the Direct3D fragment processor. The HLSL
specification states that textures are not applied if a fragment shader
is supplied.

The fixed function pipeline Direct3D graphics state is not available for
use within an HLSL pixel shader program. Shaders that wish to make use
of this data, such as material, lighting, texture and transformation
matrix state, shall declare parameters of the appropriate type and pass
values into them via declared fields of the containing ShaderProgram
node in the X3D scene graph. The parameter types and mappings to those
types from built-in X3D values are defined in <<J.4_DataTypeMapping, J.4 Data type and parameter mappings>>.

[[J.3_Loadsensor]]
==== J.3.3 LoadSensor

The LoadSensor node (See <<S9_LoadSensor, 9.4.3 LoadSensor>>) has two
output fields _isActive_ and _isLoaded_. The _isLoaded_ field behaviour
is unchanged.

The _isActive_ field is defined to issue a `TRUE` event when all
the following conditions have been satisfied:

[loweralpha]
. The content identified by the _url_ field has been successfully
loaded.
. The shader program has been successfully compiled without error.

[[J.3_Vertexattributes]]
==== J.3.4 Vertex attributes

Each vertex attribute node directly maps the _name_ field to a Direct3D
usage type for use within a Direct3D vertex declaration (with the prefix
"`D3DDECLUSAGE_`" prepended to the name), as well as an HLSL
binding semantic of the same name defined on the varying inputs to a
shader program. This language binding allows the use of the predefined
Direct3D vertex declaration usage types and HLSL binding semantics
listed in <<tJ_2, Table J.2>>.

[[tJ_2]]
Table J.2 — Supported Direct3D
vertex declaration usage types

[cols="",options="header",]
|===
|Direct3D usage type
|_POSITION_
|_NORMAL_
|_TEXCOORD_
|_TANGENT_
|_BINORMAL_
|_COLOR_
|_FOG_
|===

The X3D browser implementation shall automatically assign appropriate
internal index values for each attribute in the case where multiple
nodes have the same value in the _name_ field.

[[J.4_DataTypeMapping]]
=== J.4 Data Type and Parameter Mappings

[[J.4_NodeFields]]
==== J.4.1 Node fields

Fields that are of type SFNode/MFNode are ignored unless the value is of
type _X3DTextureNode_, _X3DMaterialNode_, or _X3DLightNode_. Field
instances of type _X3DTextureNode_ are mapped according to the
appropriate Direct3D sampler data type. The mapping from texture nodes
to built-in sampler types is defined in
<<tJ_3, Table J.3>>.

[[tJ_3]]
Table J.3 — Mapping of X3D texture node
types to HLSL sampler types

[cols=",",options="header",]
|===
|X3D Texture type |HLSL variable type
|_X3DTexture2DNode_ |sampler2D
|_X3DTexture3DNode_ |sampler3D
|_X3DEnvironmentTextureNode_ |samplerCube
|===

X3D does not define mappings to the HLSL types sampler1D,
sampler1DShadow and sampler2DShadow.

Field instances of type _X3DMaterialNode_ and _X3DLightNode_ are mapped
to structures that shall be declared in the shader program as defined in
<<tJ_4, Table J.4>>.

[[tJ_4]]
Table J.4 — Mapping of X3D material and light
node types to HLSL structure declarations

[width="100%",cols="34%,33%,33%",options="header",]
|===
|X3D node type |HLSL structure declaration |Additional information
|_X3DMaterialNode_ a|
....
struct X3DMaterial {
    float4 diffuseColor;
    float4 ambientColor;
    float4 specularColor;
    float4 emissiveColor;
    float power;
};
....

|All color values are 4-component with alpha value = 1.0.

|_X3DLightNode_ a|
....
struct X3DLight {
    int type;
    float4 diffuseColor;
    float4 specularColor;
    float4 ambientColor;
    point3 position;
    point3 direction;
    float range;
    float falloff;
    float attenuation0;
    float attenuation1;
    float attenuation2;
    float theta;
    float phi;
    bool on;
};
....

|Valid _type_ member values are 1 for Point light, 2 for Spot light and
3 for Direction light. +
All color values are 4-component with alpha value = 1.0. +
All position, direction and scalar values are assumed to be in world
space. +
The _on_ member specifies whether the light is enabled. +
|===

[[J.4_OtherFields]]
==== J.4.2 X3D field types to HLSL data types

<<tJ_5, Table J.5>> specifies the mapping of X3D field
types to data types used in the HLSL Language.

[[tJ_5]]
Table J.5 — Mapping of X3D Field Types to HLSL
Data Types

[cols=",",options="header",]
|===
|X3D Field type |HLSL Data Type
|SFBool |bool
|MFBool |bool[]
|MFInt32 |int[]
|SFInt32 |int
|SFFloat |float
|MFFloat |float[]
|SFDouble |double
|MFDouble |double[]
|SFTime |double
|MFTime |double[]
|SFNode |See <<J.4_NodeFields, J.4.1 Node fields>>
|MFNode |See <<J.4_NodeFields, J.4.1 Node fields>>
|SFVec2f |float2
|MFVec2f |float2[]
|SFVec3f |float3
|MFVec3f |float3[]
|SFVec4f |float4
|MFVec4f |float4[]
|SFVec3d |float3
|MFVec3d |float3[]
|SFVec4d |float4
|MFVec4d |float4[]
|SFRotation |float4
|MFRotation |float4[]
|MFColor |float4[]
|SFColor |float4
|SFImage |int[]
|MFImage |int[]
|SFString |Not supported
|MFString |Not supported
|SFMatrix3f |float3x3
|MFMatrix3f |float3x3[]
|SFMatrix4f |float4x4
|MFMatrix4f |float4x4[]
|===

HLSL defines maximum supported lengths of each array data type, which
may conflict with the minimum support requirements for X3D.

[[J.4_Worldstate]]
=== J.4.3 X3D world state to HLSL parameter names

Certain internal states of the X3D world, such as transformation
matrices, or the viewer's position in world space, are neither readily
available via the HLSL shader program nor directly accessible from the
X3D scene graph. Thus, if used, these state values shall be explicitly
passed in to the shader program as named parameters. This binding
defines an automatic mapping of these states to predefined shader
program parameter names. <<tJ_6, Table J.6>> defines
the mapping of internal states of the X3D world to parameter names used
in HLSL programs.

[[tJ_6]]
Table J.6 — Mapping of X3D world state to
HLSL parameter names

[cols=",",options="header",]
|===
|Parameter name |Description
|*model* |This name refers to the matrix transforming from local to
global coordinates. The model matrix transforms vertices from their
model position to their position in world space ( _i.e._, after the
effects of all Transform nodes have been applied).

|*view* |This name refers to the viewing matrix transforming from world
to view relative coordinates.

|*projection* |This name refers to the projection matrix transforming
from viewing relative coordinates to clip space, including the
projective part.

|*modelView* |This name refers to the matrix that represents the
concatenation of model and view matrices. This matrix transforms
vertices from their model position to their position in view space (
_i.e._, after the effects of all Transform nodes and the current
viewpoint have been applied).

|*modelViewProjection* |This name refers to the matrix that represents
the concatenation of model, view and projection matrices. This matrix
transforms vertices from their model position to their final position in
clip space.

|*viewPosition* |This name refers to the current viewer position in
world space coordinates.
|===

The following suffixes can be applied to the matrix built-in values. A
suffix of _I_ signifies the inverse of the matrix. _T_ signifies the
transpose of the matrix. _IT_ signifies the inverse transpose of the
matrix.

[[J.5_Eventmodel]]
=== J.5 Event model

[[J.5_Changingurlfield]]
==== J.5.1 Changing URL fields

When the _url_ receives an event changing the value, the X3D browser
shall immediately attempt to download the new source. Upon successful
download, the browser shall attempt to compile the new source and issue
the appropriate LoadSensor events. It shall not automatically activate
the shader program, nor disable the currently running shader.

Values defined at load time of the file do not require an explicit
request to activate the shader program. The X3D browser shall be assumed
to automatically activate the program once all the objects have
successfully downloaded. If some of the shader source files are not
downloaded or compiled ( _e.g._, due to errors) no activation will occur
for the shader program.

[[J.5_Changingattribfield]]
==== J.5.2 Changing the _attrib_ field

Per-vertex attributes may be defined as one of the fields of
_X3DComposedGeometryNode_. These may be changed at runtime by adding or
removing node instances. Adding new node instances to the field shall
require that the user request an explicit activate in order to make them
visible to the shader.

[[J.5_activatingprograms]]
==== J.5.3 Activating programs

The user may, at any time, request that the X3D browser activate the
composing shader objects by sending a `TRUE` value to the
_activate_ inputOnly field of the ProgramShader or PackagedShader node.
Users may need to force a re-activation of the node under various
circumstances, such as changing the _url_ field of one or more
ShaderProgram or PackagedShader nodes, or adding or removing
ShaderProgram nodes from the _programs_ field of the ProgramShader node.
Reactivating the shader shall replace the existing shader with the new
compiled shader for subsequent rendering.

[[shaders_cg_html]]
== Annex K nVidia Cg shading language binding (normative)


[[K.1_General]]
=== K.1 General

This annex defines the mapping of concepts of the Programmable shaders
component to the nVidia Cg shading language (see <<Cg>>). It
applies to the ProgramShader, ShaderProgram and PackagedShader nodes
with the _language_ field set to "Cg".

[[K.2_Topics]]
=== K.2 Topics

<<tK_1, Table K.1>> provides links to the major topics in this annex.

[[tK_1]]
Table K.1 — Topics

* <<K.1_General, K.1 General>>
* <<K.2_Topics, K.2 Topics>>
* <<Concepts, K.3 Concepts>>
** <<RenderingAPISupportDifferences, K.3.1 Rendering API support differences>>
** <<LanguageStrings, K.3.2 Language strings>>
* <<K.4_Interaction, K.4 Interaction with other nodes and components>>
** <<RenderingAPISupportDifferences, K.4.1 Vertex shader>>
*** <<VertexshaderOpenGL, K.4.1.1 OpenGL profiles>>
*** <<VertexshaderDirect3D, K.4.1.2 Direct3D profiles>>
** <<K.4_Fragmentshader, K.4.2 Fragment shader>>
*** <<FragmentshaderOpenGL, K.4.2.1 OpenGL profiles>>
*** <<FragmentshaderDirect3D, K.4.2.2 Direct3D profiles>>
** <<K.4_Loadsensor, K.4.3 LoadSensor>>
** <<K.4_Vertexattributes, K.4.4 Vertex attributes>>
*** <<VertexattributesOpenGL, K.4.4.1 OpenGL profiles>>
*** <<VertexattributesDirect3D, K.4.4.2 Direct3D profiles>>
* <<K.5_DataTypeMapping, K.5 Data type and parameter mappings>>
** <<K.5_NodeFields, K.5.1 Node fields>>
** <<K.5_OtherFields, K.5.2 X3D field types to Cg data types>>
** <<K.5_Worldstate, K.5.3 X3D world state to Cg parameter names>>
* <<K.6_Eventmodel, K.6 Event model>>
** <<K.6_Changingurlfield, K.6.1 Changing URL fields>>
** <<K.6_Changingattribfield, K.6.2 Changing the _attrib_ field>>
** <<K.6_activatingprograms, K.6.3 Activating programs>>

* <<tK_1, Table K.1 — Topics>>
* <<tK_2, Table K.2 — Language string to Cg profile mapping>>
* <<tK_3, Table K.3 — Supported Direct3D vertex declaration usage types>>
* <<tK_4, Table K.4 — Mapping of X3D texture node types to Cg sampler types>>
* <<tK_5, Table K.5 — Mapping of X3D material and light node types to Cg structure declarations>>
* <<tK_6, Table K.6 — Mapping of X3D field types to Cg data types>>
* <<tK_7, Table K.7 — Mapping of X3D world state to Cg parameter names>>




[[K_Concepts]]
=== K.3 Concepts

[[RenderingAPISupportDifferences]]
==== K.3.1 Rendering API support differences

The Cg language is a diverse set of shading capabilities that aim to
support programmable shaders for a variety of APIs. This document
supports the OpenGL and Microsoft Direct3D APIs. Programming APIs may
express the same concepts in very distinctly different ways and the two
cited APIs do so. Thus, a Cg shader program written to work on OpenGL
will not work on Direct3D. Conversely, a Cg shader program written to
work on Direct3D will not work on OpenGL.

Cg handles the incompatible code problem by defining _Cg profiles_. A Cg
profile is a set of available shading language functionality. At the
time the browser downloads the file, it can use the profile information
to guide how to compile the code to the appropriate target. This annex
defines its behaviour based on the Cg profile specified by the user.

[[LanguageStrings]]
==== K.3.2 Language strings

Cg profile information is encoded as part of the language string of the
ProgramShader node. All strings starting with "CG-" define behaviour
defined in this annex. The part after the prefix defines the programming
API and profile for which the Cg code shall be compiled. A X3D browser
thus may quickly distinguish which nodes to ignore and which to
investigate further. The source files are referenced in the
ShaderProgram nodes. This document requires that the same profile is
used for both the vertex and fragment programs.

<<tK_2, Table K.2>> defines the mappings between the
language string and the appropriate Cg profile. As Cg evolves, newer
profiles may be defined and shall follow a similar naming convention.

[[tK_2]]
Table K.2 — Language string to Cg profile mapping

[cols=",,",options="header",]
|===
|Language string   |Cg vertex shader profile |Cg fragment shader profile
|CG_OPENGL_ARB     |CG_PROFILE_ARBVP1 |CG_PROFILE_ARBFP1
|CG_OPENGL_NV30    |CG_PROFILE_VP30   |CG_PROFILE_VP30
|CG_OPENGL_NV20    |CG_PROFILE_VP20   |CG_PROFILE_VP20
|CG_D3D_SHADER_2.0 |CG_PROFILE_VS_2_0 |CG_PROFILE_PS_2_0
|CG_D3D_SHADER_3.0 |CG_PROFILE_VS_3_0 |CG_PROFILE_PS_3_0
|CG_D3D_SHADER_1.3 |CG_PROFILE_VS_1_3 |CG_PROFILE_PS_1_3
|===

[[K.4_Interaction]]
=== K.4 Interaction with other nodes and components

[[K.4_Vertexshader]]
==== K.4.1 Vertex shader

[[VertexshaderOpenGL]]
==== K.4.1.1 OpenGL profiles

The vertex shader replaces the fixed functionality of the vertex
processor. The OpenGL specification states that the following
functionality is disabled if a vertex shader is supplied:

[loweralpha]
. The model view matrix is not applied to vertex coordinates.
. The projection matrix is not applied to vertex coordinates.
. The texture matrices are not applied to texture coordinates.
. The normals are not transformed to eye coordinates.
. The normals are not rescaled or normalized.
. Texture coordinates are not generated automatically.
. Per-vertex lighting is not performed.
. Color material lighting is not performed.
. Point size distance attenuation is not performed.

[[VertexshaderDirect3D]]
==== K.4.1.2 Direct3D profiles

In Cg language Direct3D profiles, the vertex shader replaces the vertex
processing done by the Microsoft Direct3D graphics pipeline. While using
a vertex shader, state information regarding transformation and lighting
operations is ignored by the fixed-function pipeline. The Direct3D
specification states that the following functionality is disabled if a
vertex shader is supplied:

[loweralpha]
. The model view matrix is not applied to vertex coordinates.
. The projection matrix is not applied to vertex coordinates.
. The texture matrices are not applied to texture coordinates.
. The normals are not transformed to eye coordinates.
. The normals are not rescaled or normalized.
. Texture coordinates are not generated automatically.
. Per-vertex lighting is not performed.
. Color material lighting is not performed.
. Point size distance attenuation is not performed.

The fixed-function pipeline Direct3D graphics state is not available for
use within a Cg shader program. Shaders that wish to make use of this
data, such as material, lighting, texture and transformation matrix
state, shall declare parameters of the appropriate type and pass values
into them via declared fields of the containing ShaderProgram node in
the X3D scene graph. The parameter types and mappings to those types
from built-in X3D values are defined in <<K.4_DataTypeMapping, K.4 Data type and parameter mappings>>.

[[K.4_Fragmentshader]]
==== K.4.2 Fragment shader

[[FragmentshaderOpenGL]]
==== K.4.2.1 OpenGL profiles

The fragment shader replaces the fixed functionality of the fragment
processor. The OpenGL specification states that the following
functionality is disabled if a fragment shader is supplied:

[loweralpha]
. Textures are not applied.
. Fog is not applied.

[[FragmentshaderDirect3D]]
==== K.4.2.2 Direct3D profiles

In Cg language Direct3D profiles, the fragment shader, also known as a
_pixel_ shader in Cg, replaces the fixed functionality of the Direct3D
fragment processor. The Direct3D specification states that textures are
not applied if a fragment shader is supplied.

The fixed function pipeline Direct3D graphics state is not available for
use within a Cg pixel shader program. Shaders that wish to make use of
this data, such as material, lighting, texture and transformation matrix
state, shall declare parameters of the appropriate type and pass values
into them via declared fields of the containing ShaderProgram node in
the X3D scene graph. The parameter types and mappings to those types
from built-in X3D values are defined in <<K.4_DataTypeMapping, K.4 Data Type and Parameter Mappings>>.

[[K.4_Loadsensor]]
==== K.4.3 LoadSensor

The LoadSensor node (See <<S9_LoadSensor, 9.4.3 LoadSensor>>) has two
output fields _isActive_ and _isLoaded_. The _isLoaded_ field behaviour
is unchanged.

The _isActive_ field is defined to issue a `TRUE` event when all
the following conditions have been satisfied:

[loweralpha]
. The content identified by the _url_ field has been successfully loaded.
. The shader program has been successfully compiled without error.

[[K.4_Vertexattributes]]
==== K.4.4 Vertex attributes

[[VertexattributesOpenGL]]
==== K.4.4.1 OpenGL profiles

Each vertex attribute node directly maps the _name_ field to the uniform
variable of the same name. If the name is not available as a uniform
variable in the provided shader source, the values of the node shall be
ignored.

The X3D browser implementation shall automatically assign appropriate
internal index values for each attribute

[[VertexattributesDirect3D]]
==== K.4.4.2 Direct3D profiles

In Cg language Direct3D profiles, each vertex attribute node directly
maps the _name_ field to a Direct3D usage type for use within a Direct3D
vertex declaration (with the prefix "`D3DDECLUSAGE_`" prepended
to the name), as well as a Cg binding semantic of the same name defined
on the varying inputs to a shader program. This language binding allows
the use of the predefined Direct3D vertex declaration usage types and Cg
binding semantics listed in <<tK_3, Table K.3>>. If the name cannot be 
interpreted as a valid Direct3D usage type
or Cg binding semantic, the values of the node shall be ignored.

[[tK_3]]
Table K.3 — Supported Direct3D
vertex declaration usage types

[cols="",options="header",]
|===
|Direct3D usage type
|_POSITION_
|_NORMAL_
|_TEXCOORD_
|_TANGENT_
|_BINORMAL_
|_COLOR_
|_FOG_
|===

The X3D browser implementation shall automatically assign appropriate
internal index values for each attribute in the case where multiple
nodes are defined having the same value in the _name_ field.

[[K.5_DataTypeMapping]]
=== K.5 Data Type and Parameter Mappings

[[K.5_NodeFields]]
==== K.5.1 Node fields

Fields that are of type SFNode/MFNode are ignored unless the value is of
type _X3DTextureNode_, or in Direct3D profiles, _X3DMaterialNode_, or
_X3DLightNode_. Field instances of type _X3DTextureNode_ are mapped
according to the appropriate Direct3D or OpenGL sampler data type. The
mappings from texture nodes to built-in sampler types are defined in
<<tK_4, Table K.4>>.

[[tK_4]]
Table K.4 — Mapping of X3D texture node types to OpenGL or Direct3D sampler types

[cols=",,",options="header",]
|===
|X3D texture type            |OpenGL variable type |Direct3D variable type
|_X3DTexture2DNode_          |sampler2D   |sampler2D
|_X3DTexture3DNode_          |sampler3D   |sampler3D
|_X3DEnvironmentTextureNode_ |samplerCube |samplerCube
|===

X3D does not define mappings to the OpenGL types sampler1D,
sampler1DShadow and sampler2DShadow or the Direct3D types sampler1D,
sampler1DShadow and sampler2DShadow.

In Cg language OpenGL profiles, the current geometry and pipeline state
is exposed through the built-in variable _glstate_.

In Cg language Direct3D profiles, field instances of type
_X3DMaterialNode_ and _X3DLightNode_ are mapped to structures that shall
be declared in the shader program as defined in
<<tK_5, Table K.5>>.

[[tK_5]]
Table K.5 — Mapping of X3D material and light
node types to Cg structure declarations (Direct3D profiles only)

[width="100%",cols="34%,33%,33%",options="header",]
|===
|X3D node type |Cg structure declaration |Additional information
|_X3DMaterialNode_ a|
....
struct X3DMaterial {
    float4 diffuseColor;
    float4 ambientColor;
    float4 specularColor;
    float4 emissiveColor;
    float power;
};
....

|All color values are 4-component with alpha value = 1.0.

|_X3DLightNode_ a|
....
struct X3DLight {
    int type;
    float4 diffuseColor;
    float4 specularColor;
    float4 ambientColor;
    point3 position;
    point3 direction;
    float range;
    float falloff;
    float attenuation0;
    float attenuation1;
    float attenuation2;
    float theta;
    float phi;
    bool on;
};
....

a|
Valid _type_ member values are 1 for Point light, 2 for Spot light and 3
for Direction light.

All color values are 4-component with alpha value = 1.0.

All position, direction and scalar values are assumed to be in world
space.

The _on_ member specifies whether the light is enabled.

|===

[[K.5_OtherFields]]
==== K.5.2 X3D field types to Cg data types

<<tK_6, Table K.6>> indicates how the X3D field types
shall be mapped to data types used in the Cg Language.

[[tK_6]]
Table K.6 — Mapping of X3D field types to Cg data types

[cols=",",options="header",]
|===
|X3D Field type |Cg Data Type
|SFBool |bool
|MFBool |bool[]
|MFInt32 |float[]
|SFInt32 |float
|SFFloat |float
|MFFloat |float[]
|SFDouble |double
|MFDouble |double[]
|SFTime |double
|MFTime |double[]
|SFNode |See <<K.4_NodeFields, K.4.1 Node fields>>
|MFNode |See <<K.4_NodeFields, K.4.1 Node fields>>
|SFVec2f |float2
|MFVec2f |float2[]
|SFVec3f |float3
|MFVec3f |float3[]
|SFVec4f |float4
|MFVec4f |float4[]
|SFVec3d |float3
|MFVec3d |float3[]
|SFVec4d |float4
|MFVec4d |float4[]
|SFRotation |float4
|MFRotation |float4[]
|MFColor |float4[]
|SFColor |float4
|SFImage |int[]
|MFImage |int[]
|SFString |Not supported
|MFString |Not supported
|SFMatrix3f |float3x3
|MFMatrix3f |float3x3[]
|SFMatrix4f |float4x4
|MFMatrix4f |float4x4[]
|===

Cg defines maximum supported lengths of each array data type, which may
conflict with the minimum support requirements for X3D.

[[K.5_Worldstate]]
==== K.5.3 X3D world state to Cg parameter names

In Cg language Direct3D profiles, certain internal states of the X3D
world, such as transformation matrices, or the viewer's position in
world space, are neither readily available via the Cg shader program or
directly accessible from the X3D scene graph. Thus if used, these world
state values shall be explicitly passed in to the shader program as
named parameters. This binding defines an automatic mapping of these
states to predefined shader program parameter names.
<<tK_7, Table K.7>> specifies the mapping of internal
states of the X3D world to parameter names used in the Cg programs.

[[tK_7]]
Table K.7 — Mapping of X3D world state to Cg
parameter names (Direct3D profiles only)

[cols=",",options="header",]
|===
|Parameter name |Description
|*model* |This name refers to the matrix transforming from local to
global coordinates. The model matrix transforms vertices from their
model position to their position in world space ( _i.e._, after the
effects of all Transform nodes have been applied).

|*view* |This name refers to the viewing matrix transforming from world
to view relative coordinates.

|*projection* |This name refers to the projection matrix transforming
from viewing relative coordinates to clip space, including the
projective part.

|*modelView* |This name refers to the matrix that represents the
concatenation of model and view matrices. This matrix transforms
vertices from their model position to their position in view space (
_i.e._, after the effects of all Transform nodes and the current
viewpoint have been applied).

|*modelViewProjection* |This name refers to the matrix that represents
the concatenation of model, view and projection matrices. This matrix
transforms vertices from their model position to their final position in
clip space.

|*viewPosition* |This name refers to the current viewer position in
world space coordinates.
|===

The following suffixes can be applied to the matrix built-in values. A
suffix of _I_ signifies the inverse of the matrix. _T_ signifies the
transpose of the matrix. _IT_ signifies the inverse transpose of the
matrix.

[[K.6_Eventmodel]]
=== K.6 Event model

[[K.6_Changingurlfield]]
==== K.6.1 Changing URL fields

When the _url_ receives an event changing the value, the X3D browser
shall immediately attempt to download the new source. Upon successful
download, the browser shall attempt to compile the new source and issue
the appropriate LoadSensor events. It shall not automatically activate
the shader program, nor disable the currently running shader.

Values defined at load time of the file do not require an explicit
request to activate the shader program. It shall be assumed to
automatically activate the program once all the objects have
successfully downloaded. If some of the shader source files are not
downloaded or compiled ( _e.g._, due to errors), no activation shall
occur for the shader program.

[[K.6_Changingattribfield]]
==== K.6.2 Changing the _attrib_ field

Per-vertex attributes may be defined as one of the fields of
_X3DComposedGeometryNode_. These may be changed at runtime by adding or
removing node instances. Adding new node instances to the field shall
require that the user request an explicit activate in order to make them
visible to the shader.

[[K.6_activatingprograms]]
==== K.6.3 Activating programs

The user may, at any time, request that the X3D browser activate the
composing shader objects by sending a `TRUE` value to the
_activate_ inputOnly field of the ProgramShader or PackagedShader node.
Users may need to force a re-activation of the node under various
circumstances, such as changing the _url_ field of one or more
ShaderProgram or PackagedShader nodes, or adding or removing
ShaderProgram nodes from the __programs__field of the ProgramShader
node. Reactivating the shader shall replace the existing shader with the
new compiled shader for subsequent rendering.

[[htmlGuidelines_html]]
== Annex L HTML authoring guidelines (informative)


[[L_Introduction]]
=== L.1 Introduction and table of contents

This annex describes basic X3D scene integration within an HTML page and
provides guidelines for X3D browser implementers when targeting HTML
environments <<W3C-HTML5>>. These recommended practices
are intended to encourage use of X3D models compatibly with HTML pages
when used in a single Web X3D browser.

<<tL_1, Table L.1>> lists the major topics in this annex.

[[tL_1]]
Table L.1 — Topics

* <<IntroductionAndTOC, L.1 Introduction and table of contents>>
* <<X3dImplementationsHtmlBrowsers, L.2 X3D implementations in HTMLX3Dbrowsers>>
* <<PageIntegration, L.3 Page integration>>
** <<ContentDefinitionPagePresentation, L.3.1 Content definition and page presentation>>
** <<SyntaxCapitalizationValidation, L.3.2 Syntax, capitalization and validation>>
** <<id, L.3.3 Use of __id__attribute definitions>>
** <<CSS, L.3.4 Cascading Style Sheets (CSS) considerations>>
** <<CORS, L.3.5 Cross-Origin Resource Sharing (CORS) considerations>>
* <<EventHandlingFocusInteraction, L.4 Event handling, focus and interaction>>
** <<HtmlEventsX3dEvents, L.4.1 HTML and X3D synchronization>>
** <<JavaScriptECMAScript, L.4.2 JavaScript/ECMAScript considerations>>
** <<UserFocus, L.4.3 User focus considerations>>

* <<f-HtmlX3dEventPassingConnections, Figure L.1 — Example HTML X3D Rendering Synchronization and Event-Passing Connections>>

* <<tL_1, Table L.1 Topics>>


[[X3dImplementationsHtmlBrowsers]]
=== L.2 X3D implementations in HTML X3D browsers

The Hypertext Markup Language (HTML) is the World Wide Web’s core markup
language. HTML is a general description language for documents and
online applications <<W3C-HTML5>>. As part of HTML, the
Document Object Model (DOM) defines a string-based node tree for
representing HTML or XML documents, and also defines event-based
processing methods that can be implemented by multiple programming
languages <<W3C-DOM>> <<W3C-HTML5>>.

This document specifies a general-purpose architecture for publishing
and sharing 3D graphics models. Since X3D utilizes Web standards and
includes an XML file encoding, it is well suited for integration in HTML
pages over the World Wide Web.

The X3D design supports multiple goals related to use with HTML/DOM:

* X3D models are specified as a "first-class media type" similar to
other image, audio and video formats.
* Event models are harmonized so that DOM events such as user
interaction within the HTML page can also affect the X3D model, and vice
versa.
* Standards compliance is encouraged wherever possible while also
enabling ongoing interaction and interoperability improvements.
* Usage of multiple file encodings is allowed. For example, a url
address for an X3D model might point to XML, ClassicVRML, JSON, or
another file encoding.
* One or more distinct X3D scenes are allowed to be be loaded at one
time within an HTML page.
* HTML page-integration patterns specified for Scalable Vector Graphics
(SVG) <<W3C-SVG>> are consistently followed.

These general guidelines for X3D model display and interaction as part
of Web-page presentations allow continuing innovation and adaptability.

[[PageIntegration]]
=== L.3 Page integration

[[ContentDefinitionPagePresentation]]
==== L.3.1 Content definition and page presentation

There are two basic approaches to loading X3D models within HTML pages:

* Including X3D model elements within an HTML page, or else
* Referencing an external X3D model in an HTML page media element.

For X3D elements appearing within HTML document source, the HTML/DOM
`id` attribute can be used for selecting X3D model elements using
HTML-page Script nodes (as can any other HTML selector such as CSS).
Such node identification is similar to the use of `DEF` when X3D
events are passed by a ROUTE connection, allowing disambiguation of
specific node instances when needed.

There are also two basic approaches for the visual presentation of X3D
models: either

* Reserve a dedicated rectangular canvas (similar to historic EMBED
element), or else
* Float above/below other layers of content on the HTML page.

X3D Background _transparency_ field allows HTML layer(s) beneath an X3D
model to be visible (whether floating or fixed). This capability can
support special layouts for page composition.

Each approach is expected to follow <<W3C-HTML5>> and
<<W3C-DOM>> rules for page composition, and X3D rules for
scene presentation.

[[SyntaxCapitalizationValidation]]
==== L.3.2 Syntax, capitalization and validation

HTML has two syntax definitions: HTML syntax (mixed case, some
restrictions on self-closing tags) and XHTML syntax (CamelCase
capitalization, well-formed XML elements).

The capitalization of X3D elements and attributes shall match the
allowed syntax of HTML where they appear, matching case conventions for
a given HTML or XHTML syntax.

X3D model validation according to schema, DOCTYPE or other mechanisms
typically requires strict compliance to upper/lower case name
definitions in this document .

[[id]]
==== L.3.3 Use of _id_ attribute definitions

The reserved _id_ attribute on each X3D node can be considered a unique
identifier when used as part of an encompassing HTML/DOM context. Any
_id_ identifiers are in a distinct separate namespace from X3D _DEF_
identifiers and thus are not applicable for USE nodes, ROUTE statements,
or Script references.

[[CSS]]
==== L.3.4 Cascading Style Sheets (CSS) considerations

Cascading Style Sheets (CSS) is a language for describing the rendering
of structured documents (such as HTML and XML) on various display
surfaces including screen and paper. CSS is a core language for the
World Wide Web that is commonly used for separation of content and
presentation, improving layout flexibility.

Design goals for using CSS with X3D include achieving levels of
functionality similar to that which exists for using CSS with HTML.

CSS comprises multiple specifications listed in the latest version of
CSS Snapshot Recommendation <<W3C-CSS-Snapshot>>.
CSS can be applied and used for Web pages using HTML syntax or XHTML
syntax <<W3C-HTML5>>, Scalable Vector Graphics (SVG)
<<W3C-SVG>>, and Extensible Markup Language (XML)
<<W3C-XML>> documents, such as models defined using the X3D
XML encoding in <<I19776, ISO/IEC 19776-1>>.

The reserved _class_ attribute on each X3D node can provide a
space-separated list of classes that pertain from associated
stylesheets.

The reserved _style_ attribute on each X3D node permits direct
definition of style information, rather than referring to styles defined
in a separate document <<W3C-CSS-Style>> <<W3C-CSS-Snapshot>>.

CSS styling of X3D models follows the specific styling of the parent
media element on the HTML page.

The CSS _style_ attribute is not used to override the
FontStyle/ScreenFontStyle _style_ field, which is reserved for native
X3D style definitions. Instead the parent Text node's CSS _style_
attribute can be used to override FontStyle/ScreenFontStyle styling, if
appropriate and supported.

[[CORS]]
==== L.3.5 Cross-Origin Resource Sharing (CORS) considerations

https://en.wikipedia.org/wiki/Cross-origin_resource_sharing[Cross-origin
resource sharing (CORS)] "is a mechanism that allows restricted
resources on a web page to be requested from another domain, outside the
domain from which the first resource was served."

"CORS defines a way in which a X3D browser and server can interact to
determine whether it is safe to allow the cross-origin request." HTML
Web X3D browser limitations may similarly restrict loading remote
content (such as an JavaScript X3D browser) from a remote system.
Restrictions apply for any combination of locally served content and
remotely served content, including local file system.

Details regarding CORS operation by a Web X3D browser are specified in
<<WHATWG-Fetch>>.

[[EventHandlingFocusInteraction]]
=== L.4 Event handling, user focus and interaction

[[HtmlEventsX3dEvents]]
==== L.4.1 HTML and X3D synchronization

An example approach to HTML X3D Event-Passing Connections is shown in
<<f-X3DArchitecture, Figure L.1, Example HTML X3D Rendering Synchronization and Event-Passing Connections>>. This diagram illustrates
potential timing and synchronization for rendering of an HTML page and
an X3D model, with possibility of event passing between them. It is
important to achieve repeatable behavior and efficient rendering with
interactive response to user focus.

These relationships are conceptual and not necessarily indicative of any
individual implementation, in a manner similar to
<<f-X3DArchitecture, Figure 4.1 — X3D architecture>> and
<<f-ConceptualExecutionModel, Figure 4.3 — Conceptual execution model>>. Multiple design variations are permitted for HTML-X3D
implementations as long as the functional requirements of relevant HTML
and X3D specifications are met. +

[[f-HtmlX3dEventPassingConnections]]
image:https://www.web3d.org/documents/specifications/19775-1/V4.0/Images/EventModelConnectionsHtmlX3d.png[Example HTML X3D Event-Passing Connections,width=800]

Figure L.1 — Example HTML X3D Rendering Synchronization and
Event-Passing Connections

Shared HTML events and X3D events (if available) are sent and received
at end of each respective render cycle. Once initiated, an X3D
<<EventCascade, event cascade>> proceeds to completion before any
further external events are exchanged (see 
<<ExecutionModel, 4.4.8.3 Execution model>>). 
Available X3D events are shared with the HTML engine
via mechanisms such as dispatching a custom HTML event, or invoking an
author-defined callback.

Note that both HTML and X3D specifications include definitions for a
Script node, so disambiguation is necessary. One possible approach is to
require that X3D Script nodes can only appear between X3D elements
within an HTML page, and HTML Script nodes are forbidden from appearing
between X3D elements. An alternative approach is that any X3D Script
node located within HTML page might be renamed X3DScript to avoid any
node naming collisions.

[[JavaScriptECMAScript]]
==== L.4.2 JavaScript/ECMAScript considerations

JavaScript is a programming language that conforms to the ECMAScript
specification. The names are often used interchangeably, with ECMAScript
indicating strictly specified formal definitions (see
<<I16262, ISO/IEC 16262 Information technology — ECMAScript language specification>>).

Specified ECMAScript Application Programming Interface (API)
capabilities for X3D Script node are defined functionally and
<<I19775_2, ISO/IEC 19775-2 X3D Scene Authoring Interface (SAI)>> and 
encoding], respectively.

X3D browser implementations and language versions for
JavaScript/ECMAScript engines can vary. Since X3D SAI functional
requirements are carefully scoped to match the essential capabilities of
this core Web programming language, a single JavaScript/ECMAScript
engine can typically be used for both HTML and X3D event handling.

Within a Web X3D browser, implementations for HTML and X3D may share a
single JavaScript/ECMAScript engine. Such integration is often important
for both performance and synchronization issues. This consideration is
especially important when considering the demanding response-time
requirements of immersive interfaces and spatial body-tracking devices.
To aid portability and avoid unintended overloading of variable
references, it is good practice for X3D Script authors to avoid the use
of variables with global scope.

[[UserFocus]]
==== L.4.3 User focus considerations

User focus of attention refers to which part of an HTML page is
receiving user-directed events such as selection, dragging, and text
input. Such capturing of events for callback handling may seem simple
but nevertheless can become quite sophisticated, and multiple approaches
may be necessary since both displays and device interfaces can vary
widely.

X3D provides a consistent selection and navigation interface across a
wide range of devices that is based on platform-neutral definitions for
model interaction. Suggested device mappings providing consistent user
semantics are defined in 
<<behaviours_html, Annex G Recommended navigation behaviours>>.
Such flexibility is especially important when
designing model displays and interactions that support user
accessibility.

Web X3D browsers implementing HTML pay close attention to user focus
according to <<W3C-HTML5>> and correspondingly direct
user-driven events to appropriate sections of the document graph through
the DOM <<W3C-DOM>>. These are the governing references
regarding disposition of events according to user focus prior to receipt
by the X3D render engine.

Of interest is that X3D scenes can include Background _transparency_
field that may reveal underlying HTML content unobscured by geometry.
X3D browsers may optionally pass user-driven events back to the
underlying page layers for further HTML/DOM processing.

[[MedicalInterchange_html]]
== Annex M MedicalInterchange profile

(normative)

MedicalInterchange profile

[[L.1_General]]
=== L.1 General

This annex defines the X3D components that comprise the
MedicalInterchange profile. This annex includes not only the nodes that
shall be supported but also which fields in the supported nodes may be
ignored.

The name of this profile is "MedicalInterchange". This profile is
targeted towards:

* Exchange of polygonal geometry, volumetric data and accompanying
documentation between medical imaging systems.
* Possible implementation in industry-specific applications that use X3D
as an interchange format, but link to proprietary databases and
hardware.

[[L.2_Topics]]
=== L.2 Topics

<<tL_1, Table L.1>> provides links to the major topics in this
annex.

[[tL_1]]
Table L.1 — Topics

* <<L.1_General, L.1 General>>
* <<L.2_Topics, L.2 Topics in this annex>>
* <<L.3_ComponentSupport, L.3 Component support>>
* <<L.4_ConformanceCriteria, L.4 Conformance criteria>>
* <<L.5_NodeSet, L.5 Node set>>
* <<L.6_OtherLimitations, L.6 Other limitations>>

* <<tL_1, Table L.1 — Topics>>
* <<tL_2, Table L.2 — Components and levels>>
* <<tL_3, Table L.3 — Nodes for conforming to the MedicalInterchange profile>>
* <<tL_4, Table L.4 — Other limitations>>


[[L.3_ComponentSupport]]
=== L.3 Component support

<<tL_2, Table L.2>> lists the components and their
levels that shall be supported in the MedicalInterchange profile.
<<tL_3, Table L.3>> and
<<tL_4, Table L.4>> describe limitations on required
support for nodes and fields contained within these components.

[[tL_2]]
Table L.2 — Components and levels

[cols=",,",]
|===
|Component             |Level |Reference
|Core                  |1 |<<S7_SupportLevels, 7.5 Support levels>>
|Time                  |1 |<<S8_SupportLevels, 8.5 Support levels>>
|Networking            |2 |<<S9_SupportLevels, 9.5 Support levels>>
|Grouping              |3 |<<S10_SupportLevels, 10.5 Support levels>>
|Rendering             |5 |<<S11_SupportLevels, 11.5 Support levels>>
|Shape                 |3 |<<S12_SupportLevels, 12.5 Support levels>>
|Geometry3D            |2 |<<S13_SupportLevels, 13.4 Support levels>>
|Geometry2D            |2 |<<S14_SupportLevels, 14.4 Support levels>>
|Text                  |1 |<<S15_SupportLevels, 15.5 Support levels>>
|Lighting              |1 |<<S17_SupportLevels, 17.5 Support levels>>
|Texturing             |2 |<<S18_SupportLevels, 18.5 Support levels>>
|Interpolation         |2 |<<S19_SupportLevels, 19.5 Support levels>>
|Navigation            |3 |<<S23_SupportLevels, 23.4 Support levels>>
|Environmental effects |1 |<<S24_SupportLevels, 24.5 Support levels>>
|Event utilities       |1 |<<S30_SupportLevels, 30.5 Support levels>>
|Texturing3D           |2 |<<S33_SupportLevels, 33.5 Support levels>>
|Volume rendering      |4 |<<S41_SupportLevels, 41.5 Support levels>>
|===

[[L.4_ConformanceCriteria]]
=== L.4 Conformance criteria

Conformance to this profile shall include conformance criteria defined
by the specifications for those components and levels listed in
<<tL_2, Table L.2>>.

In Tables L.3 and L.4, the first column defines the item for which
conformance is being defined. In some cases, general limits are defined
but are later overridden in specific cases by more restrictive limits.
The second column defines the requirements for an X3D file conforming to
the MedicalInterchange profile. If an X3D file contains any items that
exceed these limits, it may not be possible for an X3D browser
conforming to the MedicalInterchange profile to successfully parse that
X3D file. The third column defines the minimum complexity for an X3D
scene that an X3D browser conforming to the MedicalInterchange profile
shall be able to present to the user. Fields flagged as "not supported"
may optionally be supported by X3D browsers which conform to the
MedicalInterchange profile. The word "ignore" in the minimum X3D browser
support column refers only to the display of the item; in particular,
_set__ events to ignored inputOutput fields shall still generate
corresponding __changed_ events.

[[L.5_NodeSet]]
=== L.5 Node set

<<tL_3, Table L.3>> lists the nodes which
shall be supported in the MedicalInterchange profile and specifies any
fields in these nodes for which this profile requires less than full
support.

[[tL_3]]
Table L.3 — Nodes for conforming
to the MedicalInterchange profile

[width="100%",cols="34%,33%,33%",]
|===
|Item |X3D File Limit |Minimum X3D browser Support

|Anchor |No restrictions. |Full support.

|Arc2D |No restrictions. |Full support.

|ArcClose2D |No restrictions. |Full support.

|Appearance |No restrictions. |Full support.

|Background |No restrictions. |_groundAngle_ and _groundColor_
optionally supported. _backURL_, _frontURL_, _leftURL_, _rightURL_,
_topURL_ optionally supported. _skyAngle_ optionally supported. At least
one _skyColor_ supported.

|Billboard |Restrictions as for all groups. |Full support except as for
all groups.

|BlendedVolumeStyle |No restrictions. |Full support.

|BooleanFilter |No restrictions. |Full support.

|BooleanSequencer |No restrictions. |Full support.

|BooleanToggle |No restrictions. |Full support.

|BooleanTrigger |No restrictions. |Full support.

|BoundaryEnhancementVolumeStyle |No restrictions. |Full support.

|Box |No restrictions. |Full support

|CartoonVolumeStyle |No restrictions. |Full support.

|Circle2D |No restrictions. |Full support.

|ClipPlane |No restrictions. |Full support.

|Collision |Restrictions as for all groups. |Full support except as for
all groups. Any navigation behaviour acceptable when collision occurs.

|Color |15,000 colours. |15,000 colours.

|ColorInterpolator |No restrictions. |Full support.

|ColorRGBA |15,000 colours. |15,000 colours

|ComposedVolumeStyle |No restrictions. |Full support.

|CompositeTexture3D |Minimum 512 textures. |Full support.

|Cone |No restrictions. |Full support.

|Coordinate |65,535 points. |65,535 points.

|CoordinateDouble |65,535 points. |65,535 points.

|CoordinateInterpolator |No restrictions. |Full support.

|Cylinder |No restrictions. |Full support.

|DirectionalLight |No restrictions. |Not scoped by parent Group or
Transform.

|Disk2D |No restrictions. |Full support.

|EdgeEnhancementVolumeStyle |No restrictions. |Full support.

|FillProperties |No restrictions. |Full support.

|FontStyle |No restrictions. |If the values of the text aspects
character set, _family_, _style_ cannot be simultaneously supported, the
order of precedence shall be: 1) character set 2) _family_ 3) _style_.
The X3D browser shall display all characters in Table 2 (Basic Latin)
and Table 3 (Latin-1 Supplement) of ISO/IEC 10646 (see
<<I10646, ISO/IEC 10646>>).

|Group |Restrictions as for all groups. |_addChildren_ optionally
supported. _removeChildren_ optionally supported. Otherwise as for all
groups.

<<I15948, ISO/IEC 15948>>) format. |JPEG (<<JPEG>>) and PNG (
15948]) format.

|ImageTexture3D |DICOM, JPEG (<<JPEG>>) and PNG
(<<I15948, ISO/IEC 15948>>) format. |Full support. Minimum texture
size of 256x256x256 pixels

|IndexedFaceSet |10 vertices per face. 5000 faces. Less than 15,000
indices. |10 vertices per face. 5000 faces. 15,000 indices in any index
field.

|IndexedLineSet |15,000 total vertices. 15,000 indices in any index
field. |15,000 total vertices. 15,000 indices in any index field.

|IndexedTriangleFanSet |5,000 total faces. 15,000 indices in any index
field. |5,000 total faces. 15,000 indices in any index field.

|IndexedTriangleSet |5,000 total faces. 15,000 indices in any index
field. |5,000 total faces. 15,000 indices in any index field.

|IndexedTriangleStripSet |5,000 total faces. 15,000 indices in any index
field. |5,000 total faces. 15,000 indices in any index field.

|Inline |No restrictions |All fields except _load_ which is optionally
supported.

|IntegerSequencer |No restrictions. |Full support.

|IntegerTrigger |No restrictions. |Full support.

|IsoSurfaceVolumeData |Minimum dimensions: 512 width, 512 height, 512
depth. |Full support.

|LineProperties |No restrictions. |Full support.

|LineSet |15,000 total vertices. |15,000 total vertices.

|LOD |Restrictions as for all groups. |At least first 4 _level_/ _range_
combinations interpreted, and support as for all groups.

|Material |No restrictions. |Full support.

|MetadataBoolean |No restrictions. |Full support.

|MetadataDouble |No restrictions. |Full support.

|MetadataFloat |No restrictions. |Full support.

|MetadataInteger |No restrictions. |Full support.

|MetadataSet |No restrictions. |Full support.

|MetadataString |No restrictions. |Full support.

|MultiTexture |No restrictions. a|
At least one texture displayed per node with any number specified.

Full support.

|MultiTextureCoordinate |15,000 coordinates. |15,000 coordinates.

|MultiTextureTransform |Restrictions as for all groups. |Full support.

|NavigationInfo |No restrictions. |_avatarSize_ optionally supported.
_speed_ optionally supported. _type_ optionally supported.
_visibilityLimit_ optionally supported.

|Normal |15,000 normals. |15,000 normals.

|NormalInterpolator |No restrictions. |Full support.

|OctTree |No restrictions. |Full support.

|OpacityMapVolumeStyle |No restrictions. |Full support. 3D transfer
functions shall be supported.

|OrientationInterpolator |No restrictions. |Full support.

|OrthoViewpoint |No restrictions. |Full support.

|PixelTexture |512 width. 512 height. |512 width. 512 height. Display
fully transparent and fully opaque pixels.

|PixelTexture3D |256 width. 256 height. 256 depth. |256 width. 256
height. 256 depth. Display fully transparent and fully opaque pixels.

|PointSet |5,000 points. |5,000 points.

|Polyline2D |5,000 points. |5,000 points.

|Polypoint2D |5,000 points. |5,000 points.

|PositionInterpolator |No restrictions. |Full support.

|ProjectionVolumeStyle |No restrictions. |Full support.

|Rectangle2D |No restrictions. |Full support.

|ScalarInterpolator |No restrictions. |Full support.

|SegmentedVolumeData |Minimum dimensions: 512 width, 512 height, 512
depth. |Full support.

|ShadedVolumeStyle |No restrictions. |A fields fully supported except
shadows. Shadows supported with at least Phong shading.
Henyey-Greenstein phase function not required.

|Shape |No restrictions. |Full support.

|SilhouetteEnhancementVolumeStyle |No restrictions. |Full support.

|Sphere |No restrictions. |Full support.

|StaticGroup |No restrictions. |Full support.

|Switch |No restrictions. |Full support.

|Text |100 characters per string. 100 strings. |100 characters per
string. 100 strings.

|TextureCoordinate |65,535 coordinates. |65,535 coordinates.

|TextureCoordinate3D |65,535 coordinates. |65,535 coordinates.

|TextureCoordinate4D |65,535 coordinates. |65,535 coordinates.

|TextureCoordinateGenerator |No restrictions. |Full support.

|TextureTransformMatrix3D |No restrictions. |Full support.

|TextureProperties |No restrictions. |Full support.

|TextureTransform |No restrictions. |Full support.

|TextureTransform3D |No restrictions. |Full support.

|TimeSensor |No restrictions. |_pause_, _isPaused_, _resumeTime_
optionally supported.

|TimeTrigger |No restrictions. |Full support.

|ToneMappedVolumeStyle |No restrictions. |Full support.

|Transform |Restrictions as for all groups. |_addChildren_ optionally
supported. _removeChildren_ optionally supported. Otherwise, full
support except as for all groups.

|TriangleFanSet |5,000 triangles per fan. 15,000 total triangles. |5,000
triangles per fan. 15,000 total triangles.

|TriangleSet |15,000 triangles |15,000 triangles

|TriangleStripSet |5,000 triangles per strip. 15,000 total triangles
|5,000 triangles per strip. 15,000 total triangles.

|Viewpoint |No restrictions. |Full support.

|ViewpointGroup |No restrictions. |Full support.

|VolumeData |Minimum dimensions: 512 width, 512 height, 512 depth. |Full
support.

|WorldInfo |No restrictions. |Full support.
|===

[[L.6_OtherLimitations]]
=== L.6 Other limitations

<<tL_4, Table L.4>> specifies other aspects of X3D
functionality which are supported by this profile. Note that general
items refer only to those specific nodes listed in
<<tL_3, Table L.3>>.

[[tL_4]]
Table L.4 — Other limitations

[width="100%",cols="34%,33%,33%",]
|===
|Item |X3D File Limit |Minimum X3D browser Support

|All groups |500 children. |500 children. Optionally ignore _bboxCenter_
and _bboxSize_.
|All lights |8 simultaneous lights. |8 simultaneous lights.
|Names for DEF/field |50 utf8 octets. |50 utf8 octets.
|All _url_ fields |10 URLs. |10 URLs. URN's ignored. +
|SFBool      |No restrictions. |Full support.
|SFColor     |No restrictions. |Full support.
|SFColorRGBA |No restrictions. |Full support.
|SFDouble    |No restrictions. |Full support. Range ±1e±12. Precision 1e-7.
|SFFloat     |No restrictions. |Full support.
|SFImage     |512 width. 512 height. |512 width. 512 height.
|SFInt32     |No restrictions. |Full support.
|SFMatrix4d  |No restrictions. |Full support.
|SFMatrix4f  |No restrictions. |Full support.
|SFNode      |No restrictions. |Full support.
|SFRotation  |No restrictions. |Full support.
|SFString    |30,000 utf8 octets. |30,000 utf8 octets.
|SFTime      |No restrictions. |Full support.
|SFVec2d     |No restrictions. |Full support.
|SFVec2f     |No restrictions. |Full support.
|SFVec3d     |No restrictions. |Full support.
|SFVec3f     |No restrictions. |Full support.
|SFVec4d     |No restrictions. |Full support.
|SFVec4f     |No restrictions. |Full support.
|MFColor     |15,000 values. |15,000 values.
|MFColorRGBA |15,000 values. |15,000 values.
|MFDouble    |1000 values. |1000 values.
|MFFloat     |1,000 values. |1,000 values.
|MFImage     |No restrictions. |Full support.
|MFInt32     |20,000 values. |20,000 values.
|MFNode      |500 values. |500 values.
|MFRotation  |1,000 values. |1,000 values.
|MFString    |30,000 utf8 octets per string, 10 strings. |30,000 utf8
octets per string, 10 strings.
|MFTime      |1,000 values. |1,000 values.
|MFVec2d     |15,000 values. |15,000 values.
|MFVec2f     |15,000 values. |15,000 values.
|MFVec3d     |15,000 values. |15,000 values.
|MFVec3f     |15,000 values. |15,000 values.
|MFVec4d     |15,000 values. |15,000 values.
|MFVec4f     |15,000 values. |15,000 values.
|===

[[versionContent_html]]
== Annex Z Version content

(informative)

Version content

[[Z.1_General]]
=== Z.1 General

This annex specifies the content supported by the specified versions of
X3D. Conformance requirements are stated in <<conformance_html, 6 Conformance>>.

[[Z.2_Topics]]
=== Z.2 Topics

<<tZ_1, Table Z.1>> provides links to the major topics in this
annex.

[[tZ_1]]
Table Z.1 — Topics

* <<Z.1_General, Z.1 General>>
* <<Z.2_Topics, Z.2 Topics>>
* <<VersionContent, Z.3 Version content>>

* <<tZ_1, Table Z.1 — Topics>>
* <<tZ_2, Table Z.2 — Version content (nodes)>>
* <<tZ_3, Table Z.3 — Version content (statements)>>


[[VersionContent]]
=== Z.3 Version content

<<tZ_2, Table Z.2>> lists each node specified by this
part of ISO/IEC 19775.  For each node, the fields supported by each
version are identified listed in the order specified by the node
signature. Nodes will appear in multiple rows if fields have been added
in subsequent versions.

[[tZ_2 ]]
Table Z.2 — Version content (nodes)

[cols=",,,,,,,,,,,,,,,,,,,,,,,",]
|===
| Index:       |<<IndexA, A>> |<<IndexB, B>> |<<IndexC, C>>
|<<IndexD, D>> |<<IndexE, E>> |<<IndexF, F>> |<<IndexG, G>>
|<<IndexH, H>> |<<IndexI, I>> |<<IndexK, K>> |<<IndexL, L>>
|<<IndexM, M>> |<<IndexN, N>> |<<IndexO, O>> |<<IndexP, P>>
|<<IndexQ, Q>> |<<IndexR, R>> |<<IndexS, S>> |<<IndexT, T>>
|<<IndexU, U>> |<<IndexV, V>> |<<IndexW, W>> |<<IndexX, X>>
|===

[width="99%",cols="16%,14%,14%,14%,14%,14%,14%",options="header",]
|===
|Node |Fields |3.0 |3.1 |3.2 |3.3 |4.0
a|
[[IndexA]]
<<AcousticProperties>> |absorption | | | | |X
| |description                     | | | | |X
| |diffuse                         | | | | |X
| |enabled                         | | | | |X
| |metadata                        | | | | |X
| |refraction                      | | | | |X
| |specular                        | | | | |X
|<<Analyser>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |fftSize                         | | | | |X
| |frequencyBinCount               | | | | |X
| |gain                            | | | | |X
| |minDecibels                     | | | | |X
| |maxDecibels                     | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |smoothingTimeConstant           | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|<<Anchor>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |children                        |X|X|X|X|X
| |description                     |X|X|X|X|X
| |load                            | | | | |X
| |metadata                        |X|X|X|X|X
| |parameter                       |X|X|X|X|X
| |url                             |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<Appearance>> |acousticProperties | | | | |X
| |alphaCutoff                     | | | | |X
| |alphaMode                       | | | | |X
| |backMaterial                    | | | | |X
| |fillProperties                  |X|X|X|X|X
| |lineProperties                  |X|X|X|X|X
| |pointProperties                 | | | | |X
| |material                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |shaders                         | |X|X|X|X
| |texture                         |X|X|X|X|X
| |textureTransform                |X|X|X|X|X
|<<Arc2D>> |metadata |X|X|X|X|X
| |endAngle                        |X|X|X|X|X
| |radius                          |X|X|X|X|X
| |startAngle                      |X|X|X|X|X
|<<ArcClose2D>> |metadata |X|X|X|X|X
| |closureType                     |X|X|X|X|X
| |endAngle                        |X|X|X|X|X
| |radius                          |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |startAngle                      |X|X|X|X|X
|<<AudioClip>> |autoRefresh | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     |X|X|X|X|X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |load                            | | | | |X
| |loop                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |pauseTime                       |X|X|X|X|X
| |pitch                           |X|X|X|X|X
| |resumeTime                      |X|X|X|X|X
| |startTime                       |X|X|X|X|X
| |stopTime                        |X|X|X|X|X
| |url                             |X|X|X|X|X
| |duration_changed                |X|X|X|X|X
| |elapsedTime                     |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isPaused                        |X|X|X|X|X
|<<AudioDestination>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |maxChannelCount                 | | | | |X
| |metadata                        | | | | |X
| |mediaDeviceID                   | | | | |X
| |isActive                        | | | | |X
| |channelCount                    | | | | |X
|<<Background>> |set_bind |X|X|X|X|X
| |groundAngle                     |X|X|X|X|X
| |groundColor                     |X|X|X|X|X
| |backUrl                         |X|X|X|X|X
| |bottomUrl                       |X|X|X|X|X
| |frontUrl                        |X|X|X|X|X
| |leftUrl                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |rightUrl                        |X|X|X|X|X
| |topUrl                          |X|X|X|X|X
| |skyAngle                        |X|X|X|X|X
| |skyColor                        |X|X|X|X|X
| |transparency                    | | |X|X|X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
|<<BallJoint>> |anchorPoint | | |X|X|X
| |body1                           | | |X|X|X
| |body2                           | | |X|X|X
| |forceOutput                     | | |X|X|X
| |metadata                        | | |X|X|X
| |body1AnchorPoint                | | |X|X|X
| |body2AnchorPoint                | | |X|X|X
|<<Billboard>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |axisOfRotation                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
a|
[[IndexB]]
<<BiquadFilter>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |detune                          | | | | |X
| |enabled                         | | | | |X
| |frequency                       | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |qualityFactor                   | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |type                            | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|<<BlendedVolumeStyle>> |enabled | | | |X|X
| |metadata                        | | | |X|X
| |renderStyle                     | | | |X|X
| |voxels                          | | | |X|X
| |weightConstant1                 | | | |X|X
| |weightConstant2                 | | | |X|X
| |weightFunction1                 | | | |X|X
| |weightFunction2                 | | | |X|X
| |weightTransferFunction1         | | | |X|X
| |weightTransferFunction2         | | | |X|X
|<<BooleanFilter>> |set_boolean |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |inputFalse                      |X|X|X|X|X
| |inputNegate                     |X|X|X|X|X
| |inputTrue                       |X|X|X|X|X
|<<BooleanSequencer>> |next |X|X|X|X|X
| |previous                        |X|X|X|X|X
| |set_fraction                    |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<BooleanToggle>> |set_boolean |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |toggle                          |X|X|X|X|X
|<<BooleanTrigger>> |set_triggerTime |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |triggerTrue                     |X|X|X|X|X
|<<BoundaryEnhancementVolumeStyle>> |boundaryOpacity | | | |X|X
| |enabled                         | | | |X|X
| |metadata                        | | | |X|X
| |opacityFactor                   | | | |X|X
| |retainedOpacity                 | | | |X|X
| |surfaceNormals                  | | | |X|X
|<<BoundedPhysicsModel>>  |enabled | | |X|X|X
| |geometry                        | | |X|X|X
| |metadata                        | | |X|X|X
|<<Box>> |metadata |X|X|X|X|X
| |size                            |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<BufferAudioSource>> |autoRefresh | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |buffer                          | | | | |X
| |bufferDuration                  | | | | |X
| |channelCountMode                | | | | |X
| |channelInterpretation           | | | | |X
| |description                     | | | | |X
| |detune                          | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |load                            | | | | |X
| |loop                            | | | | |X
| |loopEnd                         | | | | |X
| |loopStart                       | | | | |X
| |metadata                        | | | | |X
| |numberOfChannels                | | | | |X
| |pauseTime                       | | | | |X
| |playbackRate                    | | | | |X
| |resumeTime                      | | | | |X
| |sampleRate                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |url                             | | | | |X
| |bufferLength                    | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
a|
[[IndexC]]
<<CADAssembly>> |addChildren | |X|X|X|X
| |removeChildren                  | |X|X|X|X
| |children                        | |X|X|X|X
| |metadata                        | |X|X|X|X
| |name                            | |X|X|X|X
| |bboxCenter                      | |X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | |X|X|X|X
| |visible                         | | | | |X
|<<CADFace>> |metadata | |X|X|X|X
| |name                            | |X|X|X|X
| |shape                           | |X|X|X|X
| |bboxCenter                      | |X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | |X|X|X|X
| |visible                         | | | | |X
|<<CADLayer>> |addChildren | |X|X|X|X
| |removeChildren                  | |X|X|X|X
| |children                        | |X|X|X|X
| |metadata                        | |X|X|X|X
| |name                            | |X|X|X|X
| |bboxCenter                      | |X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | |X|X|X|X
| |visible                         | |X|X|X| 
|<<CADPart>> |addChildren | |X|X|X|X
| |removeChildren                  | |X|X|X|X
| |center                          | |X|X|X|X
| |children                        | |X|X|X|X
| |metadata                        | |X|X|X|X
| |name                            | |X|X|X|X
| |rotation                        | |X|X|X|X
| |scale                           | |X|X|X|X
| |scaleOrientation                | |X|X|X|X
| |translation                     | |X|X|X|X
| |bboxCenter                      | |X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | |X|X|X|X
| |visible                         | | | | |X
|<<CartoonVolumeStyle>> |colorSteps | | | |X|X
| |enabled                         | | | |X|X
| |metadata                        | | | |X|X
| |orthogonalColor                 | | | |X|X
| |parallelColor                   | | | |X|X
| |surfaceNormals                  | | | |X|X
|<<ChannelMerger>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |channelCount                    | | | | |X
|<<ChannelSelector>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |channelSelection                | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |channelCount                    | | | | |X
|<<ChannelSplitter>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |outputs                         | | | | |X
| |channelCount                    | | | | |X
|<<Circle2D>> |metadata |X|X|X|X|X
| |radius                          |X|X|X|X|X
|<<ClipPlane>> |enabled | | |X|X|X
| |metadata                        | | |X|X|X
| |plane                           | | |X|X|X
|<<CollidableOffset>> |enabled | | |X|X|X
| |metadata                        | | |X|X|X
| |rotation                        | | |X|X|X
| |translation                     | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |collidable                      | | |X|X|X
| |visible                         | | | | |X
|<<CollidableShape>> |enabled | | |X|X|X
| |metadata                        | | |X|X|X
| |rotation                        | | |X|X|X
| |translation                     | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |shape                           | | |X|X|X
| |visible                         | | | | |X
|<<Collision>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |collideTime                     |X|X|X|X|X
| |description                     | | | | |X
| |enabled                         |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |proxy                           |X|X|X|X|X
| |visible                         | | | | |X
|<<CollisionCollection>> |appliedParameters | | 
|X|X|X
| |bounce                          | | |X|X|X
| |collidables                     | | |X|X|X
| |description                     | | | | |X
| |enabled                         | | |X|X|X
| |frictionCoefficients            | | |X|X|X
| |metadata                        | | |X|X|X
| |minBounceSpeed                  | | |X|X|X
| |slipFactors                     | | |X|X|X
| |softnessConstantForceMix        | | |X|X|X
| |softnessErrorCorrection         | | |X|X|X
| |surfaceSpeed                    | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|<<CollisionSensor>> |collider | | |X|X|X
| |description                     | | | | |X
| |enabled                         | | |X|X|X
| |metadata                        | | |X|X|X
| |intersections                   | | |X|X|X
| |contacts                        | | |X|X|X
| |isActive                        | | |X|X|X
|<<CollisionSpace>> |collidables | | |X|X|X
| |enabled                         | | |X|X|X
| |metadata                        | | |X|X|X
| |useGeometry                     | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|<<Color>> |color |X|X|X|X|X
| |metadata                        |X|X|X|X|X
|<<ColorChaser>> |set_destination | | | |X|X
| |set_value                       | | | |X|X
| |metadata                        | | | |X|X
| |isActive                        | | | |X|X
| |value_changed                   | | | |X|X
| |duration                        | | | |X|X
| |initialDestination              | | | |X|X
| |initialValue                    | | | |X|X
|<<ColorDamper>> |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |tau                             | | |X|X|X
| |tolerance                       | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
| |order                           | | |X|X|X
|<<ColorInterpolator>> |set_fraction |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<ColorRGBA>> |color |X|X|X|X|X
| |metadata                        |X|X|X|X|X
|<<ComposedCubeMapTexture>> |backTexture | |X
|X|X|X
| |bottomTexture                   | |X|X|X|X
| |frontTexture                    | |X|X|X|X
| |leftTexture                     | |X|X|X|X
| |metadata                        | |X|X|X|X
| |rightTexture                    | |X|X|X|X
| |topTexture                      | |X|X|X|X
|<<ComposedShader>> |activate | |X|X|X|X
| |metadata                        | |X|X|X|X
| |parts                           | |X|X|X|X
| |isSelected                      | |X|X|X|X
| |isValid                         | |X|X|X|X
| |language                        | |X|X|X|X
|<<ComposedTexture3D>> |description | | | | |X
| |metadata                        | |X|X|X|X
| |repeatS                         | |X|X|X|X
| |repeatT                         | |X|X|X|X
| |repeatR                         | |X|X|X|X
| |texture                         | |X|X|X|X
| |textureProperties               | | |X|X|X
|<<ComposedVolumeStyle>> |enabled | | | |X|X
| |metadata                        | | | |X|X
| |renderStyle                     | | | |X|X
|<<Cone>> |metadata |X|X|X|X|X
| |bottom                          |X|X|X|X|X
| |bottomRadius                    |X|X|X|X|X
| |height                          |X|X|X|X|X
| |side                            |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<ConeEmitter>> |angle | | |X|X|X
| |direction                       | | |X|X|X
| |mass                            | | |X|X|X
| |metadata                        | | |X|X|X
| |on                              | | | | |X
| |position                        | | |X|X|X
| |speed                           | | |X|X|X
| |surfaceArea                     | | |X|X|X
| |variation                       | | |X|X|X
|<<Contact>> |appliedParameters | | |X|X|X
| |body1                           | | |X|X|X
| |body2                           | | |X|X|X
| |bounce                          | | |X|X|X
| |contactNormal                   | | |X|X|X
| |depth                           | | |X|X|X
| |frictionCoefficients            | | |X|X|X
| |frictionDirection               | | |X|X|X
| |geometry1                       | | |X|X|X
| |geometry2                       | | |X|X|X
| |metadata                        | | |X|X|X
| |minBounceSpeed                  | | |X|X|X
| |position                        | | |X|X|X
| |slipCoefficients                | | |X|X|X
| |softnessConstantForceMix        | | |X|X|X
| |softnessErrorCorrection         | | |X|X|X
| |surfaceSpeed                    | | |X|X|X
|<<Contour2D>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
|<<ContourPolyline2D>> |metadata |X|X|X|X|X
| |controlPoint                    |X|X|X|X|X
|<<Convolver>> |buffer | | | | |X
| |channelCountMode                | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |normalize                       | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|<<Coordinate>> |metadata |X|X|X|X|X
| |point                           |X|X|X|X|X
|<<CoordinateChaser>> |set_destination | | | |X
|X
| |set_value                       | | | |X|X
| |metadata                        | | | |X|X
| |isActive                        | | | |X|X
| |value_changed                   | | | |X|X
| |duration                        | | | |X|X
| |initialDestination              | | | |X|X
| |initialValue                    | | | |X|X
|<<CoordinateDamper>> |set_destination | | |X|X
|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |tau                             | | |X|X|X
| |tolerance                       | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
| |order                           | | |X|X|X
|<<CoordinateDouble>> |metadata |X|X|X|X|X
| |point                           |X|X|X|X|X
|<<CoordinateInterpolator>> |set_fraction |X
|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<CoordinateInterpolator2D>> |set_fraction
|X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<Cylinder>> |metadata |X|X|X|X|X
| |bottom                          |X|X|X|X|X
| |height                          |X|X|X|X|X
| |radius                          |X|X|X|X|X
| |side                            |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |top                             |X|X|X|X|X
|<<CylinderSensor>> |autoOffset |X|X|X|X|X
| |description                     |X|X|X|X|X
| |diskAngle                       |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |maxAngle                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |minAngle                        |X|X|X|X|X
| |offset                          |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
| |rotation_changed                |X|X|X|X|X
| |trackPoint_changed              |X|X|X|X|X
|<<Delay>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |delayTime                       | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |maxDelayTime                    | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
a|
[[IndexD]]
<<DirectionalLight>> |ambientIntensity |X|X|X|X|X
| |color                           |X|X|X|X|X
| |direction                       |X|X|X|X|X
| |global                          | |X|X|X|X
| |intensity                       |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |on                              |X|X|X|X|X
| |shadows                         | | | | |X
| |shadowIntensity                 | | | | |X
|<<DISEntityManager>> |address | | |X|X|X
| |applicationID                   | | |X|X|X
| |children                        | | |X|X|X
| |mapping                         | | |X|X|X
| |metadata                        | | |X|X|X
| |port                            | | |X|X|X
| |siteID                          | | |X|X|X
| |addedEntities                   | | |X|X|X
| |removedEntities                 | | |X|X|X
|<<DISEntityTypeMapping>> |metadata | | |X|X
|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |url                             | | |X|X|X
| |category                        | | |X|X|X
| |country                         | | |X|X|X
| |domain                          | | |X|X|X
| |extra                           | | |X|X|X
| |kind                            | | |X|X|X
| |specific                        | | |X|X|X
| |subcategory                     | | |X|X|X
|<<Disk2D>> |metadata |X|X|X|X|X
| |innerRadius                     |X|X|X|X|X
| |outerRadius                     |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<DoubleAxisHingeJoint>> |anchorPoint | | |X|X|X
| |axis1                           | | |X|X|X
| |axis2                           | | |X|X|X
| |body1                           | | |X|X|X
| |body2                           | | |X|X|X
| |desiredAngularVelocity1         | | |X|X|X
| |desiredAngularVelocity2         | | |X|X|X
| |forceOutput                     | | |X|X|X
| |maxAngle1                       | | |X|X|X
| |maxTorque1                      | | |X|X|X
| |maxTorque2                      | | |X|X|X
| |metadata                        | | |X|X|X
| |minAngle1                       | | |X|X|X
| |stop1Bounce                     | | |X|X|X
| |stop1ConstantForceMix           | | |X|X|X
| |stop1ErrorCorrection            | | |X|X|X
| |suspensionErrorCorrection       | | |X|X|X
| |suspensionForce                 | | |X|X|X
| |body1AnchorPoint                | | |X|X|X
| |body2AnchorPoint                | | |X|X|X
| |body1Axis                       | | |X|X|X
| |body2Axis                       | | |X|X|X
| |hinge1Angle                     | | |X|X|X
| |hinge1AngleRate                 | | |X|X|X
| |hinge2Angle                     | | |X|X|X
| |hinge2AngleRate                 | | |X|X|X
|<<DynamicsCompressor>> |attack | | | | |X
| |channelCountMode                | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |knee                            | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |ratio                           | | | | |X
| |release                         | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |threshold                       | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
| |reduction                       | | | | |X
a|
[[IndexE]]
<<EaseInEaseOut>> |set_fraction | | |X|X|X
| |easeInEaseOut                   | | |X|X|X
| |key                             | | |X|X|X
| |metadata                        | | |X|X|X
| |modifiedFraction_changed        | | |X|X|X
|<<EdgeEnhancementVolumeStyle>> |edgeColor | | | |X|X
| |enabled                         | | | |X|X
| |gradientThreshold               | | | |X|X
| |metadataColor                   | | | |X|X
| |surfaceNormals                  | | | |X|X
|<<ElevationGrid>> |set_height |X|X|X|X|X
| |attrib                          | |X|X|X|X
| |color                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |creaseAngle                     |X|X|X|X|X
| |height                          |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |xDimension                      |X|X|X|X|X
| |xSpacing                        |X|X|X|X|X
| |zDimension                      |X|X|X|X|X
| |zSpacing                        |X|X|X|X|X
|<<EspduTransform>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |set_articulationParameterValue0 |X|X|X|X|X
| |set_articulationParameterValue1 |X|X|X|X|X
| |set_articulationParameterValue2 |X|X|X|X|X
| |set_articulationParameterValue3 |X|X|X|X|X
| |set_articulationParameterValue4 |X|X|X|X|X
| |set_articulationParameterValue5 |X|X|X|X|X
| |set_articulationParameterValue6 |X|X|X|X|X
| |set_articulationParameterValue7 |X|X|X|X|X
| |address                         |X|X|X|X|X
| |applicationID                   |X|X|X|X|X
| |articulationParameterCount      |X|X|X|X|X
| |articulationParameterDesignatorArray |X|X|X|X|X
| |articulationParameterChangeIndicatorArray |X|X|X|X|X
| |articulationParameterIdPartAttachedToArray |X|X|X|X|X
| |articulationParameterTypeArray  |X|X|X|X|X
| |articulationParameterArray      |X|X|X|X|X
| |center                          |X|X|X|X|X
| |children                        |X|X|X|X|X
| |collisionType                   |X|X|X|X|X
| |deadReckoning                   |X|X|X|X|X
| |description                     | | | | |X
| |detonationLocation              |X|X|X|X|X
| |detonationRelativeLocation      |X|X|X|X|X
| |detonationResult                |X|X|X|X|X
| |enabled                         | |X|X|X|X
| |entityCategory                  |X|X|X|X|X
| |entityCountry                   |X|X|X|X|X
| |entityDomain                    |X|X|X|X|X
| |entityExtra                     |X|X|X|X|X
| |entityId                        |X|X|X|X|X
| |entityKind                      |X|X|X|X|X
| |entitySpecific                  |X|X|X|X|X
| |entitySubcategory               |X|X|X|X|X
| |eventApplicationID              |X|X|X|X|X
| |eventEntityID                   |X|X|X|X|X
| |eventNumber                     |X|X|X|X|X
| |eventSiteID                     |X|X|X|X|X
| |fired1                          |X|X|X|X|X
| |fired2                          |X|X|X|X|X
| |fireMissionIndex                |X|X|X|X|X
| |firingRange                     |X|X|X|X|X
| |firingRate                      |X|X|X|X|X
| |forceID                         |X|X|X|X|X
| |fuse                            |X|X|X|X|X
| |geoCoords                       | | | | |X
| |linearVelocity                  |X|X|X|X|X
| |linearAcceleration              |X|X|X|X|X
| |marking                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |multicastRelayHost              |X|X|X|X|X
| |multicastRelayPort              |X|X|X|X|X
| |munitionApplicationID           |X|X|X|X|X
| |munitionEndPoint                |X|X|X|X|X
| |munitionEntityID                |X|X|X|X|X
| |munitionQuantity                |X|X|X|X|X
| |munitionSiteID                  |X|X|X|X|X
| |munitionStartPoint              |X|X|X|X|X
| |networkMode                     |X|X|X|X|X
| |port                            |X|X|X|X|X
| |readInterval                    |X|X|X|X|X
| |rotation                        |X|X|X|X|X
| |scale                           |X|X|X|X|X
| |scaleOrientation                |X|X|X|X|X
| |siteID                          |X|X|X|X|X
| |translation                     |X|X|X|X|X
| |warhead                         |X|X|X|X|X
| |writeInterval                   |X|X|X|X|X
| |articulationParameterValue0_changed |X|X|X|X|X
| |articulationParameterValue1_changed |X|X|X|X|X
| |articulationParameterValue2_changed |X|X|X|X|X
| |articulationParameterValue3_changed |X|X|X|X|X
| |articulationParameterValue4_changed |X|X|X|X|X
| |articulationParameterValue5_changed |X|X|X|X|X
| |articulationParameterValue6_changed |X|X|X|X|X
| |articulationParameterValue7_changed |X|X|X|X|X
| |collideTime                     |X|X|X|X|X
| |detonateTime                    |X|X|X|X|X
| |firedTime                       |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isCollided                      |X|X|X|X|X
| |isDetonated                     |X|X|X|X|X
| |isNetworkReader                 |X|X|X|X|X
| |isRtpHeaderHeard                |X|X|X|X|X
| |isStandAlone                    |X|X|X|X|X
| |rtpHeaderExpected               |X|X|X|X|X
| |timestamp                       |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<ExplosionEmitter>> |mass | | |X|X|X
| |metadata                        | | |X|X|X
| |on                              | | | | |X
| |position                        | | |X|X|X
| |speed                           | | |X|X|X
| |surfaceArea                     | | |X|X|X
| |variation                       | | |X|X|X
|<<Extrusion>> |set_crossSection |X|X|X|X|X
| |set_orientation                 |X|X|X|X|X
| |set_scale                       |X|X|X|X|X
| |set_spine                       |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |beginCap                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |convex                          |X|X|X|X|X
| |creaseAngle                     |X|X|X|X|X
| |crossSection                    |X|X|X|X|X
| |endCap                          |X|X|X|X|X
| |orientation                     |X|X|X|X|X
| |scale                           |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |spine                           |X|X|X|X|X
a|
[[IndexF]]
<<FillProperties>> |filled |X|X|X|X|X
| |hatchColor                      |X|X|X|X|X
| |hatched                         |X|X|X|X|X
| |hatchStyle                      |X|X|X|X|X
| |metadata                        |X|X|X|X|X
|<<FloatVertexAttribute>> |metadata | |X|X|X|X
| |value                           | |X|X|X|X
| |name                            | |X|X|X|X
| |numComponents                   | |X|X|X|X
|<<Fog>> |set_bind |X|X|X|X|X
| |color                           |X|X|X|X|X
| |fogType                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |visibilityRange                 |X|X|X|X|X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
|<<FogCoordinate>> |depth | |X|X|X|X
| |metadata                        | |X|X|X|X
|<<FontStyle>> |metadata |X|X|X|X|X
| |family                          |X|X|X|X|X
| |horizontal                      |X|X|X|X|X
| |justify                         |X|X|X|X|X
| |language                        |X|X|X|X|X
| |leftToRight                     |X|X|X|X|X
| |size                            |X|X|X|X|X
| |spacing                         |X|X|X|X|X
| |style                           |X|X|X|X|X
| |topToBottom                     |X|X|X|X|X
|<<ForcePhysicsModel>> |enabled | | |X|X|X
| |force                           | | |X|X|X
| |metadata                        | | |X|X|X
a|
[[IndexG]]
<<Gain>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|<<GeneratedCubeMapTexture>> |description | | | | |X
| |metadata                        | |X|X|X|X
| |update                          | |X|X|X|X
| |size                            | |X|X|X|X
| |textureProperties               | | | | |X
|<<GeoCoordinate>> |metadata |X|X|X|X|X
| |point                           |X|X|X|X|X
| |geoOrigin                       |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
|<<GeoElevationGrid>> |set_height |X|X|X|X|X
| |color                           |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |yScale                          |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |creaseAngle                     |X|X|X|X|X
| |geoGridOrigin                   |X|X|X|X|X
| |geoOrigin                       |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
| |height                          |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |xDimension                      |X|X|X|X|X
| |xSpacing                        |X|X|X|X|X
| |zDimension                      |X|X|X|X|X
| |zSpacing                        |X|X|X|X|X
|<<GeoLocation>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |geoCoords                       |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |geoOrigin                       |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<GeoLOD>> |metadata |X|X|X|X|X
| |children                        |X|X|X|X|X
| |center                          |X|X|X|X|X
| |child1Url                       |X|X|X|X|X
| |child2Url                       |X|X|X|X|X
| |child3Url                       |X|X|X|X|X
| |child4Url                       |X|X|X|X|X
| |geoOrigin                       |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
| |level_changed                   | |X|X|X|X
| |range                           |X|X|X|X|X
| |rootUrl                         |X|X|X|X|X
| |rootNode                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<GeoMetadata>> |data |X|X|X|X|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |metadata                        |X|X|X|X|X
| |summary                         |X|X|X|X|X
| |url                             |X|X|X|X|X
|<<GeoOrigin>> |geoCoords |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
| |rotateYUp                       |X|X|X|X|X
|<<GeoPositionInterpolator>> |set_fraction |X
|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |geovalue_changed                |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
| |geoOrigin                       |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
|<<GeoProximitySensor>> |enabled | | |X|X|X
| |geoCenter                       | | |X| | 
| |center                          | | | |X|X
| |metadata                        | | |X|X|X
| |size                            | | |X|X|X
| |centerOfRotation_changed        | | |X|X|X
| |enterTime                       | | |X|X|X
| |exitTime                        | | |X|X|X
| |geoCoord_changed                | | |X|X|X
| |isActive                        | | |X|X|X
| |orientation_changed             | | |X|X|X
| |position_changed                | | |X|X|X
| |geoOrigin                       | | |X|X|X
| |geoSystem                       | | |X|X|X
|<<GeoTouchSensor>> |description |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |hitNormal_changed               |X|X|X|X|X
| |hitPoint_changed                |X|X|X|X|X
| |hitTexCoord_changed             |X|X|X|X|X
| |hitGeoCoord_changed             |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
| |touchTime                       |X|X|X|X|X
| |geoOrigin                       |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
|<<GeoTransform>> |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |geoCenter                       | | |X|X|X
| |metadata                        | | |X|X|X
| |rotation                        | | |X|X|X
| |scale                           | | |X|X|X
| |scaleOrientation                | | |X|X|X
| |translation                     | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |geoOrigin                       | | |X|X|X
| |geoSystem                       | | |X|X|X
| |visible                         | | | | |X
|<<GeoViewpoint>> |set_bind |X|X|X|X|X
| |set_orientation                 |X|X|X| |
| |set_position                    |X|X|X| |
| |centerOfRotation                |X|X|X|X|X
| |description                     |X|X|X|X|X
| |farDistance                     | | | | |X
| |fieldOfView                     |X|X|X|X|X
| |headlight                       |X|X|X| | 
| |jump                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |navigationInfo                  | | | | |X
| |navType                         |X|X|X| | 
| |nearDistance                    | | | | |X
| |orientation                     |X|X|X|X|X
| |position                        |X|X|X|X|X
| |retainUserOffsets               | | |X|X|X
| |viewAll                         | | | | |X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
| |geoOrigin                       |X|X|X|X|X
| |geoSystem                       |X|X|X|X|X
| |speedFactor                     |X|X|X|X|X
|<<Group>> |addchildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
a|
[[IndexH]]
<<HAnimDisplacer>> |coordIndex |X|X|X|X|X
| |description                     | | | | |X
| |displacements                   |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |name                            |X|X|X|X|X
| |weight                          |X|X|X|X|X
|<<HAnimHumanoid>> |center |X|X|X|X|X
| |description                     | | | | |X
| |info                            |X|X|X|X|X
| |jointBindingPositions           | | | | |X
| |jointBindingRotations           | | | | |X
| |jointBindingScales              | | | | |X
| |joints                          |X|X|X|X|X
| |loa                             | | | | |X
| |metadata                        |X|X|X|X|X
| |motions                         | | | | |X
| |motionsEnabled                  | | | | |X
| |name                            |X|X|X|X|X
| |rotation                        |X|X|X|X|X
| |scale                           |X|X|X|X|X
| |scaleOrientation                |X|X|X|X|X
| |segments                        |X|X|X|X|X
| |sites                           |X|X|X|X|X
| |skeletalConfiguration           | | | | |X
| |skeleton                        |X|X|X|X|X
| |skin                            |X|X|X|X|X
| |skinBindingCoords               | | | | |X
| |skinBindingNormals              | | | | |X
| |skinCoord                       |X|X|X|X|X
| |skinNormal                      |X|X|X|X|X
| |translation                     |X|X|X|X|X
| |version                         |X|X|X|X|X
| |viewpoints                      |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<HAnimJoint>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |center                          |X|X|X|X|X
| |children                        |X|X|X|X|X
| |description                     | | | | |X
| |displacers                      |X|X|X|X|X
| |limitOrientation                |X|X|X|X|X
| |llimit                          |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |name                            |X|X|X|X|X
| |rotation                        |X|X|X|X|X
| |scale                           |X|X|X|X|X
| |scaleOrientation                |X|X|X|X|X
| |skinCoordIndex                  |X|X|X|X|X
| |skinCoordWeight                 |X|X|X|X|X
| |stiffness                       |X|X|X|X|X
| |translation                     |X|X|X|X|X
| |ulimit                          |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<HAnimMotion>> |next | | | | |X
| |previous                        | | | | |X
| |channels                        | | | | |X
| |channelsEnabled                 | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |endFrame                        | | | | |X
| |frameDuration                   | | | | |X
| |frameIncrement                  | | | | |X
| |frameIndex                      | | | | |X
| |joints                          | | | | |X
| |loa                             | | | | |X
| |loop                            | | | | |X
| |metadata                        | | | | |X
| |startFrame                      | | | | |X
| |values                          | | | | |X
| |cycleTime                       | | | | |X
| |elapsedTime                     | | | | |X
| |frameCount                      | | | | |X
|<<HAnimSegment>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |centerOfMass                    |X|X|X|X|X
| |children                        |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |displacers                      |X|X|X|X|X
| |mass                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |momentsOfInertia                |X|X|X|X|X
| |name                            |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<HAnimSite>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |center                          |X|X|X|X|X
| |children                        |X|X|X|X|X
| |description                     | | | | |X
| |metadata                        |X|X|X|X|X
| |name                            |X|X|X|X|X
| |rotation                        |X|X|X|X|X
| |scale                           |X|X|X|X|X
| |scaleOrientation                |X|X|X|X|X
| |translation                     |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
a|
[[IndexI]]
<<ImageCubeMapTexture>> |metadata | |X|X|X|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |url                             | |X|X|X|X
| |textureProperties               | | | | |X
|<<ImageTexture>> |metadata |X|X|X|X|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |url                             |X|X|X|X|X
| |repeatS                         |X|X|X|X|X
| |repeatT                         |X|X|X|X|X
| |textureProperties               | | |X|X|X
|<<ImageTexture3D>> |metadata | |X|X|X|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |url                             | |X|X|X|X
| |repeatS                         | |X|X|X|X
| |repeatT                         | |X|X|X|X
| |repeatR                         | |X|X|X|X
| |textureProperties               | | |X|X|X
|<<IndexedFaceSet>> |set_colorIndex |X|X|X|X|X
| |set_coordIndex                  |X|X|X|X|X
| |set_normalIndex                 |X|X|X|X|X
| |set_texCoordIndex               |X|X|X|X|X
| |attrib                          | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorIndex                      |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |convex                          |X|X|X|X|X
| |coordIndex                      |X|X|X|X|X
| |creaseAngle                     |X|X|X|X|X
| |normalIndex                     |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |texCoordIndex                   |X|X|X|X|X
|<<IndexedLineSet>> |set_colorIndex |X|X|X|X|X
| |set_coordIndex                  |X|X|X|X|X
| |attrib                          | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |colorIndex                      |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |coordIndex                      |X|X|X|X|X
|<<IndexedQuadSet>> |set_index | |X|X|X|X
| |attrib                          | |X|X|X|X
| |color                           | |X|X|X|X
| |coord                           | |X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        | |X|X|X|X
| |normal                          | |X|X|X|X
| |texCoord                        | |X|X|X|X
| |ccw                             | |X|X|X|X
| |colorPerVertex                  | |X|X|X|X
| |normalPerVertex                 | |X|X|X|X
| |solid                           | |X|X|X|X
| |index                           | |X|X|X|X
|<<IndexedTriangleFanSet>> |set_index |X|X|X|X|X
| |attrib                          | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |index                           |X|X|X|X|X
|<<IndexedTriangleSet>> |set_index |X|X|X|X|X
| |attrib                          | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |index                           |X|X|X|X|X
|<<IndexedTriangleStripSet>> |set_index |X|X|X|X|X
| |attrib                          | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |creaseAngle                     |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |index                           |X|X|X|X|X
|<<Inline>> |metadata |X|X|X|X|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |global                          | | | | |X
| |load                            | | | | |X
| |url                             |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<IntegerSequencer>> |next |X|X|X|X|X
| |previous                        |X|X|X|X|X
| |set_fraction                    |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<IntegerTrigger>> |set_boolean |X|X|X|X|X
| |integerKey                      |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |triggerValue                    |X|X|X|X|X
|<<IsoSurfaceVolumeData>> |contourStepSize | | | |X|X
| |dimensions                      | | | |X|X
| |gradients                       | | | |X|X
| |metadata                        | | | |X|X
| |renderStyle                     | | | |X|X
| |surfaceTolerance                | | | |X|X
| |surfaceValues                   | | | |X|X
| |voxels                          | | | |X|X
| |bboxCenter                      | | | |X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | | |X|X
| |visible                         | | | | |X
a|
[[IndexK]]
<<KeySensor>> |description | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |actionKeyPress                  |X|X|X|X|X
| |actionKeyRelease                |X|X|X|X|X
| |altKey                          |X|X|X|X|X
| |controlKey                      |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |keyPress                        |X|X|X|X|X
| |keyRelease                      |X|X|X|X|X
| |shiftKey                        |X|X|X|X|X
a|
[[IndexL]]
<<Layer>> |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |metadata                        | | |X|X|X
| |pickable                        | | |X|X|X
| |viewport                        | | |X|X|X
| |visible                         | | | | |X
|<<LayerSet>> |activeLayer | | |X|X|X
| |layers                          | | |X|X|X
| |metadata                        | | |X|X|X
| |order                           | | |X|X|X
|<<Layout>> |align | | |X|X|X
| |metadata                        | | |X|X|X
| |offset                          | | |X|X|X
| |offsetUnits                     | | |X|X|X
| |scaleMode                       | | |X|X|X
| |size                            | | |X|X|X
| |sizeUnits                       | | |X|X|X
|<<LayoutGroup>> |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |layout                          | | |X|X|X
| |metadata                        | | |X|X|X
| |viewport                        | | |X|X|X
| |bboxCenter                      | | | | |X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | | | |X
| |visible                         | | | | |X
|<<LayoutLayer>> |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |layout                          | | |X|X|X
| |metadata                        | | |X|X|X
| |objectType                      | | |X|X|X
| |pickable                        | | |X|X|X
| |viewport                        | | |X|X|X
| |visible                         | | | | |X
|<<LinePickSensor>> |description | | | | |X
| |enabled                         | | |X|X|X
| |matchCriterion                  | | |X|X|X
| |metadata                        | | |X|X|X
| |objectType                      | | |X|X|X
| |pickingGeometry                 | | |X|X|X
| |pickTarget                      | | |X|X|X
| |isActive                        | | |X|X|X
| |pickedGeometry                  | | |X|X|X
| |pickedNormal                    | | |X|X|X
| |pickedPoint                     | | |X|X|X
| |pickedTextureCoordinate         | | |X|X|X
| |intersectionType                | | |X|X|X
| |sortOrder                       | | |X|X|X
|<<LineProperties>> |applied |X|X|X|X|X
| |linetype                        |X|X|X|X|X
| |linewidthScaleFactor            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
|<<LineSet>> |attrib | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          | | | | |X
| |vertexCount                     |X|X|X|X|X
|<<ListenerPointSource>> |description | | | | |X
| |dopplerEnabled                  | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |interauralDistance              | | | | |X
| |metadata                        | | | | |X
| |orientation                     | | | | |X
| |position                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |trackCurrentView                | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|<<LoadSensor>> |children | | | | |X
| |watchList                       |X|X|X|X|
| |description                     | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |timeOut                         |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isLoaded                        |X|X|X|X|X
| |loadTime                        |X|X|X|X|X
| |progress                        |X|X|X|X|X
|<<LocalFog>> |color | |X|X|X|X
| |enabled                         | |X|X|X|X
| |fogType                         | |X|X|X|X
| |metadata                        | |X|X|X|X
| |visibilityRange                 | |X|X|X|X
|<<LOD>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |center                          |X|X|X|X|X
| |forceTransitions                | |X|X|X|X
| |level_changed                   | |X|X|X|X
| |range                           |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
a|
[[IndexM]]
<<Material>> |ambientIntensity |X|X|X|X|X
| |ambientTexture                  | | | | |X
| |ambientTextureMapping           | | | | |X
| |diffuseColor                    |X|X|X|X|X
| |diffuseTexture                  | | | | |X
| |diffuseTextureMapping           | | | | |X
| |emissiveColor                   |X|X|X|X|X
| |emissiveTexture                 | | | | |X
| |emissiveTextureMapping          | | | | |X
| |metadata                        |X|X|X|X|X
| |normalScale                     | | | | |X
| |normalTexture                   | | | | |X
| |normalTextureMapping            | | | | |X
| |occlusionStrength               | | | | |X
| |occlusionTexture                | | | | |X
| |occlusionTextureMapping         | | | | |X
| |shininess                       |X|X|X|X|X
| |shininessTexture                | | | | |X
| |shininessTextureMapping         | | | | |X
| |specularColor                   |X|X|X|X|X
| |specularTexture                 | | | | |X
| |specularTextureMapping          | | | | |X
| |transparency                    |X|X|X|X|X
|<<Matrix3VertexAttribute>> |metadata | |X|X
|X|X
| |value                           | |X|X|X|X
| |name                            | |X|X|X|X
|<<Matrix4VertexAttribute>> |metadata | |X|X
|X|X
| |value                           | |X|X|X|X
| |name                            | |X|X|X|X
|<<MetadataBoolean>> |metadata | | | |X|X
| |name                            | | | |X|X
| |reference                       | | | |X|X
| |value                           | | | |X|X
|<<MetadataDouble>> |metadata |X|X|X|X|X
| |name                            |X|X|X|X|X
| |reference                       |X|X|X|X|X
| |value                           |X|X|X|X|X
|<<MetadataFloat>> |metadata |X|X|X|X|X
| |name                            |X|X|X|X|X
| |reference                       |X|X|X|X|X
| |value                           |X|X|X|X|X
|<<MetadataInteger>> |metadata |X|X|X|X|X
| |name                            |X|X|X|X|X
| |reference                       |X|X|X|X|X
| |value                           |X|X|X|X|X
|<<MetadataSet>> |metadata |X|X|X|X|X
| |name                            |X|X|X|X|X
| |reference                       |X|X|X|X|X
| |value                           |X|X|X|X|X
|<<MetadataString>> |metadata |X|X|X|X|X
| |name                            |X|X|X|X|X
| |reference                       |X|X|X|X|X
| |value                           |X|X|X|X|X
|<<MicrophoneSource>> |description | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |mediaDeviceID                   | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|<<MotorJoint>> |axis1Angle | | |X|X|X
| |axis1Torque                     | | |X|X|X
| |axis2Angle                      | | |X|X|X
| |axis2Torque                     | | |X|X|X
| |axis3Angle                      | | |X|X|X
| |axis3Torque                     | | |X|X|X
| |body1                           | | |X|X|X
| |body2                           | | |X|X|X
| |enabledAxes                     | | |X|X|X
| |forceOutput                     | | |X|X|X
| |metadata                        | | |X|X|X
| |motor1Axis                      | | |X|X|X
| |motor2Axis                      | | |X|X|X
| |motor3Axis                      | | |X|X|X
| |stop1Bounce                     | | |X|X|X
| |stop1ErrorCorrection            | | |X|X|X
| |stop2Bounce                     | | |X|X|X
| |stop2ErrorCorrection            | | |X|X|X
| |stop3Bounce                     | | |X|X|X
| |stop3ErrorCorrection            | | |X|X|X
| |motor1Angle                     | | |X|X|X
| |motor1AngleRate                 | | |X|X|X
| |motor2Angle                     | | |X|X|X
| |motor2AngleRate                 | | |X|X|X
| |motor3Angle                     | | |X|X|X
| |motor3AngleRate                 | | |X|X|X
| |autoCalc                        | | |X|X|X
|<<MovieTexture>> |autoRefresh | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |load                            | | | | |X
| |loop                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |pauseTime                       |X|X|X|X|X
| |pitch                           | | | |X|X
| |resumeTime                      |X|X|X|X|X
| |speed                           |X|X|X|X|X
| |startTime                       |X|X|X|X|X
| |stopTime                        |X|X|X|X|X
| |url                             |X|X|X|X|X
| |duration_changed                |X|X|X|X|X
| |elapsedTime                     |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isPaused                        |X|X|X|X|X
| |repeatS                         |X|X|X|X|X
| |repeatT                         |X|X|X|X|X
| |textureProperties               | | |X|X|X
|<<MultiTexture>> |alpha |X|X|X|X|X
| |color                           |X|X|X|X|X
| |description                     | | | | |X
| |function                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |mode                            |X|X|X|X|X
| |source                          |X|X|X|X|X
| |texture                         |X|X|X|X|X
|<<MultiTextureCoordinate>> |metadata |X|X|X
|X|X
| |texCoord                        |X|X|X|X|X
|<<MultiTextureTransform>> |metadata |X|X|X
|X|X
| |textureTransform                |X|X|X|X|X
a|
[[IndexN]]
<<NavigationInfo>> |set_bind |X|X|X|X|X
| |avatarSize                      |X|X|X|X|X
| |headlight                       |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |speed                           |X|X|X|X|X
| |transitionTime                  | |X|X|X|X
| |transitionType                  |X|X|X|X|X
| |type                            |X|X|X|X|X
| |visibilityLimit                 |X|X|X|X|X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
| |transitionComplete              | |X|X|X|X
|<<Normal>> |metadata |X|X|X|X|X
| |vector                          |X|X|X|X|X
|<<NormalInterpolator>> |set_fraction |X|X|X|X
|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<NurbsCurve>> |controlPoint |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |tessellation                    |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |closed                          |X|X|X|X|X
| |knot                            |X|X|X|X|X
| |order                           |X|X|X|X|X
|<<NurbsCurve2D>> |controlPoint |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |tessellation                    |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |closed                          |X|X|X|X|X
| |knot                            |X|X|X|X|X
| |order                           |X|X|X|X|X
|<<NurbsOrientationInterpolator>> |set_fraction |X|X|X|X|X
| |controlPoint                    |X|X|X|X|X
| |knot                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |order                           |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<NurbsPatchSurface>> |controlPoint |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |uTessellation                   |X|X|X|X|X
| |vTessellation                   |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |uClosed                         |X|X|X|X|X
| |uDimension                      |X|X|X|X|X
| |uKnot                           |X|X|X|X|X
| |uOrder                          |X|X|X|X|X
| |vClosed                         |X|X|X|X|X
| |vDimension                      |X|X|X|X|X
| |vKnot                           |X|X|X|X|X
| |vOrder                          |X|X|X|X|X
|<<NurbsPositionInterpolator>> |set_fraction |X|X|X|X|X
| |controlPoint                    |X|X|X|X|X
| |knot                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |order                           |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<NurbsSet>> |addGeometry |X|X|X|X|X
| |removeGeometry                  |X|X|X|X|X
| |geometry                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |tessellationScale               |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<NurbsSurfaceInterpolator>> |set_fraction
|X|X|X|X|X
| |controlPoint                    |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |position_changed                |X|X|X|X|X
| |normal_changed                  |X|X|X|X|X
| |uDimension                      |X|X|X|X|X
| |uKnot                           |X|X|X|X|X
| |uOrder                          |X|X|X|X|X
| |vDimension                      |X|X|X|X|X
| |vKnot                           |X|X|X|X|X
| |vOrder                          |X|X|X|X|X
|<<NurbsSweptSurface>> |crossSectionCurve |X|X|X
|X|X
| |metadata                        |X|X|X|X|X
| |trajectoryCurve                 |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<NurbsSwungSurface>> |metadata |X|X|X|X|X
| |profileCurve                    |X|X|X|X|X
| |trajectoryCurve                 |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<NurbsTextureCoordinate>> |controlPoint |X
|X|X|X|X
| |metadata                        |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |uDimension                      |X|X|X|X|X
| |uKnot                           |X|X|X|X|X
| |uOrder                          |X|X|X|X|X
| |vDimension                      |X|X|X|X|X
| |vKnot                           |X|X|X|X|X
| |vOrder                          |X|X|X|X|X
|<<NurbsTrimmedSurface>> |addTrimmingContour |X
|X|X|X|X
| |removeTrimmingContour           |X|X|X|X|X
| |controlPoint                    |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |trimmingContour                 |X|X|X|X|X
| |uTessellation                   |X|X|X|X|X
| |vTessellation                   |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |uClosed                         |X|X|X|X|X
| |uDimension                      |X|X|X|X|X
| |uKnot                           |X|X|X|X|X
| |uOrder                          |X|X|X|X|X
| |vClosed                         |X|X|X|X|X
| |vDimension                      |X|X|X|X|X
| |vKnot                           |X|X|X|X|X
| |vOrder                          |X|X|X|X|X
a|
[[IndexO]]
<<OpacityMapVolumeStyle>> |enabled | | | |X|X
| |metadata                        | | | |X|X
| |transferFunction                | | | |X|X
|<<OrientationChaser>> |set_destination | | |X|X
|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |duration                        | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
|<<OrientationDamper>> |set_destination | | |X|X
|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |tau                             | | |X|X|X
| |tolerance                       | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
| |order                           | | |X|X|X
|<<OrientationInterpolator>> |set_fraction |X
|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<OrthoViewpoint>> |set_bind | | |X|X|X
| |centerOfRotation                | | |X|X|X
| |description                     | | |X|X|X
| |farDistance                     | | | | |X
| |fieldOfView                     | | |X|X|X
| |jump                            | | |X|X|X
| |metadata                        | | |X|X|X
| |navigationInfo                  | | | | |X
| |nearDistance                    | | | | |X
| |orientation                     | | |X|X|X
| |position                        | | |X|X|X
| |retainUserOffsets               | | |X|X|X
| |viewAll                         | | | | |X
| |bindTime                        | | |X|X|X
| |isBound                         | | |X|X|X
|<<OscillatorSource>> |description | | | | |X
| |detune                          | | | | |X
| |enabled                         | | | | |X
| |frequency                       | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |periodicWave                    | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
a|
[[IndexP]]
<<PackagedShader>> |activate | |X|X|X|X
| |autoRefresh                     | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |metadata                        | |X|X|X|X
| |url                             | |X|X|X|X
| |isSelected                      | |X|X|X|X
| |isValid                         | |X|X|X|X
| |language                        | |X|X|X|X
| |Any number of additional fields as specified in <<PackagedShader, 31.4.4 PackagedShader>> | |X|X|X|X
|<<ParticleSystem>> |appearance | | |X|X|X
| |createParticles                 | | |X|X|X
| |geometry                        | | |X|X|X
| |enabled                         | | |X|X|X
| |lifetimeVariation               | | |X|X|X
| |maxParticles                    | | |X|X|X
| |metadata                        | | |X|X|X
| |particleLifetime                | | |X|X|X
| |particleSize                    | | |X|X|X
| |isActive                        | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |color                           | | | | |X
| |colorRamp                       | | |X|X|
| |colorKey                        | | |X|X|X
| |emitter                         | | |X|X|X
| |geometryType                    | | |X|X|X
| |physics                         | | |X|X|X
| |texCoord                        | | | | |X
| |texCoordRamp                    | | |X|X|
| |texCoordKey                     | | |X|X|X
| |visible                         | | | | |X
|<<PeriodicWave>> |description | | | | |X
| |enabled                         | | | | |X
| |metadata                        | | | | |X
| |optionsReal                     | | | | |X
| |optionsImag                     | | | | |X
| |type                            | | | | |X
|<<PhysicalMaterial>> |baseColor | | | | |X
| |baseTexture                     | | | | |X
| |baseTextureMapping              | | | | |X
| |emissiveColor                   | | | | |X
| |emissiveTexture                 | | | | |X
| |emissiveTextureMapping          | | | | |X
| |metadata                        | | | | |X
| |metallic                        | | | | |X
| |metallicRoughnessTexture        | | | | |X
| |metallicRoughnessTextureMapping | | | | |X
| |normalScale                     | | | | |X
| |normalTexture                   | | | | |X
| |normalTextureMapping            | | | | |X
| |occlusionStrength               | | | | |X
| |occlusionTexture                | | | | |X
| |occlusionTextureMapping         | | | | |X
| |roughness                       | | | | |X
| |transparency                    | | | | |X
|<<PickableGroup>> |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |description                     | | | | |X
| |metadata                        | | |X|X|X
| |objectType                      | | |X|X|X
| |pickable                        | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|<<PixelTexture>> |description | | | | |X
| |image                           |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |repeatS                         |X|X|X|X|X
| |repeatT                         |X|X|X|X|X
| |textureProperties               | | |X|X|X
|<<PixelTexture3D>> |description | | | | |X
| |image                           | |X|X|X|X
| |metadata                        | |X|X|X|X
| |repeatR                         | |X|X|X|X
| |repeatS                         | |X|X|X|X
| |repeatT                         | |X|X|X|X
| |textureProperties               | | |X|X|X
|<<PlaneSensor>> |autoOffset |X|X|X|X|X
| |axisRotation                    |X|X|X|X|X
| |description                     |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |maxPosition                     |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |minPosition                     |X|X|X|X|X
| |offset                          |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
| |trackPoint_changed              |X|X|X|X|X
| |translation_changed             |X|X|X|X|X
|<<PointEmitter>> |direction | | |X|X|X
| |mass                            | | |X|X|X
| |metadata                        | | |X|X|X
| |on                              | | | | |X
| |position                        | | |X|X|X
| |speed                           | | |X|X|X
| |surfaceArea                     | | |X|X|X
| |variation                       | | |X|X|X
|<<PointLight>> |ambientIntensity |X|X|X|X|X
| |attenuation                     |X|X|X|X|X
| |color                           |X|X|X|X|X
| |global                          | |X|X|X|X
| |intensity                       |X|X|X|X|X
| |location                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |on                              |X|X|X|X|X
| |radius                          |X|X|X|X|X
| |shadows                         | | | | |X
| |shadowIntensity                 | | | | |X
|<<PointPickSensor>> |description | | | | |X
| |enabled                         | | |X|X|X
| |matchCriterion                  | | |X|X|X
| |metadata                        | | |X|X|X
| |objectType                      | | |X|X|X
| |pickingGeometry                 | | |X|X|X
| |pickTarget                      | | |X|X|X
| |isActive                        | | |X|X|X
| |pickedGeometry                  | | |X|X|X
| |pickedPoint                     | | |X|X|X
| |intersectionType                | | |X|X|X
| |sortOrder                       | | |X|X|X
|<<PointSet>> |attrib | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          | | | | |X
|<<PolylineEmitter>> |set_coordIndex | | |X|X|X
| |coord                           | | |X|X|X
| |direction                       | | |X|X|X
| |mass                            | | |X|X|X
| |metadata                        | | |X|X|X
| |on                              | | | | |X
| |speed                           | | |X|X|X
| |surfaceArea                     | | |X|X|X
| |variation                       | | |X|X|X
| |coordIndex                      | | |X|X|X
|<<Polyline2D>> |metadata |X|X|X|X|X
| |lineSegments                    |X|X|X|X|X
|<<Polypoint2D>> |metadata |X|X|X|X|X
| |point                           |X|X|X|X|X
|<<PositionChaser>> |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |duration                        | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
|<<PositionChaser2D>> |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |duration                        | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
|<<PositionDamper>> |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |tau                             | | |X|X|X
| |tolerance                       | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
| |order                           | | |X|X|X
|<<PositionDamper2D>> |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |tau                             | | |X|X|X
| |tolerance                       | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
| |order                           | | |X|X|X
|<<PositionInterpolator>> |set_fraction |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<PositionInterpolator2D>> |set_fraction |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<PrimitivePickSensor>> |description | | | | |X
| |enabled                         | | |X|X|X
| |matchCriterion                  | | |X|X|X
| |metadata                        | | |X|X|X
| |objectType                      | | |X|X|X
| |pickingGeometry                 | | |X|X|X
| |pickTarget                      | | |X|X|X
| |isActive                        | | |X|X|X
| |pickedGeometry                  | | |X|X|X
| |intersectionType                | | |X|X|X
| |sortOrder                       | | |X|X|X
|<<ProgramShader>> |activate | |X|X|X|X
| |metadata                        | |X|X|X|X
| |programs                        | |X|X|X|X
| |isSelected                      | |X|X|X|X
| |isValid                         | |X|X|X|X
| |language                        | |X|X|X|X
|<<ProjectionVolumeStyle>> |enabled | | | |X|X
| |metadata                        | | | |X|X
| |intensityThreshold              | | | |X|X
| |type                            | | | |X|X
|<<ProximitySensor>> |center |X|X|X|X|X
| |description                     | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |size                            |X|X|X|X|X
| |enterTime                       |X|X|X|X|X
| |exitTime                        |X|X|X|X|X
| |centerOfRotation_changed        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |orientation_changed             |X|X|X|X|X
| |position_changed                |X|X|X|X|X
a|
[[IndexQ]]
<<QuadSet>> |attrib | |X|X|X|X
| |color                           | |X|X|X|X
| |coord                           | |X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        | |X|X|X|X
| |normal                          | |X|X|X|X
| |texCoord                        | |X|X|X|X
| |ccw                             | |X|X|X|X
| |colorPerVertex                  | |X|X|X|X
| |normalPerVertex                 | |X|X|X|X
| |solid                           | |X|X|X|X
a|
[[IndexR]]
<<ReceiverPdu>> |address | |X|X|X|X
| |applicationID                   | |X|X|X|X
| |description                     | | | | |X
| |enabled                         | |X|X|X|X
| |entityID                        | |X|X|X|X
| |geoCoords                       | | | | |X
| |metadata                        | |X|X|X|X
| |multicastRelayHost              | |X|X|X|X
| |multicastRelayPort              | |X|X|X|X
| |networkMode                     | |X|X|X|X
| |port                            | |X|X|X|X
| |radioID                         | |X|X|X|X
| |readInterval                    | |X|X|X|X
| |receivedPower                   | |X|X|X|X
| |receiverState                   | |X|X|X|X
| |rtpHeaderExpected               | |X|X|X|X
| |siteID                          | |X|X|X|X
| |transmitterApplicationID        | |X|X|X|X
| |transmitterEntityID             | |X|X|X|X
| |transmitterRadioID              | |X|X|X|X
| |transmitterSiteID               | |X|X|X|X
| |whichGeometry                   | |X|X|X|X
| |writeInterval                   | |X|X|X|X
| |isActive                        | |X|X|X|X
| |isNetworkReader                 | |X|X|X|X
| |isNetworkWriter                 | |X|X|X|X
| |isRtpHeaderHeard                | |X|X|X|X
| |isStandAlone                    | |X|X|X|X
| |timestamp                       | |X|X|X|X
| |bboxCenter                      | |X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | |X|X|X|X
| |visible                         | | | | |X
|<<Rectangle2D>> |metadata |X|X|X|X|X
| |size                            |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<RigidBody>> |angularDampingFactor | | |X|X|X
| |angularVelocity                 | | |X|X|X
| |autoDamp                        | | |X|X|X
| |autoDisable                     | | |X|X|X
| |bboxDisplay                     | | | | |X
| |centerOfMass                    | | |X|X|X
| |disableAngularSpeed             | | |X|X|X
| |disableLinearSpeed              | | |X|X|X
| |disableTime                     | | |X|X|X
| |enabled                         | | |X|X|X
| |finiteRotationAxis              | | |X|X|X
| |fixed                           | | |X|X|X
| |forces                          | | |X|X|X
| |geometry                        | | |X|X|X
| |inertia                         | | |X|X|X
| |linearDampingFactor             | | |X|X|X
| |linearVelocity                  | | |X|X|X
| |mass                            | | |X|X|X
| |massDensityModel                | | |X|X|X
| |metadata                        | | |X|X|X
| |orientation                     | | |X|X|X
| |position                        | | |X|X|X
| |torques                         | | |X|X|X
| |useFiniteRotation               | | |X|X|X
| |useGlobalGravity                | | |X|X|X
| |bboxCenter                      | | | | |X
| |bboxSize                        | | | | |X
| |visible                         | | | | |X
|<<RigidBodyCollection>> |set_contacts | | |X|X|X
| |autoDisable                     | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bodies                          | | |X|X|X
| |constantForceMix                | | |X|X|X
| |constantSurfaceThickness        | | |X|X|X
| |disableAngularSpeed             | | |X|X|X
| |disableLinearSpeed              | | |X|X|X
| |disableTime                     | | |X|X|X
| |enabled                         | | |X|X|X
| |errorCorrection                 | | |X|X|X
| |gravity                         | | |X|X|X
| |iterations                      | | |X|X|X
| |joints                          | | |X|X|X
| |maxCorrectionSpeed              | | |X|X|X
| |metadata                        | | |X|X|X
| |preferAccuracy                  | | |X|X|X
| |bboxCenter                      | | | | |X
| |bboxSize                        | | | | |X
| |collider                        | | |X|X|X
| |visible                         | | | | |X
a|
[[IndexS]]
<<ScalarChaser>> |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |duration                        | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
|<<ScalarDamper>> |set_destination | | | |X|X
| |set_value                       | | | |X|X
| |metadata                        | | | |X|X
| |tau                             | | | |X|X
| |tolerance                       | | | |X|X
| |isActive                        | | | |X|X
| |value_changed                   | | | |X|X
| |initialDestination              | | | |X|X
| |initialValue                    | | | |X|X
| |order                           | | | |X|X
|<<ScalarInterpolator>> |set_fraction |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|<<ScreenFontStyle>> |metadata | | |X|X|X
| |family                          | | |X|X|X
| |horizontal                      | | |X|X|X
| |justify                         | | |X|X|X
| |language                        | | |X|X|X
| |leftToRight                     | | |X|X|X
| |pointSize                       | | |X|X|X
| |spacing                         | | |X|X|X
| |style                           | | |X|X|X
| |topToBottom                     | | |X|X|X
|<<ScreenGroup>> |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |metadata                        | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|<<Script>> |autoRefresh | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |metadata                        |X|X|X|X|X
| |url                             |X|X|X|X|X
| |directOutput                    |X|X|X|X|X
| |mustEvaluate                    |X|X|X|X|X
| |Any number of additional fields as specified in <<S29_Script, 29.4.1 Script>> |X|X|X|X|X
|<<SegmentedVolumeData>> |dimensions | | | |X|X
| |metadata                        | | | |X|X
| |renderStyle                     | | | |X|X
| |segmentEnabled                  | | | |X|X
| |segmentIdentifiers              | | | |X|X
| |voxels                          | | | |X|X
| |bboxCenter                      | | | |X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | | |X|X
| |visible                         | | | | |X
|<<ShadedVolumeStyle>> |enabled | | | |X|X
| |lighting                        | | | |X|X
| |material                        | | | |X|X
| |metadata                        | | | |X|X
| |shadows                         | | | |X|X
| |surfaceNormals                  | | | |X|X
| |phaseFunction                   | | | |X|X
|<<ShaderPart>> |autoRefresh | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |metadata                        | |X|X|X|X
| |url                             | |X|X|X|X
| |type                            | |X|X|X|X
|<<ShaderProgram>> |autoRefresh | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |metadata                        | |X|X|X|X
| |url                             | |X|X|X|X
| |type                            | |X|X|X|X
| |Any number of additional fields as specified in <<ShaderProgram, 31.4.7 ShaderProgram>> | |X|X|X|X
|<<Shape>> |appearance |X|X|X|X|X
| |geometry                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |castShadow                      | | | | |X
| |visible                         | | | | |X
|<<SignalPdu>> |address |X|X|X|X|X
| |applicationID                   |X|X|X|X|X
| |data                            |X|X|X|X|X
| |dataLength                      |X|X|X|X|X
| |description                     | | | | |X
| |enabled                         | |X|X|X|X
| |encodingScheme                  |X|X|X|X|X
| |entityID                        |X|X|X|X|X
| |geoCoords                       | | | | |X
| |metadata                        |X|X|X|X|X
| |multicastRelayHost              |X|X|X|X|X
| |multicastRelayPort              |X|X|X|X|X
| |networkMode                     |X|X|X|X|X
| |port                            |X|X|X|X|X
| |radioID                         |X|X|X|X|X
| |readInterval                    |X|X|X|X|X
| |rtpHeaderExpected               |X|X|X|X|X
| |sampleRate                      |X|X|X|X|X
| |samples                         |X|X|X|X|X
| |siteID                          |X|X|X|X|X
| |tdlType                         |X|X|X|X|X
| |whichGeometry                   |X|X|X|X|X
| |writeInterval                   |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isNetworkReader                 |X|X|X|X|X
| |isNetworkWriter                 |X|X|X|X|X
| |isRtpHeaderHeard                |X|X|X|X|X
| |isStandAlone                    |X|X|X|X|X
| |timestamp                       |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<SilhouetteEnhancementVolumeStyle>> |enabled | | | |X|X
| |metadata                        | | | |X|X
| |silhouetteBoundaryOpacity       | | | |X|X
| |silhouetteRetainedOpacity       | | | |X|X
| |silhouetteSharpness             | | | |X|X
| |surfaceNormals                  | | | |X|X
|<<SingleAxisHingeJoint>> |anchorPoint | | |X|X|X
| |axis                            | | |X|X|X
| |body1                           | | |X|X|X
| |body2                           | | |X|X|X
| |forceOutput                     | | |X|X|X
| |maxAngle                        | | |X|X|X
| |metadata                        | | |X|X|X
| |minAngle                        | | |X|X|X
| |stopBounce                      | | |X|X|X
| |stopErrorCorrection             | | |X|X|X
| |angle                           | | |X|X|X
| |angleRate                       | | |X|X|X
| |body1AnchorPoint                | | |X|X|X
| |body2AnchorPoint                | | |X|X|X
|<<SliderJoint>> |axis | | |X|X|X
| |body1                           | | |X|X|X
| |body2                           | | |X|X|X
| |forceOutput                     | | |X|X|X
| |maxSeparation                   | | |X|X|X
| |metadata                        | | |X|X|X
| |sliderForce                     | | |X|X|X
| |minSeparation                   | | |X|X|X
| |stopBounce                      | | |X|X|X
| |stopErrorCorrection             | | |X|X|X
| |separation                      | | |X|X|X
| |separationRate                  | | |X|X|X
|<<Sound>> |children | | | | |X
| |description                     | | | | |X
| |direction                       |X|X|X|X|X
| |enabled                         | | | | |X
| |intensity                       |X|X|X|X|X
| |location                        |X|X|X|X|X
| |maxBack                         |X|X|X|X|X
| |maxFront                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |minBack                         |X|X|X|X|X
| |minFront                        |X|X|X|X|X
| |priority                        |X|X|X|X|X
| |source                          |X|X|X|X|X
| |spatialize                      |X|X|X|X|X
|<<SpatialSound>> |children | | | | |X
| |coneInnerAngle                  | | | | |X
| |coneOuterAngle                  | | | | |X
| |coneOuterGain                   | | | | |X
| |description                     | | | | |X
| |direction                       | | | | |X
| |distanceModel                   | | | | |X
| |dopplerEnabled                  | | | | |X
| |enabled                         | | | | |X
| |enableHRTF                      | | | | |X
| |gain                            | | | | |X
| |intensity                       | | | | |X
| |location                        | | | | |X
| |maxDistance                     | | | | |X
| |metadata                        | | | | |X
| |priority                        | | | | |X
| |referenceDistance               | | | | |X
| |rolloffFactor                   | | | | |X
| |spatialize                      | | | | |X
|<<Sphere>> |metadata |X|X|X|X|X
| |radius                          |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<SphereSensor>> |autoOffset |X|X|X|X|X
| |description                     |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |offset                          |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
| |rotation_changed                |X|X|X|X|X
| |trackPoint_changed              |X|X|X|X|X
|<<SplinePositionInterpolator>> |set_fraction | | |X|X|X
| |closed                          | | |X|X|X
| |key                             | | |X|X|X
| |keyValue                        | | |X|X|X
| |keyVelocity                     | | |X|X|X
| |metadata                        | | |X|X|X
| |normalizeVelocity               | | |X|X|X
| |value_changed                   | | |X|X|X
|<<SplinePositionInterpolator2D>> |set_fraction | | |X|X|X
| |closed                          | | |X|X|X
| |key                             | | |X|X|X
| |keyValue                        | | |X|X|X
| |keyVelocity                     | | |X|X|X
| |metadata                        | | |X|X|X
| |normalizeVelocity               | | |X|X|X
| |value_changed                   | | |X|X|X
|<<SplineScalarInterpolator>> |set_fraction| | |X|X|X
| |closed                          | | |X|X|X
| |key                             | | |X|X|X
| |keyValue                        | | |X|X|X
| |keyVelocity                     | | |X|X|X
| |metadata                        | | |X|X|X
| |normalizeVelocity               | | |X|X|X
| |value_changed                   | | |X|X|X
|<<SpotLight>> |ambientIntensity |X|X|X|X|X
| |attenuation                     |X|X|X|X|X
| |beamWidth                       |X|X|X|X|X
| |color                           |X|X|X|X|X
| |cutOffAngle                     |X|X|X|X|X
| |direction                       |X|X|X|X|X
| |global                          | |X|X|X|X
| |intensity                       |X|X|X|X|X
| |location                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |on                              |X|X|X|X|X
| |radius                          |X|X|X|X|X
| |shadows                         | | | | |X
| |shadowIntensity                 | | | | |X
|<<SquadOrientationInterpolator>> |set_fraction | | |X|X|X
| |key                             | | |X|X|X
| |keyValue                        | | |X|X|X
| |metadata                        | | |X|X|X
| |normalizeVelocity               | | |X|X|X
| |value_changed                   | | |X|X|X
|<<StaticGroup>> |children |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<StreamAudioDestination>> |channelCountMode
| |                                | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |mediaDeviceID                   | | | | |X
| |metadata                        | | | | |X
| |streamIdentifier                | | | | |X
| |channelCount                    | | | | |X
|<<StreamAudioSource>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |streamIdentifier                | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|<<StringSensor>> |deletionAllowed |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |enteredText                     |X|X|X|X|X
| |finalText                       |X|X|X|X|X
| |isActive                        |X|X|X|X|X
|<<SurfaceEmitter>> |set_coordIndex | | |X|X|
| |coordIndex                      | | |X|X|
| |mass                            | | |X|X|X
| |metadata                        | | |X|X|X
| |on                              | | | | |X
| |speed                           | | |X|X|X
| |surface                         | | |X|X|X
| |surfaceArea                     | | |X|X|X
| |variation                       | | |X|X|X
|<<Switch>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |whichChoice                     |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|[[IndexT]]<<TexCoordChaser2D>> |set_destination | | | |X|X
| |set_value                       | | | |X|X
| |metadata                        | | | |X|X
| |isActive                        | | | |X|X
| |value_changed                   | | | |X|X
| |duration                        | | | |X|X
| |initialDestination              | | | |X|X
| |initialValue                    | | | |X|X
|<<TexCoordDamper2D>> |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |tau                             | | |X|X|X
| |tolerance                       | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
| |order                           | | |X|X|X
|<<Text>> |fontStyle |X|X|X|X|X
| |length                          |X|X|X|X|X
| |lineBounds                      | |X|X|X|X
| |maxExtent                       |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |origin                          | |X|X|X|X
| |solid                           |X|X|X|X|X
| |string                          |X|X|X|X|X
| |textBounds                      | |X|X|X|X
|<<TextureBackground>> |set_bind |X|X|X|X|X
| |backTexture                     |X|X|X|X|X
| |bottomTexture                   |X|X|X|X|X
| |frontTexture                    |X|X|X|X|X
| |groundAngle                     |X|X|X|X|X
| |groundColor                     |X|X|X|X|X
| |leftTexture                     |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |rightTexture                    |X|X|X|X|X
| |skyAngle                        |X|X|X|X|X
| |skyColor                        |X|X|X|X|X
| |topTexture                      |X|X|X|X|X
| |transparency                    | | |X|X|X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
|<<TextureCoordinate>> |mapping | | | | |X
| |metadata                        |X|X|X|X|X
| |point                           |X|X|X|X|X
|<<TextureCoordinate3D>> |mapping | | | | |X
| |metadata                        | |X|X|X|X
| |point                           | |X|X|X|X
|<<TextureCoordinate4D>> |mapping | | | | |X
| |metadata                        | |X|X|X|X
| |point                           | |X|X|X|X
|<<TextureCoordinateGenerator>> |mapping
| |                                | | |X
| |metadata                        |X|X|X|X|X
| |mode                            |X|X|X|X|X
| |parameter                       |X|X|X|X|X
|<<TextureProjector>> |ambientIntensity | | | | |X
| |color                           | | | | |X
| |description                     | | | | |X
| |direction                       | | | | |X
| |farDistance                     | | | | |X
| |fieldOfView                     | | | | |X
| |global                          | | | | |X
| |intensity                       | | | | |X
| |location                        | | | | |X
| |metadata                        | | | | |X
| |nearDistance                    | | | | |X
| |on                              | | | | |X
| |shadows                         | | | | |X
| |shadowIntensity                 | | | | |X
| |texture                         | | | | |X
| |upVector                        | | | | |X
| |aspectRatio                     | | | | |X
|<<TextureProjectorParallel>> |ambientIntensity | | | | |X
| |color                           | | | | |X
| |description                     | | | | |X
| |direction                       | | | | |X
| |farDistance                     | | | | |X
| |fieldOfView                     | | | | |X
| |global                          | | | | |X
| |intensity                       | | | | |X
| |location                        | | | | |X
| |metadata                        | | | | |X
| |nearDistance                    | | | | |X
| |on                              | | | | |X
| |shadows                         | | | | |X
| |shadowIntensity                 | | | | |X
| |texture                         | | | | |X
| |aspectRatio                     | | | | |X
|<<TextureProperties>> |anisotropicDegree | | |X|X|X
| |borderColor (deprecated v4.0)   | | |X|X|X
| |borderWidth (deprecated v4.0)   | | |X|X|X
| |boundaryModeR                   | | |X|X|X
| |boundaryModeS                   | | |X|X|X
| |boundaryModeT                   | | |X|X|X
| |magnificationFilter             | | |X|X|X
| |metadata                        | | |X|X|X
| |minificationFilter              | | |X|X|X
| |textureCompression              | | |X|X|X
| |texturePriority                 | | |X|X|X
| |generateMipMaps                 | | |X|X|X
|<<TextureTransform>> |center |X|X|X|X|X
| |mapping                         | | | | |X
| |metadata                        |X|X|X|X|X
| |rotation                        |X|X|X|X|X
| |scale                           |X|X|X|X|X
| |translation                     |X|X|X|X|X
|<<TextureTransform3D>> |center | |X|X|X|X
| |mapping                         | | | | |X
| |metadata                        | |X|X|X|X
| |rotation                        | |X|X|X|X
| |scale                           | |X|X|X|X
| |translation                     | |X|X|X|X
|<<TextureTransformMatrix3D>> |mapping | | 
| |                                |X
| |matrix                          | |X|X|X|X
| |metadata                        | |X|X|X|X
|<<TimeSensor>> |cycleInterval |X|X|X|X|X
| |description                     | | | | |X
| |enabled                         |X|X|X|X|X
| |loop                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |pauseTime                       |X|X|X|X|X
| |resumeTime                      |X|X|X|X|X
| |startTime                       |X|X|X|X|X
| |stopTime                        |X|X|X|X|X
| |cycleTime                       |X|X|X|X|X
| |elapsedTime                     |X|X|X|X|X
| |fraction_changed                |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isPaused                        |X|X|X|X|X
| |time                            |X|X|X|X|X
|<<TimeTrigger>> |set_boolean |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |triggerTime                     |X|X|X|X|X
|<<ToneMappedVolumeStyle>> |coolColor | | | |X|X
| |enabled                         | | | |X|X
| |metadata                        | | | |X|X
| |surfaceNormals                  | | | |X|X
| |warmColor                       | | | |X|X
|<<TouchSensor>> |description |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |hitNormal_changed               |X|X|X|X|X
| |hitPoint_changed                |X|X|X|X|X
| |hitTexCoord_changed             |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
| |touchTime                       |X|X|X|X|X
|<<Transform>> |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |center                          |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |rotation                        |X|X|X|X|X
| |scale                           |X|X|X|X|X
| |scaleOrientation                |X|X|X|X|X
| |translation                     |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<TransformSensor>> |center | | |X|X|X
| |description                     | | | | |X
| |enabled                         | | |X|X|X
| |metadata                        | | |X|X|X
| |size                            | | |X|X|X
| |targetObject                    | | |X|X|X
| |enterTime                       | | |X|X|X
| |exitTime                        | | |X|X|X
| |isActive                        | | |X|X|X
| |orientation_changed             | | |X|X|X
| |position_changed                | | |X|X|X
|<<TransmitterPdu>> |address |X|X|X|X|X
| |antennaLocation                 |X|X|X|X|X
| |antennaPatternLength            |X|X|X|X|X
| |antennaPatternType              |X|X|X|X|X
| |applicationID                   |X|X|X|X|X
| |cryptoKeyID                     |X|X|X|X|X
| |cryptoSystem                    |X|X|X|X|X
| |description                     | | | | |X
| |enabled                         | |X|X|X|X
| |entityID                        |X|X|X|X|X
| |frequency                       |X|X|X|X|X
| |geoCoords                       | | | | |X
| |inputSource                     |X|X|X|X|X
| |lengthOfModulationParameters    |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |modulationTypeDetail            |X|X|X|X|X
| |modulationTypeMajor             |X|X|X|X|X
| |modulationTypeSpreadSpectrum    |X|X|X|X|X
| |modulationTypeSystem            |X|X|X|X|X
| |multicastRelayHost              |X|X|X|X|X
| |multicastRelayPort              |X|X|X|X|X
| |networkMode                     |X|X|X|X|X
| |port                            |X|X|X|X|X
| |power                           |X|X|X|X|X
| |radioEntityTypeCategory         |X|X|X|X|X
| |radioEntityTypeCountry          |X|X|X|X|X
| |radioEntityTypeDomain           |X|X|X|X|X
| |radioEntityTypeKind             |X|X|X|X|X
| |radioEntityTypeNomenclature     |X|X|X|X|X
| |radioEntityTypeNomenclatureVersion |X|X|X|X|X
| |radioID                         |X|X|X|X|X
| |readInterval                    |X|X|X|X|X
| |relativeAntennaLocation         |X|X|X|X|X
| |rtpHeaderExpected               |X|X|X|X|X
| |siteID                          |X|X|X|X|X
| |transmitFrequencyBandwidth      |X|X|X|X|X
| |transmitState                   |X|X|X|X|X
| |whichGeometry                   |X|X|X|X|X
| |writeInterval                   |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isNetworkReader                 |X|X|X|X|X
| |isNetworkWriter                 |X|X|X|X|X
| |isRtpHeaderHeard                |X|X|X|X|X
| |isStandAlone                    |X|X|X|X|X
| |timestamp                       |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|<<TriangleFanSet>> |attrib | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fanCount                        |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<TriangleSet>> |attrib | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<TriangleSet2D>> |metadata |X|X|X|X|X
| |vertices                        |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<TriangleStripSet>> |attrib | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |stripCount                      |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
|<<TwoSidedMaterial>> (deprecated) |ambientIntensity
| |                                |X|X|X
| |backAmbientIntensity            | | |X|X|X
| |backDiffuseColor                | | |X|X|X
| |backEmissiveColor               | | |X|X|X
| |backShininess                   | | |X|X|X
| |backSpecularColor               | | |X|X|X
| |backTransparency                | | |X|X|X
| |diffuseColor                    | | |X|X|X
| |emissiveColor                   | | |X|X|X
| |metadata                        | | |X|X|X
| |shininess                       | | |X|X|X
| |separateBackColor               | | |X|X|X
| |specularColor                   | | |X|X|X
| |transparency                    | | |X|X|X
a|
[[IndexU]]
<<UniversalJoint>> |anchorPoint | | |X|X|X
| |axis1                           | | |X|X|X
| |axis2                           | | |X|X|X
| |body1                           | | |X|X|X
| |body2                           | | |X|X|X
| |forceOutput                     | | |X|X|X
| |metadata                        | | |X|X|X
| |stop1Bounce                     | | |X|X|X
| |stop1ErrorCorrection            | | |X|X|X
| |stop2Bounce                     | | |X|X|X
| |stop2ErrorCorrection            | | |X|X|X
| |body1AnchorPoint                | | |X|X|X
| |body1Axis                       | | |X|X|X
| |body2AnchorPoint                | | |X|X|X
| |body2Axis                       | | |X|X|X
|<<UnlitMaterial>> |emissiveColor | | | | |X
| |emissiveTexture                 | | | | |X
| |emissiveTextureMapping          | | | | |X
| |metadata                        | | | | |X
| |normalScale                     | | | | |X
| |normalTexture                   | | | | |X
| |normalTextureMapping            | | | | |X
| |transparency                    | | | | |X
|[[IndexV]] <<Viewpoint>> |set_bind |X|X|X|X|X
| |centerOfRotation                |X|X|X|X|X
| |description                     |X|X|X|X|X
| |farDistance                     | | | | |X
| |fieldOfView                     |X|X|X|X|X
| |jump                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |navigationInfo                  | | | | |X
| |nearDistance                    | | | | |X
| |orientation                     |X|X|X|X|X
| |position                        |X|X|X|X|X
| |retainUserOffsets               | | |X|X|X
| |viewAll                         | | | | |X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
|<<ViewpointGroup>> |center | | |X|X|X
| |children                        | | |X|X|X
| |description                     | | |X|X|X
| |displayed                       | | |X|X|X
| |metadata                        | | |X|X|X
| |retainUserOffsets               | | |X|X|X
| |size                            | | |X|X|X
|<<Viewport>> |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |clipBoundary                    | | |X|X|X
| |metadata                        | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|<<VisibilitySensor>> |center |X|X|X|X|X
| |description                     | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |size                            |X|X|X|X|X
| |enterTime                       |X|X|X|X|X
| |exitTime                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
|<<VolumeData>> |dimensions | | | |X|X
| |metadata                        | | | |X|X
| |renderStyle                     | | | |X|X
| |voxels                          | | | |X|X
| |bboxCenter                      | | | |X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | | |X|X
| |visible                         | | | | |X
|<<VolumeEmitter>> |set_coordIndex | | |X|X|X
| |coord                           | | |X|X|X
| |coordIndex                      | | |X|X|X
| |direction                       | | |X|X|X
| |internal                        | | |X|X|X
| |mass                            | | |X|X|X
| |metadata                        | | |X|X|X
| |on                              | | | | |X
| |speed                           | | |X|X|X
| |surfaceArea                     | | |X|X|X
| |variation                       | | |X|X|X
|<<VolumePickSensor>> |description | | | | |X
| |enabled                         | | |X|X|X
| |matchCriterion                  | | |X|X|X
| |metadata                        | | |X|X|X
| |objectType                      | | |X|X|X
| |pickingGeometry                 | | |X|X|X
| |pickTarget                      | | |X|X|X
| |isActive                        | | |X|X|X
| |pickedGeometry                  | | |X|X|X
| |intersectionType                | | |X|X|X
| |sortOrder                       | | |X|X|X
|<<WaveShaper>> |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |curve                           | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |oversample                      | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
a|
[[IndexW]]
<<WindPhysicsModel>> |direction | | |X|X|X
| |enabled                         | | |X|X|X
| |gustiness                       | | |X|X|X
| |metadata                        | | |X|X|X
| |speed                           | | |X|X|X
| |turbulence                      | | |X|X|X
|<<WorldInfo>> |metadata |X|X|X|X|X
| |info                            |X|X|X|X|X
| |title                           |X|X|X|X|X
a|
[[IndexX]]
_<<X3DAppearanceChildNode>>_ |metadata |X|X|X|X|X
|_<<X3DAppearanceNode>>_ |metadata |X|X|X|X|X
|_<<X3DBackgroundNode>>_ |set_bind |X|X|X|X|X
| |groundAngle                     |X|X|X|X|X
| |groundcolor                     |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |skyAngle                        |X|X|X|X|X
| |skyColor                        |X|X|X|X|X
| |transparency                    | | |X|X|X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
|_<<X3DBindableNode>>_ |set_bind |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |bindTime                        |X|X|X|X|X
| |isBound                         |X|X|X|X|X
|_<<X3DBoundedObject>>_ |bboxCenter |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|_<<X3DChaserNode>>_ |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |duration                        | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
|_<<X3DChildNode>>_ |metadata |X|X|X|X|X
|_<<X3DColorNode>>_ |metadata |X|X|X|X|X
|_<<X3DComposableVolumeRenderStyleNode>>_ |enabled | | | |X|X
| |metadata                        | | | |X|X
|_<<X3DComposedGeometryNode>>_ |attrib | |X|X|X|X
| |color                           |X|X|X|X|X
| |coord                           |X|X|X|X|X
| |fogCoord                        | |X|X|X|X
| |metadata                        |X|X|X|X|X
| |normal                          |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |ccw                             |X|X|X|X|X
| |colorPerVertex                  |X|X|X|X|X
| |normalPerVertex                 |X|X|X|X|X
| |solid                           |X|X|X|X|X
|_<<X3DCoordinateNode>>_ |metadata |X|X|X|X|X
|_<<X3DChaserNode, X3DDamperNode>>_ |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |tau                             | | |X|X|X
| |tolerance                       | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
| |order                           | | |X|X|X
|_<<X3DDragSensorNode>>_ |autoOffset |X|X|X|X|X
| |description                     |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
| |trackPoint_changed              |X|X|X|X|X
|_<<X3DEnvironmentalSensorNode>>_ |center |X|X|X|X|X
| |description                     | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |size                            |X|X|X|X|X
| |enterTime                       |X|X|X|X|X
| |exitTime                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
|_<<X3DEnvironmentTextureNode>>_ |description | |X|X|X|X
| |metadata                        | |X|X|X|X
| |textureProperties               | |X|X|X|X
|_<<X3DFogObject>>_ |color | |X|X|X|X
| |fogType                         | |X|X|X|X
| |visibilityRange                 | |X|X|X|X
|_<<X3DChaserNode, X3DFollowerNode>>_ |set_destination | | |X|X|X
| |set_value                       | | |X|X|X
| |metadata                        | | |X|X|X
| |isActive                        | | |X|X|X
| |value_changed                   | | |X|X|X
| |initialDestination              | | |X|X|X
| |initialValue                    | | |X|X|X
|_<<X3DFontStyleNode>>_ |metadata |X|X|X|X|X
|_<<X3DGeometricPropertyNode>>_ |metadata |X|X|X|X|X
|_<<X3DGeometryNode>>_ |metadata |X|X|X|X|X
|_<<X3DGroupingNode>>_ |addChildren |X|X|X|X|X
| |removeChildren                  |X|X|X|X|X
| |children                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|_<<X3DInfoNode>>_ |metadata |X|X|X|X|X
|_<<X3DInterpolatorNode>>_ |set_fraction |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|_<<X3DKeyDeviceSensorNode>>_ |description | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
|_<<X3DLayerNode>>_ |pickable | | |X|X|X
| |metadata                        | | |X|X|X
| |viewport                        | | |X|X|X
|_<<X3DLayoutNode>>_ |metadata | | |X|X|X
|_<<X3DLightNode>>_ |ambientIntensity |X|X|X|X|X
| |color                           |X|X|X|X|X
| |global                          | |X|X|X|X
| |intensity                       |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |on                              |X|X|X|X|X
|_<<X3DMaterialNode>>_ |metadata |X|X|X|X|X
|_<<X3DMetadataObject>>_ |name |X|X|X|X|X
| |reference                       |X|X|X|X|X
|_<<X3DNBodyCollidableNode>>_ |enabled | | |X|X|X
| |metadata                        | | |X|X|X
| |rotation                        | | |X|X|X
| |translation                     | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|_<<X3DNBodyCollisionSpaceNode>>_ |enabled | | |X|X|X
| |metadata                        | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|_<<X3DNetworkSensorNode>>_ |description | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
|_<<X3DNode>>_ |metadata |X|X|X|X|X
|_<<X3DNormalNode>>_ |metadata |X|X|X|X|X
|_<<X3DNurbsControlCurveNode>>_ |controlPoint |X|X|X|X|X
| |metadata                        |X|X|X|X|X
|_<<X3DNurbsSurfaceGeometryNode>>_ |controlPoint |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |texCoord                        |X|X|X|X|X
| |uTessellation                   |X|X|X|X|X
| |vTessellation                   |X|X|X|X|X
| |weight                          |X|X|X|X|X
| |solid                           |X|X|X|X|X
| |uClosed                         |X|X|X|X|X
| |uDimension                      |X|X|X|X|X
| |uKnot                           |X|X|X|X|X
| |uOrder                          |X|X|X|X|X
| |vClosed                         |X|X|X|X|X
| |vDimension                      |X|X|X|X|X
| |vKnot                           |X|X|X|X|X
| |vOrder                          |X|X|X|X|X
|_<<X3DOneSidedMaterialNode>>_ |emissiveColor | | | | |X
| |emissiveTexture                 | | | | |X
| |emissiveTextureMapping          | | | | |X
| |metadata                        | | | | |X
| |normalTexture                   | | | | |X
| |normalTextureMapping            | | | | |X
| |normalScale                     | | | | |X
|_<<X3DParametricGeometryNode>>_ |metadata |X|X|X|X|X
|_<<X3DParticleEmitterNode>>_ |metadata | | |X|X|X
| |speed                           | | |X|X|X
| |variation                       | | |X|X|X
| |mass                            | | |X|X|X
| |surfaceArea                     | | |X|X|X
|_<<X3DParticlePhysicsModelNode>>_ |enabled | | |X|X|X
| |metadata                        | | |X|X|X
|_<<X3DPickableObject>>_ |enabled | | |X|X|X
| |metadata                        | | |X|X|X
|_<<X3DPickSensorNode>>_ |description | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        | | |X|X|X
| |matchCriterion                  | | |X|X|X
| |objectType                      | | |X|X|X
| |pickingGeometry                 | | |X|X|X
| |pickTarget                      | | |X|X|X
| |pickedGeometry                  | | |X|X|X
| |isActive                        | | |X|X|X
| |intersectionType                | | |X|X|X
| |sortOrder                       | | |X|X|X
|_<<X3DPointingDeviceSensorNode>>_
|description |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
|_<<X3DProductStructureChildNode>>_ |metadata | |X|X|X|X
| |name                            | |X|X|X|X
|_<<X3DProgrammableShaderObject>>_ |_none_ | |X|X|X|X
|_<<X3DPrototypeInstance>>_ |metadata |X|X|X|X|X
|<<X3DRigidJointNode>> |body1 | | |X|X|X
| |body2                           | | |X|X|X
| |forceOutput                     | | |X|X|X
| |metadata                        | | |X|X|X
|_<<X3DScriptNode>>_ |description | | | | |X
| |metadata                        |X|X|X|X|X
| |url                             |X|X|X|X|X
|_<<X3DSensorNode>>_ |description | | | | |X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
|_<<X3DSequencerNode>>_ |next |X|X|X|X|X
| |previous                        |X|X|X|X|X
| |set_fraction                    |X|X|X|X|X
| |key                             |X|X|X|X|X
| |keyValue                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |value_changed                   |X|X|X|X|X
|_<<X3DShaderNode>>_ |activate | |X|X|X|X
| |metadata                        | |X|X|X|X
| |isSelected                      | |X|X|X|X
| |isValid                         | |X|X|X|X
| |language                        | |X|X|X|X
|_<<X3DShapeNode>>_ |appearance |X|X|X|X|X
| |geometry                        |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |bboxCenter                      |X|X|X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        |X|X|X|X|X
| |visible                         | | | | |X
|_<<X3DSingleTextureCoordinateNode>>_ |mapping | | | | |X
| |metadata                        | | | | |X
|_<<X3DSingleTextureNode>>_ |description | | | | |X
| |metadata                        | | | | |X
| |textureProperties               | | | | |X
|_<<X3DSingleTextureTransformNode>>_ |mapping | | | | |X
| |metadata                        | | | | |X
|_<<X3DSoundChannelNode>>_ |channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |channelCount                    | | | | |X
|_<<X3DSoundDestinationNode>>_ |description | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |mediaDeviceID                   | | | | |X
| |metadata                        | | | | |X
| |channelCountMode                | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |isActive                        | | | | |X
| |channelCount                    | | | | |X
|_<<X3DSoundNode>>_ |description | | | | |X
| |enabled                         | | | | |X
| |metadata                        |X|X|X|X|X
|_<<X3DSoundProcessingNode>>_|channelCountMode | | | | |X
| |channelInterpretation           | | | | |X
| |children                        | | | | |X
| |description                     | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |tailTime                        | | | | |X
| |channelCount                    | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|_<<X3DSoundSourceNode>>_ |description | | | | |X
| |enabled                         | | | | |X
| |gain                            | | | | |X
| |metadata                        | | | | |X
| |pauseTime                       | | | | |X
| |resumeTime                      | | | | |X
| |startTime                       | | | | |X
| |stopTime                        | | | | |X
| |elapsedTime                     | | | | |X
| |isActive                        | | | | |X
| |isPaused                        | | | | |X
|_<<X3DTexture2DNode>>_ |description | | | | |X
| |metadata                        |X|X|X|X|X
| |repeatS                         |X|X|X|X|X
| |repeatT                         |X|X|X|X|X
| |textureProperties               | | |X|X|X
|_<<X3DTexture3DNode>>_ |description | | | | |X
| |metadata                        | |X|X|X|X
| |repeatS                         | |X|X|X|X
| |repeatT                         | |X|X|X|X
| |repeatR                         | |X|X|X|X
| |textureProperties               | | |X|X|X
|_<<X3DTextureCoordinateNode>>_ |metadata |X|X|X|X|X
|_<<X3DTextureNode>>_ |description | | | | |X
| |metadata                        |X|X|X|X|X
|<<X3DTextureProjectorNode>> |aspectRatio | | | | |X
| |description                     | | | | |X
| |direction                       | | | | |X
| |farDistance                     | | | | |X
| |global                          | | | | |X
| |location                        | | | | |X
| |metadata                        | | | | |X
| |nearDistance                    | | | | |X
| |on                              | | | | |X
| |texture                         | | | | |X
|_<<X3DTextureTransformNode>>_ |metadata |X|X|X|X|X
|_<<X3DTimeDependentNode>>_ |description | | | | |X
| |enabled                         | | | | |X
| |loop                            |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |pauseTime                       |X|X|X|X|X
| |resumeTime                      |X|X|X|X|X
| |startTime                       |X|X|X|X|X
| |stopTime                        |X|X|X|X|X
| |elapsedTime                     |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isPaused                        |X|X|X|X|X
|_<<X3DTouchSensorNode>>_ |description |X|X|X|X|X
| |enabled                         |X|X|X|X|X
| |metadata                        |X|X|X|X|X
| |isActive                        |X|X|X|X|X
| |isOver                          |X|X|X|X|X
| |touchTime                       |X|X|X|X|X
|_<<X3DTriggerNode>>_ |metadata |X|X|X|X|X
|_<<X3DUrlObject>>_ |autoRefresh | | | | |X
| |autoRefreshTimeLimit            | | | | |X
| |description                     | | | | |X
| |load                            | | | | |X
| |url                             |X|X|X|X|X
|_<<X3DVertexAttributeNode>>_ |metadata | |X|X|X|X
| |name                            | |X|X|X|X
|_<<X3DViewpointNode>>_ |set_bind | | |X|X|X
| |centerOfRotation                | | |X|X|X
| |description                     | | |X|X|X
| |farDistance                     | | | | |X
| |jump                            | | |X|X|X
| |metadata                        | | |X|X|X
| |navigationInfo                  | | | | |X
| |nearDistance                    | | | | |X
| |orientation                     | | |X|X|X
| |position                        | | |X|X|X
| |retainUserOffsets               | | |X|X|X
| |viewAll                         | | | | |X
| |bindTime                        | | |X|X|X
| |isBound                         | | |X|X|X
|_<<X3DViewportNode>>_ |addChildren | | |X|X|X
| |removeChildren                  | | |X|X|X
| |children                        | | |X|X|X
| |metadata                        | | |X|X|X
| |bboxCenter                      | | |X|X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | |X|X|X
| |visible                         | | | | |X
|_<<X3DVolumeDataNode>>_ |dimensions | | | |X|X
| |metadata                        | | | |X|X
| |bboxCenter                      | | | |X|X
| |bboxDisplay                     | | | | |X
| |bboxSize                        | | | |X|X
| |visible                         | | | | |X
|_<<X3DVolumeRenderStyleNode>>_ |enabled | | | |X|X
| |metadata                        | | | |X|X
|===

<<tZ_3, Table Z.3>> lists each statement
specified by this part of ISO/IEC 19775.  For each statement, the
parameters supported by each version are identified listed in the order
specified by the statement definition. Statements will appear in
multiple rows if parameters have been added in subsequent versions.

[[tZ_3 ]]
Table Z.3 — Version content
(statements)

[cols=",,,,,,",options="header",]
|===
|Statement |Parameters |3.0 |3.1 |3.2 |3.3 |4.0
|<<COMPONENTStatement, COMPONENT>> |name |X|X|X|X|X
| |level                    |X|X|X|X|X
|<<EXTERNPROTOStatement, EXTERNPROTO>> |externprotoName |X|X|X|X|X
| |externprotoInterfaceDeclaration |X|X|X|X|X
| |externprotoURL           |X|X|X|X|X
|<<HeaderStatement, header>> |standard |X|X|X|X|X
| |version                  |X|X|X|X|X
| |character encoding       |X|X|X|X|X
| |comments                 |X|X|X|X|X
|<<METAStatement, META>>    |key |X|X|X|X|X
| |data                     |X|X|X|X|X
|<<PROFILEStatement, PROFILE>> |name |X|X|X |X|X
|<<PROTOStatement, PROTO>>  |protoName |X|X|X|X|X
| |protoInterfaceDeclaration |X|X|X|X|X
| |protoDefinition          |X|X|X|X|X
|<<ROUTEStatement, ROUTE>>  |fromNodeName |X|X|X|X|X
| |fromFieldName            |X|X|X|X|X
| |toNodeName               |X|X|X|X|X
| |toFieldName              |X|X|X|X|X
|<<UNITStatement, UNIT>>    |category | |  | |X|X
| |name                     | |  | |X|X
| |conversionFactor         | |  | |X|X
|===

[[bibliography_html]]
== Bibliography

This annex contains the informative references in this documentS. These
are references to unofficial standards or documents. All official
standards are referenced in
<<references_html, 2 Normative references>>.

[cols="50%,50%",options="header",frame=ends,grid=rows]
|===
|Identifier |Reference

|[[BLINN]] *BLINN* |James F. Blinn, "Models of light reflection for
computer synthesized pictures", _Proceedings of 4th annual conference on
computer graphics and interactive techniques_, ACM SIGGRAPH, 1977. +
https://dx.doi.org/10.1145/563858.563893.

|[[CATROM]] *CATROM* |Catmull, Edwin and Rom, Raphael, "A class of
local interpolating splines" in _Proceedings of First International
Conference on Computer Aided Geometric Design_, published as
_Computer-Aided Geometric Design_ edited by Barnhill, Robert E. and
Reisenfeld, Richard F., New York Press, 1974.

|[[Cg]] *Cg* |_Cg Shading Language Specification_, NVIDIA Corporation,
version 3.1, 2012. +
https://developer.download.nvidia.com/cg/Cg_language.html

|[[COMPMUSIC]] *COMPMUSIC* |Charles Dodge and Thomas A. Jerse,
_Computer Music: Synthesis, Composition, and Performance_, second
edition, Cengage Learning, 1997. +
https://dl.acm.org/doi/book/10.5555/549805

|[[DDS]] *DDS* |DirectDraw Surface (DDS) File Reference, Microsoft
Software Developer Network, 2018. +
https://docs.microsoft.com/en-us/windows/win32/direct3ddds/dx-graphics-dds

|[[EBERT]] *EBERT* |Ebert, David and Rheingans, Penny, "Volume
Illustration: Non-Photorealistic Rendering of Volume Models",
_Proceedings of IEEE Visualization_, 2000, San Francisco, California
2000, 195-202. +
https://www.csee.umbc.edu/~rheingan/pubs/volillus00.pdf

|[[ENGEL]] *ENGEL* |Klaus Engel, Markus Hadwiger, Joe Kniss, Christof
Rezk-Salama and Daniel Weiskopf, _Real-Time Volume Graphics_, A. K.
Peters, 2006. +
https://www.real-time-volume-graphics.org

|[[FOLEY]] *FOLEY* |John F. Hughes, Andries van Dam, Morgan McGuire,
David F. Sklar, James D. Foley, Steven K. Feiner and Kurt Akeley,
_Computer Graphics Principles and Practice_, third Edition, Pearson,
2014. +
https://www.pearson.com/us/higher-education/program/Hughes-Computer-Graphics-Principles-and-Practice-3rd-Edition/PGM29906.html

|[[FX]] *FX* |_Reference for Direct3D_, Microsoft Windows Developer,
2018. +
https://docs.microsoft.com/en-us/windows/win32/direct3d9/dx9-graphics-reference

|[[GOOCH1]] *GOOCH1* |Amy Gooch, Bruce Gooch, Peter Shirley, and Elaine
Cohen. 1998. "A non-photorealistic lighting model for automatic
technical illustration", _Proceedings of the 25th annual conference on
Computer graphics and interactive techniques_ ACM SIGGRAPH, New York,
1998. +
https://doi.acm.org/10.1145/280814.280950

|[[GOOCH2]] *GOOCH2* |Bruce Gooch and Amy Gooch, _Non-photorealistic
rendering_, A K Peters, Ltd., Natick, MA, 2001. +
https://users.cs.northwestern.edu/~bgooch/Publications.html

|[[GIF]] *GIF* |_"GIF™" Graphics Interchange Format™_, Version 89a,
CompuServe, Columbus Ohio, 1990. +
https://www.w3.org/Graphics/GIF/spec-gif89a.txt

|[[GLSL]] *GLSL* |John Kessenich, Dave Baldwin and Randi Rost, _OpenGL
Shading Language Language_, version 4.60, The Khronos Group, 2019. +
https://www.khronos.org/registry/OpenGL/specs/gl/GLSLangSpec.4.60.pdf

|[[HENYEY]] *HENYEY* |L. Henyey and J. Greenstein, _Diffuse radiation
in the galaxy_, Astrophysics Journal, Vol. 93, 1941. +
https://ui.adsabs.harvard.edu/abs/1941ApJ....93...70H/abstract

|[[HLSL]] *HLSL* |_Microsoft High Level Shading Language Specification
for DirectX 9.0_ +
https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl

|[[LMIP]] *LMIP* |Y Sato 1, N Shiraga, S Nakajima, S Tamura, R Kikinis,
"Local Maximum Intensity Projection: A new rendering method for vascular
visualisation", _Journal of Computer Assisted Tomography_, Vol. 22, No.
6, 1998. +
https://pubmed.ncbi.nlm.nih.gov/9843232

|[[NRRD]] *NRRD* |_Definition of NRRD File Format_. +
http://teem.sourceforge.net/nrrd/format.html

|[[NURBS]] *NURBS* |Piegl, Les and Tiller, Wayne, _The NURBS Book_, 2nd
Edition, Springer-Verlag (Berlin), 1997. +
https://www.springer.com/gp/book/9783642973857

|[[OPENGL]] *OPENGL* |Mark Segal and Kurt Akeley, _OpenGL Core
Profile_, version 4.6. The Khronos Group, 2019. +
https://khronos.org/registry/OpenGL/specs/gl/glspec46.core.pdf

|[[PHONG]]PHONG*# |B. T. Phong, "Illumination for computer generated
pictures", _Communications of the ACM_, vol. 18 no. 6, 1975. +
https://users.cs.northwestern.edu/~ago820/cs395/Papers/Phong_1975.pdf

|[[SHOEMAKE]]SHOEMAKE*# |Shoemake, Ken, _Animating Rotations with
Quaternion Curves_, _Proceedings of 14th annual conference on computer
graphics and interactive techniques_, ACM SIGGRAPH 1987. +
https://www.cs.cmu.edu/~kiranb/animation/p245-shoemake.pdf

|[[SNY87]] *SNY87* |John P. Snyder, _MAP Projections: A Working
Manual_, U.S. Geological Survey Professional Paper 1395, U.S. Government
Printing Office, Washington DC, 1987. +
https://pubs.er.usgs.gov/publication/pp1395

|[[VIS2002]] *VIS2002* |Aidong Lu, C.J. Morris, D.S. Ebert, P.
Rheingans, C. Hansen, "Non-photorealistic volume rendering using
stippling techniques," _IEEE Visualization_, 2002.
https://ieeexplore.ieee.org/document/1183777

|[[VOL]] *VOL* |Brooks, Paul, _Volume data format_, 2000. +
http://paulbourke.net/dataformats/volumetric

|[[WAV]] *WAV* |_Waveform Audio File Format, Multimedia Programming
Interface and Data Specification v1.0_, Issued by IBM & Microsoft,
1991. +
https://www.loc.gov/preservation/digital/formats/fdd/fdd000001.shtml +

|[[W3C-CSS-Snapshot]] *W3C-CSS-Snapshot*
|https://www.w3.org/TR/css-2018[Cascading Style Sheets (CSS) Snapshot
2018], _World Wide Web Consortium (W3C) Working Group Note, 22 January
2019_.

|[[W3C-CSS-Style]] *W3C-CSS-Style*
|https://www.w3.org/TR/css-style-attr[Cascading Style Sheets (CSS) Style
Attributes], _World Wide Web Consortium (W3C) Recommendation, 7 November
2013_.

|[[W3C-DOM]] *W3C-DOM* |https://www.w3.org/DOM/DOMTR[Document Object
Model (DOM) Technical Reports], _World Wide Web Consortium (W3C), 1
December 2020_.

|[[W3C-HTML5]] *W3C-HTML5* |https://www.w3.org/TR/html52[Hypertext
Markup Language (HTML) 5.2], _World Wide Web Consortium (W3C)
Recommendation, 14 December 2017_.

|[[W3C-SVG]] *W3C-SVG* |https://www.w3.org/TR/SVG[Scalable Vector
Graphics (SVG) 2], _World Wide Web Consortium (W3C) Candidate
Recommendation, 4 October 2018_.

|[[W3C-XML]] *W3C-XML* |https://www.w3.org/TR/xml[Extensible Markup
Language (XML) 1.0] (Fifth Edition), _World Wide Web Consortium (W3C)
Recommendation, 26 November 2008_.

|[[WHATWG-Fetch]] *WHATWG-Fetch* |https://fetch.spec.whatwg.org[Fetch] Standard, _WHATWG community,6 March 2023_.
|===

[[componentIndex_html]]
== Component index

=== General

This index lists the components in alphabetical order by component
title. The "Component" column lists the component title and includes
links to the component specification. The "Name" column lists the
component name used in the COMPONENT statement. The "Clause" column
specifies the clause that contains the specification of the component.

[options="header,autowidth",frame=ends,grid=rows]
|===
|Component |Name |Clause
|<<annotation_html, Annotation>> |CADGeometry |42
|<<CADGeometry_html, CAD geometry>> |CADGeometry |32
|<<core_html, Core>> |Core |7
|<<environmentalTexturing_html, Cube map environmental texturing>> |CubeMapTexturing |34
|<<dis_html, Distributed interactive simulation>> |DIS |28
|<<environmentalEffects_html, Environmental effects>> |EnvironmentalEffects |24
|<<environmentalSensor_html, Environmental sensor>> |EnvironmentalSensor |22
|<<eventUtilities_html, Event utilities>> |EventUtilities |30
|<<followers_html, Followers>> |Followers |39
|<<geometry2D_html, Geometry2D>> |Geometry2D |14
|<<geometry3D_html, Geometry3D>> |Geometry3D |13
|<<geospatial_html, Geospatial>> |Geospatial |25
|<<grouping_html, Grouping>> |Grouping |10
|<<hanim_html, Humanoid animation (HAnim)>> |HAnim |26
|<<interpolators_html, Interpolation>> |Interpolation |19
|<<keyDeviceSensor_html, Key device sensor>> |KeyDeviceSensor |21
|<<layering_html, Layering>> |Layering |35
|<<lighting_html, Lighting>> |Lighting |17
|<<navigation_html, Navigation>> |Navigation |23
|<<networking_html, Networking>> |Networking |9
|<<nurbs_html, NURBS>> |NURBS |27
|<<particleSystems_html, Particle systems>> |ParticleSystems |40
|<<picking_html, Picking>> |Picking |38
|<<pointingDeviceSensor_html, Pointing device sensor>> |PointDeviceSensor |20
|<<shaders_html, Programmable shaders>> |Shaders |31
|<<rendering_html, Rendering>> |Rendering |11
|<<rigidBodyPhysics_html, Rigid body physics>> |RigidBodyPhysics |37
|<<scripting_html, Scripting>> |Scripting |29
|<<shape_html, Shape>> |Shape |12
|<<sound_html, Sound>> |Sound |16
|<<text_html, Text>> |Text |15
|<<textureProjection_html, Texture projection>> |Texture projection |43
|<<texturing_html, Texturing>> |Texturing |18
|<<texture3D_html, Texturing3D>> |Texturing3D |33
|<<time_html, Time>> |Time |8
|<<volume_html, Volume rendering>> |VolumeRendering |41
|===

[[profileIndex_html]]
== Profile index

=== General

This index lists the profiles in alphabetical order.

[cols=",^",options="header",]
|===
|Profile |Annex
|<<CADInterchange_html, CADInterchange>> |H
|<<coreprofile_html, Core>> |A
|<<fullProfile_html, Full>> |F
|<<immersive_html, Immersive>> |E
|<<interactive_html, Interactive>> |C
|<<interchange_html, Interchange>> |B
|<<MedicalInterchange_html, MedicalInterchange>> |L
|<<MPEG4interactive_html, MPEG-4 interactive>> |D
|===

[[nodeIndex_html]]
== Node, abstract node type, and abstract interface index

=== General

This index lists the nodes in alphabetical order. Abstract node types
and abstract interfaces are italicized.

[options="header,autowidth",frame=ends,grid=rows]
|===
|Subclause|Node, abstract node type, and abstract interface
|12.4.1   |<<AcousticProperties>> |16.4.1   |<<Analyser>>
|9.4.1    |<<Anchor>> |12.4.2   |<<Appearance>>
|14.3.1   |<<Arc2D>> |14.3.2   |<<ArcClose2D>>
|16.4.2   |<<AudioClip>> |16.4.3   |<<AudioDestination>>
|24.4.1   |<<Background>> |37.4.1   |<<BallJoint>>
|23.4.1   |<<Billboard>> |16.4.5   |<<BiquadFilter>>
|41.4.1   |<<BlendedVolumeStyle>> |30.4.1   |<<BooleanFilter>>
|30.4.2   |<<BooleanSequencer>> |30.4.3   |<<BooleanToggle>>
|30.4.4   |<<BooleanTrigger>> |41.4.2   |<<BoundaryEnhancementVolumeStyle>>
|40.4.1   |<<BoundedPhysicsModel>> |13.3.1   |<<Box>>
|16.4.3   |<<BufferAudioSource>> |32.4.1   |<<CADAssembly>>
|32.4.2   |<<CADFace>> |32.4.3   |<<CADLayer>>
|32.4.4   |<<CADPart>> |41.4.3   |<<CartoonVolumeStyle>>
|16.4.6   |<<ChannelMerger>> |16.4.7   |<<ChannelSelector>>
|16.4.8   |<<ChannelSplitter>> |14.3.3   |<<Circle2D>>
|11.4.1   |<<ClipPlane>> |37.4.2   |<<CollidableOffset>>
|37.4.3   |<<CollidableShape>> |23.4.2   |<<Collision>>
|37.4.4   |<<CollisionCollection>> |37.4.5   |<<CollisionSensor>>
|37.4.6   |<<CollisionSpace>> |11.4.1   |<<Color>>
|39.4.1   |<<ColorChaser>> |39.4.2   |<<ColorDamper>>
|19.4.1   |<<ColorInterpolator>> |11.4.2   |<<ColorRGBA>>
|34.4.1   |<<ComposedCubeMapTexture>> |31.4.1   |<<ComposedShader>>
|33.4.1   |<<ComposedTexture3D>> |41.4.4   |<<ComposedVolumeStyle>>
|13.3.2   |<<Cone>> |40.4.2   |<<ConeEmitter>>
|37.4.7   |<<Contact>> |27.4.1   |<<Contour2D>>
|27.4.2   |<<ContourPolyline2D>> |16.4.9   |<<Convolver>>
|11.4.3   |<<Coordinate>> |39.4.3   |<<CoordinateChaser>>
|39.4.4   |<<CoordinateDamper>> |27.4.3   |<<CoordinateDouble>>
|19.4.2   |<<CoordinateInterpolator>> |19.4.3   |<<CoordinateInterpolator2D>>
|13.3.3   |<<Cylinder>> |20.4.1   |<<CylinderSensor>>
|16.4.10  |<<Delay>>
|17.4.1   |<<DirectionalLight>>
|28.3.1   |<<DISEntityManager>>
|28.3.2   |<<DISEntityTypeMapping>>
|14.3.4   |<<Disk2D>>
|37.4.8   |<<DoubleAxisHingeJoint>>
|16.4.11  |<<DynamicsCompressor>>
|19.4.4   |<<EaseInEaseOut>>
|41.4.5   |<<EdgeEnhancementVolumeStyle>>
|13.3.4   |<<ElevationGrid>>
|28.3.3   |<<EspduTransform>>
|40.4.3   |<<ExplosionEmitter>>
|13.3.5   |<<Extrusion>>
|12.4.3   |<<FillProperties>>
|31.4.2   |<<FloatVertexAttribute>>
|24.4.2   |<<Fog>>
|24.4.3   |<<FogCoordinate>>
|15.4.1   |<<FontStyle>>
|40.4.4   |<<ForcePhysicsModel>>
|16.4.12  |<<Gain>>
|34.4.2   |<<GeneratedCubeMapTexture>>
|25.3.1   |<<GeoCoordinate>>
|25.3.2   |<<GeoElevationGrid>>
|25.3.3   |<<GeoLocation>>
|25.3.4   |<<GeoLOD>>
|25.3.5   |<<GeoMetadata>>
|25.3.6   |<<GeoOrigin>>
|25.3.7   |<<GeoPositionInterpolator>>
|25.3.8   |<<GeoProximitySensor>>
|25.3.9   |<<GeoTouchSensor>>
|25.3.10  |<<GeoTransform>>
|25.3.11  |<<GeoViewpoint>>
|10.4.1   |<<Group>>
|26.3.1   |<<HAnimDisplacer>>
|26.3.2   |<<HAnimHumanoid>>
|26.3.3   |<<HAnimJoint>>
|26.3.4   |<<HAnimMotion>>
|26.3.5   |<<HAnimSegment>>
|26.3.6   |<<HAnimSite>>
|34.4.3   |<<ImageCubeMapTexture>>
|18.4.1   |<<ImageTexture>>
|33.4.2   |<<ImageTexture3D>>
|13.3.6   |<<IndexedFaceSet>>
|11.4.4   |<<IndexedLineSet>>
|32.4.5   |<<IndexedQuadSet>>
|11.4.5   |<<IndexedTriangleFanSet>>
|11.4.6   |<<IndexedTriangleSet>>
|11.4.7   |<<IndexedTriangleStripSet>>
|9.4.2    |<<Inline>>
|30.4.5   |<<IntegerSequencer>>
|30.4.6   |<<IntegerTrigger>>
|41.4.6   |<<IsoSurfaceVolumeData>>
|21.4.1   |<<KeySensor>>
|35.4.1   |<<Layer>>
|35.4.2   |<<LayerSet>>
|36.4.1   |<<Layout>>
|36.4.2   |<<LayoutGroup>>
|36.4.3   |<<LayoutLayer>>
|38.4.1   |<<LinePickSensor>>
|12.4.4   |<<LineProperties>>
|11.4.8   |<<LineSet>>
|16.4.13  |<<ListenerPointSource>>
|9.4.3    |<<LoadSensor>>
|24.4.4   |<<LocalFog>>
|23.4.3   |<<LOD>>
|12.4.5   |<<Material>>
|31.4.3   |<<Matrix3VertexAttribute>>
|31.4.4   |<<Matrix4VertexAttribute>>
|7.4.1    |<<MetadataBoolean>>
|7.4.2    |<<MetadataDouble>>
|7.4.3    |<<MetadataFloat>>
|7.4.4    |<<MetadataInteger>>
|7.4.5    |<<MetadataSet>>
|7.4.6    |<<MetadataString>>
|16.4.14  |<<MicrophoneSource>>
|37.4.8   |<<MotorJoint>>
|18.4.2   |<<MovieTexture>>
|18.4.3   |<<MultiTexture>>
|18.4.4   |<<MultiTextureCoordinate>>
|18.4.5   |<<MultiTextureTransform>>
|23.4.4   |<<NavigationInfo>>
|11.4.9   |<<Normal>>
|19.4.5   |<<NormalInterpolator>>
|27.4.4   |<<NurbsCurve>>
|27.4.5   |<<NurbsCurve2D>>
|27.4.6   |<<NurbsOrientationInterpolator>>
|27.4.7   |<<NurbsPatchSurface>>
|27.4.8   |<<NurbsPositionInterpolator>>
|27.4.9   |<<NurbsSet>>
|27.4.10  |<<NurbsSurfaceInterpolator>>
|27.4.11  |<<NurbsSweptSurface>>
|27.4.12  |<<NurbsSwungSurface>>
|27.4.13  |<<NurbsTextureCoordinate>>
|27.4.14  |<<NurbsTrimmedSurface>>
|41.4.7   |<<OpacityMapVolumeStyle>>
|39.4.5   |<<OrientationChaser>>
|39.4.6   |<<OrientationDamper>>
|19.4.6   |<<OrientationInterpolator>>
|23.4.5   |<<OrthoViewpoint>>
|16.4.15  |<<OscillatorSource>>
|31.4.5   |<<PackagedShader>>
|40.4.5   |<<ParticleSystem>>
|16.4.16  |<<PeriodicWave>>
|12.4.6   |<<PhysicalMaterial>>
|38.4.2   |<<PickableGroup>>
|18.4.6   |<<PixelTexture>>
|33.4.3   |<<PixelTexture3D>>
|20.4.2   |<<PlaneSensor>>
|40.4.6   |<<PointEmitter>>
|17.4.3   |<<PointLight>>
|38.4.3   |<<PointPickSensor>>
|12.4.7   |<<PointProperties>>
|11.4.10  |<<PointSet>>
|14.3.5   |<<Polyline2D>>
|40.4.7   |<<PolylineEmitter>>
|14.3.6   |<<Polypoint2D>>
|39.4.7   |<<PositionChaser>>
|39.4.8   |<<PositionChaser2D>>
|39.4.9   |<<PositionDamper>>
|39.4.10  |<<PositionDamper2D>>
|19.4.7   |<<PositionInterpolator>>
|19.4.8   |<<PositionInterpolator2D>>
|38.4.4   |<<PrimitivePickSensor>>
|31.4.6   |<<ProgramShader>>
|41.4.8   |<<ProjectionVolumeStyle>>
|22.4.1   |<<ProximitySensor>>
|32.4.6   |<<QuadSet>>
|28.3.4   |<<ReceiverPdu>>
|14.3.7   |<<Rectangle2D>>
|37.4.9   |<<RigidBody>>
|37.4.10  |<<RigidBodyCollection>>
|39.4.11  |<<ScalarChaser>>
|39.4.12  |<<ScalarDamper>>
|19.4.9   |<<ScalarInterpolator>>
|36.4.4   |<<ScreenFontStyle>>
|36.4.5   |<<ScreenGroup>>
|29.4.1   |<<Script>>
|41.4.9   |<<SegmentedVolumeData>>
|41.4.10  |<<ShadedVolumeStyle>>
|31.4.7   |<<ShaderPart>>
|31.4.8   |<<ShaderProgram>>
|12.4.8   |<<Shape>>
|28.3.5   |<<SignalPdu>>
|41.4.11  |<<SilhouetteEnhancementVolumeStyle>>
|37.4.11  |<<SingleAxisHingeJoint>>
|37.4.12  |<<SliderJoint>>
|16.4.17  |<<Sound>>
|16.4.18  |<<SpatialSound>>
|13.3.7   |<<Sphere>>
|20.4.3   |<<SphereSensor>>
|19.4.10  |<<SplinePositionInterpolator>>
|19.4.11  |<<SplinePositionInterpolator2D>>
|19.4.12  |<<SplineScalarInterpolator>>
|17.4.4   |<<SpotLight>>
|19.4.13  |<<SquadOrientationInterpolator>>
|10.4.2   |<<StaticGroup>>
|16.4.19  |<<StreamAudioDestination>>
|16.4.20  |<<StreamAudioSource>>
|21.4.2   |<<StringSensor>>
|40.4.8   |<<SurfaceEmitter>>
|10.4.3   |<<Switch>>
|39.4.13  |<<TexCoordChaser2D>>
|39.4.14  |<<TexCoordDamper2D>>
|15.4.2   |<<Text>>
|24.4.3   |<<TextureBackground>>
|18.4.7   |<<TextureCoordinate>>
|33.4.4   |<<TextureCoordinate3D>>
|33.4.5   |<<TextureCoordinate4D>>
|18.4.8   |<<TextureCoordinateGenerator>>
|42.4.1   |<<TextureProjector>>
|42.4.2   |<<TextureProjectorParallel>>
|18.4.9   |<<TextureProperties>>
|18.4.10  |<<TextureTransform>>
|33.4.7   |<<TextureTransform3D>>
|33.4.6   |<<TextureTransformMatrix3D>>
|8.4.1    |<<TimeSensor>>
|30.4.7   |<<TimeTrigger>>
|41.4.12  |<<ToneMappedVolumeStyle>>
|20.4.4   |<<TouchSensor>>
|10.4.4   |<<Transform>>
|22.4.2   |<<TransformSensor>>
|28.3.6   |<<TransmitterPdu>>
|11.4.11  |<<TriangleFanSet>>
|11.4.12  |<<TriangleSet>>
|14.3.8   |<<TriangleSet2D>>
|11.4.13  |<<TriangleStripSet>>
|12.4.9   |<<TwoSidedMaterial>> (deprecated)
|37.4.13  |<<UniversalJoint>>
|12.4.10  |<<UnlitMaterial>>
|23.4.6   |<<Viewpoint>>
|23.4.7   |<<ViewpointGroup>>
|35.4.3   |<<Viewport>>
|22.4.3   |<<VisibilitySensor>>
|41.4.13  |<<VolumeData>>
|40.4.7   |<<VolumeEmitter>>
|38.4.5   |<<VolumePickSensor>>
|16.4.21  |<<WaveShaper>>
|40.4.8   |<<WindPhysicsModel>>
|7.4.6    |<<WorldInfo>>
|12.3.1  |_<<X3DAppearanceChildNode>>_
|12.3.2  |_<<X3DAppearanceNode>>_
|24.3.1  |_<<X3DBackgroundNode>>_
|7.3.1   |_<<X3DBindableNode>>_
|10.3.1  |_<<X3DBoundedObject>>_
|39.3.1  |_<<X3DChaserNode>>_
|7.3.2   |_<<X3DChildNode>>_
|11.3.1  |_<<X3DColorNode>>_
|41.3.1  |_<<X3DComposableVolumeRenderStyleNode>>_
|11.3.2  |_<<X3DComposedGeometryNode>>_
|11.3.3  |_<<X3DCoordinateNode>>_
|39.3.2  |_<<X3DDamperNode>>_
|20.3.1  |_<<X3DDragSensorNode>>_
|22.3.1  |_<<X3DEnvironmentalSensorNode>>_
|34.3.1  |_<<X3DEnvironmentTextureNode>>_
|24.3.2  |_<<X3DFogObject>>_
|39.3.3  |_<<X3DFollowerNode>>_
|15.3.1  |_<<X3DFontStyleNode>>_
|11.3.4  |_<<X3DGeometricPropertyNode>>_
|11.3.5  |_<<X3DGeometryNode>>_
|10.3.2  |_<<X3DGroupingNode>>_
|7.3.3   |_<<X3DInfoNode>>_
|19.3.1  |_<<X3DInterpolatorNode>>_
|21.3.1  |_<<X3DKeyDeviceSensorNode>>_
|35.3.1  |_<<X3DLayerNode>>_
|36.3.1  |_<<X3DLayoutNode>>_
|17.3.1  |_<<X3DLightNode>>_
|12.3.3  |_<<X3DMaterialNode>>_
|7.3.3   |_<<X3DMetadataObject>>_
|37.3.1  |_<<X3DNBodyCollidableNode>>_
|37.3.2  |_<<X3DNBodyCollisionSpaceNode>>_
|9.3.1   |_<<X3DNetworkSensorNode>>_
|7.3.4   |_<<X3DNode>>_
|11.3.6  |_<<X3DNormalNode>>_
|27.3.1  |_<<X3DNurbsControlCurveNode>>_
|27.3.2  |_<<X3DNurbsSurfaceGeometryNode>>_
|12.3.4  |_<<X3DOneSidedMaterialNode>>_
|27.3.3  |_<<X3DParametricGeometryNode>>_
|40.3.1  |_<<X3DParticleEmitterNode>>_
|40.3.2  |_<<X3DParticlePhysicsModelNode>>_
|38.3.1  |_<<X3DPickableObject>>_
|38.3.2  |_<<X3DPickSensorNode>>_
|20.3.2  |_<<X3DPointingDeviceSensorNode>>_
|32.3.1  |_<<X3DProductStructureChildNode>>_
|31.3.1  |_<<X3DProgrammableShaderObject>>_
|7.3.5   |_<<X3DPrototypeInstance>>_
|37.3.3  |_<<X3DRigidJointNode>>_
|29.3.1  |_<<X3DScriptNode>>_
|7.3.6   |_<<X3DSensorNode>>_
|30.3.1  |_<<X3DSequencerNode>>_
|31.3.2  |_<<X3DShaderNode>>_
|12.3.5  |_<<X3DShapeNode>>_
|18.3.1  |_<<X3DSingleTextureCoordinateNode>>_
|18.3.2  |_<<X3DSingleTextureNode>>_
|18.3.3  |_<<X3DSingleTextureTransformNode>>_
|16.3.1  |_<<X3DSoundChannelNode>>_
|16.3.2  |_<<X3DSoundDestinationNode>>_
|16.3.3  |_<<X3DSoundNode>>_
|16.3.4  |_<<X3DSoundProcessingNode>>_
|16.3.5  |_<<X3DSoundSourceNode>>_
|18.3.4  |_<<X3DTexture2DNode>>_
|33.3.1  |_<<X3DTexture3DNode>>_
|18.3.5  |_<<X3DTextureCoordinateNode>>_
|18.3.6  |_<<X3DTextureNode>>_
|42.3.1  |_<<X3DTextureProjectorNode>>_
|18.3.7  |_<<X3DTextureTransformNode>>_
|8.3.1   |_<<X3DTimeDependentNode>>_
|20.3.3  |_<<X3DTouchSensorNode>>_
|30.3.2  |_<<X3DTriggerNode>>_
|9.3.2   |_<<X3DUrlObject>>_
|31.3.3  |_<<X3DVertexAttributeNode>>_
|23.3.1  |_<<X3DViewpointNode>>_
|35.3.2  |_<<X3DViewportNode>>_
|41.3.2  |_<<X3DVolumeDataNode>>_
|41.3.3  |_<<X3DVolumeRenderStyleNode>>_
|===


[[A19775_2]]
== Part 2: Scene access interface (SAI)


Information technology — Computer graphics, image processing and
environmental data representation — Extensible 3D (X3D) —
Part 2: Scene access interface (SAI)

ISO/IEC 19775-2:2015

This document is ISO/IEC 19775-2:2015, Extensible 3D (X3D), Edition 3.
The full title of this part of ISO/IEC 19775 is: _Information technology
— Computer graphics, image processing and environmental data
representation — Extensible 3D (X3D) — Part 2: Scene access interface
(SAI)_.


• <<A2_foreword_html, Foreword>>
• <<A2_introduction_html, Introduction>>
• 1 <<A2_scope_html, Scope>>
• 2 <<A2_references_html, Normative references>>  
• 3 <<A2_glossary_html, Terms, definitions, acronyms and abbreviations>>
• 4 <<A2_concepts_html, Concepts>>
• 5 <<A2_dataRef_html, Data type reference>>
• 6 <<A2_servRef_html, Services reference>>
• 7 <<A2_conformance_html, Conformance and minimum support requirements>>
• A <<A2_vrml97_html, VRML scripting backwards compatibility>>


The *_Foreword_* provides background on the standards process for X3D.
The *_Introduction_* describes the purpose, design criteria, and
characteristics of X3D. The following clauses define this part of
ISO/IEC 19775:

. *_Scope_* defines the problem area that X3D addresses.
. *_Normative references_* lists the normative standards referenced in
this part of ISO/IEC 19775.
. *_Terms, definitions, acronyms and abbreviations_* contains the
glossary of terminology used in this part of ISO/IEC 19775.
. *_Concepts_* describes various fundamentals of the X3D scene access
interface.
. *_Data type reference_* defines the data types used by the application
programmer interfaces.
. *_Services reference_* defines the functionality which may be accessed
through the application programmer interfaces.
. *_Conformance and minimum support requirements_* describes the
conformance requirements for X3D implementations.

There is one annex included in the specification:

[upperalpha]
. *_VRML 97 scripting backwards compatibility_* describes the
manner in which X3D Scripting can be used to provide backwards
compatibility with VRML 97 scripting.

[[A2_foreword_html]]
== Foreword

http://www.iso.org/[ISO] (the International Organization for
Standardization) and http://www.iec.ch/[IEC] (the International
Electrotechnical Commission) form a specialized system for worldwide
standardization. National bodies that are members of ISO or IEC
participate in the development of International Standards through
technical committees established by the respective organization to deal
with particular fields of technical activity. ISO and IEC technical
committees collaborate in fields of mutual interest. Other international
organizations, governmental and non-governmental, in liaison with ISO
and IEC, also take part in the work. In the field of information
technology, ISO and IEC have established a joint technical committee,
http://www.iso.org/iso/jtc1_home.html[ISO/IEC JTC 1].

International Standards are drafted in accordance with the rules given
in the ISO/IEC Directives, Part 2.

The main task of the joint technical committee is to prepare
International Standards. Draft International Standards adopted by the
joint technical committee are circulated to national bodies for voting.
Publication as an International Standard requires approval by at least
75 % of the national bodies casting a vote.

Attention is drawn to the possibility that some of the elements of this
document may be the subject of patent rights. ISO and IEC shall not be
held responsible for identifying any or all such patent rights.

ISO/IEC 19775-2 was prepared by Joint Technical Committee ISO/IEC JTC 1,
_Information technology_, Subcommittee 24, _Computer graphics, image
processing and environmental data representation_, in collaboration with
http://www.web3d.org/[Web3D Consortium, Inc.]

This third edition cancels and replaces the second edition (ISO/IEC
19775-2:2010), which has been technically revised.

ISO/IEC 19775 consists of the following parts, under the general title
_Information technology — Computer graphics, image processing and
environmental data representation — Extensible 3D (X3D):_

____
_Part 1:  Architecture and base components_ +
_Part 2:  Scene access interface (SAI)_ (this part)
____

[[A2_introduction_html]]
== Introduction


[[A2_Purpose]]
== Purpose

X3D is a file format and related access services for describing
interactive 3D objects and worlds. X3D is designed to be used on the
Internet, intranets, and local client systems. X3D is also intended to
be a universal interchange format for integrated 3D graphics and
multimedia. X3D may be used in a variety of application areas such as
engineering and scientific visualization, multimedia presentations,
entertainment and educational titles, web pages, and shared virtual
worlds.

This part of ISO/IEC 19775 defines the scene access interface that can
be used to interact with X3D worlds both from within the worlds or from
external programs.

[[A2_scope_html]]
== 1 Scope

This part of ISO/IEC 19775 specifies a standard set of services that are
made available by a browser so that an author can access the scene graph
while it is running. Such access is designed to support inspection and
modification of the scene graph.

[[A2_references_html]]
== 2 Normative references

The following documents, in whole or in part, are normatively referenced
in this document and are indispensable for its application. For dated
references, only the edition cited applies. For undated references, the
latest edition of the referenced document (including any amendments)
applies.

[options="header,autowidth",frame=ends,grid=rows]
|===
|Identifier |Reference
|[[I10646_1]]*I10646* |http://www.iso.org/[ISO/IEC] 10646,
_Information technology — Universal Multiple-Octet Coded Character Set
(UCS)_

|[[I14496_1]]*I14496-1* |http://www.iso.org/[ISO/IEC] 14496-1:2010,
_Information technology — Coding of audio-visual objects — Part 1:
Systems_

|[[I14772_1]]*I14772-1* |http://www.iso.org/[ISO/IEC] 14772-1:1997,
_Information technology — Computer graphics and image processing — The
Virtual Reality Modeling Language — Part 1: Functional specification and
UTF-8 encoding_

|[[I14772_2]]*I14772-2* |http://www.iso.org/[ISO/IEC] 14772-2:2004,
_Information technology — Computer graphics and image processing — The
Virtual Reality Modeling Language (VRML) — Part 2: External authoring
interface (EAI)_

|[[I19775_1]]*I19775-1* |http://www.iso.org/[ISO/IEC] 19775-1:2013,
_Information technology — Computer graphics, image processing and
environmental data representation — Extensible 3D (X3D) — Part 1:
Architecture and base components_

|[[I19776_1]]*I19776-1* |http://www.iso.org/[ISO/IEC] 19776-1:2015,
_Information technology — Computer graphics, image processing and
environmental data representation— Extensible 3D (X3D) encodings — Part
1: Extensible Markup Language (XML) encoding (in preparation)_

|[[I19776_2]]*I19776-2* |http://www.iso.org/[ISO/IEC] 19776-2:2015,
_Information technology — Computer graphics, image processing and
environmental data representation — Extensible 3D (X3D) encodings — Part
2: Classic VRML encoding (in preparation)_

|[[I19776_3]]*I19776-3* |http://www.iso.org/[ISO/IEC] 19776-3:2015,
_Information technology — Computer graphics, image processing and
environmental data representation— Extensible 3D (X3D) encodings — Part
3: Compressed binary encoding (in preparation)_

|[[I19777]]*I19777* |http://www.iso.org/[ISO/IEC] 19777-1:201x,
__Information technology — Computer graphics, image processing and
environmental data representation — Extensible 3D (X3D) language
bindings — Part 1: ECMAScript (in preparation) +
__ISO/IEC 19777-2:201x, _Information technology — Computer graphics,
image processing and environmental data representation —
Extensible 3D (X3D) language bindings — Part 2: Java (in preparation)_

|[[RFC4248]]*RFC4248*
|http://www.ietf.org/rfc/rfc4248.txt?number=4248[IETF RFC 4248], _The
telnet URI Scheme_, Internet standards track protocol

|*[[W3CDOM2]]W3CDOM2*
|_http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/[W3C Document
Object Model (DOM) Level 2 Core Specification Version 1.0]_
|===

[[A2_glossary_html]]
== 3 Terms, definitions, acronyms, and abbreviations

For the purposes of this document, the terms, definitions, acronyms and
abbreviations given in <<I19775_1, ISO/IEC 19775-1>> and the following
apply.

[[A2_Errors]]
=== 3.1 errors

reasons for unsuccessful termination of a service

[[A2_File]]
=== 3.2 file

collection of related data stored on physical media or existing as a
data stream or as data within a computer program

[[A2_InitializeOnlyField]]
=== 3.3 initializeOnly field

field defined as part of a node definition whose value may only be
specified at the time that the node is instantiated

[[A2_InputCapableField]]
=== 3.4 input-capable field

either an <<A2_InputOnlyField, inputOnly field>> or an
<<A2_InputOutputField, inputOutput field>>

[[A2_InputOnlyField]]
=== 3.5 inputOnly field

field defined as part of a node definition which may only receive events

[[A2_InputOutputField]]
=== 3.6 inputOuput field

field defined as part of a node __ definition that is capable of both
receiving events and sending events

[[A2_Now]]
=== 3.7 now

present time as specified by the user's system clock

[[A2_OutputCapableField]]
=== 3.8 output-capable field

either an <<A2_InputOutputField, inputOutput field>> or an
<<A2_OutputOnlyField, outputOnly field>>

[[A2_OutputOnlyField]]
=== 3.9 outputOnly field

field defined as part of a node definition which may only send events

[[A2_Parameters]]
=== 3.10 parameters

values passed into a service

[[A2_PublicInterface]]
=== 3.11 public interface

formal definition of a node type in this part of ISO/IEC 19775

[[A2_Returns]]
=== 3.12 returns

values returned by an invocation of a service

[[A2_RunTimeNameScope]]
=== 3.13 run-time name scope

extent to which a name defined within an X3D file applies and is visible


[[A2_concepts_html]]
== 4 Concepts

[[A2_introduction]]
=== 4.1 Introduction

This clause describes key concepts in this part of ISO/IEC 19775. This
includes describing the various components of the browser and how the
interactions with the browser may be accomplished. It does not define
what the individual interactions are. Those descriptions can be found in
<<A2_servRef_html, 6 Services reference>>.

Table 4.1 provides links to the major topics in this clause.

Table 4.1 — Topics

* 4.1 Introduction
* <<A2_Overview, 4.2 Overview>>
** <<A2_General, 4.2.1 General>>
** <<A2_VRMLScripting, 4.2.2 Compatibility with VRML scripting>>
* <<A2_ImplementationDependencies, 4.3 Binding and protocol dependencies>>
* <<A2_InterfaceConstructs, 4.4 Interface constructs>>
** <<A2_Concepts, 4.4.1 Overview>>
** <<A2_UserCode, 4.4.2 User code>>
** <<A2_ContainingNode, 4.4.3 Containing node>>
** <<A2_Application, 4.4.4 Application>>
** <<A2_Session, 4.4.5 Session>>
** <<A2_Browser, 4.4.6 Browser>>
** <<A2_Scene, 4.4.7 Scene>>
** <<A2_Node, 4.4.8 Node and node lifecycle>>
** <<A2_Field, 4.4.9 Field>>
** <<A2_ExecutionContext, 4.4.10 Execution context>>
* <<A2_Events, 4.5 Events>>
** <<A2_EventsConcepts, 4.5.1 Concepts>>
** <<A2_InternalToBrowser, 4.5.2 Internal to browser>>
** <<A2_BrowserToExternalApp, 4.5.3 Browser to external application>>
*** <<A2_BrowserToExternalAppOver, 4.5.3.1 Overview>>
*** <<A2_Initialize, 4.5.3.2 Initialize>>
*** <<A2_Shutdown, 4.5.3.3 Shutdown>>
*** <<A2_NoURLsAvailable, 4.5.3.4 No URLs available>>
*** <<A2_ConnectionLost, 4.5.3.5 Connection lost>>
* <<A2_Identifiers, 4.6 Identifiers>>
* <<A2_RelativeURLs, 4.7 Relative URLs>>
* <<A2_ExecutionModel, 4.8 Execution model>>
** <<A2_InteractionTypes, 4.8.1 Overview of the interaction types>>
** <<A2_EventModelEvaluation, 4.8.2 Event model evaluation order>>
** <<A2_InternalInteractions, 4.8.3 Internal Interactions>>
*** <<A2_IntPermittedInteractions, 4.8.3.1 Permitted interactions>>
*** <<A2_IntBrowserInteractions, 4.8.3.2 Browser interactions>>
*** <<A2_RespondingToEvents, 4.8.3.3 Responding to events>>
*** <<A2_UpdatingTheSceneGraph, 4.8.3.4 Updating the scene graph>>
*** <<A2_AsynchronousActions, 4.8.3.5 Asynchronous actions>>
*** <<A2_IntMonitoringChanges, 4.8.3.6 Monitoring changes in the scene graph>>
*** <<A2_InternalUserCodeLifeCycle, 4.8.3.7 User code lifecycle>>
**** <<A2_UserCodeLifeCycleOverview, 4.8.3.7.1 Overview>>
**** <<A2_Setup, 4.8.3.7.2 Setup>>
**** <<A2_Realization, 4.8.3.7.3 Realization>>
**** <<A2_Disposal, 4.8.3.7.4 Disposal>>
*** <<A2_inputOutputFieldsContainingNode, 4.8.3.8 inputOutput fields and the containing node>>
*** <<A2_ExecutionEnvironmentAndSecurity, 4.8.3.9 Execution environment and security>>
** <<A2_ExternalInteractions, 4.8.4 External Interactions>>
*** <<A2_ExtPermittedInteractions, 4.8.4.1 Permitted interactions>>
*** <<A2_ExtBrowserInteractions, 4.8.4.2 Browser interactions>>
*** <<A2_ExtUpdatingSceneGraph, 4.8.4.3 Updating the scene graph>>
*** <<A2_ExtMonitoringChangesInTheSceneGraph, 4.8.4.4 Monitoring changes in the scene graph>>
*** <<A2_SynchronizingMultipleApplications, 4.8.4.5 Synchronizing multiple applications>>
** <<A2_ServiceGuarantees, 4.8.5 Service guarantees>>

* <<t-Fieldaccess, Table 4.2 — Permitted field access capabilities during the node lifecycle>>
* <<t-InteractionsLiveNode, Table 4.3 — Permitted field interactions of a live node>>


[[A2_Overview]]
=== 4.2 Overview

[[A2_General]]
==== 4.2.1 General

When a user wishes to interact with an X3D scene graph through use of
custom code, either as a Script node as defined in _29 Scripting
component_ in <<I19775_1, ISO/IEC 19775-1>> or from external
applications, they shall use the Scene Authoring Interface (SAI) defined
in this part of ISO/IEC 19775. This interface is a protocol for
manipulating the X3D scene graph while not directly part of the scene
graph itself.

This specification is aimed at providing a language-neutral
representation of all actions that can be performed by an external
application across this interface. Bindings to specific languages are
defined in <<I19777, ISO/IEC 19777>>. The SAI forms a common interface
that can be used either for manipulating the browser and the scene graph
from either an external application or from inside the scene graph
through the Script node. However, it is not possible for code written
for an external application to be immediately usable as a script. The
two environments have quite different requirements and abilities to
access and interact with the scene graph. This specification provides a
single, unified programmatic interface and constraints that depend on
the environment in which the code finds itself.

Conceptually, the SAI allows five types of access into the X3D scene:

* accessing the functionality of the Browser;
* receive notifications of the actions of the Browser, such as
encountering bad URLs, startup and shutdown; +
* sending events to input-capable fields of nodes inside the scene;
* reading the last value sent from output-capable fields of nodes inside
the scene; and
* getting notified when events change values of node fields inside the
scene.

[[A2_VRMLScripting]]
==== 4.2.2  Compatibility with ISO/IEC 14772

If an X3D browser wishes to conform to <<I14772_1, ISO/IEC 14772-1>>,
the browser shall support the event model and semantics defined in
<<A2_vrml97_html, Annex A VRML scripting backwards compatibility>> in
addition to the functionality specified in <<I19775_1, ISO/IEC
19775-1>>. Such support shall only be used when processing files that
conform to <<I14772_1, ISO/IEC 14772-1>>.

If an X3D browser wishes to conform to <<I14772_2, ISO/IEC 14772-2>>
(EAI), the browser shall use the following rules to determine content
validity:

[loweralpha]
. If the user code accesses the browser through the EAI, only VRML +
files as specified in <<I14772_2, ISO/IEC 14772-2>> shall be loaded.
It shall be an error to process files that conform to this part of
ISO/IEC 19775 if the user code is accessing the browser through the EAI.
. If the user code accesses the browser through the capabilities
provided by the external interactions defined in this part of ISO/IEC
19775, only X3D files as defined in <<I19775_1, ISO/IEC 19775-1>>
shall be loaded. If shall be an error to process files that conform to
<<I14772_1, ISO/IEC 14772-1>> if the user code is accessing the
browser through the SAI.

[[A2_ImplementationDependencies]]
=== 4.3 Binding and protocol dependencies

Implementation dependence is defined in terms of the language binding or
protocol encoding of the services defined in this specification. If a
service is defined to be implementation dependent, it is a requirement
of each binding and encoding to specify how that service is to be
implemented, if at all.

Bindings and encodings to these services may define their own
implementation dependent parts within that specification.

[[A2_InterfaceConstructs]]
=== 4.4 Interface constructs

[[A2_Concepts]]
==== 4.4.1 Overview

There are four main data collections in an X3D browser that can be
accessed using the services of the SAI: The browser, meta data about the
currently loaded scene, nodes within the scene graph, and fields within
nodes. The definition and specifications are framed in terms of
services. An X3D browser exposes a set of services that allow external
applications to interact with it. In order to describe these concepts, a
number of terms are defined.

[[A2_UserCode]]
==== 4.4.2 User code

Any code that makes use of the services defined in this part of ISO/IEC
19775 is considered to be user code. User code may exist either within
the scene graph or external to the browser. It shall only use the
services provided by this part and no browser implementation specific
services. In addition, these services are not designed for, nor intended
to be used for, writing native node extensions to a specific browser. A
browser may provide its own proprietary programmatic interfaces to
implement native extensions that are not part of this specification. If
code uses proprietary extensions, it shall not be considered user code
for the purposes of this part of ISO/IEC 19775.

[[A2_ContainingNode]]
==== 4.4.3 Containing node

A containing node is the node in the scene graph that is responsible for
representing user code that wishes to take part in internal interactions
(see <<A2_InternalInteractions, 4.8.3 Internal interactions>>). The life
cycle of user code shall be governed entirely by the containing node.
When the containing node becomes live, the user code becomes live. When
the containing node is removed and is no longer considered live as
defined in _4.4.2.5 Object life cycle_ in <<I19775_1, ISO/IEC
19775-1>>, the user code contained by that node shall be terminated. User
code cannot prolong the lifetime of the containing node by keeping a
reference to its containing node. The browser is the final arbiter of
when the containing node is no longer live.

There is no requirement for there to be a one-to-one mapping between a
containing node and its user code. Language bindings may permit one
instance of user code to be shared between multiple instances of a
containing node.

[[A2_Application]]
==== 4.4.4 Application

An application is the external process that is not implicitly part of
the X3D browser. This application makes some form of connection to the
X3D browser along which requests are made of the browser. The
application does not exist as part of the X3D browser as defined in
_Figure 4.1_ in <<I19775_1, ISO/IEC 19775-1>> nor forms part of the
execution model defined in _4.4.8.3 Execution model_ in
<<I19775_1, ISO/IEC 19775-1>>. An application may reside on another
machine from the X3D browser. An application may be responsible for
creating a new browser instance that is embedded within that application
or attaching itself to an already running instance of a browser (for
example, an applet on a web page).

[[A2_Session]]
==== 4.4.5 Session

A session defines the life of a single connection between the user code
and the X3D browser. It is possible for a single browser to be servicing
multiple sessions simultaneously (for example, multiple script nodes in
the one scene).

A single application may contain a number of separate sessions to
multiple browsers, but a single script node shall not. Multiple
simultaneous sessions between external applications and multiple X3D
browsers are permissible. However, individual implementations may place
some restrictions on such multiple simultaneous sessions.

A session is not an implementable part of this specification. It is
purely a conceptual mechanism by which the user can make requests for
services. It may exist prior to any connection being established between
a browser and external application or is established simultaneously with
the request for a browser connection.

[[A2_Browser]]
==== 4.4.6 Browser

The browser is the basic encapsulation mechanism for an active X3D scene
graph (that is one where time is progressing, not as a file stored on
disk). As it contains the entire scene graph, it also provides a minimal
core set of capabilities for dynamically manipulating that scene graph
at a coarse level. This scene graph may contain at most one active
LayerSet node and that node shall be a root node of the scene graph (see
_4.3.2 Root nodes_ of <<I19775_1, ISO/IEC 19775-1>>). Any other
LayerSet node contained in a scene imported using an Inline node (or
through any other means) shall be ignored.

A user may have many X3D browsers running simultaneously on their
machine. Therefore, each browser shall be represented by a unique
identifier within that session. This identifier is required to be
identical for multiple requests of a single browser instance. This is to
enable two applications that have access to the one browser instance to
share information in an unambiguous way.

Any action that requires use of the browser functionality shall identify
the service request with a browser identifier.

[[A2_Scene]]
==== 4.4.7 Scene

A scene represents a single X3D scene graph and all information about
that scene graph. The scene is the programmatic equivalent of an X3D
file. It may contain nodes, routes, proto declarations, imports and
exports and all information a valid X3D file may contain. A browser may
contain one or more scenes at any given time. For example one scene uses
an Inline node to include another scene.

A scene is not required to be live or running in the browser. A user may
construct a new scene that is not attached to a browser instance and
then programmatically fill in information such as nodes and routes. This
scene may then be passed directly to a utility program such as a pretty
printer for publishing a source file or used to replace the current
scene in the browser.

[[A2_Node]]
==== 4.4.8 Node and node lifecycle

The smallest unit of interaction with the elements in the scene graph is
the node. A node is an instance of one of the X3D nodes that are defined
in <<I19775_1, ISO/IEC 19775-1>>. A node can be removed as a unit from
the scene graph, stored, and then re-inserted at another position at
some later time in the same session without detrimental effect.

Each node is defined by a unique identifier. This identifier is unique
for that session. That is, it is possible that a single browser may be
servicing multiple applications simultaneously and therefore all node
identifiers are unique and invariant for the life of the session. This
allows two external applications to potentially share data between
themselves unambiguously and still have either external application make
service requests of the browser with that shared data.

Most operations in the SAI begin by obtaining a reference to a node.
There are multiple ways to gain a reference to a node. It may be named
using the DEF construct and fetched using the appropriate service or it
may be obtained by walking the scene graph from some arbitrary parent
node. Once a reference is obtained, all fields of that node may be
accessed, but not necessarily read or written, including initializeOnly
fields. Since an inputOutput field implicitly may be both read and
written, these are accessible using the field name or with the _set__
and __changed_ modifiers.

A node reference undergoes a lifecycle during which different
capabilities are available. The lifecycle can be expressed as:

. Creation: The node is first instantiated by the browser internals with
all field values set to defaults
. Setup: Field values are changed from the default value to the defined
initial values where required
. Realized: The node is participating in the scene graph and/or
scripting
. Disposed: The node is no longer part of a scene graph and no remaining
references to it exist at the scripting level.

Field access for reading and writing is dependent on the state of the
node. The states and capabilities are defined in
<<t-Fieldaccess, Table 4.2>>.

[[t-Fieldaccess]]
Table 4.2 — Permitted field access capabilities during the node lifecycle.

[cols=",,,,",]
|===
|Field type           |Creation |Setup |Realized |Disposed
|initializeOnly field |None |readable/writable |None |None
|inputOnly field      |None |None |writable |None
|outputOnly field     |None |None |readable |None
|inputOutput field    |None |readable/writable |readable/writable |None
|===

The transition from setup to realized states may be either implicit or
explicit. A service request exists so that the user may make a formal
notification that setup is now finished and the node can complete
whatever internal construction is required. The transition may be
implicit due to the user's actions. At the point the user does anything
with the node reference other than set the field values, the node shall
transition to the realized state.

EXAMPLE  The user creates a Box node, sets the size field, creates a
Shape node, and then immediately adds the Box to a Shape node. This set
of actions shall result in the state of the Box node changing to
Realized, while leaving the Shape node in the setup state.

Node identifiers may also be used to represent an empty node. An empty
SFNode or MFNode field value is represented by a `+NULL+` value. For
empty MFNode fields, the count of available nodes shall be zero.

[[A2_Field]]
==== 4.4.9 Field

Individual fields are defined within nodes. While it is not possible to
directly manipulate a node, a field is the method of direct manipulation
of individual properties as indicated in <<t-Fieldaccess, Table 4.2>>.

It is not possible to directly manipulate a node's properties as
entities separate from the node itself (i.e., fields do not exist
outside their containing nodes).

The field type and access type of individual fields is specified by
<<I19775_1, Part 1 of ISO/IEC 19775>>. A field is assigned a field
identifier. This is non-unique and requires a node identifier plus the
field identifier to specify a particular field with which to interact.
When accessing a field, the user shall be given the whole identifier to
the field. All fields are implicitly treated as being both readable and
writable by the service definition. Flags are used to indicate whether
that field can be read or written at that point in time (and dependent
on the node's state in the lifecycle as described in
<<t-Fieldaccess, Table 4.2>>). This state may change over time as the
node progresses through its lifecycle. For example, an initializeOnly
field of a non-live node may be writable, but once that node is inserted
into the scene graph, it shall no longer be writable. This is to aid
authoring tools and users that wish to programmatically construct a
scene around a third party browser.

Fields may be read or written at any time during the course of the
session. User code may register and unregister to receive notification
of when values of the field changes. During the registration process the
user code can supply a token that will be returned along with the data
value of the event. This token can be used by the user code to uniquely
identify this event in cases where events are not implicitly unique. The
token is not required to be passed along with the service request and
may be kept as part of the internals of the implementation on the
application interface.

Any output-capable field of a node to which the application has a
reference can be read. The value read is the last value sent by that
field or the default value for that field type if no event has ever been
sent. The data read is specific to the field type of that field and is
formatted appropriate to the language or protocol used.

[[A2_ExecutionContext]]
==== 4.4.10 Execution context

An execution context is the run-time semantic equivalent to a name scope
described in _4.4.7 Run-time name scope_ in <<I19775_1, ISO/IEC
19775-1>>. It provides a way of containing and firewalling internal
interaction code in such a manner as to represent the same restrictions
that a name space provides in the file format. For example, when a
script inside a Proto instance adds a ROUTE, the route is added to the
internals of the proto and not to the general scene.

A scene is a derived type of execution context. When the internal
interaction requests the current execution context, a scene object is
returned. The user code may then check to see if the execution context
is an instance of a full scene and behave appropriately by casting up to
the derived type, if available.


[[A2_Events]]
=== 4.5 Events

[[concepts]]
[[A2_EventsConcepts]]
==== 4.5.1 Concepts

Any transient data is carried around the X3D scene graph through the use
of events. The application may register to receive events from the X3D
scene graph, and may initiate new events. Events are considered
transient and generated only at the time when the specific action
occurs. Events shall not be stored and have the delivery deferred to
parties who have not expressed interest in the event at the time it
occurred.

EXAMPLE  An application that connects to a browser after the world has
loaded shall not be delivered an Initialize event.

[[A2_InternalToBrowser]]
==== 4.5.2 Internal to browser

An application may write a value to a field or read a value from a
field. This value does not become an event until that value is
internally represented and time stamped within the X3D browser. The
border of the browser to the application is where an event stops. Events
cannot exist externally from the X3D browser; that is, the application
cannot be inserted in the middle of an event cascade. The application
may be notified of events, initiate new events, but cannot process and
pass on events while holding up processing of the current timestamp
event cascades within the browser when it is notified of an event. It is
permissible to log events for analytic purposes.

An event is not generated until a cascade is created. If an internal
interaction directly writes to an output-capable field of another node,
no event is generated and therefore does not form part of the event
cascade. If the internal interaction writes to a input-capable field of
the containing node, an event is formed with the written value, if the
field is output-capable and is the subject of a ROUTE to somewhere else.

[[A2_BrowserToExternalApp]]
==== 4.5.3 Browser to external application

[[A2_BrowserToExternalAppOver]]
===== 4.5.3.1 Overview

The browser may directly communicate to external applications with its
own set of events. These events are used to indicate the status of the
browser or of some asynchronous problem. The number and type of events
available shall be implementation dependent. At a minimum, the following
events shall be provided in all implementations of this specification.

Event delivery from the browser to the external application shall be
guaranteed.

[[A2_Initialize]]
===== 4.5.3.2 Initialize

The initialize event is used to indicate that the browser has had a
scene loaded where it has run through the initialization process (where
the browser has loaded the world and just before it is about to issue
its first time-related event). At this point in time, node identifiers
shall be available from the getNode service of the scene (see
<<A2_getNode, 6.4.7 getNode>>).

The initialize event shall be generated immediately at the browser and
delivered to the application. The event is considered to be
asynchronous. That is, the delivery of the event (and any implementation
dependent acknowledgement scheme) shall not delay the browser in
starting the execution model evaluation.

[[A2_Shutdown]]
===== 4.5.3.3 Shutdown

The shutdown event is used to indicate that the browser is about to stop
running the current scene. This may occur under a number of different
conditions:

[loweralpha]
. the scene is being replaced (see <<A2_replaceWorld, 6.3.12
replaceWorld>> and <<A2_loadURL, 6.3.14 loadURL>>),
. the browser itself is exiting, or
. the client application has disposed of its connection to the browser
(see <<A2_BrowserDispose, 6.3.25 dispose>>).

The shutdown event shall be generated immediately at the browser and
delivered to the application. The event is considered to be
asynchronous. That is, the delivery of the event (and any implementation
dependent acknowledgement scheme) shall not delay the browser in halting
the execution model evaluation and closing down of the browser resources
except where needed to ensure the delivery of the event to the
application.

[[A2_NoURLsAvailable]]
===== 4.5.3.4 No URLs available

The SAI_BROWSER_URL_ERROR event is used to notify the application that
the browser was not able to load any of the URL/URNs in one of the
asynchronous invocations of the *`loadURL`* service (See
<<A2_loadURL, 6.3.14 loadURL>>). This indicates that no valid content was
able to be loaded or invoked from any of the URLs specified in this
call. Other calls that may involve other asynchronous loads such as
*`replaceWorld`* (see <<A2_replaceWorld, 6.3.12 replaceWorld>>)
and *`createX3DFromString`* and *`createX3DFromStream`*
(see <<A2_CreateX3DFromString, 6.3.16 createX3DFromString>>,
<<A2_createX3DFromStream, 6.3.17 createX3DFromStream>>) may also use this
event to indicate loading problems for any X3DUrlNode as specified in
_9.3.2 X3DUrlObject_ in <<I19775_1, ISO/IEC 19775-1>> such as Inlines,
textures and EXTERNPROTOs, although it is not required.

[[A2_ConnectionLost]]
===== 4.5.3.5 Connection lost

The connection lost error is used to notify the application that the
underlying implementation has lost the connection between the browser
and the application that would result in service requests not being able
to be honoured. An example would be a TCP network connection timing out
or other similar problem.

An implementation may delay sending an event that the connection has
been lost if it implements an automatic reconnection attempt. It shall
only be sent at the point where it is deemed no longer possible to
connect to the browser. There shall be no requirement for the
implementation to attempt to re-establish the connection after this
event has been generated or to attempt any form of automatic
reconnection capability.


[[A2_Identifiers]]
=== 4.6 Identifiers

What constitutes an identifier is implementation dependent. In some
cases it may be more efficient to represent a node identifier as the
entire node which includes all field information. Requests for field
information are then made on the local node. In other implementations an
identifier may be only a simple integer. The job of ensuring unique
identifiers is the sole responsibility of the browser such that
applications may share data within reasonable constraints of the
environment. The constraints on that environment may be specified as
part of the individual implementation.

It is not considered reasonable that two applications using different
service implementations be able to exchange data outside of the browser
environment.


[[A2_RelativeURLs]]
=== 4.7 Relative URLs

_9.2.2 Relative URLs_ in <<I19775_1, ISO/IEC 19775-1>> specifies the
rules for dealing with relative URLs within a browser environment. The
declaring file shall be defined as the base URL of the currently loaded
world in the browser. The currently loaded world can be obtained by a
request of the `getWorldURL` service (see <<A2_getWorldURL, 6.4.6
getWorldURL>>). In the case where a browser does not yet have an X3D file
loaded, the base document directory shall be taken to be the current
working directory of the browser. Where the browser is part of a web
page, the current working directory shall be treated as the base URL of
the page in which the web browser is embedded.

When nested relative URLs are generated (such as an EXTERNPROTO
containing a reference to a script file) the top level relative URL base
is then resolved in accordance with <<I19775_1, ISO/IEC 19775-1>>.


[[A2_ExecutionModel]]
=== 4.8 Execution model

[[A2_InteractionTypes]]
==== 4.8.1 Overview of the interaction types

Because the SAI fulfills the role of the programmatic interface for both
external applications and scripts, the execution model is capable of
working in both situations. Although the API calls are identical for
both situations, the run-time evaluation of each service request may be
different.

EXAMPLE  Servicing a field-changed notification in an internal script
shall pause the current event cascade; for an external application it
shall not.

This specification defines two types of interactions in which services
may participate:  internal (_i.e._, a script) and external (_i.e._, an
application).

[[A2_EventModelEvaluation]]
==== 4.8.2 Event model evaluation order

Scripting code allows the user to modify the scene graph with custom
behaviours. For consistent effects, the evaluation order defined in
_4.4.8.3 Execution model_ in <<I19775_1, ISO/IEC 19775-1>> is expanded
to include the service interactions allowed by a script. When internal
interaction code is provided, the following order shall be used to
evaluate all aspects of the event model.

. Update camera based on currently bound Viewpoint's position and
orientation.
. Evaluate sensor input.
. Gather external input from buffer and pass to nodes.
. Call the `+prepareEvents+` script service for all live script nodes in
the scene.
. Evaluate routes.
. Call the `+shutdown+` service on scripts that have received set_url
events or are being removed from the scene
. Generate final events for any sensors removed from the scene.
. Add/remove any routes required by an invocation of the
`+dynamicRouteHandling+` service request as defined in
<<A2_DynamicRouteHandling, 6.4.17 dynamicRouteHandling>> from any script
execution in step 6.
. Call the `+eventsProcessed+` script service for scripts that have sent
events generated in step 6.
. Call the `+initialize+` service for newly loaded internal interaction
code.
. If any events were generated from steps 5 through 10, go to step 5 and
continue until complete for the current event cascade.

If an internal interaction registers any form of callback or listener
functionality with objects defined by this specification, those
callbacks are made at the time the change occurs.

EXAMPLE  A user code in Script A issues an event on an outputOnly field
during the initialize service handling, and another piece of user code
in Script B has a listener service on that eventOut. The listener in
Script B would be fired immediately after the user code in Script A
exits and returns control to the browser core.

[[A2_InternalInteractions]]
==== 4.8.3 Internal interactions

[[A2_IntPermittedInteractions]]
===== 4.8.3.1 Permitted interactions

An internal interaction is when the user code and containing node form
part of the X3D scene graph. These nodes are subject to and participate
in the event cascade evaluation. Internal interactions may occur in the
middle of the event cascade as a direct result of receiving an event,
and may generate one or more output events in response. These events
shall continue in the current cascade. When the output events are
generated from asynchronous script evaluation or from some other process
not directly related to processing of the current event cascade as
defined in _29.2.4 EventsProcessed()_ in <<I19775_1, ISO/IEC
19775-1>>, a completely new event cascade is started.

An X3DScriptNode type as specified in _29.3.1 X3DScriptNode_ in
<<I19775_1, ISO/IEC 19775-1>> specifies a containing node although
other node types may also be defined in the future. A browser shall only
permit internal interactions by user code that is referenced from an
X3DScriptNode type or other future defined containing node type. If the
user code is referenced from any other node type, it shall consider the
code as an external interaction and act accordingly.

Internal interactions also permit direct interaction with fields of
other nodes, or some browser operations without participating in the
event cascade. This action shall only be allowed dependent on the value
of the _directOutput_ field setting of the containing _X3DScriptNode_
node. The definitions of when this behaviour is permitted is defined in
_29 Scripting component_ in <<I19775_1, ISO/IEC 19775-1>>.

Because the user code is considered to be held inside the containing
node, the view of the node's fields are reversed to the normal
situation. An inputOnly field is a readable field, not writable; an
outputOnly field is a writable field, not readable; and an
initializeOnly as well as an inputOutput field are both readable and
writable. Contrast this with an external node that is not the containing
node in <<t-InteractionsLiveNode, Table 4.3>>. This resembles the type
of access that any other built-in or native extension node may have.

[[t-InteractionsLiveNode]]
Table 4.3 — Permitted field interactions of a live node

[width="100%",cols="34%,33%,33%",]
|===
|Access Type |Containing Node |External Node
|initializeOnly + |readable/writable |no access
|inputOnly |readable |writable
|inputOutput |readable/writable |readable/writable
|outputOnly |writable |readable
|===

[[A2_IntBrowserInteractions]]
===== 4.8.3.2 Browser interactions

Internal interactions are permitted with the browser. Because the code
lies inside the current scene, they are only permitted a limited set of
the full browser services. The services clause outlines which services
will be available to internal actions and which are off limits.

During the initialization phase of the internal action, a script shall
be given a reference to the browser that is appropriate for its
interactions. This reference shall remain constant throughout the
lifetime of the script while its containing node is considered live.

[[A2_RespondingToEvents]]
===== 4.8.3.3 Responding to events

The purpose of an internal interaction is to respond to events, provide
some processing and, optionally, also generate new output for the
containing node. It may, also, provide asynchronous output that does not
correspond to any input through the use of one or more threads.
Generating output is considered in  <<A2_UpdatingTheSceneGraph, 4.8.3.4
Updating the scene graph>>. 4.8.3.4 describes the issues of responding to
input resulting from an event cascade that sends an event to one or more
output-capable fields of the containing node.

In order to respond to events, user code registers interest in the
appropriate field(s) of the containing node. Interest may be registered
with all field access types except outputOnly fields of the containing
node. Once the containing node has completed its initialization phase,
any time that one of the fields of the containing node receives an event
the user code shall be notified of this through the notification
mechanism provided by the language-specific bindings. The browser may
choose to either immediately notify the user code or to batch a number
of events together and provide a deferred notification. In either case,
the browser shall ensure that all events for that timestamp are
delivered during the event cascade for that timestamp and not at some
later time. The browser shall also obey the containing node's
_mustEvaluate_ field directive as specified in _29.4.1 Script_ in
<<I19775_1, ISO/IEC 19775-1>> when deciding whether to defer or
immediately notify.

Upon notification, the browser shall not process any more events in the
containing node's event cascade until processing has returned from the
user code (although this does permit other event cascades to continue
simultaneous processing). Values written to fields of other nodes and
the input-capable fields of the containing node shall not be passed on
to the destination node before the user code has relinquished control.

NOTE  This does not exclude a browser implementation from delivering
multiple events simultaneously to the user code if there are parallel
event cascades being evaluated (for example a browser running on a
multi-CPU machine where parallel event cascades can be evaluated and
result in two cascades delivering events to the containing node
simultaneously). The writer of the user code should be aware of, and
take appropriate precautions for, an event cascade occurring in
parallel.

When the browser has determined that the cascade or cascades are
completed, the browser may then call the containing node's
`eventProcessed()` method as defined in _29.2.4
EventsProcessed()_ in <<I19775_1, ISO/IEC 19775-1>>. The user code is
also notified of this situation at which point the user code may then
choose to perform extra evaluation and generate more output. User code
for internal notifications has no way of determining when the current
rendered frame has finished and the next frame begins.

[[A2_UpdatingTheSceneGraph]]
===== 4.8.3.4 Updating the scene graph

User code may choose to generate output in addition to receive inputs.
For internal interactions, user code is not required to generate output
in response to inputs. User code may asynchronously generate output or
write directly to other nodes at any time that the containing node is
considered live, within certain restrictions that are outlined in
<<A2_RespondingToEvents, 4.8.3.3 Responding to events>> and
<<A2_AsynchronousActions, 4.8.3.5 Asynchronous actions>>.

User code has two options for influencing the scene graph; it may write
to the output-capable fields of the containing node and have the values
be subject to the usual event cascade, or it may directly write to the
input-capable fields of another node to which the containing node and
user code already has a reference. User code may write to the containing
node's fields at any time and in accordance with the access rules
defined in <<t-Fieldaccess, Table 4.2>>. Internal interactions with
other nodes shall be subject to the rules defined by the containing
node's _directOutput_ field as specified in _29.2.6 Scripts with direct
outputs_ in <<I19775_1, ISO/IEC 19775-1>>.

There are two special cases of user code not being permitted to make
changes to fields of the containing node. The two fields of the
X3DScriptNode abstract type _mustEvaluate_ and _directOutput_ are
considered special and the user code shall not be permitted to modify
these values at runtime. User code may read these values. Scripts can be
self-modifying, thus, if the containing node is also derived from the
X3DUrlObject abstract type (see _9.3.2 X3DUrlObject_ in
<<I19775_1, ISO/IEC 19775-1>>), it may choose to change its own URL
fields, thereby replacing the current user code with new user code.

[[A2_AsynchronousActions]]
===== 4.8.3.5 Asynchronous actions

User code in some languages is allowed to operate using asynchronous
threads of execution. These allow user code to run without the need for
direct stimulus from the browser. A typical use of this situation is to
monitor a network connection for changes to be made to the scene graph.
This requires the use of internal interactions that are not created as a
direct result of field changes being received by the user code.

Internal interactions are only permitted at the times specified by
<<A2_InternalUserCodeLifeCycle, 4.8.3.7 User code lifecycle>>. The
browser shall generate an error if user code attempts to make internal
interactions at any other time. The `prepareEvents` service (see
<<A2_prepareEvents, 6.11.4.1 prepareEvents>>), if defined by the user
code, allows user code to perform completely asynchronous changes to the
scene graph, at known points in time, without the need to clock the
script using a TimeSensor or other node. This is in contrast to the
*`eventsProcessed`* service (see <<A2_eventsProcessed, 6.11.4.2
eventsProcessed>>), which is only called after the containing node has
had to process field changes.

In addition, when user code registers for one of the listener services,
the callbacks associated with this are considered asynchronous actions.
User code operating during this period shall not be permitted to make
modifications to the scene graph.

[[A2_IntMonitoringChanges]]
===== 4.8.3.6 Monitoring changes in the scene graph

The services definition for fields allows user code to register interest
in the output of fields of other nodes. Internal interaction code shall
not be permitted to register interest in field change information. If
the user code wishes to be informed of field change information, it
shall use the existing route mechanism and the appropriate scene
services to add a route between the field of interest and an
input-capable field of the containing node.

Internal user code shall only be permitted to register interest in the
output-capable fields of other nodes when the containing node's
_directOutput_ field is set to `TRUE`. It shall be an error to
allow user code to register interest in outputs if this value is set to
`FALSE`.

[[A2_InternalUserCodeLifeCycle]]
===== 4.8.3.7 User code lifecycle

[[A2_UserCodeLifeCycleOverview]]
====== 4.8.3.7.1 Overview

The lifetime of user code may be shorter for many reasons, such as the
download time to fetch the code from a remote site or other user code
changing the URL of the containing node to replace the current user
code. However, the lifecycle of user code follows the same basic
principles of the containing node. It has the same phases and undergoes
similar transitions.

The lifecycle of the containing node is defined in _4.4.2.5 Object life
cycle_ in <<I19775_1, ISO/IEC 19775-1>>.

[[A2_Setup]]
====== 4.8.3.7.2 Setup

It is assumed that there will be some delay, however small, between when
the containing node is initialized and when the user code will go
through its initialization phase. While the containing node may already
have finished the initialization phase and be in the running phase, the
user code may not have started or may be processing its initialization.

During the initialization phase, internal interaction code is given all
the information it needs for the rest of its lifecycle. The first step
of the initialization phase is the instantiation of the user code. At
instantiation, user code has no information about its containing
environment or the containing node. During this time the user code may
elect to set up any resources it requires, such as threads, network
connections or any other permitted actions of the containing environment
(see <<A2_ExecutionEnvironmentAndSecurity, 4.8.3.9 Execution environment
and security>>).

After instantiation, the user code receives notification of resources
needed to function within the internal interaction environment. It is
given the identifier of the containing browser, the list of fields of a
node (excluding any special fields) and the identifier of the containing
node (needed so that user code may add and remove routes to its
containing node). User code shall not make any service requests with the
one exception of printing messages during this period. If it does, the
browser shall generate an error.

As the last step of the initialization phase, the user code shall have
its *`initialize`* service called (see <<A2_Initialize, 6.11.3.3
initialize>>). At this point user code is free to make use of all the
services available to internal interactions.

NOTE  This would be a good time for the user code to register for change
notifications of the containing node fields or to perform external tasks
like binding a particular viewpoint.

[[A2_Realization]]
====== 4.8.3.7.3 Realization

During the runtime phase, user code is subject to the requirements of
this clause for receiving, sending and monitoring events as well as the
X3D execution model.

User code is restricted about when it may make modifications to the
scene graph. It shall only be permissible to make modifications in
response to prompts from the browser. The permitted times shall be
defined as:

. During the pre-event cascade processing service request *`prepareEvents`* (see <<A2_prepareEvents, 6.11.4.1 prepareEvents>>);
. In response to a change notification for an input-capable field of the
containing node; and
. During the post-event processing service request through the *`eventsProcessed`* service request (see <<A2_eventsProcessed, 6.11.4.2
eventsProcessed>>).

It shall be an error for user code to make a service request at any time
other than those where asynchronous interactions are permitted. Each
service request in <<A2_servRef_html, 6 Service reference>> defines
whether user code is permitted to make asynchronous requests.

[[A2_Disposal]]
======= 4.8.3.7.4 Disposal

User code will enter the shutdown phase when either the node is no
longer live or the action of other user code has resulted in the user
code being removed from the containing node (for example, changing the
URL of a script node to point at new executable content).

Notification of the change to the shutdown phase shall be through the
calling of the *`shutdown`* service request in the user code
(see <<A2_ScriptShutdown, 6.11.5.1 shutdown>>). During this phase user
code may set values to an output-capable field of the containing nodes
or write final values directly to the input-capable fields of other
nodes. At the end of the phase, the identifiers to the browser and
containing fields shall be considered as invalid. For example, if the
user code contains a thread that continues to operate after the shutdown
phase, it shall not be permitted to make modifications to the scene
graph. To do so shall generate an error.

[[A2_inputOutputFieldsContainingNode]]
===== 4.8.3.8 inputOutput fields and the containing node

The containing node is permitted to have fields with the inputOutput
access type. Because an inputOutput field represents both an inputOnly
and outputOnly field the user code may wish to write to the values, user
code is subject to some special conditions in order to remain consistent
with the core specification.

For the purposes of defining the allowable behaviour, the containing
node and the user code are considered as decoupled, non-related
entities. A notification of change in field value is a notification, and
no more. Setting the value of a field that is defined as inputOutput is
considered to be an instantaneous, atomic action. When the field is set,
the value for both the input and output are set immediately. Then the
notification to the user code is performed. Since the output of the
inputOutput field has been set, any further attempt to change the value
of the inputOutput field during the current timestamp is considered to
be subject to _4.4.8.4 Loops_ in <<I19775_1, ISO/IEC 19775-1>>. That
is, if the user code receives an event notification for its containing
node's inputOutput field, it cannot write another value to that same
inputOutput field during the same timestamp because  an output event has
already been issued and the containing node is not permitted to issue
another output event for the same field in the same timestamp.

In receiving events, the script shall only pass through the first event
received by the containing node of the inputOutput field.

If the containing node has not yet received a change to the field during
the current timestamp, the user code is permitted to write a value to
the field. If a change is received to the field after the user code has
modified it, only the inputOnly portion of the node is processed. A
notification is sent to the user code, but the value of the field shall
not be changed in accordance with the loop breaking rule in _4.4.8.4
Loops_ in <<I19775_1, ISO/IEC 19775-1>>.

[[A2_ExecutionEnvironmentAndSecurity]]
===== 4.8.3.9 Execution environment and security

All user code participating within a particular internal interaction
environment is considered to operate within a single execution space.
Code in this context is subject to the security settings of the
containing browser's environment and also the language's operating
environment. This permits user code in internal interactions to
communicate through asynchronous mechanisms that are external to the X3D
execution environment (i.e., route and event evaluation). Some language
bindings may be subject to more restrictions than others. This is
implementation independent.

EXAMPLE  User code using the Java language bindings may operate in a
web-browser sand box that does not allow network connections to any
external server, while user code using user API bindings in an
application may be given full access to the entire underlying operating
system.

For security purposes, a browser may implement whatever schemes it feels
necessary to ensure good security and to prevent content from
undertaking nefarious activities. Such activities may include virus-like
modification of the user's computer or denial of service activities or
any other activity deemed a security risk on the day.

[[A2_ExternalInteractions]]
==== 4.8.4 External interactions

[[A2_ExtPermittedInteractions]]
===== 4.8.4.1 Permitted interactions

User code that is interacting with a browser from an external
perspective is considered to have complete control over the entire
lifecycle of not only the scene graph but also the browser. External
interactions therefore have the full range of control over the browser.

Because an application is consider to be external to the browser, it
does not have intimate knowledge of the internal state and therefore
when actions may or may not be safe to make. Therefore, the external
interactions are defined to be in an advisory capacity. An external
interaction requests the browser make changes and then the browser shall
decide exactly when it it safe to act on those requests. A browser shall
honour all requests made, within the bounds of the individual services
guideline outlined below.

An external application may also wish to monitor changes in nodes,
fields and even the browser itself. The browser shall inform the
external application of the changes, but shall do so in an asynchronous
way. That is, any updates are considered to be notifications only, and
shall not hold up the browser's internal evaluations. The result is that
notifications may make it to the external application with some delay
from when they happened within the browser.

EXAMPLE  Delays may occur for data transfer between an external
application sitting on a remote computer and a browser, due to
transmission lags throughout the system.

[[A2_ExtBrowserInteractions]]
===== 4.8.4.2 Browser interactions

Browser interactions for external interactions include all the basic
services provided to internal interactions. In addition to this a number
of additional interactions are allowed. A single external application is
permitted to interact with more than one browser at a time. It may also
instruct multiple browsers to act together as a single entity or to work
individually. The lifetime of the external application is independent of
the browser.

[[A2_ExtUpdatingSceneGraph]]
===== 4.8.4.3 Updating the scene graph

A characteristic of external applications is that they may make a lot of
changes in bursts to the X3D browser. It is also possible that a single
browser may have a number of applications connected to it, all making
requests of the browser.

Events can be batched to aid in performance of the application (see
<<A2_UpdateControl, 6.3.19 updateControl>>). The mechanism provided by
this is a simple gate mechanism to hold all requests (`+BeginUpdate+`)
to update the currently loaded world until the gate is released
(`+EndUpdate+`).

When `+BeginUpdate+` is invoked, all requests to modify the contents of
the current world are buffered and not passed to the browser. This
buffering effects all requests to modify the current world including
calls to `+loadURL+` and `+replaceWorld+`. Once a call to
`+BeginUpdate+` has been made, any further `+BeginUpdate+` requests are
ignored until the next call to `+EndUpdate+` at which time `+EndUpdate+`
releases all of the currently buffered updates to the browser for
processing.

If a modification service request is made on the scene after an *`endUpdate`* and before a `+BeginUpdate+`, it shall be passed to the
scene immediately with the timestamp at the discretion of the browser.

`+BeginUpdate+`/`+EndUpdate+` requests shall be limited to the
individual session. A request by one application to `+BeginUpdate+`
shall only buffer the requests made by that application and not any
others that may be connected to that same browser instance.

When `+EndUpdate+` is invoked, the following order of execution of
requests shall be applied:

. node setValues;
. event cascade evaluation as defined in _4.4.8.3 Execution model_ in
<<I19775_1, ISO/IEC 19775-1>>.

The `+loadURL+`/`+replaceWorld+` service requests (see
<<A2_loadURL, 6.3.14 loadURL>> and <<A2_replaceWorld, 6.3.12
replaceWorld>>) are not affected by the update control process. As soon
as the browser receives these requests their execution is begun. The
service definitions define the complete behaviour of these requests.

Buffered requests from the application shall be processed before
processing any more requests either through another buffered queue or
individual requests.

[[A2_ExtMonitoringChangesInTheSceneGraph]]
===== 4.8.4.4 Monitoring changes in the scene graph

External interactions allow monitoring of any changes in the scene
graph. Notifications of these changes shall be delivered in a timely
manner and shall remain in the same sequence in which they are generated
by the browser internals.

[[A2_SynchronizingMultipleApplications]]
===== 4.8.4.5 Synchronizing multiple applications

When multiple applications make requests of the browser, the requests
shall be serviced in order of arrival time at the browser. The browser
shall determine the arrival time. Buffered updates to the scene graph
shall have their arrival time determined to be at the time that
`+EndUpdate+` is requested. The arrival time is not necessarily the same
as the timestamp at which the browser chooses to send events into the
scene graph. The timestamp that the events are sent to the scene graph
shall be determined by the browser but shall be no earlier than the time
that `+EndUpdate+` is requested. The arrival time is used to sort out
conflicting requests from multiple applications to ensure consistent
results in the application of events in the correct order.

Should the browser determine that two requests arrive simultaneously the
result is implementation dependent.

NOTE  It is permissible for the external applications to send new values
to a given inputOnly field simultaneously. For such situations the
browser shall obey _4.4.8.5 Fan-in and fan-out_ in
<<I19775_1, ISO/IEC 19775-1>>. Authors can avoid non-determanistic
behavior by ensuring that events occur in separate event cascades.

Should the browser receive a request to *`loadURL`* or *`replaceWorld`* while currently processing a similar request, the old
request is immediately terminated and the new one begun. See
<<A2_replaceWorld, 6.3.12 replaceWorld>> and <<A2_loadURL, 6.3.14
loadURL>> for more information.

[[A2_ServiceGuarantees]]
===== 4.8.5 Service guarantees

All requests for services shall be guaranteed to be honoured where the
underlying implementation supports that service. Once the application
has made a service request, that request shall be transmitted to the
browser assuming that a connection is still available. That is, all
communications are assumed to be reliable. Delivery is not guaranteed if
the connection between the browser and application has been broken (for
example, a TCP connection fails). Implementations shall define an error
condition that notifies the user that the connection has failed for each
service request. Also, the browser interface may include an event that
provides asynchronous notification to the user of the failure.

[[A2_dataRef_html]]
== 5 Data type reference

[[A2_IntroductionAndTableOfContents]]
=== 5.1 Introduction and topics

[[introduction-1]]
[[A2_Introduction]]
==== 5.1.1 Introduction

This clause describes the language independent data types used in the
definition of <<A2_servRef_html, 6 Services reference>>.

[[A2_TableOfContents]]
==== 5.1.2 Topics

Table 5.1 specifies the topics for this clause.

Table 5.1 — Topics

* <<A2_IntroductionAndTableOfContents, 5.1 Introduction and topics>>
** <<A2_Introduction, 5.1.1 Introduction>>
** <<A2_TableOfContents, 5.1.2 Topics>>
** <<A2_Concepts, 5.1.3 Concepts>>
* <<A2_DataTypeDefinitions, 5.2 Data type definitions>>
** <<A2_SAIAction, 5.2.1 SAIAction>>
** <<A2_SAIBoolean, 5.2.2 SAIBoolean>>
** <<A2_SAIBrowserApp, 5.2.3 SAIBrowserApp>>
** <<A2_SAIBrowserName, 5.2.4 SAIBrowserName>>
** <<A2_SAIBrowserRef, 5.2.5 SAIBrowserRef>>
** <<A2_SAIBrowserVersion, 5.2.6 SAIBrowserVersion>>
** <<A2_SAIComponentDeclaration, 5.2.7 SAIComponentDeclaration>>
** <<A2_SAIComponent, 5.2.8 SAIComponent>>
** <<A2_SAIEncoding, 5.2.9 SAIEncoding>>
** <<A2_SAIExecutionContext, 5.2.10 SAIExecutionContext>>
** <<A2_SAIFieldAccess, 5.2.11 SAIFieldAccess>>
** <<A2_SAIFieldDeclaration, 5.2.12 SAIFieldDeclaration>>
** <<A2_SAIField, 5.2.13 SAIField>>
** <<A2_SAIFieldName, 5.2.14 SAIFieldName>>
** <<A2_SAIFieldType, 5.2.15 SAIFieldType>>
** <<A2_SAIFieldValue, 5.2.16 SAIFieldValue>>
** <<A2_SAIFrameRate, 5.2.17 SAIFrameRate>>
** <<A2_SAILayerID, 5.2.18 SAILayerID>>
** <<A2_SAILoadState, 5.2.19 SAILoadState>>
** <<A2_SAIMatrix, 5.2.20 SAIMatrix>>
** <<A2_SAINavSpeed, 5.2.21 SAINavSpeed>>
** <<A2_SAINode, 5.2.22 SAINode>>
** <<A2_SAINodeType, 5.2.23 SAINodeType>>
** <<A2_SAIParameterList, 5.2.24 SAIParameterLIst>>
** <<A2_SAIProfileDeclaration, 5.2.25 SAIProfileDeclaration>>
** <<A2_SAIPropertyList, 5.2.26 SAIPropertyList>>
** <<A2_SAIProtoDeclaration, 5.2.27 SAIProtoDeclaration>>
** <<A2_SAIRequester, 5.2.28 SAIRequester>>
** <<A2_SAIRoute, 5.2.29 SAIRoute>>
** <<A2_SAIScene, 5.2.30 SAIScene>>
** <<A2_SAIScript, 5.2.31 SAIScript>>
** <<A2_SAIScriptImplementation, 5.2.32 SAIScriptImplementation>>
** <<A2_SAIStream, 5.2.33 SAIStream>>
** <<A2_SAIString, 5.2.34 SAIString>>
** <<A2_SAIUnitDeclaration, 5.2.35 SAIUnitDeclaration>>
** <<A2_SAIURL, 5.2.36 SAIURL>>
** <<A2_NULL, 5.2.37 NULL>>
* <<A2_ErrorTypes, 5.3 Error types>>
** <<A2_SAIError, 5.3.1 SAIError>>
** <<A2_SAIBrowserUnavailable, 5.3.2 SAI_BROWSER_UNAVAILABLE>>
** <<A2_SAIConnectionError, 5.3.3 SAI_CONNECTION_ERROR>>
** <<A2_SAIDisposed, 5.3.4 SAI_DISPOSED>>
** <<A2_SAIImportedNode, 5.3.5 SAI_IMPORTED_NODE>>
** <<A2_SAIInsufficientCapabilities, 5.3.6 SAI_INSUFFICIENT_CAPABILITIES>>
** <<A2_SAIInvalidAccessType, 5.3.7 SAI_INVALID_ACCESS_TYPE>>
** <<A2_SAIInvalidBrowser, 5.3.8 SAI_INVALID_BROWSER>>
** <<A2_SAIInvalidDocument, 5.3.9 SAI_INVALID_DOCUMENT>>
** <<A2_SAIInvalidExecutionContext, 5.3.10 SAI_INVALID_EXECUTION_CONTEXT>>
** <<A2_SAIInvalidField, 5.3.11 SAI_INVALID_FIELD>>
** <<A2_SAIInvalidName, 5.3.12 SAI_INVALID_NAME>>
** <<A2_SAIInvalidNode, 5.3.13 SAI_INVALID_NODE>>
** <<A2_SAIInvalidOperationTiming, 5.3.14 SAI_INVALID_OPERATION_TIMING>>
** <<A2_SAIInvalidURL, 5.3.15 SAI_INVALID_URL>>
** <<A2_SAIInvalidX3D, 5.3.16 SAI_INVALID_X3D>>
** <<A2_SAINodeInUse, 5.3.17 SAI_NODE_IN_USE>>
** <<A2_SAINodeNotAvailable, 5.3.18 SAI_NODE_NOT_AVAILABLE>>
** <<A2_SAINotShared, 5.3.19 SAI_NOT_SHARED>>
** <<A2_SAINotSupported, 5.3.20 SAI_NOT_SUPPORTED>>
** <<A2_SAIURLUnavailable, 5.3.21 SAI_URL_UNAVAILABLE>>
* <<A2_EventTypes, 5.4 Event types>>
** <<A2_EventTypesOverview, 5.4.1 Overview>>
*** <<A2_SAIBConnectionError, 5.4.1.1 SAI_>><<A2_SAIBrowserEvent, Browser>><<A2_SAIBConnectionError, _Connection_Error>>
*** <<A2_SAIBrowserEvent, 5.4.1.2 SAI_Browser_Event>>
*** <<A2_SAIBInitialized, 5.4.1.3 SAI_>><<A2_SAIBrowserEvent, Browser>><<A2_SAIBInitialized, _Initialized>>
*** <<A2_SAIBShutdown, 5.4.1.4 SAI_>><<A2_SAIBrowserEvent, Browser>><<A2_SAIBShutdown, _Shutdown>>
*** <<A2_SAIBURLError, 5.4.1.5 SAI_>><<A2_SAIBrowserEvent, Browser>><<A2_SAIBURLError, _URL_Error>>
** <<A2_SAIFieldEvent, 5.4.2 SAIFieldEvent>>


[[A2_Concepts]]
==== 5.1.3 Concepts

All data types in this clause are language binding independent. They
represent single value information that is passed as parameters, return
values or error conditions that can be generated through the external
authoring interface. Each language binding shall define implementations
of each of these data types.

These data types represent the specific implementation of each type;
that is, how the X3D browser would represent them internally.

[[A2_DataTypeDefinitions]]
=== 5.2 Data type definitions

[[A2_SAIAction]]
==== 5.2.1 SAIAction

SAIAction is a single value representing a qualifier for a more general
service type. Each use of the SAIAction type shall define the range of
acceptable values.

[[A2_SAIBoolean]]
==== 5.2.2 SAIBoolean

SAIBoolean represents a `TRUE` or `FALSE` value.

[[A2_SAIBrowserApp]]
==== 5.2.3 SAIBrowserApp

SAIBrowserApp is a data type that represents the complete browser
application. This is different from <<A2_SAIBrowserRef, 5.2.5
SAIBrowserRef>> because SAIBrowserApp defines the browser application
itself whereas the SAIBrowserRef defines a reference to the standardized
interface to the browser's functionality. The data type shall contain
some method for obtaining an SAIBrowserRef.

[[A2_SAIBrowserName]]
==== 5.2.4 SAIBrowserName

SAIBrowserName defines a representation of the name of the browser. If
the browser implementation does not support this information, a NULL
value is considered a legal representation of this data type.

[[A2_SAIBrowserRef]]
==== 5.2.5 SAIBrowserRef

SAIBrowserRef represents a browser reference. This is a unique
identifier per browser instance. Individual language bindings may place
conditions on uniqueness allowing other methods for checking equivalent
references to the same browser.

The browser concept is further defined in <<A2_Browser, 4.4.6 Browser>>.

[[A2_SAIBrowserVersion]]
==== 5.2.6 SAIBrowserVersion

SAIBrowserVersion defines a representation of the version of the
browser. If the browser implementation does not support this
information, a NULL value is considered a legal representation of this
data type.

[[A2_SAIComponentDeclaration]]
==== 5.2.7 SAIComponentDeclaration

SAIComponentDeclaration defines all the information about a component
and its declaration. It may be used to represent both the component
information declared in a file, and the available components from the
browser.

[[A2_SAIComponent]]
==== 5.2.8 SAIComponent

SAIComponent specifies an identifier of a component when used in a
request. Components consist of a name and a level and both are
encapsulated in this identifier.

[[A2_SAIEncoding]]
==== 5.2.9 SAIEncoding

SAIEncoding specifies an identifier for an encoding type.

[[A2_SAIExecutionContext]]
==== 5.2.10 SAIExecutionContext

SAIExecutionContext is a data type for a representation of a subscene
piece of information relating to the current name space as a run-time
entity.

[[A2_SAIFieldAccess]]
==== 5.2.11 SAIFieldAccess

This data type defines the type of access that is permitted to a field.
The valid values are initializeOnly, inputOnly, outputOnly, and
inputOutput.

[[A2_SAIFieldDeclaration]]
==== 5.2.12 SAIFieldDeclaration

SAIFieldDeclaration represents the abstract declaration of a field for a
node. The declaration is constant for all instances of that node and
does not include the field value. It can be considered a wrapper data
type that includes SAIFieldAccess, SAIFieldName and SAIFieldType data
types.

[[A2_SAIField]]
==== 5.2.13 SAIField

SAIField represents an identifier for a particular field of a node. It
is guaranteed to be unique within the scope of an individual node
reference. It is not guaranteed to be unique in terms of all field
references generated. To uniquely define a field within the scene graph,
a combination of node and field identifiers is needed.

The field concept is further defined in <<A2_Field, 4.4.9 Field>>.

[[A2_SAIFieldName]]
==== 5.2.14 SAIFieldName

SAIFieldName represents a name for a field.

[[A2_SAIFieldType]]
==== 5.2.15 SAIFieldType

SAIFieldType specifies the type of data a field represents. In some
cases (where the field type represents an MFNode or SFNode), this field
type may correspond to an SAINode. Valid types of the field are defined
in _5 Field type reference_ in <<I19775_1, ISO/IEC 19775-1>>.

[[A2_SAIFieldValue]]
==== 5.2.16 SAIFieldValue

SAIFieldValue represents the value to be set or to be returned of an
SAIFieldType in language specific terms. A table may be constructed
mapping each SAIFieldType represented to at least one language specific
entry. This data type contains an item of class SAIFieldType and an item
of the field type specified by the value of the first item. All field
types defined in _5 Field type reference_ in <<I19775_1, ISO/IEC
19775-1>> shall be supported.

[[A2_SAIFrameRate]]
==== 5.2.17 SAIFrameRate

SAIFrameRate represents the rendering rate in frames per second that is
currently being achieved by the browser.

[[A2_SAILayerID]]
==== 5.2.18 SAILayerID

SAILayerID is an identifier of the target layer for an operation. The
ordering of the layers is the ordinal position of the layer in the
layers field of the LayerSet node defined in 35.4.2 LayerSet in
<<I19775_1, ISO/IEC 19775-1>>.

[[A2_SAILoadState]]
==== 5.2.19 SAILoadState

SAILoadState represents the load state of a node or EXTERNPROTO
instance. The state shall be one of NOT_STARTED, IN_PROGRESS, COMPLETE
or FAILED.

[[A2_SAIMatrix]]
==== 5.2.20 SAIMatrix

SAIMatrix specifies an identifier for a 3×3 or 4×4 matrix.

[[A2_SAINavSpeed]]
==== 5.2.21 SAINavSpeed

SAINavSpeed represents the navigation speed of the user in base speed
units.

[[A2_SAINode]]
==== 5.2.22 SAINode

SAINode specifies an identifier for a node. Individual language bindings
may place conditions on uniqueness allowing other methods for checking
equivalent references to the same node. The node reference is not
required to be part of the active scene graph.

A NULL value is a legal value for this data type. It is used to indicate
that no node identifier is to be used. For example, for the field
service `setValue` (see <<A2_setValue, 6.7.6 setValue>>), a value
of `NULL` on an SFNode field type is used to clear the node that
may have previously been set as the value.

The node concept is further defined in <<A2_Node, 4.4.8 Node>>.

[[A2_SAINodeType]]
==== 5.2.23 SAINodeType

SAINodeType represents the type of a node.

[[A2_SAIParameterList]]
==== 5.2.24 SAIParameterList

SAIParameterList is the abstract data type used to represent a list of
parameters that may be passed to a service request. Each language
binding shall be required to define the exact listing of parameters and
their mapping to language-specific types. This may be used to represent
more than one list of parameters where a binding provides multiple
overloaded implementations of a single service.

[[A2_SAIProfileDeclaration]]
==== 5.2.25 SAIProfileDeclaration

SAIProfileDeclaration specifies all the information about a profile and
its declaration. It may be used to represent both the profile
information declared in a file, and the available profiles from the
browser.

[[A2_SAIPropertyList]]
==== 5.2.26 SAIPropertyList

SAIPropertyList is an abstract data type defining a set of key/value
pairs for the provision of properties.

[[A2_SAIProtoDeclaration]]
==== 5.2.27 SAIProtoDeclaration

SAIProtoDeclaration represents the declaration of a PROTO or
EXTERNPROTO. It does not represent an instance created from the
declaration. The declaration cannot be changed at runtime and is only
constructed from a file, stream or string. This allows a browser to
build optimized internal storage mechanisms that may not be traversable
using normal scene graph traversal mechanisms. Each language binding
shall define its own representation and methods for creating instances
of the PROTO declaration.

[[A2_SAIRequester]]
==== 5.2.28 SAIRequester

SAIRequester represents the identifier of a client application or part
thereof that is requesting a service to be performed. Variables of this
data type are usually used to identify a particular client piece of code
that is interested in listening for changes in some information in
either the scene graph or browser state that functions as a callback
device.

[[A2_SAIRoute]]
==== 5.2.29 SAIRoute

SAIRoute represents a ROUTE construct. A ROUTE is not a node in the
scene graph and does not represent a concrete structure (see 4.4.8.2
Routes in <<I19775_1, ISO/IEC 19775-1>>).

[[A2_SAIScene]]
==== 5.2.30 SAIScene

SAIScene represents a complete world and all the information that
defines it including nodes, routes, protos and exports. A scene may come
from parsing of a file, stream or string, or be programmatically
constructed through this API.

[[A2_SAIScript]]
==== 5.2.31 SAIScript

SAIScript represents the containing node for user code that performs
internal interactions. It is an X3DNode object that exists as part of
the X3D scene graph.

[[A2_SAIScriptImplementation]]
==== 5.2.32 SAIScriptImplementation

SAIScriptImplementation is a marker data type used by user code to mark
the entrance point for the user code execution. It shall provide the
lifecycle methods that the browser calls during user code execution such
as _initialize()_ and _shutdown()_. It shall not be used as a parameter
to, or return type of, any service definition.

[[A2_SAIStream]]
==== 5.2.33 SAIStream

SAIStream represents X3D content arriving continuously.

[[A2_SAIString]]
==== 5.2.34 SAIString

SAIString represents a string formatted with the UTF-8 universal
character set. (see <<A2_I10646_1, ISO/IEC 10646>>).

[[A2_SAIUnitDeclaration]]
==== 5.2.35 SAIUnitDeclaration

SAIUnitDeclaration defines all the information about units and its
declaration. It is used to represent the unit information declared for a
file, either explicitly or by default.

[[A2_SAIURL]]
==== 5.2.36 SAIURL

SAIURL is a data type which references a single URL. The
URL may be any valid URL representation but is usually defined as a
human-readable string that conforms to <<A2_RFC4248, 2.[RFC4248>>].

[[A2_NULL]]
==== 5.2.37 NULL

NULL represents the empty value. It contains no data or reference to any
data type but serves as a valid value to return from a service when
nothing can be returned and yet no error is generated.

[[A2_ErrorTypes]]
=== 5.3 Error types

[[A2_SAIError]]
==== 5.3.1 SAIError

This section defines the error types that may be generated in response
to service requests. Errors are generated as synchronous values from a
service request and returned as variables of type SAIError. These error
types appear in the errors definition of a service request (see
<<A2_ConventionsUsed, 6.1.3 Conventions used>>). A language binding shall
define the representation for the SAIError data type and assign values
for each of the errors defined below but may also define additional
error data types to these.

[[A2_SAIBrowserUnavailable]]
==== 5.3.2 SAI_BROWSER_UNAVAILABLE

This error indicates that the request to gain a reference to a
<<A2_SAIBrowserApp, SAIBrowserApp>> has failed. Examples may be that a
network connection is down or that the type of reference required is not
supported by the vendor-specific implementation of a language binding.

[[A2_SAIConnectionError]]
==== 5.3.3 SAI_CONNECTION_ERROR

An error has occurred that resulted in the connection between the
browser and external application becoming non-functional. Therefore, the
service request could not be executed. This is a different error
condition from <<A2_SAIBrowserUnavailable, SAI_BROWSER_UNAVAILABLE>> as
it assumes that a valid reference has already been obtained and the
error occurred at a later time.

[[A2_SAIDisposed]]
==== 5.3.4 SAI_DISPOSED

The request made of the current <<A2_SAINode, SAINode>>,
<<A2_SAIField, SAIField>> or <<A2_SAIBrowserRef, SAIBrowserRef>> reference
is being made to an object that has already been disposed prior to this
service request.

[[A2_SAIImportedNode]]
==== 5.3.5 SAI_IMPORTED_NODE

An operation was attempted that used an imported node when it is not
permitted as defined in _4.4.6 Import/Export semantics_ in
<<I19775_1, ISO/IEC 19775-1>>. For example, adding the imported node
as a child to another node in the current scene.

[[A2_SAIInsufficientCapabilities]]
==== 5.3.6 SAI_INSUFFICIENT_CAPABILITIES

The user is attempting to add a node to an execution context that is
greater than the capabilities defined by the profile and components
definition for that scene.

[[A2_SAIInvalidAccessType]]
==== 5.3.7 SAI_INVALID_ACCESS_TYPE

The attempt to perform an operation of a field failed because it is an
invalid action for that field type. For example, an attempt made to read
the value of an inputOnly field would generate this error.

[[A2_SAIInvalidBrowser]]
==== 5.3.8 SAI_INVALID_BROWSER

The instance of <<A2_SAIBrowserRef, SAIBrowserRef>> data type provided as
part of the parameters to the service request has been disposed of prior
to this request.

[[A2_SAIInvalidDocument]]
==== 5.3.9 SAI_INVALID_DOCUMENT

When the user has attempted to import a World Wide Web Consortium
Document Object Model (DOM) document into an X3D scene and the document
cannot be completely resolved to an X3D scene graph. There are many
cases where this error might be generated, including the following:

Example 1  an invalid document structure

Example 2  not having the correct root element

[[A2_SAIInvalidExecutionContext]]
==== 5.3.10 SAI_INVALID_EXECUTION_CONTEXT

The instance of <<A2_SAIExecutionContext, SAIExecutionContext>> data type
provided as part of the parameters to this service request has been
disposed of prior to this request.

[[A2_SAIInvalidField]]
==== 5.3.11 SAI_INVALID_FIELD

The instance of <<A2_SAIField, SAIField>> data type provided as part of
the parameters to this service request has been disposed of prior to
this request.

[[A2_SAIInvalidName]]
==== 5.3.12 SAI_INVALID_NAME

The name provided to a service request is invalid or cannot be found in
the context of that object.

[[A2_SAIInvalidNode]]
==== 5.3.13 SAI_INVALID_NODE

The instance of <<A2_SAINode, SAINodeID>> data type provided as part of
the parameters to this service request has been disposed of prior to
this request.

[[A2_SAIInvalidOperationTiming]]
==== 5.3.14 SAI_INVALID_OPERATION_TIMING

The user is attempting to make a service request that is performed
outside of the context within which such operations are permitted (see
<<A2_InternalUserCodeLifeCycle, 4.8.3.7 User code lifecycle>>). Where a
service defines this as being a possible error type, this shall only be
thrown by internal interactions. External interactions shall never
generate this error.

[[A2_SAIInvalidURL]]
==== 5.3.15 SAI_INVALID_URL

An instance of SAIURL data type provided in one or more of the
parameters to this service request are invalid due to a syntax error.
Errors due to the requested URL not being available shall generate
either an <<A2_SAIURLUnavailable, SAI_URL_UNAVAILABLE>> error or an
asynchronous event notifying of such a problem.

[[A2_SAIInvalidX3D]]
==== 5.3.16 SAI_INVALID_X3D

The SAIStream, SAIString or X3D file (for example, as a result of the
fetching of a URL reference) passed to this service request contains
invalid syntax and cannot be parsed to produce legal data types for use
in other service requests.

[[A2_SAINodeInUse]]
==== 5.3.17 SAI_NODE_IN_USE

Indication that a named node handling action has attempted to re-use a
name that is already defined elsewhere in this current scene.

EXAMPLE  A user is attempting to import a node as a name that is already
described by a DEF.

An alternative use of this error shall be to indicate that the node, or
one of its children, is currently in use in another scene. It is an
error to share a single node instance across multiple scenes
simultaneously.

[[A2_SAINodeNotAvailable]]
==== 5.3.18 SAI_NODE_NOT_AVAILABLE

An error condition used for IMPORTed nodes. The user has described a
node that the IMPORT statement has said is valid, but the underlying
Inline has not yet been loaded to verify that it is a correctly EXPORTed
node.

[[A2_SAINotShared]]
==== 5.3.19 SAI_NOT_SHARED

A service request was made that assumed the browser was currently
participating in a shared scene graph when it was not.

[[A2_SAINotSupported]]
==== 5.3.20 SAI_NOT_SUPPORTED

Generalised error for when a service request is made for a capability
that is not available in this browser implementation. For example, if
the user requests a profile declaration for a profile that is not
supported by the browser, this error may be generated.

[[A2_SAIURLUnavailable]]
==== 5.3.21 SAI_URL_UNAVAILABLE

The service request requiring the browser to have a world URL set cannot
be completed because no URL has been set. This error is typically
generated from a `getWorldURL` (<<A2_getWorldURL, 6.4.6
getWorldURL>>) or `getNode` (<<A2_getNode, 6.4.7 getNode>>)
service request.

[[A2_EventTypes]]
=== 5.4 Event types

[[A2_EventTypesOverview]]
==== 5.4.1 Overview

Browser event types are asynchronous events that are generated in
response to changes in the status of the browser implementation. The
following event types shall be implemented by each language binding.
Additional implementation dependent events may be defined to supplement
the provided event types.

[[A2_SAIBConnectionError]]
===== 5.4.1.1 SAI_Browser_Connection_Error

The event type representing an error condition has occurred in the
internal connection between the browser and the external application
(see <<A2_ConnectionLost, 4.5.3.5 Connection Lost>>).

[[A2_SAIBrowserEvent]]
===== 5.4.1.2 SAI_Browser_Event

The event type that represents the general class of events produced by
each browser service (see <<A2_BrowserToExternalApp, 4.5.3 Browser to
external application>>).

[[A2_SAIBInitialized]]
===== 5.4.1.3 SAI_Browser_Initialized

The event type representing the browser having completed the
initialisation process of loading X3D content (see
<<A2_Initialize, 4.5.3.2 Initialize>>).

[[A2_SAIBShutdown]]
===== 5.4.1.4 SAI_Browser_Shutdown

The event type representing the browser being shutdown. That is the
execution model is no longer running or content is displayed (see
<<A2_Shutdown, 4.5.3.3 Shutdown>>).

[[A2_SAIBURLError]]
===== 5.4.1.5 SAI_Browser_URL_Error

The event type representing an error condition when no URLs could be
processed to form valid X3D content (see <<A2_NoURLsAvailable, 4.5.3.4
No URLs Available>>).

[[A2_SAIFieldEvent]]
==== 5.4.2 SAIFieldEvent

The event type used to represent the notification of a change in a field
value that the external application has registered interest in.

[[A2_servRef_html]]
== 6 Services reference

[[A2_IntroAndContents]]
=== 6.1 Introduction and topics

[[A2_Introduction]]
==== 6.1.1 Introduction

This clause provides a detailed definition of the semantics of the
services that a browser shall provide to external applications as
defined in this part of ISO/IEC 19775.

[[A2_Topics]]
==== 6.1.2 Topics

Table 6.1 specifies the topics for this clause.

Table 6.1 — Topics

* <<A2_IntroAndContents, 6.1 Introduction and topics>>
** <<A2_Introduction, 6.1.1 Introduction>>
** <<A2_Topics, 6.1.2 Topics>>
** <<A2_ConventionsUsed, 6.1.3 Conventions used>>
* <<A2_EstablishingAConnection, 6.2 Establishing a connection>>
** <<A2_EstablishConnectionIntro, 6.2.1 Introduction>>
** <<A2_getBrowser, 6.2.2 getBrowser>>
** <<A2_createBrowser, 6.2.3 createBrowser>>
* <<A2_BrowserServices, 6.3 Browser services>>
** <<A2_BrowserServiceIntroduction, 6.3.1 Introduction>>
** <<A2_getName, 6.3.2 getName>>
** <<A2_getVersion, 6.3.3 getVersion>>
** <<A2_getCurrentSpeed, 6.3.4 getCurrentSpeed>>
** <<A2_getCurrentFrameRate, 6.3.5 getCurrentFrameRate>>
** <<A2_getSupportedProfiles, 6.3.6 getSupportedProfiles>>
** <<A2_getProfile, 6.3.7 getProfile>>
** <<A2_getSupportedComponents, 6.3.8 getSupportedComponents>>
** <<A2_getComponent, 6.3.9 getComponent>>
** <<A2_getExecutionContext, 6.3.10 getExecutionContext>>
** <<A2_createScene, 6.3.11 createScene>>
** <<A2_replaceWorld, 6.3.12 replaceWorld>>
** <<A2_importDocument, 6.3.13 importDocument>>
** <<A2_loadURL, 6.3.14 loadURL>>
** <<A2_setDescription, 6.3.15 setDescription>>
** <<A2_createX3DFromString, 6.3.16 createX3DFromString>>
** <<A2_createX3DFromStream, 6.3.17 createX3DFromStream>>
** <<A2_createX3DFromURL, 6.3.18 createX3DFromURL>>
** <<A2_UpdateControl, 6.3.19 updateControl>>
** <<A2_RegisterBrowserInterest, 6.3.20 registerBrowserInterest>>
** <<A2_getRenderingProperties, 6.3.21 getRenderingProperties>>
** <<A2_getBrowserProperties, 6.3.22 getBrowserProperties>>
** <<A2_changeViewpoint, 6.3.23 changeViewpoint>>
** <<A2_Print, 6.3.24 print/println>>
** <<A2_BrowserDispose, 6.3.25 dispose>>
** <<A2_setBrowserOption, 6.3.26 setBrowserOption>>
* <<A2_ExecutionContextServices, 6.4 Execution context services>>
** <<A2_getSpecificationVersion, 6.4.1 getSpecificationVersion>>
** <<A2_getEncoding, 6.4.2 getEncoding>>
** <<A2_ECgetProfile, 6.4.3 getProfile>>
** <<A2_getComponents, 6.4.4 getComponents>>
** <<A2_getUnits, 6.4.5 getUnits>>
** <<A2_getWorldURL, 6.4.6 getWorldURL>>
** <<A2_getNode, 6.4.7 getNode>>
** <<A2_createNode, 6.4.8 createNode>>
** <<A2_createProto, 6.4.9 createProto>>
** <<A2_NamedNodeHandling, 6.4.10 namedNodeHandling>>
** <<A2_getProtoDeclaration, 6.4.11 getProtoDeclaration>>
** <<A2_ProtoDeclarationHandling, 6.4.12 protoDeclarationHandling>>
** <<A2_getExternProtoDeclaration, 6.4.13 getExternProtoDeclaration>>
** <<A2_ExternProtoDeclarationHandling, 6.4.14 externprotoDeclarationHandling>>
** <<A2_getRootNodes, 6.4.15 getRootNodes>>
** <<A2_getRoutes, 6.4.16 getRoutes>>
** <<A2_DynamicRouteHandling, 6.4.17 dynamicRouteHandling>>
** <<A2_ExecutionContextDispose, 6.4.18 dispose>>
* <<A2_SceneServices, 6.5 Scene services>>
** <<A2_SceneIntroduction, 6.5.1 Introduction>>
** <<A2_getMetaData, 6.5.2 getMetaData>>
** <<A2_setMetaData, 6.5.3 setMetaData>>
** <<A2_SceneNamedNodeHandling, 6.5.4 namedNodeHandling>>
** <<A2_RootNodeHandling, 6.5.5 rootNodeHandling>>
* <<A2_NodeServices, 6.6 Node services>>
** <<A2_NodeServicesIntro, 6.6.1 Introduction>>
** <<A2_NodeServicesgetTypeName, 6.6.2 getTypeName>>
** <<A2_getType, 6.6.3 getType>>
** <<A2_getField, 6.6.4 getField>>
** <<A2_NodeGetFieldDefinitions, 6.6.5 getFieldDefinitions>>
** <<A2_NodeDispose, 6.6.6 dispose>>
* <<A2_FieldServices, 6.7 Field services>>
** <<A2_FieldServicesIntro, 6.7.1 Introduction>>
** <<A2_getAccessType, 6.7.2 getAccessType>>
** <<A2_FieldServicesgetType, 6.7.3 getType>>
** <<A2_FieldServicesgetName, 6.7.4 getName>>
** <<A2_getValue, 6.7.5 getValue>>
** <<A2_setValue, 6.7.6 setValue>>
** <<A2_RegisterFieldInterest, 6.7.7 registerFieldInterest>>
** <<A2_FieldDispose, 6.7.8 dispose>>
* <<A2_RouteServices, 6.8 Route services>>
** <<A2_getSourceNode, 6.8.1 getSourceNode>>
** <<A2_getSourceField, 6.8.2 getSourceField>>
** <<A2_getDestinationNode, 6.8.3 getDestinationNode>>
** <<A2_getDestinationField, 6.8.4 getDestinationField>>
** <<A2_RouteDispose, 6.8.5 dispose>>
* <<A2_PrototypeServices, 6.9 Prototype services>>
** <<A2_isExternProto, 6.9.1 isExternproto>>
** <<A2_CreateInstance, 6.9.2 createInstance>>
** <<A2_protoGetFieldDefinitions, 6.9.3 getFieldDefinitions>>
** <<A2_CheckLoadState, 6.9.4 checkLoadState>>
** <<A2_RequestImmediateLoad, 6.9.5 requestImmediateLoad>>
* <<A2_ConfigurationServices, 6.10 Configuration services>>
** <<A2_ConfigurationServicesIntroduction, 6.10.1 Introduction>>
** <<A2_getComponentName, 6.10.2 getComponentName>>
** <<A2_getComponentLevel, 6.10.3 getComponentLevel>>
** <<A2_getProfileName, 6.10.4 getProfileName>>
** <<A2_getProfileComponents, 6.10.5 getProfileComponents>>
** <<A2_getProviderName, 6.10.6 getProviderName>>
** <<A2_getUnitCategory, 6.10.7 getUnitCategory>>
** <<A2_getUnitConversion, 6.10.8 getUnitConversion>>
** <<A2_getUnitName, 6.10.9 getUnitName>>
* <<A2_ServicesByScriptContent, 6.11 Services provided by script content>>
** <<A2_ScriptContentIntroduction, 6.11.1 Introduction>>
** <<A2_ScriptContentCreation, 6.11.2 Creation phase>>
** <<A2_ScriptContentSetup, 6.11.3 Setup phase>>
*** <<A2_setBrowser, 6.11.3.1 setBrowser>>
*** <<A2_setFields, 6.11.3.2 setFields>>
*** <<A2_Initialize, 6.11.3.3 initialize>>
** <<A2_ScriptContentRealised, 6.11.4 Realized phase>>
*** <<A2_prepareEvents, 6.11.4.1 prepareEvents>>
*** <<A2_eventsProcessed, 6.11.4.2 eventsProcessed>>
** <<A2_ScriptContentDisposed, 6.11.5 Disposed phase>>
*** <<A2_ScriptShutdown, 6.11.5.1 shutdown>>
* <<A2_MatrixServices, 6.12 Matrix services>>
** <<A2_MatrixServicesIntroduction, 6.12.1 Introduction>>
** <<A2_MatrixSet, 6.12.2 set>>
** <<A2_MatrixGet, 6.12.3 get>>
** <<A2_MatrixInverse, 6.12.4 inverse>>
** <<A2_MatrixTranspose, 6.12.5 transpose>>
** <<A2_MatrixMultiply, 6.12.6 multiply>>
** <<A2_MatrixMultiplyWithVector, 6.12.7 multiplyWithVector>>

* <<t-Conventions, Table 6.2 — SAI request conventions>>
* <<t-updateControlSAIActionValues, Table 6.3 — updateControl SAIAction values>>
* <<t-registerBrowserInterestSAIActionValues, Table 6.4 — registerBrowserInterest SAIAction values>>
* <<t-StandardRenderingPropertyDefinitions, Table 6.5 — Standard rendering property definitions>>
* <<t-StandardPropertiesDescribingExtension, Table 6.6 — Standard properties describing extension capabilities>>
* <<t-changeViewpointSAIActionValues, Table 6.7 — changeViewpoint SAIAction values>>
* <<t-getNodeSAIActionValues, Table 6.8 — getNode SAIAction values>>
* <<t-namedNodeHandlingSAIActionValues, Table 6.9 — namedNodeHandling SAIAction values>>
* <<t-protoDeclarationHandlingSAIActionValues, Table 6.10 — protoDeclarationHandling SAIAction values>>
* <<t-externprotoDeclarationHandlingSAIActionValues, Table 6.11 — externprotoDeclarationHandling SAIAction values>>
* <<t-dynamicRouteHandlingSAIActionValues, Table 6.12 — dynamicRouteHandling SAIAction values>>
* <<t-rootNodeHandlingSAIActionValues, Table 6.13 — rootNodeHandling SAIAction values>>
* <<t-registerFieldInterestSAIActionValues, Table 6.14 — registerFieldInterest SAIAction values>>


[[A2_ConventionsUsed]]
==== 6.1.3 Conventions used

Each of the services in this clause defines a particular request that
can be made through the SAI. Each request is defined by a number of
characteristics. In <<t-Conventions, Table 6.2>> the first column
defines each characteristic type and the second defines the properties
of that characteristic.

[[t-Conventions]]
Table 6.2 — SAI request conventions
[options="autowidth",frame=ends,grid=rows]
|===
|`+parameters:+` |first param data type, second param, +
[optional parameter data type], [multiple optional parameter data type]s

|`+returns:+` |The list of return value data types or expected ranges

|`+errors:+` |List of errors data types

|`+events:+` |The first event  +
The second event

|`+buffered:+` |Simple yes, no or N/A

|`+external:+` |Yes if this is available only to an external
interface, +
No if it is available to both internal and external interfaces.
|===

Parameters are listed by data type and are shown separated by a comma
(,) and a space. A parameter shown in square brackets [] indicates a
single optional value of the data type specified within the brackets.
The "[]s" symbology, square brackets followed by the "s" character,
indicates multiple optional parameters of that type are allowed. For
example, [SAIURL]s indicates that multiple instances of the data type
SAIURL may be provided while [SAIURL] indicates that only a single
SAIURL instance may be provided.

All characteristics defined for every service shall be implemented for
each language binding. At the end of each table, explanatory text
includes extra information pertinent to the implementation of that
service.

[[A2_EstablishingAConnection]]
=== 6.2 Establishing a connection

[[introduction-3]]
[[A2_EstablishConnectionIntro]]
==== 6.2.1 Introduction

The following services can be used to establish a session and obtain a
browser reference. Individual browser implementations may support one or
both of these methods. At least one service shall be supported.

[[A2_getBrowser]]
==== 6.2.2 getBrowser

[#t-getBrowser]##

[cols=",",]
|===
|`+parameters:+` |SAIParameterList
|`+returns:+` |SAIBrowserRef 
|`+errors:+` |SAI_BROWSER_UNAVAILABLE 
|`+events:+` |none
|`+buffered:+` |N/A
|===

The `getBrowser` service returns a reference to an instance of an
X3D browser through which other service requests may be processed.

This is a blocking call. No further requests from this external
application will be processed until an SAIBrowser value has been
generated (which may include the need to start a new instance of an X3D
browser) or an error condition is generated.

If an application makes a request for the same browser twice in the same
session then the same browser identifier shall be returned.

An implementation may define more than one variant of this service with
different parameter types. For example there may be alternate forms to
access a browser embedded in a HTML page and one for remote access from
another machine within the same language binding.

Additional error types may be added by individual language bindings to
deal with platform specific issues.

[[A2_createBrowser]]
==== 6.2.3 createBrowser

[cols=",",]
|===
|`+parameters:+` |SAIParameterList, SAIPropertyList
|`+returns:+`    |SAIBrowserApp
|`+errors:+`     |SAI_BROWSER_UNAVAILABLE
|`+events:+`     |none
|`+buffered:+`   |N/A
|===

The `createBrowser` service creates a new instance of a browser
application. The browser shall start with no URL set (that is, no active
X3D scene graph). The URL may be set at a later time using the
`loadURL` (see <<A2_loadURL, 6.3.14 loadURL>>) or
`replaceWorld` (see <<A2_replaceWorld, 6.3.12 replaceWorld>>)
service requests.

The property list is used to define the properties of the browser
application itself. The service request shall use the same property list
definitions as those defined in `loadURL `(see
<<A2_loadURL, 6.3.14 loadURL>>). It is not required to support exactly
the same capabilities, but the property list format shall be identical
and any behaviours are identical.

This is a blocking request. No further requests from this external
application will be processed until a new instance of an X3D browser has
been created or an error condition is generated.

Each request of this service shall produce a new browser application
instance in accordance with the supplied parameter values.

An implementation may define more than one variant of this service with
different parameter types. For example there may be alternate forms to
start a browser on a remote machine or to create a new window within a
running application.

Additional error types may be added by individual language bindings to
deal with platform specific issues.

Individual language bindings may add extra calls to the
`SAIBrowserApp` to provide platform-specific low-level handles
for the language.

EXAMPLE  A language binding may allow access to the raw image pixel data
for an offline image renderer so that a user may use platform-specific
calls to make extra drawing and compositing actions.

[[A2_BrowserServices]]
=== 6.3 Browser services

[[A2_BrowserServiceIntroduction]]
==== 6.3.1 Introduction

The following services can be requested from a browser. Although not
specified repeatedly, all services are capable of throwing an
SAI_CONNECTION_ERROR whenever a request is made if the session between
the application and the browser has failed.

NOTE  The data representation of the parameters or return values is not
specified. It is equally valid to represent all parameters as strings as
it is for binary representations.

[[A2_getName]]
==== 6.3.2 getName

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+`    |SAIBrowserName
|`+errors:+`     |SAI_DISPOSED
|`+events:+`     |None
|`+buffered:+`   |No
|`+external:+`   |No
|===

The `getName` service returns the name of the browser. This name
is implementation dependent. If this service is not supported a
`NULL` value shall be returned.

[[A2_getVersion]]
==== 6.3.3 getVersion

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |SAIBrowserVersion
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getVersion` service returns the current version of the
browser application. The version number of the browser is implementation
dependent. If this service is not supported then a `NULL` value
shall be returned.

[[A2_getCurrentSpeed]]
==== 6.3.4 getCurrentSpeed

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAILayerID
|`+returns:+` |SAINavSpeed
|`+errors:+` |SAI_DISPOSED +
SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getCurrentSpeed` service returns the navigation speed of the
current world. The current speed is the average navigation speed for the
currently bound NavigationInfo node of the active layer in base speed
units in the coordinate system of the currently bound viewpoint.

[[A2_getCurrentFrameRate]]
==== 6.3.5 getCurrentFrameRate

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |SAIFrameRate
|`+errors:+` |SAI_DISPOSED +
SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getCurrentFrameRate` service returns the current frame
display rate of the browser in frames per second. If this is not
supported, the value returned is zero.

[[A2_getSupportedProfiles]]
==== 6.3.6 getSupportedProfiles

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |SAIProfileDeclaration [SAIProfileDeclaration]s
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getSupportedProfiles` service returns the list of all
profiles that are supported by this browser. All browsers shall support
at least one profile.  It shall be an error if the browser returns a
declaration for a profile that it does not fully support.

[[A2_getProfile]]
==== 6.3.7 getProfile

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIString
|`+returns:+` |SAIProfileDeclaration
|`+errors:+` |SAI_DISPOSED +
SAI_NOT_SUPPORTED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getProfile` service returns the declaration of the named
profile. The value of the SAIString parameter is the name of a profile
from which to fetch the declaration and shall conform exactly to the
name specified in <<I19775_1, ISO/IEC 19775-1>>. It shall be an error
if a name with the wrong case, incorrect spelling, or anything other
than an exact match is provided. The browser is only required to return
an SAIProfileDeclaration value if it supports the named profile. If it
does not support the named profile, SAI_NOT_SUPPORTED shall be
generated.

[[A2_getSupportedComponents]]
==== 6.3.8 getSupportedComponents

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |SAIComponentDeclaration [SAIComponentDeclaration]s
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getSupportedComponents` service returns a list of all
components that are supported by this browser. All browsers shall
support at least one component, as required to support profiles.

[[A2_getComponent]]
==== 6.3.9 getComponent

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIComponent
|`+returns:+` |SAIComponentDeclaration
|`+errors:+` |SAI_DISPOSED +
SAI_NOT_SUPPORTED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getComponent` service returns the declaration of the named
component. The value of the SAIComponent parameter is the name of a
component and level from which to fetch the declaration and shall
conform exactly to the naming conventions used in the file format. It
shall be an error if the user provides a name with the wrong case,
incorrect spelling or anything other than an exact match. The browser is
only required to return a SAIComponentDeclaration value if it supports
the named component and the requested level. If it does not support the
component at the level desired, SAI_NOT_SUPPORTED shall be generated.

[[A2_getExecutionContext]]
==== 6.3.10 getExecutionContext

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |SAIExecutionContext
|`+errors:+` |SAI_DISPOSED +
SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getExecutionContext` service returns the current execution
context. If used in an internal interaction, this service returns the
execution context in which the containing node exists (see
<<A2_ContainingNode, 4.4.3 Containing Node>>). When used in an external
interaction, this service returns the current top-level scene.

The execution context is the base form of a scene, but only provides
access to the local nodes, PROTOs and routes as defined by the X3D name
scoping rules as defined in _4.4.7 Run-time name scope_ in
<<I19775_1, ISO/IEC 19775-1>>. Depending on the place in the scene
graph, the returned type may be an instance of SAIScene allowing the
user to utilize the greater capabilities.

[[A2_createScene]]
==== 6.3.11 createScene

[width="100%",cols="50%,50%",]
|===
|`+parameters:+`
|SAIBrowserRef, [SAIProfileDeclaration], [SAIComponentDeclaration]s

|`+returns:+` |SAIScene

|`+errors:+` |SAI_DISPOSED +
SAI_INVALID_OPERATION_TIMING

|`+events:+` |None

|`+buffered:+` |No

|`+external+`: |No
|===

The `createScene` service creates a new empty scene that conforms
to the given profile and component declarations. Although the
specification does not require either be provided, it shall be an error
to provide neither profile nor component definitions. A user shall
provide at least one valid profile or component identifier to this
request.

A scene created this way shall always have its specification version set
to "3.0", "3.1", "3.2", or "3.3" (as appropriate) and the encoding set
to "Scripted".

[[A2_replaceWorld]]
==== 6.3.12 replaceWorld

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIScene
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_SCENE +
SAI_DISPOSED +
SAI_INVALID_OPERATION_TIMING
|`+events:+` |SAI_Browser_Shutdown  +
SAI_Browser_Initialized
|`+buffered:+` |No
|`+external+`: |No
|===

The `replaceWorld` service replaces the current world with the
world specified by the SAIScene parameter. If another
`replaceWorld` or `loadURL` (see <<A2_loadURL, 6.3.14
loadURL>>) request is made during the processing of the current request,
the current request is terminated and the new one started. In this case,
no extra shutdown event shall be generated. The initialize event shall
be generated at the point where the world is ready to be run. The scene
is not required to contain any valid content. Setting a value of
`NULL` shall clear the currently set scene and leave a blank
browser with no renderable content and no current scene.

The SAI_Browser_Shutdown event is generated immediately upon receiving
this service request.

The SAI_Browser_Initialized event is generated when the new nodes have
been set and all browser specific initialization has taken place but
before the first time driven event cascade has been started (event
cascades may have previously resulted due to the initialization process
through internal scripts).

[[A2_importDocument]]
==== 6.3.13 importDocument

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, DOMNode
|`+returns:+` |SAIScene
|`+errors:+` |SAI_INVALID_DOCUMENT +
SAI_DISPOSED +
SAI_INVALID_OPERATION_TIMING +
SAI_NOT_SUPPORTED
|`+events:+` |None +
|`+buffered:+` |No
|`+external+`: |No
|===

The `importDocument` service is a utility request to import a
World Wide Web Consortium (W3C) Document Object Model (DOM) document or
document fragment and convert it to an X3D scene. The input allows any
form of DOM Node as defined by <<A2_W3CDOM2, 2.[W3CDOM2>>]. Although all
derived types are available, it shall only be required that DOCUMENT,
DOCUMENT_FRAGMENT, and ELEMENT types are required to be supported for
the conversion process.  The method only performs a conversion process
and does not display the resulting scene. The scene may then be used as
the argument for the `replaceWorld` (see
<<A2_replaceWorld, 6.3.12 replaceWorld>>) service. When the conversion is
made, there is no lasting connection between the DOM and the generated
scene. Each request shall be a single conversion attempt (the conversion
may not be successful if the DOM does not match the X3D scene graph
structure).

Support for this method is optional and shall be dependent on the
browser support for the XML encoding (see <<I19776_1, ISO/IEC
19776-1>>). If the browser implementation supports the XML encoding, it
shall support this service. If the browser does not support the XML
encoding, the implementation may support this service. User code may
check that this service is supported through the checking the browser
properties with the `getBrowserProperties` service. If this
service is not supported by the browser implementation,
SAI_NOT_SUPPORTED error shall be generated.

[[A2_loadURL]]
==== 6.3.14 loadURL

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIURL [SAIURL]s, SAIPropertyList
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_URL +
SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |SAI_Browser_Shutdown +
SAI_Browser_Initialize +
SAI_Browser_URL_Error
|`+buffered:+` |No
|external: |No
|===

The `loadURL` service inserts the content identified by the
URL(s) in the current world under control of the contents of the
SAIPropertyList instance.

The SAI_Browser_Shutdown event is generated immediately upon receiving
this service request if the parameter list is such that the browser is
about to be shutdown (EXAMPLE replaces an HTML Frame where
the browser was embedded).

The SAI_Browser_Initialized event is generated when the new nodes have
been set and all browser specific initialization has taken place but
before the first time driven event cascade has been started (event
cascades may have previously resulted due to the initialization process
through internal scripts).

The property list definition shall include at least one property that
defines loading the URL supplied as a new world in the supplied
SAIBrowserRef. If the property list is empty, the action is to replace
the world of the current browser with the new world if the successful
URL is an X3D file.

If another `replaceWorld` (see <<A2_replaceWorld, 6.3.12
replaceWorld>>) or `loadURL` request is made during the processing
of the current request, the current request is terminated and the new
one started. In this case, no extra shutdown event shall be generated.
The SAI_Browser_Initialize event shall be generated at the point where
the world is ready to be run if `replaceWorld` was called.

[[A2_setDescription]]
==== 6.3.15 setDescription

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIString
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

If the browser supports a description title, it shall be set to the new
description. Typically, this will be the title in a window title bar. In
cases where there may be multiple browsers on a single window, the
result is implementation dependent.

[[A2_createX3DFromString]]
==== 6.3.16 createX3DFromString

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIString
|`+returns:+` |SAIScene
|`+errors:+` |SAI_INVALID_X3D +
SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED +
SAI_NOT_SUPPORTED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `createX3DFromString` service creates nodes from a string.
The string shall contain valid X3D syntax; otherwise an error is
generated. If any relative URLs are encountered in this string, the base
is assumed to be the current browser location. The string is not
required to contain the X3D file header. If it is present, it shall be
treated as an indicator to the version of X3D contained. If absent, the
default version assumed shall be that specified in _7.2.5.2 Header
statement_ in <<I19775_1, ISO/IEC 19775-1>>. A browser is not required
to support any versions prior to ISO/IEC 19775.

If the string contains legal X3D statements but does not contain any
node instances,  a valid SAIScene value shall still be returned
containing no root nodes, but with the appropriate declaration
identifiers. For example the string may contain EXTERNPROTO declarations
but no instances of any node. If the SAIString provides the content in
an encoding format that the browser implementation does not support, the
browser shall generate an SAI_NOT_SUPPORTED error.

[[A2_createX3DFromStream]]
==== 6.3.17 createX3DFromStream

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIStream
|`+returns:+` |SAIScene
|`+errors:+` |SAI_INVALID_X3D +
SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED +
SAI_NOT_SUPPORTED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `createX3DFromStream` service creates nodes from an
arbitrary, user-provided stream of input data. The stream shall contain
valid X3D syntax from the first character; otherwise, an error is
generated. If any relative URLs are encountered in this string, the base
is assumed to be the current browser location. The stream is required to
include the X3D File Header in accordance with the encoding requirements
for the format.

If the string contains legal X3D statements but does not contain any
node instances, a valid SAIScene value shall still be returned
containing no root nodes, but with the appropriate declaration
identifiers. For example, the string may contain EXTERNPROTO
declarations but no instances of any node. If the stream identified by
SAIStream provides the content in an encoding format that the browser
implementation does not support, the browser shall generate an
SAI_NOT_SUPPORTED error.

[[A2_createX3DFromURL]]
==== 6.3.18 createX3DFromURL

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIURL [SAIURL]s
|`+returns:+` |SAIScene
|`+errors:+` |SAI_INVALID_URL +
SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |SAI_Browser_URL_Error
|`+buffered:+` |No
|`+external+`: |No
|===

The `createX3DFromURL` service creates nodes from the contents of
the file represented by the URL. The URL may be a relative URL which is
considered to be using the browser location as the base document. The
scene described by that URL shall be identified by the returned SAIScene
value.

[[A2_UpdateControl]]
==== 6.3.19 updateControl

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef, SAIAction
|`+returns:+` |None
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |N/A
|`+external+`: |Yes
|===

The `updateControl` specifies the manner in which buffered
updates are processed.

The SAIAction parameter specifies the actions that may be applied
against the buffer. Other actions may be added, such as to query the
number of items, or the state of the buffer and are implementation
dependent. <<t-updateControlSAIActionValues, Table 6.3>> defines the
actions specified in this part of ISO/IEC 19775.

[[t-updateControlSAIActionValues]]
Table 6.3 — updateControl SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|updateControl |`BeginUpdate`
| |`EndUpdate`
|===

The timestamp of events generated at the call to `EndUpdate` are
implementation dependent but should be consistent with the time within
the current world. That is, timestamps cannot be in the "past" relative
to the other current events generated internally with event model at the
time when they are generated.

`BeginUpdate` and `EndUpdate` are not nesting calls. Once
`BeginUpdate` has been called, it may be called any number of
times, but only a single `EndUpdate` call is needed to release
the buffered events into the scene graph. A call to `EndUpdate`
without a previous matching `BeginUpdate` has no effect.

[[A2_RegisterBrowserInterest]]
==== 6.3.20 registerBrowserInterest

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIAction, SAIRequester
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |Receiver of all SAIBrowserEvents
|`+buffered:+` |No
|`+external+`: |Yes
|===

The `registerBrowserInterest` service nominates the requester as
the receiver of all SAIBrowserEvents. The act of making this service
request itself does not imply any events shall be generated.

The parameter of type SAIRequester could be inferred from the source of
the input and may not need to be part of the parameters and is
implementation dependent. Each binding to this service shall specify
this requirement.

The parameter of type SAIAction specifies whether this is a request to
add interest in events, or to remove interest in the events. 
<<t-registerBrowserInterestSAIActionValues, Table 6.4>> defines the
actions specified in this part of ISO/IEC 19775.

[[t-registerBrowserInterestSAIActionValues]]
Table 6.4 — registerBrowserInterest SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|registerBrowserInterest |`AddBrowserInterest`
| |`RemoveBrowserInterest`
|===

Any change to the current browser shall be sent to the listener that has
registered interest in these events. These event notifications shall be
made independent of the method of communicating with the browser.

As a minimum, a conforming implementation shall provide the events
defined in <<A2_BrowserToExternalApp, 4.5.3 Browser to External
Application>>.

[[A2_getRenderingProperties]]
==== 6.3.21 getRenderingProperties

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |SAIPropertyList
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getRenderingProperties` service is used to query for the
rendering capabilities of the browser. This gives a list of the
low-level hardware capabilities of the browser rather than what X3D
components are supported. For example, it will give the user an idea of
how many multitexture units can be handled and allows the end user to
customize the number of nodes to use in the MultiTexture node. The keys
and values in the property list are implementation dependent and are for
informative purposes only.
<<t-StandardRenderingPropertyDefinitions, Table 6.5>> lists the
properties that are returned by this service.

[[t-StandardRenderingPropertyDefinitions]]
Table 6.5 — Standard rendering property definitions

[width="100%",cols="34%,33%,33%",options="header",]
|===
|Property Name + |Value data type + |Description +
 
|Shading |String |The type of shading algorithm in use. Typical values
are Flat, Gouraud, Phong, Wireframe. +

|MaxTextureSize |String |The maximum texture size supported. The format
shall be WIDTHxHEIGHT describing the number of pixels in each direction
(for example 1024x1024). +

|TextureUnits + |Integer |The number of texture units supported for
doing multitexture.

|AntiAliased + |Boolean + |True or false if the rendering is currently
anti-aliased or not +

|ColorDepth + |Integer |The number of bits of colour depth supported by
the screen. Allows for optimized selection of textures, particularly for
lower colour depth screen capabilities. +

|TextureMemory |Float |The amount of memory in megabytes available for
textures to be placed on the video card. +
|===

 

The user shall not be able to directly effect the rendering properties
of the browser by modifying the properties returned by this service.

[[A2_getBrowserProperties]]
==== 6.3.22 getBrowserProperties

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |SAIPropertyList
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getBrowserProperties` service is used to query for the
capabilities of the browser reference itself. This gives a list of the
expanded interfaces that this browser reference is capable of
supporting. For example it may be used to query for the existence of
browser implementation-specific extensions to the defined browser class
or future extensions as provided by this specification.

<<t-StandardPropertiesDescribingExtension, Table 6.6>> defines some
standard property names that are reserved by part of ISO/IEC 19775.
Where a browser implementer chooses to add additional capabilities, the
naming convention of these additional properties shall follow the
guidelines defined in _4.1.3 Conventions_ used in part 1 of of ISO/IEC
19775 (see <<I19775_1, 2.[I19775-1>>]).

[[t-StandardPropertiesDescribingExtension]]
Table 6.6 — Standard properties describing extension capabilities

[width="100%",cols="34%,33%,33%",]
|===
|Property Name |Value data type +
  |Description

|ABSTRACT_NODES |Boolean |The browser implementation supports the
ability to describe each node type with interfaces that correspond to
the abstract node types as defined in <<I19775_1, ISO/IEC 19775-1>> in
addition to the basic requirement to support the X3DNode abstract type.
This indicates that the browser supports at least Conformance Level 2.

|CONCRETE_NODES |Boolean |The browser implementation supports the
ability to describe each node type with interfaces that correspond to
the concrete node types as defined in <<I19775_1, ISO/IEC 19775-1>> in
addition to the requirement to support all of the abstract types. This
indicates that the browser supports at least Conformance Level 3.

|EXTERNAL_INTERACTIONS |Boolean |This SAIBrowserRef supports the
additional services required by external interfaces. A SAIBrowserRef
provided to user code in internal interactions shall not set this
property.

|PROTOTYPE_CREATE |Boolean |The browser implementation supports the
ability to dynamically create PROTO and EXTERNPROTO representations
through service requests. The basic service capability only allows the
ability to create instances of predefined PROTO structures read from a
file format.

|DOM_IMPORT |Boolean |The browser implementation supports the
<<A2_importDocument, importDocument>> service request.

|XML_ENCODING |Boolean |The browser supports XML as a file format
encoding.

|CLASSIC_VRML_ENCODING |Boolean |The browser supports the Classic VRML
encoding.

|COMPRESSED_BINARY_ENCODING |Boolean |The browser supports the binary
file format encoding.
|===

 

[[A2_changeViewpoint]]
==== 6.3.23 changeViewpoint

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIBrowserRef, SAIAction, SAILayerID
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |Yes
|`+external+`: |No
|===

The `changeViewpoint` service changes the currently bound
_X3DViewpointNode_ instance on the specified Layer to the instance
defined by the action. Valid action types are previous, next, first and
last. If a layer ID is not specified, the current activeLayer is used.
When the viewpoint is changed using this service request, the browser
shall first unbind the current instance and then bind the new instance.
That is, the number of items on the bindable stack bindable nodes shall
not increase as a result of making this service request.
<<t-changeViewpointSAIActionValues, Table 6.7>> defines the actions
specified in this part of ISO/IEC 19775.

[[t-changeViewpointSAIActionValues]]
Table 6.7 — changeViewpoint SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|changeViewpoint |`Next`
| |`Previous`
| |`First`
| |`Last`
|===

This service request implies that there is a standard, well-known
ordering of the _X3DViewpointNode_ instances so that consistent visual
behaviour shall be observed. The order shall be based on the following
rules:

. The order is declared in the originally parsed file or stream,
including resolution of PROTO instances, but not including EXTERNPROTO
or _X3DInlineNode_ instances.
. Dynamically created node instances are always appended.
. Instances located in _X3DInlineNode_ instances and EXTERNPROTO
instances shall be in the order in which the external scene is resolved,
and appended to the list. The inclusion of these external instances is
also dependent on the browser property EnableInlineViewpoints.

An invalid SAILayerID shall result in the operation being ignored.
Requests for SAILayerID values less than zero or greater than or equal
to the number of defined layers are considered invalid and shall cause
error SAI_INVALID_OPERATION_TIMING to be issued.

If the world only contains the default _X3DViewpointNode_ instance, this
request has no effect on the visual output.

[[A2_Print]]
==== 6.3.24 print/println

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef, SAIString
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |SAI_DISPOSED
|`+buffered:+` |No
|`+external:+` |No
|===

The `print` service prints a message to the browser's console.
The language-specific bindings may provide overloaded variations on this
service that do not take an SAIString value, but take other data types.
Other variants may include the ability to automatically add
linefeed/newline characters without the need to explicitly declare them
in the SAIString value. A binding shall provide at least the base
SAIString variant (print) and a variant that appends linefeed/newline
characters (println).

User code may call this service at any time, without restriction, unless
the browser reference has been disposed of.

[[A2_BrowserDispose]]
==== 6.3.25 dispose

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |SAI_B_Shutdown
|`+buffered:+` |No
|`+external:+` |Yes
|===

The `dispose` service indicates that the client is about to exit
this session and the browser is free to dispose of any resources that
this client may have consumed. An SAI_Browser_Shutdown event is sent
only to this client and may be generated internally by the language
implementation on the client machine (that is, it is not required that
the browser itself generate this event, just that the event is
generated). If any events have been held because `BeginUpdate`
has been called, disposing of the browser shall also call
`EndUpdate` to release those events to the browser for final
processing.

[[A2_setBrowserOption]]
==== 6.3.26 setBrowserOption

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef, SAIString, SAIObject
|`+returns:+` |SAIBoolean
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |Yes
|===

The `setBrowserOption` service allows setting options defined in
_9.2.4 Browser options_ in <<I19775_1, ISO/IEC 19775-1>>. The name
field shall be one of the defined names in Table 9.2 in
<<I19775_1, ISO/IEC 19775-1>>. This service shall return an SAIBoolean
value indicating whether the change request was successful. A browser is
not required to support dynamic changes to any options. If a browser
option is not supported, a value of [.style1]#FALSE# shall be returned.

[[A2_ExecutionContextServices]]
=== 6.4 Execution context services

[[A2_getSpecificationVersion]]
==== 6.4.1 getSpecificationVersion

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |SAIString
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The getSpecificationVersion returns the version string that describes to
which specification version this scene adheres. This version represents
the appropriate version number as defined in <<I14772_1, ISO/IEC
14772-1>>, <<I19775_1, ISO/IEC 19775-1>>, or has value 1.0 for versions
of VRML that precede the specification in <<I14772_1, ISO/IEC
14772-1>> that are supported by the implementation.

[[A2_getEncoding]]
==== 6.4.2 getEncoding

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |SAIEncoding
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getEncoding` service returns the encoding type that was used
to produce the portion of the scene represented by the specified
execution context. The encoding is one of a fixed set, but may include
additional types that are browser implementation specific. The minimum
required set of values (but not necessarily supported by the browser
implementation) shall be:

. _Scripted_: For scenes that are created completely through the SAI and
did not originate through a file somewhere.
. _ASCII_: For VRML 1.0 specification files.
. _VRML_: For VRML and the X3D Classic VRML encoding specified in
<<I19776_2, ISO/IEC 19776-2>>.
. _XML_: For X3D XML-encoded files specified in <<I19776_1, ISO/IEC
19776-1>>.
. _CompressedBinary_: for X3D Compressed binary-encoded files specified
in <<I19776_3, ISO/IEC 19776-3>>.
. _BIFS_: For MPEG-4 BIFS-encoded format specified in
<<A2_I14496_1, ISO/IEC 14496-1>>.

[[A2_ECgetProfile]]
==== 6.4.3 getProfile

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |SAIProfileDeclaration
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getProfile` service returns the profile that is used to
describe this scene. If the specification version is for a specification
version prior to X3D, the profile shall be VRML. If no profile is
provided, this shall return `NULL`.

[[A2_getComponents]]
==== 6.4.4 getComponents

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |[SAIComponentDeclaration]s
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getComponents` service returns the component(s) used to
describe the scene. The list returned shall represent only explicit
component declarations and not the implied components from the profile
declaration. If no component definitions are set, `NULL` shall be
returned.

[[A2_getUnits]]
==== 6.4.5 getUnits

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |[SAIUnitDeclaration]s
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |no
|`+external:+` |no
|===

The `getUnits` service returns all of the units used to
describe the scene. The list returned shall represent all explicit unit
declarations and the currently applied default units.

[[A2_getWorldURL]]
==== 6.4.6 getWorldURL

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |SAIURL
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |no
|`+external:+` |no
|===

The `getWorldURL` service returns the fully qualified URL of this
scene. This returns the entire URL including any possible arguments that
might be associated with a CGI call or similar mechanism. If the world
was created entirely programmatically, the URL shall be `NULL`.

[[A2_getNode]]
==== 6.4.7 getNode

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIString, SAIAction
|`+returns:+` |SAINode
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NAME +
SAI_DISPOSED +
SAI_NODE_NOT_AVAILABLE
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getNode` service searches for a node based on specified
criteria and returns an identifier for the node.

The SAIString is to identify the name of the node that has been marked
with one of the naming statements DEF, IMPORT or EXPORT in the currently
loaded X3D scene or previously added with a `namedNodeHandling`
request (see <<A2_NamedNodeHandling, 6.4.10 namedNodeHandling>>).

The SAIAction shall indicate which of the naming types shall be used to
find the node. For example, providing an action of `ImportNode`
shall not return a name that may be valid, but describes a node named
with the DEF statement.  <<t-getNodeSAIActionValues, Table 6.8>>
defines the actions specified in this part of ISO/IEC 19775.

[[t-getNodeSAIActionValues]]
Table 6.8 — getNode SAIAction values
[cols=",",options="header",]
|===
|Service |Action Type
|getNode |`DEFNode`
| |`IMPORTNode`
| |`EXPORTNode`
|===

Access shall only be available to names in this scene. DEFs in Inlined
files shall not be accessible in accordance with _4.4.3 DEF/USE
Semantics_ and _4.4.6, Import/Export semantics_ in
<<I19775_1, ISO/IEC 19775-1>>.

If the SAIAction is `IMPORTNode` and the name is valid but the
node definition is not yet available from the source Inline node,
SAI_NODE_NOT_AVAILABLE shall be generated.

[[A2_createNode]]
==== 6.4.8 createNode

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIString
|`+returns:+` |SAINode
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED +
SAI_INVALID_NAME
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `createNode` service creates a new default instance of the
node given by the SAIString value containing the name of an X3D node
type. The availability of the node is defined by the containing scene's
profile and component declarations. The name shall only refer to a
built-in node and shall not be used to create instances of PROTOs or
EXTERNPROTOs. If the node is not available in the currently specified
profile and components, the browser shall issue the SAI_INVALID_NAME
error.

[[A2_createProto]]
==== 6.4.9 createProto

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIString
|`+returns:+` |SAINode
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED +
SAI_INVALID_NAME
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `createProto` service creates a new default instance of the
named PROTO. The naming and scoping rules for creating a proto instance
for which the current execution context is inside another proto are
defined by _4.4.7 Run-time name scope_ in <<I19775_1, ISO/IEC
19775-1>>. If there is no PROTO declaration available that matches the
given name, the browser shall generated the SAI_INVALID_NAME error.

[[A2_NamedNodeHandling]]
==== 6.4.10 namedNodeHandling

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIAction, SAIAction,
SAIString, +
[SAINode \| SAIString, [SAIString]]

|`+returns:+` |None

|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED +
SAI_IMPORTED_NODE +
SAI_NODE_IN_USE +
SAI_INVALID_NAME

|`+events:+` |None

|`+buffered:+` |Yes

|`+external:+` |No
|===

The `namedNodeHandling` service is a request to add, remove, or
update the node identified by the SAIString value where that name is
considered to use the DEF, or IMPORT semantics. The add/remove/update
shall be described by the first SAIAction value. If the name already
exists as a mapping, the current mapping is replaced with the new
mapping. When adding a new named node, the new named node is not
required to be part of this scene.

The second SAIAction value describes which of the DEF or IMPORT naming
facilities shall be the target of this service request. This ensures
that correct semantics are applied. If the action is to add and the name
is already registered, SAI_NODE_IN_USE is generated. If the action is to
replace or update, and the node is not already registered, the
implementation may treat this as an add request.
<<t-namedNodeHandlingSAIActionValues, Table 6.9>> defines the actions
specified in this part of ISO/IEC 19775.

[[t-namedNodeHandlingSAIActionValues]]
Table 6.9 — namedNodeHandling SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|namedNodeHandling |`AddDEFNode`/`UpdateDEFNode`
| |`RemoveDEFNode`
| |`AddIMPORTNode`/`UpdateIMPORTNode`
| |`RemoveIMPORTNode`
| |`AddEXPORTNode`/`UpdateEXPORTNode`
| |`RemoveEXPORTNode`
|===

The first SAIString value identifies a name with a node as it should be
known in this scene. The name is not an intrinsic property of the node
and this only serves as a mapping function.

The second argument provides an option depending on the action being
undertaken. SAINode value is a reference to the node that may be needed
for verification of the DEF name addition. For adding IMPORTs, the
second string shall be the exported node name in the DEF'd inline and
the optional third string shall be the name to store it as in this
scene.

[[A2_getProtoDeclaration]]
==== 6.4.11 getProtoDeclaration

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIString
|`+returns:+` |SAIProtoDeclaration
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NAME +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getProtoDeclaration` service returns the named PROTO
declaration representation from this scene. This shall only be used to
request PROTO declarations. A request for an EXTERNPROTO declaration
shall generate SAI_INVALID_NAME.

[[A2_ProtoDeclarationHandling]]
==== 6.4.12 protoDeclarationHandling

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIString, SAINode, SAIAction
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `protoDeclarationHandling` service is a request to add,
remove or change the ProtoDeclaration identified by the SAIString value.

The SAIAction parameter specifies whether the service request is an add
or removal of the declaration node. If the name already exists as a
mapping, the current mapping is replaced with the new map. When adding a
new declaration it may come from another scene.
<<t-protoDeclarationHandlingSAIActionValues, Table 6.10>> defines the
actions specified in this part of ISO/IEC 19775.

[[t-protoDeclarationHandlingSAIActionValues]]
Table 6.10 — protoDeclarationHandling SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|protoDeclarationHandling |`AddProto`/`UpdateProto`
| |`RemoveProto`
|===

[[A2_getExternProtoDeclaration]]
==== 6.4.13 getExternProtoDeclaration

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIString
|`+returns:+` |SAIProtoDeclaration
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NAME  +
SAI_URL_UNAVAILABLE  +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getExternProtoDeclaration` service returns the named
EXTERNPROTO declaration representation from this scene.  This shall only
be used to request an EXTERNPROTO declaration. A request for a PROTO
declaration shall generate SAI_INVALID_NAME.

[[A2_ExternProtoDeclarationHandling]]
==== 6.4.14 externprotoDeclarationHandling

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAIString, SAINode, SAIAction
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `externprotoDeclarationHandling` service is a request to add,
remove or update the ExternProtoDeclaration identified by the SAIString
value.

The SAIAction parameter is used to indicate if the service request is an
add or removal of the declaration node. If the name already exists as a
mapping, the current mapping is replaced with the new map. When adding a
new declaration, it may come from another scene.
<<t-externprotoDeclarationHandlingSAIActionValues, Table 6.11>>
defines the actions specified in this part of ISO/IEC 19775.

[[t-externprotoDeclarationHandlingSAIActionValues]]
Table 6.11 — externprotoDeclarationHandling SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|externprotoDeclarationHandling
|`AddExternProto`/`UpdateExternProto`

| |`RemoveExternProto`
|===

[[A2_getRootNodes]]
==== 6.4.15 getRootNodes

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |SAINodes
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NAME +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getRootNodes` service returns a listing of the current root
nodes of the execution context. If the context was generated from a
file, the root nodes are in the order they were declared in the file.
Any added nodes are then appended to the list in the time order they
were received at the browser. If the context was generated
programmatically, the nodes are in the order they were received by the
browser.

[[A2_getRoutes]]
==== 6.4.16 getRoutes

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |SAIRoutes
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getRoutes` service gets the list of the current routes in
the scene. The route listing returned will only be the top level routes.
Routes contained within a PROTO definition or a prototype instance shall
not be included in this list.

[[A2_DynamicRouteHandling]]
==== 6.4.17 dynamicRouteHandling

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIExecutionContext, SAINode, SAIField, SAINode,
SAIField, SAIAction

|`+returns:+` |None

|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NODE +
SAI_INVALID_FIELD +
SAI_DISPOSED

|`+events:+` |None

|`+buffered:+` |Yes

|`+external:+` |No
|===

The `dynamicRouteHandling` service is a request to process a
route according to the action specified by the SAIAction value.

The parameter of type SAIAction specifies whether this should be an add
or delete of this route. Other actions may be added, such as to query
the existence of the nominated route. Actions defined by this part of
ISO/IEC 19775 are described in
<<t-dynamicRouteHandlingSAIActionValues, Table 6.12>>. The
SAINode/SAIField pair parameters are considered as defining the source
field and destination fields for the route request.

[[t-dynamicRouteHandlingSAIActionValues]]
Table 6.12 — dynamicRouteHandling SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|dynamicRouteHandling |`AddRoute`
| |`DeleteRoute`
|===

Route modification requests are to fit with the general event model
scheme as defined in _4.4.8 Event model_ in <<I19775_1, ISO/IEC
19775-1>>. The end of the event cascade is considered to be the cascade
that is initiated by the application sending events into the X3D browser
environment. Any new cascades generated as a result of the processing of
the initial events shall not be considered for the determination of the
event cascade.

If the action is to delete a route, and the route has previously been
deleted, no error should be generated.

[[A2_ExecutionContextDispose]]
==== 6.4.18 dispose

[cols=",",]
|===
|`+parameters:+` |SAIExecutionContext
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |SAI_Browser_Shutdown
|`+buffered:+` |No
|`+external:+` |Yes
|===

The `dispose` service specifies that the client has no further
interest in the resource represented by this execution context. The
browser may now take whatever action is necessary to reclaim any
resources consumed by this execution context, now or at any time in the
future. If this execution context has already been disposed, further
requests have no effect.

[[A2_SceneServices]]
=== 6.5 Scene services

[[introduction-5]]
[[A2_SceneIntroduction]]
==== 6.5.1 Introduction

A scene is an extension of the execution context services with
additional services provided. The Scene services implementation shall
include all of the services from <<A2_ExecutionContextServices, 6.4
Execution context services>>, and include the following additional
services.

[[A2_getMetaData]]
==== 6.5.2 getMetadata

[cols=",",]
|===
|`+parameters:+` |SAIScene, SAIString
|`+returns:+` |SAIString
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getMetadata` service returns an item of metadata from the
scene that was specified using the META statement defined in 7.2.5.5
META statement in <<I19775_1, ISO/IEC 19775-1>>. Metadata specified in
the META statement is represented as an SAIString key/value pair. Each
key corresponds to exactly zero or one value.

Optionally, the browser may provide a subservice to discover the valid
keys for this scene as part of this service.

Metadata defined by metadata nodes as defined in Part 1 of ISO/IEC 19775
are specifically different and can be manipulated using
<<A2_NodeServices, 6.6 Node services>>.

[[A2_setMetaData]]
==== 6.5.3 setMetadata

[cols=",",]
|===
|`+parameters:+` |SAIScene, SAIString, SAIString
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `setMetadata` service inserts an item of metadata in the
scene in the form of a META statement as defined in 7.2.5.6 META
statement in <<I19775_1, ISO/IEC 19775-1>>. Metadata is represented as
a SAIString key/value pair. Each key corresponds to exactly zero or one
value. Setting an item with a key that already exists replaces the
existing value. If the value is `NULL` for the given key, the
META statement associated with that key is removed from the scene.

Metadata defined by metadata nodes as defined in <<I19775_1, ISO/IEC
19775-1>> are specifically different and can be manipulated using
<<A2_NodeServices, 6.6 Node services>>.

[[A2_SceneNamedNodeHandling]]
==== 6.5.4 namedNodeHandling

In addition to the capabilities described in
<<A2_NamedNodeHandling, 6.4.10 namedNodeHandling>>, the Scene services
expand the capability to also work with exporting nodes. The definition
is expanded to the following:

The `namedNodeHandling` service is a request to add, remove or
change the node identified by the SAIString value where that name is
considered to use the DEF, or IMPORT or EXPORT semantics. The
add/remove/update shall be described by the first SAIAction parameter
value. If the name already exists as a mapping, the current mapping is
replaced with the new mapping. When adding a new named node, it is not
required to be a part of this scene.

The second SAIAction parameter value describes which of the DEF, IMPORT
or EXPORT naming facilities shall be the target of this service request.
This ensures that correct semantics are applied. If the action is to add
and the name is already registered then SAI_NODE_IN_USE is generated. If
the action is to replace or update, and the node is not already
registered, the implementation may treat this as an add request.

The first SAIString value specifies a name with a node as it should be
known in this scene. The name is not an intrinsic property of the node
and this only serves as a mapping function.

The second argument provides an option depending on the action being
undertaken. The SAINode value is a reference to the node that may be
needed for verification of an EXPORT or DEF name addition. For adding
IMPORTs, the second string shall be the exported node name in the DEF'd
inline and the optional third string shall be the name to store it as in
this scene (this corresponds with the Classic VRML syntax of _IMPORT
inlined_def.export_name [AS import_name]_). For adding EXPORTs the
second argument shall be the string, which is the optional name to
export the node as. If the first SAIString does not describe a node
marked with DEF, it shall generate a SAI_INVALID_NAME error.

[[A2_RootNodeHandling]]
==== 6.5.5 rootNodeHandling

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIScene, SAINode, SAIAction
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NODE +
SAI_DISPOSED +
SAI_IMPORTED_NODE +
SAI_NODE_IN_USE +
SAI_INSUFFICIENT_CAPABILITIES
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `rootNodeHandling` service is a request to add and remove a
root node of this scene.

The SAIAction parameter is used to indicate if the service request is an
add or removal of the node. If the action is to remove and the node is
not a known root node, this shall generate an error. If the action is to
add the node, it shall be appended to the current list of root nodes.
<<t-rootNodeHandlingSAIActionValues, Table 6.13>> defines the actions
specified in this part of ISO/IEC 19775.

[[t-rootNodeHandlingSAIActionValues]]
Table 6.13 — rootNodeHandling SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|rootNodeHandling |`AddRootNode`
| |`RemoveRootNode`
|===

Nodes are bound by the capabilities of the containing scene. No node
shall be of greater capabilities than the scene's declared profile and
additional components. SAI_INSUFFICIENT_CAPABILITIES shall be generated
if the action is to add a node to the scene and that node requires
greater capabilities than the scene permits.

If the action is to add a node and the node or any of its children is
currently part of another scene, generate SAI_NODE_IN_USE.

If the action is to remove a node and the node is not a known value of
this field, the request shall be silently ignored.

[[A2_NodeServices]]
=== 6.6 Node services

[[introduction-6]]
[[A2_NodeServicesIntro]]
==== 6.6.1 Introduction

The following services can be requested of an individual node. Each
service requires an identifier for that node. After a request of an
individual node to dispose of their resources, any further request made
to a node service shall generate a disposed error.

Although not specified, all services are capable of throwing an
SAI_CONNECTION_ERROR whenever a request is made if the session between
the application and the browser has failed.

[[A2_NodeServicesgetTypeName]]
==== 6.6.2 getTypeName

[cols=",",]
|===
|`+parameters:+` |SAINode
|`+returns:+` |SAIString
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getTypeName` service returns the name of the type of the
referenced node. The type name is the name as specified in ISO/IEC
19775-1 where the node type is defined (see _Node index_ in
<<I19775_1, ISO/IEC 19775-1>> for easy access to a node definition).
If the node represents a PROTO node instance, the type name returned is
the name of the PROTO declaration.

[[A2_getType]]
==== 6.6.3 getType

[cols=",",]
|===
|`+parameters:+` |SAINode
|`+returns:+` |SAINodeType
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getType` service returns the type indicator for the
referenced node. The type indicator is either the type defined for the
basic node types in the X3D specification, or the PROTO type name if it
is a prototyped node. This service is not required to be supported for a
conforming implementation.

[[A2_getField]]
==== 6.6.4 getField

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAINode, SAIFieldName
|`+returns:+` |SAIField
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NAME  +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getField` service returns a field identifier so that
operations can be performed on the node properties. If the field
requested is an inputOutput field, either the field name or the set_ and
_changed modifiers may be used to access the appropriate form of the
node as required. Access to fields is implementation dependent.

[[A2_NodeGetFieldDefinitions]]
==== 6.6.5 getFieldDefinitions

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAINodeType
|`+returns:+` |SAIFields
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NAME  +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getFieldDefinitions` service returns a list of all the field
definitions of the referenced node. The definitions provide a limited
form of the SAIField that has all the same services except the ability
to read or write the value of the field for a specific node instance.
This request returns the SAIField values as generic responses for every
instance of this node rather than for a specific instance.

[[A2_NodeDispose]]
==== 6.6.6 dispose

[cols=",",]
|===
|`+parameters:+` |SAINode
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `dispose` node service indicates that the client has no
further interest in the resource represented by this node. The browser
may take whatever action is necessary to reclaim any resources consumed
by this node, now or at any time in the future. If this node has already
been disposed, further requests have no effect.

Disposing of a node does not remove the node from the scene graph (if it
was inserted in the first place) but rather removes any local
information per client to it. The underlying X3D node representation is
only disposed if no other applications or scene graph structures contain
references to this node. The responsibility and timing for this action
is browser-implementation specific.

[[A2_FieldServices]]
=== 6.7 Field services

[[introduction-7]]
[[A2_FieldServicesIntro]]
==== 6.7.1 Introduction

The following are services that can be requested of individual fields of
a node. If the node from which a field was retrieved has been disposed,
field services are still permitted to operate providing that the field
reference has been obtained before disposing of the node. If a call is
made to a field service after requesting disposal of the field, a
disposed error shall be generated.

Although not specified, all services are capable of throwing an
SAI_CONNECTION_ERROR whenever a request is made if the session between
the application and the browser has failed.

[[A2_getAccessType]]
==== 6.7.2 getAccessType

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAINode, SAIField
|`+returns:+` |SAIFieldAccess
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getAccessType` service returns the access type for the
specified field of the referenced node.

[[A2_FieldServicesgetType]]
==== 6.7.3 getType

[cols=",",]
|===
|`+parameters:+` |SAINode, SAIField
|`+returns:+` |SAIFieldType
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getType` field service returns the type for the specified
field of the referenced node.

[[A2_FieldServicesgetName]]
==== 6.7.4 getName

[cols=",",]
|===
|`+parameters:+` |SAINode, SAIField
|`+returns:+` |SAIFieldName
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

If supported by the implementation, the `getName` field service
returns the name of the field as it was requested from the node. If the
service requested the _set_children_ field of a grouping node, this
shall return "set_children", but if a different request was for
_children_ on the same node, "children" shall be returned.

[[A2_getValue]]
==== 6.7.5 getValue

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAINode, SAIField
|`+returns:+` |SAIFieldValue
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_ACCESS_TYPE +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getValue` field service returns the value represented by the
specified field as it exists in the world. This represents the current
value of the field at the time of the request. If the request is made of
a field that has a setValue request buffered through
`BeginUpdate`, the value returned shall be the old value prior to
the setValue request. The value of the field may be a node if the field
represents an MFNode or SFNode.

All field types shall support the option to return a single value from
multi-valued arrays.

[[A2_setValue]]
==== 6.7.6 setValue

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAINode, SAIField, SAIFieldValue
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_ACCESS_TYPE +
SAI_IMPORTED_NODE +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `setValue` field service sets the value of the specified
field. Set requests shall obey the requirements as specified for
buffered events services.

The value of the field may be an SAINode value if the field represents
an MFNode or SFNode. It is permitted to send a `+null+` to a node or
field in order to clear the value from that field. For example sending a
`+null+` to the appearance inputOutput field of a Shape node as
specified in _12 Shape component_ in <<I19775_1, ISO/IEC 19775-1>>,
shall result in the _appearance_ field being cleared and set to the
default value of `+NULL+`.

If the SAINode value is registered as an IMPORTed node in this file, it
shall generate the SAI_IMPORTED_NODE error.

All field setting services implementations shall include the ability to
set individual values. Fields that describe multi-value arrays shall
also include the ability to append and remove items from the existing
field.

[[A2_RegisterFieldInterest]]
==== 6.7.7 registerFieldInterest

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAINode, SAIField, SAIAction, SAIRequester
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_ACCESS_TYPE +
SAI_INSUFFICIENT_CAPABILITIES +
SAI_NODE_IN_USE +
SAI_DISPOSED
|`+events:+` |SAIFieldEvent
|`+buffered:+` |No
|`+external:+` |No
|===

The `registerFieldInterest` service nominates the requester as
the receiver of all SAIFieldEvents. The act of making this service
request itself does not imply any events shall be
generated. <<t-registerFieldInterestSAIActionValues, Table 6.14>>
defines the actions specified in this part of ISO/IEC 19775.

[[t-registerFieldInterestSAIActionValues]]
Table 6.14 — registerFieldInterest SAIAction values

[cols=",",options="header",]
|===
|Service |Action Type
|registerFieldInterest |`AddInterest`
| |`RemoveInterest`
|===

The parameter of type SAIRequester can be inferred from the source of
the input and may not need to be part of the parameters.

The parameter of type SAIAction specifies whether this is a request to
add interest in events or to remove interest in the events.

Which capabilities are permitted to be listened to are implementation
dependent. For example, some implementations may permit listening to
inputOnly values and outputOnly values while others will only permit
listening to outputOnly values.

[[A2_FieldDispose]]
==== 6.7.8 dispose

[cols=",",]
|===
|`+parameters:+` |SAIField
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `dispose` field service indicates that the client has no
further interest in the resource represented by this field. The browser
may take whatever action is necessary to reclaim any resources consumed
by this field, now or at any time in the future. If this field has
already been disposed, further requests have no effect.


[[A2_RouteServices]]
=== 6.8 Route services

[[A2_getSourceNode]]
==== 6.8.1 getSourceNode

[cols=",",]
|===
|`+parameters:+` |SAIRoute
|`+returns:+` |SAINode
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external+`: |No
|===

The `getSourceNode` service returns the source node of the
specified route.

[[A2_getSourceField]]
==== 6.8.2 getSourceField

[cols=",",]
|===
|`+parameters:+` |SAIRoute
|`+returns:+` |SAIString
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getSourceField` service returns the name of the source field
of the specified route.

[[A2_getDestinationNode]]
==== 6.8.3 getDestinationNode

[cols=",",]
|===
|`+parameters:+` |SAIRoute
|`+returns:+` |SAINode
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getDestinationNode` service returns the destination node of
the specified route.

[[A2_getDestinationField]]
==== 6.8.4 getDestinationField

[cols=",",]
|===
|`+parameters:+` |SAIRoute
|`+returns:+` |SAIString
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getDestinationField` service returns the name of the
destination field of the specified route.

[[A2_RouteDispose]]
==== 6.8.5 dispose

[cols=",",]
|===
|`+parameters:+` |SAIRoute
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING
|`+events:+` |None
|`+buffered:+` |Yes
|`+external:+` |No
|===

The `dispose` route service indicates that the client has no
further interest in the resource represented by this route. The browser
may take whatever action is necessary to reclaim any resources consumed
by this route, now or at any time in the future. If this route has
already been disposed, further requests have no effect.

Disposing of a route does not remove the route from the scene graph (if
it was inserted in the first place) but rather removes any local
information per client to it. The underlying X3D node representation is
only disposed of if no other applications or scene graph structures
contain references to this route and the responsibility and timing for
this action is browser implementation specific.

[[A2_PrototypeServices]]
=== 6.9 Prototype services

[[A2_isExternProto]]
==== 6.9.1 isExternproto

[cols=",",]
|===
|`+parameters:+` |SAIProtoDeclaration
|`+returns:+` |SAIBoolean
|`+errors:+` |SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `isExternproto` service checks to see if the prototype
declaration represents a PROTO or EXTERNPROTO. If it is an EXTERNPROTO,
a `TRUE` value shall be returned, and PROTO declarations shall
return `FALSE`.

[[A2_CreateInstance]]
==== 6.9.2 createInstance

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIProtoDeclaration
|`+returns:+` |SAINode
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_INVALID_NODE +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `createInstance` service creates a new instance from the
declaration of either a PROTO or EXTERNPROTO. An EXTERNPROTO instance
may fail with SAI_INVALID_NODE if the definition has not yet been
loaded.

[[A2_protoGetFieldDefinitions]]
==== 6.9.3 getFieldDefinitions

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIProtoDeclaration
|`+returns:+` |SAIField(s)
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getFieldDefinitions` service returns a list of all the field
definitions of the PROTO or EXTERNPROTO declaration. The definitions
provide a limited form of the SAIField value that has all the same
services except the ability to read or write the value of the field for
a specific node instance.

[[A2_CheckLoadState]]
==== 6.9.4 checkLoadState

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIProtoDeclaration
|`+returns:+` |SAILoadState
|`+errors:+` |SAI_INVALID_NODE +
SAI_INVALID_URL +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `checkLoadState` service checks on the current load state of
the EXTERNPROTO definition. The state shall be one of NOT_STARTED,
IN_PROGRESS, COMPLETE or FAILED. If this is called on a PROTO, a
SAI_INVALID_NODE error shall be generated.

[[A2_RequestImmediateLoad]]
==== 6.9.5 requestImmediateLoad

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIProtoDeclaration
|`+returns:+` |None
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` + |No
|===

If the SAIProtoDeclaration value represents an EXTERNPROTO, the
`requestImmediateLoad` service requests that the browser start
immediate loading of that definition. If the definition is already
loaded or the load is already in progress, this request shall be
silently ignored.

[[A2_ConfigurationServices]]
=== 6.10 Configuration services

[[introduction-8]]
[[A2_ConfigurationServicesIntroduction]]
==== 6.10.1 Introduction

The services specified here allow an application to identify the
configuration of the current world.

An SAIComponentDeclaration value specifies a component declaration
containing the information specified by the COMPONENT statement as
defined by 7.2.5.4 COMPONENT statement in <<I19775_1, ISO/IEC
19775-1>>. The services defined are the minimum required. An
implementation may provide additional informational-only services.

An SAIProfileDeclaration value specifies a profile declaration
containing the information specified by the PROFILE statement as defined
by 7.2.5.3 PROFILE statement in <<I19775_1, ISO/IEC 19775-1>> and by
the profile definition contained in the annexes of
<<I19775_1, ISO/IEC 19775-1>>. The services defined are the minimum
required. An implementation may provide additional informational-only
services.

[[A2_getComponentName]]
==== 6.10.2 getComponentName

[cols=",",]
|===
|`+parameters:+` |SAIComponentDeclaration
|`+returns:+` |SAIString
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getComponentName` service returns the formal name of the
specified component.

[[A2_getComponentLevel]]
==== 6.10.3 getComponentLevel

[cols=",",]
|===
|`+parameters:+` |SAIComponentDeclaration
|`+returns:+` |SAIString
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getComponentLevel` service returns the support level
specified for the component. When the SAIComponentDeclaration comes from
the browser services, it shall represent the maximum level supported by
the browser. When it comes from the scene services, the level represents
the requested support level for that scene.

[[A2_getProfileName]]
==== 6.10.4 getProfileName

[cols=",",]
|===
|`+parameters:+` |SAIProfileDeclaration
|`+returns:+` |SAIString
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getProfileName` service returns the formal name of the
specified profile.

[[A2_getProfileComponents]]
==== 6.10.5 getProfileComponents

[cols=",",]
|===
|`+parameters:+` |SAIProfileDeclaration
|`+returns:+` |SAIComponentDeclaration(s)
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getProfileComponents` service returns a list of
SAIComponentDeclaration instances specifying the allowed support for
each component of which the profile is comprised.

[[A2_getProviderName]]
==== 6.10.6 getProviderName

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIProfileDeclaration
|`+returns:+` |SAIString
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` + |No
|===

The `getProviderName` service is an information-only service that
returns an SAIString value containing the name of the person or company
that implemented this profile.

[[A2_getUnitCategory]]
==== 6.10.7 getUnitCategory

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIUnitDeclaration
|`+returns:+` |SAIString
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `getUnitCategory` service returns the formal category of the
specified unit declaration.

[[A2_getUnitConversion]]
==== 6.10.8 getUnitConversion

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIUnitDeclaration
|`+returns:+` |SAIString
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` + |No
|===

The `getUnitConversion` service returns the conversion factor of
the specified unit declaration.

[[A2_getUnitName]]
==== 6.10.9 getUnitName

[width="100%",cols="50%,50%",]
|===
|`+parameters:+` |SAIUnitDeclaration
|`+returns:+` |SAIString
|`+errors:+` |SAI_INVALID_OPERATION_TIMING +
SAI_DISPOSED
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` + |No
|===

The `getUnitName` service returns the user-provided name of the
specified unit declaration.

[[A2_ServicesByScriptContent]]
=== 6.11 Services provided by script content

[[introduction-9]]
[[A2_ScriptContentIntroduction]]
==== 6.11.1 Introduction

When an author provides the executable content of a script, certain
conventions shall be satisfied. This allows the browser to communicate
status information unambiguously  regardless of the type of content
language. This clause defines services that are required to be defined
by the individual language bindings in a manner such that script content
may be informed in a consistent, unambiguous manner. Script content
shall be required to run identically regardless of language used to
author the content. In contrast to the other services specifications,
the browser shall make these service requests of the user's code, and
therefore the user code shall provide implementations of these, where
necessary. All services are defined at the user's discretion and if the
user does not define the service implementation, the browser shall
silently continue.

[[A2_ScriptContentCreation]]
==== 6.11.2 Creation phase

During the creation phase, the script content is downloaded and an
instance of the content created in the appropriate execution engine.
Some content may require separate interpreters, while others may be
created in the same address and execution space as the browser code
(e.g., scripts created in the same language in which the browser itself
was written). Apart from the instantiation process, which is language
dependent, the browser shall not require any services.

[[A2_ScriptContentSetup]]
==== 6.11.3 Setup phase

During the setup phase, the browser provides the script with all of the
run-time information that it will be able to use in the system.

[[A2_setBrowser]]
===== 6.11.3.1 setBrowser

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `setBrowser` service passes to the script implementation code
the the SAIBrowserRef value to be used. There is no other way of
acquiring the SAIBrowserRef during the lifetime of the script, so if the
user code needs to know about it, it should store it now. This service
shall be performed before any other service requests are made. The
browser may call this service at any time between the creation phase and
before the Initialize service request is made. The browser is not
required to request it during the initialization process as defined
_4.4.8 Event model_ in <<I19775_1, ISO/IEC 19775-1>> although that is
time when the Browser implementers are encouraged to request this
service.

[[A2_setFields]]
===== 6.11.3.2 setFields

[cols=",",]
|===
|`+parameters:+` |SAINode, SAIField(s)
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `setFields` script service passes in the list of fields
declared in this script node instance. It also passes in the external
view of the containing script node so that the user may add and remove
routes to the script directly. The SAIField instances represent all of
the fields of a script, including the pre-defined fields. (See
<<A2_UpdatingTheSceneGraph, 4.8.3.4 Updating the scene graph>> for
details on the field access restrictions). This request shall be
performed between the setBrowser and initialize service requests.

[[A2_Initialize]]
===== 6.11.3.3 initialize

[cols=",",]
|===
|`+parameters:+` |None
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `initialize` script service provides notification to the
script that all basic initialization has been completed and that the
user code is active in the scene graph.  At this point, the user code
may access script field values and change the state of the script.

[[A2_ScriptContentRealised]]
==== 6.11.4 Realized phase

[[A2_prepareEvents]]
===== 6.11.4.1 prepareEvents

[cols=",",]
|===
|`+parameters:+` |None
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |Yes
|===

The `prepareEvents` service provides notification that the
browser is about to start the event cascade processing in accordance
with step 4 of the event execution model as described in _4.4.8.3
Execution model_ in <<I19775_1, ISO/IEC 19775-1>>. All values changed
during this call shall have the current time stamp, but events shall not
be immediately propagated upon return from the user code. This service
request shall be called every frame regardless of whether the containing
node received any events. If the containing node provides directOutputs,
these shall be passed immediately to the underlying nodes.

[[A2_eventsProcessed]]
===== 6.11.4.2 eventsProcessed

[cols=",",]
|===
|`+parameters:+` |SAIBrowserRef
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |SAI_Browser_Shutdown
|`+buffered:+` |No
|`+external:+` |Yes
|===

The `eventsProcessed` service provides notification that the
current event cascade processing has finished and that the containing
node is now allowed to make updates to the scene graph. This is useful
for user code that wishes to be more efficient and only generate new
events after a collection of field changes are received. Within a given
frame, user code may have this service called more than once. User code
cannot guarantee that all changes to the containing node will be
received by this time and should take appropriate precautions. This
service request shall only be called after the containing node has
received one or more events in this timestamp. If the containing node
has received no events in the current timestamp it shall be an error for
the browser to request this service.

[[A2_ScriptContentDisposed]]
==== 6.11.5 Disposed phase

[[A2_ScriptShutdown]]
===== 6.11.5.1 shutdown

[cols=",",]
|===
|`+parameters:+` |None
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |SAI_Browser_Shutdown
|`+buffered:+` |No
|`+external:+` |Yes
|===

The `shutdown` service provides notification that the user code
has been disposed of by the containing node. This may be due to the
complete shutdown of the browser, the loaded world changing or the
containing node changing the user code to another implementation. After
this service request has been completed, user code will no longer be
functional or executed.

[[A2_MatrixServices]]
=== 6.12 Matrix services

[[introduction-10]]
[[A2_MatrixServicesIntroduction]]
==== 6.12.1 Introduction

Matrix objects represent the standard mathematic matrix capabilities
using double precision numbers and column-major order. All services here
shall be interpreted using standard mathematical definitions of
matrices.

Implementations shall provide matrices that are 3x3 and 4x4. They may
define other orders of matrices. Implementations may also define
additional convenience services in addition to this minimum subset; for
example, the ability to individually access matrix elements.
Implementations may allow direct access to the individual row and column
values of the matrix.

In the following service definitions, the parameters describe single
precision inputs. An implementation shall also provided overloaded
definitions that include double precision input.

[[A2_MatrixSet]]
==== 6.12.2 set

[cols=",",]
|===
|`+parameters:+` |SAIMatrix, SFVec3f, SFRotation, SFVec3f, SFRotation,
SFVec3f

|`+returns:+` |None

|`+errors:+` |None

|`+events:+` |None

|`+buffered:+` |No

|`+external:+` |No
|===

The `set` matrix service sets the matrix to the new value
calculated from the parameters. The parameters are defined to represent,
in order: translation, rotation, scale, scaleOrientation, and center. If
a value for a parameter is not specified, the default value for that
parameter shall be the default value for the equivalent field of the
Transform node defined in _10.4.4 Transform_ in <<I19775_1, ISO/IEC
19775-1>>.

[[A2_MatrixGet]]
==== 6.12.3 get

[cols=",",]
|===
|`+parameters:+` |SAIMatrix, SFVec3f, SFRotation, SFVec3f, SFRotation,
SFVec3f

|`+returns:+` |None

|`+errors:+` |None

|`+events:+` |None

|`+buffered:+` |No

|`+external:+` |No
|===

The `get` service computes and returns the transformation values
from the matrix. The parameters are defined to represent, in order:
translation, rotation, scale, scaleOrientation and center.

[[A2_MatrixInverse]]
==== 6.12.4 inverse

[cols=",",]
|===
|`+parameters:+` |SAIMatrix
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `inverse` service calculates the inverse of this matrix in
place.

[[A2_MatrixTranspose]]
==== 6.12.5 transpose

[cols=",",]
|===
|`+parameters:+` |SAIMatrix
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `transpose` service transposes this matrix in place.

[[A2_MatrixMultiply]]
==== 6.12.6 multiply

[cols=",",]
|===
|`+parameters:+` |SAIMatrix, SAIMatrix
|`+returns:+` |None
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `multiply` service multiplies the first matrix by the second
matrix instance placing the result in the first matrix. Implementations
shall define multiplication operations in both directions: left and
right.

[[A2_MatrixMultiplyWithVector]]
==== 6.12.7 multiplyWithVector

[cols=",",]
|===
|`+parameters:+` |SAIMatrix, SFVec3f
|`+returns:+` |SFVec3f
|`+errors:+` |None
|`+events:+` |None
|`+buffered:+` |No
|`+external:+` |No
|===

The `multiplyWithVector` service multiplies this matrix and a
vector together. Implementations shall define multiplication operations
in both directions: left and right.

[[A2_conformance_html]]
== 7 Conformance and minimum support requirements


[[A2_IntroAndContents]]
=== 7.1 Introduction and topics

[[A2_Introduction]]
==== 7.1.1 Introduction

This clause defines the minimum required support for language bindings
conforming to this part of ISO/IEC 19775.

[[A2_Topics]]
==== 7.1.2 Topics

Table 7.1 lists the topics for this clause.

Table 7.1 — Topics

* <<A2_IntroAndContents, 7.1 Introduction and topics>>
** <<A2_Introduction, 7.1.1 Introduction>>
** 7.1.2 Topics
** <<A2_Objectives, 7.1.3 Objectives>>
** <<A2_Scope, 7.1.4 Scope>>
* <<A2_Conformance, 7.2 Conformance>>
** <<A2_ConformancetoISO, 7.2.1 Conformance to this part of ISO/IEC 19775>>
** <<A2_LanguageBindings, 7.2.2 Language Bindings>>
* <<A2_MinRequirements, 7.3 Minimum support requirements>>
** <<A2_RequirementsforImpl, 7.3.1 Requirements for implementations>>
** <<A2_InternalExternal, 7.3.2 Supporting internal and external interactions>>
** <<A2_Level1, 7.3.3 Level 1>>
** <<A2_Level2, 7.3.4 Level 2>>
** <<A2_Level3, 7.3.5 Level 3>>

* <<t-SpecsForSAIDataType, Table 7.2 — Specifications for SAI data type implementations>>
* <<t-SpecsForSAIBrowser, Table 7.3 — Specifications for SAI browser implementations>>
* <<t-SpecsForSAIGeneral, Table 7.4 — Specifications for SAI general services>>
* <<t-SpecsForSAIScript, Table 7.5 — Specifications for SAI script content interaction>>
* <<t-SpecsForSAIUtils, Table 7.6 — Specifications for SAI utility services>>


[[A2_Objectives]]
==== 7.1.3 Objectives

This clause addresses conformance of X3D browsers that provide a scene
authoring interface (SAI).

The primary objectives of the specifications in this clause are:

[loweralpha]
. to promote interoperability by eliminating arbitrary subsets of
ISO/IEC 19775;
. to promote extensibility within a well-defined environment;
. to promote uniformity in the development of conformance tests;
. to promote consistent results across X3D browsers;
. to facilitate automated test generation.

[[scope]]
[[A2_Scope]]
==== 7.1.4 Scope

Conformance is defined for language bindings to this specification and
therefore X3D Browsers and applications that use the facilities provided
by the Scene Authoring Interface language-specific bindings as specified
in <<I19777, ISO/IEC 19777>>.

Due to the abstract nature of this specification, it is not possible to
specify the conformance tests of individual language bindings of the
specification. Separate Conformance sections shall be provided within
each language binding that provide the necessary information to
implement language-specific binding conformance tests.

A concept of base profile conformance is defined to ensure
interoperability of X3D applications and X3D browsers. Base profile
conformance is based on a set of limits and minimal requirements. Base
profile conformance is intended to provide a functional level of
reasonable utility for X3D language bindings while limiting the
complexity and resource requirements of X3D browsers. Base profile
conformance may not be adequate for all uses of the SAI.

[[A2_Conformance]]
=== 7.2 Conformance

[[A2_ConformancetoISO]]
==== 7.2.1 Conformance to this part of ISO/IEC 19775

A X3D browser is only conformant to this part of ISO/IEC 19775 if it
also conformant to the current profile as specified in
<<I19775_1, ISO/IEC 19775-1>>. In addition, the following conditions
shall be met:

[loweralpha]
. Requests of the Browser services shall conform exactly to the
behaviour as specified in this part of ISO/IEC 19775.
. Where a browser is required to read and parse X3D content, it shall be
able to handle any X3D file that conforms to the profile being supported
as defined in <<I19775_1, ISO/IEC 19775-1>> or separate specification
for such profiles.
. Only nodes in the top level world (the file defined by the
`getWorldURL` service) that are named with the DEF construct
shall be visible to the `getNode` browser service request.
. There shall be no difference in treatment of events that result from
an external service request compared to events generated within the X3D
browser environment. That is, externally generated event cascades shall
have no favoured treatment.

[[A2_LanguageBindings]]
==== 7.2.2 Language bindings

A language binding to this part of ISO/IEC 19775 is conforming if:

[loweralpha]
. It implements the services defined in this specification including
return values, error conditions and asynchronous events.
. The services implemented conform to the required functionality for the
subject profile.
. It provides sections outlining conformance and minimum requirements of
implementations of that binding.

[[A2_MinRequirements]]
=== 7.3 Minimum Requirements

[[A2_RequirementsforImpl]]
==== 7.3.1 Requirements for implementations

All profiles supporting the authoring component shall support the Level
1 functionality as defined in this section. There are two levels of
conformance, that of the language binding and the browser
implementation.

A language binding shall at a minimum implement the services required
for the profile to be supported. It may also define its own optional set
of minimum requirements that are no less than the requirements of this
section. A browser implementation shall, in addition to the base support
for the subject profile, also support the minimum capabilities defined
for the subject profile. In general, the browser requirements are
specified as general requirements that deal with specific language
issues.

Where a browser implements two or more language bindings with different
levels of minimum requirements, the browser shall support the minimum
requirements for each language separately. Therefore, if one language
has higher requirements, the lower requirements of the other shall not
be used.

[[A2_InternalExternal]]
==== 7.3.2 Supporting internal and external interactions

Although external interactions use a superset of the services defined
for internal interactions, language bindings to the abstract
specification are not required to implement both. They may choose one or
the other or both. (It is strongly recommended that a binding support
both.)

A conformant browser implementation is not required to provide both
internal and external implementations of a given language binding. It
shall be possible for a browser to support internal interactions only
with language A and external interactions only with language B. In
addition, the browser may choose to support only internal interactions
or only external interactions. There is no requirement to support both
internal and external interactions.

[[A2_Level1]]
==== 7.3.3 Level 1

<<t-SpecsForSAIDataType, Table 7.2>> through
<<t-SpecsForSAIUtils, Table 7.6>> define the minimum requirements for
a base profile. The first column specifies the item for which
conformance is being defined. These refer to the services as defined by
this specification. The second column specifies the requirements for a
language binding specification of that item. The third column specifies
the requirements of a browser implementation of that service. SAI
implementations shall throw an SAIError (such as SAI_NOT_SUPPORTED) if a
capability is not supported.

For all these requirements, it shall be assumed that the language
binding shall provide complete implementation of all the parameters
required for the individual services. Language bindings of data types
may be implemented as primitive types in the target language rather than
as separate data types. <<t-SpecsForSAIDataType, Table 7.2>> through
<<t-SpecsForSAIUtils, Table 7.6>> indicate where this is permitted.

A browser conformant to this level shall support bindings to the X3DNode
and X3DMetadataObject abstract representations along with all field
types.

[[t-SpecsForSAIDataType]]
Table 7.2 — Specifications for SAI data type implementations

[width="100%",cols="34%,33%,33%",]
|===
|Item |Binding support |Minimum browser support

|SAIAction |Full support as required by the individual service request
|As defined by the language

|SAIBoolean |Full Support |Full Support

|SAIBrowserApp |Full Support if createBrowser supported. +
Not required if only getBrowser supported. |Optional +
(based on getBrowser/createBrowser requirements)

|SAIBrowserName |Primitive Type |Full Support

|SAIBrowserRef |Full Support |Full Support

|SAIBrowserVersion |Primitive type |Full Support

|SAIComponentDeclaration |Primitive type describing at least name and
level |Full Support

|SAIComponent |Primitive type |Full Support

|SAIEncoding |Specifies the type of encoding. |Full Support

|SAIExecutionContext |Provides access to a subscene. |Full Support

|SAIFieldAccess |Separate data types for the four types defined by
ISO/IEC 19775-1. |Full Support

|SAIFieldDeclaration |Provide information on access type, data type and
name |Full Support

|SAIField |Full Support |Full Support

|SAIFieldName |Primitive type |Full Support

|SAIFieldType |Separate data types for all types defined in 5 Field type
reference of ISO/IEC 19775-1. |Full Support

|SAIFieldValue |Primitive type as appropriate to the given field. +
Where field is an SF/MFNode shall be SAINodeID |Number of values for
setting and getting as defined in the applicable profile as defined in
<<I19775_1, ISO/IEC 19775-1>>.

|SAIFrameRate |Primitive Type |Full Support

|SAILayerID |Primitive Type |Full Support if the Layering component is
supported.

|SAILoadState |Primitive Type |Full Support

|SAIMatrix |Primitive Type |Full Support

|SAINavSpeed |Primitive Type |Full Support

|SAINode |Full Support |Full Support

|SAINodeType |Primitive type |SAIString representation of the node name

|SAIParameterList |As required by langauge and service definition.
|Dependent on language and browser implementation

|SAIProfileDeclaration |Description of at least name and components used
in the profile |Full Support

|SAIPropertyList |Primitive type |5 key-value pairs. Values dependent on
language bindings

|SAIProtoDeclaration |Full Support |n/a

|SAIRequester |Full Support |Full Support

|SAIRoute |Full Support |Full Support

|SAIScene |Full Support |Full Support

|SAIScript |Full Support |Full Support

|SAIScriptImplementation |Full Support |Full Support

|SAIStream |Full Support |Full Support

|SAIString |Full Support |Full Support

|SAIUnitDeclaration |Full Support |One entry for each type of unit
category.

|SAIURL |Both URL and URN support |As specified in the applicable
profile defined in <<I19775_1, ISO/IEC 19775-1>> for all _url_ fields

|SAIError |Separate types for each error condition that may occur as
defined in <<A2_S5.3, 5.3 Error Types>>. |Generate error conditions as
appropriate
|===

[[t-SpecsForSAIBrowser]]
Table 7.3 — Specifications for SAI browser implementations

[width="100%",cols="25%,25%,25%,25%",]
|===
|Item |Binding support |Minimum internal support |Minimum external
support

|Establishing a connection | | |

|getBrowser, createBrowser |At least one of getBrowser or createBrowser
services shall be provided. |N/A |At least one method of connection with
a browser shall be provided. Unsupported connection methods shall throw
an error.  +
Ignore _SAIParameterList_

|Browser services | | |

|getName |Shall provide |Return NULL if not supported |Return NULL if
not supported

|getVersion |Shall provide |Return NULL if not supported. |Return NULL
if not supported

|getCurrentSpeed |Shall provide |Return 0.0 if not supported |Return 0.0
if not supported

|getCurrentFrameRate |Shall provide |Return 0.0 if not supported |Return
0.0 if not supported

|getSupportedProfiles |Shall provide |Full Support |Full Support

|getProfile |Shall provide |Full Support |Full Support

|getSupportedComponents |Shall provide |Full Support |Full Support

|getExecutionContext |Shall provide |Full Support |Full Support

|createScene |Shall provide |Support creating scenes for the same
profiles and components as used by data encodings. |

|replaceWorld |Full support |Full support |Full support

|importDocument |Shall provide |Return NULL if not supported |Return
NULL if not supported

|loadURL |Shall provide |Full support. Ignore _SAIPropertyList_
parameter values. |Full support. Ignore _SAIPropertyList_ parameter
values.

|setDescription |Shall provide |No restriction |No restriction

|createX3DFromString |Shall provide |Support File Limits  as specified
in the applicable profile defined in <<I19775_1, ISO/IEC 19775-1>>. |

|createX3DFromStream |Provision dependent of language capabilities for
creating raw I/O streams |Support File Limits  as specified in the
applicable profile as defined in <<I19775_1, ISO/IEC 19775-1>>. |

|createX3DFromURL |Shall provide |Support File Limits  as specified in
the applicable profile as defined in <<I19775_1, ISO/IEC 19775-1>>. |

|updateControl |SAIActions of start buffering and end buffering |N/A
|Full support

|registerBrowserInterest |SAIActions of add and remove interest. |Events
for initialization, shutdown, invalid URLs and connection lost. |

|getRenderingProperties |Shall provide |No restrictions |No restrictions

|getBrowserProperties |Shall provide |No restrictions |No restrictions

|setBrowserOptions |Shall provide |No restrictions |No restrictions

|changeViewpoint |Shall provide |No restrictions |No restrictions

|print/println |Shall provide |No restrictions |No restrictions

|dispose |Shall provide |No restrictions |No restrictions
|===

[[t-SpecsForSAIGeneral]]
Table 7.4 — Specifications for SAI general services

[width="100%",cols="34%,33%,33%",]
|===
|Item |Binding Support |Minimum Browser Support

|Execution context services | |

|getSpecificationVersion |Full Support |Full Support

|getEncoding |Shall provide |Full Support

|getProfile |SAIProfileDeclaration |Full support.

|getComponents |SAIComponentDeclarations |Full Support

|getUnits |SAIUnitDeclarations |Full Support

|getWorldURL |Shall provide |Full Support

|getNode |Full Support |Full Support

|createNode |Full Support |Full Support

|createProto |Full Support |Full Support

|namedNodeHandling |SAIActions of add and delete nodes and imports |Full
support.

|getProtoDeclaration |Shall provide |Full Support

|protoDeclarationHandling |SAIActions of add and delete PROTO |Full
Support

|getExternProtoDeclaration |Full Support |Full Support

|externprotoDeclarationHandling |SAIActions of add and delete
EXTERNPROTO |Full support.

|getRootNodes |Shall provide |Full Support

|getRoutes |Shall provide |Full Support

|dynamicRouteHandling |SAIActions of add and delete route |Full support.

|dispose |Shall provide |No restrictions

|Scene services | |

|getMetaData |Shall provide |Full Support

|setMetaData |Shall provide |Full Support

|namedNodeHandling |SAIActions of add and delete exports |Full support

|rootNodeHandling |SAIActions of add and delete nodes |Full support

|Node services | |

|getTypeName |Shall provide |Full support

|getType |Shall provide |no restrictions

|getField |Full Support |All fields shall be accesible dependent on
access rules for internal and external interactions and node lifecycle.

|getFieldDefinitions |Full Support |Full Support

|dispose |Shall provide |No restrictions

|Field services | |

|dispose |Full support |Full support

|getAccessType |Shall provide |Full support

|getType |see SAIFieldType |Full support

|getName |Full Support |Field name without _set__ or __changed_
modifiers

|getValue |get1Value not required |Full Support

|setValue |set1Value not required |Full Support. Where fields are MF
fields, minimum number of values to be supported  as specified in the
applicable profile defined in <<I19775_1, ISO/IEC 19775-1>>.

|registerFieldInterest a|
SAIActions of add and remove interest

outputOnly and the output side of inputOutput fields shall be supported

|As per supported langauge binding(s).

|Route services | |

|dispose |Full support |Full support

|getSourceNode |Full support |Full Support

|getSourceField |Full support |Full Support

|getDestinationNode |Full support |Full Support

|getDestinationField |Full support |Full Support

|Prototype services | |

|isExternProto |Full support |Full Support

|createInstance |Full support |Full Support

|getFieldDefintions |Full support |Full Support

|checkLoadState |Full support |Full Support

|requestImmediateLoad |Full support |Full Support

|Configuration services | |

|getComponentName |Full support |Full Support

|getComponentLevel |Full support |Full Support

|getProfileName |Full support |Full Support

|getProfileComponents |Full support |Full Support

|getProviderName |Full support |Full Support

|getUnitCategory |Full support |Full Support

|getUnitConversion |Full support |Full Support

|getUnitName |Full support |Full Support
|===

[[t-SpecsForSAIScript]]
Table 7.5 — Specifications for SAI script content interaction

[cols=",,",]
|===
|Item |Binding support |Minimum browser support
|setBrowser |Full support |Full Support
|setFields |Full support |Full Support
|initialize |Full support |Full Support
|prepareEvents |Full support |Full Support
|eventsProcessed |Full support |Full Support
|shutdown |Full support |Full Support
|===

[[t-SpecsForSAIUtils]]
Table 7.6 — Specifications for SAI utility services

[cols=",,",]
|===
|Item |Binding support |Minimum browser support
|Matrix |At least 3x3 and 4x4 sizes |Full Support
|===

[[A2_Level2]]
==== 7.3.4 Level 2

A browser conformant to Level 2 shall support everything in Level 1 and
shall support all abstract node types derived from X3DNode for the
components implemented in the browser. The browser shall also support
all additional objects that may be introduced by the implementation.

[[A2_Level3]]
==== 7.3.5 Level 3

A browser conformant to Level 3 shall support all of the requirements of
Level 2 and also support binding specific interfaces for each concrete
node representation.

[[A2_Annevrml97_html]]
== Annex A VRML97 Scripting Backwards Compatibility

[[A2_TableOfContentsAndIntroduction]]
=== A.1 Introduction and topics

[[A2_Introduction]]
==== A.1.1 Introduction

This annex provides a detailed description of how an X3D compliant
application may provide support for backwards compatibility for
scripting code originally designed and implemented for
_<<I14772_1, ISO/IEC 14772-1>> Virtual Reality Modeling Language
(VRML) Functional specification and UTF-8 encoding_. It is provided for
backwards-compatibility purposes only and shall not be required for any
browser to implement if they do not conform to part 1 of ISO/IEC 14772.

The VRML event and scripting model had a number of flaws and
incompatibilities even between languages. It is strongly recommended
that this annex not be implemented by browsers that do not claim to
support ISO/IEC 14772-1 in addition to ISO/IEC 19775-1.

[[A2_Topics]]
==== A.1.2 Topics

Table A.1 lists the topics for this annex.

Table A.1 — *Topics*

* <<A2_TableOfContentsAndIntroduction, A.1 Introduction and topics>>
** <<A2_Introduction, A.1.1 Introduction>>
** A.1.2 Topics
* <<A2_Concepts, A.2 Concepts>>
** <<A2_ConceptsIntroduction, A.2.1 Introduction>>
*** <<A2_RequirementsForBackwardsCompatibility, A.2.1.1 Requirements for
backwards compatibility>>
*** <<A2_DifferencesBetweenVRMLAndX3D, A.2.1.2 Differences between VRML
and X3D>>
** <<A2_BehaviourForUnsupportedScripting, A.2.2 Behaviour for
unsupported scripting>>
** <<A2_BehaviourOnEncounteringExposedFields, A.2.3 Behaviour on
encountering exposedFields>>
* <<A2_ECMAScriptLanguageBinding, A.3 ECMAScript language binding>>
** <<A2_ECMAScriptRequirements, A.3.1 Requirements>>
** <<A2_DeterminatioOfRequiredSpecification, A.3.2 Determination of
required specification>>
** <<A2_SupportedScriptURLs, A.3.3 Supported script URLs>>
*** <<A2_InlineScriptDefinition, A.3.3.1 Inline script definition>>
*** <<A2_ECMAScriptMIMETypes, A.3.3.2 MIME types>>
* <<A2_JavaLanguageBinding, A.4 Java language binding>>
** <<A2_JavaRequirements, A.4.1 Requirements>>
** <<A2_JavaDeterminatioOfRequiredSpecification, A.4.2 Determination of
required specification>>


[[A2_Concepts]]
=== A.2 Concepts

[[A2_ConceptsIntroduction]]
==== A.2.1 Introduction

[[A2_RequirementsForBackwardsCompatibility]]
===== A.2.1.1 Requirements for backwards compatibility

This annex specifies the requirements for browsers that wish to conform
to this specification and also support the ability to run scripts
written for the programmatic interfaces and event model semantics
defined in <<I14772_1, ISO/IEC 14772-1>>, within an X3D environment.
That is, the URL in the Script node specified in _29.4.1 Script_ in
<<I19775_1, ISO/IEC 19775-1>> defines content that uses one of the
interfaces defined in this part of ISO/IEC 19775.

A browser shall not be conformant to this specification if it only
supports scripting interface defined in <<I14772_1, ISO/IEC 14772-1>>.
A conformant browser to this Annex shall also support the full
requirements of this part of ISO/IEC 19775 including all required
language bindings.

[[A2_DifferencesBetweenVRMLAndX3D]]
===== A.2.1.2 Differences between VRML and X3D

The main difference between <<I14772_1, ISO/IEC 14772-1>> and this
part of ISO/IEC 19775 is the definition of the event model.
<<I14772_1, ISO/IEC 14772-1>> leaves many decisions up to the browser
implementer and therefore a lot of Script node content can be
incompatible. The major issue is dealing with the way scene graph
changes are propagated when the user code writes to the field. In the
Java language annex values need to be delivered immediately, yet the
ECMAScript language annex said they are to be deferred until the user
code has exited execution. Such incompatibilities mean supporting direct
backwards compatibility is an optional-only feature.

[[A2_BehaviourForUnsupportedScripting]]
==== A.2.2 Behaviour for unsupported scripting

Determination of the supported script capabilities shall follow the
rules specified in _9 Networking Component_ in <<I19775_1, ISO/IEC
19775-1>>. The browser shall attempt to load the URIs in the required
order, determining whether an individual script file is supported.
Rejection of unsupported script types shall be based on the rules
defined in the corresponding annexes of <<I14772_2, ISO/IEC 14772-2>>.
A browser shall not preferentially support one specification over
another beyond the preference order defined by the script node
definition. For example, if the user content defines a
<<I14772_1, ISO/IEC 14772-1>> conformant script code in the _url_
field before a <<I19775_1, ISO/IEC 19775-1>> conformant script code,
and the browser implementation supports backwards compatibility in a
language as defined in this Annex, then the <<I14772_1, ISO/IEC
14772-1>> script shall be executed.

When user content defines internal interaction code that includes
<<I14772_1, ISO/IEC 14772-1>>-conformant scripts and the browser
implementation does not support backwards compatibility, or does not
support backwards compatibility in that language, the browser shall
ignore that script and move to the next item in the _url_ listings. This
is the same behaviour as not being able to locate a file or the code is
not in a language supported by the browser.

[[A2_BehaviourOnEncounteringExposedFields]]
==== A.2.3 Behaviour on encountering exposedFields

<<I14772_1, ISO/IEC 14772-1>> does not permit the use of read and
write fields (i.e., exposedFields). The use of such fields is permitted
in this part of ISO/IEC 19775. It is possible, though a highly
discouraged practice, to define a scripting node with an exposedField
and define the user code conformant to <<I14772_1, ISO/IEC 14772-1>>.

In this situation, the browser shall treat the exposedField as a
separate set of eventIn, eventOut and field objects. When the
exposedField is written from the event model, the user code shall be
notified like a normal eventIn notification. After this point, the rules
for reading and writing the value of the exposedField semantics defined
in <<A2_inputOutputFieldsContainingNode, 4.8.3.8 inputOutput fields and
the containing node>> shall be followed.


[[A2_ECMAScriptLanguageBinding]]
=== A.3 ECMAScript language binding

[[A2_ECMAScriptRequirements]]
==== A.3.1 Requirements

If a browser intends to support <<I14772_1, ISO/IEC 14772>> backwards
compatibility for the ECMAScript language in the script node, it shall
do so in conformance with _Annex C ECMAScript language binding_ in
<<I14772_1, ISO/IEC 14772-1>>.

[[A2_DeterminatioOfRequiredSpecification]]
==== A.3.2 Determination of required specification

A browser shall determine which version of the specification is
supported through the use of the protocol definition or MIME type given
with the external file. No other indicators shall be used.

[[A2_SupportedScriptURLs]]
==== A.3.3 Supported script URLs

[[A2_InlineScriptDefinition]]
===== A.3.3.1 Inline script definition

Browsers supporting the ECMAScript backwards compatibility shall support
the use of inlined script nodes through the use of the customized
protocol definition _javascript_. The support specified in _7
Conformance and minimum support requirements_ in <<I14772_1, ISO/IEC
14772-1>> is required in addition to the other required protocols for the
ECMAScript specification as specified in _Annex C ECMAScript scripting
reference_ in <<I14772_1, ISO/IEC 14772-1>>. An example of the inlined
script definition is:

....
Script {
    url "javascript: function foo() { ... }"
}
....

The url field may contain multiple URL's referencing either a remote
file or in-line code as shown in the following example:

....
Script {
    url [
        "http://foo.com/myScript.js",
        "javascript: function foo( ) { ... }"
    ]
}
....

The use of the _javascript_ protocol shall require the browser to
support the objects and semantics defined in the Annex A  specification.
It shall be an error for a browser that conforms to this part of ISO/IEC
19775 to support the _javascript_ protocol with script content that uses
Objects defined in Annex A of this part of ISO/IEC 19775.

The use of the _ecmascript:_ protocol shall indicate the script conforms
to Annex A of this part of ISO/IEC 19775. A browser shall not provide
<<I14772_1, ISO/IEC 14772-1>>-defined objects to a script that uses
the _ecmascript:_ protocol.

[[A2_ECMAScriptMIMETypes]]
===== A.3.3.2 MIME types

The MIME type for <<I14772_1, ISO/IEC 14772-1>> ECMAScript source code
is defined as follows:

....
application/javascript
....

For backwards compatibility with old web servers, it is recommended
browsers also support the following mime type:

....
application/x-javascript
....

The use of the `+application/ecmascript+` or
`+application/x-ecmascript+` MIME types shall indicate the script
conforms to Annex A of this specification. A browser shall not provide
VRML-defined objects to a script that uses these MIME types.


[[A2_JavaLanguageBinding]]
=== A.4 Java language binding

[[A2_JavaRequirements]]
==== A.4.1 Requirements

If a browser intends to support <<I14772_1, ISO/IEC 14772-1>>
backwards compatibility for the Java language in the script node, they
shall do so in conformance with _Annex B Java platform scripting
reference_ in <<I14772_1, ISO/IEC 14772-1>>.

[[A2_JavaDeterminatioOfRequiredSpecification]]
==== A.4.2 Determination of required specification

As it is impossible to predetermine which set of classes and interfaces
a Java class file implements through the use of the URL protocol or MIME
type, a browser shall determine which version of the specification is
supported by examining the base class or interfaces implemented by the
user code. Determination of this may be made through the language
introspection capabilities or using the `+instanceof+` operator.

A Java script that claims to support <<I14772_1, ISO/IEC 14772-1>>
shall extend the base class `+vrml.node.Script+`. If a script class file
extends the <<I14772_1, ISO/IEC 14772-1>> base class and implements
the `+org.web3d.x3d.sai.X3DScriptImplementation+` interface then the
browser shall use the X3D SAI semantics and execution and is not
required to support <<I14772_1, ISO/IEC 14772-1>> or objects that
conform to <<I14772_1, ISO/IEC 14772-1>>. It is recommended that a
browser issue a warning when it detects such a situation.


[[B19776_1]]
== Part0l: XML Binding (19776-1)

Extensible 3D (X3D) encodings +
ISO/IEC 19776-1:2015

Part 1:  XML encoding

This document is Part 1 of ISO/IEC 19776, Extensible 3D (X3D) encodings.
The full title of this part of the International Standard is:
_Information technology — Computer graphics, image processing and
environmental data representation — Extensible 3D (X3D) encodings — Part
1: Extensible Markup Language (XML) encoding_.

• <<B1_foreword, Foreword>>
• <<B1_introduction, Introduction>>
• 1 <<B1_scope, Scope>>
• 2 <<B1_references, Normative references>>
• 3 <<B1_definitions, Definitions, acronyms, and abbreviations>> 
• 4 <<B1_concepts, Concepts>>
• 5 <<B1_EncodingOfFields, Encoding of fields>>
• 6 <<B1_EncodingOfNodes, Encoding of nodes>>
• 7 <<B1_conformance, Conformance>>
• A <<B1_DTD, Document Type Definition (DTD)>>
• B <<B1_Schema, XML schema>>
• C <<B1_examples, Examples>>
• <<B1_bibliography, Bibliography>>


The *_Foreword_* provides background on the standards process for X3D
encodings. The *_Introduction_* describes the purpose, design criteria,
and characteristics of X3D encodings. The following clauses define this
part of ISO/IEC 19776:

. *_Scope_* defines the problem area that the XML encoding of X3D
addresses.
. *_Normative references_* lists the normative standards referenced in
this part of ISO/IEC 19776.
. *__Definition__s, acronyms, and abbreviations* contains the glossary
of terminology used in this part of ISO/IEC 19776.
. *_Concepts_* describes various fundamentals of the XML encoding of
X3D.
. *_Encoding of fields_* specifies the XML encoding of data types used
by X3D nodes.
. *_Encoding of nodes_* specifies the XML encoding of X3D nodes.
. *_Conformance_* describes the conformance requirements for
implementations of the XML encoding.

There are several annexes included in the specification:

[upperalpha]
. *_X3D Document Type Definition (DTD)_* presents the DTD grammar for
the X3D XML file format.
. *_X3D Schema_* presents the XML Schema grammar for the X3D XML file
format.
. *_Examples_* includes a variety of XML encoded example files.

*_Bibliography_* lists references which may have more information.


[[B19776_2]]
== Part02: Classic VRML Binding (19776-2)

Extensible 3D (X3D) encodings +
ISO/IEC 19776-2:2015

Part 2:  Classic VRML encoding

This document is the text for Part 2 of ISO/IEC 19776, Extensible 3D
(X3D) encodings. The full title of this part of the International
Standard is: _Information technology — Computer graphics, image
processing and environmental data representation — Extensible 3D (X3D)
encodings — Part 2: Classic VRML encoding_.

• <<B2_foreword, Foreword>>
• <<B2_introduction, Introduction>>
• 1 <<B2_scope, Scope>>
• A <<B2_grammar, Grammar>>
• 2 <<B2_references, Normative references>>
• B <<B2_examples, Examples>>
• 3 <<B2_definitions, Terms, definitions and abbreviated terms>>
• 4 <<B2_concepts, Concepts>>
• 5 <<B2_EncodingOfFields, Encoding of fields>>
• 6 <<B2_EncodingOfNodes, Encoding of nodes>>
• 7 <<B2_conformance, Conformance>>
• <<B2_bibliography, Bibliography>>


The *_Foreword_* provides background on the standards process for X3D
encodings. The *_Introduction_* describes the purpose of X3D encodings.
The following clauses define this part of ISO/IEC 19776:

. *_Scope_* defines the technology area that the Classic VRML encoding
of X3D addresses.
. *_Normative references_* lists the normative specifications referenced
in this part of ISO/IEC 19776.
. *_Definitions_* contains the glossary of terminology used in this part
of ISO/IEC 19776.
. *_Concepts_* describes fundamentals of the Classic VRML encoding of
X3D.
. *_Encoding of fields_* specifies the Classic VRML encoding of data
types used by X3D nodes.
. *_Encoding of nodes_* specifies the Classic VRML encoding of X3D
nodes.
. *_Conformance_* describes the conformance requirements for
implementations of the Classic VRML encoding.

The following annexes are included in the specification:

[upperalpha]
. *_Grammar_* presents the grammar for the X3D Classic VRML file format.
. *_Examples_* includes a variety of Classic VRML encoded example files.

*_Bibliography_* lists references that may have more information.


[[B19776_3]]
== Part03: Compressed Binary Binding (19776-3)

Extensible 3D (X3D) encodings +
ISO/IEC 19776-3:2015

Part 3:  Compressed binary encoding

This document is Part 3 of ISO/IEC 19776, Extensible 3D (X3D) encodings.
The full title of this part of the International Standard is:
_Information technology — Computer graphics, image processing and
environmental data representation — Extensible (X3D) encodings — Part 3:
Compressed binary encoding_.

• <<B3_foreword, Foreword>>
• <<B3_introduction, Introduction>>
• 1 <<B3_scope, Scope>>
• 2 <<B3_references, Normative references>>
• 3 <<B3_definitions, Definitions, acronyms, and abbreviations>>
• 4 <<B3_concepts, Concepts>>
• 5 <<B3_EncodingOfFields, Encoding of fields>> 
• 6 <<B3_conformance, Conformance>>
• A <<B3_tables, Fast infoset tables>>
• B <<B3_nodecompressors, Node compressor registry>>
• C <<B3_examples, Examples>>
• <<B3_bibliography, Bibliography>>

The *_Foreword_* provides background on the standards process for X3D
encodings. The *_Introduction_* describes the purpose, design criteria,
and characteristics of X3D encodings. The following clauses define this
part of ISO/IEC 19776:

. *_Scope_* defines the problem area that the Compressed binary encoding
of X3D addresses.
. *_Normative references_* lists the normative standards referenced in
this part of ISO/IEC 19776.
. *_Definitions_* contains the glossary of terminology used in this part
of ISO/IEC 19776.
. *_Concepts_* describes various fundamentals of the Compressed binary
encoding of X3D.
. *_Encoding of fields_* specifies the Compressed binary encoding of
data types used by X3D nodes.
. *_Conformance_* describes the conformance requirements for
implementations of the Compressed binary encoding.

There are several annexes included in the specification:

[upperalpha]
. *_Fast infoset tables_* specifies the initial table values for each
syntactic element.
. *_Node compressor registry_* contains the listing of all registered
node compressors.
. *_Examples_* includes a variety of examples encoded in the X3D
Compressed binary encoding.

*_Bibliography_* lists references which may have more information.

[[C19777_1]]
== Part1: ECMAScript Binding (19777-1)

Information technology — Computer graphics and image processing —
Extensible 3D (X3D) language bindings +
Part 1: ECMAScript

ISO/IEC CD 19777-1:201x

This document is the Committee Draft of Part 1 of ISO/IEC 19777 Edition
2, Extensible 3D (X3D) language bindings. The full title of this part of
the International Standard is: _Information technology — Computer
graphics and image processing — Extensible 3D (X3D) language bindings —
Part 1: ECMAScript_.

• <<C1_foreword, Foreword>>
• <<C1_introduction, Introduction>>
• 1 <<C1_scope, Scope>>
• 2 <<C1_references, Normative references>>
• 3 <<C1_glossary, Definitions>>
• 4 <<C1_concepts, Concepts>>
• 5 <<C1_tables, Tables>>
• 6 <<C1_types, Type definitions>>
• 7 <<C1_functions, Function definitions>>
• A <<C1_VRMLrelationship, Relationship to ISO/IEC 14772>>
• B <<C1_examples, Examples>>


The *_Foreword_* provides background on the standards process for X3D
language bindings. The *_Introduction_* describes the purpose of X3D
language bindings. The following clauses define this part of ISO/IEC
19777:

. *_Scope_* defines the problem area that the ECMAScript language
binding of X3D addresses.
. *_Normative references_* lists the normative standards referenced in
this part of ISO/IEC 19777.
. *_Definitions_* specifies the terms used in this part of ISO/IEC
19777.
. *_Concepts_* describes various fundamentals of the ECMAScript language
binding of X3D.
. *_Tables_* describes the mapping between abstract names and bound
names.
. *_Type definitions_* specifies the binding of abstract data types to
ECMAScript data types.
. *_Function definitions_* specifies binding of abstract service and
function definitions to ECMAScript function definitions.

There are two annexes included in this part of ISO/IEC 19777:

[upperalpha]
. *_Relationship to ISO/IEC 14772_* describes the relationship to
features of VRML 97
. *_Examples_* includes a variety of ECMAScript bound example files.


[[C19777_2]]
== Part2: Java Binding (19777-2)

Extensible 3D (X3D) language bindings +
Part 2:  Java

ISO/IEC 19777-2:2005

This document is Part 2 of ISO/IEC 19777, Extensible 3D (X3D) language
bindings. The full title of this part of the International Standard is:
_Information technology — Computer graphics and image processing —
Extensible 3D (X3D) language bindings — Part 2: Java._

• <<C2_foreword, Foreword>>
• <<C2_introduction, Introduction>>
• 1 <<C2_scope, Scope>>
• 2 <<C2_references, Normative references>>
• 3 <<C2_concepts, Concepts>>
• 4 <<C2_tables, Tables>>
• 5 <<C2_types, Type definitions>>
• 6 <<C2_functions, Function definitions>>
• A <<C2_compilation, Constructs in compilation order>>
• B <<C2_abstracts, Abstract node interfaces>>
• C <<C2_concretes, Concrete node interfaces>>
• D <<C2_examples, Examples>>

The *_Foreword_* provides background on the standards process for X3D
language bindings. The *_Introduction_* describes the purpose of X3D
language bindings. The following clauses define this part of ISO/IEC
19777:

. *_Scope_* defines the problem area that the Java language binding of
X3D addresses.
. *_Normative references_* lists the normative standards referenced in
this part of ISO/IEC 19777.
. *_Concepts_* describes various fundamentals of the Java language
binding of X3D.
. *_Tables_* describes the mapping between abstract names and bound
names.
. *_Type definitions_* specifies the binding of abstract data types to
Java data types.
. *_Function definitions_* specifies binding of abstract service and
function definitions to Java function definitions.

There are several annexes included in the specification:

[loweralpha]
. *_Compilation order_* contains all bound constructs in compilation
order.
. *_Abstract node interfaces_* contains definitions of Java interfaces
that match with abstract node types defined in IS0/IEC 19775-1.
. *_Concrete node interfaces_* contains definitions of Java interfaces
that match with the concrete nodes defined in IS0/IEC 19775-1.
. *_Examples_* includes a variety of Java bound example files.

